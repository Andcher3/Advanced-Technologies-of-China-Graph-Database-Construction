{Reference Type}: Journal Article
{Title}: 农业领域多模态融合技术方法与应用研究进展
{Author}: 李道亮;赵晔;杜壮壮
{Author Address}: 中国农业大学信息与电气工程学院;国家数字渔业创新中心;
{Journal}: 农业机械学报
{Year}: 2025
{Volume}: 56
{Issue}: 01
{Pages}: 1-15
{Keywords}: 多模态融合;传感器;遥感技术;作物监测;计算机视觉;农业精准管理
{Abstract}: 多模态融合技术通过结合多源数据，可以克服单一模态的局限性。近年来，传感器以及遥感技术的发展为作物监测提供了更加丰富的数据源，光谱数据、图像数据、雷达数据以及热红外数据被广泛应用于作物监测中。通过利用计算机视觉技术以及数据分析方法，可以从中获取作物的表型参数、理化特征等信息，从而有助于评估作物的生长状况、指导农业生产管理。现有研究多数是基于单一模态数据展开，而单一模态的数据仅有一种类型的输入，缺乏对整体信息的理解，且容易受到单模态噪声的影响；部分研究虽然采用了多模态融合技术，但仍未能充分考虑模态间的复杂交互关系。为了深入分析多模态融合技术在农业领域应用的潜力，本文首先阐述了农业领域中多模态融合的先进技术与方法，重点梳理了多模态融合技术在作物识别、性状分析、产量预测、胁迫分析及病虫害诊断领域中的应用研究成果，分析了多模态融合技术在农业领域中存在的数据利用程度低、有效特征提取难、融合方式单一等问题，并对未来发展提出展望，以期通过多模态融合的方法推动农业精准管理、提高生产效率。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz5cL6k79XB00_EZAaaZ-4_-Fc-h4484EVSJhek-ju9uSfA1VjhMwETKqIx0KXKL3F6dUaEFlmKB8beDpl6GAlkWxpSDLFk45EcvFdoHnAC79YdE1ghKFfX7rasy1Xs0yL4tgR6y2vVStMLFrjDFtMf9PT3ZJ6ObsQQYZbR7VDGi4vvEe3-KxQoHk4H2-oNhME=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像篡改检测方法综述
{Author}: 张汝波;蔺庆龙;张天一
{Author Address}: 大连民族大学机电工程学院;北京航空航天大学网络空间安全学院;
{Journal}: 智能系统学报
{Pages}: 1-22
{Keywords}: 深度学习;图像篡改检测;计算机视觉;卷积神经网络;图像处理;图像取证;图像伪造;伪造检测
{Abstract}: 随着数字图像编辑工具的普及，图像篡改变得越来越容易，大量被篡改后的虚假图像通过网络和社交媒体进行传播，这对法律、新闻媒体和科学研究等领域的真实性和可信度构成了威胁。图像篡改检测的目的是检测和定位篡改图像中的篡改区域，以保护图像的可信度。本文对基于深度学习的篡改检测方法进行了回顾总结。首先，介绍了目前图像篡改检测领域的研究现状。其次，对近5年的深度学习方法进行了分类整理。然后，介绍了主要的数据集和评价指标，以及各种方法的性能对比。最后，探讨了目前篡改检测方法的局限性并对未来的发展方向进行了展望。
{ISBN/ISSN}: 1673-4785
{Notes}: 23-1538/TP
{URL}: https://link.cnki.net/urlid/23.1538.TP.20250123.1117.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的多视图立体视觉综述
{Author}: 樊铭瑞;申冰可;牛文龙;彭晓东;谢文明;杨震
{Author Address}: 中国科学院国家空间科学中心;中国科学院大学;国科大杭州高等研究院;
{Journal}: 软件学报
{Year}: 2025
{Issue}: 04
{Pages}: 1692-1714
{Keywords}: 深度学习;计算机视觉;三维重建;多视图立体视觉
{Abstract}: 多视图立体视觉在自动驾驶、增强现实、遗产保护和生物医学等领域得到广泛应用.为了弥补传统多视图立体视觉方法对低纹理区域不敏感、重建完整度差等不足,基于深度学习的多视图立体视觉方法应运而生.对基于深度学习的多视图立体视觉方法的开创性工作和发展现状进行综述,重点关注基于深度学习的多视图立体视觉局部功能改进和整体架构改进方法,深入分析代表性模型.同时,阐述目前广泛使用的数据集及评价指标,并对比现有方法在数据集上的测试性能.最后对多视图立体视觉未来有前景的研究发展方向进行展望.
{ISBN/ISSN}: 1000-9825
{Notes}: 11-2560/TP
{URL}: https://link.cnki.net/doi/10.13328/j.cnki.jos.007248
{DOI}: 10.13328/j.cnki.jos.007248
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果分拣算法综述
{Author}: 安晓东;李阳;刘柳;钟佳
{Author Address}: 郑州航空工业管理学院机械工程学院;
{Journal}: 自动化技术与应用
{Pages}: 1-12
{Keywords}: 机器视觉;水果分拣;深度学习;图像分割;光谱成像技术
{Abstract}: 机器视觉检测技术是农业水果自动化分拣系统的关键技术之一，其中水果目标特征的识别准确度对农业自动化生产过程具有重要影响。近年来，计算机技术飞速发展，深度学习算法在水果目标检测任务中表现出优良的性能。提出基于机器视觉技术在农业水果分拣领域的应用，针对图像分割算法、水果目标检测算法、深度学习与光谱成像融合检测技术三个方面进行归纳总结。最后分析了机器视觉技术在水果分拣中的应用挑战和未来发展趋势。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/urlid/23.1474.TP.20241230.1344.163
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在食品无损检测中的应用研究进展
{Author}: 唐彦嵩;徐锐豪;王夙加
{Author Address}: 清华大学深圳国际研究生院;
{Journal}: 中国食品学报
{Year}: 2024
{Volume}: 24
{Issue}: 12
{Pages}: 13-27
{Keywords}: 食品无损检测;食品安全;机器视觉;机器学习;深度学习
{Abstract}: 随着全球食品消费需求的增加，食品无损检测技术在食品质量控制和安全保障中变得日益重要。本文系统综述机器视觉在食品无损检测中的应用与发展趋势。通过分析当前文献，探讨包括RGB成像、多光谱成像、高光谱成像等多种成像技术，以及图像处理、机器学习和深度学习等检测算法在食品无损检测中的应用。分析机器视觉在食品无损检测中应用的技术挑战，如数据集的匮乏和模型在通用场景下泛化能力不足。基于当前研究现状，展望未来的研究方向，提出多模态数据融合、嵌入式检测系统以及与深度学习技术的紧密结合等可能的发展路径，旨在为食品无损检测技术的创新提供参考和方向。
{ISBN/ISSN}: 1009-7848
{Notes}: 11-4528/TS
{URL}: https://link.cnki.net/doi/10.16429/j.1009-7848.2024.12.002
{DOI}: 10.16429/j.1009-7848.2024.12.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的类球状水果采摘识别算法研究进展
{Author}: 李辉;张俊;俞烁辰;李志鑫
{Author Address}: 湖州师范学院信息工程学院;浙江省农业科学院食品科学研究所;
{Journal}: 果树学报
{Year}: 2025
{Volume}: 42
{Issue}: 02
{Pages}: 412-426
{Keywords}: 水果采摘;目标检测算法;深度学习;卷积神经网络;计算机视觉
{Abstract}: 中国在水果产量方面处于全球领先地位，但因人力资源减少和老龄化问题，传统的人工采摘方式已经无法满足快速高效的采摘需求，研发集成计算机视觉的自动化水果采摘设备成为解决劳动力短缺难题的关键。水果大多呈类球状，相关的识别算法研究居多，探讨了柑橘、蜜桃等类球状水果的识别算法。根据应用场景的不同，分析了传统类球状水果识别算法与基于深度学习的类球状水果识别算法在网络结构方面的差异与改进，对水果采摘识别算法进行总结并提出算法的未来发展趋势。传统算法在简单场景下表现有效，但在复杂环境中往往会受到设计特征的限制，基于深度学习的算法因其高效性和准确性更适合自动化水果采摘的需求。总结了类球状水果识别算法的研究进展，在处理复杂环境时深度学习算法具有良好的有效性和适应性，更适合部署在自动化采摘设备；也提出了未来的研究方向，即通过优化算法性能、数据集构建及扩增，以及结合多模态数据提升算法的精度和适应性。
{ISBN/ISSN}: 1009-9980
{Notes}: 41-1308/S
{URL}: https://link.cnki.net/doi/10.13925/j.cnki.gsxb.20240309
{DOI}: 10.13925/j.cnki.gsxb.20240309
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在农作物病虫害监测中的应用
{Author}: 韩庆江
{Author Address}: 山西应用科技学院;
{Journal}: 南方农机
{Year}: 2024
{Volume}: 55
{Issue}: S1
{Pages}: 58-60+77
{Keywords}: 计算机视觉;农作物病虫害;监测技术;图像识别
{Abstract}: 【目的】农业现代化的发展使得农作物遭受病虫侵害的情况日益繁多且复杂，农作物病虫害监测技术面临着监测难题，研究计算机视觉技术在农作物病虫害中的应用具有重要现实意义。【方法】深入分析了计算机视觉技术在农作物病虫害监测中的应用优势，评估了计算机视觉技术在病虫害监测中的效率和准确性，研究并优化了图像采集、特征提取和识别算法等关键技术，设计并实现了一个综合的病虫害监测系统，同时进行了性能评估。【结果】在多次现场测试中，由此系统完成的检测准确率超过85%，该监测系统可帮助农民迅速采取行动，降低了约20%的化学药剂使用量，相比传统人工监测方法，计算机视觉系统能处理更多影像数据并覆盖更广阔农业区域，从而大幅提升监控效率。【结论】计算机视觉技术显著提升了诊断精度与效率，有助于促进精准农业的发展。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvws104EfwHHI7tqO1NAQ_5M_HK_TvwOx0Cpvyw4xIOx2wmBNOQfN9FzMvNIiV2oWGN9sukxtMgbM-LhleHXeYGr4tILkBE-f1oap2UuoCmzSi5gthcxDCOUXnAfB-656G3SYMiWTpj8MWgazZNRnGnoanfP-SDyjTF7EXYqABwVMd6Vqh9moJ-2BrxX1qDUKfM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属表面缺陷检测
{Author}: 付山;谢晖;易建业
{Author Address}: 湖南大学机械与运载工程学院;季华实验室;
{Journal}: 电镀与精饰
{Year}: 2024
{Volume}: 46
{Issue}: 12
{Pages}: 145-146
{Abstract}: <正>金属是很多金属制品生产过程中的重要原材料，随着社会工业发展水平的不断提高，企业生产的金属工件更加精细、复杂。在汽车、医疗、航空航天等领域，金属材料更是起着不可替代的作用。在实际生产中，某些行业使用的金属制品对金属工件的表面质量要求十分严格。受材料本身质量、加工工艺水平、搬运及运输防护条件等多种因素影响，厂商提供的金属工件可能会存在划痕、凹凸、粘结、辊印等表面缺陷，这些缺陷不仅会影响工件的美观性，还可能影响工件的耐受性、抗疲劳性、抗腐蚀性等，甚至直接影响工件的功能，对后其续使用造成不可估量的影响，导致企业、社会的经济效益受损。因此检测金属表面缺陷并对金属表面缺陷造成工件功能失采取预防措施成为目前金属加工企业的重点研究内容。为更好地改善金属表面质量，人们提出多种缺陷检测技术，其中基于机器视觉的金属表面缺陷检测技术便是一种典型方法，下文简单介绍基于机器视觉的金属表面缺陷检测技术原理与特点，描述其具体的实现方法，为企业解决金属表面质量问题提供参考。
{ISBN/ISSN}: 1001-3849
{Notes}: 12-1096/TG
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwmVQ35jQJqOq2CPCI15sYPAu1aoy0PDC7STZUnBvflmR_tOrlICrDWa1UG3Wrfyy6T43JHpURPZlqJvYaMYI-nuhPdpjJEmIJQDKtT_Nu4wVULPxbu4WpLODSOKGLY6jNeLK-OmJpa8ty0jBlXJllWxFHFXqnF0rvDJnKG5PuUXcpUUIluKOWUeFwpsIL45oc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像字幕生成综述
{Author}: 周峻宇;施水才;王洪俊
{Author Address}: 北京信息科技大学计算机学院;拓尔思信息技术股份有限公司;
{Journal}: 软件导刊
{Year}: 2025
{Volume}: 24
{Issue}: 01
{Pages}: 211-220
{Keywords}: 图像字幕生成;深度学习;跨模态;计算机视觉;自然语言处理
{Abstract}: 图像字幕生成是一个重要且充满挑战的研究领域，旨在为静态图像生成自然语言描述，其在深度学习和视觉—语言预训练技术的推动下取得明显进步。阐述深度学习方法在图像字幕生成中的应用，介绍几种基于深度学习的模型和算法，包括循环神经网络、卷积神经网络、对抗生成网络和Transformer等模型，以及最新的视觉—语言预训练技术。这些模型在图像字幕生成任务中发挥了重要作用，通过学习图像与语言之间的关联，能够生成准确且流畅的描述。同时，强调该领域面临的挑战，如物体虚构、缺失上下文、光照条件、语境理解和指代表达等问题，需要模型具备推理能力。未来，将进一步提高图像字幕生成的性能和质量，推动其在实际应用中的应用。
{ISBN/ISSN}: 1672-7800
{Notes}: 42-1671/TP
{URL}: https://link.cnki.net/urlid/42.1671.TP.20241210.1645.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业零件智能分拣系统设计
{Author}: 陈宜涛;方成刚;张文东;程丽娟
{Author Address}: 南京工业大学机械与动力工程学院;
{Journal}: 工业仪表与自动化装置
{Year}: 2024
{Volume}: 
{Issue}: 06
{Pages}: 24-29
{Keywords}: 机器视觉;工业机器人;物体分拣;标定;识别抓取
{Abstract}: 针对工业生产中机器视觉与机器人结合广泛的应用需求，该文设计了一种智能分拣系统，该系统基于机器视觉技术，能够识别并定位传送带上运动的目标物体。该系统通过对相机和坐标系的标定来保证机器人识别抓取的定位精度，利用YOLOv5检测算法识别传送带上的目标物体，并采用形心坐标法来确定目标物体的中心像素坐标，然后运用仿射变换方法来实现对目标物体的精确定位。实验结果表明，本智能分拣系统在工业分拣零件的过程中特定目标工件识别的准确率可以达到98%以上，而机器人定位抓取目标工件的精度误差保持在1 mm以内。因此设计的智能分拣系统能够对工业生产中的零件进行高精度的识别定位及抓取，该系统能够有效地满足工业生产中对于零件自动分拣的精确要求，显示出其在工业自动化领域的广泛应用潜力。
{ISBN/ISSN}: 1000-0682
{Notes}: 61-1121/TH
{URL}: https://link.cnki.net/doi/10.19950/j.cnki.CN61-1121/TH.2024.06.005
{DOI}: 10.19950/j.cnki.CN61-1121/TH.2024.06.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像的虚拟试衣综述——从深度学习到扩散模型
{Author}: 杨浩哲;郭楠
{Author Address}: 东北大学计算机科学与工程学院;
{Journal}: 计算机工程与应用
{Pages}: 1-21
{Keywords}: 计算机视觉;虚拟试衣;翘曲处理;图像合成;扩散模型
{Abstract}: 基于图像的虚拟试衣作为虚拟试衣领域经济便利的一种技术形式，旨在通过模特图像与服装图像来合成逼真的试穿效果，其在网购、服装设计、动画等领域都受重点关注。近年来，以扩散模型为代表的生成式大模型凭借其相比传统深度学习方法更强大的生成能力，推动了该领域的新突破与变革。然而领域内缺乏对大模型时代下对基于图像的虚拟试衣研究的进一步分析与全面概述。本文对基于图像的虚拟试衣进行汇总，按照数据预处理、翘曲生成和试穿结果生成这三步基线技术流程，对主流技术方法进行了划分和解析，对所引的领域代表性文献所用的实现方案进行详细分析，并对主要流程方法进行总结与对比。介绍基于图像的虚拟试衣的常用数据集、评价指标与损失函数。最后，结合所引的领域代表性文献对大模型时代下基于图像的虚拟试衣存在的困难与不足进行详细分析与分类，并据此对相关技术的未来发展与改进方向进行概括与展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20241209.1400.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能机器人路径规划系统设计
{Author}: 王舒平
{Author Address}: 中国石油集团电能有限公司;
{Journal}: 自动化技术与应用
{Pages}: 1-7
{Keywords}: 智能机器人;机器视觉;路径规划;信息交互;系统设计
{Abstract}: 智能机器人避障能力不足会影响机器人工作效率，为了增强多领域内智能机器人的工作效率，设计基于机器视觉的智能机器人路径规划系统。通过构建单片机控制单元、驱动电路模块、机器视觉模块和信息交互模块，完成系统的硬件部分设计，为机器人机械运动提供能源并采集机器人所处环境的视频和图像。以视频和图像作为信息交互材料进行环境图像的预处理及障碍物检测，TLD实时目标跟踪，智能机器人的路径规划，引导智能机器人完成目标任务，实现系统的软件部分设计。实验结果表明，所设计系统在不同环境下均具备较高的效率和较强的避障能力，能够实现设计目的。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/urlid/23.1474.TP.20241203.1422.030
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 手机表面缺陷的机器视觉检测方法研究进展
{Author}: 吴一全;庞雅轩
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 智能系统学报
{Year}: 2025
{Volume}: 20
{Issue}: 01
{Pages}: 33-51
{Keywords}: 机器视觉;缺陷检测;手机屏幕玻璃盖板;手机外壳;深度学习;数据集;性能评价指标;图像处理
{Abstract}: 智能手机在现代人们的学习、工作与生活中扮演着十分重要的角色，手机的大批量生产给手机表面(手机屏幕玻璃盖板、手机外壳)缺陷检测工作提出了更高的要求，而基于机器视觉的检测方式能够更加快速准确地实现对手机表面缺陷的检测。以该领域面临的挑战为思路，总结了近10年来基于机器视觉的手机表面缺陷检测的研究进展。首先列举了手机表面存在的典型缺陷，并分析了机器视觉应用于手机表面缺陷检测工作中面临的部分难题，其中包括算法的精度、实时性、鲁棒性3个方面；然后分别针对上述问题的改进方法进行了分析与对比；进一步总结了目前可供使用的手机表面缺陷数据集及算法的性能评价指标；最后根据手机表面缺陷检测领域面临的问题进行了总结与展望。
{ISBN/ISSN}: 1673-4785
{Notes}: 23-1538/TP
{URL}: https://link.cnki.net/urlid/23.1538.tp.20241126.1610.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 卷积神经网络目标检测算法研究进展
{Author}: 任青阳;王彦丁;施俭
{Author Address}: 重庆交通大学山区桥梁及隧道工程国家重点实验室;重庆交通大学土木工程学院;
{Journal}: 科学技术与工程
{Year}: 2024
{Volume}: 24
{Issue}: 32
{Pages}: 13665-13677
{Keywords}: 卷积神经网络(CNN);目标检测;计算机视觉;特征表示
{Abstract}: 随着深度学习的进步，卷积神经网络(convolutional neural network, CNN)在目标检测领域的应用取得了显著的提升。相比传统人工特征构造的方法，CNN算法具备自动特征提取和强大的泛化能力，在复杂场景下，目标检测任务得到更好的解决。此外，该算法具有更好的鲁棒性，使其在实际应用中具备更高的可靠性和效率。首先回顾卷积神经网络的发展历程，重点介绍其在计算机视觉领域的应用，并突出与传统算法相比在图像处理方面的明显优势。接着，对分类与分割算法、目标检测算法和基于区域与回归检测的3种主流算法进行介绍，特别强调各类算法在解决目标定位、分类和语义分割等关键问题上的创新和突破。然后，对现有的公开数据集进行归纳。最后，展望目标检测算法未来的发展趋势。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwWj_Wgv3NxE24SWq1CEj1IZXW0yMSy4__7zspqnEQFF_NbEAJWD8n2-Tn9Yl5dRpXRoGTiMKn-uCi8fh07WmDq-u_82-AHJAy6vA31DO7NQZUg0I1vTyLj5l36PaCh5YLCKyRQzQJiE_EfVBrea7le47rOYvePeQ-fn9AERcq1GdDl7_5Z6PU0gjOMGJrxT_Y=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的干眼检测算法综述
{Author}: 刘俊;张志;万光荣;林铭炜
{Author Address}: 重庆邮电大学软件工程学院;福建师范大学计算机与网络空间安全学院;
{Journal}: 福建师范大学学报(自然科学版)
{Year}: 2024
{Volume}: 40
{Issue}: 06
{Pages}: 19-29
{Keywords}: 干眼症;泪河高度;泪膜破裂时间;睑板腺;深度学习
{Abstract}: 对当前干眼检测算法的研究进展进行总结和分析。首先，介绍干眼症基本概念和识别干眼症的重要指标。其次，将现有检查方法和算法按照泪河高度检查、泪膜破裂时间测定、睑板腺功能检查进行介绍和分析。通过对不同算法的总结和分析，比较各自算法的优点并归纳缺点。最后，对待解决的相关问题进行讨论，并展望干眼检测未来发展趋势。
{ISBN/ISSN}: 1000-5277
{Notes}: 35-1074/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwMsceyAumtX5kPmDzeA5qT12D58jqyQQMQp3TIh44qmiSK5UWsNG0-BLawXuMl-xS5w632QRa_AJR704AMX75EmHQPYw3hLggMc5DDtYWFMhyqateEv7qSvP7rmDy632Oq4Vxp7uhE7fpD7363-dGEnR85PxkV4tELTrZhiFb1a2OlnQGX5oobAQ3AqkqUyoQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的计算机视觉在隧道衬砌病害检测中的应用综述
{Author}: 张令心;王茂岑;谢贤鑫;沈俊凯;李宁
{Author Address}: 中国地震局工程力学研究所地震工程与工程振动重点实验室;地震灾害防治应急管理部重点实验室;上海建工四建集团有限公司;
{Journal}: 建筑结构
{Year}: 2024
{Volume}: 54
{Issue}: 20
{Pages}: 143-155+142
{Keywords}: 隧道工程;隧道衬砌;病害检测;计算机视觉;深度学习
{Abstract}: 隧道衬砌作为隧道的重要支撑结构，对其中存在的病害进行检测显得十分重要。然而，传统的隧道病害检测方法高度依赖人工，效率低下，并且存在一定的安全风险，因此，如何高效、安全地实现病害的自动检测成为了热门的方向之一。深度学习（DL）和计算机视觉（CV）被视为实现隧道衬砌病害自动检测的具有发展前景的方法。为了阐明DL技术和CV技术在病害检测中的研究与应用，总结了隧道衬砌病害检测技术的发展历程；基于数据对于DL模型训练的重要性，总结了衬砌病害数据集的建立过程；随后，总结了基于DL的CV技术在隧道衬砌表面病害和内部病害检测方面的方法和应用；最后，讨论了目前研究中存在的问题，并对未来的发展进行了展望。
{ISBN/ISSN}: 1002-848X
{Notes}: 11-2833/TU
{URL}: https://link.cnki.net/doi/10.19701/j.jzjg.TK24007
{DOI}: 10.19701/j.jzjg.TK24007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机器人环境感知技术研究
{Author}: 黄晓清;朱荣钊
{Author Address}: 厦门华天涉外职业技术学院信息技术学院;湖北大学计算机与信息工程学院;
{Journal}: 太原学院学报(自然科学版)
{Year}: 2024
{Volume}: 42
{Issue}: 04
{Pages}: 24-29
{Keywords}: 机器视觉;环境感知;巡检机器人
{Abstract}: 环境感知技术是巡检机器人场景应用的核心技术，对传统单目感知技术存在的环境适应性差的问题，提出了融合雷达感知和视觉感知的双目环境感知技术。通过雷达外参、相机外参、相机内参建立了5个坐标系之间的转换关系，实现了雷达传感与视觉传感之间的有效融合。将其应用于矿井用巡检机器人环境感知中，采用Canny边缘检测算法检测图像边缘，SVM实现图像语义分割。通过样机实验验证了雷达传感与视觉传感融合的双目感知技术对环境的感知能力比较强，感知结果明显优于单独的视觉感知和雷达感知。这对巡检机器人在复杂、恶劣环境下的应用提供了技术支撑。
{ISBN/ISSN}: 2096-191X
{Notes}: 14-1386/G4
{URL}: https://link.cnki.net/doi/10.14152/j.cnki.2096-191X.2024.04.004
{DOI}: 10.14152/j.cnki.2096-191X.2024.04.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的表面微小缺陷检测方法综述
{Author}: 郑太雄;黄鑫;尹纶培;朱意霖;江明哲
{Author Address}: 重庆邮电大学先进制造工程学院;
{Journal}: 重庆邮电大学学报(自然科学版)
{Year}: 2024
{Volume}: 36
{Issue}: 05
{Pages}: 954-965
{Keywords}: 注意力机制;缺陷检测;特征提取;特征融合;生成对抗网络;计算机视觉
{Abstract}: 表面微小缺陷具有尺度小、对比度低和样本数量不足等特点，导致基于深度学习的缺陷检测精度低和漏检率高，故基于视觉的表面微小缺陷检测一直是一项具有挑战性的工作。研究发现，增强网络模型特征提取能力、减少特征丢失或梯度消失以及采用注意力机制关注图像中重要的区域有利于提高表面微小缺陷的检测精度。该文系统分析了能够有效提高表面微小缺陷检测精度的ResNet、DenseNet、FPN等网络结构，总结了注意力机制在表面微小缺陷检测中的应用，分析了生成对抗网络(generative adversarial networks, GAN)针对表面微小缺陷样本不足问题的解决方案和具体应用，全面总结了微小表面缺陷检测中有效的网络结构和解决机制。
{ISBN/ISSN}: 1673-825X
{Notes}: 50-1181/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwMflAUVi3OB1Mj5kOLLHYWXPmudH0cAFaqdR-ajQk09yDAeBippGnjtSv81HsZ_Vm85Ti6lbiUGuOQHEHMiU_0L2MWyVSoDp0jbqmIw12LhnkXh8TD6ChRKBvxD2gVxGozzLwkBvCQZUTQ3lf_TxIVq08-FEg9zPLKfrkPX7Wvybwxwj8eDvEcn_wt5Drz00E=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉番茄采摘机器人系统的研究
{Author}: 郭骐纲
{Author Address}: 无锡索威尔信息科技有限公司;
{Journal}: 农业装备技术
{Year}: 2024
{Volume}: 50
{Issue}: 05
{Pages}: 11-13+23
{Keywords}: 机器视觉;采摘;机器人系统;人工智能
{Abstract}: 随着现代农业技术的发展，自动化采摘机器人在农业生产中扮演着越来越重要的角色。文章综述了基于机器视觉的采摘机器人系统的研究进展，重点探讨了在自然光照多变、作业空间复杂、作业对象多样等复杂环境下的精准识别技术。通过分析现有的图像处理、深度学习和多传感器融合技术，提出了未来的研究方向和挑战。随着技术的不断发展，基于机器视觉的采摘机器人系统将为现代农业发展提供更加高效和智能的解决方案。
{ISBN/ISSN}: 1671-6337
{Notes}: 32-1646/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy4bd19n44Jtb09o5siQeAk0lmj69PRWiaAzE4rdQLWchij_wxwF5o2_7y2nJbWu-UCa71-qiGvZLcl2z-3yM3e7dPOcSpD8AnmJ6tZQNRUmvn4SH6-yjdoJvyZL8UL_zpFkstzkRJQjKRwHy0V4orU_8Dmu0-n3qmZ9ttv3TWHddHp4k3xPtwRylkXYKZDMxM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与多传感器融合的智能番茄采摘机器人设计
{Author}: 张炜;史桐源;沈博源;伊硕;王瀚宇
{Author Address}: 郑州科技学院;
{Journal}: 农业技术与装备
{Year}: 2024
{Volume}: 
{Issue}: 09
{Pages}: 13-16+19
{Keywords}: 机器视觉;采摘机器人;路径优化;番茄采摘
{Abstract}: 设计了一款番茄采摘机器人，它可以自动规划进入温室的路径，识别和采摘成熟的番茄。智能采集机器人关键组件涵盖控制器、逻辑控制器等；规划最佳收获路径的过程中，为了规避收获机器人机械臂的潜在障碍，对采集的图像数据进行了严格的预处理，随后采用高精度的双目视觉系统，通过图像匹配和三维重建技术，准确获取果园中水果与蔬菜的三维空间位置信息；在此基础上结合霍夫变换算法与深度学习算法，自动规划出最优化的收获路径。精密测试结果和运动轨迹表明机器人成功收获率约为85%，满足采摘要求。
{ISBN/ISSN}: 1673-887X
{Notes}: 14-1343/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxbPQ1zje2s9hzVcfxyGgjJ0llrypbPFqHRDp3p0wt0Tppl4HKMzb6SCs4AK85e8mB9kb4rlicxibWXScbOTSnEXLQGqRZYHjZDfsLV33FiOcTmzw0XOE5JlbCI1KQC4ahzM95XLREabJiu0pIZRr9RpkYaINM6dGN9fVOdeESzBa7MAc18Yw2wG-DGmDzoMlU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种改进YOLOv5s的森林火灾烟雾检测算法
{Author}: 张立国;张琦;金梅;袁煜淋;王泓沣
{Author Address}: 燕山大学电气工程学院;
{Journal}: 计量学报
{Year}: 2024
{Volume}: 45
{Issue}: 09
{Pages}: 1314-1323
{Keywords}: 机器视觉;火灾烟雾检测;深度学习;YOLOv5s;轻量化;小目标检测;Focal-EIOU
{Abstract}: 提出一种基于改进YOLOv5s的森林火灾烟雾检测算法。构建包含16573幅图片的火焰烟雾数据集，解决训练数据不足的问题，提高训练模型的泛化能力。设计一种轻量化的GC-C3模块替换原有的C3模块，减少模型参数量和计算量；将加权双向特征金字塔网络结构融合到Neck结构中，增强网络对于中小目标的检测能力；修改网络空间金字塔池化结构，使用SimSPPF结构替换SPPF,提高了网络的计算效率和检测准确度；将边界框回归损失函数CIOU替换为Focal-EIOU,加快模型的收敛速度，解决正负样本不匹配的问题。实验结果表明：改进之后的网络平均检测准确度提高2.3%,模型参数数量下降46.7%,模型计算量下降47.5%。
{ISBN/ISSN}: 1000-1158
{Notes}: 11-1864/TB
{URL}: https://link.cnki.net/urlid/11.1864.tb.20240920.1522.030
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉工件识别定位与抓取研究
{Author}: 赵岩;程家浩;王震;闫仕程;康军
{Author Address}: 天津理工大学电气工程与自动化学院;
{Journal}: 天津理工大学学报
{Pages}: 1-8
{Keywords}: 机器视觉;目标定位;模板匹配;改进Linemod-2D;机器人抓取
{Abstract}: 针对传统的机器人工件抓取过程中识别精度低的问题，提出了一种最大类间方差法（Nobuyuki Otsu）与改进的Linemod-2D算法相结合的方法对工件识别定位与抓取研究。Otsu对图像双边阈值计算，Canny算子对图像边缘提取，最后对图像的边缘离散化，提高了工件识别的实时性和准确性，增加了工件识别的鲁棒性。同时，将Linemod-2D的梯度量化增加到16个方向，金字塔的层数可以根据目标图像大小自适应加快匹配速度。DH参数法对机器人仿真分析，控制Dobot CR5机器人的运动，实现了对工件的抓取和放置。实验结果与预期相符，满足智能制造中的实际需求。
{ISBN/ISSN}: 1673-095X
{Notes}: 12-1374/N
{URL}: https://link.cnki.net/urlid/12.1374.n.20240914.1047.038
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 工业机器人中机器视觉的应用
{Author}: 陶禹龙
{Author Address}: 北京邮电大学计算机学院(国家示范性软件学院);
{Journal}: 模具制造
{Year}: 2024
{Volume}: 24
{Issue}: 09
{Pages}: 168-170
{Keywords}: 机器视觉;工业机器人;深度学习;智能化
{Abstract}: 随着工业自动化技术的发展，机器视觉在工业机器人领域的应用日益重要。概述了工业机器人现状和机器视觉技术原理，分析了图像采集、分析处理及深度学习在机器视觉中的应用，并探讨了实际应用中的挑战和解决方案。结论指出，机器视觉是推动工业自动化的关键力量，为生产提供智能高效方案。未来，在人工智能背景下，机器学习和深度学习将促进机器视觉在工业机器人领域的广泛应用和发展。
{ISBN/ISSN}: 1671-3508
{Notes}: 44-1542/TH
{URL}: https://link.cnki.net/doi/10.13596/j.cnki.44-1542/th.2024.09.055
{DOI}: 10.13596/j.cnki.44-1542/th.2024.09.055
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 无人机航拍图像中绝缘子缺陷检测的深度学习方法研究进展
{Author}: 刘传洋;吴一全;刘景景
{Author Address}: 南京航空航天大学电子信息工程学院;池州学院机电工程学院;
{Journal}: 电工技术学报
{Pages}: 1-21
{Keywords}: 绝缘子缺陷检测;无人机航拍图像;深度学习;计算机视觉
{Abstract}: 依托计算机视觉和深度学习技术，从海量的无人机航拍图像中实现绝缘子缺陷检测，已经成为电力运维工作亟待解决的问题。近年来，深度学习方法在绝缘子缺陷检测任务中表现出了优异的性能。该文综述了无人机航拍图像中绝缘子缺陷检测的深度学习方法研究进展。首先，简述了基于深度学习的输电线路巡检研究现状；其次，阐述了基于深度学习的绝缘子缺陷检测方法，主要从目标检测模型、轻量化网络模型、级联检测模型以及其他方法进行归纳总结，按照深度学习算法的发展历程，阐明了基于双阶段、单阶段、Anchor-free的目标检测算法，概述了轻量化网络、级联检测在绝缘子缺陷检测中的应用；然后，介绍了用于绝缘子缺陷检测的公开和自建数据集；最后，指出了深度学习技术在绝缘子缺陷检测应用中存在的问题，并对未来研究工作进行了展望。
{ISBN/ISSN}: 1000-6753
{Notes}: 11-2188/TM
{URL}: https://link.cnki.net/doi/10.19595/j.cnki.1000-6753.tces.240610
{DOI}: 10.19595/j.cnki.1000-6753.tces.240610
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于半监督学习的水下鱼群目标识别与跟踪系统研究及实现
{Author}: 高浩天
{Tertiary Author}: 于红;温锡圣
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 多目标跟踪;目标检测;半监督学习;YOLOv7;DeepSORT
{Abstract}: 水下鱼群目标识别与跟踪对准确获取养殖鱼的生长状态、发现鱼类异常行为以及实现精准投喂具有重要意义。在养殖环境下,鱼类图像标注费时费力。如何使用少量的有标注数据就能够准确识别并跟踪鱼类目标,是应用鱼类目标识别跟踪的现实问题。此外,鱼类有独特的运动规律,通用跟踪器应用于鱼类跟踪时效果不佳。为解决上述问题,提出基于半监督学习的水下鱼群目标识别与跟踪方法,具体内容及创新点如下:1.融合高效注意力模块的YOLOv7与改进半监督自训练的水下鱼群目标检测模型STEAM-YOLOv7:为降低对标注数据的依赖,提出了融合高效注意力模块的YOLOv7与改进半监督自训练的水下鱼群目标检测模型STEAM-YOLOv7。为提高模型的学习效率,提出高效注意力模块,指导网络注重于学习重要通道的知识,提升网络特征提取能力从而提升检测准确度。为利用无标注数据辅助模型训练,对半监督学习中的自训练方法进行改进并引入模型训练过程,以不确信度作为伪标签的筛选条件以改进自训练,并采取迭代训练的训练模式,使模型利用无标注数据实现性能提升。为验证所提方法有效性,本文在养殖鱼群数据集上进行了消融实验,不同注意力模块的性能对比实验,不同自训练方法的对比实验。融合高效注意力模块的YOLOv7的准确率和召回率较原版YOLOv7相比,分别提升了1.99%与1.23%,所提改进自训练方法与其它自训练方法相比,召回率有明显提升。2.基于STEAM-YOLOv7和改进Deep SORT的水下鱼类目标跟踪模型:为使跟踪算法适应养殖环境鱼类跟踪任务,提出基于STEAM-YOLOv7和改进Deep SORT的水下鱼类目标跟踪模型。利用所提的STEAM-YOLOv7作为Deep SORT算法的检测器,保证检测的高精度与高速度。此外,为使Deep SORT在进行卡尔曼滤波更新时更符合真实水下养殖情景,采用置信度加权卡尔曼滤波替代原版卡尔曼滤波,提升目标轨迹预测的准确度。为验证所提改进方法的有效性,本文在养殖鱼群目标跟踪数据集上进行了对比实验。实验中,改进Deep SORT算法的MOTA与IDF1分别为44.67%和48.47%,跟踪指标相较于模型改动前有显著提升。3.鱼群识别与跟踪系统:为方便所提跟踪模型的使用,设计了鱼群识别与跟踪系统,能对连续图像和视频中的鱼类目标进行识别跟踪,并将结果以视频形式展示。为满足不同需求,设计了模型选择模块,使用户可自行选择上游检测模型,实现系统灵活操作。此外,为使用户可根据具体水下环境调节模型参数,设计了阈值调节模块,简化用户操作,提高使用效率。鉴于跟踪模型对连续视频帧图像与视频数据的处理不同,设计了数据选择模块,使用户可自行选择输入数据形式。为方便用户直观查看跟踪结果,设计了结果展示模块。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2024.000738
{DOI}: 10.27821/d.cnki.gdlhy.2024.000738
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉水果分拣系统研究
{Author}: 许虎;惠宇龙;万宏强
{Author Address}: 西安国信物联技术有限公司;西安工业大学机电工程学院;
{Journal}: 现代电子技术
{Year}: 2024
{Volume}: 47
{Issue}: 17
{Pages}: 136-142
{Keywords}: 机器视觉;水果分拣;HSV颜色模型;Canny边缘检测算法;轮廓提取;最小外接圆法
{Abstract}: 为解决市面上水果分拣设备体积庞大、效率低等问题，文中给出的水果分拣系统以苹果为测试样本，将相机拍摄的RGB图像转换为HSV图像，并根据H分量分布情况计算苹果表面的色泽度，同时用Canny边缘检测算法提取苹果边缘的轮廓，用最小外接圆法计算苹果果径的大小，结合苹果色泽度和果径大小对苹果进行等级分级。系统试验表明，样本颜色与大小均与苹果的特征相符，分拣设备和人工分拣果径大小误差在±1.35 mm以内。该系统可实现精确分拣、自动化运行等目标，提高了分拣精度及效率。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2024.17.022
{DOI}: 10.16652/j.issn.1004-373x.2024.17.022
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv8和多目标跟踪的鱼苗计数方法
{Author}: 申阳;王冲宇;赵佳怡;都令炜;熊新;周明刚
{Author Address}: 湖北工业大学农机工程研究设计院;湖北时瑞达重型工程机械有限公司;
{Journal}: 农业工程学报
{Year}: 2024
{Volume}: 40
{Issue}: 16
{Pages}: 163-170
{Keywords}: 水产养殖;机器视觉;鱼苗计数;YOLOv8;多目标跟踪
{Abstract}: 水产养殖业中鱼苗的数量检测是一个重要环节。针对传统的人工计数方法效率低、精度差、易造成鱼苗应激和损伤等问题，该研究以体长20～50 mm的草鱼苗为检测对象，提出了一种基于改进YOLOv8和多目标跟踪的小鱼苗计数方法。根据鱼苗目标小且检测速度要求高的特点，在YOLOv8算法中引入了P2小目标检测层，同时在检测头前添加GAM(global attention mechanism)注意力机制，并将目标识别损失函数优化为Inner-SIoU(inner-SCYLLA-intersection over union)损失函数以加快模型的收敛速度、提高对小目标和重叠目标的识别准确率；然后，针对检测识别到的鱼苗目标，结合多目标跟踪算法实现了一种适用于小鱼苗的跟踪计数方法。最后通过设计鱼苗计数试验平台、采集制作数据集、训练计数模型并进行计数试验验证该计数方法的优点和性能指标。试验结果表明，平均计数精度、平均绝对误差、均方根误差分别为97.16%、 3.67、 5.26，各项指标优于YOLOv5+DeepSORT、 YOLOv8+DeepSORT、 YOLOv8+StrongSORT、YOLOv8+ByteTrack、YOLOv8+BoT-SORT等方法。该研究方法能够以更快的速度和更高的准确性统计视频中小鱼苗数量，为工厂化水产养殖的鱼苗快速准确计数、生物量估计等奠定了基础。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20240813.1021.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像处理技术的动物行为识别研究进展
{Author}: 李林葳;宋鑫悦;张智盛;段永鹏;侯欣宇;籍海娜;宋艳波;李菊霞;李艳文;刘振宇
{Author Address}: 山西农业大学信息科学与工程学院;海南大学信息与通信工程学院;山西农业大学生命科学学院;山西农业大学农业工程学院;旱作农业机械关键技术与装备山西省重点实验室;
{Journal}: 中国畜牧杂志
{Year}: 2024
{Volume}: 60
{Issue}: 10
{Pages}: 24-34
{Keywords}: 动物行为;行为识别;图像处理;机器视觉
{Abstract}: 动物行为识别旨在理解动物的行为，并对每种行为贴上类别标签，具有广泛的应用前景。近年来，动物行为识别在计算机视觉领域受到了越来越多地关注。动物行为识别技术的发展经历了从传统的基于手工特征的方法向基于深度学习的方法演变。本文根据动物行为识别技术发展的基本脉络，综述了传统方法和深度学习方法中的主要流派和技术手段，概述了各种技术手段优缺点及其在动物行为研究中的应用情况。
{ISBN/ISSN}: 0258-7033
{Notes}: 11-2083/S
{URL}: https://link.cnki.net/doi/10.19556/j.0258-7033.20231103-04
{DOI}: 10.19556/j.0258-7033.20231103-04
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能送药小车设计
{Author}: 李城州;袁宝聚;陈美玲;赵文豪
{Author Address}: 南京工业大学浦江学院;
{Journal}: 工业控制计算机
{Year}: 2024
{Volume}: 37
{Issue}: 07
{Pages}: 152-154
{Keywords}: STM32;OpenMV;K210;数字识别;PID算法;智能送药
{Abstract}: 以加强对医护人员的保护、无接触辅助医疗为导向，设计了一种智能送药小车。小车采用STM32为主控制器，通过OpenMV进行循迹，K210进行数字识别，结合显示模块、驱动模块等，加入PID算法使小车运行更加平稳，采用MobilneNetV2算法使K210数字识别效果更优，实现了小车在不同距离下的药品配送任务。该设计具有系统完整、操作简单、可扩展性强等优点，实现了在医疗领域智能化的创新。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwedu2PwFRZlWrE3DjI8_7GN0Pa87_GkeOFhPDDlRdhoa4jCiKYVe_HbtZnV5UlFpYLtuoT8P_WnTXjMaJacTyZWFp6lhwaUI3vM-LK9sseA3SaRBwpIVGkNCudKU0LY0pPQQIvYTs-blLDMjBCEmeLd_Y8epLWZhfn9xVZZ2PktTCZq5arfREW9QBSdAz1OPM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: AIGC图像质量评估指标研究
{Author}: 邢润媚;常升龙;何宽;朱曙光;高琼;胡昊
{Author Address}: 河南交通职业技术学院物流学院;郑州大学土木工程学院;河南师范大学软件学院;河南恒茂创远科技股份有限公司;黄河水利职业技术学院测绘工程学院;河南理工大学测绘与国土信息工程学院;华北水利水电大学水利学院;
{Journal}: 南京信息工程大学学报
{Year}: 2025
{Volume}: 17
{Issue}: 01
{Pages}: 63-73
{Keywords}: 人工智能生成内容;深度学习;计算机视觉;图像;质量评估
{Abstract}: 人工智能生成内容(AIGC)技术可为人类提供各种类型的信息生成服务，如何对AIGC进行准确的质量评估，是当前亟待解决的问题.本文主要针对大模型生成图像的质量及其评估指标开展深入研究.首先，从技术方面概述了当前评估AIGC的常见方法，如深度学习方法和计算机视觉方法等，介绍并分析了准确性、相关性、一致性、可解释性等指标在不同类型生成内容评估方面的表现.然后，为了展示评估指标的实际作用，以百度文心一言为例，对其生成的图像进行评估实验：使用直方图和噪点数量等量化指标对生成图像进行客观评估；使用整体协调性和美观性等视觉感官指标对生成图像进行主观评估.最后，综合对比客观评估和主观评估的结果，筛选出色偏、噪点数量、心理预期等AIGC产品质量评估的高可靠性指标.实验结果验证了综合使用主客观评估指标进行AIGC产品评估方法的有效性和可靠性.
{ISBN/ISSN}: 1674-7070
{Notes}: 32-1801/N
{URL}: https://link.cnki.net/doi/10.13878/j.cnki.jnuist.20240515002
{DOI}: 10.13878/j.cnki.jnuist.20240515002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的汽车车牌识别方法
{Author}: 崔清源;朱银锋;何友军;赵宝剑;周军
{Author Address}: 安徽建筑大学机械与电气工程学院;
{Journal}: 佳木斯大学学报(自然科学版)
{Year}: 2024
{Volume}: 42
{Issue}: 05
{Pages}: 70-74
{Keywords}: 机器视觉;Halcon;C#;光学字符识别;Visual Studio
{Abstract}: 针对车牌号识别，提出了一种通过机器视觉来进行识别的方法，用来解决汽车车牌号检测与识别以及显示的问题。首先通过Halcon软件对捕获到的带有车牌的图片进行形态学处理，定位出车牌的位置，分割出车牌号的字符，随后通过光学字符识别的方法将车牌号进行识别。再通过C#在Visual Studio平台进行识别系统的窗体设计，完成Halcon软件与C#的交互。在系统中，可以达到读取图片，展示车牌，将识别出的车牌号显示出等功能。并且识别速度快，操作方便，通过一键点击即可获得结果。
{ISBN/ISSN}: 1008-1402
{Notes}: 23-1434/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzzisYslcDP7SRax-eeFPebH0VkVV7b3glz_QisohL9zd6Ayo3AnHMPczF75voacmUm2rLFYrMbCmAXcgEws7v2c4I40yVmt2CjzBDJ96jiO2T16LZhIZ6r2RUnoTU_ZmI3VsCafJXTJDv0mK1MIO9iXOtHfwG6EgIB-NAYZpdAPCQE5x_R49tJEcKleUuxLGU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的芯片缺陷检测研究进展
{Author}: 胡志强;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2024
{Volume}: 45
{Issue}: 07
{Pages}: 1-26
{Keywords}: 半导体芯片;缺陷检测;芯片封装;机器视觉;深度学习;芯片缺陷数据集
{Abstract}: 半导体芯片作为集成电路的重要组成部分，对其质量要求越来越高，因芯片在小型化、高密度的制造过程中产生缺陷，进而影响了芯片的性能和寿命。因此，缺陷的检测与识别对芯片可靠性的提升十分重要。综述了近10年来国内外基于机器视觉的芯片缺陷检测方法的研究进展。首先介绍了芯片的制造流程以及当前主流的芯片封装技术。然后概述了用于芯片缺陷成像的主流无损检测技术，主要包括光学成像、声学成像、红外热成像、电磁成像与X射线成像等技术。接着分别重点阐述了基于传统技术和基于深度学习的芯片表面的缺陷检测方法。随后按照缺陷部位比较分析了芯片封装体的缺陷检测方法。最后总结芯片缺陷检测当前存在的问题，对未来的研究方向进行了展望。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2412735
{DOI}: 10.19650/j.cnki.cjsi.J2412735
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像显著性目标检测算法研究
{Author}: 郭富强
{Tertiary Author}: 宋霄罡
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 显著目标检测;卷积神经网络;双分支结构;注意力机制;特征融合
{Abstract}: 显著目标检测(Salient Object Detection,SOD)是计算机视觉领域的重要任务之一,旨在从复杂场景中准确地识别和定位出最显著、最引人注目的目标。随着深度学习技术的不断进步,显著目标检测方法也飞速发展。通过训练深度神经网络学习图像中显著目标的特征表示,进而实现高效的显著目标检测。然而,现有的基于RGB显著目标检测模型受光照等环境影响导致预测边缘模糊、显著目标预测不完整等问题。基于RGB-D显著目标检测模型一定程度上能够缓解光照带来的影响,但又面临着多模态特征如何高效融合利用的问题。因此,本文主要研究如何让在只有RGB输入的情况下预测出完整且边缘清晰的显著图像,如何在RGB-D输入的情况下充分利用每个模态的信息,使它们之间能够更好地融合,以及如何解决出现的边缘模糊等问题。具体工作如下:(1)本文针对RGB输入,提出了一种将Transformer与卷积神经网络(Convolutional Neural Network,CNN)结合的双支路编码器结构,以平衡全局语义信息和局部细节特征。考虑到Transformer和CNN所提取的特征存在差异,直接融合可能引入噪声。因此,本文提出了一种融合增强模块,该模块采用渐进式融合策略,逐步融合两个分支的特征,并利用混合注意机制对不同特征进行加权融合,以最小化两个分支特征的差异,最大程度地保留两个分支提取的语义特征和细节特征。此外,由于重复下采样导致细节信息丢失,而在预测显著目标轮廓时需要大量的细节信息。因此,本文引入了一种边缘细化模块。该模块利用显著特征提取边缘特征,并利用这些边缘特征对预测结果逐步细化,增强了显著特征与边缘特征之间的联系,无需引入额外的边缘提取分支。通过在五个基准测试集上进行实验评估,本文提出的方法与其他现有方法相比精度更高,边缘更清晰。(2)针对RGB输入图像质量低,光照环境不确定等因素的影响,导致显著目标检测的精度降低,本文通过引入深度信息来克服这些问题,研究如何充分利用并融合RGB-D显著目标检测输入的多模态信息,提出了跨模态注意力融合增强模块,针对不同模态使用相应的注意力机制进行融合,使RGB图像和深度图像携带的信息充分融合,提高了模型对具有挑战性场景的检测的能力。但由于两种模态的输入融合后容易淡化边缘信息并且引入噪声,出现目标轮廓预测困难的情况。因此,设计了一种CNN低层特征引导的边缘特征提取模块,使用CNN提取的低级细节特征对跨模态融合特征进行噪声过滤与边缘特征增强以得到边缘锐利的显著预测图。通过在五个广泛应用的测试数据集上的定量和定性的比较验证了所提出网络的有效性。这表明我们的方法能够有效地利用RGB和深度信息,并通过CNN辅助提取低层细节信息提高了显著目标检测的精度。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000355
{DOI}: 10.27398/d.cnki.gxalu.2024.000355
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于线扫立体视觉结合的免示教焊接机器人焊缝检测与路径规划
{Author}: 乔嘉拓
{Tertiary Author}: 杨延西
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 机器视觉;三维重建;焊缝识别;工业机器人;运动规划
{Abstract}: 随着工业自动化和智能化的发展,焊接技术也在不断演进,逐渐趋向于数字化和自主化发展。多数钢结构件存在着品种多、批量小、焊缝形状位置一致性差,机器人重复定位过程复杂等缺点,焊缝的准确检测定位与机器人免示教路径规划面临诸多挑战。因此,基于机器视觉技术的进步,对免示教自主焊接系统进行深入研究和探索具有重要的意义。为此,本文提出了基于线结构光和立体视觉结合的焊缝检测定位与免示教焊接机器人路径规划方法,主要研究内容如下:(1)搭建了一套双视觉系统免示教机器人焊接实验平台,由立体相机、线结构光扫描相机与机器人组成。采用线结构光扫描弥补立体视觉在大范围成像时精度损失的问题,立体视觉弥补线结构光视觉在工件任意放置时,无法自主规划扫描路径的问题。(2)针对线结构光视觉单帧无法大范围成像,整体工作台多帧扫描拼接耗时的缺陷,本文提出了一种基于立体视觉的大范围空间焊缝快速定位方法。以RANSAC算法为核心,通过空间位置求解,快速定位焊缝位姿,并规划扫描朝向,为线结构光扫描提供路径指引。实验表明,在100× 100cm的工作台上,算法在0.117s 内可定位焊缝位姿,并且定位精度可达到0.84mm,角度偏差0.34°。(3)针对立体视觉在大范围下精度损失的缺陷,考虑到线结构光扫描测量高精度的优势,本文提出了一种基于线结构光扫描的焊缝高精度定位方法。以Steger算法为基础,研究线结构光三维测量原理,研制了线结构光扫描相机。针对线激光在金属表面发生反射的问题,提出了一种在三维空间下基于FPFH算法提取焊缝特征点的方法。实验表明,单帧线激光图像焊缝特征点提取误差0.0134mm,算法处理时间0.014s。(4)针对免示教机器人焊接过程中可能发生碰撞的问题,提出了一种改进RRT*的路径规划方法。在建立机器人MD-H模型以及正逆运动学基础上,在RRT*算法基础上加入探索树双向生长与贪心算法改进,并对机器人建立碰撞检测模型,自动生成焊接路径,实现免示教自动焊接。实验表明,在复杂二维和三维环境中算法均可100%生成无碰撞路径,并且在路径参数上优于RRT*算法,在不需要示教的情况下自动实现焊接。(5)为了验证所研究方法的有效性,开发了免示教机器人自主焊接平台,分别对焊缝检测与定位和免示教机器人路径规划功能进行了实验研究,实验结果表明,对工件任意位姿放置,本文均可100%完成对焊缝的定位与机器人模拟焊接实验。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000534
{DOI}: 10.27398/d.cnki.gxalu.2024.000534
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双向特征融合的轻量化火灾检测算法研究
{Author}: 王雨
{Tertiary Author}: 孙帮勇
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 火灾检测;深度学习;多尺度特征;注意力机制;特征融合
{Abstract}: 火灾作为人类生活中遇到的最大灾害之一,直接影响着人们的财产和生命安全,因此研究高精度的实时火灾检测方法具有重要意义。传统火灾检测多依赖各种接触型传感器,如火焰检测传感器、烟雾检测传感器等,在实际应用中这类传感器受探测距离和设备安装位置等多种因素限制。近年来,随着先进光学和计算机视觉技术的发展,基于计算机视觉的火灾检测方法取得显著进展。基于视觉的火灾检测,通过对视频和图像中的火焰或烟雾特征进行准确识别,能够快速判断火灾是否发生并确定火灾位置,具有检测速度快、应用场景广和检测准确率高等优点。不过,目前基于计算机视觉的火灾检测方法依旧面临着两个挑战性问题,一是在火灾图像或视频中存在着火灾目标尺度跨度大、易与背景混淆等问题,导致其检测精度不够高;二是针对火灾图像或视频中远距离且火势较小的目标,现有火灾检测方法仍存在一定的局限性。针对以上问题,本文利用自然场景图像的自身像素信息,基于深度学习方法开展了实时性火灾检测方法研究。本文的研究内容和主要贡献概括如下:(1)针对火焰或烟雾尺度跨度大和背景混淆等问题,构建了一种具有两个关键性功能模块的高精度实时火灾检测网络,在探测精度和速度之间实现了较好的平衡。首先,设计了轻量级主干网络来提取图像特征,能够有效判别背景中的火灾和烟雾,并与现有方法相比大幅降低了模型参数量;同时,构造了一个多尺度检测子网络,以选择性地强调通道和空间对不同特征的贡献,有助于不同尺度火灾目标的检测;最后,本文采用解耦头部分别预测火灾或烟雾的类别和位置,获得了较高的检测精度。此外,针对现有公开火灾检测数据集较少的问题,提出了一个更具挑战性的数据集(SF数据集)以验证所提出方法的有效性。通过大量主观、客观的对比实验表明,本文提出的网络模型能够在一定程度上有效提升火灾检测准确率,尤其是对于尺度跨度大的火灾图像。本工作所提出的方法在SF数据集上达到69.42%mAP,模型参数为43.62M,具较高的检测性能。(2)针对远距离小目标检测精度较低以及模型泛化能力弱等问题,本文提出了一种基于级联稀疏查询机制的轻量化火灾检测网络。首先,建立了轻量化的图像特征提取模块,通过在YOLOv5s主干网络中嵌入轻量化注意力模块,用于解决火灾检测中火焰与烟雾的多尺度难点;其次,利用深层特征提取模块,对不同层级的特征图进行深度处和多尺度融合;最后,利用嵌入轻量化的级联稀疏查询模块提升对早期火灾中的小火焰和薄烟雾的检测准确率。经验证,该方法在SF-dataset、D-fire数据集以及FIRESENSE数据集mAP均实现了最优的检测效果,并且通过大量的对比实验,结果表明该算法可以将双向特征融合的特性充分发挥,在不同场景下,火灾检测准确率皆得到明显提升。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000443
{DOI}: 10.27398/d.cnki.gxalu.2024.000443
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像语义分割算法研究
{Author}: 张文新
{Tertiary Author}: 刘涵;梁莉莉;吴华勇
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 语义分割;轻量级语义分割;RGB-T语义分割;多模态特征融合;多尺度特征融合
{Abstract}: 图像语义分割是计算机视觉领域中的一项重要任务,旨在将图像中的每个像素分配给预定义的语义类别,现已广泛应用于医学分析、自动驾驶和无人机影像等各个领域。随着深度学习和神经网络的飞速发展,传统的基于深度学习的语义分割技术日趋成熟,但这些语义分割网络常常需要较深的网络层数才能得到较为准确的预测结果,这就导致在资源受限或要求实时性能的场景下,传统的语义分割网络参数庞大、计算量大的这些问题会限制其在实际场景中的广泛应用。另一方面,传统的语义分割网络大多是针对单一可见光图像作为输入的,在一些光线不足或能见度过低的场景下往往表现出较低的鲁棒性。为了解决实时性差和单一可见光语义分割应用场景局限这两个问题,轻量级的语义分割技术和可见光-热红外(RGB-Thermal,RGB-T)语义分割技术应运而生。主流的轻量级语义分割大多借鉴于图像分类任务的轻量级骨干网络,由于缺乏特定任务的设计并不能很好的解决图像分割问题。除此之外,现有的轻量级分割模型通常通过剪裁或调整大小来限制输入图片大小以降低模型计算复杂度,该方法很容易忽略图像边界和小目标周围的细节外观特征,导致了可视化精度的下降。另一方面,现有的RGB-T语义分割技术大都是利用简单的相加求和方式去融合两种模态间的信息,往往难以有效地处理多模态图像中的异质性信息,这会导致丢失大量模态间多层次的互补特征信息进而影响分割精度。基于此本文研究了具有实时性的轻量级语义分割网络和多模态的RGB-T语义分割网络。主要研究内容如下:(1)提出了一种基于注意力和多尺度上下文的轻量级可见光语义分割网络模型。该模型利用一种新颖高效的短期密集连接网络作为主干网络进行特征提取,相较于其他预训练好的分类网络有较强的针对性和较小的计算量。在此基础上,本文加入了多尺度特征融合模块来对全局上下文信息进行多尺度特征提取,并采用多路径特征注意力融合模块将底层细节特征和高层语义特征信息结合。经过与主流网络的对比以及模块消融实验,验证了本文所提方法的有效性,实验结果也表明本文的方法在实时性和准确性之间达到了更好的平衡。(2)提出了一种基于多级特征融合和注意力的RGB-T图像语义分割网络模型。针对现有网络对于多模态特征仅仅采用简单的拼接融合操作的方式,本文采用多级融合的策略来将两种模态的信息进行分级融合,并在此基础上引入了残差空间池化金字塔模块进行多尺度的信息处理,对于编码器每一级的输出都通过混合的通道空间注意力机制来进行特征增强,并采用交叉相乘的方式指导融合两种模态间的互补特征信息,使得每一层的特征信息都能得到充分融合。在MFNet数据集上的对比实验和消融实验表明,本文的方法比现有主流网络获得了更好的精度。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001111
{DOI}: 10.27398/d.cnki.gxalu.2024.001111
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多尺度和多分辨率Transformer的图像分类算法研究
{Author}: 张鑫
{Tertiary Author}: 刘晶
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 图像分类;Transformer;多尺度;多分辨率;细粒度特征;自注意力机制
{Abstract}: 近些年来,计算机视觉领域研究得到了广泛的关注。图像分类作为计算机视觉领域的一个重要研究方向,取得了显著的研究成果。目前,图像分类算法的一个主流分支是基于Transformer架构。Transformer架构是将图像先统一划分成相同尺度的图像块,然后再进行特征学习继而分类。然而,图像被划分成相同尺度的图像块,会影响Transformer架构学习目标区域特征的能力;尤其会影响图像边缘与纹理等细粒度特征的学习。为此,本文提出了两种基于Transformer架构的图像分类算法,主要研究内容如下:(1)提出了一种基于自适应多尺度Transformer的图像分类算法。首先,图像输入到算法的自适应定位目标区域模块,该模块利用SIFT特征提取方法和MeanShift聚类算法,将图像划分为目标和非目标两大区域;其次,将自适应定位目标区域模块的输出结果输入到多尺度特征提取模块。该模块使用较小尺寸的卷积核提取图像目标区域的细粒度特征、使用较大尺寸的卷积核提取非目标区域的粗粒度特征,再将细粒度特征与粗粒度特征进行拼接,输出整幅图像的多尺度特征图;然后,多尺度特征图送到自适应多尺度Transformer Block模块,学习图像块间的自注意力特征;最后,将自注意力特征输入到分类头,获得分类结果。实验表明,在不进行预训练的情况下,相较于现有的基于Transformer架构的分类方法,本算法能够提升图像分类精度值为1.3%。(2)提出了一种基于多分辨率Swin Transformer的图像分类算法。首先,图像输入到小波分解模块,将图像分解为四个不同方向的频谱图,捕捉图像细节与边缘纹理等细粒度特征;其次,将四个小波频谱图输入到多分辨率特征提取模块,学习同一频谱图的块之间的自注意力特征。多分辨率特征提取模块由四个前两个阶段的Swin Transformer Block构成,每个Swin Transformer Block负责学习一个小波频谱图的自注意力特征学习;然后,将不同频段的自注意力特征输入到多分辨率融合模块,该模块先特征融合得到整幅图像的自注意力特征,再学习整幅图像的全局自注意力特征。多分辨率融合模块由Swin Transformer Block阶段3构成;最后,将全局自注意力特征到分类头,得到分类结果。实验表明,相较于现有方法,本算法在计算参数降低情况下,图像分类精度值能够提升4.3%。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001710
{DOI}: 10.27398/d.cnki.gxalu.2024.001710
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 三维点云及图像-点云配准方法研究
{Author}: 艾阳
{Tertiary Author}: 杨溪
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 点云配准;动态网络;图像匹配
{Abstract}: 近年来,随着传感器技术的快速发展,三维点云数据的获取变得越来越容易,点云配准和图像-点云配准这两个计算机视觉中的关键研究领域也受到越来越多学者的关注。它们涉及将来自不同传感器、不同时间或不同视角获取的数据进行精确对齐的技术。这些技术为三维重建、环境感知、增强现实(AR)以及自动驾驶等领域提供了强有力的技术支持同时具有广泛应用前景。点云配准是指将两个或多个点云数据准确的对齐到同一坐标系中。在点云配准问题中,点云数据中会存在大量非重叠区域的点,这些点会对点云特征提取和配对造成干扰,同时会占据大量不必要的计算资源从而影响点云配准的效率。针对此问题,本文创新性的引入动态网络的方式改进点云配准的效率问题,通过对执行多次迭代过程来动态的去除点云中的外点。具体来说,本文采用基于密度的聚类方式来寻找内点集中的区域,然后利用迭代的方式进行多次局部配准。借鉴动态网络的思想,本文采用点云配准中的一阶一致性指标作为判别器来动态的判定每次迭代的结果是否满足终止条件。本文方法的运行时间在室内数据集3DMatch上提升超过41%,在室外数据集KITTI上提升超过33%,同时在配准准确率上达到当前最佳结果。图像-点云配准是将二维图像与三维点云进行跨模态数据融合的任务。该任务通常结合图像丰富的纹理信息和点云的空间信息来进行更全面的场景表示。然而由于不同模态之间的特征差异导致特征的匹配往往难以准确对应。本文针对带有纹理信息的三维模型与拍摄照片进行配准的问题提出基于图像匹配的图像-点云配准算法。首先对于跨模态问题,本文使用三维可视化工具将三维模型进行截图,同时读取截图的相机信息来建立三维模型到二维图像之间的对应关系。通过使用图像匹配预训练模型对三维模型的截图和拍摄照片进行关键点提取和图像匹配,得到图像关键点配对关系。然后利用相机投影模型将三维坐标点与图像关键点进行映射,得到图像-点云关键点配对关系并利用Pn P-RANSAC计算图像与三维点云之间的转换矩阵。本文提出的方法通过与基于手动标注的方法进行对比,证明在实际场景中能明显提高效率同时具有稳定性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.006761
{DOI}: 10.27162/d.cnki.gjlin.2024.006761
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向森林火情监测的图像检测分割方法研究
{Author}: 何阳
{Tertiary Author}: 张友民;张立东
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 森林火情监测;图像目标检测;图像实例分割;轻量化模型;Yolov3;Maskrcnn
{Abstract}: 森林是地球的重要组成部分,人们用肺于人来比喻森林于地球,由此可见森林的重要性。但是森林火灾一直威胁着森林环境,当前森林火情监测其他方法存在成本高、早期火情监测难度大等问题。无人机以其灵活、准确及成本低的优点广泛应用于森林火情监测工作。本文以森林火情监测为出发点,以图像检测为方法,开展基于无人机图像的检测和分割方法研究,辅助林业人员识别早期森林火灾并估计森林火灾危害程度,主要内容包括:
(1)针对在地面端准确快速的进行火情检测任务,提出了一种基于Re-yolo的森林火情检测方法。该方法利用Yolov3目标检测网络进行优化,在主要框架不变的前提下应用参数重构方法、跨阶段部分结构以及SE权重注意力模块等优化策略,保证模型检测速度的前提下提升模型对于森林火情检测的准确性。Re-yolo方法检测速度为33.8FPS,并且检测精度超过Yolov3模型以及Yolov5-s等其他目标检测方法。
(2)针对无人机机载计算机算力有限,一般方法无法在无人机监测火情的过程中达到实时监测的问题。本节研究内容目的是设计一种适用于计算能力不强的机载计算机端的深度学习方法,根据这一目的,本文提出了基于Reyolo-tiny的轻量化方法,实现在低算力条件下对火情的有效监测。为了增强轻量化后模型的检测能力,先对Re-yolo模型进行修改,增强其检测精度。接着通过将增强后Re-yolo模型的主干网络替换为轻量化模型,然后通过滤波器剪枝的模型压缩方法对模型进行处理,得到一种基于Re-yolo的轻量化方法,提出一种轻量化思路,使得模型对森林火情检测达到实时准确检测的要求
(3)针对难检测目标检测困难、检测精度不高的问题,提出一种基于查询机制改进的实例分割方法Query-maskrcnn。对于地面端精确的火情监测任务,在Maskrcnn的模型框架下引入基于查询的解码器输出头,并在像素解码器中引入特征对齐模块。该方法在保证检测分割实时性的前提下提高检测分割精度,实验结果最优模型的检测速度为17.5FPS,基本实现了实时检测分割,平均像素准确率MPA值达到91.8%,超过Maskrcnn等方法。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000049
{DOI}: 10.27398/d.cnki.gxalu.2024.000049
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器学习与计算机视觉技术在食品质量评价中的研究进展
{Author}: 黄晓琛;张凯利;刘元杰;陈洪;黄凤洪;魏芳
{Author Address}: 中国农业科学院油料作物研究所,油料脂质化学与营养湖北省重点实验室,油料油脂加工技术国家地方联合工程实验室;中国农业大学信息与电气工程学院,农业农村部农业信息获取技术重点实验室;湖北洪山实验室;
{Journal}: 食品科学
{Year}: 2024
{Volume}: 45
{Issue}: 12
{Pages}: 1-10
{Keywords}: 机器学习;食品质量;计算机视觉;食品检测
{Abstract}: 近年来，随着社会对食品质量和安全的关注度不断提高，计算机视觉技术在食品质量评价领域逐渐受到重视并开始广泛应用。通过学习技术，如人工神经网络、卷积神经网络和支持向量机等，研究人员能够利用大量的食品图像和相关数据进行训练，从而实现对食品质量的自动评估和监测。特别是深度学习技术的发展，使得计算机能够更加准确地识别食品的外观、形状、颜色等特征，进而对其进行分类、预测和质量检测。除了在食品质量评价中的常规应用，学习技术还被用于更复杂的任务，如食品缺陷检测、异物检测、新鲜度评估等。这些技术不仅可以提高食品生产和加工的效率，还能够减少人为因素带来的误差，从而确保食品质量和安全。然而，尽管学习技术在食品质量评价中的应用取得了显著进展，但仍然存在一些挑战需要克服。例如，食品图像数据集的获取和标注成本较高，数据质量和数量的不足可能会影响模型的性能和泛化能力。此外，模型的可解释性和透明性也是一个重要问题，尤其是在需要对食品质量评价结果做出解释或决策的情况下。因此，未来的研究需要继续探索如何提高数据集的质量和规模、优化模型的鲁棒性和可解释性，以及开发更加高效和可持续的食品质量评价系统。
{ISBN/ISSN}: 1002-6630
{Notes}: 11-2206/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzjgHsgsD022cl-q9U35b1xgFWbZjgRlrrLpmoYtTkyuh6IiG-JRjbaKE9ZBZ7T0h4XM9-Fe2FL8kvB4jvPRuDzfJdqAQbB3eBdxccTST-rYF13giYqlz1xf0oGYu8VcjfBfT4KCg7eTF756rGaWKZbj_Gru8ofBfSzsu8Chzf-gPJOF_4mdEZBmSYNKXrFh3U=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv8的矿工不安全行为检测方法研究
{Author}: 方成焰
{Tertiary Author}: 杨超宇
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 矿下不安全行为;目标检测;YOLOv8;Transfomer
{Abstract}: 煤炭是我国重要的能源来源,确保其开采过程的安全和智能化至关重要。在开采过程中,由于矿工不安全行为导致的事故占比高达85%以上。因此,对于在煤矿井下环境下的矿工行为进行实时性的检测以及管理具有重要意义。本文通过深度学习方法以及目标检测算法,针对煤矿井下人员的违规行为检测方法研究。本文的研究内容如下:1.为了解决YOLOv8目标检测模型训练速度慢和召回率低的问题,论文对其网络结构及各模块的工作原理进行了深入剖析。在YOLOv8基础上,实施了多项改进:首先,将回归分支的损失函数升级为更高效的Func-Io U损失函数;其次,选用了Mobile Net V3作为主干网络,以减轻模型负担,并将Mobile Net V3结构中的SENet模块替换为GAM注意力机制,以提升特征提取能力;最后,将激活函数更换为Mish函数,以在速度与准确率之间达到更好的平衡。实验结果显示,改进后的模型在测试中表现优异,尤其在煤矿违规行为识别中的安全帽佩戴检测任务中取得了显著成果。模型训练的收敛速度显著提升,误检和漏检情况大幅减少,证明了其在煤矿违规行为识别等领域的广泛应用价值。2.为了同时提升模型的训练和检测速度,同时保持较高的准确率,论文引入了GSConv卷积方法。为减轻深度可分离卷积对模型准确率的影响,论文在特征融合前加入了SENet注意力机制,为不同特征提取通道赋予相应的权重,从而强调关键通道。经过修改后的卷积模块在准确率上更接近标准卷积,实现了速度与准确率的双重提升。为了进一步增强模型的局部和全局特征提取能力,论文引入了Swin Transformer方法,并结合Bo TNet网络结构,大幅减少了模型的计算量。在此基础上,论文设计并分析了Vi T-YOLO模型网络结构。在矿工违规行为数据集上的对照实验显示,Vi T-YOLO训练的模型损失函数收敛速度远快于原模型,m AP值也高于原模型,检测效果显著提升,表现优于其他模型。这一结果证明了Vi T-YOLO在矿工违规行为识别等领域的优越性能。图29表9参89
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2024.001308
{DOI}: 10.26918/d.cnki.ghngc.2024.001308
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能水果采摘机器人系统设计研究
{Author}: 梁雨凤
{Author Address}: 江西制造职业技术学院;
{Journal}: 中国设备工程
{Year}: 2024
{Volume}: 
{Issue}: 11
{Pages}: 34-35
{Keywords}: PLC;机器视觉;智能水果采摘机器人
{Abstract}: 本文基于西门子S7-200型PLC和机器视觉技术设计智能水果采摘机器人系统，首先阐述了利用机器视觉算法对待采摘水果图像、坐标和位姿进行确定的方案，其次详细设计了系统的硬件组成模块、地址分配和梯形图程序编译思路，最后运用MCGS软件设计了系统的人机交互控制模块。通过现场实测发现，本系统可以稳定识别并采摘水果，且采摘耗时较短，平均准确率达到90%以上，具有较强的运行稳定性和推广价值。
{ISBN/ISSN}: 1671-0711
{Notes}: 11-4623/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz-mkyixqh7jLTwP1xm9WqYS8wZMwk-T2vPnAmkUWDZ8nucztEmQBBotu_oRf9Bu6TtjnjnwoL5VTfBSO_VbbyvcjUHVGGs61aZZqyXK8rrJ8cgSTfL6DOlS1JrtvnkDo2n-08oqrlmzAVzZfoQYaxfTGPdgJZ-j_S-sZeO5A7pMyQ_mAsGJNflezdd2FRM2Kk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于课堂视频的学生行为智能识别与分析研究
{Author}: 胡海涛
{Tertiary Author}: 杨美红
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;行为识别;目标检测;多目标跟踪;学生行为分析
{Abstract}: 近年来,人工智能技术飞速发展,在各行业的应用受到广泛关注,极大地推动了传统领域的创新发展。特别是在教育领域的教学评价环节,传统教学评价方法依赖教师的直观观察与个人经验,费时费力且评价结果具有主观性,无法适应当前教育需求。因此,如何将人工智能技术应用于教学评价环节,提高教学评价的客观性、准确性及效率,进而改进教学方法,提高教育质量,实现基于深度学习的学生行为智能识别分析,是当前教育技术领域的研究重点。
目前研究存在以下问题:没有针对学生课堂行为的公开数据集,且自建数据集教室场景单一,导致深度学习模型泛化能力较差;真实课堂场景中,学生遮挡、光线等问题会影响现有深度学习算法的识别效果;偏重深度学习算法的优化,忽视学生行为数据的分析,尚未构建科学的分析评价方法;基于深度学习算法构建的课堂分析系统,未考虑大规模应用时所需的庞大计算资源。
针对现存问题,本研究的主要工作内容如下:
(1)构建学生课堂行为数据集。在不同时段、不同光照条件下采集齐鲁工业大学8种不同教室类型的课堂监控视频,共约100GB。通过数据预处理、标注等步骤,构建高质量的学生行为数据集。该数据集含有7652张不同类型的课堂图像,134645条学生行为标注数据,为本研究提供数据支持。
(2)构建基于课堂视频的学生行为智能识别模型。该模型有目标检测和目标跟踪两个核心模块。其一,经过对比实验,选定YOLOv5作为目标检测模块的基础模型,并根据数据集特点,改进激活函数与非极大值抑制方法;改进后,新模型对数据集中学生行为的识别精度显著提升,可达93.58%,较原算法提高4.73%。其二,选择Deep Sort算法作为目标跟踪模块的基础算法,并针对学生ID切换问题,改进Io U匹配机制,引入K邻域匹配方法;优化后,新算法的ID切换次数平均减少52次,目标跟踪准确率提高至80.25%,较原算法提高3.57%。实验数据表明,优化后的学生行为智能识别模型,能够精准识别学生课堂行为,对课堂分析提供技术支撑。
(3)设计学生行为分析与教师授课效果量化评价方法。其一,提出有效抬头听讲修正方法,准确计算学生各类行为的有效时长。其二,通过权重组合优化实验,确定学生课堂专注度得分计算方法,并将专注度得分转换为等级评价,方便教师直观分析学生课堂表现。其三,基于个人和班级两个角度,提出学生课堂行为占比分析方法,辅助教师针对不同学生和班级的课堂表现及时调整教学方式。其四,依据班级整体抬头率,结合授课效果评估标准,评估教师授课效果。对每种方法进行实例分析与对比实验,证明结合智能识别模型的学生行为分析与授课效果评价方法具有准确性与实用性。
(4)开发基于算力网络的学生课堂行为智能识别与分析云平台。分析目前学生行为识别系统的资源限制问题,并介绍算力网络的优势;详细阐述云平台的核心需求设计、总体设计以及数据库设计;根据设计思路搭建云平台,达到实时识别与分析全校课堂视频流,生成课堂可视化报告的目的。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000350
{DOI}: 10.27278/d.cnki.gsdqc.2024.000350
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数字孪生的超高层建筑火灾疏散路径规划研究
{Author}: 莫崇德
{Tertiary Author}: 刘心男;赵钿
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 数字孪生;超高层建筑;火灾疏散;人群监测;路径规划
{Abstract}: 改革开放以来,中国经济迅速发展,超高层建筑的数量和规模随之大幅增加,逐渐达到世界领先水平。超高层建筑人员密度高,垂直疏散距离长,随着建筑高度的增加,火灾等突发事件的风险也显著提升。一旦发生火灾,由于“烟囱效应”,火势蔓延迅速,人员疏散极为困难,往往导致灾难性后果。尤其是超高层建筑主要依靠垂直疏散,在楼梯间的长时间疏散过程中,高密度的疏散人群会极大地消耗体力,而且在恐慌心理和盲目行动等多重因素的影响下,极易引发踩踏、窒息等危险情况,导致二次伤害。
因此,为强化超高层建筑安全管理,响应相关政策号召和要求,本文依托“十四五”国家重点研发项目子课题,开展了超高层建筑火灾疏散路径的研究。研究采用了机器学习的YOLOv5和Byte Track算法,对楼梯间疏散人群进行目标识别和跟踪,并计算疏散人群密度和速度,为火灾和踩踏风险条件下的最优疏散路径规划模型提供数据支持。同时,基于数字孪生五维模型,设计开发适用于超高层建筑火灾垂直疏散的智能引导系统,以引导人群快速逃离火海。本文的主要研究内容如下:
(1)研究了楼梯间疏散人群密度和速度监测方法。基于计算机视觉和机器学习技术,针对超高层建筑火灾疏散,特别是楼梯间垂直疏散场景,提出了一种识别、提取和计算人群密度和移动速度的方法。具体而言,本文采用了YOLOv5与Byte Track相结合的人群目标检测和跟踪算法。首先,利用YOLOv5算法识别人像目标,统计楼梯面积内的人群数量并计算人群密度。随后,采用Byte Track算法跟踪并提取单位时间内的视频图像帧,计算人群在视频图像中的像素位移,通过比例转换计算实际位移,从而得出单位时间内的人群疏散速度。这种基于YOLOv5和Byte Track的人群目标监测和跟踪方法能够实时监测超高层建筑火灾疏散过程中人群疏散状态,计算密度和速度,为下一章的动态路径规划提供了数据支持。
(2)建立了超高层建筑火灾疏散动态路径规划模型算法。当前的室内火灾疏散研究主要以大型公共建筑水平疏散为主,难以满足超高层建筑以垂直疏散为主的需求。因此,本文基于传感器采集的火灾环境参数,包括温度、一氧化碳和烟雾浓度,并结合人群疏散密度和速度,提出了一种考虑火灾和踩踏风险的最快疏散路径动态规划模型算法,即疏散时间最短。不同于传统的最短距离路径规划研究,本文首先通过风险量化方法,将火灾风险和踩踏风险分为三个等级。当路径风险达到Ⅲ级(危险等级)时,模型算法会首先将这些路径断开。对于安全路径,算法通过路径长度和疏散速度计算疏散时间矩阵,并基于Dijkstra算法规划最快疏散路径。
(3)设计开发了基于数字孪生的超高层建筑火灾疏散数字孪生引导系统。本文基于当前数字孪生理论研究,提出了超高层建筑的数字孪生五维模型,包括物理实体(PE)、虚拟模型(VM)、孪生数据(DD)、智能算法(IA)和应用服务(AS)五个维度。并基于五维模型,设计开发适用于超高层建筑火灾疏散的智能引导系统,以集成超高层建筑BIM空间信息、火灾态势感知和疏散人群监测数据以及路径规划模型算法,实现对疏散人群的动态路径规划和智能引导。本研究加强了超高层建筑的安全管理,提高了火灾情况下的疏散效率,减少了人员伤亡和经济财产损失,确保了疏散路径的实时性、安全性、科学性和可靠性,对于提升超高层建筑的安全性和火灾应对能力具有重要意义。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2024.000698
{DOI}: 10.26926/d.cnki.gbfgu.2024.000698
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer和CNN的图像分割算法研究
{Author}: 张凯乐
{Tertiary Author}: 熊昌镇
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 实时语义分割;编解码结构;注意力机制;Transformer
{Abstract}: 图像语义分割是计算机视觉领域的重要研究分支。近年来,基于卷积神经网络(CNN)的语义分割算法取得了很大的进展。同时,基于Transformer的深度学习算法在图像分割领域也有着很好的表现。考虑到CNN结构可以有效地获取图像局部特征的依赖关系,Transformer结构可以很好地对图像全局特征的依赖关系进行建模,故可将二者结合以获得高性能的分割网络。然而,如何结合二者优点,设计出性能优异、计算成本低的语义分割网络是该领域的关键问题和挑战。针对以上问题,本文设计了一种基于CNN和Transformer的实时语义分割算法,主要工作总结如下:
(1)本文提出的融合CNN和Transformer的图像分割算法,采用编解码结构的图像分割框架,为了有效结合Transformer可以提取全局特征信息的优势,在CNN编码模块后加入轻量级Transformer编码模块,通过其高效多头注意力机制和多层感知器结构来反映图像复杂的空间变换和特征长距离依赖关系。同时,本算法设计了一个基于金字塔池化的特征融合模块,采用多尺度的池化方法对CNN和Transformer编码器提取到的特征进行筛取,并整合不同尺度的特征,有效地聚合了不同区域的上下文信息。本文算法在解码器部分设计了基于多种注意力机制的特征融合模块,该模块通过空间注意力机制和通道注意力机制的特点来融合不同的特征,并使用坐标注意力机制来强化特征的坐标信息。
(2)本文在Cityscapes和Camvid数据集上设计实验并对实验结果进行分析。在Cityscapes数据集上对本文算法设计的各个模块进行消融实验,实验结果验证了算法中各模块的有效性。然后在两个数据集上设计了与当前语义分割任务下主流算法的对比实验,实验结果表明本文算法在Cityscapes验证集上的分割精度m Io U可以达到78.7%,推理速度为173.2帧/秒,在分割精度和速度上均获得了具有竞争力的结果。最后,在两个数据集上设计模型的可视化实验,对模型的预测图像进行分析,实验结果很好地体现了本文算法的优秀性能。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2024.000059
{DOI}: 10.26926/d.cnki.gbfgu.2024.000059
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉技术的无人机检测跟踪方法
{Author}: 刘新锋;陈梦雅;李成龙;陈关忠;张晓
{Author Address}: 山东建筑大学计算机科学与技术学院;山东建筑大学行业大数据研究中心;山东建筑大学学报编辑部;
{Journal}: 济南大学学报(自然科学版)
{Year}: 2024
{Volume}: 38
{Issue}: 04
{Pages}: 445-455
{Keywords}: 计算机视觉技术;无人机检测;目标跟踪;模型剪枝
{Abstract}: 针对无人机因目标较小而难以检测、检测速度慢、难于跟踪等问题，提出一种基于目标检测YOLOv5s算法和目标跟踪DeepSORT算法的无人机检测跟踪方法；采用自采数据集和公开数据集构建无人机检测数据集，使用针对小目标的数据增强方法以扩充数据集多样性；选择合适的YOLOv5算法模型实现无人机目标的精准、快速检测，引入基于批标准化层的模型剪枝方法进一步提高模型检测速度；利用DeepSORT算法实现无人机目标的实时追踪；通过对比YOLOv3、 YOLOv4、 Fast R-CNN以及改进前的YOLOv5算法，验证了本文方法在无人机检测方面的性能。结果表明：提出的无人机检测跟踪方法的全类平均精度达到0.947,每秒浮点运算次数达到2.93×10～9,在无人机检测的精度和速度方面均具有优势。
{ISBN/ISSN}: 1671-3559
{Notes}: 37-1378/N
{URL}: https://link.cnki.net/doi/10.13349/j.cnki.jdxbn.20240605.002
{DOI}: 10.13349/j.cnki.jdxbn.20240605.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进神经辐射场的三维重建技术研究
{Author}: 张志铭
{Tertiary Author}: 段建勇;廖联军;冯建呈
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;三维重建;图形学;计算机视觉;神经辐射场
{Abstract}: 三维重建是指利用图形学的方法,在计算机中实现对现实场景的虚拟化和可视化。该技术广泛应用于文物保护、医疗可视建模、VR/AR等领域。传统的方法往往伴随着重建成本高、依赖硬件、对环境条件敏感等问题。而基于深度学习的三维重建方法解决了传统方法的痛点,且取得了不弱于传统方法的重建效果。神经辐射场(Ne RF)是基于深度学习的三维重建方法之一,该方法能渲染生成照片级别的图像,是近年来的研究热点。但原始的神经辐射场模型存在一定局限性,例如:少样本输入下重建效果较差、训练与渲染速度慢、场景中存在遮挡时会出现重建失真的问题。本文针对上述问题展开研究,主要工作与贡献如下:
(1)针对少样本输入场景下重建效果较差的问题,本文第三章提出了一种结合深度信息的神经辐射场模型:通过引入深度估计网络获取高质量深度信息,并将其作为深度监督的来源。对每张图片增加了用于模拟光照信息的额外嵌入向量,减小了少样本场景下因光照差异引起的重建失真问题。利用深度信息指导采样过程,使采样点集中在物体表面附近,提高了整体重建质量。
(2)针对训练与渲染速度慢的问题,本文第四章提出了一种神经辐射场的加速模型:以动态更新的采样策略不断筛除无效采样点,通过减少采样点的数量实现了训练的加速。引入差异性的MLP感知机网络,针对不同类型的采样点使用不同尺寸的网络,通过减小网络的尺寸进一步提高了训练效率。设计了用于缓存场景信息的父子表结构,优化了渲染过程,实现了渲染的加速。
(3)针对因暂态遮挡而导致的重建失真的问题,本文的第五章提出了一种去遮挡的神经辐射场模型:在静态MLP网络的基础上增加了一个用于处理暂态物体的暂态网络。暂态网络用于学习场景中临时出现的遮挡物信息,在体渲染时减少其对成像贡献的比重,降低了遮挡物对重建造成的影响。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2024.000655
{DOI}: 10.26926/d.cnki.gbfgu.2024.000655
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv8的安全帽佩戴检测方法的研究
{Author}: 张田楷
{Tertiary Author}: 宋旭东
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 安全帽检测;YOLOv8;注意力机制;轻量化
{Abstract}: 在我国建筑和工业生产等行业,大多数安全事故由高处坠落和物体撞击引起。作为关键的个人防护装备,安全帽可以显著降低这类事故对头部的伤害。目前,多数工地仍依赖人工目视检查安全帽佩戴情况,这种方法既耗时又易出错。因此,实现施工现场的智能化管理,实时监控工人佩戴安全帽的状态,具有极其重要的实际价值。在众多基于深度学习的目标检测技术中,本研究选用了无锚框的YOLOv8算法作为研究基础,简化了检测框架,增强对不同尺度目标的适应性,拥有更高的检测效率和速度以及定位精度。然而,由于施工现场环境的复杂性,YOLOv8在安全帽检测任务中可能会出现漏检和误检问题,且由于目标检测模型的参数量庞大,难以将其部署在施工现场等资源限制的设备上。因此,本研究将对此算法进行优化,来提升其在安全帽佩戴检测中的表现。本文的研究主要包括以下几个方面:(1)为了解决原有YOLOv8模型在对复杂环境中安全帽佩戴的检测存在的问题,提出了一种基于注意力机制的多尺度检测方法TA-YOLOv8。首先引入双维度注意力机制TDAM,使模型同时关注通道和空间信息。接着整合了ASPP金字塔,通过不同采样率的空洞卷积来捕获多尺度信息,这使得模型能够更有效地处理来自不同距离的目标,尤其提升在检测小目标安全帽时的检测性能。最后通过实验对比发现,该方法的m AP@0.5达到92.2%,相比原模型YOLOv8提高了5.3%,FPS达到了102帧,在安全帽检测任务上的精确度有了明显提升,且与检测速度也达到了良好的平衡。(2)为解决目前安全帽检测方法存在的参数量和计算量大的问题,提出一种轻量化检测方法GI-YOLOv8,首先采用Ghost Net中的轻量化模块来替换传统网络的标准卷积层和Bottleneck结构,以此减少模型的参数量与复杂性。其次,为了补偿轻量化模型可能带来的性能下降,引入了Inner-Io U损失函数,进一步加快模型收敛,并提升整体检测精度。经过一系列对比实验,结果显示该方法在降低模型的参数量和计算量方面表现出色,与原模型相比,参数量和计算量分别降低了69%和70%。此外,该模型的m AP@0.5达到了90.8%,并且每秒131帧的处理速度满足了实时性检测的要求。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2024.000067
{DOI}: 10.26990/d.cnki.gsltc.2024.000067
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO模型的垃圾分类算法设计与实现
{Author}: 毛少华
{Tertiary Author}: 王文东
{Publisher}: 延安大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 计算机视觉;YOLO模型;注意力机制;垃圾分类
{Abstract}: 随着社会经济的发展和人民生活水平的提高,科技迭代和居民日常生活所产生的垃圾也迎来了爆炸式的增长.虽然我国的垃圾管理机制越来越规范,但仍存在垃圾分类工作需依靠居民的自觉分类意识和人工挑拣工作效率低的问题.现如今,随着计算机视觉技术的蓬勃发展,YOLO系列目标检测算法在目标检测方面表现优异,将垃圾分类任务和YOLO目标检测算法相结合,为人们高效解决垃圾分类问题提供了新思路.因此,本文基于深度学习的算法,将垃圾分类任务与YOLO目标检测算法相结合,提出了新模型并对其进行了应用.本文主要研究内容如下:首先,依据国家对垃圾管理的标准,构建了垃圾分类数据集.利用人工采集和网络爬虫的技术收集日常垃圾图像,采用图像增强技术对数据进行了预处理,扩充数据集,增强数据的多样性,构建了共计4692张垃圾图像和47个生活中常见的垃圾类别的垃圾分类数据集,为后期实验提供了强大的数据保障.其次,根据注意力机制特征提取能力强的特性,对YOLOv8s模型结构进行了改进,提出了融合注意力机制的SE+CBAM+YOLOv8s的垃圾分类模型.通过消融实验、同类模型对比实验和实时效果检测实验表明,本文改进模型的准确率、m AP(0.5)和m AP(0.5-0.95)的值相较于原来的YOLOv8s模型分别提升了11.15、4.33和2.52个百分点.验证了模型具有较强的泛化能力.最后,利用Py Qt5编写可视化程序,开发了基于深度学习的YOLOv8垃圾分类系统,可准确快速地检测出垃圾所属类别和置信度,为将本文改进的YOLOv8s模型应用到垃圾分类实际任务中提供了可能性.
{URL}: https://link.cnki.net/doi/10.27438/d.cnki.gyadu.2024.000702
{DOI}: 10.27438/d.cnki.gyadu.2024.000702
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO的道路目标检测算法研究
{Author}: 李树壮
{Tertiary Author}: 翟双
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: YOLO算法;目标检测;稀疏残差网络;双模态特征融合;光流法
{Abstract}: 随着计算机视觉技术的飞速发展,目标检测技术在智能交通、工业检测领域有了广泛的应用。其中道路目标检测因交通驾驶安全的需要成为研究热点。然而,实时道路交通环境的复杂性和图像识别设备的限制导致检测图像存在差异,特别是小目标如远处行人、车辆等,其尺寸小、分辨率低等问题进一步增加了检测难度。传统的手工特征提取方法在处理复杂道路场景时面临挑战,而深度学习技术的兴起为道路目标检测带来了突破。
尽管深度学习算法在目标检测方面取得了显著进展,但现有算法在识别车辆、行人、交通标志等关键要素时,往往仍需驾驶人员的辅助干预,无法完全实现自主决策。此外,在光照不均匀的环境中,图像帧的质量可能受到影响,导致目标检测算法的准确性下降,且现有算法对于特殊目标及小目标的检测能力仍显不足,增加了智能驾驶系统在实际应用中的风险。因此,由各种原因导致的道路交通事故仍然时有发生,亟需更为精确、鲁棒的目标检测算法来提升智能驾驶系统的安全性与可靠性。本文通过利用双模态稀疏网络提高图像对比度,增加输入细节,并通过改进YOLOv8算法的骨干网络（Backbone）和颈部网络（Neck）等操作提高道路目标尤其是小目标检测的精确率,具体研究内容如下:
（1）针对光流法在车辆移动过程中因光照不均导致的目标检测误差较大的问题,提出了一种基于改进稀疏残差网络的目标检测算法,其网络模型包含了图像预处理、特征提取和特征融合三个模块,创新性地将稀疏残差网络输入端分为两个分支,分别为稀疏残差分支和空洞卷积分支,这两个分支作为输入视频帧的特征提取和融合模块,经过不同尺度的卷积核多尺度提取后输入至下一模块;针对视频帧图像细节不足的问题,利用基于多权值的联合损失函数进行图像细节恢复,使用残差网络,在保证图像原始结构的情况下,对图像进行分割和重建,从而更好的实现图像细节恢复功能;同时提出改进的核主成分分析法,对融合后即将输入光流场的特征进行降维处理,解决算法冗余的问题;利用实时性较高的YOLOv5算法的后处理模块改进光流估计算法,提高光流场对图像的处理速度。实验结果表明,在公开数据集上进行测试,本文方法的PSNR（Peak Signal-to-Noise Ratio）值为29.6756,SSIM（Structural Similarity Index）值为0.8766,均高于同类目标检测增强算法,检测平均精度较YOLOv5算法提高2.09,具有较高的准确性。
（2）针对一般的单模态目标检测算法在道路小目标检测中容易受到背景噪声等因素的影响,导致小目标识别精度较低,出现错检漏检等情况。本文提出一种基于YOLOv8的双模态小目标检测算法。首先对输入的一一对应可见光和红外光图像进行双模态特征提取,提出特征加权模块,创新性地赋予二者权重,通过该权重计算出二者融合的最佳比例后对提取的特征进行加权融合,解决双模图像简单一比一融合后二者缺点易凸显的问题。然后对融合后的特征进行全局注意力机制加强,增强小目标与背景的对比度,加强后的特征经过SPPF模块进行空间金字塔池化,通过联合损失函数在保留小目标轮廓的同时保留小目标的图像细节,以解决小目标在检测过程中仅识别出位置不能识别出种类的问题。最后经过处理的特征进入骨干网络和颈部网络改进的YOLOv8检测模块,通过引入卷积Pcov和GSConv改进C2f中的卷积以选择性地提取双模态融合特征信息,以实现对道路小目标的检测增强。实验结果表明,本文算法在红外光和可见光双模输入时AP0.5为76.5,较YOLOv5-s提升5.0,较YOLOv8提升2.9,FPS较YOLOX提升10Hz,与YOLOv8持平,因此本文与其他同类算法相比,对道路小目标有更高的识别精度,可以有效减少小目标错检漏检概率。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2024.000656
{DOI}: 10.27805/d.cnki.gccgy.2024.000656
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态融合的3D目标检测方法研究
{Author}: 许如玉
{Tertiary Author}: 张正
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 计算机视觉;自动驾驶;3D目标检测;多模态融合
{Abstract}: 目标检测技术的成熟发展,促使自动驾驶越来越走进人们的生活。多模态融合的检测方法对于自动驾驶系统中的3D目标检测至关重要。神经网络模型在激光雷达点云3D目标检测和相机图像2D目标检测上都取得了重大进展。然而,由于点云和图像模态不同,跨模态的信息交互面临巨大的挑战。因此,在自动驾驶领域,研究一种能充分保留并融合各个模态特征的高精度3D目标检测技术极为重要。
点云和图像是自动驾驶中的两个最为常见的感知源,点云可以提供精确的距离信息,图像有着更密集丰富的语义信息。目前,相比于基于图像和基于点云的单模态3D目标检测方法,多模态融合的方法普遍更受欢迎。然而,与图像特征相比,点云更为稀疏,特别是对于远距离和小目标,提取到的特征量较少,现有的多模态融合方法的检测性能受到了限制。此外,现有的多模态融合方法忽略了特定模态下的有用信息,特征聚合粗糙化,从而影响了模型的性能。针对上述局限问题,本文基于Transformer模型,对跨模态融合的3D目标检测技术进行研究,具体工作如下:
1.针对远距离、小目标点云稀疏问题,为提高多模态融合的3D目标检测准确率,本文提出了基于点云稠密化的像素级特征融合3D目标检测方法,以提取更多有效特征。首先,采用基于远距离采样的方法进行点云稠密化,根据2D实例分割结果生成密集的3D虚拟点云,来增强原始稀疏点云;然后,为了在目标检测过程中能充分利用每种模态特定的有用信息,使每种模态特征都能被学习并保持其独特的特性,本文设计了多模态双边交互方法,将点云和图像特征分别作为Q(查询矩阵),跨模态特征作为K(键矩阵)和V(特征值矩阵)做交叉注意力学习。在nu Scenes数据集上的实验表明,本文方法在3D目标检测中取得了较为先进的成果。
2.针对当前多模态像素级特征融合方法中信息损失和特征聚合粗糙问题,本文提出了基于孪生神经网络的实例级特征融合3D目标检测算法。首先,利用2D框和3D框的几何一致性来选取有效候选框,以减轻选取所有对比框的工作量;然后,将成对的预测框送入相似性约束结构,采用交叉模式对预测框进行相似性约束,使两个模态特征相似性最大化,增强融合过程中的语义一致性。在nu Scenes公开数据集上的多项对比实验证明了本方法的有效性。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2024.000209
{DOI}: 10.26926/d.cnki.gbfgu.2024.000209
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于ViT-改进YOLOv7的稻田杂草识别
{Author}: 陈学深;吴昌鹏;党佩娜;张恩造;陈彦学;汤存耀;齐龙
{Author Address}: 华南农业大学工程学院;
{Journal}: 农业工程学报
{Year}: 2024
{Volume}: 40
{Issue}: 10
{Pages}: 185-193
{Keywords}: 机器视觉;深度学习;YOLOv7;ViT;稻田杂草;识别
{Abstract}: 为解决光线遮蔽、藻萍干扰以及稻叶尖形状相似等复杂环境导致稻田杂草识别效果不理想问题,该研究提出一种基于组合深度学习的杂草识别方法。引入MSRCP(multi-scale retinex with color preservation)对图像进行增强,以提高图像亮度及对比度;加入ViT分类网络去除干扰背景,以提高模型在复杂环境下对小目标杂草的识别性能。在YOLOv7模型中主干特征提取网络替换为GhostNet网络,并引入CA注意力机制,以增强主干特征提取网络对杂草特征提取能力及简化模型参数计算量。消融试验表明:改进后的YOLOv7模型平均精度均值为88.2%,较原YOLOv7模型提高了3.3个百分点,参数量减少10.43 M,计算量减少66.54×10～9次/s。识别前先经过MSRCP图像增强后,与原模型相比,改进YOLOv7模型的平均精度均值提高了2.6个百分点,光线遮蔽、藻萍干扰以及稻叶尖形状相似的复杂环境下平均精度均值分别提高5.3、3.6、3.1个百分点,加入ViT分类网络后,较原模型平均精度均值整体提升了4.4个百分点,光线遮蔽、藻萍干扰一级稻叶尖形状相似的复杂环境下的平均精度均值较原模型整体提升了6.2、6.1、5.7个百分点。ViT-改进YOLOv7模型的平均精度均值为92.6%,相比于YOLOv5s、 YOLOXs、 MobilenetV3-YOLOv7、 YOLOv8和改进YOLOv7分别提高了11.6、10.1、5.0、4.2、4.4个百分点。研究结果可为稻田复杂环境的杂草精准识别提供支撑。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20240521.1620.031
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO v8的无人机视角下青皮核桃目标检测
{Author}: 钟天泽;云利军;杨璇玺;陈载清;吴明杰
{Author Address}: 云南师范大学信息学院;云南省教育厅计算机视觉与智能控制技术工程研究中心;云南省林业调查规划院生态分院卫星林业应用中心;
{Journal}: 郑州大学学报(理学版)
{Pages}: 1-7
{Keywords}: 目标识别;无人机视角;机器视觉;果实测产;核桃检测
{Abstract}: 目前针对核桃测产的方法大多停留在利用传统的统计学模型上,其准确率几乎无法保证。因此,拟以青皮核桃为例,建立了无人机航拍视角下的核桃图像数据集,创新性地首次将Coordinate Attention机制嵌入YOLO v8模型中,利用改进后的YOLO v8-CA模型算法对青皮核桃进行目标检测。实验结果表明,改进后的新模型YOLO v8-CA与原始YOLO v8和YOLO v5相比,在mAP值上分别提高了0.4%和5.1%,在Recall值上分别提高了1.9%和8.9%。
{ISBN/ISSN}: 1671-6841
{Notes}: 41-1338/N
{URL}: https://link.cnki.net/doi/10.13705/j.issn.1671-6841.2023256
{DOI}: 10.13705/j.issn.1671-6841.2023256
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的液晶屏/OLED屏缺陷检测方法综述
{Author}: 林思媛;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 中国图象图形学报
{Year}: 2024
{Volume}: 29
{Issue}: 05
{Pages}: 1321-1345
{Keywords}: 缺陷检测;液晶屏(LCD);OLED屏;机器视觉;深度学习;纹理背景消除;无监督学习
{Abstract}: 液晶屏（liquid crystal display, LCD）和有机发光半导体（organic light-emitting diode, OLED）屏的制造工艺复杂，其生产过程的每个阶段会不可避免地引入各种缺陷，影响产品的视觉效果及用户体验，甚至出现严重的质量问题。实现快速且精确的缺陷检测是提高产品质量和生产效率的重要手段。本文综述了近20年来基于机器视觉的液晶屏/OLED屏缺陷检测方法。首先给出了液晶屏/OLED屏表面缺陷的定义、分类及其产生的原因和缺陷的量化指标；指出了基于视觉的液晶屏/OLED屏表面缺陷检测的难点。然后重点阐述了基于图像处理的缺陷检测方法，包括介绍图像去噪和图像亮度矫正的图像预处理过程；考虑到所采集的液晶屏/OLED屏图像存在纹理背景干扰，对重复性纹理背景消除和背景抑制法进行分析；针对Mura缺陷边缘模糊等特点，总结改进的缺陷分割方法；阐述提取图像特征并使用支持向量机、支持向量数据描述和随机森林算法等基于特征识别的缺陷检测方法。接着综述了基于深度学习的缺陷检测方法，根据产线不同时期的样本数量分别总结了无监督学习、缺陷样本生成、迁移学习和监督学习的方法，其中无监督学习从基于生成对抗网络和自编码器两个方面进行阐述。随后梳理了通用纹理表面缺陷数据集和模型性能的评价指标。最后针对目前液晶屏/OLED屏缺陷检测方法存在的问题，对未来进一步的研究方向进行了展望。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwAWnnB-YWUKFQjWULbYNbyBD3sDKReZHoLW-n3GM3EAKGBETmnKoH6K29WQxe3sCtzYtDhCAZtvm6EtYQmnz2PJc2msS8HZnAkz8me7Wes6tBzXLX9FSfPIl6ymbqzqg-Z38EKy0P8rQQFRpU0HlcNPbC_JBXqA0ElYnfiM4Be7--87F8_tZ1i8IX2ZGMvqmQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 果园环境下采摘机器人水果目标识别算法探究——以绿色阳光玫瑰葡萄为例
{Author}: 徐晓婧;李艳
{Author Address}: 嘉兴职业技术学院;
{Journal}: 智慧农业导刊
{Year}: 2024
{Volume}: 4
{Issue}: 09
{Pages}: 25-28+33
{Keywords}: 绿色葡萄;图像分割;OTSU算法;SVM算法;机器视觉
{Abstract}: 该文研究果园环境下绿色阳光玫瑰葡萄的果实图像分割和定位方法。在分析了顺光、逆光和夜间3种光照情况下的采集图像后，选取最能体现绿色葡萄果实的颜色分量作为分割算法的输入图像。利用最大类间方差法（OTSU）和支持向量机法（SVM）实现果实和背景区域的分割。实验结果对比表明，绿色葡萄在夜间的识别率高于晴天顺光和逆光的情况。比较2种算法的准确率，可以发现SVM算法在晴天顺光和逆光时的准确率更高，而OTSU算法在夜间情况时较高，达到了98.7%。
{ISBN/ISSN}: 2096-9902
{Notes}: 23-1613/S
{URL}: https://link.cnki.net/doi/10.20028/j.zhnydk.2024.09.007
{DOI}: 10.20028/j.zhnydk.2024.09.007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识蒸馏的高效图像语义分割方法研究
{Author}: 刘宇昂
{Tertiary Author}: 王骏;张伟
{Publisher}: 华东师范大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 语义分割;知识蒸馏;资源高效;模型压缩;推理加速;域适应
{Abstract}: 图像语义分割是计算机视觉领域的一项基础识别任务,其核心目标是依据每个像素所代表的语义类别对其进行精确的划分和归类。由于高算力模型、先进算法以及海量数据的支持,深度学习方法促成了图像语义分割技术的发展和进步,并在自动驾驶、医疗诊断、遥感影像等领域得到了广泛应用与实践。然而,目前的深度学习方法在图像语义分割中也面临一些挑战。模型方面,深度学习模型通常具有大量的参数,导致计算复杂度高,难以在资源受限的设备上进行部署和推理。算法方面,常规监督算法训练的轻量化模型性能难以满足预期效果。数据方面,大量标注数据的获取通常需要耗费大量的人力和时间,且需要承担隐私风险。因此,提高图像语义分割方法的训练效果和推理效率、降低标注成本等资源高效性研究成为十分有前景的方向。本文从算法、模型和数据三个角度切入,利用知识蒸馏技术,对高效的图像语义分割方法进行了详尽的研究,具体如下:1.算法方面:针对语义分割的两种蒸馏学习算法。教师-学生架构作为最广泛的蒸馏学习范式,在语义分割任务中会面临知识传递单一的局限性问题,从而无法为轻量化学生模型提供足够丰富的学习信息。为此,本文提出了一种多样知识融合的算法,以全面地对语义分割模型的中间层特征进行知识蒸馏,提高了分割结果的准确性。另外,常规的教师-学生架构的蒸馏方式需要引入庞大的教师模型提供指导,无疑会显著增加计算资源的需求,导致训练的低效性。为了避免使用大型教师网络的训练成本,本文重新审视了分割中的标签和特征蒸馏问题,并提出了自解耦与集成蒸馏框架用于训练高效的语义分割模型。2.模型方面:轻量化ViT架构的语义分割模型蒸馏研究。现有的模型压缩与加速算法主要应用于卷积神经网络,无法支持最先进的视觉Transformer(ViT)架构。为了实现语义分割ViT模型的轻量化和推理加速,本文从推理阶段和预训练阶段入手,分别提出了基于自蒸馏和动态推理的语义分割ViT加速方法和基于多种自监督教师模型的预训练蒸馏算法。通过动态减少参与计算的token数量,可以逐步提高语义分割ViT模型的推理速度。利用多种预训练范式得到的教师模型指导,可以实现通用预训练模型的轻量化和高性能,显著提升在语义分割等多种下游任务的表现。3.数据方面:知识蒸馏驱动的语义分割无源域适应方法。无监督域适应(UDA)可以解决深度神经网络在语义分割中过度依赖像素级标注数据的挑战,而这种数据需要大量成本投入。然而,现有的UDA方法要求完全访问源数据集以减小源域和目标域之间的差距,这无法满足隐私保护的需求。为此,本文提出了一种用于语义分割的无源域自适应框架。该框架只需要一个经过良好训练的源模型和一个无标签的目标域数据集进行微调,通过模型适配期间的知识转移来恢复和保留源域知识,并从目标域中提取有价值的信息进行自监督学习。该框架整合了针对语义分割的像素级和区块级优化目标,实验证明所提出的框架相对于现有依赖源数据的UDA方法更加有效。本论文的研究工作深入探索了蒸馏算法的设计、模型优化和数据利用等方面,为图像分割任务提供了一系列资源高效的解决方案。通过实验验证,本文的方法在多个数据集上取得了优秀的分割结果和效率优势,具有实际应用的潜力。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2024.000263
{DOI}: 10.27149/d.cnki.ghdsu.2024.000263
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉和PLC技术的貉子皮自动分拣系统设计与实现
{Author}: 刘经伟
{Tertiary Author}: 孙德杰;张波
{Publisher}: 河北科技师范学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 机器视觉;图像处理;PLC技术;皮草
{Abstract}: 随着工业自动化水平的持续进步,皮草行业也正在努力寻求技术的创新与突破。本文着重介绍了一种新型的自动化分拣方案——基于机器视觉和可编程控制器(Programmable Logic Controller,PLC)技术的貉子皮自动分拣系统。该系统结合了机器视觉的高效识别能力和PLC的稳定控制能力,旨在提升貉子皮分拣的效率和精度。本文提出的方案主要依赖于机器视觉系统来精确捕捉貉子皮的尺寸关键信息,再通过PLC控制系统进行快速准确的分类操作。此方案不仅大幅提高了分拣速度,简化了分拣流程,更显著降低了由人为因素导致的错误率。
首先,对皮草样品进行高质量的图像采集。通过对皮草图像进行预处理,包括去噪、二值化、边缘检测等,以突出皮草的特征,系统能够精确地识别和测量貉子皮的尺寸特征参数。此参数将作为后续自动分拣的基础数据。
其次,详细分析了分拣系统的功能需求,确定了系统的性能指标和主要参数,使用专业的机械建模软件,详细的设计机械部分,包括各个部件的尺寸、材料、连接方式,建立了分拣系统的三维模型,这个系统将由多个精密组件构成,以确保其能够在高速运转中保持稳定性和耐用性。
最后,根据系统需求,我们选择了合适的PLC控制器、传感器、执行器等硬件,设计了系统的电气原理图、拓扑图,确保电气连接的准确性,实现对分拣系统的精确控制。编写了PLC控制程序,实现了对分拣系统的精确控制,如执行器的动作控制,并对电气程序进行仿真测试,以确保其在实际运行中的稳定性和可靠性。
此方案的优势在于其高度的自动化和智能化,能够显著提升貉子皮的分拣效率,同时降低人工操作的错误率,同时具有较强的灵活性和可扩展性,可以轻松地适应不同的分拣需求和环境。本文提出的基于机器视觉和PLC技术的貉子皮自动分拣系统设计方案,不仅解决了当前皮草分拣中的效率问题,还为行业的自动化和智能化发展提供了新的思路和方向。
{URL}: https://link.cnki.net/doi/10.27741/d.cnki.ghbkj.2024.000199
{DOI}: 10.27741/d.cnki.ghbkj.2024.000199
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的车型车牌识别研究
{Author}: 陈冠宇
{Tertiary Author}: 尚雅层
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 车型识别;车牌号识别;放大号识别;YOLOv7-Tiny;PP-OCR
{Abstract}: 随着社会发展,各种自动化、智能化的产品层出不穷。交通智能化也得到迅速发展,车牌识别技术很普遍。但对于一些车辆特别是大型车辆,其车牌出现遮挡、污渍等情况,利用目前识别车牌号的方法存在识别不准确的情况。为提高车牌识别准确率,本文基于深度学习,对车牌号识别进行了深入研究。大型车辆都要喷刷有车牌放大号,本文提出了利用车牌放大号辅助车牌识别的车型车牌识别模型。
本课题利用改进的YOLOv7-Tiny目标检测算法对行进中的车辆及其的车牌和放大号进行检测,再利用字符识别算法对检测出的车牌和放大号进行识别,另外应用本文提出的算法,设计了一种车辆车牌识别系统。
结合本课题的需求,以及现有的实验条件,利用BITVehicle和CCPD等数据集互为补充,制作了车型、车牌和放大号检测数据集,车牌和放大号识别数据集,并且对数据集进行了重新标注。
对目标检测方法中的YOLOv7-Tiny算法进行了改进,主要涉及注意力机制、损失函数和卷积层三个方面。在本研究建立的数据集上对新模型进行了训练和评估。实验结果表明,增强的模型实现了平均精度(m AP)值的提升,计算复杂度和模型体积有所降低。
本文使用PP-OCR网络中的识别部分在所建车牌和放大号识别数据集上进行训练,所得模型将原始模型在准确度上有大幅提升。为了实现模型轻量化,之后对所得模型进行了量化训练,虽然其模型精度有小幅下降,但其体积大幅下降。
最后对目标检测和字符识别模型进行Tensorrt加速和部署,并设计了监控界面系统,可以在实际操作中使用。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000085
{DOI}: 10.27391/d.cnki.gxagu.2024.000085
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和PLC的谷糙分级控制系统设计
{Author}: 李欣;齐家敏;程昊;王炎春
{Author Address}: 湖北文理学院机械工程学院;湖北航宇嘉泰飞机设备有限公司;
{Journal}: 现代电子技术
{Year}: 2024
{Volume}: 47
{Issue}: 09
{Pages}: 124-130
{Keywords}: 谷糙分级;嵌入式;机器视觉;图像处理;PLC;电机控制;传感器;人机交互
{Abstract}: 针对传统谷糙分离机应用人工调节分级板存在定位精度低、成本高、工作效率受限等弊端，提出一种基于机器视觉和PLC的谷糙分级控制系统。搭建嵌入式视觉检测平台，对谷糙检测的图像处理算法进行多级式递进融合设计，对谷糙的特征分级点进行提取；基于位置偏移的方法联动电机驱动程序，实现PLC控制系统的精确定位；结合传感器技术，根据谷糙的重力、表面粗糙度、流量、设备振动频率及倾斜角等特性，在上位机组态监控下进行设备校正，进而实现谷糙自动化、智能化分级。实验结果表明：该谷糙分级控制系统的平均定位精度为96%，回砻谷含糙率低于5%，具有良好的工作性能和稳定性，能够取代传统人工机械操作，降低人工成本，提高工作效率，并增加大米生产线的生产效益。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2024.09.023
{DOI}: 10.16652/j.issn.1004-373x.2024.09.023
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的茶叶嫩芽识别方法研究进展
{Author}: 张昆;袁博涵;崔静莹;刘宇洋;毛敏;王鹏;曾庆轩
{Author Address}: 信阳师范大学物理电子工程学院;信阳市浉河区农业农村局;
{Journal}: 山东农业科学
{Year}: 2024
{Volume}: 56
{Issue}: 05
{Pages}: 163-170
{Keywords}: 计算机视觉;芽叶嫩芽识别;品质等级分类;智能化采茶
{Abstract}: 一直以来茶叶嫩芽的采摘都依赖于手工，机械化采摘依旧是难题。近些年计算机视觉技术飞速发展，为智能化采摘茶叶嫩芽提供了技术前提，受到科研人员的广泛关注，已率先在茶叶嫩芽识别领域展开了相关研究。本文从茶叶嫩芽检测识别、品质等级分类识别两方面来综述当前茶叶嫩芽识别的研究进展，介绍了分别基于传统图像处理法、机器学习算法和基于深度学习算法的茶叶嫩芽检测识别方法，比较分析了每种方法的优缺点，着重介绍了深度学习算法在茶叶嫩芽品质等级分类中的应用研究进展，同时总结了当前茶叶嫩芽研究领域的热点及存在的诸多难点，并对今后茶叶嫩芽识别研究的方向进行了展望，以期为茶叶嫩芽智能化采摘提供相应的技术支持。
{ISBN/ISSN}: 1001-4942
{Notes}: 37-1148/S
{URL}: https://link.cnki.net/doi/10.14083/j.issn.1001-4942.2024.05.021
{DOI}: 10.14083/j.issn.1001-4942.2024.05.021
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的轨道交通站内火灾检测与定位
{Author}: 张金雷;杨健;刘晓冰;陈瑶;杨立兴;高自友
{Author Address}: 北京交通大学,系统科学学院;北京交通大学,交通运输学院;
{Journal}: 交通运输系统工程与信息
{Year}: 2024
{Volume}: 24
{Issue}: 03
{Pages}: 53-63
{Keywords}: 智能交通;火灾检测;深度学习;轨道交通车站;计算机视觉
{Abstract}: 为及时有效地处理轨道交通站内火灾事件，本文提出基于计算机视觉的站内火灾检测与精细化火灾定位模型(Fire-Detect)。首先，基于Unity仿真模拟和收集互联网图像数据的方式制作站内火灾图像与视频数据集Fire-Rail，用于训练构建的火灾检测算法和精细化火灾定位算法；其次，基于卷积神经网络、残差结构与通道注意力机制构建火灾检测算法，用于检测站内监控视频中每帧分别为“正常状态”或“疑似火灾”状态；最后，在“疑似火灾”状态下，模型启动精细化火灾定位算法，将图像以及后续的每帧图像输入精细化火灾定位算法中，并实时输出火灾发生场景下的精细化火灾定位信息。在Fire-Rail数据集上进行实验，火灾检测算法在测试集的准确率为95.12%；此外，卷积神经网络层级实验平衡了资源消耗和准确率，消融实验验证了各部分的有效性，鲁棒性实验表明，该算法能处理大部分噪声，整体模型的平均火灾定位检测精度mAP为77.3%，可应用于轨道交通站内视频监控设备。
{ISBN/ISSN}: 1009-6744
{Notes}: 11-4520/U
{URL}: https://link.cnki.net/doi/10.16097/j.cnki.1009-6744.2024.03.006
{DOI}: 10.16097/j.cnki.1009-6744.2024.03.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv8的陶瓷类型检测方法及实践
{Author}: 揭嘉俊
{Tertiary Author}: 彭永康
{Publisher}: 景德镇陶瓷大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 陶瓷类型检测;YOLOv8算法;注意力机制;DCNv2可变形卷积;计算机视觉
{Abstract}: 陶瓷,作为中国上下五千年的历史瑰宝,以其独特的艺术魅力和精湛的工艺技术吸引着世人的目光。从青花瓷的淡雅幽深,到粉彩瓷的绚丽多姿,再到斗彩瓷的精巧繁复,每一种陶瓷都承载着深厚的历史文化内涵。为了解陶瓷,人们通常通过检索陶瓷图片来了解陶瓷,但这种方法既低效又有失准确率。为解决这一问题,本文提出了基于YOLOv8的陶瓷类型检测算法,该算法是一种先进的实时目标检测算法,通过深度学习和计算机视觉技术,能快速准确地从输入的陶瓷图片中提取特征,进而检测出陶瓷的类型。
针对YOLOv8算法特征提取能力有限和小目标的检测效果不佳的问题,本文在YOLOv8的neck端中分别添加3种不同的注意力机制（MHSA、SA、CBAM）,并在骨干网络中添加DCNv2 可变形卷积,得到 YOLOv8+SA+DCNv2、YOLOv8+MHSA+DCNv2 和 YOLOv8+CBAM+DCNv2 三种改进模型,简称为YOLOv8SD、YOLOv8MD和YOLOv8CD。在训练模型前通过爬虫爬取了青花瓷、粉彩瓷、斗彩瓷、玲珑瓷和颜色釉瓷5种陶瓷共23354张图片,从中筛选出符合要求的图片共1076张,并对筛选出的图片使用随机转化、mixup、mosaic共3种数据增强算法将数据集扩充至9000张,然后使用labelimg软件对数据集进行标注。为验证单独添加DCNv2卷积与三种注意力机制这两种优化策略带给模型的性能增益,本文对包含基础YOLOv8和三种改进模型在内共8个模型做了消融实验,实验结果表明单独加模块的方法对模型的性能提升不大。接着对三种改进算法进行了混淆矩阵的分类精度和混淆度分析、召回率图像的置信度和召回率分析和三种损失函数boxloss、clsloss和dflloss的数值变化分析,根据消融实验和以上三种分析的结果筛选出YOLOv8CD为最优改进模型,最后将最优算法与YOLOv8算法和YOLOv5算法做对比实验以验证改进后模型的性能。实验结果表明,在精确率P上,YOLOv8CD 相较 YOLOv5 和 YOLOv8,提升了 8.8%和 2.2%;在召回率 R 上,YOLOv8CD 对比 YOLOv5 和 YOLOv8,提升了 18.7%和7.2%;在 mAP@.5 平均精度值上,YOLOv8CD对比YOLOv5提升了 8.1%,对比YOLOv8下降了 0.4%;在mAP@[.5:.95]平均精度值上,YOLOv8CD相较YOLOv5和YOLOv8,提升了24.6%和9.6%。根据以上数据能说明YOLOv8CD模型在主干网络引入可变形卷积DCNv2和在Neck端加入CBAM注意力机制确实能给模型带来性能上的提升。此外,本文基于Django框架还设计了一个的网页界面,用于上传图片并展示识别结果以及提供相应陶瓷类型的详细介绍,旨在促进陶瓷艺术的传播和普及。
{URL}: https://link.cnki.net/doi/10.27191/d.cnki.gjdtc.2024.000330
{DOI}: 10.27191/d.cnki.gjdtc.2024.000330
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 注意力机制在视网膜血管分割中的应用综述
{Author}: 裴峻鹏;汪有崧;李增辉;王伟
{Author Address}: 上海理工大学健康科学与工程学院;海军军医大学海军特色医学中心;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 14
{Pages}: 50-65
{Keywords}: 视网膜血管分割;神经网络;注意力机制;计算机视觉
{Abstract}: 视网膜血管的自动分割在眼科和心血管疾病的计算机辅助诊断中发挥着重要作用。注意力机制能够提高经典神经网络模型对图像特征提取的效率和精度，因此注意力机制在视网膜血管分割模型中广泛使用。首先回顾了视网膜血管分割的常用数据集及评价指标，接着根据工作机理将注意力分为选择性注意力机制和自注意力机制两类；根据计算机视觉任务中的作用域将注意力方法分为通道注意力、空间注意力以及混合注意力三类，结合视网膜血管分割任务重点介绍了以上三类方法的代表性注意力模型的具体应用，并对相关模型进行性能对比和评价。最后，对注意力机制存在的问题以及未来的发展趋势进行了讨论。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20240412.1822.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的桥梁结构车致振动及裂缝识别研究
{Author}: 袁杭明
{Tertiary Author}: 叶肖伟;秦建设
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 桥梁健康监测;计算机视觉;结构振动监测;模型优化;裂缝量化评估
{Abstract}: 桥梁结构作为交通基础设施的重要组成部分,是连接不同地点的关键纽带。它们跨越河流、湖泊、海峡等自然障碍,使得陆地交通得以延续,是物流运输和人员流动的重要通道,支撑着各种经济活动的顺利进行。然而,桥梁结构在服役过程中会遭受多种损害。环境作用、初始损伤、车辆荷载等因素可能导致混凝土产生裂缝、剥落和磨蚀,混凝土分解和钢筋锈蚀,从而影响桥梁结构的完整性和安全性。其中,车辆荷载是引起桥梁结构产生开裂变形的重要原因。过多过重的车辆会引起桥梁结构振动疲劳,引起结构开裂,并进一步引发其他病害。裂缝作为桥梁损伤的一种常见形式,其出现可能预示着结构强度的减弱或耐久性的降低。通过及时、准确的裂缝识别,可以对桥梁的健康状况进行有效评估,从而采取相应的维护或加固措施,避免潜在的安全风险。此外,裂缝识别还有助于预测桥梁的剩余寿命,为桥梁的维护管理提供科学依据,确保桥梁的正常运行,延长其使用寿命,对于保障交通安全、促进经济社会发展具有重要意义。因此,本文围绕车致振动及桥梁结构裂缝的监测问题,开展以下研究:(1)建立了基于YOLO神经网络和图像处理的车辆识别与追踪方法。针对车辆追踪的问题,本文获取了杭州某大桥桥塔的现场车流监控视频。经过筛查与选取,获得了1000帧图像并对其中的车辆按照重量分为四类进行标注。通过YOLOv7网络开展了车辆识别与追踪研究,分析了模型准确率以及误差形成原因。利用检测线实现了上下行车辆的数量统计,进一步结合图像处理方法,实现了车辆速度监测,为评估桥面车辆荷载情况提供了支撑。(2)建立了基于计算机视觉的桥梁结构分布式振动监测方法。传统接触式桥梁结构振动监测方法需要固定支撑点,难以进行临时布置的问题,发展了计算机视觉桥梁结构动态位移监测方法。通过笔记本电脑、工业相机和消费级单反镜头搭建了图像获取设备;通过室内振动台试验,分析了模板匹配算法和稀疏光流算法在位移监测方面的特征;开展现场监测分析了斜拉桥主塔和桥梁跨中等区域的振动特性。(3)建立了基于生成式对抗网络和虚拟混合的半真实桥梁结构裂缝数据集。针对裂缝训练样本数量少,标注花费巨大的问题,利用既有的生成式对抗网络建立了包含10000张裂缝图像和像素级标注的裂缝标签;通过裂缝标注的长度和宽度参数评价了虚拟裂缝与真实裂缝之间长宽形态特征的分布;提出了基于图像裁剪拼接的虚实混合数据集,为裂缝数据集的扩展提供了比完全虚拟图像更为逼真的样本;利用经典的U-Net语义分割模型测试了所建样本在裂缝识别性能方面的提升作用。(4)提出了基于注意力机制的桥梁结构裂缝识别方法。针对桥梁结构裂缝区域占图像全部面积比例很小,图像背景中含有较多噪声图案,干扰因素众多的问题,建立了采用注意力机制改进的U-Net网络。通过三种架构网络模型之间的性能指标以及实际图像测试交叉对比,分析了注意力机制在裂缝语义分割方面的作用,提高了模型对裂缝的识别性能。(5)基于计算机视觉的结构裂缝尺寸评估。基于识别后的裂缝区域图像,提出了基于形态腐蚀方法的裂缝骨架提取算法,通过不同长短、粗细以及包含不同空隙的裂缝形态图像,对比分析了多种不同宽度计算方法在裂缝尺寸提取方面的差异。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2024.000239
{DOI}: 10.27461/d.cnki.gzjdx.2024.000239
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的机械臂苹果采摘系统设计与试验
{Author}: 吴杰
{Tertiary Author}: 闫银发;刘莫尘;杨化伟
{Publisher}: 山东农业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 苹果采摘;机器视觉;机械臂;运动控制;深度学习
{Abstract}: 苹果树属于温带落叶乔木,其果实口感丰脆,营养丰富,水溶性高,易被人体吸收,被誉为“水果之冠”。然而,苹果的采摘工作属于劳动密集型,且采摘具有明显的季节性特点。目前,苹果的采摘主要依靠人工进行,这种方式效率低下,制约了农产品的市场竞争力。为了提高苹果采摘的效率,本研究提出一种基于机器视觉的机械臂-手复合体苹果采摘系统,旨在解决矮砧密植果园场景下的苹果采摘问题,实现苹果采摘的机械化、智能化。本文的主要研究工作如下:(1)针对识别模型在果园非结构化环境下存在远距离场景苹果检测精度低且存在漏检误检等问题,本研究基于YOLOv7卷积神经网络进行改进,首先在骨干网络底层加入Gam注意力机制对通道与空间进行权重配比,通过抑制背景信息,聚焦感兴趣区域对目标进行特征提取;利用NMD优化模型Io U,提高了远距离场景下的小目标识别能力,提升了模型的回归精度;采用Bi FPN结构优化颈部网络,提高模型的多尺度融合能力,丰富特征融合信息;另外添加辅助检测头,提高模型识别精度。同原始网络相比,改进后模型的准确率、召回率、m AP@0.5与m AP@0.5-0.95分别提高4.3、1.8、4.4和7.9个百分点。(2)基于双目深度相机,对目标果实进行空间定位。通过机械臂与双目视觉传感器组合平台并通过手眼标定求解坐标系变换关系,得出像素坐标系、图像坐标系、相机坐标系与机械臂坐标系外参变换矩阵。在实验室进行果实空间坐标校准和定位试验,基于检测识别网络与三维空间定位算法,测量位置与计算位置在世界坐标系下三轴误差分别为0.003 m、0.002167 m和0.003833 m。检测识别网络与空间定位算法实现苹果的检测定位,用于苹果采摘平台的研发。(3)基于D-H参数法对采摘机械臂进行运动学建模,完成机械臂运动学逆解的求取并对其进行刚体碰撞分析,实现机械臂初步的路径规划与轨迹规划。进一步采用RRT-connect解决机械臂路径规划问题,并对路径进行平滑处理,实现采摘机械臂在果园环境下的路径规划。(4)搭建苹果采摘机械臂-手复合体采摘平台,对试验结果进行统计分析,实现其“识别定位、坐标变换、路径规划、采摘卸果”功能。在果园环境下对苹果进行采摘试验,记录并分析试验数据。试验结果表明:造成采摘失败的重要原因有路径规划失败、果柄分离失败以及枝干对末端执行器干扰。基于采摘序列优化等优化方法对平台采摘策略进行优化使得采摘成功率提升了2.92个百分点,但采摘作业还会受限于末端执行器尺寸、以及路径规划非最优解等问题。平台的单个苹果平均采摘时间为12.025 s,造成采摘时间过长的原因有:路径规划求解路径非最优解,末端运动规划存在冗杂路径。
{URL}: https://link.cnki.net/doi/10.27277/d.cnki.gsdnu.2024.000390
{DOI}: 10.27277/d.cnki.gsdnu.2024.000390
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 夜跑友好视角下城市街道环境视觉感知评价
{Author}: 陈崇贤;刘欣宜;邱添;刘京一
{Author Address}: 华南农业大学林学与风景园林学院;
{Journal}: 风景园林
{Year}: 2024
{Volume}: 31
{Issue}: 04
{Pages}: 36-43
{Keywords}: 风景园林;视觉感知;计算机视觉;城市街道;体力活动;夜间;地理加权回归(GWR)
{Abstract}: 【目的】随着现代生活方式的转变，城市居民对夜跑活动的需求日益增加。已有跑步环境研究较多关注日间情景，城市街道夜间环境对跑者的影响还有待进一步探究。【方法】以广州越秀核心区为研究区域，利用计算机视觉和人机对抗评分平台评估不同类型街道对夜跑的安全感、恢复力、舒适度、吸引力及环境质量等方面视觉感知的影响，并运用空间自相关方法和地理加权回归模型研究各类街道环境要素与夜跑环境视觉感知之间的关系。【结果】研究发现，滨水街道和商业街可提升夜跑者的舒适度和恢复力，历史文化街道可增强夜跑的安全感和吸引力，而餐饮街和商住混合区街道较难激发正面跑步体验。不同街道环境要素对夜跑环境视觉感知的影响存在差异。【结论】考虑夜跑环境视觉感知评价对优化城市夜间跑步环境具有指导意义，未来可以通过区分街道类型，采取有针对性的规划设计措施来提升不同街道的夜跑体验质量。
{ISBN/ISSN}: 1673-1530
{Notes}: 11-5366/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw9jfBgEhMy73CDNQCSBMjyDAfstyY9RG7pULiOhHeoWAHhx61JokrwOElZRnYryWZ3S0p12Qsq7y1OoSiLuiy9dOokVOZhWWXGnjPIaaJ2gL609a-eoB0g-pMX4fcuckxgz7fBuejHtBMbAWjjhoN39R2MMm6Y223lEsONRgfDKnGpoJvhtKuiRjEZUyV8uos=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾分类算法研究与应用
{Author}: 王光清;李文拴;党佳琦;张愉
{Author Address}: 延安大学化学与化工学院;
{Journal}: 计算技术与自动化
{Year}: 2024
{Volume}: 43
{Issue}: 01
{Pages}: 78-83
{Keywords}: 垃圾分类;色块追踪模块;模型训练;YOLOv3算法优化
{Abstract}: 垃圾分类识别算法是目前研究的热点问题，本文通过引入色块追踪模块Lab颜色模型对YOLOv3算法进行优化，利用优化后的算法搭建训练模型。并针对目前垃圾类别利用网络爬虫爬取日常生活中常见的垃圾图像并进行分类，形成数据集。其次通过优化的YOLOv3算法对处理好的数据集进行模型训练，将训练后的模型进行模型检测。最后通过实际测试，优化后的YOLOv3算法识别的平均准确率达到了94.33%,与原始算法相比，优化后的算法在稳定性和准确度上都有了明显的改善。
{ISBN/ISSN}: 1003-6199
{Notes}: 43-1138/TP
{URL}: https://link.cnki.net/doi/10.16339/j.cnki.jsjsyzdh.202401013
{DOI}: 10.16339/j.cnki.jsjsyzdh.202401013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于事件相机的目标检测算法研究
{Author}: 张亚丽;田启川;唐超林
{Author Address}: 北京建筑大学电气与信息工程学院;建筑大数据智能处理方法研究北京市重点实验室;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 13
{Pages}: 23-35
{Keywords}: 事件相机;目标检测;神经网络
{Abstract}: 事件相机是模仿生物视网膜的成像方式，具有高动态、低延迟、高时间分辨率以及低功耗的特性。其突破传统相机难以捕捉在高动态范围情况下的物体并进行目标识别的困境，事件相机的特性对于研究基于事件相机的目标检测问题具有实验意义。简要叙述事件相机的现状、发展过程、优势与挑战，介绍了各种类型事件相机的工作原理和一些基于事件相机的目标检测算法，阐述了基于事件相机的目标检测算法面对的挑战和未来趋势，并进行了总结。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20240318.1659.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的玫瑰花检测与特征提取
{Author}: 李锐风;杨云福;杨永发;于永顺
{Author Address}: 西南林业大学机械与交通学院;
{Journal}: 中国农业科技导报
{Year}: 2024
{Volume}: 26
{Issue}: 04
{Pages}: 106-113
{Keywords}: 玫瑰花;机器视觉;图像识别;特征提取
{Abstract}: 种植环境下的玫瑰花分布紧密、互相遮挡，为准确检测并提取玫瑰花的特征，基于机器视觉对玫瑰花的颜色和形状进行识别与处理。首先选取双边滤波对玫瑰花图像去噪，然后采用六角锥体模型颜色空间（hexagonal cone colour model,HSV）提取玫瑰花颜色，创建滚动条函数对六角锥体颜色模型各分量图阈值分割从而确定最佳阈值，最后运用形态学运算、面积阈值、孔洞查询填补等方法提取玫瑰花轮廓，并提出玫瑰花内切圆形状拟合算法，将拟合内切圆的圆心和半径作为玫瑰花图像特征。结果表明，玫瑰花颜色阈值能够有效去除玫瑰花枝叶、泥土等图像，形状拟合算法能有效提取玫瑰花的形状特征，并擦除玫瑰花苞。运用该算法单朵玫瑰花识别率为98.17%,3朵及以下重叠玫瑰花的识别率为92.67%,4朵及以上重叠玫瑰花的识别率为74.07%，被枝叶遮挡的玫瑰花识别率为83.03%，该套机器算法在复杂的种植环境中能有效识别并提取玫瑰花的特征值，结果可为玫瑰花采摘机器人研究提供重要技术支撑。
{ISBN/ISSN}: 1008-0864
{Notes}: 11-3900/S
{URL}: https://link.cnki.net/doi/10.13304/j.nykjdb.2022.0951
{DOI}: 10.13304/j.nykjdb.2022.0951
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MobileNetV2-DeepLabv3+的混凝土坝水下裂缝语义分割模型
{Author}: 何旺;钮新强;田金章;朱延涛
{Author Address}: 河海大学水利水电学院;长江设计集团有限公司水资源工程与调度全国重点实验室;国家大坝安全工程技术研究中心;长江勘测规划设计研究有限责任公司;
{Journal}: 水利水电科技进展
{Year}: 2024
{Volume}: 44
{Issue}: 06
{Pages}: 106-112
{Keywords}: 混凝土坝;水下裂缝;MobileNetV2-DeepLabv3+;语义分割;机器视觉
{Abstract}: 为解决深度学习算法难以有效检测混凝土坝水下裂缝的问题，构建了基于MobileNetV2-DeepLabv3+的混凝土坝水下裂缝语义分割模型。该模型引入轻量化网络MobileNetV2,同时将深层特征下采样倍数降为8,以提高小数据集工况下的识别准确率和推理速度；将交叉熵损失函数与Dice损失函数的组合作为模型的损失函数，以缓解类别不平衡问题。工程实例验证结果表明：该模型在测试集上的平均像素准确率和平均交并比分别高达90.87%和86.33%,满足水下裂缝语义分割精度要求；典型工况下的混凝土坝水下裂缝的分割效果优于其他对比模型，泛化能力强；模型具有内存占比小、推理速度快的特点，可用于混凝土坝水下裂缝的检测。
{ISBN/ISSN}: 1006-7647
{Notes}: 32-1439/TV
{URL}: https://link.cnki.net/urlid/32.1439.TV.20240311.1952.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5密集人群检测算法改进
{Author}: 丛笑含
{Tertiary Author}: 李士心
{Publisher}: 天津职业技术师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: YOLOv5;密集人群检测;CARAFE;Soft-NMS;OTA;深度学习
{Abstract}: 随着智慧城市和智能交通系统的快速发展,对密集人群检测的需求显著增加。近几年发生了几起大型人群聚集引发的踩踏事件,这对社会造成了不小的伤害和损失。为了确保公共安全并能够及时处置突发事件,需要在聚集场所进行实时传输画面,对人群聚集数量、密度以及人流方向等多种数据进行采集与分析。密集人群检测技术的研究和发展一直是计算机视觉领域的热点和难点问题之一,其难度在于行人在图像中的表现形式非常多样化、背景复杂、遮挡严重。随着深度学习技术的不断发展和普及,深度学习方法在密集人群检测任务中表现出了优异的性能,成为当前密集人群检测领域主流的技术之一。在本文中,提出了一种新的密集人群检测方法,该方法考虑了行人彼此之间的接近性,并利用上下文信息来提高准确性。本文采用的方法在几个具有挑战性的数据集上具有显著优势,证明了其在现实场景中的有效性。因此本文主要对密集人群的检测技术展开研究,具体工作为:
(1)收集密集人群检测领域的公开数据集,对比分析几个数据集的特点,选择Crowd Human数据集作为本文研究对象。数据集提供了详细的标注信息,包括每个人的边界框坐标、关键点位置和属性标签。Crowd Human专注于复杂场景,其中可能存在遮挡、不同尺度的人体、多样化的姿势和场景。这使得该数据集对于训练鲁棒性强的人体检测模型非常有用。Crowd Human数据集相对较大,包含了大量的图像和相应的标注。数据集通常被划分为训练集、验证集和测试集,以便进行模型的训练、调优和评估。这有助于确保模型在不同数据集上的泛化性能。考虑到Crowd Human数据集没有开放测试集的标注,本文挑选Crowd Human数据集中训练集和验证集3000和500张图片。
(2)针对YOLOv5模型在检测单目标、密集遮挡人群时存在检测精度较低的问题,通过改进检测模型提升检测精度。CARAFE模块通过上采样的特征图以及一个可学习的波形操作,重新组合局部特征信息,以产生更高分辨率、相邻信息的特征图;为了进一步优化标签分配策略,针对每个真实框,只挑选每个FPN层中距离边界框中心最近的r2锚框,对于其他锚框,对应的成本会加上额外常数项,减少训练阶段其被分配为正样本的概率。其次,根据预测框和对应真实框的IOU值动态估计每个真实框合适的正样本数量,降低计算量,加强标签分配策略泛化能力,提高目标识别模型的准确率;最后使用Soft-NMS代替原有的NMS,保留IOU中等,但置信度较高的框,防止漏检,提高网络在检测密集人群时的精度。
经过3个模块的改进后,相比于原始YOLOv5s,m AP0.5上升了6%,m AP0.95上升了8%。定位损失、置信度损失、F1分数、m AP曲线等指标均有随提升。
{URL}: https://link.cnki.net/doi/10.27711/d.cnki.gtjgc.2024.000027
{DOI}: 10.27711/d.cnki.gtjgc.2024.000027
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的齿轮缺陷检测方法研究
{Author}: 王海腾
{Tertiary Author}: 杨耿煌;田楷
{Publisher}: 天津职业技术师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 机器视觉;深度学习;齿轮缺陷检测;YOLOv8s;图像处理
{Abstract}: 由于锻造工艺的原因,新生产的汽车齿轮表面经常会出现缺陷,使用带有缺陷的齿轮极易导致安全事故的发生,因此对新生产的汽车齿轮进行缺陷检测是一道十分重要的工序。本文以汽车齿轮缺陷检测为研究内容,搭建了汽车齿轮缺陷检测系统,使用基于深度学习的目标检测算法对汽车齿轮的端面和齿面进行缺陷检测,通过试验验证方法的有效性和实用性。本文的主要研究工作包括:
1.根据齿轮缺陷检测任务的实际需求,制定详细的工作方案。设计了汽车齿轮缺陷检测系统的整体结构和齿轮缺陷检测流程。完成工业相机、工业镜头和光源的选型,分析并选取合适的光源照明方式,最终搭建齿轮图像硬件采集平台,完成汽车齿轮端面和齿面图像数据的采集工作。
2.对收集到的汽车齿轮图像数据进行筛选,完成齿轮端面和齿面数据集的构建。使用标注工具对齿轮端面和齿面数据集进行缺陷标注,对数据集中各缺陷数量进行统计。研究基于深度学习的YOLOv8s算法的网络结构和YOLOv8s算法提供的图像数据增强技术,选取有效的图像数据增强技术丰富齿轮数据集的多样性,提高算法模型的泛化能力和鲁棒性。
3.针对YOLOv8s算法在汽车齿轮齿面上缺陷检测精度低的问题,对YOLOv8s算法的网络进行改进。在YOLOv8s网络中加入CBAM注意力机制,帮助YOLOv8s算法能够忽视图像中的无关背景区域,仅关注齿轮缺陷区域。在算法中增加小目标检测层,将浅层的特征图与深层的特征图拼接后的结果送入小目标检测层,提升YOLOv8s算法对齿轮小目标缺陷的检测能力。采用基于深度可分离卷积的Mobile Net v3对YOLOv8s网络进行轻量化处理,解决由于增加CBAM注意力机制和小目标检测层导致的计算量增加和检测速度降低的问题。
4.将训练好的齿轮端面和齿轮齿面缺陷检测模型部署在汽车齿轮缺陷检测系统中,完成实际的汽车齿轮缺陷检测任务,并对试验结果进行分析,验证了原始YOLOv8s算法在汽车齿轮端面缺陷检测任务上的实用性和改进的YOLOv8s算法在汽车齿轮齿面缺陷检测任务上的实用性。
{URL}: https://link.cnki.net/doi/10.27711/d.cnki.gtjgc.2024.000119
{DOI}: 10.27711/d.cnki.gtjgc.2024.000119
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 全景影像在城市研究中的应用进展综述
{Author}: 侯鑫;王艳;王绚;范伟
{Author Address}: 天津大学建筑学院;
{Journal}: 计算机科学与探索
{Year}: 2024
{Volume}: 18
{Issue}: 07
{Pages}: 1661-1682
{Keywords}: 全景影像;街景图像;城市研究;人工智能;深度学习
{Abstract}: 全景成像技术的进步，街景图像工具的普及，以及人工智能领域的计算机视觉、机器学习和深度学习技术的快速发展，推动了在城市研究中利用全景影像进行大规模、自动化的判别与解析。上述领域的快速发展促使近20年来全景影像、人工智能和城市研究领域之间涌现了大量交叉成果。借助文献计量工具中常用的CiteSpace和VOSviewer作为分析平台，梳理了全景影像在城市研究中的应用进展。首先利用文献共被引聚类网络与术语时区图，划分了全景影像在城市研究中的三个发展阶段。然后借助合著网络和关键词聚类分析，梳理了各阶段全景影像在城市研究中的合著关系、全景影像的获取方式、图像信息的提取技术，归纳了全景影像在城市研究中的四个主要应用领域：城市建成环境、城市景观环境、城市物理环境和智慧城市。最后在历史分期视域下，剖析了促成全景影像应用领域发展的主要驱动因素，并总结了应用全景影像的城市研究目前存在的挑战和未来的发展趋势。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.tp.20240227.1827.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圣女果采摘机械臂的动作研究
{Author}: 陈肖宇;马兴录;刘扬
{Author Address}: 青岛科技大学信息科学技术学院;
{Journal}: 计算机测量与控制
{Year}: 2024
{Volume}: 32
{Issue}: 02
{Pages}: 181-188
{Keywords}: 圣女果采摘机器人;带蒂采摘;机器视觉;轮廓拟合算法;机械臂特定动作生成
{Abstract}: 针对当前圣女果采摘机器人无法保证带蒂采摘的问题，提出一种通过机器视觉进行圣女果姿态分析进而生成特定的机械臂采摘动作的方法；该方法通过模拟人手采摘流程，能够使得机械臂末端执行器到达采摘位置时与圣女果的果蒂方向保持一致；整体系统包括对成熟圣女果的目标检测、测距算法的实现、圣女果方向识别以及机械臂动作生成；根据轮廓拟合算法的思想进行算法改进，实现针对圣女果的更加精确、稳定的方向识别算法，从而获得机械臂末端执行器与圣女果果蒂方向一致的目标位姿，进而实现相应机械臂采摘动作的生成；多次实验表明，改进后的对于圣女果方向的识别算法相较于传统轮廓拟合算法而言误差角度更小，对于不同姿态圣女果的方向识别更具稳定性，因此更加适用于实际采摘流程中根据圣女果姿态生成机械臂的特定采摘动作。
{ISBN/ISSN}: 1671-4598
{Notes}: 11-4762/TP
{URL}: https://link.cnki.net/doi/10.16526/j.cnki.11-4762/tp.2024.02.027
{DOI}: 10.16526/j.cnki.11-4762/tp.2024.02.027
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一款基于CNN+OpenCV的智能送药小车设计
{Author}: 张秉文;张岳;何西远
{Author Address}: 山东青年政治学院信息工程学院;
{Journal}: 现代信息科技
{Year}: 2024
{Volume}: 8
{Issue}: 04
{Pages}: 175-179
{Keywords}: 机器视觉;智能送药;CNN;Dijkstra算法
{Abstract}: 智慧医疗是我国医疗界备受关注的领域之一，智能送药设备是其中重要组成部分。智能送药设备可以避免人为原因导致药品发送延误，提高工作效率，保证工作质量。在疫情期间，更是可以有效减少医务人员感染的风险。文章设计了一款基于CNN+OpenCV的智能送药设备，以树莓派3B+作为主控芯片，使用五路灰度传感器等硬件模块，采用Dijkstra算法实现最短路径、OpenCV进行图像处理、CNN实现数字识别，模拟了医院病房送药任务。经过多次测试，设备均能高效地完成送药任务。
{ISBN/ISSN}: 2096-4706
{Notes}: 44-1736/TN
{URL}: https://link.cnki.net/doi/10.19850/j.cnki.2096-4706.2024.04.036
{DOI}: 10.19850/j.cnki.2096-4706.2024.04.036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果分级分拣系统关键技术分析
{Author}: 段宇赫;高明昕
{Author Address}: 辽宁科技大学机械学院;辽宁科技大学创新创业学院;
{Journal}: 中国机械
{Year}: 2024
{Volume}: 
{Issue}: 06
{Pages}: 73-76
{Keywords}: 机器视觉;水果分级分拣;关键技术
{Abstract}: 传统的水果检测采用人工检测方式，这种检测方式效率低，误判率比较高，而采用机器视觉的方式对水果进行水果分级分拣，能够有效提高工作效率和降低错误率。基于此，本文在阐述机器视觉技术的基础上，就机器视觉水果分级分拣系统关键技术展开分析，以期为水果分拣技术的发展研究提供一定的参考借鉴。
{ISBN/ISSN}: 1003-0085
{Notes}: 11-5417/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvypDPqVbETcSOXCawQLnCdFWrZpT6aRMVEzaUFR9GFGr8pwJbtDxpN39yZBRteAQDupku8cLHIsj5lZAElipKh0XOfC8f1LW7shzkHVzDgOm0q3LwjJb02aTZb4HPISYnwhlSIULOq9JoaxoCzIIDphbe2FBCvfMHlym3rjZWzm5ThM0PQ2pStQHNpLtlihcjM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的采摘机器人作业优化研究
{Author}: 王新科;李凯
{Author Address}: 郑州职业技术学院;
{Journal}: 农机化研究
{Year}: 2024
{Volume}: 46
{Issue}: 08
{Pages}: 235-239
{Keywords}: 采摘机器人;计算机视觉;视觉控制;识别准确率;采摘成功率
{Abstract}: 为进一步提高我国采摘机器人智能化作业水平及采摘效率，基于计算机视觉应用技术展开优化研究。以采摘机器人结构组成为设计基点，运用视觉控制核心理念建立采摘机器人视觉识别处理与控制数学模型，实施相适应的采摘路径规划和系统采摘状态输出设计。同时，进行视觉采摘验证试验，结果表明：基于计算机视觉的采摘机器人系统优化正确可行，整机综合采摘效率可达94.61%,系统识别准确率与控制精度分别相对提升了6.12%和5.25%,机器人采摘成功率可提升至95.98%。因此，将计算机视觉处理技术有效应用至采摘机器人设计改进，对于类似农业采摘与收获装备开发研究可提供创新及借鉴思路，推广价值良好。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2024.08.015
{DOI}: 10.13427/j.cnki.njyi.2024.08.015
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在农业领域的应用
{Author}: 王宇航;曹洪武
{Author Address}: 塔里木大学信息工程学院;
{Journal}: 现代农业科技
{Year}: 2024
{Volume}: 
{Issue}: 04
{Pages}: 178-181
{Keywords}: 智慧农业;计算机视觉技术;应用
{Abstract}: 随着国家大力发展智慧农业，计算机视觉技术在农业领域的应用越来越广泛，不断推动农业生产向高质量、高产量方向发展。本文从农作物病虫害识别、种子和果实分级检测、农作物生长环境监测和农田土壤特征分析等方面分析了计算机视觉技术在农业领域的应用，并探讨了计算机视觉技术和深度学习在农业领域的相关研究，以期为智慧农业的飞速发展提供参考。
{ISBN/ISSN}: 1007-5739
{Notes}: 34-1278/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzHlsj8YVnLzyFvrJ4R0RkEvRIkJTZJCQDLfaf4JmFEJWRtRNVn_fQE2TjdlL-qNSSaaZ_iSHMusuB-Zb1h51fEFH5ywGPjC53lmIehLG-aXMKWBD0HkcttG26CXAOcIifo2XcMxskcb45f-VfZfr3OZtr7LfV7FLS6YjMXrOeMXu1plT5fiyDRWV3sHQiskSk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的机械臂分拣系统设计
{Author}: 崔亚飞;张松亚
{Author Address}: 永州职业技术学院;
{Journal}: 机电工程技术
{Year}: 2024
{Volume}: 53
{Issue}: 02
{Pages}: 217-220
{Keywords}: 机械臂;计算机视觉;物体检测
{Abstract}: 在不同的产品上市之前，需要对产品进行分拣，确保产品没有任何缺陷，以卖出更好的价格，但手动检查成本高昂，需要花费大量人工费用和时间，因此许多公司倾向于使用现代技术来实施产品检测过程。提出了一种基于机器人与计算机视觉系统关联的方法，使用SolidWorks软件设计了一个具有4个自由度的机械臂，机械臂将罐头放入传送带，然后将其传送到检测室，通过连接到计算机上的相机拍摄产品的图像，并通过LabVIEW程序处理图像，使用MATLAB对模型进行了仿真，并使用Arduino微控制器控制原型执行的过程。当有缺陷的产品通过传送带时，系统会改变路径，将产品从生产线上移除。仿真和实验结果证明，设计的分拣系统能够抓取罐头，然后最终检测出罐头，将有缺陷的罐头带出生产线，已经实现了96%的准确度。在产品分拣过程中使用这项技术，将在短时间内提高生产率和质量。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz0SDLfpQ8ecKWQXPYGJn0wlW5iL0PVO7igySBUyxAEigPylaI0N2woZZfHkEfw2ipSPfRPFYdHGfvLypBvgmOP9XWCf-L_BLgo6O9kWIHUHPcdiRmukDxS2iYNt52k6N8TgjI0oDxs5eFIl7W7pzcITY8KrHKraoP461wbx3H7ITpKwvEo1uyB9DT9yA2W_8M=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像处理与识别在果蔬成熟度监测中的研究及应用
{Author}: 黎施欣;范小平
{Author Address}: 华南农业大学食品学院;
{Journal}: 包装工程
{Year}: 2024
{Volume}: 45
{Issue}: 03
{Pages}: 153-164
{Keywords}: 果蔬成熟度;图像处理;图像识别;计算机视觉检测技术;神经网络
{Abstract}: 目的 分析了果蔬成熟度自动监测对发展智慧农业的重要意义，对图像处理与识别技术在监测果蔬成熟度领域的研究与应用现状进行综述、总结与展望，以期为我国发展果蔬成熟度在线或自动检测识别技术提供参考。方法 对图像处理与识别在监测果蔬成熟度中的原理、优势进行分析，对特征提取、深度学习中的神经网络在该领域中的应用研究进展进行综述。结果 采用以图像处理和识别为核心的计算机视觉检测技术对果蔬的颜色、纹理等外部特征进行成熟度检测具有优势，结合神经网络对果蔬成熟度进行检测的识别率高，可在采摘、运输等场景对果蔬成熟度进行监测。结论 图像处理与识别技术在果蔬成熟度监测领域有望得到突破，将催生更多新的应用场景。
{ISBN/ISSN}: 1001-3563
{Notes}: 50-1094/TB
{URL}: https://link.cnki.net/doi/10.19554/j.cnki.1001-3563.2024.03.018
{DOI}: 10.19554/j.cnki.1001-3563.2024.03.018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于轻量化YOLOv8的安全帽检测
{Author}: 张碧川;刘卫东;米浩;景亚宁
{Author Address}: 山西师范大学物理与信息工程学院;
{Journal}: 电脑与电信
{Year}: 2024
{Volume}: 
{Issue}: Z1
{Pages}: 35-39
{Keywords}: 轻量化;YOLOv8算法;python;目标检测;图像分割;计算机视觉
{Abstract}: 安全帽检测是一项具有重要应用价值的计算机视觉任务，涉及建筑工地、矿山、电力等多个领域的安全管理。然而，安全帽检测也面临着诸多挑战，如目标尺寸和长宽比的巨大变化、目标速度的快速变化、目标遮挡和背景干扰等。为了解决这些问题，提出了一种基于轻量化YOLOv8算法的安全帽检测方法，利用YOLOv8的高速和高精度特点，结合安全帽的特征，实现了对安全帽的有效检测。
{ISBN/ISSN}: 1008-6609
{Notes}: 44-1606/TN
{URL}: https://link.cnki.net/doi/10.15966/j.cnki.dnydx.2024.z1.017
{DOI}: 10.15966/j.cnki.dnydx.2024.z1.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的金属表面缺陷检测
{Author}: 李涛;刘俊江;张聪;朱磊
{Author Address}: 齐齐哈尔大学通信与电子工程学院;
{Journal}: 高师理科学刊
{Year}: 2024
{Volume}: 44
{Issue}: 01
{Pages}: 36-42
{Keywords}: 金属表面缺陷;空间金字塔池化;机器视觉;目标检测
{Abstract}: 由于金属产品生产过程中各种因素的影响，金属工件可能会存在一些表面缺陷．这会降低材料强度，缩短工件寿命，并且增加安全风险．因此，需要对金属产品表面进行质量检测，这也是保证工业生产质量的关键环节．与传统人工检测相比，基于机器视觉的表面缺陷检测方法具有速度快、精度高等优点．提出了一种改进的YOLOv5算法，用于金属表面缺陷检测研究，在原YOLOv5算法的基础上将空间金字塔池化结构SPP替换成SPPCSPC，提高模型对金属表面缺陷的检测能力．为了验证算法的有效性，分别采用YOLOv3,YOLOv4,YOLOv5及改进的YOLOv5算法对1 800张金属表面缺陷样本图像进行对比测试．结果表明，与YOLOv3,YOLOv4,YOLOv5原算法相比，改进的YOLOv5算法平均目标检测精度均值分别提高了4.3%,3.3%,2%．通过大量图片的学习，可以获得更好的精确率．
{ISBN/ISSN}: 1007-9831
{Notes}: 23-1418/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxyOwrTAElQtQrVcu0CfcVR6gJy5J_6WS5jXm2gxvWv_aMYQt8wiL4gpN8-oSZQFL4hjnJo17fIGNTUAzYGLgAfULbyuc4gLVkarq__CCNPNNzpg3ZRZo_196m5-eQrSYsAYxPMGAU9x06Je-F1KqAF_vkAwhxcyLRhN4UyGzIngZ1RXa_JdDZu4A5Qb8c0aFc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的视线估计方法综述
{Author}: 温铭淇;任路乾;陈镇钦;杨卓;战荫伟
{Author Address}: 广东工业大学计算机学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 12
{Pages}: 18-33
{Keywords}: 计算机视觉;深度学习;视线估计;眼动跟踪;人机交互
{Abstract}: 视线估计是一种预测人眼注视位置或注视方向的技术，在人机交互和计算机视觉的应用中发挥重要作用。近几年，深度学习的飞速发展改变了许多计算机视觉任务，利用深度学习进行基于外观的视线估计已成为关注热点。围绕深度学习模型的训练流程，从视线数据预处理、视线特征提取、视线学习策略、视线估计模型结构四个方面对近年基于深度学习的视线估计方法进行了综述和分析；然后介绍视线估计领域主流公开数据集，并对常用数据集分别进行2D和3D视线估计方法的对比分析。最后，探讨了当前视线估计领域的研究难点与挑战，并对未来的发展趋势进行总结与展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20240129.0942.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在桥隧工程中的应用现状及展望
{Author}: 杨兴宇;陈光耀;朱俊潼;徐照
{Author Address}: 东南大学土木工程学院;东南大学软件学院;
{Journal}: 工业建筑
{Year}: 2024
{Volume}: 54
{Issue}: 09
{Pages}: 209-218
{Keywords}: 计算机视觉;桥隧工程;工程管理;信息技术;施工技术
{Abstract}: 桥隧工程是土建领域的重要分支，随着建筑数字化程度的提高和设备硬件的升级，计算机视觉已经成为桥隧工程中数字化发展的关键支撑技术。为系统全面地揭示计算机视觉在桥隧工程领域的研究热点和趋势，聚焦于计算机视觉在桥隧工程领域的应用，利用知识图谱工具对相关文献进行可视化分析，并分别从图像处理与特征提取、目标检测与跟踪、目标分类与识别、三维重建与SLAM和智能分析与决策五个计算机视觉任务对其理论与应用技术进行系统性的总结归纳。在此基础上，还从数据集缺陷性、图像准确性、检测实时性、算法适用性四个方面出发，总结了目前研究难点，指出和探讨了应用难点解决方案，并对未来发展进行展望，为进一步研究与技术应用提供理论支撑。
{ISBN/ISSN}: 1000-8993
{Notes}: 11-2068/TU
{URL}: https://link.cnki.net/urlid/11.2068.TU.20240122.1447.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算视觉传播研究：理论体系、范式转型与学术想象力
{Author}: 于德山
{Author Address}: 南京师范大学新闻与传播学院;
{Journal}: 传媒观察
{Year}: 2024
{Volume}: 
{Issue}: 01
{Pages}: 39-46
{Keywords}: 计算视觉传播;范式转型;学术想象力
{Abstract}: 计算视觉传播使用计算机视觉方法，在方法体系、问题视域与解题标准方面带来研究范式的转型，为传统的视觉传播（视觉文化传播）研究注入了新的活力和新的学术想象力。同时，在计算视觉传播研究的实践中，我们还应该注意将这一研究范式与视觉传播（视觉文化传播）研究范式结合起来，注意西方研究相关工具与数据库的适用性，警惕其中可能蕴含的政治、国家和种族等方面的视觉算法偏见。在此背景中，增强计算视觉传播研究基于像素的图像与社会文化的阐释能力，发挥这一研究的人文关怀作用，从中国传统视觉精神、视觉（文化）传播实践与视觉经验出发，分析与预测中国视觉传播（视觉文化传播）的热点、难点与发展趋势，突出中国问题域的独特性，彰显其紧迫性与现实性。提炼出具有中国特色的计算视觉传播（视觉文化传播）研究范式，这是计算视觉传播研究理论本土化建构的意义所在。
{ISBN/ISSN}: 1672-3406
{Notes}: 32-1712/G2
{URL}: https://link.cnki.net/doi/10.19480/j.cnki.cmgc.2024.01.002
{DOI}: 10.19480/j.cnki.cmgc.2024.01.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的电力巡检机器人自动化系统设计
{Author}: 黄松涛
{Author Address}: 国网内蒙古东部电力有限公司通辽供电公司;
{Journal}: 自动化技术与应用
{Year}: 2024
{Volume}: 43
{Issue}: 01
{Pages}: 35-38+43
{Keywords}: 机器视觉;转向电机;电力巡检机器人;自动化系统;CCD摄像机
{Abstract}: 为实现巡检中更低的误检率，设计一种基于机器视觉的电力巡检机器人自动化系统。利用远距离激光雷达配合多种设备，实现机器人的定位导航。根据图像预处理模块能够实现巡检图像的色彩分割、降噪滤波等处理。总控平台模块主要由六部分构成，分别为图像识别单元、核心服务单元等。通过硬件与软件相结合实现机器人的电力巡检功能。实验结果表明，设计的机器人运动指标良好，能够实现高效变电站巡检，同时系统的巡检导航性能良好，巡检误检率较低，说明系统满足设计需求。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2024)01-0035-05
{DOI}: 10.20033/j.1003-7241.(2024)01-0035-05
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 汽车智能驾舱驾驶疲劳检测系统设计
{Author}: 柏俊波;周涛琪;柏俊杰
{Author Address}: 上海易咖智车科技有限公司;重庆科技学院电气工程学院;
{Journal}: 现代电子技术
{Year}: 2024
{Volume}: 47
{Issue}: 01
{Pages}: 147-152
{Keywords}: 疲劳驾驶检测;人脸识别;机器视觉;眨眼率;帧差法;FPGA
{Abstract}: 疲劳驾驶是影响交通安全的主要因素，当前疲劳驾驶的检测方法普遍存在设备体积大、侵入性强、实时性差等弊端。文中设计的基于FPGA的疲劳驾驶检测系统，首先利用区域长宽比改进YCbCr人脸分割算法，提高算法在驾驶环境中对于人脸的辨识度；然后建立动态视频人眼跟踪模型，在人脸范围内定位人眼位置，采用三帧差算法检测眨眼动作，以眨眼率作为疲劳的评价指标，对司机状态进行实时监控；最后利用FPGA芯片完成实时图像数据的处理和疲劳驾驶检测。实验证明，该系统具备在光线昏暗和佩戴眼镜等场景下检测疲劳状态的能力，并且检测系统充分发挥FPGA芯片数据并行处理优势，具备体积小、速度快、集成度高，通电即可工作的特点，有利于在狭小的驾驶舱环境部署，具有一定的工程应用价值。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2024.01.026
{DOI}: 10.16652/j.issn.1004-373x.2024.01.026
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 目标检测算法
{Author}: 王国超;柴琳;金立左
{Author Address}: 东南大学软件学院;东南大学自动化学院;
{Journal}: 工业控制计算机
{Year}: 2023
{Volume}: 36
{Issue}: 12
{Pages}: 10-11+14
{Keywords}: 目标检测;计算机视觉;深度卷积神经网络
{Abstract}: 目标检测是计算机视觉任务的一个重要组成部分，也是人工智能的一个重要应用，其目的是在自然图像中的大量预定义类别中定位对象实例。同时目标识别也有着广泛的应用场景，可以应用到自动驾驶技术中以及各种侦察车上。系统性介绍了主要的目标识别方法，之后主要介绍两种基于深度卷积神经网络的目标识别方法，并分别说明了它们的应用场景，同时通过具体的实验数据对比了骨干网络的优缺点。与传统的基于特征的目标检测方法相比，基于深度学习的目标检测方法可以同时学习图像的低级特征和高级特征。最后展望了目标检测方法的发展前景。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxM0_7Dvm_AxnwNWMSiCTbFPIVR7G1m1Bob5arkHAxUuHe4x7oaCg2OXAbes2S0R6VopPhZ8x0dQeM1GQy1Vg0-43V7aqESjYHDQJ3dKM4Du1wqgPbnzDySbg7_lzCcxccg5CeOJ99rWSf68LkfiE2mZKQWiXcd3Y7ngejdYgxfljinRifbPzg3ufTaiL8_VhE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于计算机视觉的三维稠密重建方法研究综述
{Tertiary Title}: 2023届中国系统仿真与虚拟现实技术高层论坛论文集
{Author}: 崔浩浩;邸彦强;孟宪国
{Author Address}: 陆军工程大学石家庄校区;
{Secondary Title}: 2023届中国系统仿真与虚拟现实技术高层论坛
{Place Published}: 中国北京
{Subsidiary Author}: 北京理工大学、哈尔滨工程大学、北京工商大学、中国自动化学会专家咨询工作委员会、中国仪器仪表学会数字城市测控技术分会、中国自动化产业链创新联合体、中国计算机系统仿真应用组织委员会
{Year}: 2023
{Pages}: 7
{Keywords}: 三维稠密重建;计算机视觉;深度学习
{Abstract}: 三维稠密重建是计算机视觉领域的重要研究方向之一,具有重要的研究价值。传统三维稠密重建算法已经在诸多领域得到应用,但在完整性、鲁棒性等方面仍存在一定的问题。随着深度学习技术的发展,其在三维重建方面的研究正得到广泛的关注。本文对传统的与基于深度学习的重建方法展开了具体介绍,其中,基于深度学习的重建方法主要介绍了以MVSNet、神经辐射场Ne RF为代表的两大类方法。最后对基于视觉的三维重建方法进行了总结,并列举了未来可能的发展趋势。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.073611
{DOI}: 10.26914/c.cnkihy.2023.073611
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习算法的图像处理技术
{Author}: 吕园园
{Author Address}: 苏州高博软件职业技术学院;
{Journal}: 长江信息通信
{Year}: 2023
{Volume}: 36
{Issue}: 12
{Pages}: 71-73
{Keywords}: 计算机;视觉算法;图像处理
{Abstract}: 随着深度学习的快速发展，利用深度学习方法对图像进行识别和检测，已经成为主流方法之一。文章对以计算机视觉算法为基础的图像处理技术进行了简单的描述，并建立了一个图像处理的架构，同时对机器视觉系统的真实感进行了探讨，介绍了以ARM微处理器为核心，采用快速投影机投射和横向传递技术，实现了3D图像的三维重建，并在此基础上，提出基于CNN的深度学习算法。实验结果显示，文章所提出的方法具有结构简单、成本低廉、无视觉干扰、人性化、人机互动等优点。
{ISBN/ISSN}: 2096-9759
{Notes}: 42-1914/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyAiVQF5AF_EZvK1XKAwfwbezcjtNxzI1cYnL7tYSZY6hxCGTSTy3ivGsSZJdsgMZZDKbZPGymKV9t2Km4Ujz8g8pWM4CtgXZNw9p9_By9ZVDJ0xfwgG2erWXs9S6X-lvzc_c2ppW12LRSNTzlPQbsb7FVKu-7QE2wLJjYDupfpVTRA8V86jWWTGZrpUYYaI9g=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 现代农业领域中计算机视觉技术的运用与发展
{Author}: 秦昌友;杨艳山;顾峰玮;陈盼阳;秦维彩
{Author Address}: 苏州农业职业技术学院;农业农村部南京农业机械化研究所;南京工程学院;
{Journal}: 中国农机化学报
{Year}: 2023
{Volume}: 44
{Issue}: 12
{Pages}: 119-128
{Keywords}: 计算机视觉;图像处理;现代农业;自动化
{Abstract}: 计算机视觉是一个涉及使机器“看到”的领域。该技术使用相机和计算机代替人眼来识别，跟踪和测量目标以进行进一步的图像处理。随着计算机视觉的发展，这种技术在现代农业领域得到广泛的应用，并在其发展中发挥关键作用。首先，详细阐述计算机视觉的概念、组成部分和工作原理。其次，介绍国内外计算机视觉技术在水产养殖、畜牧养殖、农作物生长监测、农作物病虫害监视、果蔬识别定位与采摘等领域的研究进展与应用情况。通过分析发现，现有技术可以促进现代农业自动化发展，实现低成本、高效率、高精度的优势。然而，未来技术将继续向现代农业新的应用领域拓展，需要克服的技术问题会更多。最后，系统总结和分析计算机视觉技术在现代农业的应用与挑战，探讨未来的机遇和前景，为研究者提供最新的参考。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2023.12.019
{DOI}: 10.13733/j.jcam.issn.2095-5553.2023.12.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的异形零件尺寸精密测量方法
{Author}: 林辉;刘栩宇
{Author Address}: 韶关学院智能工程学院;
{Journal}: 机电工程技术
{Year}: 2024
{Volume}: 53
{Issue}: 08
{Pages}: 183-185+214
{Keywords}: 机器视觉;视觉测量;异形零件;Halcon
{Abstract}: 针对目前异形零件尺寸测量中存在的精度低、成本高、难以实现在线测量等问题，提出一种基于Halcon的异形零件尺寸精密测量方案，包括硬件和软件算法两部分。硬件部分主要对工业相机、工业镜头和光源进行选型，并设计了测量装置。软件算法部分，首先利用Halcon对相机进行标定获得其内外参数，然后通过灰度处理、阈值分割等算子得到零件区域，接着通过区域特征筛选、最小二乘算法拟合区域最大内接圆和最小外接圆、计算两线段距离、计算两直线夹角、计算区域个数等方法实现对异形零件的齿高、外槽宽度、外槽角度、圆孔角度、外槽深度、齿数等参数的测量。最后，与高精度三坐标测量机的测量结果对比，结果表明采用本方法测量异形零件的齿高、外槽宽度和外槽深度的精度达到0.04 mm，测量外槽角度和圆孔角度的精度达到0.03°。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://link.cnki.net/urlid/44.1522.TH.20231214.1101.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于多尺度融合注意力机制的群猪检测方法
{Author}: 林华浦;张凯;李浩;刘昱菲;陈子霖;马钦
{Author Address}: 中国农业大学信息与电气工程学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 21
{Pages}: 188-195
{Keywords}: 图像识别;机器视觉;注意力机制;多目标跟踪;YOLOv7;小目标检测;猪只计数
{Abstract}: 群猪检测是现代化猪场智慧管理的关键环节。针对群猪计数过程中,小目标或被遮挡的猪只个体易漏检的问题,该研究提出了基于多尺度融合注意力机制的群猪检测方法。首先基于YOLOv7模型构建了群猪目标检测网络YOLOpig,该网络设计了融合注意力机制的小目标尺度检测网络结构,并基于残差思想优化了最大池化卷积模块,实现了对被遮挡与小目标猪只个体的准确检测;其次结合GradCAM算法进行猪只检测信息的特征可视化,验证群猪检测试验特征提取的有效性。最后使用目标跟踪算法StrongSORT实现猪只个体的准确跟踪,为猪只的检测任务提供身份信息。研究以育肥阶段的长白猪为测试对象,基于不同视角采集的视频数据集进行测试,验证了YOLOpig网络结合StongSORT算法的准确性和实时性。试验结果表明,该研究提出的YOLOpig模型精确率、召回率及平均精度分别为90.4%、85.5%和92.4%,相较于基础YOLOv7模型平均精度提高了5.1个百分点,检测速度提升7.14%,比YOLOv5、YOLOv7tiny和YOLOv8n 3种模型的平均精度分别提高了12.1、16.8和5.7个百分点,该文模型可以实现群猪的有效检测,满足养殖场管理需要。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20231213.1319.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业割草机器人全区域覆盖路径规划研究——基于计算机视觉技术
{Author}: 吴蓓;李霞;李进
{Author Address}: 武汉工程科技学院;武汉纺织大学传媒学院;
{Journal}: 农机化研究
{Year}: 2024
{Volume}: 46
{Issue}: 06
{Pages}: 68-72
{Keywords}: 割草机器人;路径规划;CCD*;纹理特征;计算机视觉
{Abstract}: 首先，采用运动控制、能源、传感器、核心处理器和割草等5个模块设计了农业割草机器人试验平台；然后，利用纹理特征对障碍物图像分割算法进行分析研究；最后，基于CCD*实现了割草机器人的全区域覆盖作业。实验结果表明：使用研究的CCD*算法大大提高了割草机器人全区域覆盖作业的能力和作业效率。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2024.06.003
{DOI}: 10.13427/j.cnki.njyi.2024.06.003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义分割的道路识别与视觉定位融合算法研究
{Author}: 施卓炜
{Tertiary Author}: 甘兴利
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 视觉定位;位姿估计;语义分割;深度学习;神经网络架构搜索;注意力机制;知识蒸馏
{Abstract}: 视觉定位和语义分割一直以来都是计算机视觉领域中两项重要的感知计算任务,但在近年来视觉定位和语义分割的结合任务仍然存在着许多挑战。其中一个挑战便是如何处理视觉定位和语义分割之间的不一致性。视觉定位通常依赖于低级的几何图像信息,而语义分割则更关注于高级语义信息。而将这两个任务结合起来便需要解决它们之间信息差异与互通问题,从而实现融合系统的一致性和准确性。另一个挑战是如何实现实时性和高计算效率。视觉定位和语义分割往往都需要对大规模图像数据进行处理,这可能导致计算复杂度和计算资源的增加。因此,在结合视觉定位和语义分割时,需要考虑如何设计高效的算法和优化策略以满足应用场景的实时性需求。
而在传统的实时语义分割应用中,往往会因为追求模型推断速度而牺牲一些重要的低级细节信息和高级语义特征,这便会导致极少有轻量化的分割算法能够在延迟和精度之间取得绝佳的平衡点,而本文提出的解决方案便是通过注意力与多尺度改进蒸馏网络结构,使得语义分割网络能够在低延迟环境下实现高效的像素分割。该方法首先通过神经架构搜索和自适应注意力机制集成多分辨率分支搜索架构生成分支,然后利用师生蒸馏网络训练出具备低延迟和高精度的轻量级网络模型。
而在融合系统的数据传输方面则是使用RGB提取法,将分割出来的目标图层进行位置计算与归类,得到比目标检测更为具体的目标位置信息,并通过该联合算法使定位系统在小目标以及复杂路况下也能实施定位,并将其核心位置点返回为目标点的像素坐标,再通过定位中的维度转化代码得到位置的真实坐标和对应的仿真雷达地图中的像素点。该实时轻量级语义分割模型可以与定位系统以及车辆循迹模块一同完成实时车辆的目标定位任务,并且保证帧率与数据的同步。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000133
{DOI}: 10.27840/d.cnki.gzjkj.2024.000133
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的二维图像质量缺陷检测研究进展
{Author}: 张德海;祝志逢;李艳芹;黄子帆;马选雄;许宸语;刘祥
{Author Address}: 郑州轻工业大学机电工程学院;中标防伪印务有限公司;
{Journal}: 包装工程
{Year}: 2023
{Volume}: 44
{Issue}: 23
{Pages}: 198-207
{Keywords}: 机器视觉;印刷质量;缺陷检测;图像处理
{Abstract}: 目的 机器视觉图像处理技术是近年在图像处理领域发展起来的一门新兴边缘交叉学科，二维图像的质量检测是印刷行业中必不可少的环节，分析基于机器视觉的二维图像质量缺陷检测流程，探索影响基于机器视觉的二维图像质量缺陷检测精度的相关因素，为后续研究印刷品的二维图像自动化检测和质量控制提供参考。方法 在此基础上，围绕图像预处理中的灰度转换、噪声过滤、固定阈值分割、自适应阈值分割、Otsu法及边缘检测，对图像配准中的基于灰度统计信息分布配准方法、基于特征的图像配准方法进行总结，然后归纳分析图像的缺陷提取和分类。结论 以实际例子对上述研究内容进行了提炼，通过图像预处理中的噪声过滤为后续缺陷提取提供清晰图像，减少伪影干扰；通过图像预处理中的灰度变换、阈值分割、感兴趣区域提取减少系统处理时间，为实现高效的缺陷检测奠定了坚实的基础；通过图像配准消除了机械振动引起的图像位置偏移，确保后续缺陷提取的准确性；通过图像缺陷提取和分类帮助印刷企业找出生产问题，提供有针对性的改进措施，可为生产高质量产品提供支持。
{ISBN/ISSN}: 1001-3563
{Notes}: 50-1094/TB
{URL}: https://link.cnki.net/doi/10.19554/j.cnki.1001-3563.2023.23.024
{DOI}: 10.19554/j.cnki.1001-3563.2023.23.024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于统计机器学习的复杂场景多模态语义分割算法研究
{Author}: 张涵
{Tertiary Author}: 周武杰
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 计算机视觉;深度学习;语义分割;多模态;知识蒸馏;对比学习
{Abstract}: 近年来随着大数据、人工智能、云计算等新一代科学技术的应用,我国数字经济的发展规模正逐年扩大。具《中国数字经济发展研究报告》统计,2022年我国数字经济规模首次突破50亿大关,数字经济已经占我国GDP总规模的41.5%。可见大力发展以大数据、人工智能等为代表的新技术已经成为保证我国社会经济高质量发展的重要因素。计算机视觉技术已经在自动驾驶、人脸识别、智能监控等领域发挥着重要作用。本文我们主要研究在复杂场景下的多模态语义分割问题,旨在通过彩色图片(RGB)、热力图像(Thermal)和深度图像(Depth)在监督机制的作用下探究出语义分割问题更好的解决方案。希望我们的研究能够助力计算机视觉领域的发展,为我国经济高质量发展做出贡献。我们的研究主要包含以下四个部分:
(1)在研究的第一部分,我们以城市街道场景为研究背景,利用了RGB和Thermal两种信息作为输入提出了一种模态记忆共享和形态互补网络。与以往的解决方案往往会忽视不同样本之间的联系不同,我们在编码器部分构建了一个模态记忆共享模块促进了跨模态多尺度样本信息的阶段学习和记忆共享。除此之外我们在解码阶段构建了解码联合单元,它可以根据信息类别提取两种不同的形态特征,实现多尺度跨模态融合信息的互补利用。
(2)在第二部分,考虑到镜子类物体反应出来的是周围环境的特征,这对计算机视觉的发展造成了巨大的困扰。因此从这一部分开始,我们针对镜子这种具有视觉迷惑性的物体进行分割研究。这里我们利用RGB和Depth信息构建了一个分层辅助融合网络,该网络在编码阶段拥有一个分层引导融合结构促进跨模态信息的有效利用,在解码阶段首先增强了编码部分的融合特征,随后通过跨层交叉融合实现跨层信息的阶段融合和噪声过滤。
(3)在第三部分,我们发现Depth图像虽然能够促进镜子分割任务性能的提升,但是Depth图像存在大量的噪音点,为此我们首先通过形态学算法闭操作从输入端提升深度图像的质量,然后我们还提出了一个近邻匹配与模态自适应算法,该算法在编码阶段对跨尺度跨模态特征进行自适应融合,促进需求模态信息的互补。除此之外,在前两部分我们还发现虽然模型的性能有了质的提升但是这往往需要模型拥有较高的参数量和模型复杂度,这往往是阻碍许多算法离线部署的重要因素。为了解决以上问题,我们针对所提出的算法设计了一个专门的知识蒸馏方案。该方案以样本信息的复杂度评判结果为指引,促进教师和学生模型间知识的渐进式转移。达到了模型性能和复杂度之间的平衡,促进了模型性能的提升。
(4)在最后一部分,我们发现差异模态在不同阶段之间的差异程度有很大区别,为此我们设计了一个分阶段融合差异模态的算法,该算法考虑到了编码部分不同阶段跨模态特征之间的差异性,促进了差异模态特征更好的利用。除此之外,我们发现我们之前的工作都是在追求所提出模型的预测分布和目标预测分布的重合度尽可能接近。但是我们却忽略了预测目标的类内和类间分布关系。为此我们把对比学习融入了知识蒸馏框架,促进了目标物体类内特征的聚合和类间特征的远离。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000187
{DOI}: 10.27840/d.cnki.gzjkj.2024.000187
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的尺寸测量研究进展
{Author}: 曹广如;黄石甫
{Author Address}: 株洲时代新材料科技股份有限公司;
{Journal}: 轨道交通材料
{Year}: 2023
{Volume}: 2
{Issue}: 06
{Pages}: 29-33
{Keywords}: 机器视觉;图像处理;尺寸测量;智能制造
{Abstract}: 基于机器视觉的尺寸测量是近年来在计算机视觉领域中备受关注的一个研究方向。随着人工智能和图像处理技术的快速发展，利用机器视觉进行精确尺寸测量的方法因其准确、高效、非接触的特性，被广泛应用于智能制造、质量控制和自动化系统等领域。常用的机器视觉尺寸测量方法，包括特征提取、边缘检测、模板匹配和三维重建等技术，通过建立相机与被测物的相对坐标，计算转换得到测量数据。同时，基于机器学习和深度学习的尺寸测量方法，通过建立高效准确的尺寸预测模型，实现更灵活准确测量。机器视觉测量从利用设备获取数据的方式的不同，可分为被动测量与主动测量，文章将针对上述方法在两种方式上的应用，对基于机器视觉的尺寸测量技术进行综述，总结了机器视觉测量存在的问题，并对其发展趋势进行了展望。
{ISBN/ISSN}: 2097-1923
{Notes}: 32-1905/U
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwTwzT0P2UKkwdNYmhXtTSbBD9If8qZAvYsN5vJMZuJjR2c2YkDUbRDHUTsu7iTCfHp0SK3psN0GlJO_XWdMVrt7iN43dSpXK7trverYBpSEi7WzoNLg7DptzrmkG3F6Xgy-pwUd8BW_9sX93q51jCnTIhveN_MHsPy_SniWdjiRcqcOpLEGU3C_xs8-AiUedc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轮胎外观缺陷检测系统研究
{Author}: 闫栋梁
{Tertiary Author}: 何为凯;许芝光
{Publisher}: 山东交通学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 轮胎缺陷检测;机器视觉;轮胎三维建模;YOLOv7
{Abstract}: 轮胎作为汽车的重要组成部分,其质量和安全性对行驶安全和车辆性能至关重要。因此,汽车轮胎制造过程中的质量检测尤为重要。传统的轮胎外观缺陷检测方法通常依赖于人工目视检查,这种方法不仅效率低下、检测质量不稳定而且人工成本高。现代制造业普遍朝着自动化和智能化方向发展,但是由于轮胎的特殊性导致数据采集复杂、外观缺陷多样性等问题,轮胎外观缺陷的智能检测并未得到深入发展。针对当前轮胎检测行业中存在的难题,本文主要做了以下工作:
(1)针对轮胎外观图像采集的方式,设计了轮胎外观数据采集平台,该平台包括采集设备、机械臂、轮胎夹持装置、旋转抱紧装置以及底座与传送带等部分。采集设备利用机器视觉设备,包括激光轮廓仪、结构光相机等多种采集装置对轮胎不同部位的外观信息进行采集,获取精准完整的轮胎信息,为后续模型训练提供高质量的图像数据;
(2)基于数据采集平台中结构光相机采集到的点云数据进行轮胎三维建模,实现可见光图像与3D点云之间的多源异构数据转化融合,实现轮胎3D图像建模与显示。构建每种轮胎型号的3D模型,导入MES系统,以进行该型号轮胎外观缺陷智能检测。
(3)基于多传感器信息融合方法构建的轮胎3D图像模型和YOLOv7算法模型,搭建轮胎外观缺陷检测神经网络训练模型。针对传统YOLOv7中转置卷积复杂度和参数量大的问题,引入了能够生成自适应卷积核的CARAFE上采样算子,更好地保留空间信息和上下文信息,提高了采样精度。为保证使网络更加关注与训练任务有关的信息,通过对比实验比较其他注意力模块,最终选择对改进后的算法模型中添加无参数的Sim AM注意力模块,使模型的准确度得到进一步提升。
通过上述研究工作,实现了轮胎外观缺陷的准确识别,并通过实验验证理论方法的有效性和可行性,在实际测试中取得了较高了的识别率。
{URL}: https://link.cnki.net/doi/10.27864/d.cnki.gsjtd.2023.000185
{DOI}: 10.27864/d.cnki.gsjtd.2023.000185
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进MobileNet算法的城市道路场景实例分割研究与应用
{Author}: 邢嘉舒
{Tertiary Author}: 徐硕博;陈新
{Publisher}: 山东交通学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;图像实例分割;城市道路场景;轻量级模型
{Abstract}: 实例分割是计算机视觉中一项任务,需要预测对象实例并生成各像素分割掩码,在自动驾驶,医学影像分析,视频监控,虚拟现实等方面具有广泛的应用前景。本研究旨在解决城市道路中实时实例分割的关键问题,以提高交通安全性和智能交通系统的效率。通过深入分析城市道路的复杂性和多样性,引入了先进的实时实例分割算法,旨在实现对城市道路中的车辆、行人、自行车等目标的准确识别和分割。目前,实例分割算法专注于提升算法的分割精度,但忽略了快速识别分割的要求。虽然有一部分算法能够及时分割,但却无法保证准确率。另外,一些分割精度较高的算法通常具有庞大的网络结构和复杂的数据处理过程,导致边缘设备无法实现实例分割技术。为解决这些问题,本文选用了YOLOv8算法作为基础模型,优化轻量化网络MobileNet＿v3优化其网络结构,并根据先进的边界框损失函数优化其训练方式,旨在在有限的计算设备资源条件下,设计一种能够实现实时实例分割目标的模型。本文的主要的研究内容如下:
(1)提出一种基于YOLOv8和改进的MobileNet实例分割网络。针对当前实例分割算法检测速度较慢,达不到城市道路所要求的实时性等问题,本文选择了YOLOv8算法作为基准网络。首先,通过借鉴C2f中融合不同梯度流特征信息的操作,对MobileNet＿v3进行改进并设计了Mb＿2f模块,以优化YOLOv8-m分割网络。新设计的模块在提高分割精度的同时,降低了GFLOPs和参数量,确保了实时性要求的满足。为了更好的处理图像中的局部和全局的信息,使得网络在处理不同尺寸的目标时更具有鲁棒性,对主干网络和颈部网络之间的SPPF模块进行了升级,命名为SPPF+。SPPF+模块在提取和融合不同尺寸特征信息方面更为精细,进一步提升了模型的分割精度。
(2)对实例分割网络训练与推理优化进行改进。在城市道路场景中,针对低质量边界框对模型训练的不良影响,尤其在存在复杂背景、目标遮挡或尺寸差异较大的情况下,对YOLOv8-m中的边界框损失进行了改进,由CIoU优化为Focal-CIo U,提高了模型的检测效果。鉴于城市道路场景中边缘设备计算资源受限的情况,本文进一步对模型进行轻量化。通过优化批量归一化通道剪枝流程和引入TensorRT量化技术,成功实现了在边缘设备上部署并进行快速推理的目标。这一系列改进使得模型在计算资源有限的环境中仍然能够高效运行。
(3)设计了一个城市道路场景的实例分割系统。用户能够通过该系统轻松而准确地识别和分割城市道路场景中的各种对象。该系统使用改进后的实例分割网络,通过分析图像中的像素级信息,能够将道路、车辆、行人等不同类别的物体精确地分割出来。用户可以通过简单直观的界面与系统进行交互,可以上传城市道路场景的图像或视频,也可以直接调用摄像头,并实时获得系统对图像中物体的分割结果。
{URL}: https://link.cnki.net/doi/10.27864/d.cnki.gsjtd.2023.000190
{DOI}: 10.27864/d.cnki.gsjtd.2023.000190
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的混凝土桥塔内表面病害智能识别方法研究
{Author}: 陈波
{Tertiary Author}: 张华
{Publisher}: 西南科技大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 卷积神经网络;有监督学习;知识挖掘;数据驱动;混凝土病害
{Abstract}: 桥塔作为斜拉索型桥梁承压的主要构件,其安全稳定是保证整个桥梁工程正常使用的重要核心。然而随着整体桥梁工程服役时间逐步累积以及大量内外部因素共同影响,在桥塔内表面极易形成多种病害特征。若不及时对这些病害特征进行处理将导致桥塔的耐久性和防渗性急剧下降,甚至对整个桥梁工程产生不可逆的损伤。因此对桥塔内部病害进行周期性巡检、精准鲁棒的识别和及时的维护修补是保证整个桥梁工程长期安全稳定运行的重要措施。由于桥塔内部环境复杂、风险系数高,缺乏多病害类别、多样本数量和高成像质量的图像数据对各病害类型进行分析,同时常规的识别方法无法满足桥塔内部多类病害精准识别及量化的需求。围绕以上难题及需求,本文以大跨径斜拉索桥梁桥塔内表面多类病害为研究对象,以计算机视觉技术为载体,在病害图像预处理优化、多类别病害识别、裂缝语义分割、分割结果后处理等关键技术上开展深入研究,构建了大跨径斜拉索桥梁桥塔内表面病害诊断系统。具体研究工作如下:1)针对当前大跨径斜拉索桥梁桥塔内表面病害识别方法研究中缺乏相关典型图像数据的问题,本文采用搭载了高清工业相机等传感器的重叠旋转多节伸缩式机械臂病害采集系统对桥塔内部各区域进行全覆盖式病害图像采集。围绕采集的原始有效病害数据量较少、图像分辨率较高、图像亮度不足、存在各类噪声干扰等问题,本文分析了桥塔各类别病害形成机理和演变规律,并开展了基于图像增强和图像增广的预处理技术研究,实现了降低图像分辨率、提高病害区域对比度、缓解噪声干扰等功能,结合基于源域迁移的图像快速分类技术实现了对裂缝图像、气孔图像、剥落图像和锈蚀图像的精准且快速的分类目的,分类准确率达到99.00%,构建了多类别、多样本、高质量的桥塔内表面病害数据集。2)针对桥塔内表面病害样本数据较少且纹理特征复杂、特征提取过程中病害信息损失较大以及病害定位精度不足等问题,本文研究了面向特征复用的桥塔内表面病害网格级识别技术。通过引入基于稠密连接结构的DenseNet网络对病害特征进行更加有效的提取,充分融合浅层特征与深层特征以减少特征提取过程中的有效信息损失;同时结合全局平均池化模块和多重注意力模块对提取到的高维抽象特征进行增强,提升网络对病害信息的关注程度;设计了适用于桥塔内表面多类别病害识别的三重联合损失函数,包含病害置信度损失部分、病害分类损失部分和病害定位损失部分,分别从三个不同角度对网络模型的性能进行评估并用于训练过程。最终平均查准率、平均召回率、平均F1分数和类别平均精度分别达到89.19%、75.44%、81.06%和86.04%。3)针对当前基于机器视觉的混凝土裂缝语义分割方法存在的特征信息损失严重、裂缝定位精度差和无法有效解决类间样本不均衡等问题,以及桥梁塔柱内部裂缝图像纹理特征复杂、非结构化分布等特点,本文研究了知识与数据双驱动的桥塔裂缝像素级分割技术。通过统计学理论对裂缝图像进行隐式知识挖掘;基于统计结果构建了多阶段多分辨裂缝特征提取网络,凭借强健的特征传递流从多维度、多尺度学习裂缝特征信息,减少裂缝特征信息在传递过程中的损耗;基于统计结果提出了基于类别的裂缝特征增强网络,根据分割任务快速计算目标区域与其他区域的相似性以聚集不同区域上下文特征,实现提升模型对裂缝特征的分割性能;基于统计结果提出了适用于裂缝语义分割的损失函数,根据裂缝像素占比改变模型可观测样本数量,重置裂缝像素与非裂缝像素对损失函数的贡献率,以提升分割模型对裂缝特征的定位精度。最终裂缝像素准确率、召回率、交并比以及总像素准确率分别达到91.54%、88.88%、82.31%和99.82%。4)针对桥塔内表面裂缝分割模型参数量较大、预测结果中存在部分噪点、裂缝特征不连续以及各类别病害缺乏量化信息等问题,本文研究了基于病害识别结果的桥塔内表面健康诊断技术。通过知识蒸馏策略将高精度裂缝分割网络作为教师模型引导训练轻量化裂缝分割学生模型,其裂缝像素精度、裂缝像素召回率、裂缝像素交并比、裂缝像素F1指数、总像素精度分别达到87.16%、83.54%、74.47%、85.31%和99.74%,同时模型浮点运算量和参数量分别仅为原模型的25%和20%;结合基于数学形态学开闭运算的图像优化算法,降低噪声干扰、平滑裂缝区域;借助数学形态学相关算法提取裂缝区域的骨架信息,计算裂缝区域的像素级尺寸;结合传感器自身参数、数据采集过程参数以及相机成像原理等的坐标变换关系,将各类别病害区域的像素级尺寸映射为实际物理尺寸,并提出了桥塔内表面损伤评估方法,为桥梁工程的风险评估和施工需求提供数据支撑,最终集成构建混凝土桥塔内表面病害健康诊断系统。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2024.000141
{DOI}: 10.27415/d.cnki.gxngc.2024.000141
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的无人机航拍图像目标检测算法研究与实现
{Author}: 庄佳远
{Tertiary Author}: 陈旭灿
{Publisher}: 军事科学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;深度学习;无人机航拍图像;目标检测
{Abstract}: 随着无人机技术的飞速发展,无人机已经在多个领域引发了革命性的变革。从农林植保的精准管理到城市规划的空中勘测,无人机的广泛应用为各行各业带来了高效、精确的数据支持,推动了现代社会的智能化和科技进步。同时,深度学习技术的不断进步,特别是在计算机视觉领域的突破性发展,为图像处理和目标识别提供了强大的工具。将无人机技术与深度学习相结合,特别是在无人机航拍图像目标检测领域,不仅可以进一步提高图像识别的准确性和效率,还能够拓展无人机应用的新领域,如智能农业、城市管理、环境监测等。
然而,无人机航拍图像通常具有背景复杂、小目标占比高、大视场、噪声和形似物干扰严重等特点,直接将现有目标检测算法应用于无人机航拍图像往往效果不佳。传统的目标检测算法在这样的复杂场景下常常表现不佳,需要针对这些特殊性进行深入研究和优化。因此,本论文提出特定任务解耦语义编码TSCODE,它利用语义上下文编码SCE生成更加注重对象的整体特征和语义信息的特征表示,以适应无人机航拍图像中目标相对较小、环境复杂的特点,同时还利用细节保留编码DPE捕捉对象的局部特征和精确位置,进一步提升模型在大视场下定位目标的能力。这种方法的独特之处在于,它在目标检测过程中引入了对整体特征和局部特征分别进行优化的机制,使得模型更好地适应了无人机航拍图像的特殊场景。通过这种特定任务解耦的方法,TSCODE为无人机航拍图像目标检测领域的研究提供了新的思路。
另一方面,本论文还提出了一种通用的降低分辨率检测头RHOD,该设计的核心思想是充分利用低分辨率特征图的计算效率,通过特征融合FF降低特征图分辨率并结合基于特征查询FQ的分辨率恢复方法进行预测,避免了在高分辨率特征图上进行大量的卷积操作。该设计能够在保持模型精度的同时,大幅减少模型的计算量,为目标检测算法在无人机设备上落地部署提供了崭新的思路。
最后,本论文还将TSCODE和RHOD这两个研究成果与最新轻量化技术相结合,提出了一种基于深度学习的轻量化无人机航拍图像目标检测算法TRDE。实验结果表明,该方法能够使用较低的计算资源运行目标检测算法,且具有良好性能。这种轻量化方法为无人机航拍图像目标检测提供了更广泛的应用前景,不仅满足了高效、精确目标检测的需求,同时也为无人机技术的进一步发展提供了可靠的支持。通过这些研究,本文为无人机航拍图像目标检测领域的深入探索提供了新的思路和方法,具有重要的理论和应用价值。
{URL}: https://link.cnki.net/doi/10.27193/d.cnki.gjsky.2023.000169
{DOI}: 10.27193/d.cnki.gjsky.2023.000169
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 油气管道内部损坏检测机器人视觉检测与定位技术研究
{Author}: 王昭
{Tertiary Author}: 王建锋;李军
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 管道机器人;破损检测;机器视觉;图像处理;融合定位
{Abstract}: 油气管道作为重要的能源运输载体,其质量及运行安全直接影响油气能源的安全使用。为了保证油气管道安全运行,需要对管道尤其是管道内部进行检测和评估。对管道的损坏尤其是管道内部的损坏进行定位和判断具有重要的工程应用价值。由于油气管道内部环境恶劣,并且由于管道管径的限制,人工进入管道进行管道内部损坏检测是不可行的。近年来,随着机器人技术的快速发展,利用机器人作为载体,搭载视觉检测系统对管道内部检测是可行的方式。本文主要研究可以用于油气管道内部损坏检测的机器人,重点研究管道内部损坏视觉检测方法和定位方法。主要工作如下:
首先,分析了管道内部损坏检测技术和管道内部定位技术的国内外研究现状,提出了基于机器人载体的油气管道内部视觉检测与定位技术的总体方案,重点分析了图像采集与基于深度学习的油气管道内部损坏提取与定位研究方案。
其次,研究基于YOLOv5的管道内部损坏分割与分类方法。分析YOLOv5网络的基本框架。研究图像预处理方法,利用小波去噪方法对采集的图像进行降噪处理,根据不同噪声水平对频域小波系数进行分段处理估计噪声方差并且对噪声方差进行平滑处理,从而消除缺陷图像中的噪声,提高图像质量,该方法能够有效地保留图像的细节信息和能量。利用Retinex方法对图像进行图像增强和均衡处理,提升了图像的对比度,并且重新调整了图像色彩分布,减少了不同拍摄光照对图像质量的影响。研究基于YOLOv5的管道内部损坏图像分割与分类方法,将经过预处理和均衡处理后的图像通过YOLOv5进行损坏图像的分割和分类,在样本训练中针对样本量不足的问题对原始样本进行了扩充处理。通过试验表明,本文方法在管道内部损坏图像分割和分类方面有较好的性能。
然后,提出了基于惯性系统与里程计融合的管道检测机器人定位方法,建立了基于惯性系统与里程计融合的误差模型,采用扩展卡尔曼滤波与离线数据平滑处理技术进行融合滤波处理,利用提出的基于惯性传感器与里程计融合方法实现了管道内部的较精确定位。进行仿真试验验证了所提出的方法有较好的性能。
最后,搭载实验平台进行图像采集处理与定位试验,试验结果表明,本文的基于机器视觉的油气管道内部损坏图像检测与定位方法有较好的精度。本文方法可以为管道内部的检测技术及产业化应用提供一定的参考。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2023.000121
{DOI}: 10.27831/d.cnki.gxjxy.2023.000121
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于卷积神经网络模型的裂纹鸡蛋图像识别
{Author}: 李舒;唐梦笛;同思远;孙柯
{Author Address}: 安徽师范大学生命科学学院;
{Journal}: 食品与机械
{Year}: 2023
{Volume}: 39
{Issue}: 11
{Pages}: 18-22+63
{Keywords}: 鸡蛋;裂纹;计算机视觉;卷积神经网络;判别准确率;检测
{Abstract}: 目的:提高基于计算机视觉的鸡蛋裂纹检测方法的准确性和运行效率。方法:使用禽蛋模拟撞击设备得到裂纹鸡蛋，并通过鸡蛋动态图像采集设备采集不同角度裂纹鸡蛋和完好鸡蛋图像，然后以原始图像和经预处理后图像分别建立用于裂纹鸡蛋图像识别的YOLO-v5、ResNet和SuffleNet模型，并比较不同模型识别准确度以及对未经预处理图像的适应性。结果:YOLO-v5、ResNet和SuffleNet模型均可有效识别经过预处理的裂纹鸡蛋图像，其验证集准确率分别为98.8%,97.8%,99.4%。对于未经预处理的裂纹鸡蛋，ResNet模型判别准确率较低，而SuffleNet模型对其适应性较好，判别准确度超过99%。结论:在卷积神经网络模型中，SuffleNet模型适用于裂纹鸡蛋图像的识别，且采集的图像无需进行预处理。
{ISBN/ISSN}: 1003-5788
{Notes}: 43-1183/TS
{URL}: https://link.cnki.net/doi/10.13652/j.spjx.1003.5788.2023.80144
{DOI}: 10.13652/j.spjx.1003.5788.2023.80144
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人工件分拣系统
{Author}: 蒋智蓓;崔亚飞;秦龙
{Author Address}: 永州职业技术学院;
{Journal}: 机电工程技术
{Year}: 2023
{Volume}: 52
{Issue}: 11
{Pages}: 170-173
{Keywords}: 工业机器人;机器视觉;工件分拣
{Abstract}: 工业机器人在工业生产中的应用越来越广泛，但机器人缺乏感知能力，所以它还没有达到工业自动化的水平。随着机器视觉的发展，新兴技术已被应用于工业机器人，以提高生产效率。在智能改进中，机器视觉起着至关重要的作用。设计了一种基于机器视觉工业机器人的工件分拣系统。该系统通过相机在工件上进行图像采集，拍摄工件图像；然后，通过相机标定，获得三维空间中物体的几何信息，以重建和识别物体；之后，通过采用Canny算法获取工件边缘信息，进行工件的图像预处理，为后续图像处理做铺垫；提出结合概率霍夫变换和弗里曼链码算法，对工件进行图像形状识别；计算工件中心空间坐标，指导机器人完成分拣工作。实验结果表明，该分选系统能够实现快速工件识别，从而满足分拣的要求。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxXTok1G-BkWmbpSjEvomCaX3U5pV4328zkiz1ikqBtkxrNwKAm_aaEfZbQlyPgvt2kTaWIsrFA3SsxhM4pGi3YuUzUrbp3RWoGl6a9QecI3chxipBzCQFPURiWh3LONpwg5dOrM3euM1YoTiMBj7fNSfC7s1f155FI-rTE_FEuk7baOWkSJC_whQV1NNF4Afg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MATLAB GUI的图像处理和机器视觉辅助教学平台设计与实现
{Author}: 祁峥东;阎妍;杨正颖;常合轩;殷海金;姜欣怡;陈果;陈麒光
{Author Address}: 南京晓庄学院信息工程学院、人工智能学院;南京晓庄学院电子工程学院;
{Journal}: 南京晓庄学院学报
{Year}: 2023
{Volume}: 39
{Issue}: 06
{Pages}: 57-65+81
{Keywords}: MATLAB GUI;图像修复;图像增强;辅助教学;数字图像处理;演示系统
{Abstract}: 图像处理和机器视觉课程涉及知识面广，需要掌握计算机、数学、大数据、编程等相关知识，但现有的图像处理和机器视觉实验系统程序结构复杂，传统的直接在命令行进行编程的方法在教学直观性方面表现力弱，学生在课程学习中无法理解机器视觉相关算法的基本原理，不适合在课堂学习的初级阶段推广。为提高教学质量及学生的学习兴趣，在Matlab环境下，本文利用图形用户接口(GUI)设计并开发了此套图像处理辅助教学系统。本系统涵盖了图像处理和机器视觉的核心内容，分为图像修复、图像增强、图像滤波三大部分，实现了图像处理的可视化操作，系统交互性强，特别强调了模块化工程，将每个实现图像处理功能的代码分别进行function函数定义，有利于老师的教学讲解与学生的理解、自主学习。设计结果表明，该系统对图像的处理效果良好，化抽象为直观，可以更好地辅助教师授课、帮助学生理解和自学。
{ISBN/ISSN}: 1009-7902
{Notes}: 32-1619/C
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwAmbKOvbYq1vx_zhvO6uercDUiS3mqwaJtQGrUNqVBVaHPGXrlQQsLAJ6agurOf_CN9pymgrpKRmIbGYUQXPJec9bYCv_uxputDdO-XtVHhrfHBW8UhXfKDvWGsOM8IsOaYxSa_Ay5_R0WaSx20L3LCWwCcsj6D53EBirxw37OpEp8iy0LA2D9e-JHuFQ_7v4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于深度学习的视觉SLAM研究综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会论文集
{Author}: 严永嘉;蹇木伟;刘宏哲;徐冰心;徐成
{Author Address}: 北京联合大学北京市信息服务重点实验室;北京联合大学机器人学院脑与认知智能北京实验室;山东财经大学计算机科学与技术学院;
{Secondary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会
{Place Published}: 中国江苏镇江
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2023
{Pages}: 4
{Keywords}: 计算机视觉;深度学习;实时定位与建图;研究综述
{Abstract}: 视觉实时定位与建图(Simultaneous Localization and Mapping,SLAM)是一项关键性的计算机视觉技术,用于实现机器或机器人在未知环境中的自主定位和地图构建,在机器人导航、增强现实和无人驾驶等领域被广泛应用。随着深度方法在图像处理领域的飞速发展,二者相结合推动SLAM技术在应对更加复杂多变的环境的同时提高准确率。通过回顾传统SLAM方法流程,文中提供了对使用深度方法进行模块替代和端到端SLAM的全面概述和详细分析。此外,还介绍了视觉SLAM面临的挑战,并提出了相应的解决方案和未来的研究方向。总之,此项工作旨在帮助读者全面了解视觉SLAM技术的发展现状和潜力,并为进一步研究和应用视觉SLAM提供指导和启示。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.055284
{DOI}: 10.26914/c.cnkihy.2023.055284
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于深度学习的图像分割方法及研究现状
{Tertiary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会论文集
{Author}: 原颖;杜煜;苗思琦;赵世昕;张昊
{Author Address}: 北京联合大学北京市信息服务工程重点实验室;北京联合大学机器人学院;
{Secondary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会
{Place Published}: 中国江苏镇江
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2023
{Pages}: 4
{Keywords}: 深度学习;语义分割;实例分割;计算机视觉
{Abstract}: 近年来,基于深度学习的图像分割方法在计算机视觉中取得了巨大的成功,深度学习方法逐渐成为主流。对于深度学习方法的不同原理,将其划分为不同的类型,并归纳主流的数据集。最终讨论该领域目前面临的挑战,并提出几个未来潜在的发展方向进行总结。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.055292
{DOI}: 10.26914/c.cnkihy.2023.055292
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 飞机蒙皮缺陷自动化检测研究进展
{Author}: 周雨轩;周文彬;李小丽;陈新波;周正干
{Author Address}: 北京航空航天大学;海军航空大学青岛校区;
{Journal}: 航空制造技术
{Year}: 2023
{Volume}: 66
{Issue}: 22
{Pages}: 69-77
{Keywords}: 飞机蒙皮;超声检测;机器视觉;图像处理;自动化检测
{Abstract}: 飞机蒙皮作为飞机外部主要的维形构件，具有承担载荷、保持其气动性能的作用。与传统的仅依靠目视蒙皮缺陷检测方法相比，使用自动化超声检测内部缺陷及基于机器视觉的外部缺陷检测方法具有检测效率高、自动化程度高、检测结果一致性强等显著优势。根据飞机蒙皮缺陷自动化检测研究进展，介绍了飞机蒙皮的典型缺陷类型，分别综述了自动化超声无损检测技术和机器视觉图像处理技术在蒙皮缺陷检测中的应用，总结了蒙皮缺陷检测领域目前存在的问题与技术难点，展望了飞机蒙皮自动检测领域未来的发展趋势。
{ISBN/ISSN}: 1671-833X
{Notes}: 11-4387/V
{URL}: https://link.cnki.net/doi/10.16080/j.issn1671-833x.2023.22.069
{DOI}: 10.16080/j.issn1671-833x.2023.22.069
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的动态人体手势检测识别技术研究
{Author}: 张丞
{Tertiary Author}: 侯义斌;何坚
{Publisher}: 北京工业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 计算机视觉;深度学习;人机交互;手势识别;手势检测;多模态融合
{Abstract}: 手势识别是人机交互领域的重要研究方向,其目的是使计算机理解人体手势在特定场景下表达的含义,进而为个体提供准确、高效的服务。手势识别技术的应用范围已经覆盖至人们的生活、娱乐、工业和医疗等多个方面。基于计算机视觉的手势识别具有自然、成本低等优点,近年来受到广泛关注。然而,视觉信息具有复杂、多样性等特点,如何从视觉序列中检测手势,进而准确地识别手势是手势识别技术面临的难点问题。本文从手势动作中人物身体部件之间的时空关联关系出发,研究视觉手势时空上下文特征的描述、提取以及融合方式,提高手势检测和识别方法的性能。论文针对骨架手势识别、图像手势识别以及手势检测三方面内容开展研究,并取得如下创新性研究成果:
(1)针对已有手势识别方法中多模态骨架数据融合利用能力不足的问题,提出一种基于多模态骨架图的图卷积手势识别方法。首先,根据人体结构分别以人体和手部的关节位置、旋转角度、骨骼矢量和根旋转角度共同描述人体手势,提出一种多模态骨架相互关联的创新型图结构,描述手势时空特征与关联关系;其次,针对传统空间配置分区策略在短路图结构上存在的退化问题,提出一种高度分层分区策略,实现短路图结构的均匀分区;最后,设计图卷积网络架构,学习固定、数据驱动以及层级数据驱动的三种连接关系强度。方法解决了保留拓扑结构的模态间相关特征融合提取问题,实现骨架手势的准确识别。
(2)面向肢体与细粒度手部动作协同的复杂手势,提出一种基于图像焦点融合的手势识别方法。首先,依据身体部件之间的自然连接和逻辑关联关系,分多个层次对部件进行组合,提出一种层次化部件组合方法,实现不同手势动作的多种焦点位置覆盖;其次,提取人体表面模态数据,并在特征级、决策级将其与视觉和光流模态融合,进而增强焦点的特征描述能力;最后,针对每种手势类别分别学习不同焦点的分类贡献度,提出一种可排除相关性较低焦点干扰的焦点融合方案。方法解决了多层次焦点选取和互补融合问题,实现肢体与细粒度手部动作协同的复杂手势的准确识别。
(3)面向动态手势序列中的手势检测问题,提出一种基于部件亲和场的手势检测方法。首先,提出一种以三维热力图卷表示骨架时空关联的方法,描述关节位置与置信度、时空域骨架铰链关系以及部件运动轨迹;其次,提出一种基于高斯函数的边界概率序列构建方法,降低手势边界拟合难度;最后,设计一种时间域非退化的卷积网络架构以提高手势检测精度。方法解决了三维卷特征的时空上下文描述问题,实现连续动态手势的准确检测。
(4)面向智能驾驶场景中的交通指挥手势检测识别问题,融合基于骨架和图像的检测识别方法,进行了多模态集成的交通指挥手势检测识别实验。首先,基于人体骨架通过多模态骨架图描述肢体特征,基于视觉图像焦点描述身体部件的全局和局部细粒度特征,基于部件亲和场检测手势边界,融合骨架与图像特征识别手势类别。其次,设计了一种基于滑动窗口的流数据计算方案,通过早期检测和批量并行运算提高计算带宽利用效率。最后,采集构造了包含四种指挥方向的交通指挥手势数据集,对方法进行验证,并在真实室外环境中进行在线实验。
本课题针对动态手势检测识别问题,研究了基于多模态骨架图的手势识别方法、基于图像焦点融合的手势识别方法以及基于部件亲和场的手势检测方法,集成了多模态手势检测识别架构,解决由肢体和手部动作协同的连续动态人体手势检测识别问题,取得了良好的检测识别效果。方法可应用于自然人机交互、智能驾驶等多种场景,具有良好的理论研究意义和应用价值。
{URL}: https://link.cnki.net/doi/10.26935/d.cnki.gbjgu.2023.000367
{DOI}: 10.26935/d.cnki.gbjgu.2023.000367
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在瓜菜检测应用中的研究进展
{Author}: 戴军
{Author Address}: 苏州工业园区服务外包职业学院智能管理学院;同济大学经济与管理学院;
{Journal}: 中国瓜菜
{Year}: 2023
{Volume}: 36
{Issue}: 11
{Pages}: 1-9
{Keywords}: 人工智能;机器学习;机器视觉;瓜菜检测
{Abstract}: 机器视觉技术是一种通过机器代替人眼来做测量和判断的技术。作为一种新兴的检测方法，其在瓜菜检测方面解决了传统人工检测效率低、检测成本高且需较强专业性和经验问题，提高了检测的实时化与智能化水平。检测结果为瓜菜后续诊断防治和产销工作提供靶向性指导具有重要意义。阐述了机器视觉的技术机理及其在瓜菜检测中的应用逻辑和该技术在瓜菜病虫害、长势监测、品质分级等检测应用中的研究进展，同时对该技术在瓜菜检测应用中的不足展开讨论，并展望了此类检测技术的应用前景。
{ISBN/ISSN}: 1673-2871
{Notes}: 41-1374/S
{URL}: https://link.cnki.net/doi/10.16861/j.cnki.zggc.20231030.006
{DOI}: 10.16861/j.cnki.zggc.20231030.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的采摘机器人采摘定位与导航方法
{Author}: 蒙贺伟;周馨曌;吴烽云;邹天龙
{Author Address}: 石河子大学机械电气工程学院;佛山市中科农业机器人与智慧农业创新研究院;广州商学院;华南农业大学工程学院;
{Journal}: 自动化与信息工程
{Year}: 2023
{Volume}: 44
{Issue}: 05
{Pages}: 1-7
{Keywords}: 采摘机器人;机器视觉;自主导航;可行驶区域检测;果实目标识别;采摘点定位
{Abstract}: 自主导航与采摘定位作为采摘机器人的关键任务，可有效减轻人工劳动强度，提高作业精度与作业效率。该文阐述和分析基于视觉的采摘机器人采摘定位与自主导航方法，主要涉及视觉导航的可行驶区域检测、果实目标识别及采摘点定位，并根据国内外的研究现状，对机器视觉的最新发展和未来发展趋势进行展望。
{ISBN/ISSN}: 1674-2605
{Notes}: 44-1632/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzW-YUc6NBj0iRIOBsyUA9qA7icWS9RKU2DIm5M4Immrxj_rM4GtrODOE-WWSFAudQxak9O7acM7d7sp7gLrZo1Touhl31E4GNgId94GyMap7AoUARHnM4u9kzVQGOs-wvMv6yeJzJzrcqjN7RdvkRM4I8JUT77_OL1SDDWLGA0iexJ5hDhW7LrSGJBiLc6g8M=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉SLAM的水果采摘机器人研究进展
{Author}: 孟繁;周馨曌;吴烽云;邹天龙
{Author Address}: 仲恺农业工程学院;佛山市中科农业机器人与智慧农业创新研究院;广州商学院;
{Journal}: 自动化与信息工程
{Year}: 2023
{Volume}: 44
{Issue}: 05
{Pages}: 8-13+31
{Keywords}: 同步定位与地图构建;水果采摘机器人;机器视觉;自动化
{Abstract}: 水果采摘机器人是一种具有较大潜力的农业自动化技术，不仅需在复杂且不断变化的环境中连续作业，还面临地形、树木分布、天气变化、环境光照、遮挡等多种挑战。视觉同步定位与地图构建（SLAM）作为一种成本低廉且能够提供丰富语义信息的技术，有望提高水果采摘机器人的效率和自动化程度。近年来，视觉SLAM在水果采摘机器人领域取得了一系列重要进展，主要包括深度学习优化方法、基于点线特征的优化方法、基于RGB-D的视觉SLAM优化方法、动态环境中视觉SLAM优化方法、回环检测和后端优化方法等。未来，水果采摘机器人领域的研究将朝着更高的自动化程度和采摘效率方向发展；可能的发展方向包括更复杂的感知系统、更智能的决策算法、更强大的硬件支持等。此外，水果采摘机器人在多样化水果园中的适应性和鲁棒性研究也将引领这一领域的发展。通过不断推动视觉SLAM技术的创新，水果采摘机器人有望成为现代农业的重要工具，提高水果产量并减轻农业劳动力短缺的问题。
{ISBN/ISSN}: 1674-2605
{Notes}: 44-1632/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwwkP14pERAmwS_Xooonk-dIb3z5LhSWa9Mom8TzmtFojRL_XNY0xEOlm9QPKFPDC9Ug44tiu5zTervGF0nLP4VkbZyUyoL8aJMIsiA0cd4ndE9kjpiVcZ462w27awBdw13vS_YOAvAfLQEdNeVfYa1pYt-JdjaHw7a0-AHBgM3J-IDKNrzN4N5vl45wvWiTFc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于“机器视觉+深度学习”目标检测的皮革表面缺陷检测系统研究
{Author}: 何茜
{Author Address}: 陕西邮电职业技术学院;
{Journal}: 中国皮革
{Year}: 2023
{Volume}: 52
{Issue}: 11
{Pages}: 59-63
{Keywords}: 机器视觉;深度学习;皮革表面缺陷;智能化检测
{Abstract}: 针对皮革表面缺陷人工检测效率低、准确率低等问题，基于机器视觉和深度学习算法等构建了一种皮革表面缺陷检测系统。对该系统的主要框架及核心功能进行分析，以一般皮革表面光学检测系统为对象进行检测精度与检测效率对比。结果表明，基于“机器视觉+深度学习”的皮革表面缺陷检测系统检测精度更高，在应用初期的检测效率与一般检测系统较为接近，但随着应用时间的增长，系统检测效率优势也会逐渐显现。
{ISBN/ISSN}: 1001-6813
{Notes}: 11-2649/TS
{URL}: https://link.cnki.net/doi/10.13536/j.cnki.issn1001-6813.2023-011-015
{DOI}: 10.13536/j.cnki.issn1001-6813.2023-011-015
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于transformer和生成对抗网络的3D人脸生成和重建研究
{Author}: 范国玉
{Tertiary Author}: 葛琦
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 三维模型;注意力机制;体渲染;生成对抗网络
{Abstract}: 在人类的日常生活中,三维模型在日常生活的展示与交互中,扮演着日益关键的角色。但是,日常生活中往往不能获取到精确拍摄的人体头部图像,鉴于场景的干扰和被拍摄者相对相机的距离和角度,在很多情况下只能获取到人脸的大致形状。因此,研究如何通过简单的人脸掩膜图像生成不受环境光照影响的三维人体头部模型具有重要的意义。随着计算机视觉技术的不断进步,在自然语言处理中起着十分重要作用的注意力机制模型(Transformers)也被广泛运用到了视觉语义特征提取当中。通过Transformers将语义掩膜图像编码成隐变量,并将其编码到所需要的场景潜在代码中,通过多层全连接层和Embedding层找到语义信息之间的关联性,我们便可以结合掩膜图像和二维图像之间的时空特征,强化神经网络结构的语义信息依赖性,从而生成更加精细的结构。本文针对上述问题,设计了语义信息模块采用编码-解码结构,在编码器中使用映射网络(Custom Mapping Network)用于将输入的噪声向量(z)映射到高维空间,并将Swin Transformer语义掩码编码到所要训练的3D生成模型,并且在3D生成模型的前向过程中把多分辨率输入图像分成多个子块,更有效地处理多分辨率图像,保持了计算效率和模型性能的平衡。对空间点采样的空间编码信息与解码器中的低层语义特征拼接,最终通过将隐编码进行MLP聚合,得到所需的三维空间隐式表示。为了验证基于生成对抗网络的神经辐射场技术,本文基于CelebAMask-HQ、CatMask数据集进行了实验。实验结果表明,本文设计的基于Swin Transformer编码的隐式神经表达模型的生成效果在CelebAMask-HQ和CatMask数据集上分别达到了40.6和24.1的FID以及2.15和2.50的IS,提升效果明显。同时考虑到我们对于头部模型的需求不仅仅局限于人体头部图像的简单观看,我们更多地需要参数化头部模型,通过将面部表情、头发样式、服装和姿势等进行单独编码,并将所需操控的编码信息加入到生成过程中,从而实现高质量的人体头部操控。对此,本文在训练时利用3DMM进行人脸信息要素提取,然后结合第三章中的Swin Transformer对输入的人脸图像进行特征融合,并使用多个面部编码器将输入图像转换为多个不同的域以表示和合成人头的精细细节。最后采用生成对抗网络进行对抗性训练,以此获得具有逼真感的可控制的人体头部模型,并且实现了3D自由查看软件,可以用于实时的人体头部动态渲染和操控。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000964
{DOI}: 10.27251/d.cnki.gnjdc.2023.000964
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Swin Transformer的深度伪造检测技术研究与实现
{Author}: 杜承峻
{Tertiary Author}: 陈云芳
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度伪造检测;多通道;二维卷积;通道注意力;自注意力
{Abstract}: 深度伪造(Deepfake)是深度学习(Deep Learning)和伪造(Fake)的混成词。此技术可将已有的图像或视频叠加至目标图像或视频上。该技术的滥用使得网络上信息传播的复杂程度日益加剧,不法分子利用这些技术进行诽谤、欺诈、勒索,危害国家安全,损害个人和社会公共利益。因此,如何针对这些伪造内容进行高效检测已经成为亟待解决的问题。本文基于多通道信息提取方法、混合缩放方法和双流注意力方法,提出了两种深度伪造检测方法,并进一步实现了便捷高效的深度伪造检测系统。本文主要研究内容如下:(1)本文提出一种基于多通道Swin Transformer的深度伪造检测方法。通过提取图像的色彩空间、人脸特征空间和频域空间中的通道信息并将其堆叠为多通道信息,实现了数据的多通道信息提取。将这些多通道信息输入到Swin Transformer特征提取器进行检测,并通过交叉熵损失函数和Adam W优化器执行模型的反向传播过程,最终得到检测模型。在公开数据集Face Forensics++(FF++)上进行测试后,实验结果显示该方法的深度伪造检测准确率达到了94.71%,优于其他检测方法。(2)本文提出一种基于混合缩放双流注意力网络的深度伪造检测方法。该方法通过将混合缩放模块和基于Swin Transformer的双流注意力模块结合以检测深度伪造视频。混合缩放模块由残差下采样、融合卷积和压缩卷积组成,实现了更高效的局部特征提取。双流注意力模块则通过结合自注意力机制和通道注意力机制,实现了全局维度与通道维度的特征提取。在整体架构设计中,混合缩放模块负责提取数据的浅层局部特征,而双流注意力模块负责提取数据的深层全局特征。通过在FF++数据集上进行实验,结果显示该方法的深度伪造检测准确率达到了95.62%,证实了其优越性。(3)本文设计并实现了一种深度伪造检测系统。该系统采用标准的浏览器/服务器架构,前端基于Vue框架构建,后端使用Flask框架进行开发。对于异步任务,系统采用Redis作为消息队列,由Celery负责处理队列中的异步任务。在提供用户权限和记录管理等基础功能服务的基础上,通过将前述深度伪造检测方法作为模块单独嵌入到系统中,为用户提供便捷的深度伪造检测服务。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000173
{DOI}: 10.27251/d.cnki.gnjdc.2023.000173
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的单幅图像去雨算法研究
{Author}: 陈辉
{Tertiary Author}: 朱松豪
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去雨;注意力机制;Transformer;轻量级网络
{Abstract}: 雨图像中的雨纹、雨滴、雨雾等降雨场景会对图像中的背景信息造成严重的干扰,不仅严重影响视觉效果,还会降低一些户外计算机视觉系统的可靠度和准确性。因此,如何有效地从退化图像中去除雨纹信息,恢复被破坏的背景纹理信息,是一个值得被研究的问题。为了解决单幅图像去雨问题,本文利用卷积神经网络和视觉Transformer两种技术的优点设计图像去雨算法。首先,针对普通基于卷积神经网络的去雨方法中存在的去雨不足、泛化性差等问题,设计了一种端到端的图像去雨网络,注重于学习多尺度特征信息,以生成清晰、干净的无雨图像。其次,针对卷积神经网络缺乏非局部信息建模能力,以及Transformer的过度参数化增加了系统复杂性等问题,进一步探索将Transformer和卷积神经网络相结合,设计混合的轻量级图像去雨方法。然后,针对传统的编码器-解码器结构的Transformer存在的计算量大、运行时间慢等问题,对网络模型进行优化设计,使得模型使用更少的参数达到最佳的性能。最后,通过在大量基准数据集上的实验证明了,我们所提出的方法比其他先进的方法在定量指标和定性分析上表现更为优越,并且具有良好的泛化能力,同时计算成本和参数量远小于同类型的其他模型。具体研究内容如下:(1)提出一个基于卷积神经网络的端到端图像去雨算法,称为联合多尺度特征学习和注意力机制的密集连接图像去雨网络。该网络使用基于多尺度分割注意力模块改进的密集连接网络作为总体框架,分割注意力模块旨在使用注意力机制学习降雨区域特征,密集连接网络增强了特征复用,提高了模型运行效率。包含多个密集层的密集连接网络使用渐进式多尺度特征学习方法,在多重降采样的基础上,使用重参数化VGG模块提取不同尺度特征信息,有效表征雨纹特征。(2)提出一个Transformer与卷积相结合的轻量级图像去雨算法,称为非线性递归Conv-Transformer图像去雨网络。首先,设计了一种基于卷积网络和Transformer双分支的特征提取模块,将卷积网络的局部建模能力和Transformer捕获全局上下文的非局部建模能力相结合;其次,在残差递归网络架构的基础上,我们使用一种非线性映射模块实现约束递归,并采用通道注意力融合多分支残差特征,从而实现了网络轻量化。(3)提出了一个基于轻量级编码器-解码器架构的Transformer图像去雨算法,称为基于全卷积解码器的通道Transformer去雨网络。首先,设计了一个全新的通道Transformer模块获得全局上下文信息,其中运用深度可分离卷积有效学习多尺度的局部特征,并通过堆叠该模块构成了Transformer编码器。其次,设计了一个基于全卷积架构的解码器,利用mask注意力和反向瓶颈卷积实现特征渐进融合和特征恢复,显著降低计算复杂度和GPU内存需求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001774
{DOI}: 10.27251/d.cnki.gnjdc.2023.001774
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人体姿态估计研究
{Author}: 王家祥
{Tertiary Author}: 何利文
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;人体姿态估计;注意力机制;轻量化网络
{Abstract}: 人体姿态估计任务是计算机视觉领域的研究重点和热点之一。它旨在通过分析图像或视频中的人体,检测和定位人体的关键点以获取人体的姿态信息。近年来,受益于深度学习和卷积神经网络的快速发展,人体姿态估计网络在动作捕捉,电影、游戏和虚拟现实等领域实现了广泛应用。但是在人体姿态估计任务中仍然存在各式各样的问题,如部分网络设计复杂,导致网络参数量和计算开销过大等问题以及由于遮挡、姿态多样性、视角变化、光照变化等因素的干扰,导致网络的检测精度不高的问题。因此,本文提出了两种算法分别解决上述问题,同时将其中一种算法应用于健身评分系统的开发之中。本文主要工作及创新点如下:针对网络参数量和计算开销过大问题,提出了基于HRNet的轻量化人体姿态估计网络。该网络以HRNet网络为主干网络,使用轻量型的模块替代原始网络中的标准卷积,降低网络的计算开销和参数量;其次添加无参注意力机制,同时获取特征图在通道和空间维度信息特征,提高网络模型对图像中关键点检测的能力;最后在COCO和MPII两种数据集上与当前流行的网络模型进行了对比实验,实验结果表明提出的网络在牺牲少量精度的情况下,网络参数和计算量有了大幅降低。将Conv Ne Xt V2网络引入人体姿态估计任务中,并将其作为主干网络。针对遮挡等因素的干扰而导致网络检测精度不高的问题,使用结合了卷积和自注意力优点的VAN模块改进主干网络,增强了网络对局部上下文信息的提取以及在空间和通道维度的自适应,使得网络在针对输入图像尺度较小以及被遮挡的人体关键点的特征提取能力方面有所提高,从而提高整个网络对于人体姿态关键点的检测精度。针对专业健身成本高等问题,将轻量化人体姿态估计网络IGSNet与DTW算法结合,设计并实现了一个健身评分系统。该系统使用轻量化网络对用户姿态估计,通过DTW算法对姿态进行评分,最后根据评分给出建议。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001066
{DOI}: 10.27251/d.cnki.gnjdc.2023.001066
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度神经网络的道路缺陷识别
{Author}: 戴尹
{Tertiary Author}: 刘烨
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: YOLOv5;道路裂缝;目标检测;语义分割
{Abstract}: 近年来,我国公路实现快速发展,然而随着车辆的通行带来了众多难以解决的养护问题。裂缝是道路表面最为普遍、最易于发生和最早期出现的损伤类型之一,其存在伴随着道路的整个使用寿命,并随着道路的老化而变得更加严重。因此,准确地检测道路裂缝对于道路养护具有重要的意义。传统的图像处理算法在道路裂缝检测方面存在着一定的缺陷,如对图像的光照、阴影等干扰较为敏感,且需要大量的人力物力,同时精度与鲁棒性较差。基于计算机视觉的道路裂缝检测方法具有更高的准确率、更强的泛化能力、更高的自动化程度和更快的检测速度,能够更好地应对实际场景中的道路裂缝检测需求。据此,本文以道路裂缝作为研究对象,对基于计算机视觉的道路裂缝检测、分割算法展开研究。(1)本文提出一种基于注意力机制的改进YOLOv5裂缝检测模型。针对图像中道路裂缝宽度较小,容易被现有的目标检测网络所忽略的问题,本文引入混合注意力机制用以增强模型的特征提取能力,通过实验论证在不同网络阶段引入注意力模块的性能差异,同时引入温度参数来改进损失函数,用以解决图像中裂缝与背景正负样本不平衡的问题。改进后对于裂缝数据集模型的平均精度提高2.5%。(2)本文提出一种检测-分割多任务裂缝提取网络模型。针对现实养护需要快速、准确地检测出裂缝,并确定其轮廓大小和位置的要求,本文提出多任务网络裂缝提取模型。通过多任务网络可以使用实例级别标注来训练分类任务,并使用像素级别标注来训练分割任务,实现对较难获得的像素级别标注以及较容易获得的实例级别标注的充分利用。通过共享主干网络,避免重复计算相同的特征图,同时可以充分利用已经提取的特征,减少模型的计算量和内存消耗,提高模型的效率、泛化能力和准确性。实验结果表明,多任务共享主干网络通过共同训练可以相互促进,获得更好的检测分割性能。(3)本文提出一种基于对抗网络思想的弱监督语义分割裂缝提取模型。针对分割模型训练需要大量样本且分割数据集难制作、难获取的问题,本文以对抗网络思想为依托,设计两个不同的分割网络作为生成网络,用来增加标签的多样性,加强分割类别之间的关联,同时判别网络通过两种不同的输入,分别判断生成网络产生的两个输出是否正确,从而促进两个生成网络之间的竞争和协作,增强模型对裂缝特征的学习能力。在模型的训练过程中,采用弱监督学习方式,利用少量有标注的裂缝图像进行训练,通过对抗网络的竞争和协作机制,实现对未标注图像的语义分割。实验结果表明,本文提出的模型在裂缝分割任务上表现出较好的性能和泛化能力,具有较强的实用价值和应用前景。综合所述,论文采用深度学习算法完成裂缝检测工作,针对裂缝宽度较小、分割数据集像素级别的标注样本较少等问题开展研究,取得了一定的进展。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001673
{DOI}: 10.27251/d.cnki.gnjdc.2023.001673
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于GAN的无监督学习与全局自注意力机制的低光照增强算法研究与实现
{Author}: 周宇
{Tertiary Author}: 韩光
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像增强;无监督学习;注意力机制;生成对抗网络;自注意力
{Abstract}: 受设备硬件陈旧、光线不足、曝光时长较短等因素影响,在这些条件下拍摄出的图像质量往往因为缺少光信号而严重受损,这些照明不足的图像所丢失的细节和对比度不仅会造成不愉快的主观感受,还会降低许多高层计算机视觉系统的性能。为使低光照图像中的细节可见,尽可能地恢复低光图像的特征并抑制噪声的产生,提高计算机视觉系统的性能,本文针对当前研究面临的重难点,提出了基于生成对抗网络的无监督学习双路融合低光照增强网络,使用非配对数据集和生成对抗网络增强低光图像。为了进一步提升增强图像的全局亮度一致性,本文同时对夜间图像特点进行深入分析,并提出了一种基于轻量级Transformer全局自注意力的图像增强网络,优化当前低光照增强算法存在的参数冗余和网络复杂度过高等问题。具体而言,本文的工作总结如下:(1)针对增强过程易放大噪声以及图像质量下降等问题,本文提出了基于GAN的无监督学习双路融合低光照增强网络,可从非配对的低光和正常光数据集中学习到低光图像到正常光图像的映射方式。用于对输入图像执行增强步骤的生成网络由双支路构成,上支路是注重对噪声进行抑制的细化分支,下支路是基于注意力机制的简化U-Net全局重建分支,用于高质量图像的生成。判别网络采用特征金字塔的多尺度判别结构来增强图像全局一致性、避免局部过曝光。同时改进了损失函数,引入全新的保真度循环一致性损失来进一步提高图像纹理信息的恢复质量。通过大量定性与定量的实验结果对比分析,证明了本文方法能够在增强图像视觉效果的同时,有效地抑制增强后图像伪影的产生和噪声的放大。(2)针对算法参数冗余、网络结构复杂而导致无法实时输出增强画面以及增强图像的全局亮度不一致等问题,本文提出了基于轻量级Transformer全局自注意力图像增强网络。目前大部分低光照增强算法均是对于图像全局的增强,这就导致了原本光照不均匀的图像在增强之后会产生局部过曝光等问题。因此本文重新改进了Transformer自注意力机制部分,使其不仅能够充分发挥在图像全局特征相关性方面的优势,而且还避免了因参数的冗余造成的计算复杂度上升问题。实验证明,本算法能够在输出高质量图像与性能方面取得一个较好的平衡点,并且在处理明暗分布不均匀的图像时也能兼顾亮度全局一致性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000717
{DOI}: 10.27251/d.cnki.gnjdc.2023.000717
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的红外小目标检测算法研究
{Author}: 何悦
{Tertiary Author}: 朱虎
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 红外小目标;深度展开网络;生成对抗网络;编解码网络;自适应字典
{Abstract}: 红外小目标检测技术被广泛应用于军事、工业、农业、交通等领域,因红外成像具有准确度高、隐蔽性高、成像清晰、抗干扰能力强等特点,所以具有重大研究价值。近年来得益于强劲的算法理论和特征分析技术的发展,以YOLO和Faster R-CNN为代表,基于深度学习的检测技术获得了长足的进步。但以上方法仅仅是通过遍历局部图像来获取特征,导致检测准确率较低,且检测种类受限,处理速度也无法满足实时性要求,与实际应用的要求还有很大的距离。为了提高红外小目标检测算法在不同场景下的检测效果,本文提出了两种改进算法,主要研究成果如下:(1)针对红外小目标检测算法的漏检率与虚警率高的问题,本文提出了基于深度展开对抗网络的红外小目标检测算法,其检测框架由生成对抗网络与深度展开网络构成,所设计的网络生成器部分由深度展开网络构成,因此被称为深度展开对抗网络。对于输入的红外图像则分别输入至两个生成器,生成器由深度展开网络构成,通过控制其展开层数可以分别有效地针对虚警和漏检两个问题。判别器则起到了监督的作用,能够有效地优化网络,提升整体检测效果。(2)本文针对红外小目标检测技术当前面临的挑战,还提出了一种基于自适应字典的多尺度编解码红外小目标检测网络,其整体结构由编解码网络与自适应字典变换模块构成。在检测过程中,红外图像首先被输入至编码网络,该网络会分别输出不同尺度的红外图像与特征图至解码网络,其中特征图由自适应字典变换模块处理输出,由于其原理类似于注意力机制,且获取通用键值的方式类似于查字典,因此被称为自适应字典变换。解码器则会将获取的输入进行融合,经过处理并得到最终检测结果。为了研究本论文所提出算法的性能及有效性,本文数据集采用了真实的红外背景图像,且涵盖范围广,包含不同天气情况、不同拍摄范围的红外图像,并通过主客观实验对比与分析,验证了本文所提出的红外小目标检测算法的有效性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001261
{DOI}: 10.27251/d.cnki.gnjdc.2023.001261
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于混合方式的室内老人跌倒检测系统的方法实现
{Author}: 钱庆庆
{Tertiary Author}: 李晓飞
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 跌倒识别;AlphaPose;情绪识别;决策层融合
{Abstract}: 根据我国进行第七次人口普查,目前我国60岁以上人口占比达18.7%,老龄化现象正在加剧,预计居家养老将是未来主要养老方式之一,统计研究表明,跌倒是独居老人威胁最大的意外之一,如何确保独居老人的居家安全已经成为当前主要研究热点之一。随着各种先进AI算法的提出,针对独居老人跌倒问题,采用多算法融合方案,快速准确地识别出监控视频中老人异常跌倒行为具有重要的研究意义。本文基于AlphaPose算法和情绪识别技术提出了一种视频跌倒识别方案,该方案最大程度地利用监控场景中的音视频信息,通过人脸识别、跌倒判断和情绪识别,在发生独居老人跌倒时,能及时将老人的身份信息以及是否需要救助的情况发送给家属和医疗机构,便于医疗机构根据跌倒者身份及时采取相应的救护措施,本文的主要研究内容如下:(1)针对原始的跌倒检测算法容易发生错误判断的情况,本文设计了一种决策层融合算法,将基于Alpha Pose模型得到的跌倒检测结果和基于LSTM模型得到情绪识别结果进行融合,通过实验获取不同算法结果的加权系数,确保最终跌倒判决的精度。实验表明,本文方法与单一Alpha Pose模型相比,提升了判决精度。(2)基于本文改进的融合算法,设计和实现了一种音视频联合跌倒判决的监控系统方案,采集室内环境下的监控视频,实现跌倒动作、身份信息和情绪识别等功能。实验结果表明,系统检测精度较高且能实时工作,达到预期设计要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001838
{DOI}: 10.27251/d.cnki.gnjdc.2023.001838
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的三维摄影测量技术研究
{Author}: 周庆森
{Tertiary Author}: 赵来定
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;相机标定;单目视觉;图像分割;双目视觉;立体匹配
{Abstract}: 近年来,随着信息技术、图像分析技术和计算机视觉技术的发展,机器视觉在各个领域得到了广泛应用。机器视觉通过图像采集、处理和分析技术,从图像中提取几何信息,实现对场景的三维感知。虽然机器视觉技术在图像测量领域有广泛应用,但目前大部分应用都只适用于特定的测量任务,并且设备成本较高。此外,如何解决工业测量中难以用传统测量方法测量尺寸的问题,是目前机器视觉领域研究的一个重要方向。本文使用集成两个工业相机的摄像设备,设计了基于机器视觉的三维摄影测量系统,实现了单目视觉的平面面积测量和双目视觉的立体高度测量。主要工作如下:1.单目与双目相机标定。相机标定是图像测量的首要任务,本文使用基于平面棋盘格的相机标定方法,进行单目与双目相机标定,并根据漂移误差对标定参数做出精度评估。在单目测量系统中利用相机参数实现图像去畸变以及三维重建。在双目测量系统中利用相机参数以及描述左右相机相对位置的旋转矩阵和平移向量,实现图像去畸变和左右图像的极线校正。2.单目相机获取深度信息,引入聚类算法进行平面面积测量。针对单目视觉中待测物平面在Z轴位置不确定的问题,采用约束方式确定平面深度,将整个平面的深度视为已知,克服了单目视觉无法获取深度信息的问题,实现目标点的三维重建。此外,针对待测物形状不规则的情况,本文采用了K-means聚类进行图像分割,提取待测物区域并计算其面积占比,实现了精准的面积测量。3.双目视觉引入约束信息进行特征点立体匹配。传统的特征点匹配算法对左右图像的所有信息进行检测匹配,运算量大并且误匹配率高。本文在特征点匹配前加入左右图像极线平行的约束条件,并使用改进的Canny算法对待测物提取上下边缘,将极线与上下边缘交点作为特征点,降低了特征点检测的计算量并且保证了匹配的准确性。4.测量系统的可视化设计。本文基于MATLAB平台的GUIDE(Graphical user interface design environment)设计了一套完整的可视化三维摄影测量系统。经过多次实验和测试,得出的结果表明,单目视觉测量系统在测量平面面积时误差在1%以内,双目视觉测量系统在测量高度时误差在1mm以内。测量精度可以满足大部分工业测量场景的需求。本文设计的基于机器视觉的三维摄影测量系统适用于皮革、纺织、木材、金属板材、橡胶等,对面积和高度厚度有测量需求的场景。实验结果表明,该系统能够实现精准的平面面积测量以及立体高度测量,具有一定的实用价值。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001898
{DOI}: 10.27251/d.cnki.gnjdc.2023.001898
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多尺度特征融合的人脸表情识别
{Author}: 楼亦墨
{Tertiary Author}: 卢官明
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人脸表情识别;多尺度特征融合;注意力机制;金字塔卷积;残差网络;深度学习
{Abstract}: 人脸表情识别作为计算机视觉中常见的研究领域之一,在人机交互等现实场景下有着重要的应用价值。目前在人脸表情识别领域依旧存在一些问题,比如基于深度学习的人脸表情识别虽然是目前的主流方法,但是在利用深度神经网络提取特征的阶段,随着网络层数的加深,网络的感受野逐渐变大,导致输出的特征图的分辨率变小,对细节的感知能力变差。多尺度特征融合技术对图像的浅层特征和深层特征进行融合,可以解决浅层特征语义性缺乏和深层特征细节丢失的问题。为了能够在图像上提取到更有效的特征,引入了注意力机制,让网络重点关注到对人脸表情识别有用的信息上去,提高人脸表情识别的准确率。本文对基于多尺度特征融合的人脸表情识别展开研究,主要的研究内容和创新工作如下:(1)针对深度神经网络存在的深层特征细节信息丢失和浅层特征语义信息缺乏等问题,提出了基于多尺度特征融合的人脸表情识别算法。在FER2013数据集上的实验结果表明,当采用VGG16、Inception-V3和Res Net50为主干网络时,基于多尺度特征融合的表情识别模型的准确率比基于单一特征的表情识别模型分别提升了0.79、1.02和0.50个百分点;在RAFDB数据集上的实验结果表明,当采用VGG16、Inception-V3和Res Net50为主干网络时,基于多尺度特征融合的表情识别模型的准确率比基于单一特征的表情识别模型分别提升了1.13、0.36和0.36个百分点,验证了多尺度特征融合的有效性。(2)为了进一步提高人脸表情识别性能,在网络中引入了注意力机制。提出了改进通道注意力模块和改进空间注意力模块,并将二者级联得到混合注意力模块。在FER2013数据集上的实验结果表明,当采用VGG16、Inception-V3和Res Net50为主干网络时,基于混合注意力的多尺度特征融合的表情识别模型的准确率比不加混合注意力的多尺度特征融合的表情识别模型分别提升了1.33、1.60和1.08个百分点;在RAF-DB数据集上的实验结果表明,当采用VGG16、Inception-V3和Res Net50为主干网络时,基于混合注意力的多尺度特征融合的表情识别模型的准确率比不加混合注意力的多尺度特征融合的表情识别模型分别提升了1.35、1.76和1.99个百分点,验证了混合注意力模块的有效性。(3)由于卷积运算的局域化,CNN固有的小感受野限制了其在全局上理解场景的能力,为了增大感受野,在网络中引入多头注意力来提高模型的人脸表情识别性能,提出了基于多头注意力的多尺度特征信息交互与融合模块。在RAF-DB数据集上的实验结果表明,当采用Res Net50为主干网络时,基于多头注意力的多尺度特征融合的表情识别模型能够获得82.99%的准确率,验证了多尺度特征信息交互与融合模块的有效性。(4)为了进一步提升网络提取特征的质量,在基于多头注意力的多尺度特征融合人脸表情识别模型中引入金字塔卷积,利用由不同大小和深度的卷积组成的残差模块替代Res Net50中的残差模块来对残差网络进行改进。在RAF-DB数据集上的实验结果表明,当采用Res Net50为主干网络时,基于多头注意力的多尺度特征融合的表情识别模型在引入金字塔卷积之后,模型准确率比未引入金字塔卷积的表情识别模型提升了3.57个百分点,验证了金字塔卷积的有效性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000403
{DOI}: 10.27251/d.cnki.gnjdc.2023.000403
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的煤尘环境下掘进空间煤岩界面感知与精准识别
{Author}: 张云;童亮;来兴平;曹胜根;闫保旭;刘永孜;孙浩强;杨彦斌;何伟
{Author Address}: 西安科技大学能源学院;中国矿业大学煤炭资源与安全开采国家重点实验室;
{Journal}: 煤炭学报
{Year}: 2024
{Volume}: 49
{Issue}: 07
{Pages}: 3276-3290
{Keywords}: 煤岩截割界面;SE-CA-DeepLabV3+;巷道掘进;煤岩识别平台;图像分割
{Abstract}: 巷道掘进过程中煤岩识别技术是掘进机截割头自动调整的核心，同样是制约矿山智能化建设的关键难题之一。针对当前采掘失衡，掘进工作面缺乏成熟有效的煤岩识别方案，现有基于图像的煤岩识别模型存在分割精度差、无法灵活部署等问题，提出一种应用在掘进工作面下基于图像分割的煤岩截割界面感知与精准识别方法。该方法结合掘进工作面实际截割情况，采用MobileNetV2特征提取网络作为DeepLabV3+的主干网络，使模型更好地兼顾分割精度和模型复杂度；将空洞空间卷积池化金字塔模块输出的高级特征进行通道注意力(SE)操作，分配通道权重以强化对重点特征信息的训练；在主干网络输出的浅层特征引入通道空间注意力(CA)机制，使浅层特征图中的低级表征信息加权，从而设计出融合双注意力机制于DeepLabV3+的煤岩截割界面识别模型。同时搭建煤尘环境下煤岩识别实验平台模拟掘进机截割后形成的煤岩截割面，研发巷道掘进过程中煤岩截割界面采集方法，并以实际矿井的掘进工作面为工程背景，验证该煤岩识别模型的分割精度以及实际应用性。研究结果表明：SE-CA-DeepLabV3+模型的平均交并比和平均像素精度分别为97.15%和98.51%，相较于其他模型具有更优的分割性能。将所建立模型对来自陕北试验矿井掘进工作面的原始煤岩图像进行验证，平均误差为0.7%，每秒传输帧数为43 fps，满足井下现场应用部署条件。
{ISBN/ISSN}: 0253-9993
{Notes}: 11-2190/TD
{URL}: https://link.cnki.net/doi/10.13225/j.cnki.jccs.2023.0677
{DOI}: 10.13225/j.cnki.jccs.2023.0677
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向多目标医疗垃圾分类的智能识别分拣系统设计
{Author}: 张歆羽;杨钟亮;周哲画;张凇;毛新华
{Author Address}: 东华大学机械工程学院;青岛虚拟现实研究院有限公司;曼彻斯特大学;北京中丽制机工程技术有限公司;
{Journal}: 智能系统学报
{Year}: 2024
{Volume}: 19
{Issue}: 03
{Pages}: 584-597
{Keywords}: 机器视觉;目标检测;Delta分拣系统;机械设计;人工智能;医疗垃圾;垃圾分类;智能垃圾箱
{Abstract}: 医疗垃圾中存在大量的病毒和细菌，为解决医疗垃圾源头智能分类问题，开发了基于机器视觉和Delta机构的智能分拣平台样机，并提出一种三阶段的多目标医疗垃圾识别分拣（medical waste recognition-indexes-sorting,MWRIS）算法。第1阶段提出数据增强扩容的IE-YOLOv4算法建立起医疗垃圾识别模型，与Faster R-CNN、RetinaNet、CenterNet等5种模型比较；第2阶段索引分类模型用于管理分类规则；第3阶段定位分拣算法指导目标定位分拣。在集成了MWRIS算法的分拣样机上，采集14种，2217张医疗样本图像，完成医疗垃圾分拣实验。结果表明，使用IE-YOLOv4的MWRIS算法对医疗垃圾识别准确率显著提升至99.30%，分拣实验对目标定位准确率达到96.17%，最终分类正确率为86.67%，验证了多目标医疗垃圾识别分拣系统的有效性。
{ISBN/ISSN}: 1673-4785
{Notes}: 23-1538/TP
{URL}: https://link.cnki.net/urlid/23.1538.TP.20231008.1504.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图神经网络的乳腺癌病理图像分析方法综述
{Author}: 陈思硕;王晓东;刘西洋
{Author Address}: 西安电子科技大学计算机科学与技术学院;
{Journal}: 计算机科学
{Year}: 2024
{Volume}: 51
{Issue}: 06
{Pages}: 172-185
{Keywords}: 乳腺癌病理图像;图神经网络;图分类;数字病理
{Abstract}: 病理诊断是癌症诊断和治疗过程中的金标准，利用人工智能模型对癌症病理图像进行自动分析不仅可以减轻病理学家的工作负担，还可以提高诊断结果的准确性。然而，病理图像的大尺度特点以及对预测结果可解释性的高要求为人工智能模型带来了巨大的挑战。在近年来的研究中，图神经网络在建模图像中实体的空间上下文关系及可解释性方面都展现出了强大的能力，为数字病理的研究提供了新的思路。文中回顾了近年来计算机视觉领域的相关工作，分析了图神经网络在乳腺癌病理图像分析中的优势，分类和比较了现有的面向乳腺癌病理图像的图构建方法，分析和对比了乳腺癌病理图像分析中的图神经网络模型，整理了近年来的研究中常用的工具包与公开数据集，总结了基于图神经网络的乳腺癌病理图像分析研究中存在的挑战并对未来的研究方向进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20231008.0915.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态特征融合的传输线路检测模型研究
{Author}: 季川茗
{Tertiary Author}: 叶绿;周武杰
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 智能无人机;传输线检测;目标检测;多模态;深度学习
{Abstract}: 随着我国《“十四五”国家安全生产规划》提出要积极推广使用先进的无人机巡查监察系统,基于无人机的传输线检测技术得到快速发展。由于搭载检察系统的无人机具有节省人力成本,时间成本,更便捷等优点,为工业检测和商业应用提供了帮助。其中,在复杂环境下比如山地和铁路上方利用无人机对输电线这一类传输线的感知和识别可代替人工,保障电力稳定供给供应。
随着人工智能的发展,深度学习被提出并在工业范围中取得重要应用,其中图像融合和目标检测作为深度学习中的重要视觉感知技术,可以帮助无人机高精度地完成识别传输线的任务。具体来说,图像融合可以预先将红外图和可视化图进行图片融合,为后续的识别任务提供更加优质的图像来源。而多模态目标检测技术可以在一些复杂场景比如雾霾,雨雪天,前后背景难以区分等情况下识别传输线。然而,目前的识别算法存在计算参数量大的问题,难以部署在移动设备上。因此,针对上述问题,本文首先研究多模态图像融合技术,来对可视化图和红外图进行图像融合,随后,本文对多模态融合检测技术以及知识蒸馏技术展开研究,提出单模态学生网络,以解决多模态的融合问题以及大模型难以部署在移动终端的问题。本文主要贡献如下:
(1)红外图像与可见光图像融合是计算机视觉中一个长期研究的课题,它突出了辐射和细节纹理信息,完整、准确地描述了物体。然而,大多数方法通常提取编码器段中的特征并使用粗糙的融合策略。与这些算法不同,本文使用卷积残差结构作为主干网和Uniformer作为辅助主干提取编码器段中的远程信息。此外,我们提出了一种基于注意力机制的有效多尺度融合策略来整合两种模式。
(2)为了构建一种适用于移动设备的有效目标检测算法,本文介绍了一种新型的双特征融合学生网络EDFNet-S*。该网络是专门为分析传输线检测(TLD)场景而设计的,采用交叉特征蒸馏。值得注意的是,该网络大大减少了模型的参数计数。此外,本文还提出了一种四输入融合模块,旨在熟练地整合上下文信息。该模块促进了浅层和深层特征的协同利用,有效解决了双模融合场景中上下文信息的监督问题。
(3)目前,现有的多模态融合算法对不同模态间没有精确配准,并且不能部署在RGB图像采集的无人机终端。为了解决这些问题,本文提出了基于知识蒸馏的双向引导配准算法(BGRNet-S*)用于传输线检测。该方法在教师网络的融合模块中引双向引导配准机制,并通过知识蒸馏和对比学习联合训练将双模态教师网络的知识传递给单模态学生网络,进一步减小了模型参数并能够在单RGB图像采集的无人机终端部署。
(4)为了学生网络学习到更多的不同的知识,充分发挥学生网络的潜力,我们设计了一种可以动态调整的多教师联合蒸馏的训练方法,并设计了多尺度整合模块使得学生充分学习到不同教师网络的不同纬度的信息。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000115
{DOI}: 10.27840/d.cnki.gzjkj.2024.000115
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的食品外包装缺陷检测算法研究进展
{Author}: 戈明辉;张俊;陆慧娟
{Author Address}: 中国计量大学信息工程学院;浙江省农业科学院食品科学研究所;
{Journal}: 食品与机械
{Year}: 2023
{Volume}: 39
{Issue}: 09
{Pages}: 95-102+116
{Keywords}: 食品包装;机器视觉;自动化;深度学习;缺陷检测算法
{Abstract}: 食品包装在生产过程中由于各种因素会导致缺陷产生，包装缺陷种类多，背景复杂。通过视觉成像和计算机信息处理完成包装的识别、检测和测量等任务的机器视觉检测，相比传统的人工检测，具有执行速度快、精度高等特点，可显著提高生产自动化程度。文章根据食品外包装常见缺陷，从缺陷检测算法的角度介绍传统机器视觉检测算法和深度学习相关算法在食品外包装缺陷检测中的研究应用，并对检测算法在食品外包装缺陷检测中的应用前景，以及存在的问题进行分析与展望。
{ISBN/ISSN}: 1003-5788
{Notes}: 43-1183/TS
{URL}: https://link.cnki.net/doi/10.13652/j.spjx.1003.5788.2022.80943
{DOI}: 10.13652/j.spjx.1003.5788.2022.80943
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO v7-tiny的甜椒畸形果识别算法
{Author}: 王昱;姚兴智;李斌;徐赛;易振峰;赵俊宏
{Author Address}: 华南农业大学工程学院;岭南现代农业科学与技术广东省实验室;广东省农业科学院设施农业研究所;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 11
{Pages}: 236-246
{Keywords}: 甜椒畸形果;YOLO v7-tiny;目标检测;机器视觉
{Abstract}: 甜椒在生长发育过程中容易产生畸形果，机器代替人工对甜椒畸形果识别和摘除一方面可提高甜椒品质和产量，另一方面可解决当前人工成本过高、效率低下等问题。为实现机器人对甜椒果实的识别，提出了一种基于改进YOLO v7-tiny目标检测模型，用于区分正常生长和畸形生长的甜椒果实。将无参数注意力机制(Parameter-free attention module, SimAM)融合到骨干特征提取网络中，增强模型的特征提取和特征整合能力；用Focal-EIOU(Focal and efficient intersection over union)损失替换原损失函数CIOU(Complete intersection over union),加快模型收敛并降低损失值；使用SiLU激活函数代替原网络中的Leaky ReLU,增强模型的非线性特征提取能力。试验结果表明，改进后的模型整体识别精确度、召回率、平均精度均值(Mean average precision, mAP)mAP0.5、mAP0.5-0.95分别为99.1%、97.8%、98.9%、94.5%,与改进前相比，分别提升5.4、4.7、2.4、10.7个百分点，模型内存占用量为10.6 MB,单幅图像检测时间为4.2 ms。与YOLO v7、Scaled-YOLO v4、YOLOR-CSP等目标检测模型相比，模型在F1值上与YOLO v7相同，相比Scaled-YOLO v4、YOLOR-CSP分别提升0.7、0.2个百分点，在mAP0.5-0.95上分别提升0.6、1.2、0.2个百分点，而内存占用量仅为上述模型的14.2%、10.0%、10.0%。本文所提出的模型实现了小体量而高精度，便于在移动端进行部署，为后续机械化采摘和品质分级提供技术支持。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230926.1554.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Transformer驱动的图像分类研究进展
{Author}: 石争浩;李成建;周亮;张治军;仵晨伟;尤珍臻;任文琦
{Author Address}: 西安理工大学计算机科学与工程学院;中山大学网络空间安全学院;
{Journal}: 中国图象图形学报
{Year}: 2023
{Volume}: 28
{Issue}: 09
{Pages}: 2661-2692
{Keywords}: Transformer;自注意力机制;深度学习;图像分类;可扩展位置编码
{Abstract}: 图像分类是图像理解的基础，对计算机视觉在实际中的应用具有重要作用。然而由于图像目标形态、类型的多样性以及成像环境的复杂性，导致很多图像分类方法在实际应用中的分类结果总是差强人意，例如依然存在分类准确性低、假阳性高等问题，严重影响其在后续图像及计算机视觉相关任务中的应用。因此，如何通过后期算法提高图像分类的精度和准确性具有重要研究意义，受到越来越多的关注。随着深度学习技术的快速发展及其在图像处理中的广泛应用和优异表现，基于深度学习技术的图像分类方法研究取得了巨大进展。为了更加全面地对现有方法进行研究，紧跟最新研究进展，本文对Transformer驱动的深度学习图像分类方法和模型进行系统梳理和总结。与已有主题相似综述不同，本文重点对Transformer变体驱动的深度学习图像分类方法和模型进行归纳和总结，包括基于可扩展位置编码的Transformer图像分类方法、具有低复杂度和低计算代价的Transformer图像分类方法、局部信息与全局信息融合的Transformer图像分类方法以及基于深层ViT(visual Transformer)模型的图像分类方法等，从设计思路、结构特点和存在问题等多个维度、多个层面深度分析总结现有方法。为了更好地对不同方法进行比较分析，在ImageNet、CIFAR-10(Canadian Institute for Advanced Research)和CIFAR-100等公开图像分类数据集上，采用准确率、参数量、浮点运算数（floating point operations,FLOPs）、总体分类精度（overall accuracy,OA）、平均分类精度（average accuracy,AA）和Kappa（κ）系数等评价指标，对不同方法模型的分类性能进行了实验评估。最后，对未来研究方向进行了展望。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwHRm4gPp3XHUo3ydgUgw-jZtGlSuH5XQpIgPktHisszWYmF2myBhHMJQzgHrX6hcKk8IMGpdLWjyjo3x4iuIlYrCXBoZoBVeBmtKnBqA2PX91C8xQCsBK1wTGDoVNTFq7zn3bOtyq9r3eCUrDqjsnt7pqK8Xn-80rBq9hXcvq3U8gUrIQdcXHgy0RhWQhbrAM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 柑橘采摘机器人图像识别算法研究
{Author}: 王大明;何逸霏;李华英;苟于江;何辉波
{Author Address}: 西南大学工程技术学院;
{Journal}: 中国农机化学报
{Year}: 2023
{Volume}: 44
{Issue}: 09
{Pages}: 222-226+264
{Keywords}: 柑橘采摘机器人;柑橘识别;Hough变换;机器视觉;收获机械
{Abstract}: 柑橘作为我国重要的水果对增加我国果农收入有重要的作用，因此柑橘的自动采摘机器人已经成为当下研究的热点。针对柑橘采摘机器人核心的机器视觉部分进行柑橘图像识别算法的设计，选取HSV颜色空间中的S分量值作为柑橘识别的颜色特征，进行图像增强、去噪和分割预处理操作。综合比较Canny、Sobel、LOG三种边缘算子下的Hough变换，最终确定柑橘图像识别的最优方案。试验结果表明：基于Sobel边缘检测算子下的Hough变换的柑橘识别算法最优，对单个无枝叶遮挡柑橘识别成功率为97%,单个有枝叶遮挡柑橘识别成功率为90%,多个柑橘果实重叠识别成功率为80.6%,在一定程度上能够有效保证柑橘采摘机器人对柑橘果实的成功识别。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2023.09.031
{DOI}: 10.13733/j.jcam.issn.2095-5553.2023.09.031
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于孪生网络的目标跟踪算法综述
{Author}: 马玉民;钱育蓉;周伟航;公维军;帕力旦·吐尔逊
{Author Address}: 新疆大学软件学院;新疆维吾尔自治区信号检测处理重点实验室;新疆大学软件工程重点实验室;新疆师范大学;
{Journal}: 计算机工程与科学
{Year}: 2023
{Volume}: 45
{Issue}: 09
{Pages}: 1578-1592
{Keywords}: 孪生网络;人工智能;计算机视觉;视觉目标跟踪
{Abstract}: 孪生网络是由2个或多个人工神经网络建立的耦合框架，因其将回归问题转换为相似度匹配问题，备受计算机视觉领域的研究人员关注。随着深度学习理论的快速发展，目标跟踪技术在生活中得到了广泛的应用。基于孪生网络的目标跟踪算法以其相对优越的准确率和实时性逐渐代替了传统的目标跟踪算法，成为目标跟踪的主流算法。首先，介绍了目标跟踪任务面对的挑战和传统方法；然后，介绍了孪生网络的基础结构及其发展，汇总了近年来基于孪生网络的目标跟踪算法与相应设计原理；另外，介绍多个用于目标跟踪测试的主流数据集，并基于这些数据集对比了基于孪生网络的目标跟踪算法的性能；最后，提出基于孪生网络目标跟踪算法目前存在的问题及对未来的展望。
{ISBN/ISSN}: 1007-130X
{Notes}: 43-1258/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvykdj6-JpknkA5jyebPiDM1IMThySWrk66ttoPcqi80if53c18f_RVSdgzpFoRg3R2TPXKcPVLtTY-JELwNtp01YY2xTza7XYPpYloPKnwV0wECUeQi4oj3OXKdhSzBUAppGzX2MPkCv_9-NUn4pjeUVtLDyxLAo3Ewheu8VgH1p2beW049UhYtZ66jwE0lQzU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的养殖动物计数方法研究综述
{Author}: 王静;李蔚然;刘业强;李振波
{Author Address}: 中国农业大学信息与电气工程学院;中国农业大学国家数字渔业创新中心;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: S1
{Pages}: 315-329
{Keywords}: 养殖动物;计数;机器学习;深度学习;计算机视觉
{Abstract}: 数量计量是动物养殖管理的基础工作，其结果对于动物养殖的生产效率、养殖成本管控及经济效益评估等具有重要意义。基于计算机视觉的计数方法解决了传统人工计数存在的测量误差大、耗时费力等问题，减轻了养殖人员的工作负担。本文统计分析了近十年的养殖动物视觉计数相关研究，从传统机器学习与深度学习两方面对养殖动物计数算法进行分析与讨论。此外，对水产养殖、畜禽养殖与特种动物养殖领域的养殖动物计数应用进行梳理与总结。同时，对目前公开发布的养殖动物计数数据集进行概述。最后，从数据集、应用场景、计数方法3方面分析讨论养殖动物计数研究面临的主要挑战，并对未来研究进行展望。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230911.1752
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与PLC的工业零件自动检测及分拣系统
{Author}: 丁江涛;王帅;王强
{Author Address}: 池州学院集成电路与嵌入式应用研究中心;马鞍山学院人工智能创新学院;
{Journal}: 蚌埠学院学报
{Year}: 2023
{Volume}: 12
{Issue}: 05
{Pages}: 82-87
{Keywords}: 目标检测;PLC控制器;深度学习;自动分拣
{Abstract}: 以西门子S7-1200PLC为控制核心，结合深度学习目标检测算法，构建了一套基于机器视觉的工业零件自动分拣系统。传统工业分拣系统在进行分类与位置信息确定时需要分步进行，采用端到端目标检测算法在分类的同时获得物体的位置坐标。视觉模块将数据位置与类别信息输送至机器人控制系统中为后续机械臂抓取做准备，同时视觉模块判断输送带是否存在零件，将指令输入至PLC控制器中，进而控制输送带以及非标设备的工作状态。实验结果表明，利用目标检测算法最终的分拣准确度为91.1%,抓取速度可以达到1.3 s/个。
{ISBN/ISSN}: 2095-297X
{Notes}: 34-1321/Z
{URL}: https://link.cnki.net/doi/10.13900/j.cnki.jbc.2023.05.010
{DOI}: 10.13900/j.cnki.jbc.2023.05.010
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于差分特征学习与注意力机制的图像变化检测方法及应用研究
{Author}: 薛丁华
{Tertiary Author}: 雷涛
{Publisher}: 陕西科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 图像变化检测;差分特征学习;注意力机制;对地监测;油藏驱替
{Abstract}: 图像变化检测是通过对比分析同一视角位置不同时期获取的图像,提取并分析差异特征,最后识别变化区域的过程。近年来,图像变化检测技术已被广泛应用于军事、农业、环境监测、工业评估等领域。其中,基于遥感技术的快速发展,图像变化检测方法已经成为全球地表变化研究中的前沿技术,可以帮助人们更好的了解地球表面的动态变化。同时,将图像变化检测方法应用于驱油路径检测,能为评估驱替剂性能以及油藏模拟技术提供数据支撑。尽管现阶段已涌现出大量的图像变化检测研究工作,然而这些方法在实际应用中仍面临以下挑战:(1)当前变化检测方法在特征提取过程中存在差分特征信息表达不足问题,导致算法难以有效区分伪变化特征信息和应对复杂变化场景检测任务;(2)当前变化检测方法存在模型复杂度较高,在实际任务中部署较难问题。针对以上问题,本论文开展基于差分特征学习与注意力机制的图像变化检测方法及应用研究,为遥感对地监测和油藏驱替评估提供技术保障。本论文的主要工作和贡献总结如下:(1)基于差分特征学习及核尺度自适应注意力的图像变化检测方法针对传统注意力机制忽略了不同特征图的尺度差异并限制了注意力机制的空间灵活性问题,提出了差分特征学习及核尺度自适应注意力图像变化检测方法。该方法首先利用特征映射和卷积核尺度之间的关系,设计了尺度自适应注意力模块以有效获取差分特征信息。其次,该方法提出基于图像块嵌入的多层感知器模块,通过跳跃连接方式学习局部和全局像素关联,实现低层和高层特征的深度融合,以缩小高低级特征之间的语义差距问题。与普通注意力模块相比,该模块具有较强的特征识别能力,且具有较强的全局特征学习能力。在遥感影像数据集和驱油图库上的实验结果表明,所提出的变化检测方法具有较好的检测性能,模型参数为13.10MB,模型大小为37.13MB,平均检测精度为90.25%,且能够提供具有更精确轮廓的变化区域。同时消融实验结果和分析进一步验证了所提出变化检测方法在遥感影像数据集和驱油图库上的有效性和适用性,为提升对地监测方法性能、驱替理论的完善及应用提供技术保障。(2)基于Transformer特征学习及信息索引的深度监督图像变化检测方法针对传统变化检测方法难以考虑特征空间信息问题,提出Transformer特征学习及信息索引的深度监督图像变化检测方法。该方法首先在网络编码阶段进行特征学习,同时保留特征索引信息,并结合Transformer多头注意力机制学习变化信息的长程依赖关系。其次,在解码阶段利用深度监督策略从多尺度特征图聚合角度学习变化特征的高级语义特征信息,同时利用特征索引信息,将不同分辨率特征图恢复到较大分辨率特征图,最后经过深度监督模块生成变化映射结果。实验结果和消融实验结果表明,所提出方法能学习差分特征信息的长程依赖关系;并改善低分辨率特征图直接映射到原始分辨率导致特征空间位置信息不足问题。与同类别方法相比较,模型参数、模型大小居中,分别为41.85MB和146.92MB。同时在本文数据集上的平均检测精度提升到90.39%,与最优对比方法相比,平均精度值提升了 1.09%。最后本论文验证了所提出变化检测方法在遥感影像数据集和驱油图库上的有效性。为对地监测和评估驱替剂性能提供经验和数据支持。(3)基于孪生Swin-Transformer跨尺度差分特征信息的图像变化检测方法针对当前变化检测网络复杂度较高且难以充分利用双时相图像特征问题,提出基于孪生Swin-Transformer的跨尺度差分特征信息图像变化检测方法。首先,该方法利用权值共享的孪生网络分别提取双时相特征信息,来更好的捕捉图像中不同尺度和层次的变化特征信息。其次,在特征提取阶段,设计了跨尺度差异特征注意力模块,该模块通过对当前层特征信息以及前一层特征信息进行卷积操作和注意力信息获取,并进行信息融合。最后结合多尺度特征聚合解码模块以实现最终的变化检测结果。该方法具有较强的网络特征识别能力,且能使相邻层特征信息相互引导,以获得更丰富的差分特征信息。相关实验结果和消融实验结果表明,所提出方法在变化检测任务上具有较好的检测精度和视觉效果,模型参数和模型大小分别为21.57MB和53.89MB,在本论文相关数据集上的平均检测精度提升到90.51%,与最优对比方法相比,平均精度值提升了 1.21%。同时验证了该方法在遥感影像数据集和驱油图库上的有效性,为对地监测技术,驱替剂性能评估以及流体渗流特征规律的探索奠定理论基础。(4)基于联合多频谱信息的全尺度Swin-Transformer图像变化检测方法针对当前变化检测方法模型复杂度较高、部署难度较大及检测结果细节不清晰和边界模糊问题,提出基于联合多频谱信息的全尺度Swin-Transformer图像变化检测方法。首先,该方法通过设计多频谱通道注意力模块来获取更全面的双时相特征信息,并提高建模特征图通道相关性的能力。其次,基于多频谱通道注意力模块设计和变化检测任务的实际需求,构建了联合多频谱差分特征增强引导块以实现差分特征学习。此外,与基于孪生网络的方法不同,该方法设计了一个全尺度Swin-Transformer模块作为第三个特征提取分支,并结合金字塔解码模块来建模多尺度变化目标的长程依赖关系。该方法弥补了仅执行全局平均池化操作导致的特征表示不足的问题,并增强了模型对真实变化目标的位置感知能力。实验结果表明该方法可以有效地克服小目标漏检变化区域问题,进而实现更完整和紧凑的变化区域。所提出方法在相关数据集上的平均检测精度提升到91.81%,且对应了较小的模型复杂度,模型参数和模型大小分别为11.13MB和43.54MB。同时验证了该方法在遥感影像数据集和驱油图库上的有效性和适用性,可为深度研究对地监测技术、驱替机理的发展提供技术支撑。
{URL}: https://link.cnki.net/doi/10.27290/d.cnki.gxbqc.2023.000548
{DOI}: 10.27290/d.cnki.gxbqc.2023.000548
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的钢结构表面锈蚀程度检测方法
{Author}: 逯鹏;赵天淞;王剑;常好诵;郑云;刘小兰
{Author Address}: 中冶检测认证有限公司;中冶建筑研究总院有限公司;天津城建大学;
{Journal}: 工业建筑
{Year}: 2024
{Volume}: 54
{Issue}: 08
{Pages}: 133-139
{Keywords}: 钢结构;表面锈蚀;损伤检测;计算机视觉;滑动窗口法
{Abstract}: 针对钢结构表面锈蚀损伤,传统的人工检测方法耗时、费力,且受检测人员技术水平限制。计算机视觉技术为钢结构表面锈蚀的检测和分类提供了一种快速准确的替代方法。目前常用的锈蚀程度检测技术多基于卷积神经网络结构,由于网络结构自身的缺陷,在进行锈蚀程度分类时存在忽略图像中部分锈蚀特征的问题,导致错误的检测结果。为此,提出了一种基于Vision Transformer网络结构的钢结构表面锈蚀程度识别方法,通过引入自注意力机制(SA)在进行特征提取的过程中保证数据的完整性,并在自建的锈蚀程度图像数据集上进行验证,该方法对锈蚀程度的分类准确率可达到90%。此外,还提出一种基于滑动窗口法的钢结构表面锈蚀程度检测方法,对待检测的钢结构图像进行切割,利用训练好的网络结构进行锈蚀程度检测,将检测后的图像重新拼接,实现钢结构表面锈蚀程度的可视化。
{ISBN/ISSN}: 1000-8993
{Notes}: 11-2068/TU
{URL}: https://link.cnki.net/urlid/11.2068.TU.20230830.2032
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的自然场景文本检测综述
{Author}: 连哲;殷雁君;云飞;智敏
{Author Address}: 内蒙古师范大学计算机科学技术学院;
{Journal}: 计算机工程
{Year}: 2024
{Volume}: 50
{Issue}: 03
{Pages}: 16-27
{Keywords}: 深度学习;计算机视觉;自然场景文本;文本检测;多方向文本检测;多尺度文本检测
{Abstract}: 基于深度学习的自然场景文本检测技术已成为计算机视觉和自然语言处理领域的重要研究方向，不仅具有广泛的应用前景，而且也为研究人员提供了一个探索神经网络模型和算法的新平台。首先，介绍自然场景文本检测技术的相关概念、研究背景和发展现状。接着，分析近年来基于深度学习的文本检测方法并将其分为基于检测框、基于分割、基于两者混合、其他4类，阐述4类经典和主流方法的基本思路和主要算法流程，归纳总结不同方法的使用机制、适用场景、优劣点及仿真实验结果和环境设置，明确不同方法之间的关联关系。然后，介绍自然场景文本检测的常用公共数据集和文本检测性能评估方法。最后，指出基于深度学习的自然场景文本检测技术目前所面临的主要挑战并对其未来发展方向进行展望。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0067427
{DOI}: 10.19678/j.issn.1000-3428.0067427
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在动物行为分析中的应用研究进展
{Author}: 申通;王硕;李孟;秦伦明
{Author Address}: 上海电力大学电子与信息工程学院;中国科学院上海微系统与信息技术研究所;
{Journal}: 计算机科学与探索
{Year}: 2024
{Volume}: 18
{Issue}: 03
{Pages}: 612-626
{Keywords}: 动物行为分析方法;深度学习;动物姿态估计
{Abstract}: 近年来动物行为分析已成为脑科学与人工智能等领域的重要研究手段之一，研究者基于深度学习的图像分析技术，构建了自动化、智能化的动物行为分析方法。相较于传统的动物行为分析方法，该类方法无需对动物进行特殊标记，可高效地对动物的姿态进行估计和跟踪，实验情景贴近自然情况，为复杂的动物行为实验提供了潜在可能性。对深度学习在动物行为分析中的应用研究进行综述，首先简要分析动物行为分析的任务及现状；然后重点介绍并比较现有的基于深度学习的动物行为分析工具，根据实验分析的行为维度，将该类工具分为二维的动物行为分析工具和三维的动物行为分析工具，并对工具的功能、性能以及适用范围进行论述；进而介绍了现有的动物数据集和评价指标，对现有的动物行为分析工具所利用的算法机制从优势、局限性、适用场景做出总结；最后，从数据集、实验范式和低延时性等方面对基于深度学习的动物行为分析工具做出展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20230824.1838
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV和PyQt的数字图像处理综合实验平台开发
{Author}: 江健;张琪;王财勇
{Author Address}: 中国人民公安大学;北京建筑大学;
{Journal}: 电脑知识与技术
{Year}: 2023
{Volume}: 19
{Issue}: 24
{Pages}: 6-8+13
{Keywords}: 数字图像处理;计算机视觉;OpenCV;PyQt;综合实验平台
{Abstract}: 为了帮助学生更好地理解和掌握数字图像处理的基本理论和方法，文章基于OpenCV和PyQt设计开发了一个数字图像处理综合实验平台，包含图像基本操作、图像增强、图像复原、图像分割、形态学等模块，各个模块涵盖了数字图像处理的经典算法，并且提供了可视化界面显示图像处理的结果以及可交互的参数选择界面调整算法的性能。该实验平台不仅能有效提升教学效果，而且能帮助学生充分理解图像处理知识，激发学生学习兴趣。
{ISBN/ISSN}: 1009-3044
{Notes}: 34-1205/TP
{URL}: https://link.cnki.net/doi/10.14004/j.cnki.ckt.2023.1253
{DOI}: 10.14004/j.cnki.ckt.2023.1253
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人脸识别的智慧教室学生考勤系统设计
{Author}: 李国平;李小纳
{Author Address}: 广东碧桂园职业学院;东莞职业技术学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2023
{Volume}: 35
{Issue}: 16
{Pages}: 130-132
{Keywords}: 人脸识别算法;学生考勤;身份验证;实时识别
{Abstract}: 传统的学生签到与考勤方式存在着许多问题，如教师人工签到不便，学生代签到、漏签到和误签到等。为了解决这些问题并提高考勤的准确性和效率，文章引入人脸识别技术作为改进方案。该系统通过采集学生的人脸数据，使用先进的人脸识别算法进行实时识别和身份验证，既能够自动准确地记录学生的签到情况，又高效地减轻教师的工作负担。本研究探索了基于人脸识别技术的智慧教室学生考勤系统的设计与实现，展示了其在教育领域的潜在应用价值。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyOrZnFHAM6nc7kXbCxmNN4oQKuiNahizfsluppLmOU8ohK3GF5hvQmO23jaIk-jiU9zM3WjTSN7tOrTUIpZ0oCkeK1caPWrnNjFRtU0beZTI56bYha3n6tCF17RogNBEUhPOsuqTktaVL0q-CkFfLjjEdol7NWmXAuBqwXP63fkpUjX_68VGkxKbyVBckCj-0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的烟草在线检测技术研究进展
{Author}: 吴玉生;李安虎;万亚明;孟天晨
{Author Address}: 厦门烟草工业有限责任公司;同济大学机械与能源工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2024
{Volume}: 61
{Issue}: 08
{Pages}: 49-62
{Keywords}: 机器视觉;图像识别;深度学习;在线检测;瑕疵剔除
{Abstract}: 烟草行业高端产品规模的扩大与消费者对产品质量需求的提高，给烟草在线检测技术带来了巨大挑战。针对烟草生产过程中烟丝异物难以剔除，影响卷烟口感、烟草叶片病情害种类繁多且病情复杂、卷烟外包装瑕疵难以识别等问题，传统人工在线检测方法效率低下，且正确率难以保证，无法适应我国烟草行业的高质量发展。在阐明基于机器视觉的烟草在线检测原理的基础上，围绕视觉检测原理和深度学习模型两个方面系统地阐述烟草在线检测技术的研究现状与最新进展，结合现有典型应用分析不同视觉模型以及深度学习模型检测方法的优越性和局限性，进而探讨基于机器视觉的烟草在线检测技术的发展趋势和前景。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230821.1402
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉Transformer在低级视觉领域的研究综述
{Author}: 朱凯;李理;张彤;江晟;别一鸣
{Author Address}: 长春理工大学物理学院;长春理工大学中山研究院光电/生物纳米检测与制造中心;长春理工大学电子信息工程学院;吉林大学交通学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 04
{Pages}: 39-56
{Keywords}: Transformer;深度学习;注意力机制;计算机视觉;低级视觉任务
{Abstract}: Transformer是一种革命性的神经网络模型架构，最初为自然语言处理而设计，但其由于卓越的性能，在计算机视觉领域获得了广泛的应用。虽然关于Transformer在自然语言处理领域的应用有大量的研究和文献，但针对低级视觉任务的综述相对匮乏。简要介绍了Transformer的原理并分析归纳了几种变体。在低级视觉任务的应用方面，将重点放在图像恢复、图像增强和图像生成这三个关键领域。通过详细分析不同模型在这些任务中的表现，探讨了它们在常用数据集上的性能差异。对Transformer在低级视觉领域的发展趋势进行了总结和展望，提出了未来的研究方向，以进一步推动Transformer在低级视觉任务中的创新和发展。这一领域的迅猛发展将为计算机视觉和图像处理领域带来更多的突破，为实际应用提供更加强大和高效的解决方案。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230817.1249
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器学习的计算机视觉应用
{Author}: 沈一心
{Author Address}: 利兹大学;
{Journal}: 电脑编程技巧与维护
{Year}: 2023
{Volume}: 
{Issue}: 08
{Pages}: 109-111
{Keywords}: 计算机视觉处理;机器学习;艺术风格
{Abstract}: 对于图像的计算机视觉处理而言，机器学习的合理应用至关重要。为确保机器学习算法及其相关技术在计算机视觉处理中的应用效果，研究者与技术人员需要对其主要的应用策略展开深入研究。主要分析了计算机视觉处理中的机器学习技术应用，包括机器学习在艺术风格迁移、图像内容定义、图像内容重构及图像风格定义等计算机视觉处理中的应用策略。
{ISBN/ISSN}: 1006-4052
{Notes}: 11-3411/TP
{URL}: https://link.cnki.net/doi/10.16184/j.cnki.comprg.2023.08.038
{DOI}: 10.16184/j.cnki.comprg.2023.08.038
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的物流自动分拣系统设计
{Author}: 李菁
{Author Address}: 西安职业技术学院;
{Journal}: 自动化技术与应用
{Year}: 2023
{Volume}: 42
{Issue}: 08
{Pages}: 34-37+41
{Keywords}: 机器视觉;物流分拣;自动分拣系统;图像数据
{Abstract}: 以降低现有系统抓取物品的坐标偏差和物流分拣错误率为目标，设计基于机器视觉的物流自动分拣系统。该系统通过工业相机与图像采集卡实时捕捉物品的图像信号，通过计算机软件处理为图像数据，用作机械手抓取识别使用；采用皮带传送装置将物品进行实时传送，并通过机械手控制程序与机器视觉引导程序完成物品的自动分拣，剔除不合格产品，并将其传输至物品回收槽，验证结果表明：该系统图像采集时间短、图像质量高；抓取物品的坐标偏差角度小，不同数量和类别物品正确识别率较高，分拣错误率较低。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2023)08-0034-05
{DOI}: 10.20033/j.1003-7241.(2023)08-0034-05
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉中角点检测算法研究
{Author}: 尚硕;曹建荣;汪明;郑学汉;高鹤
{Author Address}: 山东建筑大学信息与电气工程学院;山东正晨科技股份有限公司;
{Journal}: 计算机测量与控制
{Year}: 2024
{Volume}: 32
{Issue}: 01
{Pages}: 217-225
{Keywords}: 角点检测;运动检测;图像匹配;视频跟踪;三维重建;目标识别
{Abstract}: 角点检测是运动检测、图像匹配、视频跟踪、三维重建和目标识别等必不可少的关键步骤，角点检测的准确性直接影响实验结果；为了更好地了解角点检测技术的发展现状，根据3种现有的角点检测方法分类对角点检测方法及相关改进进行了总结分析，并选择了FAST、SUSAN、SIFT、Shi-Tomas这几种较为典型的角点检测算法进行了实验对比，并给出了实验结果；不同的实际应用对角点检测的要求不同，不同的角点检测算法也可以相互结合，通过对现有角点检测技术的总结分析为在实际应用中对角点检测技术的选择和改进方向提供了借鉴和参考。
{ISBN/ISSN}: 1671-4598
{Notes}: 11-4762/TP
{URL}: https://link.cnki.net/doi/10.16526/j.cnki.11-4762/tp.2024.01.031
{DOI}: 10.16526/j.cnki.11-4762/tp.2024.01.031
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人智能分拣系统设计与实现
{Author}: 周宇权
{Author Address}: 广西机电职业技术学院;
{Journal}: 电子制作
{Year}: 2023
{Volume}: 31
{Issue}: 16
{Pages}: 107-110
{Keywords}: 机器视觉;工业机器人;智能分拣系统;设计;实现
{Abstract}: 在我国经济地快速发展，我国的工业自动化水平也在得到逐步提升。众所周知，在工业自动化中，自动分拣是非常重要的一个环节。传统的工业机器人分拣精确度不高，工业化生产需求难以得到充分满足。在本文中，笔者基于机器视觉设计了新的工业机器人自动分拣系统。该系统分为两大部分，一部分是硬件部分，该部分包括了硬件总体框架和机器人视觉分拣系统。另外一部分是软件部分，该部分不仅能够处理工业机器人自动分拣图像，而且能够基于机器视觉识别自动分拣工件类型。设计了工业机器人自动分拣程序，实现了工业机器人智能自动分拣。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2023.16.021
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2023.16.021
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉下的旋转目标检测研究综述
{Author}: 王旭;吴艳霞;张雪;洪瑞泽;李广生
{Author Address}: 哈尔滨工程大学计算机科学与技术学院;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 08
{Pages}: 79-92
{Keywords}: 计算机视觉;深度学习;目标检测;旋转目标;性能比较
{Abstract}: 传统目标检测器通过水平边界框(Horizontal Bounding Box, HBB)定位目标，在检测方向角任意、分布密集、长宽比大、背景复杂的目标时，往往精度较低、泛化能力较差。在边界框中增加不同旋转角度的旋转目标框可有效解决上述问题，其被广泛应用在遥感图像、场景文本图像、货架商品图像等目标检测领域，具有重要研究价值。目前大多数工作旨在构建不同的旋转目标检测模型，对现有模型的归纳总结及深入分析的综述性工作较少。为此，对旋转目标检测现有研究成果进行了详细综述。首先根据当前流行的目标框表征方式，将目标框分为旋转矩形框(Oriented Bounding Box, OBB)、四边形边界框(Quadrilateral Bounding Box, QBB)和点集(Point set) 3种类型，并比较了不同旋转目标检测算法的优缺点、网络结构和性能；其次分析了目前常用的旋转目标检测数据集和性能评价指标；最后对目前研究中存在的问题进行简要总结和讨论，并对未来的发展趋势进行展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy0QoxpVqtsO9qAMb7uvAXaMZS9PolzT0bGLDkfm6SHfO_T0h6oNraGaRxfDeCW6wRIq-zqF1RIsbsmow_BGoZMU-WX_coMevhQfbYqJueHmH1_7wSjZf-PBEWhpVB-YLECLrW6Oxnxcj4QFL-PwT11XXD4vgbxiYdQK3cGpYIhcGm_jw_1-jIet0f9EjLBqjM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉结构健康监测的研究进展及在大型游乐设施上的应用展望
{Author}: 于宗营;沈功田;赵章焰;吴占稳;刘渊
{Author Address}: 武汉理工大学交通与物流工程学院;中国特种设备检测研究院国家市场监管重点实验室(特种设备安全与节能);
{Journal}: 机械工程学报
{Year}: 2023
{Volume}: 59
{Issue}: 16
{Pages}: 167-181
{Keywords}: 计算机视觉;主要组成;应用现状;结构健康监测;大型游乐设施
{Abstract}: 在生产生活中，设备设施结构安全对保障国家经济运行和人民日常生活至关重要。结构健康监测能够有效的提高设备设施结构的安全性和稳定性。随着计算机视觉测量技术的发展和硬件水平的提升，基于计算机视觉测量的结构健康监测技术受到越来越多的关注。计算机视觉测量已经被广泛应用于结构的表面缺陷、空间坐标、位移、拉索索力等监测领域中，但是在大型游乐设施的结构健康监测中应用较少。介绍计算机视觉概况，综述了研究进展并进行了应用展望。首先，通过时间顺序梳理了计算机视觉的发展历程；然后概述了计算机视觉测量的硬件组成和软件组成部分，指出各组成部分的主要特征；主要分类介绍计算机视觉测量技术在各领域的应用现状，并与传统测量方法对比分析，概括各种方法的特点和不足；最后对计算机视觉测量技术在大型游乐设施结构健康监测中的应用做出展望，指出了计算机视觉测量技术在大型游乐设施结构健康监测中的主要研究方向和重点任务。
{ISBN/ISSN}: 0577-6686
{Notes}: 11-2187/TH
{URL}: https://link.cnki.net/urlid/11.2187.TH.20230824.1144
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的手机盖板表面缺陷检测系统设计
{Author}: 崔焱;彭可;杨玉娥;代礼奇;刘明
{Author Address}: 湖南师范大学工程与设计学院;
{Journal}: 制造业自动化
{Year}: 2023
{Volume}: 45
{Issue}: 07
{Pages}: 75-79+96
{Keywords}: 机器视觉;缺陷检测;圆度误差;图像差分;模板匹配
{Abstract}: 针对手机盖板在实际生产过程中产生的缺陷，提出了基于机器视觉的手机盖板表面缺陷检测系统。首先，利用机械臂和CMOS工业相机搭建系统硬件平台，对手机盖板检测图像进行采集。然后，采用高斯滤波、最大类间方差法以及Canny边缘检测对待检测图像进行预处理。最后，针对不同的缺陷采用不同的方法进行检测，采用最小二乘法的IR孔圆度误差判定方法对IR孔不良缺陷进行检测；采用图像差分算法对油墨点缺陷进行检测；对于LOGO不良缺陷，提出一种改进的模板匹配检测方法，改进了传统的模板匹配算法并引入自动寻边算法。实验结果表明，即使在有误差的情况下系统也能够准确的检测出手机盖板表面缺陷。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwo0JDFNdxpJoVrtbVYMB3PebDZ52fIDH2keNCRHaERq2zyvi-61CrMcxoloQ3FcYwr8QmhqzckXadgJcAHL7epsKaD62y6ZDzpiEigeUYJrp3xPbYuNICuITvH_fsXZ3KQHttXdn5RbjJrn8uRTbf4Bvm-PCcufiKboV2o_vfcDndRFbkteTCOeT3alERUDQM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业害虫智能视觉检测研究综述
{Author}: 王春桃;梁炜健;郭庆文;钟浩;甘雨;肖德琴
{Author Address}: 华南农业大学数学与信息学院;农业农村部华南热带智慧农业技术重点实验室;广东省农业人工智能重点实验室;广州市智慧农业重点实验室;
{Journal}: 中国农机化学报
{Year}: 2023
{Volume}: 44
{Issue}: 07
{Pages}: 207-213
{Keywords}: 虫情监测;计算机视觉;目标检测;机器学习;深度学习
{Abstract}: 农业害虫智能视觉检测是实现虫情自动实时监测的重要技术，首先介绍经典机器学习技术在国内外害虫智能视觉检测中的应用，然后整理以R-CNN、Fast R-CNN、Faster R-CNN、SSD和YOLO等深度学习技术为核心的新一代害虫智能视觉检测方法的研究进展。接着，剖析农业害虫智能视觉检测方法在研究及实际应用中存在的问题，其中基于经典机器学习的方法存在特征捕获能力和检测精度较低、资源消耗较大以及鲁棒性较弱等问题；基于深度学习的方法比基于经典机器学习的方法拥有更高检测性能，但存在数据分布不同和目标较小时识别效果较差、检测精度低和速度慢等问题。最后，针对基于深度学习的方法在农业昆虫数据库的制作、数据分布偏移的鲁棒性处理、深度特征学习、多场景应用4个方面对未来研究方向进行展望。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2023.07.028
{DOI}: 10.13733/j.jcam.issn.2095-5553.2023.07.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向计算机视觉的吸烟检测方法研究综述
{Author}: 何嘉彬;李雷孝;林浩;徐国新
{Author Address}: 内蒙古工业大学数据科学与应用学院;内蒙古自治区基于大数据的软件服务工程技术研究中心;天津理工大学计算机科学与工程学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 01
{Pages}: 40-56
{Keywords}: 计算机视觉;吸烟检测;目标检测;行为识别
{Abstract}: 公共场所吸烟严重危害人们身体健康甚至生命财产安全，因此实时高效的吸烟检测具有重要意义。目前基于计算机视觉的吸烟检测以高效率、高精度等优势逐渐成为主流方法。在对非计算机视觉的吸烟检测方法进行简要概述的基础上，重点归纳总结了三类基于计算机视觉的检测方法。探讨了颜色、外观、运动等多种烟雾特征的提取方法；介绍了基于单步骤和多步骤目标检测两种方法提取烟支目标；从人工特征构建、深度学习特征提取角度论述不同类型的吸烟动作特征提取方法。对上述方法进行分析总结并展望未来研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230706.1345.026
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 医学CT影像超分辨率深度学习方法综述
{Author}: 田苗苗;支力佳;张少敏;晁代福
{Author Address}: 北方民族大学计算机科学与工程学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 03
{Pages}: 44-60
{Keywords}: 超分辨率;医学CT影像;深度学习;计算机视觉;神经网络
{Abstract}: 图像超分辨率（SR）是计算机视觉领域提高图像分辨率的重要处理方法之一，在医学图像领域有重要的研究意义和应用价值。高质量和高分辨率的医学CT影像在当前的临床过程中非常重要。近年来，基于深度学习的医学CT影像超分辨率重建技术取得了显著的进展，对该领域内的代表性方法进行了梳理，系统回顾了医学CT影像超分辨率重建技术的发展。介绍了SR基本理论，给出常用的评价指标；重点阐述基于深度学习的医学CT影像超分辨率重建方向的创新与进展，对各个方法的主要特点和性能进行了综合比较分析。最后，讨论了医学CT影像超分辨率重建方向上存在的困难和挑战，并对未来的发展趋势进行了总结与展望，希望能为相关研究提供参考。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230706.0857.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的谷物品种识别研究进展
{Author}: 陈卫东;范冰冰;王莹;刘超;李宛玉
{Author Address}: 河南工业大学信息科学与工程学院;河南工业大学粮食储运国家工程研究中心;
{Journal}: 河南工业大学学报(自然科学版)
{Year}: 2024
{Volume}: 45
{Issue}: 01
{Pages}: 133-142
{Keywords}: 谷物品种识别;机器视觉;机器学习;深度学习
{Abstract}: 品种纯度是谷物种子重要的质量指标，种子质量安全直接关乎国家粮食安全。国标规定的品种纯度鉴定采用形态鉴定法和苯酚染色法，鉴定结果受制于检验人员的经验且耗时较长。近年来，机器视觉技术和机器学习、深度学习算法发展迅速，在谷物品种识别和纯度、净度检测中取得了较大进展。主要从图像采集、图像预处理以及机器学习、深度学习技术在谷物品种识别领域的应用等方面进行归纳，分析了目前取得的研究成果以及存在的问题，对该领域未来研究重点进行了展望。
{ISBN/ISSN}: 1673-2383
{Notes}: 41-1378/N
{URL}: https://link.cnki.net/doi/10.16433/j.1673-2383.2024.01.017
{DOI}: 10.16433/j.1673-2383.2024.01.017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的文本引导图像生成研究
{Author}: 杨杰
{Tertiary Author}: 刘涵
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 生成对抗网络;文本生成图像;三元注意力机制;匹配感知梯度惩罚;条件密集调制块;BERT文本编码器
{Abstract}: 相比于抽象复杂的文本信息,人们更容易理解生动形象的图像信息,因为图像信息能够更好地突出重点。但是,获得与文本信息匹配的图像信息却更为困难。文本引导图像生成任务需要综合运用计算机视觉和自然语言处理两个领域,属于交叉领域研究,该任务根据给定描述物体形状、颜色等细节信息的文本生成符合语义的图像。而一条文本描述可以对应多张不同像素的视觉内容,因此该任务的难点在于既要生成清晰、自然和多样化的图像,又要与输入文本语义相符。目前,文本引导图像生成任务的主要方法是利用生成对抗网络及其改进算法,采用多阶段生成对抗网络架构,逐步生成不同分辨率的图像以生成高分辨率图像。然而,这种架构的训练不稳定,耗时长,具有大量的网络参数和计算量,生成的图像看起来像是简单信息的堆叠,缺乏细节和真实性。本文基于文本引导图像生成领域的发展现状和存在问题出发,主要工作如下:(1)为了解决生成图像视觉效果和多样性差、缺乏细节信息的问题,本文提出了基于三元注意力的生成对抗网络模型(Triple Attention-based GAN,TAGAN)。该模型采用一对生成器和判别器,其中生成器结合三元注意力机制在上采样过程中不断提取文本特征、完善图像细节信息,并将二者特征有效融合,从而生成符合语义且清晰自然的图像。另一方面,为了帮助生成器收敛,判别器采用单向输出机制,将有效结果直接指向真实且匹配的数据对,以提供准确的方向,并利用匹配感知梯度惩罚来提升生成图像与输入文本的匹配程度。(2)针对文本生成图像的模型日益复杂、参数量大且训练时间长的问题,本文提出了轻量级特征融合生成对抗网络模型(Lightweight Feature Fusion GAN,LFGAN),生成网络在前向传播时结合条件卷积和密集连接重复利用文本信息,并用文本信息作为条件来调节生成图像的视觉效果。同时,为了提高生成图的视觉效果,本文采用了 BERT文本编码器和感知损失函数,提高生成器对于文本信息的理解和二者特征的匹配度,从而增强了生成图的细节信息。本模型采用简单的单体结构,并在生成过程中补充了缺失的信息,因此模型参数数量大大减少,同时实现了与对比模型相当的视觉效果。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000639
{DOI}: 10.27398/d.cnki.gxalu.2023.000639
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的活塞组件智能分拣系统研究
{Author}: 李承承
{Tertiary Author}: 李淑娟
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 活塞组件;机器视觉;协作机器人;目标检测与定位;智能分拣系统
{Abstract}: 活塞组件作为动力设备中的核心部件之一,对设备的性能及使用寿命有着重要的影响。当前对于活塞组件的制造已经建立了自动化生产流程,但是其装配工作仍然主要采用人工装配的方法,工人工作强度高且装配效率低。而利用离线编程方法或直接示教方法的机器人,则只能针对固定位置与固定姿态的零件进行抓取然后进行装配,一旦零件到达装配工位时位置或姿态发生变化,就很有可能导致机器人抓取失败而无法完成原定的装配任务从而严重影响生产效率,并且需要多条传送带与机器人同时工作,过程复杂且成本高。为了提高生产效率、降低生产成本并同时准确抓取不同位姿零件,本文针对活塞组件的抓取分拣任务,以xArm6机器人、深度相机与末端执行器组件等设备为硬件平台,以ROS系统为软件平台提出了以机器视觉辅助机器人的智能分拣系统,本文的主要研究内容如下:(1)采用xArm6机器人为主体、以Intel Realsense D435i双目深度相机为图像获取设备、以柔性手爪作为末端执行器搭建了机器人智能分拣系统。同时基于ROS系统构建了相机与机器人的控制功能包,实现了硬件设备与上位机的实时通信,并利用上位机控制柔性手爪电机正反转,从而实现了对末端执行器工作状态的自动控制。(2)研究了系统各坐标系间转换矩阵的计算方法,利用张正友标定法和棋盘格的相机内参标定方法获取了分拣系统中图像像素坐标系与相机坐标系之间的转换矩阵。基于ArUco标定板搭建了眼在手上模式的机器人手眼标定系统,并利用Tsai-Lenz方法对实验中获取的标定板和机器人的位姿数据进行求解,得到了系统相机坐标系与机器人坐标系间的转换矩阵。最后通过实验对获取的坐标转换矩阵的准确性进行了验证。(3)为了完成对目标物品的识别与定位,本文采用了 YOLOv3深度学习目标检测算法与OpenCV图像处理库结合的方法来搭建目标检测模块,通过采集活塞组件的图像制作数据集并结合ROS完成对目标数据集的训练从而得到权重文件,实现了对不同活塞组件的检测。同时与使用Faster R-CNN算法作为目标检测方法的检测结果进行对比,发现本文使用的YOLOv3方法在对活塞组件的检测正确率与检测速度上都更加优越。利用标定得到的转换矩阵,将像素坐标系下目标物品定位点转换到世界坐标系下,完成了对目标物品的定位,并设计实验对定位精度进行了验证,得到在X、Y轴上的定位误差在1mm左右,在Z轴上的定位误差在0.5mm左右,完全可以满足系统需求。(4)采用改进的D-H方法对xArm6机器人建立模型,进行了正逆运动学分析并利用MATLAB对运动学分析结果进行了模拟。利用xArm6机器人的三维模型建立了 URDF运动仿真模型与对应的运动控制功能包,并基于Rviz可视化插件在上位机中搭建了机器人智能分拣系统的仿真环境。基于MoveIt运动规划插件与RRT-Connect算法并结合目标点的坐标信息实现了对机器人运动轨迹的规划,在仿真环境与实际环境下进行了多次对活塞组件的分拣实验且对实验结果进行了分析。同时使用Faster R-CNN方法进行了活塞组件抓取对比实验,最终发现本文提出的ROS与YOLOv3结合的系统在针对活塞组件的抓取分拣成功率上有着较大提升。最终实现了系统在复杂环境下针对活塞组件的识别与分拣功能,实验表明该系统对目标零件的检测准确率达到97.67%,检测速度达到0.048秒,分拣成功率达到95.33%,与常用深度学习方法Faster R-CNN相比检测速度提高了两倍,目标检测准确率提高了 1.34%,分拣成功率提高了 4.66%,并且完全可以实现现场环境下针对不同活塞组零件的分拣抓取任务。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000293
{DOI}: 10.27398/d.cnki.gxalu.2023.000293
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 反无人机视觉检测与跟踪技术进展分析
{Author}: 杨辉跃;简钰洪;涂亚庆;容易圣;刘坚
{Author Address}: 陆军勤务学院军事物流系;32620部队;
{Journal}: 国防科技
{Year}: 2023
{Volume}: 44
{Issue}: 03
{Pages}: 40-51
{Keywords}: 反无人机;机器视觉;运动目标检测;目标识别;目标跟踪
{Abstract}: 为应对无人机“黑飞”“滥飞”等对国防和公共安全造成的巨大威胁，反无人机技术研究成为当前迫切的现实需求。首先，对比分析雷达、无线电、声音、机器视觉4类典型的反无人机检测技术；其次，重点针对反无人机的视觉检测与跟踪技术，从目标检测、无人机识别、无人机跟踪等角度，详细分析视觉检测与跟踪关键技术的优势与不足，以及各项技术在反无人机检测跟踪中的应用情况及改进策略；最后，探讨应用中较为突出的检测精度、跟踪遮挡、实时性、数据集收集标准、多技术融合5个方面问题和发展趋势，为相关技术研究提供参考。
{ISBN/ISSN}: 1671-4547
{Notes}: 43-1365/E
{URL}: https://link.cnki.net/doi/10.13943/j.issn1671-4547.2023.03.06
{DOI}: 10.13943/j.issn1671-4547.2023.03.06
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果分级系统
{Author}: 刘佳浩;高军伟;张炳星;王建冲
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 食品与机械
{Year}: 2023
{Volume}: 39
{Issue}: 06
{Pages}: 112-118
{Keywords}: 机器视觉;水果分级;边缘检测;最小外接圆法;HSI颜色模型
{Abstract}: 目的:解决目前水果分级检测方法效率低、误检率高等问题。方法:以苹果为分拣对象，设计一个基于机器视觉的水果分级系统。对实时采集得到的苹果图像进行预处理，使用改进的Canny边缘检测算法进行边缘提取，通过最小外接圆法拟合边缘坐标得到苹果的横切面半径。将采集到的RGB图像转换为HSI图像，根据H分量范围计算红色区域比例，判断苹果的色泽度。统计区域像素点个数，分别求取苹果的面积和周长，计算出苹果的圆形度。结合苹果果径长度、色泽度和圆形度3个特征值对苹果进行综合分级。结果:50个苹果样本试验结果表明，水果分级系统和人工分拣测量的果径误差范围在±1.5 mm以内，样本颜色特征与苹果实际外观相符，圆度值的大小与实际形状优劣相符。结论:该系统满足实际生产中对于苹果分级的需求，有助于实现苹果品级的准确识别。
{ISBN/ISSN}: 1003-5788
{Notes}: 43-1183/TS
{URL}: https://link.cnki.net/doi/10.13652/j.spjx.1003.5788.2022.80967
{DOI}: 10.13652/j.spjx.1003.5788.2022.80967
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的番茄识别和成熟度检测研究
{Author}: 高倩
{Tertiary Author}: 诸德宏
{Publisher}: 江苏大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 番茄检测;计算机视觉;Mask RCNN网络;YOLOv3;RGB Net;HSV Net
{Abstract}: 近年来,随着番茄生产规模的扩大,番茄的产量和品质都有了很大的提高。传统的人工采摘方式由于社会人口老龄化严重,农业劳动力日益短缺的问题而难以满足生产需要,因此实现番茄产业机械化和智能化已成为当务之急。计算机视觉领域的崛起,使得番茄产业智能化成为可能。本文利用计算机视觉算法,对于番茄识别和成熟度检测问题进行研究,具体研究内容如下:首先,针对番茄采摘机器人采摘过程中涉及的不同环境,选择白天和黑夜两个时间段进行图像采集:白天图像采集分别选择顺光、背光和逆光三种不同条件,而夜间图像采集则通过增加辅助光源来实现有效采集,并通过数据増广方法扩充整个数据集。然后选择图像预处理算法对夜间番茄图像进行去暗光处理。最后,建立属于自己的番茄图像数据集用来做后续图像识别与检测。其次,对于番茄识别检测问题,采集大量番茄图像作为样本,通过Labelme软件对图像一一进行标注,获得json格式数据集。提出了一种基于Mask RCNN的番茄识别检测方法,详细分析了Mask RCNN模型的结构并对其进行改进。主干网络中引入Inception模块,在RPN(Region Proposal Network)阶段提出了一种新型Ro I提取器来代替传统的Ro I提取器,并在网络模型中使用空洞卷积算法。然后在自制番茄数据集上,对番茄检测模型进行了实验验证,与原始Mask RCNN算法相比AP和AR值均有提升,检测结果表明本文改进算法不仅实现了对番茄识别,还实现了实例分割。最后,对于采摘番茄成熟度问题,设计了一种基于计算机视觉的番茄成熟度检测方法。通过YOLOv3(You Only Look Once)算法对目标区域(即番茄果实)进行获取;对两个特征提取网络RGB Net和HSV Net分别进行预训练,在此基础上,将提取到的RGB和HSV颜色特征进行特征融合,并利用分类网络来实现番茄颜色特征识别;根据对应番茄颜色来判定出番茄成熟度状况。测试结果展示出,与其他经典网络模型相比而言,本文所设计的以颜色为主要识别特征的番茄成熟度检测方法,能够以较高的识别准确率实现对番茄果实的颜色识别,并可以有效区分出番茄成熟度。上述图像预处理、番茄识别和成熟度检测方法,为实现番茄智能化采摘提供了一种有效解决方案,对推动番茄产业智能化发展具有重要意义。
{URL}: https://link.cnki.net/doi/10.27170/d.cnki.gjsuu.2023.001640
{DOI}: 10.27170/d.cnki.gjsuu.2023.001640
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在农业机器人定位中的作用
{Author}: 王瑞阳;徐洋
{Author Address}: 许昌电气职业学院;
{Journal}: 南方农机
{Year}: 2023
{Volume}: 54
{Issue}: 13
{Pages}: 90-92
{Keywords}: 机器视觉;农业;机器人;定位
{Abstract}: 随着科学技术的飞速发展，机器视觉技术在不同的应用场景下取得了良好的效果。机器视觉技术通过卷积神经网络、YOLO等模型，可以实现目标检测、目标分类、位置识别等。实践证明，农业机器人进一步结合机器视觉技术可以极大地提高农业智能化水平。基于此，课题组介绍了机器视觉技术在农业中的应用场景，详细分析了农业机器人的定位解决方案，结合单目相机提出了实现目标定位的方法，结合图像特征点提出了农业机器人位置的确定方法。结果表明，机器视觉技术能够实现农业机器人的精确定位，有利于农业的智慧化、自动化发展。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyfDWwjsVUahY0O-_JPfiYTw0_ZFPY4WsC_pHd-8S9XAkom8Ya38MLu3k4KX879e1XvgNCktUR07EpDUdqEH-Ex1rXs4LbwQJgqWNzmTEr8vvH0G637wA9sduigsvZrBmcNC0ravPgXn1s4lYRuA5cQ8EogB7dGKjxZHUgWvzSbRuYqh8vcgDJMACuPi-JH1R8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的低照度场景下的行人检测算法的研究
{Author}: 王淇
{Tertiary Author}: 刘丽娟;周宏伟
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;YOLOv5;MobileViTv3;低照度;ExDark
{Abstract}: 低照度行人检测是指在光线较暗或光照条件不理想的情况下,利用计算机视觉技术来检测和识别行人目标的研究领域,在光照较暗或不理想的环境中,行人目标容易被忽略或难以辨识,增加了交通事故的风险。因此,通过研究低照度行人检测技术,可以提高行人的安全性,减少交通事故的发生。此外,对于自动驾驶、机器人导航和智能监控等系统,研究低照度行人检测能够增强感知能力,提高系统的安全性和可靠性。在智慧城市中,低照度行人检测对于交通管理、安全监控和救援响应等方面也至关重要,综上所述,研究低照度行人检测具有显著的必要性和广泛的应用前景。
针对低照度目标检测场景中存在的检测效果差、误检、漏检等问题,本文提出了两种改进的低照度目标检测方法,并设计和实现了一种针对低照度场景的行人监测系统。具体而言,本文的研究工作主要围绕以下几个方面展开:
(1)提出了基于YOLOv5-RCD的低照度场景下的行人检测算法,该算法通过引入注意力机制和结构重参数化思想来增强网络特征提取能力。针对上采样过程的语义信息丢失问题,本文使用了转置卷积来进行上采样操作。此外,针对目标检测分类任务和回归任务之间的冲突问题,本文提出了一种轻量化的解耦头。在训练策略方面,本文采用SIo U代替CIo U,以提升训练速度和推理精度。另外,为进一步提升算法性能,本文还采用了知识蒸馏技术。最后在自制的夜间行人数据集上进行了有效性验证,其中m AP@0.5提升了5.2%,m AP@0.5:0.95提升了2.2%。
(2)提出了基于MV-YOLO的轻量级多尺度特征融合检测算法。首先,使用URetinex-Net算法对低光照图像进行增强,以降低漏检率。接下来,采用Mobile Vi Tv3对骨干网络进行重构,以增强模型的特征提取能力。在特征融合网络部分,提出了一种多级特征融合模块,旨在融合更加丰富的语义信息。最后,在公开的Ex Dark数据集上的实验结果验证了MV-YOLO算法的有效性,其中m AP@0.5提升了7.6%,m AP@0.5:0.95提升了5.9%。
(3)基于上述两种算法,设计和实现了一款基于Py Qt5的低照度行人监测系统。该系统能够在夜晚低光照条件下实现行人监控和识别,并具有较高的检测精度和实时的检测速度,满足实际使用需求。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000653
{DOI}: 10.26990/d.cnki.gsltc.2023.000653
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的钢材表面缺陷检测方法
{Author}: 闫瑾
{Tertiary Author}: 董华军;郝留成
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;深度学习;目标检测;YOLOv5;钢材缺陷
{Abstract}: 钢材作为国民经济的支柱产业,在基础建设和工业发展中有着举足轻重的作用。近十年来,中国都保持一个高钢材产量,使得钢材的质量检测成为不可忽视的一个重要环节。尽管最近几年针对质量检测的研究在检测方法和检测设备上都得到一定程度的发展,但对多类型问题的高效准确检测还没有得到妥善解决。随着机器视觉的普及应用,如何使用深度学习对钢材表面缺陷进行准确高效的检测已经成为了工业界研究的重点。
本文在对深度学习网络进行充分学习后,了解到双阶段检测方法与单阶段检测方法的区别。搭建了实验平台,根据数据集与训练结果进行参数的选择及调整。根据本文所需的高效检测要求,选择目前工业界使用广泛的YOLOv5网络作为钢材表面缺陷检测的基础算法进行实验。对YOLOv5根据模型大小不同而划分的四种网络在相同实验环境下进行试验对比分析。实验数据表明,YOLOv5s模型的检测精度达到70%以上且可以实现实时性要求,为四种模型对比下的性能最优模型。故而本文选择YOLOv5s网络进行后续的改进优化。
本文对预测头部进行改进,将原本的耦合头部进行解耦,从而分为两个分支对目标检测的分类和定位任务进行输出。YOLOX将预测头部解耦,经实验验证解耦头部可以减少对网络性能损坏的同时,大幅度提升收敛速度且对检测精度有一定提升。通过在YOLOv3上验证解耦头的可行性,将解耦头改进应用于YOLOv5s模型中进行实验,总结改进模型检测算法的可行性及改进效果。实验结果表明,改进后的YOLOv5s-DH模型平均精度均值达到75.5%,FPS达到62.3。
综上所述,本文提出的改进检测模型在检测准确率和检测速率上都有较大的提升,在实际工业生产中具有一定意义。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000538
{DOI}: 10.26990/d.cnki.gsltc.2023.000538
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件外形尺寸在线测量技术研究
{Author}: 张伟
{Tertiary Author}: 鲍泽富
{Publisher}: 西安石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 孔形工件;机器视觉;图像处理;边缘提取;在线测量
{Abstract}: 随着工业制造智能化的迅速发展,企业对产品测量的需求逐渐提升,企业需要根据及时的测量反馈来判断是否对生产工艺进行调整,传统测量方式已无法满足企业的测量任务需求。机器视觉技术与传统测量方式相比不仅测量精确度高、速度快、无需接触待测件,能够实现无损测量,而且可以实现在线测量。因此本文以孔形工件为研究对象,对其外形尺寸在线测量技术进行研究,主要研究内容如下:针对孔形工件生产过程中的外形尺寸测量,本文根据实际测量需求对在线测量系统整体结构进行设计,搭建了直观的轻量化测量系统平台,对硬件进行了选型并采用Lab VIEW、MATLAB、Python等编程方式联合开发了测量软件系统;对采集到的孔型工件图像进行预处理,提出一种改进的自适应中值滤波方法并与其他滤波算法进行对比分析与研究,引入图像评价指标客观评价,结果表明所提方法具有良好的图像滤波去噪效果;提出采用AOA改进的OTSU阈值分割方法将图像二值化,使待测量的目标区域与背景分离,减少无用信息干扰,对所提方法与其他阈值分割方法进行对比分析,结果表明所提分割方法可以有效保留边缘细节特征,运行速度较传统OTSU方法提高50.18%,评价指标Recall值较传统OTSU方法提高0.006554,所提方法用于图像分割优于传统方法;采用深度学习型的RCF边缘检测方法对图像边缘特征进行检测提取,并与其他多种边缘提取方法进行对比分析,对RCF边缘检测方法提取图像会产生粗边缘的现象进行优化处理;采用Zernike矩亚像素级别的边缘检测方法进一步提取较像素级别更为精确的亚边缘级别边缘点,并利用最小二乘方法对亚像素边缘点进行圆拟合尺寸测量与直线拟合尺寸测量。设置两组测量实验,测量结果表明该测量系统测量精度为0.01mm,测量总体标准差在0.0028mm左右,测量相对误差低于0.060%,单次测量速度为2.3s,是人工抽检速度的13.04倍。在线测量系统测量速度远高于人工抽检速度,且具有较高精确度,具有一定的实际应用价值。
{URL}: https://link.cnki.net/doi/10.27400/d.cnki.gxasc.2023.000132
{DOI}: 10.27400/d.cnki.gxasc.2023.000132
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的交通标志检测与识别算法研究
{Author}: 洪溥江
{Tertiary Author}: 殷丽凤
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 卷积神经网络;残差网络;注意力机制;小目标检测;图像识别
{Abstract}: 在汽车自动驾驶如火如荼开展的当下,有关交通标志检测与识别的研究无疑是其中一个较为重要的细分领域。近年来,随着深度学习技术的兴起,相关的科研人员借助卷积神经网络等深度学习领域的相关算法对交通标志的检测与识别进行研究。但是,由于目标图像过小、采集环境复杂等因素,相关算法的效果容易被影响,导致算法效果差。为了改善交通标志检测和识别的效果,本文基于卷积神经网络等深度学习技术,从以下几个方面进行研究:
首先,在目标检测方面:提出一种改进的单次多框检测器(Single Shot Multi Box Detector,SSD)模型FSE-SSD解决原始SSD网络模型对小目标检测效果不佳的问题。一方面在SSD网络中引入特征金字塔算法,增强特征表达能力。另一方面利用通道注意力机制,对特征通道之间的相互依赖关系建模,彻底融合高层语义和浅层重要信息,提高小目标检测准确率。通过在PASCAL VOC2007数据集的实验证明,FSE-SSD检测准确率达到80.04%,优于经典算法和前沿算法。
其次,在图像识别方面:基于密集连接网络(DenseNet)和深度金字塔残差网络(Dense PyramidResNet,DPRN)提出一种新的深度神经网络模型DensePyramidNet(DPN)进行图像识别。首先在DenseNet基础上引入DPRN金字塔残差单元的思想,并优化Dense Block为协同增效密集模块(Synergy Dense Block)。其次设计了一个基于空洞卷积的模块用于并行特征提取。最后将所提出的设计在DenseNet的基础上进行融合得到DPN模型。DPN不仅克服了DenseNet中的一些问题,而且具有与DenseNet相同的普遍适用性。在Cifar10数据集上通过实验验证,准确率为83.98%,表明DPN模型具有很好的效果。
最后,在实际应用方面,将提出的FSE-SSD模型和DPN模型应用于交通标志检测与识别中,采取消融实验、对比实验等手段,从准确率、损失、模型参数量等方面多角度分析。验证了提出的两个模型在交通标志检测识别方面的优越性。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000326
{DOI}: 10.26990/d.cnki.gsltc.2023.000326
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 采摘机器人目标识别技术研究——基于机器视觉及深度学习
{Author}: 李臣杰
{Author Address}: 河南林业职业学院;
{Journal}: 农机化研究
{Year}: 2024
{Volume}: 46
{Issue}: 01
{Pages}: 220-224
{Keywords}: 采摘机器人;机器视觉;深度学习;目标识别;图像处理;SSD
{Abstract}: 为了解决采摘机器人识别目标果实难的问题，提出了一种基于机器视觉及深度学习的采摘机器人目标识别技术，可结合图像采集、图像处理、SSD深度学习算法，实现对橘柑的精准识别。试验结果表明：采摘机器人目标识别技术对橘柑具有较高的识别率，证实了该方法的可行性，对采摘机器人研究具有一定的参考价值。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2024.01.013
{DOI}: 10.13427/j.cnki.njyi.2024.01.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉技术的分拣系统设计
{Author}: 舒慧;张融;李皓;杨世昌
{Author Address}: 武昌工学院智能制造学院;绿色风机制造湖北协同创新中心;
{Journal}: 科技与创新
{Year}: 2023
{Volume}: 
{Issue}: 11
{Pages}: 54-56
{Keywords}: 机器视觉;二维码;控制系统;快递分拣
{Abstract}: 在“中国制造2025”进程中，机器人应用已经步入生产生活的方方面面，在物流及其他行业的发展中具有很大的潜力。随着工业自动化和物流技术的发展，根据市场对高新技术的需求，传统机器人配置了智能化的机器视觉系统，并开始助力物流配送系统的自动化改造，使它能够完成更加复杂、烦琐的工作，大幅提高生产效率、缩减成本。因此，基于机器视觉技术的分拣系统在物流配送领域具有一定的应用价值。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2023.11.014
{DOI}: 10.15913/j.cnki.kjycx.2023.11.014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去雾算法研究
{Author}: 牛丽丽
{Tertiary Author}: 陈辉;付辉;陈以虎
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去雾;卷积神经网络;生成对抗网络;Transformer;注意力机制
{Abstract}: 雾和霾都是悬浮在空气中的颗粒物,光在雾霾中传播时,很大一部分光线会被吸收、散射或反射,风景的能见度会显著降低,采集的图像质量也将严重退化,往往会出现轮廓模糊,对比度低,亮度偏暗,物体特征不明显等现象,增加了高级计算机视觉研究的难度。因此,如何将雾天条件下拍摄的图像还原成对应的晴好天气条件下的图像成为一个极其重要的研究方向。近年来,针对该领域的研究涌现出越来越多的图像去雾方法,从最初的基于非物理模型的图像增强方法,到基于物理模型的方法,直至人工智能技术的大发展使得基于深度学习的去雾方法成为目前的研究主流。基于大数据的机器学习方法有强大的特征感知和获取上下文信息的能力,对大气退化图像的复原和细节信息的增强有着非常明显的处理优势,更能精确地建立退化有雾图像到清晰图像的映射关系,从而使得去雾以后的图像更接近于真实图像。这类算法准确率高,效果好,恢复出的无雾图像最接近于真实图像。但是,已有的基于深度学习的去雾算法也会存在一些弊端,比如说去雾不彻底,颜色过饱和,参数量大,成对数据集难以收集等。为此,本文做出以下创新性工作,以解决上述问题:(1)针对已有去雾算法特征提取不充分等问题,提出了一种端到端的基于多尺度残差和注意力机制的图像去雾算法。首先,通过三个小尺度的卷积核进行卷积运算提取雾图的浅层特征,可以在得到较大感受野的同时降低参数量。然后,将其输入多个由多尺度残差空洞卷积特征提取模块和多尺度注意力机制模块串联组成的网络模块,多尺度空洞卷积残差特征提取模块可以提取不同感受野的雾图特征并进行不同维度的特征融合,有效解决特征尺度单一问题,多尺度注意力机制模块可合理分配不同特征的权重,并抑制无关的冗余信息。最后,把雾图中的雾特征筛减便得到无雾图的特征图,再通过卷积操作恢复出无雾图像。通过一系列对比实验,证明了该网络可以较好地把图像中存在的雾霾去除。(2)提出一种基于CycleGAN的无监督去雾网络。为解决网络参数量大、训练慢和成对数据集难以获取等问题,改进了原本用于域迁移的Cycle GAN网络,使其能更好地应用于图像去雾领域。首先,对编码解码器结构进行改进,全部使用卷积核为3的卷积进行图像特征提取和图像重构,并加入多处残差连接,以减少参数量。接着,在特征转换部分,采取残差块加注意力机制的方案,串联多个该模块用于雾图到无雾图的特征转换,注意力机制采用了空间和通道结合的注意力机制,是一种简单而有效的轻量级注意力机制,既可以有效关注通道特征又可以更好提取空间特征,使得去雾效果得以提升。此外,在原有对抗损失、特征损失和循环一致性损失的基础上,加入感知损失,该损失利用VGG19网络的第4池化层的输出来提取高级和低级特征组合,从而保留图像的原始结构。通过实验分析,所提去雾方法能够很好的去雾。(3)提出一种基于Transformer架构的图像去雾算法。通过大量研究发现,卷积神经网络(Convolutional Neural Networks,CNN)在深度学习图像去雾领域有许多优势,但是其缺点也不可忽略,比如CNN的感受野通常较小,以及对输入的内容不适应性较高。近年来,另一类神经网络架构Transformer在自然语言处理和高级计算机视觉任务上显示出显著的性能提升,可以有效弥补CNN的不足。因此,论文结合两者优势设计出新的图像去雾算法,通过在构建多头自注意力和前馈网络块中进行一系列关键性设计,提出了一种高效的Transformer模型,该模型可以捕获远程像素交互,即对离得远的像素之间也可以建立联系,且对于尺寸大的图像也同样适用。整体网络架构呈编码器—解码器形式,编、解码器都是由几个Transformer块构成,编码器经过Transformer所提取到的特征会输入到相应的解码阶段,使得底层特征与高层特征有效融合,高效恢复图像细节信息。实验分析表明,所提去雾方法有更好的去雾效果。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2023.000811
{DOI}: 10.27206/d.cnki.ggsgu.2023.000811
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 机械手上下料的视觉识别定位系统研究
{Author}: 姚明杰
{Tertiary Author}: 符朝兴
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;机械手;YOLOv8;模板匹配;旋转不变性
{Abstract}: 随着“中国制造2025”接近尾声,我国制造业的生产制造过程已经日趋自动化、现代化和智能化。在制造业工厂流水线的工序上,越来越多的机械手取代了人工进入自动化生产。基于机器视觉的机械手因其智能、灵活、高效的特点已逐渐成为现代工厂中主要的工业机械手。但目前机器视觉相关算法对于边界模糊、对比度低的物体仍存在检测不准确或检测速度慢等问题,其应用范围仍存在一定的限制。本文针对目前工业生产中视觉技术对于管材类物料识别难度大难以实现自动上下料的问题,设计一套基于机器视觉的机械手上下料系统,针对边界模糊、对比度低的堆叠钢管识别难度大的问题,提出一种识别算法以满足视觉系统的识别准确性与实时性,以提高工厂的生产效率。本文的主要内容和创新点如下:(1)机械手上下料系统总体设计与搭建。首先对工厂中管材类物料上下料工序的需求进行分析,设计上下料系统的总体方案,并对系统的关键技术进行分析,指出本课题所使用的模板匹配算法当前存在的不足并提出了改进思路;此外对搭建的机械手建立了D-H模型,并通过D-H模型对机械手进行正、逆运动学分析,并分析了机械手末端执行器的工作空间;最后完成了相机标定与手眼标定等前期准备工作。(2)开展物料架的识别与定位。针对大视场图像使用模板匹配算法对目标匹配速度慢的问题,提出预先使用YOLOv8目标检测算法对物料架进行检测,并根据预测框裁剪图像作为模板匹配算法的输入图像的方法。针对模拟的实验场景建立了物料架的目标检测数据集,并采用数据增强算法扩充数据集以提高算法的泛化性;基于Py Torch框架搭建了模型训练环境并基于YOLO v8算法对模型进行训练。经验证,本文训练的模型对物料架的检测准确率达到100%。(3)提出了一种改进的旋转不变NCC算法。针对传统旋转不变NCC算法在旋转目标检测中金字塔各层运算量大的问题,提出使用Hough变换与金字塔分层策略相结合的方式以提升算法的实时性,并通过图像的Gamma增强提升算法的鲁棒性。经实验验证,本文改进算法在速度上提升57%以上,且具有更高的匹配精度,在不同光线环境下本文算法的识别准确率均能达到95%以上,具有较高的鲁棒性。(4)开展机械手上下料系统集成实验测试。在模拟的实验环境中,分别从定位精度、准确度以及实时性三个方面对本文设计的系统进行了实验测试。实验结果表明,本文设计的机械手上下料系统具有较高的识别准确率、识别速度以及定位精度,对提高智能化车间的生产效率具有较强的工程意义。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2023.001516
{DOI}: 10.27262/d.cnki.gqdau.2023.001516
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的红枣外观缺陷检测及分级技术研究
{Author}: 董晨晨
{Tertiary Author}: 庞茂
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 红枣;图像处理;机器视觉;卷积神经网络;缺陷检测
{Abstract}: 红枣是我国传统滋补佳品,近年来,随着国民收入的不断提升,人们对于高质量的食物需求增加,而红枣有着天然维生素丸的称号,营养丰富,越来越受到市场的追捧,消费规模呈现持续增长趋势。
目前,红枣采摘后对表面缺陷和大小区分主要以人工观察并筛选为主,这种方式劳动强度较大,并且分选不均。由于人工分级受主观影响较大,导致红枣的分级在筛选后仍然不规范,影响到红枣商品化处理。
本文的主要工作针对红枣分级准确率低与速度慢的问题,以红枣为研究对象,提出图像处理结合卷积神经网络的方法对红枣进行缺陷检测及分选。
设计红枣缺陷检测系统设备的总体方案,对图像采集装置进行了选取与调试并通过拍摄完成红枣图像数据集的构建。
查阅《干制红枣质量等级》的分选标准,并测量现有红枣样本的几何形态,确定红枣的分级标准,同时根据红枣的体型特点和瑕疵,制定了红枣的缺陷类别。
由于受光照和拍摄时环境影响,图像会产生大量噪声,不利于图像的特征提取,造成缺陷检测困难,通过灰度化、图像滤波、OTSU阈值分割、膨胀和腐蚀形态学操作的图像预处理,经轮廓检测计算红枣图像大小面积,实现大小等级分级。并将红枣图像轮廓面积以及拟椭圆化面积通过最小二乘线性回归分析,设置畸形果的面积差阈值来判断畸形果。
设计基于卷积神经网络的算法对红枣表面缺陷进行检测。本文首先将应用图像分类的典型模型进行对比,选用性能最优的轻量级Efficient Netv2网络,然后对Efficient Netv2网络的结构和参数改进,并引入Coordinate Attention注意力和FRe LU激活函数,最后完成基于改进Efficient Netv2的网络模型。经试验验证,采用改进Efficient Netv2模型时,样本中的缺陷检测准确率高达97.72%。
针对实际的检测需求,对检测界面的各功能单元进行了模块化的设计。利用QT软件进行红枣分级机主程序的开发,以实现对系统各功能的有效控制。
试验结果表明,基于图像处理和改进Efficient Netv2的算法模型在红枣缺陷检测及分选上拥有出色的性能,可将此方法应用到实际生产中的红枣缺陷检测及分选,为实现对红枣的精准检测奠定了良好的基础。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2023.000172
{DOI}: 10.27840/d.cnki.gzjkj.2023.000172
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于弱监督学习的轻量级图像语义分割方法研究
{Author}: 张曼
{Tertiary Author}: 周勇
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 轻量化;聚类量化;知识蒸馏;架构搜索;小样本学习
{Abstract}: 图像语义分割是计算机视觉领域中的重要研究分支之一,也是图像处理和图像理解的关键技术之一。图像语义分割可以被定义为图像像素点分类任务,将图片中属于同一对象的像素划分至同一类,最终将图片分割为互不相交的几块区域,实现语义级别的目标对象分割。图像语义分割技术目前已经广泛应用于各行各业,例如医学影像诊断、自动驾驶系统、遥感土地监测和无人机图像处理等。但目前的语义分割方法难以满足实际应用需求。首先,神经网络的训练依赖于大量精确标注的数据,这无疑增加了训练成本。其次,深度神经网络参数量巨大,对内存与算力的需求较高,难以直接部署到智能设备中。此外,人工干预设计网络架构的模式自动化程度较低,不符合通用人工智能的研究理念。最后,大多数分割模型的泛化性能较差,需要针对特定任务进行人工调参并充分训练,难以快速适应新任务。弱监督图像语义分割由于标签的监督级别低,获取难度小而备受关注。弱监督语义分割使用的弱标签可以分为边界框(bounding box)、涂鸦(scribble)、点(point)和图像级标签(image-level label)。其中图像级标签监督程度最弱,给模型的分割精度带来了极大的挑战。针对以上问题,本文基于图像级标签实现弱监督语义分割任务,针对模型的监督级别、轻量化与泛化性能展开多方面的研究,在深度模型的效率、泛化性与分割精度间取得更好的平衡。取得的创新性研究成果主要包含以下方面:(1)针对语义分割网络训练受精确标签数量及内存资源限制的问题,提出一种基于聚类量化的轻量级弱监督语义分割方法。首先采用二次类激活映射方法生成精度更高的伪掩码,改善类激活映射导致的目标对象覆盖区域缺失的问题。其次,在弱监督语义分割网络的训练过程中基于K-means聚类实现图片参数轻量化,缓解内存占用。最后,引入通道-空间注意力机制筛选重要内容和位置信息,提升模型的分割性能。对比与消融实验证明了本方法用较低的训练代价取得了优越的分割表现。(2)针对大规模神经网络参数量巨大,计算复杂度高且训练时间长的问题,提出基于特征蒸馏的轻量化方法,实现弱监督语义分割与半监督图片分类任务。对于弱监督语义分割,改进上一章节使用的伪掩码生成方法,提出基于梯度的二次类激活映射方法,避免了网络结构对类激活映射的限制。面向半监督分类任务训练时,仅使用部分真实标签。在特征蒸馏模块中建立教师网络到学生网络的特征映射,提高小型学生网络的特征提取能力,从而提高轻量级模型的性能。此外,封装多种经典骨干网络,通过设置超参数灵活地选择不同网络结构参与训练。通过图像分类与分割实验,证明了该方法能利用轻量网络取得较好的任务表现。(3)面向弱监督语义分割任务,针对目前神经架构搜索方法训练时间过长且硬件需求高的问题,提出基于块结构的轻量级神经架构搜索方法。使用基于梯度的二次类激活映射方法,用于生成伪标签,参与后续分割网络架构搜索的训练。利用强化学习搜索网络块结构及对应操作,通过共享操作单元及知识蒸馏等方式加速训练过程。实验进行了2,000轮,结果证明该方法实现了神经架构搜索过程轻量化,且能快速搜索出分割表现较好的网络架构。(4)针对语义分割网络的泛化性能差,无法快速适应新任务的问题,提出基于元学习的弱监督小样本语义分割方法。在伪掩码生成阶段提出一种基于通道-空间注意机制的加权二次类激活映射方法,充分扩展目标对象的覆盖面积,提高伪标签精度。在小样本语义分割阶段,采用基于优化的元学习方法,利用先验知识快速适应新任务,提高网络的泛化性能。避免了每次重新训练整个网络,有效提高了网络效率。实验结果表明了所提出方法能有效泛化至新任务,同时获得了较为准确的语义分割结果。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.000098
{DOI}: 10.27623/d.cnki.gzkyu.2023.000098
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于地磁和惯性增强感知的室内视觉定位关键技术研究
{Author}: 束明聪
{Tertiary Author}: 陈国良
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 室内定位技术;视觉定位;地磁特征;惯性感知;多传感器融合
{Abstract}: 随着信息技术迅猛发展与落地应用,位置服务逐渐成为各领域技术交叉的纽带,其中室内定位技术是解决室内位置服务的研究热点与难点。视觉定位利用智能终端相机感知场景视觉信息获得相机位姿,可实现室内行人精准定位,具有无设施依赖性、抗异构性、普适性和定位精度高等优点,已成为当前基于终端相机感知行人位置的重要方法。由于室内大范围动态场景复杂多变,面向行人的室内视觉定位存在以下几个问题:室内大型三维地图中进行视觉定位需获得全局场景下的初始位姿,存在耗时长与视觉偏差问题;室内复杂环境中视觉纹理信息较少或特征冗余,导致特征匹配准确率低与连续位姿解算效率低问题;室内动态场景下视觉特征遮挡或缺失导致视觉定位失效与跳动问题;室内复杂跨楼层、多场景的视觉定位模型中,视觉定位方案设计与模型可靠性研究较少。针对上述问题,本文围绕基于智能手机室内视觉定位技术为核心,多种传感器信息协同感知为主体,探究基于地磁和惯性信息增强感知的室内视觉定位方法,重点是对地磁和惯性的多种增强感知策略开展研究,构建面向大众的高精度、鲁棒视觉定位模型,并在大型复杂室内跨楼层环境下进行性能测试与可靠性验证,主要贡献集中于以下四个方面:(1)针对大范围室内场景下视觉定位初始化效率低问题,提出了室内地磁特征辅助初始位姿快速解算方法。该方法利用室内地磁信息实现全局大型三维地图下粗略位置识别,提出了面向视觉定位初始化的局部三维地图快速截取策略;室内地磁特征可有效避免相似场景视觉偏差问题,降低基于直接视觉特征匹配或图像检索辅助的初始位姿解算误差,提高了覆盖多场景三维地图中视觉定位初始化速度与图像注册率;针对室内复杂拓扑空间下地磁特征可区分性欠缺问题,提出了基于多尺度循环神经网络的地磁特征提取与定位方法,利用长序列地磁的粗、细粒度信息进行空间、时间相关性特征提取,提高地磁表征差异性,实现异构设备、多用户、多场景下基于地磁特征的室内位置识别稳定性与准确性,保证视觉定位初始化的先验位置识别精度与可靠性。(2)针对视觉特征相似或纹理较少的复杂室内场景下特征匹配准确率低与位姿解算效率低问题,提出了基于智能手机内置MEMS增强感知的视觉特征匹配与定位优化方法。该方法利用惯性相对定位方式的高频与连续性优势,提出基于MEMS惯性传感器先验位姿信息引导视觉特性匹配算法;研究了顾及行人运动特征约束的姿态估计算法,构建了基于载体先验位姿、误差不确定性范围与相机模型联合感知的场景局部三维特征求解模型,提出了视觉特征匹配池高效估计策略,获得复杂室内场景下视觉特征准确匹配,实现位姿解算的2D-3D数据鲁棒关联。多种复杂场景下测试表明视觉特征匹配内点率提高至63%,连续定位平均耗时降低至0.22秒,明显提升了视觉特征匹配准确性与相机位姿解算效率。(3)针对动态室内场景中光线变化或遮挡等原因导致视觉特征匹配失效,存在视觉定位跳动与不连续问题,提出了基于因子图优化的惯性与视觉融合室内定位方法。该方法以惯性感知行人运动状态为基础,构建惯性和视觉信息联合感知的松耦合融合定位策略,探究了基于MEMS惯性传感器相对定位方式与基于视觉感知绝对定位方式的优势互补定位方法,解决了视觉特征缺失或遮挡场景下视觉定位间断问题,提高了连续室内定位的位置输出有效性约48%;建立了基于高精度视觉定位方法的全局位置约束,降低了基于惯性传感器PDR定位累积误差,多种测试场景下最大定位误差优于1.15米,其中大厅、步行楼梯与狭长走廊场景下平均定位误差为分别为0.43米、0.41米和0.46米,定位精度优于基于单一传感器定位方法。(4)针对大型跨楼层室内场景下高精度定位模型设计与综合性能测试分析,提出了基于地磁/惯性/视觉多源融合室内定位模型MIVI,选择复杂多楼层室内环境下进行对比测试,测试场景覆盖停车场、步行楼梯、大厅、走廊等7种典型室内场景,将MIVI定位模型与PDR、3D-LBMS、VINS、VBL四种定位模型进行对比测试。实验结果表明,MIVI明显优于基于惯性的PDR和3D-LBMS模型;与视觉定位模型相比,多个测试路线中平均定位精度优于VINS定位模型约85%,定位有效性优于VBL模型约42%;考虑到视觉定位的图像分辨率差异、手持姿态变化以及设备异构因素影响,对模型鲁棒性进行综合测试,结果表明,MIVI定位模型具有长距离、跨楼层、多场景精准位置追踪能力,复杂室内场景下可实现稳定可靠、高精度连续定位。本文有图93幅,表23个,参考文献291篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.000046
{DOI}: 10.27623/d.cnki.gzkyu.2023.000046
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于眼动分析的广告视觉计算与偏好预测研究
{Author}: 梁松
{Tertiary Author}: 钱建生
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 广告图像;视觉显著性;情感计算;眼动追踪;偏好预测
{Abstract}: 在智能媒体和智能营销环境下,计算广告学已经成了广告学领域独立的一个分支学科和交叉学科。从早期关注创意内容以吸引受众的品鉴与回味,到运用各式的认知心理学理论、神经生物学理论和媒介技术来刺激和撩拨用户的感官,再到通过大数据计算来捕捉用户的需求以进行个性化推荐,最终将用户对个体生活方式的需求与企业对效能和利润的追求更完美地融合。而大数据时代带来信息爆炸的红利的同时也带来大量信息冗余,给如何精准地揣测消费者心理和预测消费者行为决策带来了新的挑战。就广告特点而言,广告内容大多为人工设计场景,融入了大量认知心理学的策略和伎俩。与自然场景相比,广告具有更丰富的视觉元素,更深的文本语义,更难的场景理解,更多元的风格类型,常常表现出说服性、目的性、诱导性等商业属性。而这些特征是如何影响用户的视觉注意力、心理动机、情感偏向和行为决策的,难以评估。相关的研究集中在基于对比统计式试验方法的经济管理学领域,得到的多为经验性结论,难以量化,同时也缺少公开可用的广告数据集。在交叉学科和计算机视觉快速发展的背景下,本文提出了新的思考和解决方法。从用户的视觉感知与情感分析的角度对广告进行视觉溯源性分析。沿着用户对广告“如何看”到“怎么想”的总体研究思路,从眼动信息中挖掘用户对广告的情感态度,为偏好预测和个性化推荐等广告实践提供生物学角度的理论支撑与可计算范式。本文的主要工作及贡献如下:(1)为探究广告视觉与用户的情感感知的关系,本文首先建立基于眼动追踪的广告图像情感数据集ADD1000。借助高精眼动追踪仪采集了57位具有不同性格特质的被试在自由状态下观看1000张广告图像的眼动数据,以及他们对广告偏好、情感属性、美感、品牌喜爱度等多种情感维度的主观认知数据。另外,对被试的视觉注意力、广告情感属性、眼动特征和被试性格特质之间进行相关性分析,得出一系列具有启发性的结论。本数据集弥补了研究社区缺乏公开可用的带有个性化情感标签和视觉注意力基准的多媒体数据集的空白,为非自然场景的视觉注意力计算和视觉情感分析任务提供可靠的数据基础,也可以为自然场景下的视觉任务提供理论辅助和实验对比的新基准。(2)为快速准确地获取用户在观看广告过程中的视觉注意力分布,在所提出的广告数据集ADD1000上测试了主流的显著性预测模型。发现这些模型在做跨库任务中存在诸多问题,比如,普遍性能较差,高性能模型也往往伴随较慢的推理速度、较高的计算复杂度或较大的模型尺寸,在实际应用中十分不便。因此,提出了基于多通道激活优化的快速显著性预测模型。具体地,在双支路孪生网络架构中,采用轻量级的主干网络分别学习图像的全局和局部的显著性特征,加快了模型的推理速度;基于三种手工特征设计了多通道激活优化模块,增加了模型的可解释性的同时也优化了模型对细节信息的显著性表征;孪生网络之间的参数共享策略又进一步减小了模型的尺寸。在多个显著性数据集上的大量实验结果表明所提出的方法有效地兼顾了预测性能、推理速度、计算复杂度和模型尺寸,具有更广泛的应用前景。(3)不同于内容元素充满随机性的自然图像,广告图像主要由文本元素和图片元素构成,元素之间具有较强的语义相关性,共同烘托产品和传递品牌信息。而当前基于自然场景设计的显著性模型无法准确地捕捉广告的这两种异质性元素区域对视觉吸引的强度差异,尤其表现出对文本区域的显著性预测不足的缺陷。首先,通过对广告情感数据集ADD1000的眼动信息可视化,再建了广告图像显著性数据集,并依此提出基于文本增强学习的广告图像显著性预测模型。模型分为三个核心模块:通用显著性先验特征提取模块,文本显著性增强学习模块和特征融合学习模块。具体地,采用先进的文字识别技术对广告文本进行识别,通过膨胀腐蚀方法生成广告的纯文本地图,再输入到轻量级的主干网络模块进行文本的显著性特征学习,然后与基于现有显著性方法提取到的显著性先验特征进行融合学习。在所提出的广告显著性数据集上的实验结果表明,提出的方法性能优于目前主流的显著性预测方法,且模型可以作为优化框架普遍地增强通用显著性模型对广告图像的预测能力。(4)为进一步探究用户的视觉信息中蕴含的对广告情感维度的认知线索,首次引入图神经网络对眼动行为信息进行建模,提出了基于个性化眼动图推理的广告偏好预测模型。另外,考虑到在视觉注意力选择机制下,人眼只关注或重点关注感兴趣的区域,即视觉显著性区域,而非整个广告视野。因此,又引入个性化视觉显著性图与广告内容做匹配学习,实现从“怎么看”到“看什么”再到“怎么想”的视觉情感分析过程。具体分为三个步骤:将眼动数据进行图嵌入表示,然后输入图神经网络模块学习眼动拓扑相关的偏好特征表示;将广告通过标准卷积映射到高维特征空间,再把像素表示为节点,实现对广告内容的图嵌入表示,然后输入到图神经网络模块学习广告全局语义相关的偏好特征表示;将广告显著性先验图与广告全局内容特征在高维空间进行匹配和融合,再将特征图中不相交的区域聚合为新的节点,实现广告显著性区域内容的图嵌入表示,然后输入到图神经网络模块学习广告图像的注意力内容相关的偏好特征表示;最后,将三种特征表示经过全局平均池化和全连接层映射为当前观察者的广告偏好分值。据我们所知,本方法是首个基于眼动信息推理的广告图像情感计算模型。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.000036
{DOI}: 10.27623/d.cnki.gzkyu.2023.000036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于特征预测和融合的行人重识别方法研究
{Author}: 尹军辉
{Tertiary Author}: 郭军
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 行人重识别;对比学习;掩码预测;多视角一致性;多模态融合
{Abstract}: 随着多媒体技术的高速发展,视频监控已经被广泛应用于公共场所,行人重识别也成为了当前计算机视觉领域的研究热点之一。行人重识别旨在识别检索出不同相机视角下待查询的行人图像。其中,如何提升行人重识别系统在无标注数据上的性能,如何有效利用相机信息学习具有视角不变性的行人视觉表达,在无标注数据上如何缓解对比学习系统与无监督聚类算法的不兼容问题,如何有效利用模态间数据分布特性提升跨模态行人识别系统的准确率,是行人重识别在复杂现实场景下的四大关键问题。针对上述四个关键问题,本文主要围绕特征预测和特征融合两个方面,沿着自监督掩码预测,多视角对比学习,多级别特征融合,和多模态特征融合的思路展开研究。其中,特征预测关注如何通过模型算法从原始数据中提取有效的特征表示,以便更好地描述数据的内在结构和关系。首先,本文详细探讨了特征预测方法,包括针对无标签数据的掩码预测方法和针对多视角行人图像的对比预测方法。特征预测为特征融合奠定了基础,而特征融合关注如何将多个特征进行有效地结合,以提高最终模型的性能。其次,本文深入讨论了特征融合的原理和方法,包括基于多级别实时对比学习的行人特征融合算法和基于相似性推理和原型学习的多模态融合算法。最后,大量实验结果表明,本文提出的方法可以有效提升特征的完备性、鲁棒性以及算法的高效性和场景自适应能力。本文的主要创新和贡献如下:·为充分利用模型输入的无标注数据,提出了基于聚类和掩码预测的行人特征学习方法。针对现有无监督行人重识别算法在特征空间只关注低级别的局部信息问题,本文提出了基于掩码预测的特征学习方法。该方法结合空间掩码操作和离线时序网络生成不同的时空掩码特征,并通过一致性学习来增强不同掩码特征在视觉和时间维度上的信息一致性。为确保所学特征的完备性,本文对不同掩码特征利用相同监督信息执行分类任务,这也进一步增强了不同特征间的视觉一致性。最后,本文提出的方法能够帮助无监督聚类过程获得更完备的特征并实现语义级聚类,从而确保行人识别网络关注到语义级全局信息。·为缩小不同相机之间的数据分布差异,提出了基于多视角对比预测的行人重识别方法。针对不同相机下数据风格差异较大的情况,本文利用核密度估计实现了不同视角下图像编码预测估计,该预测过程可被用于模型训练的目标任务并提升模型对视角变化的鲁棒性。为提升模型对不同行人身份的判别力,本文在多视图编码预测的过程中引入了基于正负样本的对比学习机制,以增大不同行人间的图像特征差异同时保持同一行人身份的特征紧凑性。实验结果表明本文提出的多视角对比预测方法在多个公开数据集上可以有效提升行人重识别模型的识别准确率。·为解决当前行人重识别系统与聚类算法的不兼容问题,提出了基于多级别实时对比学习的行人特征融合算法。本文考虑无监督聚类算法密度可达的原则,提出了实时记忆更新策略,并随机选择实时特征作为类别代理,以最大程度保留原有数据特征分布,增强无监督聚类算法的聚类能力。在此基础上,提出了两种实时对比学习方法以将多个特征来源进行有效结合,提升算法效率和模型的识别能力。实验结果表明,该框架能够提升模型在无监督和域适应任务上的识别性能。·为减少不同模态场景间数据分布的差异,提出了基于相似性推理和原型学习的多模态融合算法。本文基于多模态数据集中行人身份模态间相互重叠的特性,构建了可用于不同模态间正负样本挖掘的特征相似性矩阵,并在此基础上提出了一种相似性推理机制,以促进不同模态数据的特征融合。为进一步挖掘模态内的多粒度特征信息,本文在模态共享特征的基础上实施多粒度原型学习,从而提高增强模型在跨模态场景的自适应能力。实验结果表明,本文提出的方法能够有效提升模型在跨模态图像检索任务上的识别能力。综上,本文关注复杂场景下的行人重识别问题研究,针对无标注样本的有效利用、学习视角不变视觉特征、对比学习系统与无监督聚类算法的不兼容及模型的跨模态场景应用展开了深入研究。本文首先探讨了无标注数据中特征学习的完备性,在此基础上,利用相机信息和聚类算法的特性,将多视角学习和实时特征更新的思想融入到对比学习框架之中。最后,本文将行人识别系统拓展到了多模态场景,力求为现实场景下行人重识别提供理论参考和实践意义。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000249
{DOI}: 10.26969/d.cnki.gbydu.2023.000249
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的印刷电路板表面图像增强与缺陷识别研究
{Author}: 于心怡
{Tertiary Author}: 李涵雄
{Publisher}: 中南大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: PCB表面缺陷检测;数据生成;图像增强;缺陷识别;深度学习
{Abstract}: 在智能制造过程中,印刷电路板(PCB)作为各种精密仪器、智能设备的重要组成部分,其表面质量的好坏之间关系到电子设备能否正常工作,准确高效地进行PCB表面缺陷检测是产品质量控制的关键。虽然现有的以特征提取、图像识别等计算机视觉技术为主的自动光学检测系统能够大体上满足工业上对于PCB表面质量的检测需求,但由于实际工程应用中PCB表面检测容易受到环境影响、PCB表面图像纹理复杂且缺陷尺度不一、图像标注困难等问题,限制了PCB表面缺陷检测的准确率。针对工业PCB表面缺陷检测过程中受到数据集分布不均匀、图像噪声与标签噪声等的干扰,造成误检的问题,本文提出了基于深度学习的PCB表面图像增强以及缺陷识别算法。本文的主要研究内容与成果如下:
(1)针对工业生产过程中采集到的缺陷图像数据集存在的样本数量分布不均衡的问题,本文建立了一种新型的异构注意力机制数据生成算法。该算法不仅设计了新型异构自注意力机制和可分离卷积相结合的生成对抗模型架构,来有效学习并扩充数据特征,还提出了新的铰链损失函数及联合训练方式来优化整个模型。实验结果表明,所提算法有效解决了缺陷数量不均衡问题,同时提高了缺陷识别的准确率。
(2)针对复杂工业环境中采集到的图像存在低对比度与多噪点存在的问题,提出一种两阶段图像内在表征分解与颜色调节下的图像增强算法。首先设计了两阶段的图像内在表征分解模型来获取光照图与反射图,利用正常光图像与暗光图像的不同特点,在保留更多细节的同时去除噪声。同时通过从RGB空间到HSI空间的映射,设计了颜色调节器解决增强图像的颜色失真。设计了新型的联合损失函数,不仅考虑到传统的重建特征信息,还包含了图像的亮度、平滑度与结构一致性。最终在设计的PCB暗光数据集以及公开数据集上的视觉感知效果与图像质量分析都证明了所提算法的有效性。
(3)针对工业PCB表面图像普遍存在的特征不明显、多噪声、缺陷尺度差异等图像不确定性问题,提出了一种基于改进Retinex分解和稀疏表示的PCB缺陷识别算法。该算法根据反射分量与光照分量在频域信息中的特点,建立了一种改进的Retinex图像分解模型,有效地解决了不均匀光照下图像阴影分量中突变与平滑的差异性,并通过稀疏表示的方式获取其中的特征信息。本文设计了双层注意力特征融合模块,在关注图像结构信息的同时,也关注目标的像素信息。通过引入不同比例的图像不确定性来设计多组对照实验,从准确率、召回率、精确率和推理速度等方面都验证了所提算法的优越性。
(4)针对数据集标注过程中产生的标签不确定性会导致缺陷识别的准确率下降的问题,提出了一种新的基于半监督协同学习的鲁棒性学习策略。首先设计了多尺度对称残差滤波器,在去除图像噪声的同时获取相应的先验知识。建立了辅助推理模型,利用一小部分准确标签去修正并生成伪标签。最终提出了一种联合概率推理引擎,利用知识迁移来训练浅层的主推理模型,这样就能在提高模型检测性能的同时减少计算成本。最终在HRIPCB上的实验结果表明,在不同比例标签噪声的实验中所提算法的准确率都能达到最高。
(5)介绍了智能制造过程中PCB表面缺陷检测的工作流程,通过图像预处理、缺陷分割、缺陷识别等模块提出了PCB表面缺陷检测的总体架构。针对实际工业生产过程中PCB表面缺陷检测的难点问题,设计具有不同比例图像不确定性和标签不确定性的实验,使用采集的PCB样本图像来进行验证。在工业应用的各个评价指标上的实验结果证明了本文所提算法能够适用于复杂工业环境中的PCB表面缺陷检测。
综上所述,本文以PCB表面缺陷检测过程中的实际需求和问题为导向,提出了PCB表面图像的数据增强与缺陷识别算法。实验结果证明,本文提出的算法能够有效解决PCB表面缺陷检测过程中存在的部分难点问题,其研究成果能够为智能制造过程中的相关检测领域提供理论研究价值。
图65幅,表39个,参考文献134篇
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2023.000122
{DOI}: 10.27661/d.cnki.gzhnu.2023.000122
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的人脸检测若干问题研究
{Author}: 骆实
{Tertiary Author}: 李雄飞
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 计算机视觉;人脸检测;卷积神经网络;小尺度人脸;极度纵横比;人脸采样;边界框校正
{Abstract}: 近年来,卷积神经网络在各种计算机视觉任务中取得了巨大的成功,人脸检测作为计算机视觉中的重要研究方向,其性能也得到了不断的提高。在人脸检测的应用场景中会存在很多限制因素,对人脸检测的性能带来极大的挑战,例如尺度、表情、姿态、遮挡、光照、模糊等。本文详细阐述了基于卷积神经网络的人脸检测的工作进展,以进一步提升检测性能为目标,提出了若干人脸检测方法。本文的主要工作包括以下三个方面的研究内容。1.随着人脸尺度的减小,基于卷积神经网络的检测器性能急剧下降。针对小尺度人脸检测性能不佳的问题,提出一种新颖的多尺度人脸检测器。该方法的创新点在于从四个方面关注小尺度人脸:构造多分支检测架构,将保留更多小尺度信息的浅层作为检测层;设计了尺度敏感锚框,更小的锚框用于匹配小尺度人脸,从而扩大了锚框尺度的覆盖范围;添加特征融合模块,利用相邻高层分支的特征辅助检测小尺度难检测人脸;同时采用多尺度训练和多尺度测试策略,使所提模型对各种尺度都具有鲁棒性。2.现有锚框匹配方法采用固定阈值划分正样本。然而,极端纵横比人脸与锚框的最大交并比往往低于正样本阈值,从而导致采样失败。锚框补偿虽然可以缓解采样不充分,但无法保证补偿样本质量和正样本整体质量。针对极端纵横比人脸采样不充分的问题,提出了一种广域纵横比匹配策略,从更广泛的人脸纵横比范围收集具有代表性的正样本锚框。该方法的创新点在于为极端纵横比人脸构造可变的正样本采样域值。在保证正样本整体质量的前提下,可以获得许多与极端纵横比人脸相关的高质量正样本参与训练。此外,设计了感受野多样化模块,在特征增强阶段获得更加鲁棒的人脸特征。3.基于卷积神经网络的人脸检测遵循监督学习模式,它的检测性能依赖于训练数据集的标注质量。然而,现有的人脸检测数据集均是人工标注的,很难保证每张人脸的标注质量。针对训练集人脸边界框标注不准确的问题,提出了边界框深度校正的方法。该方法的创新点在于借助深度模型预测的人脸边界框来识别并替换训练集中未对齐的人脸标注。使用校正后的标注来训练检测模型,会降低模型的回归损失。进而打破原有分类损失和回归损失的平衡,使模型在训练阶段更加专注于降低分类损失。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.000593
{DOI}: 10.27162/d.cnki.gjlin.2023.000593
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人体行为视觉识别与理解网络架构研究
{Author}: 刘全乐
{Tertiary Author}: 车翔玖
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 行为理解;计算机视觉;深度学习;神经网络
{Abstract}: 国务院正式发布《新一代人工智能发展规划》以来,我国人工智能技术进入全新的发展阶段,智能安防、智慧医疗、智能教育、无人驾驶、智能制造等新型人工智能技术和产业在国家的大力支持下高速发展并取得长足的进步,这给人们的生活带来了极大的便利。“十四五”规划提出要“加快数字化发展,建设数字中国”,强调要激活数据要素潜能,更进一步驱动传统产业数字化转型升级,打造数字经济新优势的新发展理念。人是社会生活的主体,构建针对人体行为进行分析理解的智能化算法模型是发明各类智能应用、发展数字经济、建设智能型社会生态系统必需的一项关键技术。人体行为识别与理解技术是计算机视觉领域的研究热点,它们是许多图像和视频分析任务的基础,具有重要的理论研究意义。在当今建设数字中国的时代背景下,其现实意义亦是愈加凸显。从各种图像和视频中提取特定的人体行为模式,并对其进行分析与理解是基于计算机视觉的人体行为识别与理解方法的核心任务。目前,随着计算机视觉和深度学习技术的发展,研究者们提出了大量基于卷积神经网络(Convolutional Neural Network,CNN)、图卷积网络(Graph Convolutional Network,GCN)和循环神经网络(Recurrent Neural Network,RNN)的人体行为识别与理解算法。由于其灵活的架构设计和良好的性能,这些方法得到了广泛的认可和应用。与此同时,由于大量各类型的视觉传感器在各种环境部署应用,其产生的图像和视频数据存在复杂的背景、光照、视点等干扰因素,这使在真实场景下提取和理解人体行为特征仍然是一项重要挑战。因此,本文以计算机视觉与深度学习技术为基础,针对复杂真实场景中的人体行为理解问题,研究构建具备较高精确度、鲁棒性、实用性的神经网络架构。主要工作如下:针对现有人体行为识别方法准确率低、计算复杂度高、特征提取抗干扰能力弱的问题,本文构建双流残差时空注意力网络(Two-Stream Residual SpatialTemporal Attention Network,2S-RSTAN)。双流网络架构具备从视频中同时提取时空特征的能力,已经被广泛应用于视频行为理解任务。但视频在时间和空间维度上都存在大量的冗余信息,增加了网络学习的难度,限制了网络的性能。为了解决这一问题,提出在双流架构的基础上,首先利用随机稀疏采样策略,极大地减少视频中的冗余帧,然后,利用残差学习和时空注意力机制搭建神经网络模型,学习视频中的人体行为特征,使网络更专注于有意义的时空特征。在构建的双流残差时空注意力网络中,两个支流分别使用RGB图像和差分图像作为输入。每个支流都是由残差时空注意力模块叠加而成,能够在时间和空间维度上生成注意力感知特征,大大减少冗余信息对网络训练带来的负面干扰。结合残差学习的固有特性,可以构建足够深的网络来充分学习视频中的时空信息。随着层的加深,位于不同深度的残差时空注意力模块能够自适应地生成相应层的注意力感知特征。实验结果表明,所提出的网络架构能够有效提升人体行为识别能力。并且,相比于3D网络,本文的网络具备更加轻量级的特点,能够满足现实场景的使用需求。针对现有人体行为识别与理解网络可解释性差、鲁棒性低以及学习过程存在盲目性的问题,本文构建人体局部关系推理网络(Body Part Relation Reasoning Network,BPRRN)。人体的局部特征是人体行为的重要组成部分,并且在不同的人体行为中,人体各部位的特征之间存在一定的关联性,这种关联信息对于推理人体行为具有重要意义。鉴于此,提出从关系推理的视角出发建立人体局部关系推理网络。将人体划分为十个区域,使网络重点关注这些区域特征的学习。同时,构建人体局部关系推理模块探索各区域特征在不同人体行为条件下的潜在关系,并将这种局部关系信息与人体整体特征、场景特征进行结合推理图像中的人体行为。在时间域,构建时间关系推理模块,对相邻视频帧的人体行为特征进行建模,探索相邻视频帧之间潜在的时间关系,从而推理视频级别的人体行为。实验结果表明,提出的局部关系推理模块和时间关系推理模块均能提高网络的人体行为理解能力。此外,从可视化的实验结果中可以看出,局部行为特征为整个人体行为的推理结果提供了很好的可解释性。现有人体行为识别与理解网络在训练过程中被动地感知图像和视频中的人体行为模式,缺乏结合先验知识进行判断的主动认知能力。鉴于此,本文构建人体行为知识转移网络(Human Activity Knowledge Transfer Network,HAKTN)。当缺乏足够的训练数据时,现有神经网络架构难以从数据中接收到充足的有价值信息,从而导致较差的性能表现。而人类可以利用自己的先验知识,通过主观判断来理解场景中蕴含的信息。受此启发,HAKTN将与数据关联的先验知识融入神经网络的训练过程中,从而使网络具备人类的认知和感知能力。通过研究人体的各局部动作之间及其与场景中物体之间的共现关系,构建共现概率知识矩阵,利用该矩阵引导网络更好地提取人体局部动作特征。根据人体骨骼的生理结构特点,构建人体骨架知识矩阵,并据此对各局部动作特征进行建模,推理人体行为。相比于现有基于深度学习的人体行为理解方法,该网络实现了主动认知能力与被动感知能力的统一。通过数值实验证明了该方法的有效性,并且实验结果表明,提出的人体行为知识转移网络可以在基于常规数据和小样本数据的实验中取得良好的结果,进一步验证了该网络具有较高的鲁棒性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.000697
{DOI}: 10.27162/d.cnki.gjlin.2023.000697
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的交通标志识别研究
{Author}: 白伟
{Tertiary Author}: 纪占林;李硕
{Publisher}: 华北理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;目标检测;You only look once(YOLO);交通标志检测;轻量化;剪枝
{Abstract}: 目标检测和图像识别是计算机视觉应用领域的重要组成部分。随着无人驾驶技术的日益发展,高精度识别和轻量化部署成为了交通标志检测的重要任务。
受光线、小目标、背景复杂等多种因素的影响,传统的交通标志识别技术效果并不理想,因此本文提出了一个基于YOLOv5s的高精度检测模型YOLOv5-TDHSA,主要工作如下:利用Transformer自注意力模块替换YOLOv5s的Backbone和Neck部分的最后一层CSP,从而更全面地采集图像特征信息;将YOLOv5s的耦合检测头进行解耦,利用分支结构分别进行定位和识别两个任务,提高检测精度;设计小目标检测层,通过增加一组自适应锚框,使网络能够更好的检测图像中的小目标;利用统计学方法(Friedman检验和Bonferroni-Dunn检验)分析所提出的模型和对比模型间的差异性和优劣。经过测试,基于YOLOv5-TDHSA模型搭建交通标志目标检测系统可以满足高准确率和实时性的需求。
在两个公开的数据集上进行试验,结果表明,对平均精度(m AP)和F1 score而言,所提出的YOLOv5-TDHSA模型优于原始YOLOv5s模型和其他三种先进的对比模型。在TT100k数据集上获得了83.4%的m AP值和0.811的F1 score值,在CCTSDB2021数据集上的m AP值为69.8%,F1 score值为0.72。
受移动端设备存储空间和算力资源的限制,复杂的模型结构不利于其部署。因此基于YOLOv8提出了一个轻量化模型YOLOv8-GPF来解决上述问题,主要工作如下:将YOLOv8与Ghost Net网络融合,减少模型参数量并降低模型计算复杂度;然后进行稀疏化训练和剪枝,进一步缩减参数量,最后进行微调以提高检测精度。
在TT100k和CCTSDB2021数据集上分别进行了实验,实验结果表明,在保证较高m AP和F1 score的前提下,权重文件大小、参数量和计算量分别减少了36.1%-36.3%,29.6%-30.8%和28.9%-29.1%。
图39幅;表40个;参81篇。
{URL}: https://link.cnki.net/doi/10.27108/d.cnki.ghelu.2023.000548
{DOI}: 10.27108/d.cnki.ghelu.2023.000548
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的农作物病虫害识别与检测研究
{Author}: 陈港明
{Tertiary Author}: 齐芳
{Publisher}: 中南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;注意力机制;卷积神经网络;Transformer;害虫检测;病害识别
{Abstract}: 农作物病虫害防治是各地种植者始终面临的巨大挑战。传统的病虫害识别与检测需要依赖生物学家的专业知识或者阅览相关专业书籍来实现,该方法不仅花费巨大的人力成本,而且效率低下,容易错过防治病虫害的最佳时期。近年来许多研究者将计算机视觉技术应用于病虫害识别与检测,解放了许多手工操作,在提高识别与检测性能的同时降低生产成本,有利于现代化农业的发展。但是依靠数字图像处理算法和机器学习算法的传统计算机视觉技术,缺乏处理大规模图像数据的能力和泛化能力,不容易推广。随着深度学习的强大特征学习能力不断被挖掘,基于深度学习的方法已经成为病虫害识别与检测的有效手段。本文在现有基于深度学习的目标检测和图像识别算法基础上,围绕农作物病虫害的识别与检测展开系统性的研究,主要研究内容包括以下两个方面:
(1)针对基于卷积神经网络的害虫检测算法引入大量手工设计组件问题,本文提出了一种基于卷积神经网络和Transformer的害虫检测算法。首先,通过引入Transformer处理特征信息,消除了大量的手工设计组件。其次,将残差网络和通道注意力机制相结合组成特征提取网络,有效提升模型的特征提取能力。再次,针对Transformer处理特征信息时计算复杂度较大和无关特征信息过度获取的问题,提出了一种多头交叉相乘注意力模块建立对象查询之间长远距离的依赖关系,有效降低了模型的计算复杂度和无关特征信息的影响。最后,在公开的大规模害虫数据集上进行了实验评估。实验结果表明,与基于卷积神经网络的害虫检测算法相比,本算法拥有较高的检测准确率,具有一定的先进性和适用性。
(2)针对基于卷积神经网络的病害识别算法在实际中的应用,本文提出了一种基于通道注意力机制的卷积神经网络的病害识别算法,实现了模型复杂度和识别准确率的平衡。首先,通过设计一个深度可分离卷积的残差单元处理图像数据,有效降低了模型的参数量。其次,通过引入轻量级通道注意力机制的方式,有效增强特征信息的提取能力。最后,在公开的大规模病害数据集上进行了实验评估。实验结果表明,本算法具有较好的识别性能,可以部署于实际中的终端设备。
图33幅,表13个,参考文献85篇
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2023.001026
{DOI}: 10.27661/d.cnki.gzhnu.2023.001026
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的伪造人脸视频检测研究
{Author}: 张帅
{Tertiary Author}: 肖波
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;计算机视觉;深度伪造;伪造检测;伪造溯源
{Abstract}: 随着人工智能技术的不断进步和发展,篡改真实视频中的人脸图像变得越来越容易,通过深度伪造方法生成的人脸伪造视频的质量变得越来越好,甚至达到以假乱真的效果。伪造生成人脸视频不仅会给公众的信息安全带来威胁,侵犯公民肖像权,而且相关涉政视频可能会使政府公信力受损,产生政治信任危机等问题。因此,针对真假难辨的人脸视频,通过深度学习方法对其进行伪造检测成为了迫切任务,具有极强的现实意义和社会价值。基于此,本论文充分调研当前领域的研究现状,设计科学合理的实验方法对基于深度学习的伪造人脸视频检测展开研究。论文的主要工作包括:1.在基于Video-level的深度伪造人脸视频检测算法研究中,论文提出了一种基于模型融合的伪造检测算法。针对现有方法对跨帧间信息提取能力不足的问题,引入自注意力机制,加强网络对时间维度上长距离信息的特征提取能力。同时在网络结构中加入帧内信息特征提取支路,通过模型融合方法,弥补了现有方法无法挖掘到帧内时域信息的不足。通过科学的对比实验和消融实验,证明了检测算法的优越性和相应创新模块的有效性。2.在基于Frame-level的深度伪造人脸视频检测算法研究中,针对GAN生成伪造图像的独特频谱特征,论文提出了一种基于特征融合的伪造检测算法。在网络中加入跨模态特征提取模块,将频域指纹信息和时域信息进行特征融合,提升了算法对GAN伪造视频帧的检测效果。同时,论文将传统的二分类伪造检测任务拓展到多分类伪造溯源任务场景,设计了合理的对比实验,验证算法的伪造溯源效果。3.基于伪造检测任务的需求分析和可行性分析,面向实际应用场景,结合论文所提出的两种伪造检测算法,论文设计并实现了深度伪造人脸视频检测及溯源系统。所设计系统前端页面简洁清晰,用户操作简单便捷,降低了人脸视频伪造检测的技术门槛。本论文基于深度学习技术,针对深度伪造人脸视频检测场景提出了不同角度的创新算法,通过大量实验证明所提出算法在伪造检测和方法溯源上的有效性。此外,将所提出的检测算法通过系统形式应用实际,实现了伪造检测和伪造方法溯源功能。因此,本论文的研究具有一定的理论意义和应用价值。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000198
{DOI}: 10.26969/d.cnki.gbydu.2023.000198
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的立体测量系统的研究与实现
{Author}: 肖颖超
{Tertiary Author}: 徐永安
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;双目视觉;立体测量;点云可视化
{Abstract}: 双目视觉立体测量技术相比于其他立体测量方法具有设备简单、成本低和效率高的优势,通常被应用于三维人脸识别、机器人避障、虚拟现实等领域。因此近年来一直是立体测量领域中的研究热点。本文基于双目视觉的相关原理来实现对立体测量系统的开发与研究,主要的工作内容如下:第一,本文系统研究了双目视觉成像理论,利用OpenGL、OpenCV、MFC等工具完成了一套基于双目视觉的立体测量系统的设计与实现。该系统提供了相机标定、立体测距、三维点云可视化等功能。第二,本文采用棋盘格作为标定模板,相机标定时需要提取标靶的角点特征信息,针对传统Harris角点检测算法在提取棋盘格角点信息不准确的问题,本文在原算法的基础上引入快速的二值化图像预处理和角点过滤层进行了改进,实现了棋盘格角点的有效提取,提高了 Harris角点检测算法的准确性和可靠性。第三,在立体匹配步骤中,本文使用了基于Census变换的SGM(Semi-Global Matching)的立体匹配算法。针对立体匹配算法获得的视差图中部分匹配失败的区域,本文提出了一种基于插值填空的局部特征填充法对视差图中未匹配到的像素点进行了一定程度上的修复,并使用中值滤波对获得的视差图进行平滑去噪,将其应用于立体匹配的视差优化步骤中,改善了视差图的质量和点云数据的可视化效果。第四,为了有效管理点云数据和提高点云数据进行三维可视化时的效率,本文设计并实现了一种基于深度特征的分层型数据结构。该数据结构可以有效地过滤掉点云数据中的噪声,可以利用深度特征信息对点云数据进行分割提取,为后续的被测量物体三维点云可视化和三维重建等拓展研究提供了高效的数据结构。通过本文设计的双目视觉立体测量系统,完成了相机标定、图像立体匹配、三维点云可视化等功能的实现,本文的立体测距结果在一定测量范围内,误差可控制在1%以内,三维点云可视化效果较好并且支持点云数据的分割提取。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2023.000736
{DOI}: 10.27441/d.cnki.gyzdu.2023.000736
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的刚体目标姿态估计
{Author}: 刘景赫
{Tertiary Author}: 林宝军
{Publisher}: 中国科学院大学(中国科学院微小卫星创新研究院）
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;姿态解算;YOLO;Transformer;非合作目标
{Abstract}: 在机器人导航、自动驾驶和虚拟/增强现实等应用中,基于RGB信息的目标的6维姿态估计都是非常重要的一步。该问题定义为:从一张参考图像中,定位出预定义的一些目标,并确定这些目标相对于相机系的旋转角度和平移向量。目前该问题的解决方案可分为两类:单阶段算法和双阶段算法。单阶段算法根据输入图像直接输出一个六维的向量,属于端到端范式,不依赖其他形式的中间表达。随着深度神经网络的拟合能力逐渐增强,研究者开始依赖该能力完成上述表达的检索。双阶段算法依赖目标的3D结构,首先在图像中定位关键点,然后基于关键点的2D坐标,及其在3D结构中的3D坐标,优化投影方程,从而完成姿态解算。在此类方法中,关键点充当了姿态解算的中间表示,因此关键点的定位精度很大程度上决定了姿态解算的精度。至于关键点定位方面的研究,则经历了从基于图像处理的方案到基于深度学习的方案的转变。本文围绕上述两类方法,对该问题展开了全面的研究,主要工作如下:在双阶段算法阵营中,基于经典的双阶段姿态算法YOLO-6D进行研究并改进。从提升关键点定位精度方面考虑,在训练时添加了语义分割分支。语义分割任务本质上属于像素级分类任务,其可以增强backbone对细粒度特征的理解能力,而关键点定位任务亦依赖于此能力,因此根据多任务学习原理,添加语义分割任务可以提高模型对关键点的定位精度。此外在推理时切除语义分割分支,因此模型的推理速度不会被削弱。经实验验证,在LINEMOD数据集上的2D投影指标和ADD指标分别达到了94.43%和67.37%,优于其他经典的双阶段算法。且算法能以73FPS的推理速度运行,兼具高精度和实用性。在单阶段算法阵营中,本文利用DETR结构进行目标的姿态解算。DETR是一项利用Transformer技术进行目标检测的工作,其一改基于卷积的密集预测思路,转而利用Transformer的全局建模能力,将目标检测视为集合预测问题,具有流程简洁、不需要人为先验、不需要后处理去重的优点。基于此,本文亦将姿态估计问题视为集合预测问题,开发了一套简洁的单阶段姿态估计算法,继承了DETR的上述优势。此外,针对DETR存在的“缺少多尺度训练”和“收敛速度慢”的问题,又引入了多尺度可变形注意力机制,解决了上述问题。在YCB-Video数据上的实验结果表明,所提算法取得了83.0%的ADD指标,高于其他经典的单阶段算法,且具有流程简介,推理速度快的优点。针对空间环境中,非合作的航天器,相对于已方的姿态估计,展开研究。在上述关于单阶段算法和双阶段算法的研究过程中发现,双阶段算法阵营中,基于投票机制的关键点定位方案,取得的姿态精度是普遍高于其他双阶段算法和单阶段算法的,其对遮挡问题和截断问题具有较好的鲁棒性。因此从提高卫星姿态精度的方面考虑,开发了基于投票机制的卫星姿态估计模型。此外,由于卫星场景中,关键点的分布较分散,而基于卷积的投票机制感受野受限,无法对关键点之间的关联性进行建模,针对该问题,在投票网络中引入了自注意力机制,增强了神经网络的全局建模能力,提高了关键点的定位精度,继而提高了姿态估计的精度。在Kelvin姿态挑战赛中取得了0.012分,排名所有算法第3位。
{URL}: https://link.cnki.net/doi/10.44194/d.cnki.gwxwx.2023.000016
{DOI}: 10.44194/d.cnki.gwxwx.2023.000016
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像识别的机械手上料系统的研究与设计
{Author}: 刘颖
{Tertiary Author}: 张立广;张健康
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;上料机械手;相机标定;NCC匹配;机械手控制
{Abstract}: 在工业生产过程中,传统工业流水线多使用人工方法对工件进行检测、识别与上料,该方法存在劳动力强度大、效率低及价格昂贵等缺点。由于机器视觉具有高精度、非接触、高适应等优点,因此常与机械手结合应用于工业生产中。本文针对多个壳状工件在随意摆放和整齐摆放的多目标多角度状态下,利用视觉机械手对其进行识别上料工作,提高系统的智能化和高效化水平。由于壳状工件在识别中存在边界锈渍及阴影、遮挡等问题,本文基于灰度信息匹配设计了针对多目标多角度壳状工件的视觉机械手上料系统,实现对目标工件位姿信息(三维坐标和角度)的获取,满足自主识别和精准上料的作业需求。首先,通过分析视觉机械手上料系统的工艺流程与技术指标,对系统进行研究与设计。确定了系统的组成、设计框架与上料平台,将系统分为视觉识别部分与机械手上料控制部分进行研究,提高上料效率。其次,为获取目标工件的位姿信息,设计视觉识别方法。对机器视觉成像原理和标定方法进行研究,设计成像模型;通过单目视觉标定获取相机内外参数,为后续的上料奠定基础。再对相机采集的工件图像进行中值滤波和直方图均衡化预处理,提高图像质量。对工件位姿识别中的匹配算子进行研究,针对传统NCC(Normalized Cross-Correlation,归一化互相关)匹配算法计算复杂、速度慢及正确率低等问题,本文采用了基于小波金字塔的NCC匹配算法来获取目标工件二维像素和角度信息,该算法对模板图像建立小波金字塔结构,利用分层匹配提高匹配效率,实现对工件的快速准确识别。为获取单目视觉系统下的工件三维深度信息,提出基于二分算法的Hough识别算子获取目标工件的对比像素,再与基于定焦的像素比例方法结合,对深度信息进行计算,获取工件的位姿信息。然后,对机械手上料控制方法进行研究,实现壳状工件上料。将视觉识别获取的目标工件位姿数据反馈给机械手,引导机械手对工件进行上料,并利用电机的线性自抗扰控制提高机械手控制的位置精度和稳定性。同时,对机械手的运动学进行分析,确定机械手的轨迹规划方案,实现稳定、可靠的运动。最后,对视觉机械手上料系统软件进行开发,测试上料效果。实验结果表明,本系统的识别时间在2-5S之间,抓取上料时间≤6S,上料成功率达86%,可以满足系统指标要求,实现系统的自动化运行。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000932
{DOI}: 10.27391/d.cnki.gxagu.2023.000932
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的航拍图像目标检测算法研究
{Author}: 赵立敏
{Tertiary Author}: 白宗文
{Publisher}: 延安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;航拍图像;目标检测;残差网络;YOLOv5
{Abstract}: 近几年,无人机在人们的日常生活中越来越普及,很多场景中由于客观原因的限制大量采用了无人机,比如:无人机预警、无人机抓拍、无人机劝导等,无人机逐渐在复杂场景下变得不可替代。无人机航拍图像在军事侦探、紧急事件、智慧交通、农业妨害等领域有着实际的应用和研究价值。随着技术的不断更新,无人机航拍技术愈发成熟,航拍图像空间分辨率越来越高,图像的细节信息越来越丰富,从而为研究航拍图像小目标检测、多尺度目标检测和复杂场景下的目标检测奠定了坚实的基础。由于计算机算力和基于深度学习的目标检测算法不断更新迭代,基于深度学习的航拍图像目标检测算法也成为了目标检测方向的一个研究热点。由于航拍图像与通用目标检测数据集有很大差异,与通用目标检测数据集相比,航拍图像主要存在小目标占比较大、目标尺寸差异大、背景信息与目标信息相似等特点,根据航拍图像中存在的问题,我们需要对目标检测原算法进行优化,以便得到更好的检测效果。本文在通用目标检测YOLOv5的基础上进行改进,提出了基于坐标注意力和Swin Transformer的多尺度无人机航拍图像目标检测算法,在基于YOLOv5原算法的特征提取模块C3和特征融合网络进行改进。本文的主要工作如下:(1)针对航拍图像中小目标占比较高,同时,由于航拍图像拍摄以俯瞰的形式成像,造成大量目标被遮挡或像素信息不完整等问题,使得YOLOv5原算法误检、漏检率高。针对这个问题,在原算法基础上增加了一个微小目标检测层。其次,针对预测头的边界框回归任务,将原有的GIOU损失函数替换为Alpha-IOU损失函数,从而提升了网络模型的检测性能。(2)针对航拍图像中目标尺寸差异大、背景信息复杂等问题,在YOLOv5原算法的基础上引入坐标注意力和Swin Transformer模块。坐标注意力将通道注意力分解为两个一维特征编码过程,分别沿两个空间方向聚合特征。通过这种方式,可以沿一个空间方向捕获远程依赖关系,同时可以沿另一个空间方向保留精确的位置信息。然后将得到的特征图单独编码成一对方向感知和位置敏感的注意力图,这些图可以互补地应用于输入特征图,以增强感兴趣对象的表示。本文在YOLOv5中的Backbone部分引入坐标注意力模块,可以使网络更高效地提取特征信息,忽略航拍图像中的背景信息等不重要的信息,更多地关注图像中需要检测的目标信息。本文引入一种分层Transformer,它是用移位窗口来进行计算的,Swin Transformer通过在窗口内使用自注意力机制,带来了更高的效率,使网络更好地关注感兴趣区域,因此忽略背景信息。同时,通过采用移动窗口,使相邻的两个窗口之间有信息交互,上下层之间也就有了跨窗口连接,从而变相达到了一种全局建模的效果。在YOLOv5中的Neck部分引入了Swin Transformer模块,可以有效地捕获图像的全局信息,得到丰富的上下文信息,解决了多尺度目标的问题,同时,可以有效地提取图像中的目标信息,忽略掉背景信息。(3)考虑到在航拍图像中采用通用目标检测算法,得到的检测效果较差。针对这个问题,本文从网络结构中的特征提取和特征融合部分着手,在特征提取Backbone部分,YOLOv5原算法中采用的是C3模块,此模块主要借助CSPNet提取分流的思想,同时结合残差结构的思想。本文将Backbone部分的C3模块替换为C2f模块,C2f模块参考了C3模块和YOLOv7中使用的ELAN的思想,ELAN模块可以获得更丰富的梯度信息,从而可以更高效地提取目标的特征信息。为了使网络更高效地融合Backbone提取的特征信息,本文把Neck中的PAFPN模块改为DAMO-YOLO中的GFPN(Generalized FPN),GFPN能够充分交换高级语义信息和低级空间信息。
{URL}: https://link.cnki.net/doi/10.27438/d.cnki.gyadu.2023.000833
{DOI}: 10.27438/d.cnki.gyadu.2023.000833
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 番茄采摘机械手的场景感知及试验研究
{Author}: 李晶
{Tertiary Author}: 王妍玮;王志强
{Publisher}: 黑龙江八一农垦大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 棚室番茄;机械手;神经网络;点云
{Abstract}: 番茄是世界上种植最广泛的一种蔬菜。其含有丰富的番茄红素,有药用价值及很高的营养价值,因此,番茄的种植面积及产量均呈稳步上升趋势。近年来,农村人口城镇化的加快,使番茄采摘劳动力出现明显短缺。随着人工智能技术的发展,在番茄采摘过程中使用智能化机械,减轻人力负担的同时提高采摘效率。以北纬39°大连市金州区棚室番茄为研究对象,从番茄采摘机械手的场景感知展开研究,通过对番茄生长环境的调研、对人工采摘和机械手采摘的动作对比,运用计算机视觉识别和定位的方法,通过.NET编写程序,改进和优化算法,使用双目深度相机动态识别番茄的果实形态,利用卷积神经网络对识别准确率进行优化,提高识别效率,进而提高机械手采摘的效率,同时对提高遮挡番茄的识别率也有一定效果。主要研究内容包括:(1)设计了番茄采摘机械手的场景感知系统。场景感知系统由行走底盘、采摘执行器、视觉系统、控制系统四个部分组成,行走底盘采用差分轮式机构。机械臂采用三自由度机械臂,机械手采用刀片式剪枝机构,视觉系统采用双目深度相机。(2)对场景感知系统中番茄的识别进行研究。使用Label Img软件进行番茄静态数据集的制作,使用.NET编写程序,实现对番茄动态数据帧的提取。基于深度学习卷积神经网络,使用YOLOv7算法进行识别,从而提高番茄的目标识别效率。(3)对场景感知系统中番茄的定位进行研究。使用双目深度相机对番茄进行目标定位,使用张氏标定法进行相机标定和纠正畸变,使用Python语言编写程序,将点云数据转换后通过上位机、下位机传输,实现视觉系统与采摘执行器的信号传输。(4)用.NET语言编写了场景感知系统操作程序,并进行田间试验。经过试验验证,动态识别反馈时间缩短,识别速度提高。番茄的识别准确率98.2%,对遮挡番茄的识别率达到95.1%。
{URL}: https://link.cnki.net/doi/10.27122/d.cnki.ghlnu.2023.000150
{DOI}: 10.27122/d.cnki.ghlnu.2023.000150
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 联合检测和重识别神经网络的多目标跟踪算法研究
{Author}: 侯皓雄
{Tertiary Author}: 高伟
{Publisher}: 中国科学院大学(中国科学院西安光学精密机械研究所)
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视觉多目标跟踪;坐标注意力;角度中心损失;二次数据关联;轻量化网络
{Abstract}: 视觉多目标跟踪作为热点的计算机视觉任务之一,广泛应用在视频监控、交通规划、无人驾驶以及军事勘察等领域。其目的是定位视频中多个感兴趣目标,同时为每个目标分配唯一且长时有效的身份标识,以此获得多个目标的运动轨迹。基于联合检测和重识别神经网络的多目标跟踪算法可以实现模型端到端的训练和推理,但是面对复杂场景时,如目标表观特征变化、相似目标干扰以及频繁遮挡等,其仍然存在错检、身份标识切换以及轨迹断裂等问题,并且模型尺寸较大,推理过程中比较耗时。本文旨在解决上述多目标跟踪算法综合跟踪能力和实时性不足问题,使用Fair MOT算法作为基线,围绕算法网络框架、多目标跟踪器和轻量化模型三个方面进行创新和改进,主要工作如下:(1)提出了一种基于坐标编码的增强重识别多目标跟踪算法。首先,为了满足多目标跟踪算法对共享特征的高质量要求,本文通过在特征提取网络中间层融入坐标注意力模块来整合通道和空间信息,使网络更加关注感兴趣特征。然后,针对基线算法提取的重识别特征模糊问题,使用提出的角度中心损失函数来监督重识别分支训练,在角度空间中将同类目标的重识别特征约束在其类别特征中心附近,获取高质量可判别的特征。最后,根据多任务学习的耦合性,分析多目标跟踪需要低维度重识别特征,并选取适应本文算法的维度,以此平衡检测和重识别两个子任务。在MOT17 Val数据集上,相较于基线算法多目标跟踪指标MOTA和IDF1分别提升了0.7和1.4,IDs数量降低了18.6%。(2)提出了一种基于融合特征相似度的二次数据关联多目标跟踪算法。在已经改进的网络框架基础上,进一步优化多目标跟踪器。一方面,针对基线算法特征相似度表达能力不足的问题,设计了GR(GIo U and Re-ID)融合特征相似度,联合运动特征模型和重识别特征模型进行综合评估,更好地反映了检测框和轨迹预测框之间的相似关系。另一方面,针对以往数据关联过程中对低置信检测框处理不佳的问题,提出了一种高效的改进型二次数据关联策略,对高、低置信度检测框分为两个阶段与轨迹进行匹配,有效避免了信息损失,减少因为遮挡产生的漏检以及轨迹断裂问题。在MOT17 Val数据集上,相较于基线算法MOTA和IDF1分别提升了1.8和3.2,IDs数量降低了32.7%。除此之外,在官方MOT Challenge榜单上,于MOT16 Test和MOT17 Test两个数据集赛道相较于其他先进算法取得领先。(3)提出了一种基于轻量化网络的多目标跟踪算法并在嵌入式平台部署。针对基线算法的高存储空间占用和高推理耗时问题,本文设计了轻量化的特征提取网络,对当下最新版本的YOLOv8s检测网络进行适应性改造,引入到联合检测和重识别范式的多目标跟踪算法框架中。为了缩小因为模型尺寸减小导致的跟踪精度差距,使用前文已提出的部分组件进行优化,在维持具有竞争性跟踪能力的同时实现了小模型和快速推理,并在算力和功率受限的嵌入式平台部署。在MOT17 Val数据集上,相较于基线算法MOTA损失了3.4,但模型尺寸减小了68.7%,运行帧率提高了1.7倍。
{URL}: https://link.cnki.net/doi/10.27605/d.cnki.gkxgs.2023.000064
{DOI}: 10.27605/d.cnki.gkxgs.2023.000064
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像边缘检测算法研究
{Author}: 耿石磊
{Tertiary Author}: 赵建光
{Publisher}: 河北建筑工程学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 边缘检测;深度学习;注意力机制;HED网络
{Abstract}: 图像边缘检测是计算机视觉和图像处理领域中的基本问题,在数字图像处理中,更深层次的计算和操作都是基于边缘检测的结果,因此如何准确、清晰地感知并提取图像的边缘成为了图像处理的关键工作。随着深度学习引领计算机视觉的快速发展,基于卷积神经网络的边缘检测算法已经成为了图像处理中的研究热点,在清晰场景下的边缘检测已经得到了优秀的结果,但在处理模糊图像时会出现边缘提取不准确的问题,在弱边缘图像的处理工作中会出现边缘提取不完全的问题。因此,本文基于HED网络为基础,对图像边缘检测算法展开新的研究,本文的主要工作如下:(1)提出了一种基于HED网络的边缘检测算法。通过分析HED网络在不同场景下的检测结果,针对传统HED网络在弱图像边缘表现出来的边缘不完整等问题,提出改进的深度学习网络算法。对HED网络结构进行修改,将两个池化层改为同步长、相同卷积核数量的卷积层,减少池化层数量,提高了每个卷积层输出图像的分辨率。修改了侧面输出层中的反卷积层,优化了网络模型。为避免出现二分类等问题,调整网络的激活函数,引入非线性函数Re LU作为深度学习网络的激活函数。设计实验对改进的网络模型进行验证,针对实验结果进行分析。经实验结果验证,修改后的网络结构性能得到提升。(2)提出了融合软性注意力机制的深度学习网络模型。针对改进后的HED网络中,数据计算量大、计算资源有限的问题,通过软性注意力机制对输出数据进行权值分配,调整网络内部的计算顺序,将计算资源优先集中在外部边缘的处理上,提高网络模型效率。对上述网络模型进行实验,在BSDS500和NYUDv2数据集上进行验证。设置评价指标,从网络响应速率、检测精度和可视化图像分析三个角度分析实验结果。经过实验验证,改进后的深度学习网络模型对比原始网络模型在相关指标上均有所提升。
{URL}: https://link.cnki.net/doi/10.27870/d.cnki.ghbjz.2023.000108
{DOI}: 10.27870/d.cnki.ghbjz.2023.000108
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的机械臂路径规划方法的研究
{Author}: 杜吉祥
{Tertiary Author}: 蔡长青;徐庆
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机械臂;运动学;机器视觉;图像处理;路径规划
{Abstract}: 生产流程中目标物体的识别和抓取是非常重要的。由于传统工业机器人的智能化程度有限,因此无法实现全面应用。机器人技术可以应用于各种复杂的环境,而不仅仅是简单的场景。随着计算机和大数据技术的进步,机器人已经变得越来越具有创造力。随着技术的进步,传统的工业机器人已经不再能够满足当今复杂的环境和任务的要求,它们可以根据自身的计算能力,自主地完成各种重复、单一且具有规律性的任务,而无需受到外部环境的影响。因此,赋予机器人视觉感知能力具有极其重要的意义,可以改变未来的发展方向。针对上述问题,本文以DOBOT四自由度轻量型桌面机械臂为研究对象,结合机器视觉和路径规划算法应用到机器人控制系统中,并围绕着图像处理与路径规划这一问题,并在仿真环境和现实状态中设计并搭建了一套实验平台。机器人在感知到目标物体位置后,根据规划算法动态地调整自身的运动行为,保证机器人成功抓取目标后按照规划路径运行到放置点。这篇文章将综合运用机器人运动学、机器视觉和路径规划等技术,进行研究与分析。主要内容如下:1.搭建基于视觉的机械臂抓取仿真实验平台,通过仿真环境分析视觉处理系统和路径规划系统。2.通过MATLAB构建DOBOT机械臂运动学模型,并利用MATLAB软件解算其变换矩阵,从而得到机械臂的运动学方程。根据DOBOT机械臂的结构特征,对机械臂进行运动学分析。3.通过MATLAB分析实现机器视觉的图像处理与图像标定,通过图像预处理、边缘检测、图像标定等操作,保证对目标物体的准确识别与定位。4.实现基于采样的快速扩展随机树路径规划算法,通过引入样条插值和目标点引力场的方法对RRT*算法进行改进,保证视觉获取到目标点位置后,能够高效地进行路径规划。5.结合MATLAB和Coppelia Sim(VREP)联合仿真环境搭建实物运行场景。对整个系统进行实验验证与分析。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000458
{DOI}: 10.27805/d.cnki.gccgy.2023.000458
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉Transformer的行人检测算法研究
{Author}: 吕新尧
{Tertiary Author}: 白成杰
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 行人检测;视觉Transformer;Transformer编码器;Transformer解码器;鲁棒性
{Abstract}: 行人检测是计算机视觉领域中的一个经典问题,其性能决定了各种以人为中心视觉技术的发展,如何设计具有更高性能、更强鲁棒性的行人检测算法,一直是具有重要现实意义的研究课题。随着深度学习的发展,研究者提出了诸多基于卷积神经网络的行人检测算法,在检测准确率和检测速度上,都取得了很大提升。近年来随着Transformer从自然语言处理领域发展到计算机视觉领域,凭借其全局注意力机制,在图像识别、目标检测等视觉任务中展现出强大的性能,使用视觉Transformer进行行人检测,已成为值得研究的热门方向。针对通用目标检测算法DETR在行人检测上的不足,从自动驾驶应用视角出发,基于DETR进行了改进,提出了一种完全Transformer的行人检测算法CF-DETR,主要研究工作概括为5个方面。(1)网络架构设计。算法遵循DETR检测器的端到端检测设计,将行人检测流程简化为集合预测问题。使用基于集合的全局损失函数,通过二分匹配和Transformer的编码器-解码器体系结构,强制进行唯一的预测,简化了检测流程。(2)编码器设计。在DETR中,受到计算复杂度的限制,编码器的处理对象是经过卷积神经网络提取出的图像特征。而在CF-DETR中,使用Transformer编码器直接处理图片,并使用Swin Transformer中的窗口注意力,来解决计算量偏大问题。(3)解码器设计。CF-DETR使用解耦方式,即将解码器中的目标查询解耦为内容查询和空间查询两部分,提高了算法训练的收敛速度。此外,为了给模型提供更好的位置先验,对解码器中的互注意力部分进行了修改,进一步增强检测器性能。(4)算法验证。为探究CF-DETR算法改进的有效性,在多个数据集上进行对比实验和消融实验,通过实验数据验证算法改进的可行性与有效性,通过可视化分析,直观展示检测效果。(5)鲁棒性与泛化性研究。深入探究鲁棒性,通过跨数据集训练测试的方式,评估算法的鲁棒性和泛化性。对此进行多组实验探究,并使用多数据集渐进式训练的方式,进一步提高检测器的性能。经过一系列研究工作,取得了一些成果以及创新之处如下:(1)更具整体性的网络结构设计。原始DETR使用卷积神经网络进行特征提取,然后使用Transformer对特征进行处理,仅仅使用了卷积神经网络的高层特征,容易造成细节特征丢失。而CF-DETR直接使用Transformer处理原始图片,受益于Transformer的全局注意力,能够使网络更好把握全局特征和细节特征,进一步提高网络性能。摒弃卷积神经网络,使用Swin Transformer编码器直接处理图像,进一步简化了网络结构,增强了算法网络结构的整体性。(2)更容易收敛的网络设计。由于DETR中分类任务和定位任务都依赖于目标查询,这对目标查询的质量提出了更高要求,使得网络需要更多轮次的训练才能收敛。CF-DETR对两个任务进行了解耦,将目标查询解耦为内容查询和位置查询两部分,分别负责分类和定位任务,显著加快了网络的收敛速度。此外,为了给检测网络提供更好的位置先验,在注意力图中注入比例信息,进一步加快网络收敛。(3)进一步提高网络的鲁棒性和泛化性。通过对现有算法在交叉数据集上训练测试结果进行分析,采用规模更大、更具有多样性的行人检测数据集进行预训练,使用渐进式微调策略,使得网络获得更强的性能,进一步提高检测的准确性。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2023.001618
{DOI}: 10.27280/d.cnki.gsdsu.2023.001618
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于关键点检测的水下鱼体长度测量技术研究与实现
{Author}: 程思奇
{Tertiary Author}: 于红;刘圣聪
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 鱼类体长测量;计算机视觉;关键点检测;YOLO5Face;Realsense D435i
{Abstract}: 工厂化养殖正朝着精准养殖的方向发展,鱼类体长数据是精准养殖中的一项重要指标,能够直接反映鱼类的生长情况,为渔业领域提供可参考的数据。随着计算机视觉的发展,已有大量采用图像处理或深度学习技术的无接触式鱼类体长测量研究,但部分方法仍需人工干预、限制了鱼类的自由游动,不适用于水下鱼体长度的动态测量。因此,本文针对上述问题,提出了基于关键点检测的水下鱼体长度测量方法,具体内容及创新点如下:(1)基于R-YOLO5F模型和分段测量的鱼体长度测量方法。针对YOLO5Face模型定位鱼体特征点不准确的问题,提出了R-YOLO5F模型。模型借鉴Res Net(Residual Network,残差网络)中残差模块的思想,通过在输出层的卷积模块两端进行短接,以获得更加丰富的高层特征,提升关键点检测的准确性;针对鱼在游动过程中身体弯曲对体长测量结果造成的影响,提出了五点式关键点标注方案,结合R-YOLO5F模型和Realsense D435i深度相机并利用欧氏距离公式对鱼体进行分段测量。为验证所提模型及测量方法性能,分别设计了模型和测量误差的对比实验。实验结果表明,关键点检测模型R-YOLO5F的召回率、准确率分别达到了93.46%、91.62%,较原模型分别提升了1.18%和0.88%。测量结果表明,五点式测量方案平均相对误差较两点式测量低1.04个百分点。(2)基于DR-YOLO5F的鱼体关键点检测模型。针对R-YOLO5F模型在鱼体倾斜等情况下出现关键点偏移的问题,对模型进行了改进,提出了DR-YOLO5F模型。为解决特征丢失的问题,借鉴Dense Net(Densely Connected Convolutional Networks,密集连接卷积网络)中Dense Block的思想,在Neck层和输出层之间以密集连接的方式对特征进行传递,以提高关键点检测的准确率。为验证改进后的模型性能,对DR-YOLO5F模型分别进行消融实验和模型对比实验。实验结果表明,DR-YOLO5F模型的准确率、召回率分别达到了94.67%、93.52%,较R-YOLO5F模型分别提高了1.21%、1.90%。并对改进前后的模型进行鱼体长度测量的误差对比实验,结果表明,改进后的模型DR-YOLO5F的体长平均相对误差较R-YOLO5F降低了0.89%。(3)鱼体长度测量系统的设计与实现。本文设计了一种无接触式鱼体长度测量系统,能够对输入数据中的鱼类目标进行关键点检测并输出体长测量结果。考虑到用户对系统的具体需求,在模型检测模块与长度测量模块两大主要模块的基础上,还添加了数据输入模块为用户提供多种读取数据的方式,同时为方便用户对模型、参数等进行选择或修改,设计了权重选择模块与参数调整模块。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2023.000289
{DOI}: 10.27821/d.cnki.gdlhy.2023.000289
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的医学影像语义分割算法研究
{Author}: 周鑫
{Tertiary Author}: 尹晓霞
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学影像分割;乳腺癌分割;深度学习;Transformer
{Abstract}: 病灶的准确分割对各类疾病的定量分析有重要意义,早发现病灶,早确诊能大幅提高患者的生存率。随着人工智能技术近些年的兴起,研究人员尝试将语义分割与医学影像分析结合,旨在提高医生临床检查中分割病灶的效率。乳腺癌是一种患病人数较多的疾病,针对乳腺癌病灶诊断难点提出对应的解决方案具有重要的现实意义。本文重点探讨乳腺癌医学影像诊断中遇到的微小病灶定位难题以及肿瘤生长扩散带来的模糊边界问题。针对上述两个乳腺癌诊断的关键问题,本文从不同方向提出两个基于Transformer的乳腺癌病灶分割模型。本文的主要研究工作概述如下:(1)磁共振成像是重要的乳腺癌检测方法,但是乳腺癌病灶在磁共振影像中面积小,难以定位。针对乳腺癌肿瘤在磁共振影像中定位困难的现状,本文提出一种基于轴向注意力机制的Transformer分割模型。与其他医学分割方法不同,本文仅依赖注意力机制构建分割模型,深入探索Transformer模型在乳腺癌分割任务上的应用潜力。针对医学影像尺寸偏大的特点,本文将二维图像上传统的注意力机制分解为沿图像高度轴与宽度轴的两个一维注意力,降低Transformer在大尺寸医学影像上的计算复杂度。本文在轴向注意力计算的过程中引入相对位置信息和门单元,限制不准确的位置信息并突出可能包含病灶的像素块。在乳腺癌磁共振影像数据集上的测试表明,基于轴向注意力的Transformer分割算法对乳腺癌微小病灶有良好的定位精度,实现定位病灶的基本功能。(2)在临床诊断中,仅完成肿瘤的准确定位还不足以辅助医生提高诊断效率,一个更为棘手的问题是癌细胞固有扩散特性导致病灶与正常组织之间存在模糊边界。为了解决这一难题,本文提出一种基于边缘注意力的Transformer分割模型,通过引入边缘关键点以及构建针对边缘分割的损失函数,提高对肿瘤模糊边界的分割精度。此外,通过在模型解码器部分加入参考点,实现边缘分割准确的同时做到定位准确。乳腺癌磁共振影像及乳腺癌超声影像共三个数据集上的实验结果表明,本文提出的模型具有良好的分割性能,各项指标均超过对比模型,能有效解决乳腺癌病灶在不同类型影像中的模糊边界问题,保证了病灶分割的准确性与完整性。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.000946
{DOI}: 10.27040/d.cnki.ggzdu.2023.000946
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉技术的无人机检测方法
{Author}: 陈梦雅
{Tertiary Author}: 刘新锋;侯小叶
{Publisher}: 山东建筑大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 无人机检测;小目标检测;计算机视觉;YOLOv5;EfficientNet;DeepSORT;基于BN层的模型剪枝方法
{Abstract}: 无人机技术近年来发展迅猛,广泛应用于各行各业。然而,随着无人机技术的不断发展,无人机引发的恐怖袭击、武装冲突事件越来越多,机场的黑飞事件、隐私泄露事件也时有发生,无人机技术的需求越来越强烈。因此,研究精准的无人机检测方法对于国防和社会安全具有重要的意义。然而,由于无人机具有“飞行轨迹低、运动速度慢、体积小”等特点,检测存在一定的困难。针对无人机目标过小难以检测、检测受光线限制、易与空中飞行的鸟类混淆、检测速度难以达到实时性标准、难于跟踪等问题,本文提出了一种基于计算机视觉技术的无人机检测方法,具体解决方案如下:1.为了解决夜间或光线昏暗条件下难以检测的问题,本文建立了可见光和热像两种数据集,用于日、夜间两种模型的生成,并加入Det-Fly公开数据集对自采数据集进行补充,共包含23858张图像的数据。同时,加入两种数据增强方法。为弥补热像模型与可见光模型的检测差距,在热像数据集中添加了灰度化可见光图像的数据增强技术;为进一步提高数据集背景、位置多样性,对两种数据集都增加一种针对小目标的数据增强方法。实验结果能够证明两种数据增强方法的有效性。2.针对实际应用场景对检测速度的要求,本文选用检测速度较快的YOLOv5算法实现无人机目标检测模型。通过对YOLOv5的不同版本和输入分辨率进行测试,确定了适合无人机检测的最优参数,并得到可见光和热像两种检测模型。同时,在YOLOv5无人机检测模型的基础上增加基于BN层的模型剪枝方法,以进一步提高模型的检测速度。为了解决无人机与鸟类混淆的问题,本文选用Efficient Net算法对YOLOv5检测结果进行二次分类,能够有效提高检测精度。3.为解决目标检测中可能出现的遮挡、重叠或不清晰等问题,本文引入了多目标跟踪算法Deep SORT实现无人机目标的实时跟踪,并对其进行了改进,引入DIo U匹配方式提高预测轨迹的准确性和降低目标跟丢次数。实验结果表明,本文方法在无人机目标跟踪方面具有较高的准确性,且能够满足实时性标准。为了更好地展示跟踪效果,本文基于Python GUI实现了跟踪系统可视化展示,提供可见光、热像模式选择,能够精准定位每个出现在视野中的无人机目标并实时追踪。总体来说,本文提出了一种基于计算机视觉技术的无人机检测方法,通过数据集优化处理、模型选择和剪枝、检测+跟踪模式等,解决了无人机检测领域常见的检测难点。实验结果显示,所提出算法在精度和速度方面均有一定的优势,该方法具有一定的实际应用价值,可以为无人机技术的发展提供一定的参考和指导。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2023.000452
{DOI}: 10.27273/d.cnki.gsajc.2023.000452
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的林业害虫图像识别方法研究
{Author}: 刘陆洋
{Tertiary Author}: 刘冰
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像识别;深度学习;林业害虫数据集;自监督分类;目标检测
{Abstract}: 近些年来,图像识别技术得到了迅速发展,在农业领域得到了广泛应用,极大的降低了病虫害对农作物的影响。如今,农业害虫识别领域存在着如下问题:对于林业虫害领域缺乏可用的数据集,部分基于实验室环境收集的数据集无法适应复杂环境的应用需求;另一方面,模型对细粒度特征的提取存在着一定的限制,从而导致了小目标害虫的识别性能无法满足现实需求。针对上述问题,本文对基于深度学习的林业害虫分类和检测方法开展研究,主要工作内容如下:（1）数据集的构建。创建了林业害虫数据集（FPD）。包含了用于分类的FPD-Classification数据集和选用了旋转、翻折、添加噪声等数据增强方式进行样本扩充,并添加注释信息,用于检测任务的FPD-Detection数据集。（2）提出一种改进的自监督Mo BY害虫分类模型。由于Mo BY缺少对图像细粒度特征的提取,从而导致模型在细粒度目标上的性能较低。针对该问题,本文借鉴像素重建模块,提出了轻量级Pixel-decoder模块,并基于Mo BY模型构建一种新的网络模型,命名为Pixel＿Mo BY。经过实验验证,Pixel＿Mo BY模型在FPD-Classification数据集上的准确率提高到了74.41%,较Mo BY模型提高了3.32%。此外,该模型在下游小目标检测任务上相较于Mo BY也提高了2.78%。最后通过消融试验,找到了最佳的网络参数。（3）提出一种改进的DETR目标检测模型。由于Transformer的自注意力造成的特征图分辨率不能太高的问题导致检测性能不佳,对此,为兼顾计算量与性能,设计了一种改进的DETR网络模型,添加轻量化的特征提取分支,提高模型在各个尺度目标上的检测性能。命名为DW＿DETR,通过实验验证模型改进的有效性,经实验验证,DW＿DETR模型在FPD-Detection数据集上相比原模型在m AP和m APsmall分别取得了8.4%和6.1%的精度提升。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000226
{DOI}: 10.27805/d.cnki.gccgy.2023.000226
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉和深度学习的疲劳驾驶检测算法研究
{Author}: 贾慧杰
{Tertiary Author}: 肖中俊
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 疲劳驾驶检测;人脸检测;头部姿态估计;面部多因素结合
{Abstract}: 疲劳驾驶是造成交通事故的重要原因,因此实现有效的疲劳驾驶检测尤为重要。目前的疲劳驾驶检测算法存在舒适性差、易受外界因素影响(光照强度、戴口罩、戴太阳镜)、准确度低、实时性差等问题。现有的疲劳检测算法大多是基于单网络的,由于司机处于疲劳驾驶状态时,每个司机所呈现的疲劳状态会有差异,因此基于单网络的疲劳检测算法很难同时准确的检测出驾驶员所有的面部特征。针对这些问题,本文设计了基于计算机视觉和深度学习的疲劳驾驶检测系统。该系统包括人脸检测模块、头部姿态估计模块、眼嘴状态判断模块以及多因素融合判定模块。首先通过人脸检测模块检测驾驶员的人脸和五个特征点,并根据特征点截取出驾驶员眼睛和嘴区域。将检测到的驾驶员人脸图像和截取到的眼睛和嘴区域分别传入到头部姿态估计模块和眼嘴状态判断模块中,来计算驾驶员的头部姿态角和进行眼嘴状态判断。最后通过多因素融合判定模块综合的对驾驶员的疲劳状态进行判定。本文主要工作和创新点如下:1.在人脸检测模块中本文设计了一款轻量人脸检测网络。该网络可以在减少计算量、提高推理速度的同时保证了准确率,实现了在驾驶过程中可以实时、准确的进行人脸检测和人脸对齐。网络包括特征提取、特征融合、多任务损失函数三个部分构成。本文设计了新的损失函数,该损失函数除了进行人脸框回归外还可以回归人脸五个特征点,有助于人脸检测。新损失函数可以使模型收敛更快、人脸框回归更稳定,提升网络准确度。2.在头部姿态估计模块中本文设计了一个用于计算驾驶员头部姿态角的网络。该网络将头部姿态回归问题转化为分类问题,采用由粗到细的分类策略。与利用CNN提取二维人脸关键点的主流方法相比,该网络计算复杂度更低、准确率更高、检测速度更快。3.在眼嘴状态判断模块中本文使用对全局信息把握能力更好的Transformer来代替CNN。Transformer利用自身的自注意力机制能更好的学习图像的全局信息。同时为了更加充分的利用图片的上下文信息,本文对Transformer中的self-attention机制进行改进,首先对key进行上下文编码,然后通过卷积来生成注意力矩阵。4.驾驶员在出现疲劳状态时面部多个特征会有明显的变化,如眨眼频率的变化,打哈欠次数增多,眼睛闭合时间变长,头部姿态不端正等现象。因此本文根据驾驶员的眼睛、嘴和头部姿态三个面部特征设计了MF-Algorithm,通过头部姿态估计模块和眼嘴状态判断模块的输出,根据眨眼频率、闭眼时间比例、单次闭眼时长、打哈欠时间比例以及头部姿态多个因素综合判断驾驶员是否存在疲劳驾驶的情况。5.利用多个模块检测驾驶员的面部特征,并利用多个模块的信息来综合进行判断,各个模块互相作用减少外界因素的干扰,可以有效地解决驾驶员开车时戴墨镜或口罩导致嘴或眼睛被遮挡的问题。整个系统基于计算机视觉和图像处理技术来获取驾驶员面部特征。该系统仅需要在驾驶员前方放置一个RGB相机,保证了驾驶员的舒适性。利用多个网络相互结合可以减少外界因素的影响,利用驾驶员多个面部特征进行综合判断可以提升系统的准确度。在WIDER FACE和BIWI公共数据集上证明了各个模块的有效性,同时,整个系统在自建数据集上进行测试,准确度到达了97.8%。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000899
{DOI}: 10.27278/d.cnki.gsdqc.2023.000899
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件识别与定位系统研究
{Author}: 高伟
{Tertiary Author}: 李致金
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;识别;定位;机器人
{Abstract}: 随着我国工业进程的进一步深化,产品生产的批量越来越大,产品生产中工艺要求也越来越精细。传统制造企业中,产品生产中的相关检测常采用人工操作或半自动化机械式操作。人工操作存在误差大、工作强度高以及成本高等问题,而使用半自动化机械操作只能单一的执行,灵活性差,无法达到自动化生产中快速、高效、智能化的要求。本文从工业生产具体应用出发,设计了一套基于机器视觉的工件识别定位检测系统,围绕该系统主要完成以下工作:(1)机器视觉系统的整体标定。建立相机视觉模型,通过Matlab标定相机,获取相机内外参数并得出其投影误差。根据实际情况,相机与机器人之间采用眼到手模型,并优化该模型的手眼标定方法,快速获取机器人坐标与相机坐标的转换矩阵。通过相机标定与手眼标定得出的参数为之后的定位打下基础。(2)图像预处理与轮廓提取。首先,结合检测工件的特性,设计了合理的图像预处理方案,通过SSIM和PSNR指标分析衡量三种滤波效果,最终选择效果较好的双边滤波。对比分析常用的分割法效果,实验表明OTSU分割法效果更优。然后,针对OTSU分割算法存在效率低和抵抗性能差问题,本文提出了改进OTSU图像分割算法。使用滤波前后的差分图像作为OTSU算法的输入,在OTSU算法中引入本文改进后的海鸥算法。通过实验表面,改进后的OTSU算法能够通清晰的提取出本文研究内容的商标轮廓信息。最后,通过形态学处理分割的图像,去除多余孤立的点并消除毛刺和孔洞。(3)针对Hu矩匹配在复杂工况下难以选取合适阈值实现精确匹配识别、SIFT特征匹配在复杂工况下存在特征点误匹配问题以及耗时较多问题,本文提出了基于全局Hu匹配和局部SIFT匹配融合的Hu-SIFT快速匹配方法,并针对融合后的Hu-SIFT算法存在的问题,提出了改进后的Hu-SIFT算法,提升匹配精度,降低了运算时间,满足了实时检测的需求。对工件检测中定位需求,提出了主轴旋转法降低了最小外接矩形的时间复杂度,并利用基于辅助模板与最小外接矩形结合的定位方法。(4)设计了产品检测定位系统。具体分析了软件主要功能,基于VS2019开发环境、MFC Windows平台应用程序开发框架以及Open CV开源图形处理库,编制了一套产品视觉检测软件系统。完成了硬件的设计、安装和调试。视觉系统计算出定位数据传输给与4轴机器人实现精确定位。本系统实现了产品在线检测、工艺定位的智能化,提高了协作厂家工业生产的自动化水平。本课题设计系统已应用于亳州福达印务有限公司生产线中,取得了很好的使用效果和经济效益。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2023.000278
{DOI}: 10.27248/d.cnki.gnjqc.2023.000278
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的混凝土桥梁裂缝分级检测研究
{Author}: 张锋
{Tertiary Author}: 王立彬;王飞球
{Publisher}: 南京林业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 无人机;计算机视觉;裂缝检测;图像拼接;图像处理
{Abstract}: 我国混凝土桥梁存量大,增长快,“老龄”混凝土桥梁数量增长迅速,导致养护压力日益增大。表观裂缝是表征混凝土桥梁性能的重要指标之一,其快速检测和精确定位是混凝土桥梁养护的重要技术支撑。计算机视觉技术近年来发展迅速,然而,受限于对计算资源和储存设备的较高要求,其在中小型桥梁上仍无法得到广泛应用。本文结合无人机摄影技术及计算机视觉技术,实现了桥梁裂缝检测的分级检测及检测结果的多维度可视化,填补了桥梁智能检测在资源受限条件下的空白。具体研究内容如下:(1)通过文献分析总结了无人机、计算机视觉技术以及桥梁检测系统理论在桥梁运维中的应用现状,指出了目前桥梁病害检测与管维过程中的不足之处,在此基础上提出了本文研究框架。(2)提出了一个包含140000张图像的大型混凝土裂缝图像数据集,并构建了一个基于卷积神经网络的轻量级裂缝分类检测模型,能够在有限的计算资源和储存设备条件下对桥梁裂缝进行快速、准确的识别检测。并且在移动办公笔记本上能够稳定快速地运行,适用于中小型桥梁的快速检测和大型桥梁的初步筛查,能满足轻量级检测需求。(3)构建了基于YOLOv5和YOLACT算法的桥梁裂缝精细化检测模型,实现了实时性目标检测和实例分割,与轻量级裂缝分类检测模型共同组成混凝土桥梁裂缝分级检测算法。并通过目标框标注和像素级实例分割标注,建立了一个包含1231张表观裂缝图像的数据集。定量评估和定性评估结果表明,模型具有较高的检测精度和较强的鲁棒性,具有优秀的高速推理优势。并设计完成了一个集成三种检测模型的图形用户界面,能够快速上传图像或视频,并自动调用所选用模型和输出检测结果。(4)提出了一种适用于可视化检测结果的图像拼接方法,能够将无人机拍摄的局部高清图像无损拼接为一张完整的高分辨率二维全景图像。试验结果表明,该算法可有效排除噪声和光照条件影响,并对大量图像包括红外类图像进行快速准确的拼接,并结合裂缝分级检测算法实现裂缝整体的识别检测,具有较强的鲁棒性。(5)采用无人机倾斜摄影技术实现桥梁全貌的三维模型重建,为桥梁提供全局的数字图像信息。能够针对复杂的桥梁结构,迅速准确地定位裂缝位置,从而全面地掌握现役桥梁的实际状态,为检测结果提供可靠且直观的宏观可视化支持。综上所述,本研究结合深度学习的目标检测技术、全景图像拼接技术以及基于倾斜摄影的三维重建技术等多种计算机视觉方法,实现了桥梁病害分级检测、定位与可视化的全面覆盖。该系统适用于各类型桥梁及其不同检测需求,通过微观、局部及宏观层面,能够生成清晰直观的输出结果。本研究为桥梁检测领域提供了一种具有学术价值和实用性的综合解决方案,有望推动我国桥梁运维领域的智能化转型。
{URL}: https://link.cnki.net/doi/10.27242/d.cnki.gnjlu.2023.001019
{DOI}: 10.27242/d.cnki.gnjlu.2023.001019
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的景区清洁机器人垃圾分拣方法研究
{Author}: 高飞
{Tertiary Author}: 郝崇清;樊劲辉
{Publisher}: 河北科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 改进YOLO v7;垃圾分拣;机器人;改进MobileNet v3;ROS
{Abstract}: 传统的景区垃圾清理主要靠人工完成,其效率低、成本高且部分垃圾对人体有害。随着机器视觉和机器人技术的快速发展,使用机器人代替人工进行垃圾分拣已经成为发展趋势,因此研究基于机器视觉的景区清洁机器人对于景区垃圾清理的无人化、智能化具有重要意义。本文利用ROS操作平台并结合深度学习方法构建具有垃圾分类识别功能的视觉系统,并部署到移动机器人实验平台,通过手眼标定以及Move It!中的运动规划算法实现景区垃圾分拣回收任务,具体内容如下:(1)针对当前垃圾图像分类网络大多存在结构复杂、精度低的问题,本文以轻量化模型Mobile Net v3作为垃圾目标检测的骨干网络,通过分类层结构优化、数据增强、RAdam优化和迁移学习等方法对垃圾分类网络进行改进。Mobile Net v3网络经改进后,在国际公开数据集Trash Net上达到了99.6%的平均准确率,其性能优于其他文献所提垃圾分类算法。(2)针对当前公开垃圾数据集较少,且现有数据集大多存在种类较少、分布不均的问题,本文在华为云垃圾分类大赛提供数据集(4大类、40小类)的基础上结合景区垃圾背景自制了垃圾数据集(4大类、25小类)。本文使用YOLO v7作为景区垃圾目标检测的基础网络,针对YOLO v7网络结构复杂、参数量大的问题,将改进后的Moblie Net v3替换掉YOLO v7中的ELAN-CSP骨干网络,并将特征融合网络(FPN)的普通卷积替换为深度可分离卷积。此外,SE注意力模块的引入,可以加强YOLO v7网络的特征表达能力,降低因模型参数量减少而造成精度降低的影响。结果表明,改进后的YOLO v7垃圾检测网络对比原模型,参数量和浮点运算次数(FLOPs)分别降低了49.6%和73.5%,大幅精简网络结构,使模型更轻量化,训练速度更快,最终训练模型在自制数据集上m AP值达90.8。(3)将训练好的改进检测模型部署到移动操作机器人平台,并完成对景区垃圾的分类识别工作,根据识别结果确定执行抓取的垃圾目标及对应放置点。通过手眼标定算法获得目标与机器人基座的坐标变换矩阵,结合ROS中的Move It!运动学计算模块,求解夹爪目标抓取位姿及各关节目标角度,使用RRT-Connect算法完成垃圾的分类抓取动作。本文所提改进YOLO v7模型为景区垃圾分类提供了一种轻量化的实时高效检测算法,结合ROS和机器人平台,给景区垃圾分类的无人化作业提供了一种新思路。
{URL}: https://link.cnki.net/doi/10.27107/d.cnki.ghbku.2023.000504
{DOI}: 10.27107/d.cnki.ghbku.2023.000504
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属手机外壳尺寸测量及表面缺陷检测系统
{Author}: 廉祥
{Tertiary Author}: 沈满德
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;畸变矫正;亚像素边缘检测;引导滤波;缺陷检测
{Abstract}: 金属手机外壳生产过程非常复杂,需要经过多道工序,并且在此过程中时常会出现尺寸超限、表面外观缺陷等质量问题。为了确保其质量符合标准,采用有效的检测手段是必要的。由于生产量庞大,传统的人工检测方法已经无法满足需求。因此,本文基于机器视觉技术对金属手机外壳尺寸测量以及表面缺陷检测进行了研究,主要研究内容如下:(1)搭建了视觉检测系统硬件平台。综合考虑实际应用需求和经济效益,完成了对相机、镜头以及光源的合理选型。在尺寸测量研究中,先使用球积分光源进行相机标定,再使用背光源进行尺寸测量;而在表面缺陷检测研究中,球积分光源与背光源同时使用。(2)介绍了相机标定的原理以及图像畸变的原因,并使用标定算法对图像畸变进行了矫正。通过标定得到的相机内外参数,有效消除了图像的径向畸变与切向畸变。(3)研究了金属手机外壳尺寸测量算法。通过对比几种常见边缘检测算法的检测效果,最后选择了Canny边缘检测算法对手机外壳边缘进行粗定位。同时,提出了一种加权灰度积分中值与拉格朗日插值的亚像素边缘检测方法,完成对手机外壳边缘的精确检测。将求解出的亚像素边缘点利用最小二乘法拟合成直线,并根据所得直线方程计算距离,以实现尺寸测量。(4)研究了金属手机外壳表面缺陷检测算法。采用引导滤波方法,在抑制金属磨砂纹理噪声的同时,尽可能地保护缺陷原有特征。针对手机外壳表面图像光照不均和噪声干扰的问题,提出了一种基于面积阈值与局部阈值分割的缺陷分割算法。通过对缺陷特征进行量化,提出了一种金属手机外壳常见缺陷的分类算法,最终完成对金属手机外壳的四种表面缺陷的检测。(5)针对上述算法研究进行了相关实验,验证了尺寸测量算法和表面缺陷检测算法的可行性、准确性以及鲁棒性,并设计了一套视觉检测系统软件。实验结果表明,尺寸测量算法的精度达到0.03mm以内,平均耗时为354ms;表面缺陷检测算法正确率达到95.11%,平均耗时为376ms。两种算法均具有良好的应用价值,能够满足实际生产的要求。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2023.000343
{DOI}: 10.27698/d.cnki.gwhxj.2023.000343
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的安全帽检测算法研究
{Author}: 徐华
{Tertiary Author}: 邓在辉
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 安全帽检测;目标检测;深度学习;YOLOv5
{Abstract}: 近年来,未佩戴安全帽引发的事故问题层出不穷,如何有效地对工人佩戴安全帽的情况进行监视是建筑安全领域面临的一个重要问题。传统安全帽检测算法依赖人工设计的特征,易受环境因素的影响,稳定性差且检测效果欠佳。为了提高安全帽的检测效果,本文从特征选择、特征融合、网络结构改进等方面开展研究,因此,本文提出了基于残差网络融合注意力机制的安全帽检测方法、基于改进网络结构的安全帽检测方法,实验结果验证了所提出方法的有效性。本文主要工作内容如下:针对YOLOv5算法在进行小目标检测,存在抗干扰能力弱、漏检多等问题,本文提出了基于残差网络融合注意力机制的安全帽检测方法。该方法先使用残差将深-浅层特征信息连接,加强网络与网络之间信息的相互分享,然后再利用注意力机制提升检测算法的精度,最后将原网络的损失函数替换为EIOU,使网络能够更好地反映物体之间的重叠程度,从而提升网络检测能力。通过实验验证改进的有效性,随后采用消融实验和对比实验验证网络改进模块的改进效果以及改进后网络整体的效果。针对YOLOv5算法在进行小目标检测时,存在特征提取能力差、精度较低等问题,本文提出了一种基于改进网络结构的安全帽检测方法。该方法首先采用了Mascio-9的数据增强方式丰富了目标背景,其次引入SE-Net注意力机制使网络聚焦于对识别和分类任务关键的特征,将PANet层替换成Bi FPN层进一步加强网络的特征提取能力,引入加权边框融合方法替代非极大值抑制方法,进一步改善漏检问题,最后对损失函数进行优化。在自制数据集上进行了相关实验,实验结果表明,与原网络模型相比,该方法能够高效的进行安全帽检测,进一步提升了网络精度,实验准确率达91.76%。本文提出的改进的YOLOv5的安全帽检测算法在一定程度上能够有效的解决模型抗干扰能力弱、精度低、漏检较多的问题,并在建筑生产安全领域发展上存在一定的应用空间。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2023.000759
{DOI}: 10.27698/d.cnki.gwhxj.2023.000759
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人脸表情识别研究
{Author}: 刘义凡
{Tertiary Author}: 张洪艳;李文超
{Publisher}: 吉林化工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人脸表情识别;多通道特征融合;卷积神经网络;计算机视觉;驾驶员状态分析
{Abstract}: 近些年来,随着科学技术的不断进步,人工智能领域也取得了快速的发展。并且,人工智能技术已经广泛应用于人类生活学习、生命健康、出行安全等各方面,人们对其应用能力提出了更高的要求。人工智能在人脸表情识别领域的研究,因为其特有应用价值正受到越来越多学者的关注。由于表情识别是一个横跨了计算机、人工智能、生物神经学等多种复杂学科融合而成的交叉学科,所以在机器视觉、生命安全、人机交互、安全出行等诸多领域都有着巨大的应用价值。人脸表情是人类情感信息最为直接的信息传递载体,它可以实时的表达出人类的喜怒哀乐和具体情绪状态。但是表情识别的前提是需要先对人脸进行精准的捕捉与定位,然后对采集到的图像进行图像预处理,以便后期能够更好的完成人脸局部细节特征的提取工作。特征提取作为本课题研究的重点,特征提取工作完成的优劣将直接决定了最终人脸表情识别的结果。因此,针对此项重难点本文提出一种将传统特征提取方法与深度学习相结合的方式来完成这一重要任务。具体的研究方法如下:1.针对传统方式很难完成人脸图像深层次多维度细节特征提取困难的问题,本文提出使用LBP直方图的方法完成纹理特征的提取工作,并作为多通道特征融合的一层特征通道;使用边缘检测Canny算子对图像的边缘特征完成提取,并将提取到的边缘特征图像作为另一层特征通道;将以上两种特图像和原始图像进行通道融合。最终,将具有三通道特征的图片像经过数据的预处理输入到已经搭建好的网络模型中去完成模型的训练和识别分类。以此来解决传统方式提取图像特征难的问题2.为了解决主流模型中常见的鲁棒性不强、且模型泛化能力弱的问题,本文中提出一种基于Inception Module改进的可分离卷积网络的人脸表情识别方法。其中,模型同时使用四个改进后的Inception Module在模型框架中承担着主要的提取特征的任务。在每一个模块当中都包含了相对完整的结构,如池化层和卷积层等。同时本模型采用了多样化非对称小卷积组合的方式替代大卷积的思路,能够最大程度发挥小卷积核对图像局部细节的高度提取,每个模块针对不同的图片区域都可以最大程度的完成特征提取工作,并最终在公开数据集FER-2013上完成精度测试。并通过和主流模型对比证明本模型在深度特征挖掘、弱化光照影响方面表现更加优秀,且网络模型具有了更强的鲁棒性和泛化能力。3.考虑到网络模型的实际应用问题结合当下的安全出行问题,为了解决受外界环境影响驾驶员情绪出现波动,并做出危险驾驶行为造成严重损失的安全问题,本文模型进行了实际场景实验测试。同时,为了验证本模型的稳定性选择在自制数据集上进行实验完成精度测试,最后数据证明本模型稳定且精度不俗。通过实际的测试验证了模型具有很强的鲁棒性和识别准确率。
{URL}: https://link.cnki.net/doi/10.27911/d.cnki.ghjgx.2023.000114
{DOI}: 10.27911/d.cnki.ghjgx.2023.000114
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的CoreXY结构写字机器人的研究与实现
{Author}: 徐振中
{Tertiary Author}: 孙立辉;仇兆浩
{Publisher}: 吉林化工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;CoreXY结构;写字机器人;手写中文识别;ARM控制器
{Abstract}: 基于机器视觉的CoreXY结构写字机器人设计是在常规写字机器人写字的基础功能之上,利用机器视觉和嵌入式技术,解决目前写字机器人存在的智能化水平低、难以独立运行等问题。具体来说,即通过机器视觉技术识别出手写中文图片中的文字,然后将识别结果送入搭载嵌入式Linux系统的ARM主控,进而控制CoreXY结构写字机器人写字。首先,本文基于手写中文识别和控制CoreXY结构写字机器人写字这两个问题,开展了调查和研究,并提出了利用机器视觉技术识别手写中文图片中的汉字和利用运动控制程序控制CoreXY结构写字机器人写字解决方案。经过论证,确定系统研究技术路线和实现方案。其次,本文通过系统总体设计、写字机器人机械结构设计、系统硬件设计、系统软件设计和系统运行测试五部分内容进行阐述。其中,系统总体设计对系统总体架构、系统工作流程以及系统研究技术路线进行了详细描述,从宏观上展现系统实现思路;写字机器人机械结构设计对CoreXY结构及运动原理进行介绍,并探讨如何组装CoreXY结构写字机器人;系统硬件设计介绍了各个功能单元的硬件组成模块以及实现的电路原理图;系统软件设计从系统主程序设计、写字机器人运动控制程序设计、中文手写识别算法设计以及写字机器人上位机控制软件设计四方面进行说明;最后进行系统运行测试,包括文本编辑及绘制测试和文本图像识别绘制测试,并给出相关设置参数和分步绘制测试结果图。再次,经过多次实验和对系统架构进行优化,结果表明,使用深度学习框架TensorFlow搭建基于LeNet-5模型改进的卷积神经网络在中文手写数据集HWDB1.1上进行训练和测试,识别准确率较高。使用PC机或ARM控制器结合Qt软件开发的写字机器人窗口控制程序配合运行GRBL运动控制程序的Arduino单片机来控制写字机器人,能够完成写字功能。最后,完成的基于机器视觉的CoreXY结构写字机器人设计可以完成手写中文识别和通过人机交互窗口控制机器人写字,具有识别准确率高和书写流畅等优点。此外,该设计还可应用在教学研究、文字图像识别、文本抄录、工程制图等方面,具有一定的经济和实用价值。
{URL}: https://link.cnki.net/doi/10.27911/d.cnki.ghjgx.2023.000036
{DOI}: 10.27911/d.cnki.ghjgx.2023.000036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的火焰目标检测及识别
{Author}: 王玺
{Tertiary Author}: 武曲
{Publisher}: 青岛理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 火焰识别;YOLOv5;目标检测;深度学习;注意力机制
{Abstract}: 目标检测作为计算机视觉领域的重要研究方向之一,在面部识别、车辆检测、视频监控、自动驾驶、行人跟踪、农业医学等领域均具较广泛应用。近年来,受全球气候变暖影响,森林山火的发生日渐频繁,给青岛市森林资源和经济发展造成不可估量的损失,生态系统的稳定性和人民群众的生命财产安全受到严重威胁。将目标检测技术应用于火情的监控,具有重要的理论和工程意义。本文以YOLOv5为基准模型,围绕火焰目标检测展开研究,将深度学习应用于复杂场景下的火焰目标检测及识别算法,提出基于CBAM注意力机制的YOLOv5算法。该算法保留了YOLOv5算法网络结构等方面的优势,通过对算法改进,弥补了火焰目标形态复杂所引起检测精度、检测速度、检测准确度等方向的退化。主要工作如下:(1)针对干扰因素影响下火焰目标检测虚警率较高的问题,首先在YOLOv5的跨阶段局部(Cross Stage Partial,CSP)模块的残差组件中,插入ECA注意力机制模块,进行ECA+YOLOv5算法设计。其次在YOLOv5骨干网络的SPPF层上方加入CBAM注意力机制模块,进行CBAM+YOLOv5算法设计。同时,针对两种算法分别优化了损失函数进行实验,利用注意力机制将检测期间更多的注意力集中在关键特征上,获得包含更多有效信息的特征图,从而提高了检测的精确度。(2)为了验证改进后的检测算法综合性能是否更好,本文通过制作实验数据集、配置实验环境,对Faster RCNN、YOLOv5、ECA+YOLOv5和CBAM+YOLOv5进行对比,比较四者在本实验整理的火焰测试集上平均检测精度(P)、召回率(R)、平均精度均值(m AP)、检测速度(FPS)等性能指标的结果值。实验表明,CBAM+YOLOv5的P、R、m AP和FPS比Faster RCNN分别提高了36.2%、31.6%、36.5%和14,比YOLOv5分别提高了5.6%、0、4.3%和6,比ECA+YOLOv5分别提高了2.6%、0、4%和2。因此得出结论,即组合改进后的CBAM+YOLOv5网络在各方面都能实现更优效果。(3)为满足实际环境的应用需求,本文基于Py Qt5框架设计开发了火焰检测应用系统。该应用系统是集图片和视频离线检测、在线检测、识别标签实时显示等功能于一身的目标检测系统,经验证其检测效果良好,使CBAM+YOLO5火焰检测模型向投入到实际应用中迈进一步。
{URL}: https://link.cnki.net/doi/10.27263/d.cnki.gqudc.2023.000840
{DOI}: 10.27263/d.cnki.gqudc.2023.000840
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的橙果定位采摘方法与试验
{Author}: 李燕
{Tertiary Author}: 刘洁
{Publisher}: 华中农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 橙果;识别;定位;机器视觉;采摘执行器;深度相机
{Abstract}: 橙果是我国重要的经济作物之一,常栽种于丘陵山地,采摘所需劳动量极大,实现橙果的机械化、智能化采摘迫在眉睫。针对生长环境复杂、光线变化、枝叶遮挡等因素对橙果采摘执行器作业的干扰,本文对橙果定位与采摘方法进行了研究并完成了试验验证,为后续装备研发和果蔬采摘机器人的研制提供理论和技术参考。本文主要工作如下:(1)橙果采摘装置视觉系统的构建与调试:针对果实三维定位需求,本文选择了双目结构光深度相机Real Sense d435i构建视觉系统,采用眼固定方式安装相机;基于图像处理算法结合深度相机,完成了果实的三维定位;标定了相机内外参,完成了果实三维坐标的坐标系转换;基于路径最短原则,确定了果实的最佳采摘顺序;使用Py Qt软件设计了人机交互界面,提升了操作的效率及方便性;(2)橙果识别算法的对比、选择和优化:分别使用基于形态学的图像处理算法、3D点云处理算法和深度学习模型3种方法进行果实识别。基于形态学的图像处理算法中,基于色差法结合大津法(Otsu)对果实进行分割提取,对分割后的果实进行轮廓检测,获取果实质心坐标;针对重叠果实,采用分水岭结合形态学的处理算法实现重叠连通域的分割,再进行轮廓检测。3D点云处理算法中,采用基于色彩的阈值分割方法分离果实、去除背景,采用基于欧式距离的聚类方法结合随机抽样一致性算法对多个果实进行分类并拟合,获取果实质心位置及半径。深度学习模型中,选用YOLOv4模型,使用Mobile Net v2模块代替CSPDarknet网络作为主干网络,使用深度可分离卷积代替部分标准卷积,实现模型的轻量化。改进模型的识别准确率、召回率、调和均值F1、平均精度分别为97.57%、92.27%、94.85%、97.24%,模型大小为46.5 M。比较了3种识别算法的效果:在同一测试集中,对上述3种识别算法进行验证。结果表明:形态学图像处理算法、3D点云处理算法和改进YOLOv4算法的识别成功率分别为79.49%、74.36%和98.72%。改进YOLOv4模型的识别成功率较其他两种算法大幅提升,在复杂的自然环境中具有较强的鲁棒性。(3)橙果定位算法的设计与验证:设计了基于深度相机结合改进YOLOv4模型的橙果定位方法。该方法将果实定位过程分解为二维定位及深度获取两个步骤。采集果实的彩色图及深度图,经数据对齐后,基于改进YOLOv4模型完成果实质心的二维坐标获取,记录该点位置,将其映射到深度相机获取的深度图中以获取该点的深度值,并对果实半径进行求解。利用测试集对上述定位算法进行验证,结果表明:识别成功率达98.72%,三维定位成功率达96.15%。深度信息获取过程中,平均绝对误差MAE为3.48 cm,平均绝对百分比误差MAPE为2.72%。(4)采摘执行器硬件及控制系统的搭建与测试:以直角坐标机械臂作为采摘执行机构、三爪型柔性自适应机械爪为采摘末端执行器搭建硬件系统;以笔记本电脑作为上位机,以STM32作为主控制器构建控制系统。视觉系统实现果实的三维定位后,通过STM32的定时器输出固定数量脉冲控制各根轴上的步进电机转动固定圈数,实现目标果实的接近。基于RS485原理控制机械爪开闭,完成果实的抓取与松放。(5)定位精度试验及采摘试验的设计与实现:在室内条件下对所提视觉引导方法的定位精度进行验证,结果表明:X、Y、Z方向上的平均绝对误差分别为:5.85 mm、6.76 mm、8.59 mm,误差在末端执行器容错范围内,符合实际采摘时的定位精度要求。在室内室外条件下分别进行了采摘试验:室内条件下本文所提算法的采摘成功率达87.29%。考虑机械臂有效行程及室外光照造成的深度信息获取失败问题,在室外条件下设置果实采摘范围,对处于采摘范围内的果实进行采摘,结果表明室外条件下采摘成功率达79.81%,平均单果采摘时间为8.9 s。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2023.001300
{DOI}: 10.27158/d.cnki.ghznu.2023.001300
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 利用OpenPose骨骼追踪术辅助健美操教学的应用研究
{Author}: 刘翠微
{Tertiary Author}: 冯云辉
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 健美操教学;智能技术;智能化教学辅助系统;OpenPose骨骼追踪术
{Abstract}: 健美操是一项集运动、美学与强身于一体的体育运动,目前在高校都将健美操课程纳入体育课程或者是单独开设课程。但在高校健美操课程的教学过程中,还存在教学内容单一、学生学习的主动性和积极性欠缺、对复杂动作学习困难等的问题。来自深度学习的OpenPose骨骼追踪术是一种基于计算机视觉技术的算法,在量化体育运动、全身姿态检测方面发挥着重要作用。其原理是通过识别人体关键部位的位置,在教学中实现学生动作姿态的跟踪和分析,为学生提供及时、准确的指导,并给予一定的动作纠正建议。为了探索人与智能技术在课堂教学中的应用成效,本文采用文献资料法、问卷调查法、专家访谈法等构建了基于OpenPose骨骼追踪术辅助健美操教学的智能系统,并确定相应的实验指标,通过实验法对广州大学50名学生进行为期8周的实验干预。本文旨在确保不改变体育课程性质的前提下,验证其智能化教学辅助系统对学生健美操动作的掌握、习得过程及教学效果的影响。主要结论如下:1)通过对健美操动作教学智能化辅助手段的应用现状调查分析可知,目前应用在健美操教学上的辅助手段还是比较单一、传统,学生对智能化教学的辅助手段期望值较高。2)针对智能化的教学需求,构建了OpenPose骨骼追踪术辅助教学系统,该系统包括动作数据采集模块、标准动作姿势的设定模块、动作姿势的骨骼运动定位分析模块、智能评估反馈模块。通过对系统的测试应用后得到良好的效果并为教学实验做好一定的基础。3)实验结果显示,OpenPose骨骼追踪术辅助教学系统具有较强的针对性,能对学生的动作练习提供及时的动作反馈及动作纠正建议,对学生成套动作的掌握具有促进作用;并且实验发现在动作的阶段性考核中,宜多采用在动作形成的起始阶段,即泛化、分化阶段,这对学生动作记忆的形成具有较大的帮助,并能够激发学生学习的积极性和能动性,但在对教学的总成绩以及表现力影响不明显。4)“人工智能+教育”是教育发展的方向,未来的教学必然离不开智能化的教学手段,利用OpenPose骨骼追踪术辅助健美操教学系统得到教师与学生的认可,使智能化教学的发展得到早日实现。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.002040
{DOI}: 10.27040/d.cnki.ggzdu.2023.002040
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和双目视觉的混凝土坝裂缝检测与测量
{Author}: 高宇佳
{Tertiary Author}: 邹彦艳
{Publisher}: 东北石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;双目视觉;混凝土坝裂缝;YOLOv5s;裂缝识别与测量
{Abstract}: 中国大坝水库总量为世界第一,作为中国水利建设中不可或缺的一部分,大坝的安全检测成为了避免发生重大水利灾害的一个措施。影响大坝安全的因素有很多,地形因素、施工质量问题、环境因素、自然因素等等,其中,由于自然因素影响导致的大坝老化率问题尤为严重,随之而来因为老化率,使大坝产生大量裂缝。正如说,堤溃蚁穴,气泄针芒,关乎大坝安全中即使是很小的裂缝也不能被忽视,因为它们可能会造成巨大灾害的后果,所以大坝安全检测十分重要。大坝安全监测工作一直是一个难题,由于大坝内部结构复杂、情况多样,人工检测存在危险性大、操作困难、费时费力、检测数据不精确、不直观等缺点。随着计算机的快速发展,深度学习和双目立体视觉技术成为工业检测、工业测量、科学研究等领域的一个热点技术。针对上述问题,本文将深度学习和双目立体视觉技术相结合,研究基于深度学习和双目立体视觉技术的大坝裂缝智能化检测和测量方法,其主要的研究工作如下:(1)由于雨水冲刷导致的大坝材质不均匀和光照等原因,使得获得的图像失真退化,所以首先对获取的大坝裂缝图像进行图像预处理。本文介绍了线性变换、直方图均衡化、对数变换三种图像增强和空间域法、频率域法两种滤波去噪的图像处理方法,以均方根(MSE)、峰值信噪比(PSNR)作为评价指标,对不同的去噪和增强算法进行对比,最后决定选用中值滤波算法来消除图像中的噪声。经过图像分割算法的对比,使用大津法来分割裂缝图像,最后再进行骨架线和边缘提取。(2)在大坝裂缝检测方面,本文在原来YOLOv5s的基础上,提出了一种改进的YOLOv5s的大坝裂缝检测模型。把YOLOv5s原有的主干特征提取网络换为轻量化的Ghost Net,再在预测端融合了高效的CA(Coordinate Attention)注意力机制。首先将预处理后的大坝裂缝图像用Label Img标注;然后再进行网络模型的训练和测试;使用召回率(Recall)、精准率(Precision)、图像每秒传输帧率(FPS)和平均精度值(m AP)四个指标来对优化后的模型进行评估,并将结果对比目前的几种主流算法。实验结果表明,改进的算法对大坝裂缝检测精度和速度均有一定程度的提升,也满足了工业检测的实时性。(3)在裂缝测量方面,本文将双目立体技术和大坝裂缝测量应用相结合。在双目立体视觉技术方面,做了相机标定、双目校正、图像匹配等工作。利用双目视觉技术计算两端边缘(长边)像素点的三维坐标,再利用欧式距离公式计算裂缝的宽度(长度)。设计一系列的测量实验,验证了本文对大坝裂缝测量的可行性。本文提出的改进算法能够更好的检测大坝裂缝,提出的测量方法能对大坝裂缝进行有效测量,能够为今后大坝的智能化安全监测提供参考和实用价值。
{URL}: https://link.cnki.net/doi/10.26995/d.cnki.gdqsc.2023.000714
{DOI}: 10.26995/d.cnki.gdqsc.2023.000714
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体姿态估计的体育评测关键技术研究与应用
{Author}: 曾庆超
{Tertiary Author}: 刘军
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 姿态估计;动作识别;运动评测;轻量化模型;边缘计算
{Abstract}: 近些年来,随着计算机视觉应用的快速发展,利用该技术进行在线体育比赛和体育锻炼,从而提高体育教学质量的应用也受到了人们的广泛关注。然而,当前基于计算机视觉的运动动作识别框架注重对运动过程中的不同动作进行分类,对于其他更进一步的操作,如计数、过滤不当动作、输出运动动作建议等,仍然缺乏相关的研究和实际的落地应用。本文旨在探究基于姿态估计的动作检测框架与计数算法,并将其应用于体育运动检测识别领域。针对上述问题,本文首先提出了一种基于姿态估计的运动动作检测框架与计数算法,通过利用深度学习技术实现运动动作的细粒度分割和识别,提高了体育评测场景下运动动作的识别准确率。其次,本文以高校体育测试作为实际应用场景,设计了端云结合的动作检测系统,落地了相关算法,完成了针对仰卧起坐、引体向上等高校体育评测场景下的运动动作的计数和过滤。最后,本文通过优化网络模型和推理加速等方法,改进了端云结合系统,成功实现了云上训练网络,在边缘设备上部署轻量化模型完成实时推理的方案,进一步提升了运动动作检测计数任务的效率。本文的研究成果有望为在线体育比赛和体育锻炼等场景提供技术支持和参考。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000202
{DOI}: 10.26969/d.cnki.gbydu.2023.000202
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Vision Transformer的图像检索方法研究
{Author}: 修丙楠
{Tertiary Author}: 许信顺
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 细粒度图像检索;行人重识别;Vision Transformer;卷积神经网络
{Abstract}: 图像检索是计算机视觉领域中一个非常重要的研究任务。近些年,随着技术的发展,更具有挑战性的子任务相继被提出并吸引了越来越多的关注,比如细粒度图像检索、行人重识别。在这两个子任务中,基于卷积神经网络(Convolutional Neural Network,CNN)的模型已经取得了不错的性能。借助于卷积神经网络,这些方法可以充分地提取并利用图像的全局特征。然而,在细粒度图像检索和行人重识别任务中,局部特征对于提高检索准确性来说同样具有非常重要的作用。最近,基于Vision Transformer(ViT)的方法在传统的图像分析领域取得了巨大的成功,这归因于ViT在捕获图像中最具有判别力的区域和图像中细粒度特征方面具有天然的优势。然而,如何将ViT应用到这些更具有挑战性的子任务中需要进一步探索。因此,面向细粒度图像检索和行人重识别任务,本文开展了基于ViT的研究工作。本文首先利用ViT作为特征提取网络,并提出了一个基于ViT的细粒度图像检索方法,来更好地利用图像的局部特征。在该方法中,本文设计了一个局部对齐损失函数,动态地计算两张图片成对区域之间的最小距离,从而找到两张图片之间相对应的局部区域。进一步地,将所有对应区域之间的距离加权求和作为两张图片之间的距离,以此来更好地衡量图片之间的相似度。这样,图像中具有判别力的区域能够被有效的捕获,图像中蕴含的细粒度特征也得到了更好地利用。同时,该方法中还引入了一个二次排序机制,不仅提高了检索的效率,还最大程度上保证了检索结果的准确率。在上述基础上,为了同时利用图像的全局信息和局部的细粒度信息,本文考虑将CNN和ViT结合,引入了一个新颖的混合ViT架构作为特征提取网络,并提出了一个基于混合ViT的细粒度图像检索方法。该方法进一步探讨了如何将CNN和ViT更有效地结合起来,以充分发挥两者的共同作用。具体来说,在该方法中设计了一个关键区域重分析模块,利用CNN来指导ViT中关键区域的选择,从而生成更具有代表性的用来检索的全局特征向量。此外,还设计了一个混合网络特征融合模块来对CNN和ViT的特征进行有效地融合,从而得到信息更丰富的输出特征。同时,在此方法中对局部对齐损失函数进行了改进,提出了一个全局一局部对齐损失函数来更好地度量两张图片之间的相似性。为了验证所提出的基于混合ViT架构的模型在不同任务上的泛化能力,本文对第二个方法进行了改进,提出了一个基于混合ViT的行人重识别方法,并测试了其在行人重识别任务上的性能。在此方法中,首先设计了一个层次特征融合模块,来充分利用CNN和ViT中间层的图像特征,从而使最终用于检索的特征包含更丰富的粗粒度和细粒度信息。此外,还提出了一个自监督优化排序模块,来进一步提高模型的检索效率和准确率。为了验证模型的性能,本文在广泛应用的两个细粒度图像检索数据集(CUB-200-2011、Cars-196)和两个行人重识别数据集(DukeMTMC、MSMT17)上进行了大量的对比实验,并对模型进行了消融实验。实验结果证明了所提出方法的有效性。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.002104
{DOI}: 10.27272/d.cnki.gshdu.2023.002104
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合YOLOv7和BYTE多目标跟踪的多类别海珍品计数方法
{Author}: 安志强;李智军;刘硕;赵永刚;陈启俊;左然涛;林远山
{Author Address}: 大连海洋大学信息工程学院;辽宁省海洋信息技术重点实验室;设施渔业教育部重点实验室,大连海洋大学;大连鑫玉龙海洋生物种业科技股份有限公司;大连海洋大学水产与生命学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 09
{Pages}: 183-189
{Keywords}: 机器视觉;深度学习;海珍品计数;水产养殖;多目标跟踪
{Abstract}: 针对目前养殖过程中海珍品计数方法成本高、效率低、计数精度难以保障等问题,该研究以真实底播养殖环境下的海珍品为研究对象,以水下拍摄的海珍品视频为数据源,提出一种基于视频多目标跟踪的多类别海珍品计数方法。首先,采用性能优异的YOLOv7算法实现海珍品目标检测器,为多目标跟踪提供输入;然后,结合真实养殖环境下同类别海珍品外观相似性高、不清晰等特点,借鉴BYTE算法的多目标跟踪思想,设计多类别轨迹生成策略和基于轨迹ID号的计数策略,提出一种多类别海珍品跟踪与计数方法。并提出一套更适用于基于轨迹ID号计数方法的评估指标。试验结果表明,改进平均计数精度、改进平均绝对误差、改进均方根误差及帧率分别为91.62%、5.75、6.38和32帧/s,各项指标多优于YOLOv5+DeepSORT、YOLOv7+DeepSORT、YOLOv5+BYTE、YOLOv7+BYTE等算法,尤其改进平均计数精度、帧率指标比YOLOv5+DeepSORT高了29.51个百分点和8帧/s,且在改进平均绝对误差、改进均方根误差指标上分别降低19.50和12.08。该研究方法可有效帮助水产养殖企业掌握水下海珍品数量,为现代化渔业的测产研究提供技术参考,为水产养殖的智慧管理提供科学决策依据。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20230526.1003.028
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向视觉任务的迁移学习方法研究
{Author}: 魏国强
{Tertiary Author}: 吕岩;陈志波
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 迁移学习;骨干网络;域自适应学习;元学习
{Abstract}: 随着数据规模的扩大和计算能力的增强,机器学习在众多任务中都取得了快速的发展。传统机器学习方法往往假设训练数据和应用场景中的测试数据具有一致的分布。然而,在实际应用中,不同的应用场景数据变化较大,训练数据与测试数据的分布往往不一致,这使得传统机器学习面临着巨大的挑战。迁移学习在这方面提供了一种解决方案,它可以在分布不同但又存在一定相似性的不同数据和任务之间进行知识迁移,借助已经通过训练学到的知识,在新场景中构建更好的模型,从而在实际应用中实现更佳的效果。研究迁移学习具有重要的学术和实际应用价值,它能在不同场景下快速构建高效、准确的网络模型。迁移学习作为机器学习领域的研究重点之一,具有广泛的研究和应用前景。本文主要关注和研究计算机视觉中的迁移学习,首先分析了现有的迁移学习方法,并从模型结构、优化、特征三个不同的角度进行了概述和介绍,同时总结了现有研究方法中的不足。接着,本文基于迁移学习的核心,即通过知识迁移提升模型在新领域中目标任务的性能,着重探讨了如何从模型结构、优化和特征三个不同的角度设计更加有效的迁移学习方法,以使得迁移学习能够面向最终的应用任务进行高效的知识迁移,这三个方面的研究分别对应于:(一)从模型结构角度,本文提出了一种基于动态网络的面向任务的预训练-微调方法。本文首先关注于目标域有监督的迁移学习中最常见的预训练-微调学习范式。在这个范式中,模型首先在较大规模的源域数据集上进行预训练,然后在目标域上利用标签监督对预训练好的模型进行微调,以实现知识迁移并使模型更好地适应目标任务和数据集。我们从网络结构的角度出发,分析了现有的网络结构设计,并提出了一种高效的基于主动令牌融合的动态网络结构。在经过预训练后,在不同下游任务和数据集上进行参数微调的时候,我们新提出的网络能够能根据数据分布的变换和任务所需知识的差异,自适应地调整自身网络结构,从而将预训练学到的知识更有效地迁移到不同的下游任务中。(二)从网络优化角度,本文提出了一种基于元学习的面向任务的无监督域自适应方法。本文关注于迁移学习中的一个重要方向:无监督领域自适应。针对这个方向,我们指出了知识迁移过程中存在的一个问题,即领域自适应任务在优化过程中与最终目标任务优化方向可能不一致。这可能会导致模型迁移对最终任务无益的知识,从而影响迁移学习的性能。为了解决这个问题,我们从网络训练过程中的优化角度出发,提出了一种新的基于元学习的训练优化策略MetaAlign。MetaAlign通过改变优化过程,使网络在迁移学习的训练阶段考虑最终任务的优化方向,以实现更有效的面向任务的无监督知识迁移。(三)从特征角度,本文提出了一种基于特征选择的面向任务的无监督域自适应方法。在无监督域自适应学习的框架下,我们从“应该迁移什么样的知识”的角度出发,分析了现有方法在知识迁移过程中并未针对最终目标任务进行优化的问题。这个问题可以归结为两个主要方面:应该迁移什么样的知识和如何选择应该迁移的知识。针对这个问题,我们提出了一种基于特征选择和对齐的方法ToAlign。我们利用源域数据集中的真实标签,在监督训练的参数梯度信息中定位并提取与任务优化相关的知识。基于这些信息,我们通过注意力机制来调制迁移学习过程,从而实现任务导向的无监督域自适应学习。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.000814
{DOI}: 10.27517/d.cnki.gzkju.2023.000814
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的四足机器人变电站巡检关键技术研究
{Author}: 彭孟乐
{Tertiary Author}: 姜晓勇
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 四足机器人;变电站巡检;自适应多头结构;轻量级特征金字塔;云台纠偏控制
{Abstract}: 变电站作为电网系统中负责电压和电流的交换及分配电能的一个重要场所,关系到了整个国家和社会的电力需求和经济发展。因此,对变电站幵展全面的定期巡检工作变得尤为重要。随着机器人及计算机视觉技术的不断发展,智能机器人为变电站巡检提供了一个新的思路和机遇。然而,变电站巡检机器人多采用轮式机器人作为运动机构,受限于轮式机构的运动特性,机器人对变电站地形的适应能力不强,很难实现复杂地形下的巡检任务,必须铺设专门的巡检道路,极大的提高了巡检成本。四足机器人具有很好的地形适应能力;但是,由于其多自由度的运动特性和复杂的结构特性,往往存在定位精度差的问题,导致采集的图像质量差,影响巡检效果。机器人变电站巡检主要依靠各种图像传感器采集图像信息,通过对图像的分析从而判断是否有异常点存在。基于深度学习的目标检测算法凭借其强大的学习能力,逐渐成为现在目标检测与识别的主流方法;但是存在模型较大、实时性低等问题,尤其不利于在移动设备上部署。基于以上背景,本文展开了基于机器视觉的四足变电站机器人巡检关键技术研究。以变电站巡检机器人相关技术研究现状为基础,确定使用四足机器人代替轮式机器人来实现变电站巡检任务。在此基础上,开展了变电站设备快速定位和云台纠偏控制技术研究,解决了四足机器人定位不准确导致的高质量获取设备图像的技术难点;开展了基于机器视觉的变电站设备检测与识别技术研究,解决了现有方法检测精度低、实时性差、不适合在嵌入式智能硬件上布署等问题。同时,设计相关实验对基于四足机器人的变电站巡检系统进行验证。主要研究工作如下:1)完成了四足巡检机器人的系统总体方案设计,为了满足变电站电力设备巡检需求,进行了相关硬件选型和软件系统设计。2)开展变电站设备快速定位与纠偏技术的研究。建立云台运动学模型;使用基于SSD(Single Shot Multi Box Detector)改进的快速定位算法定位出相机视野中的待检测设备;通过云台运动学模型进行坐标变化,控制云台将待检测设备调整到相机视野中心,实现云台纠偏控制。3)开展基于卷积神经网络的变电站目标检测与识别技术研究。针对变电站多目标检测设计了基于自适应多头结构和轻量级特征金字塔网络(Adaptive Multi-head Structure and Lightweight Feature Pyramid Network,AHLNet),在特征提取阶段设计了自适应多头结构网络(Adaptive Multi-head Structure Network,AMHNet),在特征融合阶段设计了轻量级的特征金字塔网络(Lightweight Feature Pyramid Network,LFPN),并在上采样阶段引入空间注意力机制(Spatial Attention Mechanism,SA),通过以上改进实现了提高了轻量化、简单化、高精度的目标检测网络设计。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2023.000150
{DOI}: 10.27840/d.cnki.gzjkj.2023.000150
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLO算法的高压输电线路绝缘子与缺陷检测技术研究
{Author}: 沈陆朋
{Tertiary Author}: 辛建波;夏永洪
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 输电线路;绝缘子检测;缺陷检测;改进YOLOV5s模型;模型部署
{Abstract}: 我国地域广阔,发电资源分布不均衡,结合我国的“双碳”目标,未来输电线路长距离输送电能的需求将会越来越高。输电线路上的绝缘设备长期暴露在各种环境中,容易发生破损、缺陷等故障,严重影响了电力系统的供电可靠性,为此,针对高压输电线路绝缘子与缺陷的检测技术进行研究。针对无人机拍摄角度导致的水平矩形框检测下绝缘子检测背景区域过大的问题,采用旋转框代替水平框对绝缘子进行检测,以检测速度和精度效果较好的YOLOV5s算法作为基准模型,在原来模型上引入旋转模块(CSL,Circular Smooth Label),提出一种改进YOLO模型(CSL-YOLO)。通过在该算法下构建的旋转绝缘子数据集实验结果表明,CSL-YOLO的平均准确率(m AP,mean Average Precision)达到了92.5%,表明该算法对图像中的目标检测效果良好,实现了目标的旋转检测,有效地解决了绝缘子在水平边界框下会导致检测框之间有较强的重叠、目标范围表示不准确的问题。为提升检测速度和检测精度,将YOLOV5s主干特征网络提取网络替换为Swin Transformer并添加注意力机制,提出一种改进YOLOV5s算法。通过在数据集上训练的实验结果表明,改进的模型进一步提升了模型检测精度,对高压输电线路上的缺陷有更好的检测效果,该模型的准确率由94.4%提高到96.2%。且该算法模型大小仅为13.8MB,为后续能部署在嵌入式硬件上的高压输电线路缺陷目标检测研究奠定了模型基础。针对嵌入式设备相对于大型GPU计算能力弱、模型移植精度低的问题,通过使用Tensor RT对所提改进YOLOV5s模型进行压缩与加速,将其移植到英伟达嵌入式设备Jetson Nano中。在Jetson Nano上的检测速度约为21帧/s,相对于未加速时的5帧/s,可以得知加速后模型检测速度大幅度提升,接近于实时检测(30帧/s),适合嵌入式边缘计算平台的部署。同时将电力检测人员面对的代码界面转换为图形界面,方便工作人员使用和操作。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2023.004397
{DOI}: 10.27232/d.cnki.gnchu.2023.004397
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉感知理论与技术在煤炭工业领域应用进展综述
{Author}: 巩师鑫;赵国瑞;王飞
{Author Address}: 中煤科工开采研究院有限公司智能化开采分院;天地科技股份有限公司开采设计事业部;煤炭科学研究总院开采研究分院;陕西陕煤黄陵矿业有限公司一号煤矿;
{Journal}: 工矿自动化
{Year}: 2023
{Volume}: 49
{Issue}: 05
{Pages}: 7-21
{Keywords}: 煤矿智能化;机器视觉;状态感知;煤矿安全监测;拣选识别;煤岩识别;定位导航;位姿检测
{Abstract}: 机器视觉技术对改善煤矿安全监测手段、提高装备自动化水平具有积极意义。详细阐述了当前煤矿智能化建设过程中基于机器视觉的不同场景和系统下的设备信息状态感知原理，综述了机器视觉感知技术在煤矿安全监测、拣选识别、煤岩识别、定位导航、运输检测、位姿检测和信息测量等方面的实践应用；分析指出未来煤矿机器视觉感知技术应深入挖掘采掘工作面机器视觉场景理解需求，构建生产全视场监视检测体系，提升多时空多维度多变量集成监测效果，改善视频自主监视告警能力，增强视觉引导能力，并形成地面生产管理运行系统的视觉资料统一化管理方式等，重点研究综采装备（群）姿态同时空测量、采掘环境动态变化感知、生产全视场监测与自主告警、煤矿机器人视觉引导控制等技术；指出煤矿机器视觉感知技术在防爆或本安型智能视觉传感器研发、高效视觉测量与分析、检测识别测量精度提升、图像高质量标注方面仍存在挑战，通过开发具有边缘计算能力的视觉传感器，构建井上下视觉分布式测量方案，实现各类复杂环境下开采信息准确识别与测量，可有效提高机器视觉感知技术在煤炭行业的更深层次融合和应用。
{ISBN/ISSN}: 1671-251X
{Notes}: 32-1627/TP
{URL}: https://link.cnki.net/doi/10.13272/j.issn.1671-251x.2022100087
{DOI}: 10.13272/j.issn.1671-251x.2022100087
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的PCB焊接缺陷检测系统研究
{Author}: 易欢;汪志成
{Author Address}: 东华理工大学机械与电子工程学院;
{Journal}: 仪表技术
{Year}: 2023
{Volume}: 
{Issue}: 03
{Pages}: 55-58
{Keywords}: 机器视觉;缺陷检测;图像识别;机器视觉软件
{Abstract}: 针对中小型企业在焊接缺陷检测领域中存在人工成本高、检测精度低、实时性差等问题，提出了基于机器视觉的焊接缺陷检测系统，在生产线上安装多套图像采集装置。根据现场情况，设计了多套打光方案，实现连锡、焊点偏位、芯线断开等缺陷的高清成像；基于HALCON软件，采用图像定位、图像预处理、图像分割、形态学处理及焊接缺陷识别算法，完成了USB接口缺陷的精确检测，并将结果显示在上位机界面。测试生产线上实际采集的402幅缺陷图像，结果表明，系统成功检出率达86%,基本满足实际生产需要。该检测系统用于中小型企业生产，有利于大幅度提高检测效率和缺陷检测智能化水平，同时降低检测成本。
{ISBN/ISSN}: 1006-2394
{Notes}: 31-1266/TH
{URL}: https://link.cnki.net/doi/10.19432/j.cnki.issn1006-2394.2023.03.010
{DOI}: 10.19432/j.cnki.issn1006-2394.2023.03.010
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的细粒度图像分类研究
{Author}: 程金龙
{Tertiary Author}: 马昕
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 细粒度图像分类;注意力机制;知识蒸馏;特征融合
{Abstract}: 细粒度图像分类是计算机视觉和模式识别领域的一个重要研究方向,其目的是对某一传统语义类别下不同子类类别进行分类,在生态环境保护、医学影像分析、智能交通、智能安防等领域具有重要的科学意义和应用价值。由于子类类别图像之间具有较小的类间差异和较大的类内差异的特点,分类模型需要捕获图像中细微的局部差异性区域,学习图像中最有辨识性的特征。现有的方法存在差异性局部区域定位不够精准,以及对多尺度局部特征学习利用不足等问题。针对以上问题,本文构建了基于深度学习的细粒度图像分类网络,主要研究内容概括如下:(1)针对细粒度图像差异性局部区域定位不够精准及多尺度局部特征学习利用不足的问题,提出了融合多尺度注意力机制和知识蒸馏的细粒度图像分类算法。首先,利用骨干网络不同阶段输出特征的尺度差异,实现多尺度特征提取;然后,引入双重注意力模块对不同尺度的特征进行精细化筛选,增强不同尺度局部差异性特征的表达;同时,利用特征融合模块将筛选后的多尺度特征映射到同一特征空间进行融合,获得多尺度局部互补性特征;最后,提出了基于全局输出响应的知识蒸馏模块,利用训练好的教师网络的全局输出值,监督学生网络在多尺度分支上更好地学习区域细粒度特征,增强网络对细粒度图像多样化细微特征的表达。大量的实验结果验证了所提方法相比现有的方法在细粒度图像基准数据集上的分类精度有一定的优势。(2)针对视觉Transformer只关注全局信息,不能生成多尺度细粒度分类特征的问题,提出了基于视觉Transformer的特征选择和融合的细粒度图像分类算法。为了获取细粒度图像的局部信息和全局信息,首先,提出了自适应阈值的特征标记选择模块,在不引入额外参数的情况下,利用网络自身产生的注意力权重挖掘辨识性特征标记,达到去除背景干扰的目的,提升了网络捕获差异性局部特征的能力;其次,引入了特征融合模块,聚合不同层间的类别编码和具辨识性的特征标记作为融合特征,输入Transformer最后一层编码器中,让最后一层编码器输出的类别编码学习聚合细粒度图像的全局特征和局部特征;最后,提出基于多层特征信息的集成分类模块,分别提取Transformer网络最后三层的类别编码,将其输入到分类器中进行预测,分类网络集成不同层间的互补性信息,提升模型最终的分类效果。大量的实验结果验证了所提方法相比现有的方法在细粒度图像基准数据集上的分类精度具有较强的竞争力。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.002309
{DOI}: 10.27272/d.cnki.gshdu.2023.002309
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件表面粗糙度检测方法研究
{Author}: 杨悦
{Tertiary Author}: 赵英亮
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 表面粗糙度;GLCM;Gabor滤波;SVR回归;粒子群算法
{Abstract}: 在机械加工领域中,工件表面的粗糙度是评估表面质量的关键指标,工件的安全性、机械性能和使用寿命都会受其影响,特别是对于那些具有特定功能的工件(如密封、相对移动等)。目前,表面粗糙度的检测技术大多使用接触式测量仪或光学仪器,但是由于这很容易导致工件表面的损坏,又或者在实际制造生产过程中对机械设备和环境的要求较高,因此无法应用于实际制造过程中。将机器视觉技术运用于工件表面粗糙度检测,可以有效地解决检测效率低、精度差和检测成本高等问题。本文以机器视觉理论为基础,采用纹理特征提取方法对立铣工件进行非接触式无损的表面粗糙度检测。本文主要研究内容如下:(1)探讨了工件表面粗糙度的定义,以及其与波纹度和表面形状误差之间的差异,深入剖析了以上概念的具体含义;根据标准阐述了表面粗糙度的评估参数,并详细介绍了如何采样和评定长度;(2)以立铣工件为研究对象,获取工件表面图像,并建立数据集。在对工件图像进行预处理的基础上,提取表面图像特征,构建参数与表面粗糙度之间的模型关系;(3)针对传统灰度共生矩阵(Gray Level Co-Occurrence Matrix,GLCM)的提取误差和旋转不变性较差的问题,本文提出改进的灰度共生矩阵特征提取算法,并通过实验验证其鲁棒性优于传统GLCM;针对GLCM获取的是工件图像的全局特征,缺少对局部特征的描述,本文提出了通过对工件表面Gabor特征融合的粗糙度检测方法,特征向量的维数可以有效降低,改善了特征的表征能力;(4)构建基于立铣工件表面粗糙度Ra的支持向量机回归(Support Vector Regression,SVR)模型。以基于ET-GLCM提取的8个纹理特征和基于Gabor的融合特征为模型输入,对应表面粗糙度Ra为输出,通过构建SVR回归模型实现立铣工件表面粗糙度的非线性检测。为了提高表面粗糙度预测的准确性和运算速度,利用改进粒子群算法(Improved particle swarm optimization,IPSO)对SVR的核函数参数和惩罚因子进行优化,有效避免了算法陷入局部极小值的问题和SVR模型参数选择的盲目性。通过与其它回归模型的比较和对不同特征组合的预测实验,验证了所提模型具有更优越的预测性能,所提出的纹理特征提取方法更具有优越性。实验证明它有效解决了目前非接触式检测工件粗糙度方面存在的问题,对于实现其他需检测光滑度的工程应用同样有着十分重要的作用。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000050
{DOI}: 10.27470/d.cnki.ghbgc.2023.000050
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手语识别研究与应用
{Author}: 罗文杰
{Tertiary Author}: 陈萌;郭晓峰
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;MediaPipe;YOLOv5;手语识别
{Abstract}: 由于听觉丧失和声带受损,聋哑人无法用口语与人交流,肢体动作语言便成为听障弱势群体之间主要沟通方式。目前手语并未在社会上全面普及,且听障弱势群体普遍识字困难,使得普通健听人士和聋哑人之间存在不小的沟通障碍。因此,研究手语识别技术具有重要的社会意义,不仅帮助聋哑弱势人群更好地融入日常生活中,而且还能促进信息无障碍交流社会福利事业的发展。基于计算机视觉的手语识别可分为两个方向:一种是基于手语图像手势的识别,另一种是基于手语视频的动态识别。本文旨在针对以往手语识别算法中所存在的不足之处,提出新的改进方法,并在提升识别准确率的基础上搭建手语识别应用程序。本文的研究成果分为以下三个部分:(1)静态手语识别:针对目前手语应用场景中对于识别准确性的需求,提出基于改进6.0版YOLOv5目标检测算法的静态字母手语识别模型SA-YOLOv5。首先,以YOLOv5s6为基准网络对其进行了优化,通过实验对比在Backbone末端嵌入Sim Am注意力机制,在不引入额外参数下提升特征提取能力;其次为了使该模型能够充分利用目标不同尺度特征,使用自适应空间特征融合ASFF模块以加强网络特征融合。和基准网络YOLOv5s6相比,改进后的SA-YOLOv5手语识别模型m AP平均精度均值整体提高了3.7个百分点,取得较好的效果。(2)动态手语孤立词识别:为了解决以往手语视频流复杂背景中冗余信息造成的干扰以及模型复杂度过高等问题,提出一种M-LRCN网络架构。首先是基于Media Pipe的手语视频人体姿态预处理方法,将预处理后的手语视频连续帧作为LRCN手语识别模型的输入。其次针对LRCN网络模型中存在的参数量大且准确率不高的问题,将LRCN中提取视频中空间特征的Alex Net替换为轻量型网络Mobile Net V3。在CSL数据集前一百类手语孤立词中,该方法的准确率达到了91.75%,比Alex Net-LSTM模型提高了11.95%,模型大小降低约为88.5%,进一步的降低模型参数量的规模。(3)本文根据上述改进的算法,使用PYQT、Android、Tensor Flow Lite等框架,分别实现了桌面端和移动端的静态和动态手语识别应用。并在实际使用中对各个客户端的系统交互界面进行了验证和调整。通过这些改进,手语识别系统的使用变得更加便捷和快速,更好地满足不同场景下使用者的需求。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2023.003074
{DOI}: 10.27232/d.cnki.gnchu.2023.003074
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进Yolo v5s的居家跌倒行为检测的研究
{Author}: 宗樟平
{Tertiary Author}: 陈炼;李艳琴
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;跌倒检测;Yolo;注意力机制;时序变化
{Abstract}: 我国自2021年就已经进入了老龄化社会,并且根据目前的趋势看来,社会的老龄化问题会进一步加剧,而老年人的跌倒问题是影响老年人健康的重要因素之一。独居老人跌倒事件频发,如果老人在跌倒后得不到及时的救助,轻则受伤耽误治疗,严重的话可能危及生命。因此,具有实时跌倒检测的研究很有必要性。本文对人体站立以及跌倒的姿态进行特征提取,引入注意力机制关注人体信息,对人体的跌倒判别进行了研究,研究的主要内容如下:(1)研究了基于融合通道空间注意力机制的人体目标识别算法。在所监控的环境中,首先必须获得人体所处的位置,才能够对人体的姿态做出准确的判断。针对在室内环境中环境复杂、物品较多导致难以识别到人体的问题,本文提出了一种融合通道空间注意力机制,针对CBAM的通道关系依赖学习层,利用1×1卷积层替换了原先的全连接层,减少模型的参数量。在网络残差块结构以及骨干网络中添加注意力机制后,能够更加关注区域内人体的运动状况,有效降低了其他物体对结果的干扰。(2)针对于现有的Yolo v5s网络,对于骨干网络,使用hard-swish激活函数替换了Leaky Re LU激活函数,利用ASPP网络结构替换了原有的SPP结构。对于颈部结构,采用了Bi FPN结构,以及对初始特征进行进一步提取的preBi FPN结构替换Yolo v5s的FPN+PAN结构,通过对比实验,采用更优的结构使得目标检测的精准度以及召回率有了明显的提高。(3)研究了一种基于视频帧时序变化的跌倒判定方法,一般的基于视频的跌倒检测往往都是切取每一帧的图像对其进行姿态分类,经过对这些算法的研究,发现这类算法容易造成误判,比如容易将平躺,蹲下等姿态视为跌倒状态。本文将目标检测结合多帧关联视频帧,设计了算法来进行跌倒判断,并且采用了多摄像头的投票机制来综合判断,有效降低了误判率。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2023.003973
{DOI}: 10.27232/d.cnki.gnchu.2023.003973
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 支持抗光照目标检测的改进YOLO算法
{Author}: 姚宇捷;彭育辉;陈泽辉;何维堃;吴庆;黄炜;陈文强
{Author Address}: 福州大学机械工程及自动化学院;福建汉特云智能科技有限公司;
{Journal}: 汽车工程
{Year}: 2023
{Volume}: 45
{Issue}: 05
{Pages}: 777-785
{Keywords}: 机器视觉;抗光照图像处理;Ghostnet网络;损失函数
{Abstract}: 针对现有的深度学习目标检测算法中存在的复杂光照场景下检测精度不高、实时性差等问题，提出了一种基于YOLO算法的抗光照目标检测网络模型YOLO-RLG。首先，将输入模型的RGB数据转换为HSV数据，从HSV数据分离出抗光照能力强的S通道，并与RGB数据合并生成RGBS数据，使输入数据具备抗光照能力；其次，将YOLOV4的主干网络替换成Ghostnet网络，并对其在普通卷积与廉价卷积的模型分配比例上进行调整，在保证检测精度的同时提高检测速度；最后，用EIoU替换CIoU改进模型的损失函数，提高了目标检测精度和算法鲁棒性。基于KITTI与VOC数据集的实验结果表明，与原网络模型比较，FPS提高了22.54与17.84 f/s，模型降低了210.3 M，精确度（AP）提升了0.83%与1.31%，且算法的抗光照能力得到显著增强。
{ISBN/ISSN}: 1000-680X
{Notes}: 11-2221/U
{URL}: https://link.cnki.net/doi/10.19562/j.chinasae.qcgc.2023.05.007
{DOI}: 10.19562/j.chinasae.qcgc.2023.05.007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的芯片缺陷检测技术研究
{Author}: 尤世军
{Tertiary Author}: 张建敏
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像分割;特征提取;缺陷检测
{Abstract}: 近年来,随着人工智能和大数据等技术的飞速发展,芯片已成为现代化产业中不可或缺的组成部分。然而,由于芯片制造过程的复杂性和缺陷的隐蔽性,芯片缺陷的存在和影响仍然是一个普遍存在的问题。利用机器视觉等技术对芯片图像进行自动缺陷检测,可以有效地增加企业的生产效率。因此,本文的研究主要基于机器视觉在芯片缺陷检测方面的应用,通过采用先进的图像处理技术,成功地开发出了一种针对晶圆芯片和芯片Frame的缺陷检测系统。本文对芯片图像的预处理算法和芯片的缺陷检测算法进行了重点研究。主要工作如下:(1)预处理算法研究。针对晶圆图像的边缘轮廓清晰的特点,设计了一套晶圆图像的预处理分割算法,算法包括图像拼接、倾斜矫正、图像滤波、边缘检测以及轮廓提取,最后通过单芯片轮廓的最小外接矩形坐标信息分割出单个芯片图像,分割准确率达到了100%;针对背景复杂、边界模糊以及芯片相连等特征的芯片Frame图像,提出了一种基于模板匹配的芯片Frame图像分割算法,首先,对整幅芯片Frame图像预分割出多个区域模块;然后,基于区域模块图像采取模板匹配算法匹配单芯片图像;最后,通过合并单芯片的重叠匹配框并记录合并框的坐标信息来分割出单芯片图像。实验结果表明:经过实验选取合适的模板和阈值,能使该算法的分割准确率达到100%,且比不基于区域模块匹配的分割算法节省了至少45.76%的分割时间,满足芯片Frame高精和高速的分割需求。(2)缺陷检测算法研究。通过对晶圆芯片和芯片Frame的缺陷类型特征分析,针对每种缺陷类型分别设计了缺陷特征提取方法用于缺陷检测:针对空Die缺陷,采取模板匹配算法识别空Die缺陷芯片;针对外来物缺陷,提出中值滤波结合高斯滤波模糊芯片图像,通过阈值分割提取外来物缺陷特征;针对芯片污染缺陷,提出在频域图像内经过带通滤波增强污染物,在利用阈值分割算法提取污染物;针对焊点偏离、焊球尺寸超标、银浆爬高等缺陷,则利用Halcon工具中的threshold算子提取目标物并通过测量相关尺寸实现芯片Frame的缺陷检测,并分别对其进行算法验证,实验结果表明了本文设计的缺陷检测算法误检率低于5%,检测的准确性达到90%以上。(3)缺陷检测系统实现。设计了系统硬件的成像方案,对相机、镜头、光源等硬件的选型以及安装方式等方面做了详细介绍;阐述了系统软件的运行流程和实现的技术细节,并在设计的软件系统上运用上述算法实现了对芯片的分割以及对芯片缺陷的检测。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2023.000139
{DOI}: 10.27800/d.cnki.gjhdx.2023.000139
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的桥梁智能检测方法与装备研发
{Author}: 蒋赏
{Tertiary Author}: 张建
{Publisher}: 东南大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 桥梁检测;计算机视觉;深度学习;无人机系统;三维重建
{Abstract}: 桥梁是我国交通网络中的重要组成部分。近几十年我国桥梁建设取得了举世瞩目的成绩,但同时桥梁坍塌等事故也时有发生。如何维护数量庞大的桥梁健康服役是如今土木领域的一项研究重点。桥梁在长期运营服役过程中受长期交通荷载和突发事件等因素影响难免会产生损伤,影响桥梁安全运营。定期检测桥梁的健康状态,从而维修、加固桥梁是维持桥梁安全运营的重要手段。目前广泛应用的基于人工的桥梁检测方法因其效率低、成本高和危险性大等因素而逐渐不能满足体量庞大的桥梁检测需求。基于此,本文从桥梁检测的实际需求出发,将桥梁检测分为桥梁病害检测、变形检测和三维形态检测三个层次,在“测量最优”和“分析最优”两个层面分别研究如何提升桥梁检测的智能化、高效化和高精化程度。其中“测量最优”是针对桥梁数据采集的特殊需求开发检测设备获取数据,“分析最优”则是对获取的海量多源数据开发高精度和自动化的分析算法。具体研究内容如下:
(1)裂缝是桥梁病害检测中最常见也是最受关注的类型,对此提出了基于吸附式无人机和智能手机的裂缝实时检测方法。该方法首先针对裂缝的宽度小而桥梁体型庞大的矛盾,设计了一种具备飞行和吸附爬行两种工作模式的无人机,从而能以飞行检测的方式先对结构进行快速粗略检测,再对发现病害的位置执行贴近吸附的精细化检测,从而使微小裂缝也能被采集到。其次针对无人机获取的视频的自动化分析问题,设计了一种以智能手机为处理终端的裂缝图像分析方法,该方法通过智能手机上移植的轻量化裂缝检测模型和宽度计算算法对裂缝进行实时框选和快速宽度计算。在建筑的外墙裂缝检测的测试中,所提出的裂缝检测方法实现了0.1毫米精度的裂缝检测和在智能手机端6帧/秒的实时检测效率。
(2)进一步针对桥梁多类型病害的检测,提出了基于视觉定位无人机和边缘计算的多类型病害识别与定位方法。对于病害图像的采集和预处理,首先针对桥梁周边GPS信号微弱造成传统无人机无法定位的难题,设计了一种以双目视觉定位代替GPS定位的无人机系统克服该问题。然后针对飞行拍摄时造成的图像运动模糊和分辨率不足的问题,提出了基于光流估计的去运动模糊方法和基于超分辨率的图像清晰化方法。对于病害分析,通过对YOLO v3模型更换轻量化的骨干网络得到推理速度快且对计算性能要求低的轻量化网络,在所建立的多类型病害数据库中训练完成后该网络可在无人机机载计算机上实现边缘计算实时识别病害。最后提出一种基于视觉实时建图的病害定位方法,使所检测的病害能直接反映在结构上。在一座混凝土斜拉桥的桥底和桥塔病害检测中,所提出方法和系统实现了桥底等无GPS环境的巡检、17.5帧/秒的多类型病害实时识别和病害的自动定位。
(3)病害检测中还存在对内部信息测量的需求,对此提出了基于可碰撞无人机与视觉-接触式相结合的病害检测方法。以桥梁的涂层检测为切入点,其检测包括表观劣化和涂层厚度测量两部分。首先针对钢结构桥梁周边磁干扰大、障碍物多和接触检测的需求,设计了一种具备3D打印的耐碰撞框架、UWB伪GPS定位和弹性力反馈机械臂的无人机系统执行检测,该无人机在接触桥梁时可以通过压力反馈控制无人机维持稳定的接触状态,从而能使机械臂上的磁涡流探头测量涂层厚度。在涂层检测上,提出了一种视觉和接触式相结合的方法,首先通过相机对桥梁涂层进行快速视觉检测,其核心是采用一种无锚的目标检测网络实时识别涂层是否存在剥落、空鼓和消退;而后对于检测到的涂层劣化区域,对其周边采取接触式无损检测方法测量厚度分布情况。所提出方法被应用于一座钢结构人行桥的底部涂层检测中,与人工手持测量设备相比,所提出方法的误差小于5%。
(4)针对桥梁的变形检测,为克服传统基于视觉的测量方法在远距离测量大跨度桥梁时精度随之下降的问题,提出基于无人机机载双相机的桥梁变形测量方法,该方法的核心是提出采用具有长焦相机和广角相机的双相机同时拍摄桥梁梁体上的变形部位和桥墩不动点,以桥墩为参考物从理论推导角度将无人机的基点运动剔除。在变形测量上,为克服传统基于图像特征匹配的方法易受光照变化等干扰丢失目标的问题,提出采用深度学习定位测量靶标,利用卡尔曼滤波预测增强测量鲁棒性的变形测量方法。所提出方法被应用于一座悬索桥在车流荷载下的变形测量中,结果证明所提出方法具有高精度和稳定的优势。
(5)进一步将变形测量推广到全场变形测量中,针对静态结构的变形和移动构件的变形测量,分别提出了一种基于全景相机和基于多无人机同步追踪的变形测量方法。针对大尺寸缩尺模型的力学测试下的全场变形测量,提出应用全景相机获取全场图像,设计了立方体投影分割和独立标定方法将畸变严重的全景图像转化成正常视角的图像,然后针对缩尺模型节点小纹理不足造成传统变形测量方法极易丢失目标的问题提出一种基于小目标检测网络辅助定位和亚像素直线检测的节点中心坐标精度提取方法,从而能稳定、精确地解算节点位移。而针对桥梁建设中的大尺寸构件吊装的变形测量问题,应用多个无人机分布结构四周同步飞行追踪,同时获取结构侧面变形情况,采用基于Ar Uco编码靶标的高实时性变形计算方法得到每个侧面的变形,最后通过多无人机的视场匹配关系和立体几何理论将二维变形恢复为三维变形。上述方法被应用于一座大尺寸结构缩尺模型的变形检测和模拟钢筋部品吊装的变形测量中,与全站仪等设备的结果对比验证了所提出方法的实用性。
(6)桥梁的三维形态检测在桥梁建设和服役阶段都具有重要意义,但如何快速建立大规模桥梁结构的精确三维模型是其中的难点。对此提出了基于无人机载激光相机融合的桥梁三维重建方法和点云快速分割方法提取桥梁线形。首先搭建了融合非重复式扫描激光雷达和相机的低成本三维扫描设备,将其集成于无人机上进行动态扫描,其中采用基于目标的标定方法标定相机和激光雷达,应用视觉激光紧耦合的方法建立视觉里程计重建三维点云,从而实时建立桥梁的三维点云模型。其次采取一种由粗略到精细的图像分割网络精准从图像中分割桥梁构件,根据相机和激光雷达的标定关系将图像的分割结构投影到点云中,从而快速分割出桥梁构件,提取桥梁三维线形。所提出方法被应用于一座在役混凝土拱桥的线形测量中,与高精度三维激光扫描设备进行对比验证所提出方法的精度和效率。
{URL}: https://link.cnki.net/doi/10.27014/d.cnki.gdnau.2023.000216
{DOI}: 10.27014/d.cnki.gdnau.2023.000216
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉Transformer的复杂环境植物病害检测算法研究与实现
{Author}: 郭译凡
{Tertiary Author}: 兰艳亭
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 植物病害检测;计算机视觉;深度学习;Vision Transformer;卷积神经网络
{Abstract}: 在现代农业生产过程中,植物病害会严重降低农作物产量从而威胁粮食安全。近些年随着人工智能技术的发展,不少学者采用计算机视觉结合深度学习的解决方案应用于检测植物病害。但是,由于该技术在农业生产应用场景下仍然存在一些问题。本文以复杂环境下植物病害检测为核心问题,通过构建深度学习检测模型,提高在复杂环境下植物病害的检测准确率及鲁棒性。主要工作归纳如下:1.复杂环境下植物病害检测的研究。针对复杂环境下病害检测设计了Convolutional Swin Transformer(CST)系列模型以及ACmixed Alex Net网络结构。通过将卷积神经网络和自注意力机制结合的方式获得了极高的鲁棒性。其中,在黄瓜数据集中CST系列模型最高获得0.909的检测准确率,ACmixed Alex Net则获得0.904的检测准确率;香蕉数据集下CST系列模型最高获得0.922的检测准确率,ACmixed Alex Net则获得0.940的检测准确率。2.图像噪声对植物病害检测影响的研究。针对该问题,提出CST系列模型,在实验中测试其在噪声影响下检测植物病害的性能表现。首先,将在真实环境下拍摄得到的图像数据中分别增加10%、20%和30%的椒盐噪声。在增加了噪声的黄瓜数据集下CST系列模型仍然能够维持0.8的检测准确率;在检测增加噪声的香蕉数据集时,即便增加了30%的椒盐噪声仍然能够获得0.9的检测准确率。3.光照强度对植物病害检测影响的研究。针对该问题,提出ACmixed Alex Net模型。首先,将香蕉数据集中图像的亮度分别提高和降低10%、20%以及30%,获得共6种不同图像亮度。在该数据下测试得到ACmixed Alex Net在提高30%亮度的情况下获得最高0.956的检测准确率;同时在降低30%亮度的条件下仍然达到0.9的检测准确率。4.移动设备中可用性研究。通过将算法模型以Android软件的形式部署在移动设备中。首先,采用Py Torch Mobile将训练好的CST系列模型和ACmixed Alex Net模型封装至Android软件。随后,在实验中测试部署后的软件检测植物病害的性能表现,在移动端模型经过剪枝优化后,整体检测准确率仍然保持在0.8以上。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.001063
{DOI}: 10.27470/d.cnki.ghbgc.2023.001063
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的车道线检测与车辆偏离预警方法研究
{Author}: 钟勇
{Tertiary Author}: 黄艳国
{Publisher}: 江西理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 车道线检测;滑动窗口法;拓展卡尔曼滤波;TLC模型;车辆偏离预警
{Abstract}: 智能辅助驾驶系统(advanced driving assistance system,ADAS),使用车身硬件感知车辆周围环境以进行数据搜集,并对车辆数据信息进行系统运算与分析,提醒驾驶者潜在危险并采取相对应措施,有效提升驾驶舒适性与安全性。其中车道线检测与车辆偏离预警技术作为智能辅助驾驶系统的重要组成部分,如何基于现有的视觉硬件基础来达到较好的车道线检测以及预警效果成为行业研究热点。为此,本文基于单目摄像机进行道路环境感知并结合改进后的图像处理算法来实现结构化道路中前方车道线识别与车辆偏离预警功能的优化提升,主要研究工作如下:(1)为确保后续车道检测有精简的数据输入,对道路图像进行预处理操作。对畸变矫正后的车道线图像进行多通道加权图像灰度化处理,使得车道线主体与环境背景有更明显的区分度;通过改进OTSU算法的最优阈值求解方法使得阈值分割的速度得到提升;然后使用HED模型提取出车道线边缘特征并框选出车道线感兴趣区域,结合自适应逆透视变换模型将车道线图像转换成平行模式。结果表明,本文预处理方法所得车道线特征明显、图像噪声较少、处理速度也得到提升。(2)常规车道线提取方法在拟合弯道时存在准确率或实时性下降的缺陷,使用改进滑动窗口法结合拓展卡尔曼滤波进行车道线检测与跟踪。将预处理后的图像作为算法输入,首先确定左右车道线像素在图像中的起始位置;然后将起始位置作为初始窗口位置并按规则进行滑动,获取窗口像素并进行车道曲线拟合,在窗口遍历图像后进行车道曲线的平滑优化,得到车道线检测结果;基于以上检测结果结合拓展卡尔曼滤波进行车道线跟踪,改善复杂环境下的车道线识别率。实验测试表明,改进后的车道线检测算法能够兼顾直道与弯道识别,在提升整体车道线检测准确率的同时算法实时性也得到保证。(3)基于TLC预警模型在预警时间上的优势,对其计算过程与预警决策进行优化以提升预警准确性。首先基于相机成像原理计算出相机外部参数以便于获取计算所需参数;其次基于TLC模型原理计算出车辆偏航角,并利用车道线检测信息改进车辆横向偏离距离计算方式并计算弯道曲率半径,根据所得参数计算出车辆跨越车道线所需时间;最终通过评价函数判断车辆所属运动状态,并结合系统阈值对车辆进行偏离预警输出。通过实验验证与分析,本文方法在多种环境中的预警效果表现良好,能够避免一些误警现象的出现,在预警准确率上有一定的提升,实时性能够满足系统要求。
{URL}: https://link.cnki.net/doi/10.27176/d.cnki.gnfyc.2023.000845
{DOI}: 10.27176/d.cnki.gnfyc.2023.000845
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5s的名优绿茶品质检测
{Author}: 尹川;苏议辉;潘勉;段金松
{Author Address}: 杭州电子科技大学电子信息学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 08
{Pages}: 179-187
{Keywords}: 机器视觉;图像识别;茶叶品质检测;YOLOv5s;感受野;swin transformer;注意力机制;SimOTA
{Abstract}: 针对实际检测过程中茶叶数量多、体积小、茶叶之间颜色和纹理相似等特点，该研究提出了一种基于YOLOv5s的名优绿茶品质检测算法。首先，该算法在骨干网络层引入膨胀卷积网络，通过增大感受野的方式增强茶叶微小特征的提取。其次，改进特征融合进程，基于通道注意力和空间注意力抑制无关信息的干扰，构建CBAM注意力机制优化检测器。接着根据swin transformer网络结构在多个维度对小尺度茶叶的特征进行交互和融合。最后，配合SimOTA匹配算法动态分配茶叶正样本，提高不同品质茶叶的识别能力。结果表明，改进后的算法精准度、召回率、平均精度均值、模型体积、检测速度分别为97.4%、89.7%、91.9%、7.11MB和51帧/s，相较于基础的YOLOv5s平均精度均值提高了3.8个百分点，检测速度提高了7帧/s。利用相同数据集在不同目标检测模型上进行对比试验，与Faster-RCNN、SSD、YOLOv3、YOLOv4等模型相比，平均精度均值分别提升10.8、22.9、18.6、8.4个百分点，进一步验证了该研究方法的有效性和可靠性。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.s.20230515.1849.016
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的智能仓储管理系统设计与研究
{Author}: 吴杰昊
{Tertiary Author}: 张广渊;王振飞
{Publisher}: 山东交通学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;仓储管理;货物数量统计;货物堆放模型
{Abstract}: 仓储管理对于减少货品储存过程中的损失,以及提高货品经济效益具有重要意义。仓储货物数量的统计是仓储管理中重要的信息源,为科学的仓储管理策略提供了数据支持。传统货物数量统计基于RFID技术获取流通的货物的信息,存在耗时、费力、复杂的问题。现有的基于计算机视觉的统计方法尚不成熟,设备规划困难、经济成本较高且准确率不理想,在货物数量统计领域的应用并不广泛。为解决上述问题,本文提出了基于合理性损失的货物堆放模型构建方法。在仅使用原有监控摄像头的基础上构建出货物模型并完成高精度的货物数量估算。为获得更高质量的建模效果,本文还设计了基于CSwin-Unet分割模型结合像素位置权重损失函数的货物区域分割方法。主要研究内容如下:(1)PPW-CSwin-Unet的货物区域分割模型。为实现对货物区域进行精确分割,本文在Swin-Unet模型的基础上加以改进,设计了CSwin-Unet语义分割模型,并在COCO stuff数据集上进行了预训练。此模型能够快速、精确的完成语义分割任务。为解决货仓图像内像素重要程度不均衡的问题,本文设计了像素位置权重(pixel position weight,PPW)损失函数。使用其在本地货物分割数据集对CSwin-Unet进行微调,能够获得更好的特征提取效果。(2)货物数量估算与基于合理性损失的货物堆放模型构建。为实现箱式货物数量的估算,本文设计了基于XGBoost回归模型的货物数量估计方法。在此基础之上,为了构建具象化的货物堆放模型,本文设计了基于合理性损失的货物堆放模型构建方法。此方法不仅构建了数字化的货物堆放的三维模型,而且可以通过累加计算完成货物数量的估算,对可视化及其他科学管理工作具有重要意义。(3)基于YOLOv4的仓库电子围栏。为实现高精度的货仓区域电子围栏功能,本文设计了基于YOLOv4的闯入检测算法。使用YOLOv4对仓库内物体进行目标检测,通过目标框特征点与仓位投影多边形的关系,实现对目标位置是否在电子围栏内的识别判定。结合前后多帧的判定结果优化当前帧的判定结果,提高连续帧的判定准确率。最终达到了98.67%的准确率,能够满足任务需要。基于上述研究,本论文研发了基于B/S架构的仓储管理系统,实现对仓库内货物数据的实时监测与管理。主要功能包括货物数量估算、货物堆放模型构建、电子围栏监测。此外,将电子围栏进出记录与货物模型结果相结合,生成货物进出库记录。通过对建模结果进行分析,提供货物进出库单元位置推荐,为货物仓储自动化管理提供数据支持。
{URL}: https://link.cnki.net/doi/10.27864/d.cnki.gsjtd.2023.000137
{DOI}: 10.27864/d.cnki.gsjtd.2023.000137
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手势识别研究
{Author}: 杨钰敏
{Tertiary Author}: 徐硕博;陈新
{Publisher}: 山东交通学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手势识别;卷积神经网络;注意力机制;Transformer
{Abstract}: 手势识别一直是人机交互领域不可或缺的部分,它的研究状况与人机交互技术的发展相辅相成。虽然现在的人工智能技术对手势识别的准确率有了一定的提升,但在实际操作中,还是会受到很多因素的影响:手势图片中场景复杂多变,干扰因素过多;手势数据集中手部的大小,所在的位置各不相同;手部形状颜色千差万别等。这些因素都会影响网络对于手部的特征提取,从而影响手势识别的准确率。因此,在复杂环境中准确地识别手势,是一项极具挑战性的任务。为解决上述难点问题,本文将进行以下几个方面的研究:(1)在复杂的背景下,由于手势与周围的背景难以区分,手势识别变得困难。为了减少复杂背景对手势识别的影响,本文提出了一种基于Histogram of Oriented Gradients和Faster Regional based Convolutional Neural Network融合的手势识别网络。首先采用目标检测的方法,提取手势区域;然后通过引入HS模块来微调网络的分类损失值,以提高网络的手势识别准确率;最后引入了Squeeze-and-Excitation空间注意机制来提高预测边界框的精度。(2)图像中场景复杂程度、手型和手部大小都会对手势识别产生影响,为了解决这些问题,本文提出了一种基于改进Light-weight,General-purpose,and Mobile-friendly Vision Transformer的手势识别网络,提高网络特征提取的鲁棒性。为了增强网络对手部的敏感度,设计了一个MS-MViT模块,通过混合形状窗口的自注意力机制来增加网络对特征图全局信息提取的能力,降低复杂场景对模型识别精度的影响。通过引入Spatial Pyramid Pooling模块,结合特征图的局部特征和全局特征,丰富特征图的表达能力,以便更好地识别不同大小的手。(3)设计了一个深度网络手势识别系统。用户能够根据待识别图像的类型,选择合适的网络进行手势识别,并实现识别结果可视化展示,以此为用户带来更高的自由度,有助于用户更好的理解识别结果。
{URL}: https://link.cnki.net/doi/10.27864/d.cnki.gsjtd.2023.000145
{DOI}: 10.27864/d.cnki.gsjtd.2023.000145
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在农作物种子检测中的研究进展
{Author}: 王昊;祝玉华;李智慧;甄彤
{Author Address}: 粮食信息处理与控制教育部重点实验室(河南工业大学);河南工业大学信息科学与工程学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 22
{Pages}: 69-83
{Keywords}: 种子检测;机器视觉;不完善粒;图像处理
{Abstract}: 农作物种子是农业生产的基础。种子检测作为一种重要的手段，在种子生产、贸易和利用的各个环节都扮演着不可或缺的角色。然而传统的农作物种子识别方法效率低，需要人力以及专业检测设备的支持。相比之下，机器视觉技术能够通过模拟人的视觉功能来实现对目标的无损检测，效率高、准确度高，有助于实现农作物种子的品种识别、分级、分类的自动化、智能化。首先简单叙述了机器视觉技术中图像采集、预处理的方法，并以玉米种子为例给出了目前主流的处理流程，然后具体叙述了机器视觉技术中传统机器学习和深度学习两种检测方式在农作物种子检测中的应用，最后针对玉米不完善粒的研究，在分为以上两种检测方式进行具体叙述的同时，指出了目前存在的问题以及玉米不完善粒检测未来的研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230512.1451.008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于OpenCV的工业机器视觉软件开发
{Author}: 庄晓岩
{Tertiary Author}: 朱俊
{Publisher}: 内蒙古大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 工业机器视觉软件;面向对象;软件封装;OpenCV;应用测试
{Abstract}: 机器视觉是一种通过对图像、视频等信息进行采集、处理和分析,从中提取出有用的特征和信息,并通过算法和模型进行智能处理和决策的技术。机器视觉在某些方面与人眼视觉相比有很大优势,如感光范围广、可连续且稳定工作、环境适应能力强、精度高、可重组性强、易于信息集成等。目前关于机器视觉的软件主要是一些商业化软件,其功能不一定满足与适合企业的需求。一些研究者基于Open CV所开发的系统软件,其功能只在某一方向上有所成就,无法满足企业多个不同项目的需求。因此,为了企业的发展,需要自主研发相应的工业机器视觉软件。本文主要研究内容如下:
(1)了解和掌握机器视觉方面的基础理论知识,同时也对企业的各个项目需求进行深入分析和挖掘。在视觉算法的复杂性与视觉软件的易用性两者之间取得平衡,开发了一款多功能、可视化、面向对象的工业机器视觉软件,并将视觉软件封装成为安装程序,以便用户安装使用。所开发的视觉软件的侧重点不在于对机器视觉的某个特定领域的深入研究,而是提供有可能应用于不同项目的各个机器视觉算法。采用开源Open CV视觉库作为基础算法库,如果Open CV所提供的算法可以满足软件的功能需求,则可以有选择性的使用其提供的功能作为底层算法;如果软件的一些功能需求Open CV无法实现或者实现的结果不理想,也可以对其算法进行改进优化或者自行编写算法。
(2)将所开发的视觉软件在实际的工业环境中进行应用测试,经过测试,证明本视觉软件具有流程配置灵活简洁、性能稳定可靠、操作简单易学等良好特性。根据实际的应用与企业的需求,同时也综合考虑其他因素,对视觉软件的应用范畴与功能进行了相应地拓展,并在之后的应用中取得了较好的效果。同时在应用测试中发现了视觉软件的某些功能存在问题并提出了相对应的解决方案,从而实现了对视觉软件的优化和改进,提高了机器视觉软件的应用效果和可靠性。
随着智能制造行业的快速发展,本视觉软件会应用在更多、更复杂的环境中,这就需要不断地拓展视觉软件的功能,不断地完善机器视觉软件,使其功能更加丰富、强大。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2023.001285
{DOI}: 10.27224/d.cnki.gnmdu.2023.001285
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的视觉问答研究综述
{Author}: 李祥;范志广;李学相;张卫星;杨聪;曹仰杰
{Author Address}: 郑州大学网络空间安全学院;郑州大学河南先进技术研究院;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 05
{Pages}: 177-188
{Keywords}: 视觉问答;跨模态;人机交互;推理能力;可解释性
{Abstract}: 视觉问答是计算机视觉和自然语言处理的交叉领域。在视觉问答的任务中，机器首先需要对图像、文本这两种模态数据进行编码，进而学习这两种模态之间的映射，实现图像特征和文本特征的融合，最后给出答案。视觉问答任务考验模型对图像的理解能力以及对答案的推理能力。视觉问答是实现跨模态人机交互的重要途径，具有广阔的应用前景。最近相继涌现出了众多新兴技术，如基于场景推理的方法、基于对比学习的方法和基于三维点云的方法。但是，视觉问答模型普遍存在推理能力不足、缺乏可解释性等问题，值得进一步地探索与研究。文中对视觉问答领域的相关研究和新颖方法进行了深入的调研和总结。首先介绍了视觉问答的背景；其次分析了视觉问答的研究现状并对相关算法的和数据集进行了归纳总结；最后根据当前模型存在的问题对视觉问答的未来研究方向进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw-s48PUmm7B5zoRUP91fdIhcxH5pME7UNzv3Fh11mnc_3QNHEDSxrC_EvLIyEbcto3tAoFStxRFZPcxcRH5q1Q3OwAbV36pI3NViHKfmkDFKiWmbyN3tGoIWY8yGSGLUTCQku8JL3tDFxaCXqHGmheoOc4G-Qfvssff4cisleOujBnSjVbx6JmJG8PXWjrD0E=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 乳腺癌病理图像细胞识别与组织分类算法研究
{Author}: 张晓璇
{Tertiary Author}: 冯前进
{Publisher}: 南方医科大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 淋巴细胞识别;组织结构分类;深度学习;病理图像分析;乳腺癌
{Abstract}: 病理图像作为医学图像中的重要成员,一直被认为是用于诊断疾病的“金标准”。对病理图像的定量描述,例如细胞的形态及空间分布,组织结构的类型及面积等,有助于深入理解疾病发生发展的潜在规律,从而提示一些癌症可以早预防、早诊断和早干预以降低发病率,提升存活率。然而,病理图像自身超高的空间分辨率给人工定量评估带来巨大挑战。通过计算机辅助分析方法,可以有效弥补医生在临床决策过程中难以准确定量描述病理图像的现状,以更客观、稳健的全自动方式协助病理医生进行快速精准的临床诊断、病程分析及预后预测等。本文围绕H&E染色乳腺癌病理图像定量分析中的关键难点问题,分别从细胞层面与组织层面基于深度学习方法开展以下研究工作:(1)基于密集双任务网络的乳腺癌淋巴细胞识别。针对乳腺癌淋巴细胞体积小且空间分布复杂等特性造成的人工量化难问题,此工作提出了一种基于深度学习的密集双任务神经网络(Dense Dual-Task Network,DDTNet),用于对H&E染色乳腺癌病理图像中的淋巴细胞同时进行自动精准检测与分割。特征编码主干网络用于提取与淋巴细胞位置及形态相关的多尺度深层次特征;检测和分割解码器分别将深层次特征映射为淋巴细胞位置和形态概率图;特征融合模块为分割解码器快速引入带有淋巴细胞位置信息的多尺度深层特征,提升细胞识别性能。在三个乳腺癌淋巴细胞数据集上验证了该方法在细胞检测和分割两方面卓越的性能。此外,本工作还提出了一种基于水平集的半自动细胞标注方法TILAnno,为基于数据驱动的细胞识别框架发展提供源动力。(2)基于高效区域感知网络的乳腺癌组织结构分类。针对乳腺癌组织结构种类繁杂且分布无章以及病理图像定量分析时效性需求等特性造成的人工量化难问题,此工作提出了一种基于深度学习的高效区域感知神经网络(Efficient Region-Aware Network,ERANet),用于对 H&E 染色乳腺癌病理图像中的组织结构进行快速精确的自动划分。轻量级多尺度特征提取模块为局部区域高效聚合不同感受野下的多尺度上下文信息;轻量级动态区域注意力模块通过构建区域间相关性实现全局特征的动态分区增强;子区域分类策略高效编码邻域上下文信息并快速输出区域分类结果;基于区域正则化的损失函数帮助模型建模乳腺癌各组织结构间独有的空间分布关系。在三个乳腺癌组织结构分类数据集上验证了该方法在模型精度与推理速度之间进行了良好的权衡。综上,本文从两种不同的角度展示了基于深度学习方法辅助病理图像精准定量分析的可行性,为计算病理学的发展提供有力的工具及理论基础。
{URL}: https://link.cnki.net/doi/10.27003/d.cnki.gojyu.2023.000102
{DOI}: 10.27003/d.cnki.gojyu.2023.000102
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像拼接算法研究与实现
{Author}: 罗亚娜
{Tertiary Author}: 王中生;于福亚
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像拼接;卷积神经网络;单应变换;transformer;SE注意力机制
{Abstract}: 近些年来,图像拼接技术成为了计算机视觉领域的一个研究热点。传统的图像拼接技术在面对弱纹理或无纹理的图像时,如林区、天空以及海面等场景,由于特征检测能力不足,从而会导致拼接效果不佳;在深度学习中,有监督的方法由于数据集的标记工作存在人工成本高,时间开销大等问题,导致该方法难以得到普及;而无监督的方法由于图像间的视差问题,在面对大视差的待拼接图像时,其拼接结果也往往不太理想。为了更好的对林区图像进行拼接,本文提出了一个全新的、无监督的深度学习图像拼接算法,其在面对特征较少且拥有不同视差问题的林区图像,皆拥有较好的图像拼接效果。该算法主要分为单应变换和图像缝合两部分:(1)在基于transformer的单应变换网络中,以卷积神经网络强大的特征提取能力为基础,采用单应变换的方式,在求得图像间的单应变换矩阵后,利用transformer将特征映射通过单应矩阵进行空间变换,从而将大视差的待拼接图像转换为小视差的待拼接图像,其在保证图像内容完整性的同时,也降低了待拼接图像间的视差问题;(2)在基于注意力机制的图像缝合网络中,以VGG-16网络为基础,首先对小视差的图像进行缝合操作,然后采用卷积神经网络和SE注意力机制相结合的方式,解决了初步图像缝合后存在的色彩亮度不一致以及色彩失真等问题。经过实验对比,在主观视觉方面,本文所提出的算法在各类不同的林区场景拼接任务中,拼接缝自然且拼接伪影较少,同时色彩失真率较低;在量化分析方面,本文所提出图像拼接算法的PSNR值比SIFT算法提升了1.991 d B,比SFE算法提升了11.7921 d B,比DHN算法提升了0.803 d B;且本文所提出图像拼接算法的SSIM值比SIFT算法提升了7.37%,比SFE算法提升了8.68%,比DHN算法提升了2.32%。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000215
{DOI}: 10.27391/d.cnki.gxagu.2023.000215
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去噪研究与应用
{Author}: 吴垒
{Tertiary Author}: 徐昊
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去噪;元学习;深度学习;计算机视觉
{Abstract}: 图像是一种常见的信息存储形式,其不仅能直观地表示大量相关的信息,还具有易于存储和传输等优势。由于各种环境和信道因素的影响,图像在采集、压缩和传输过程中难免受到噪声的干扰,导致图像信息失真或丢失。同时,因为噪声的存在,可能对后续的图像处理任务,如图像分类产生不利影响。真实噪声的无噪声标签也不易获取。因此,如何依靠少量训练样本并从含噪图像中恢复出有意义的信息是当今图像处理领域内的一个重要问题。为了解决真实噪声去噪问题,本文提出了多尺度两阶段图像去噪网络模型(MTDNet)与基于元学习的多尺度两阶段去噪模型(MMTDNet)。本文的主要研究工作分为两个方面,分别为高性能图像去噪模型的构建、在少量训练样本中提高模型的去噪能力。最后将该模型投入到网站应用中。具体相关研究工作如下:(1)本文基于UNet提出了一种多尺度两阶段图像去噪网络模型,目标是在保留图像的高维信息条件下实现对图像中真实噪声的去除。在网络的两个阶段中,本研究利用注意力机制、空洞卷积与普通卷积提取不同尺度的特征,再将第一阶段空洞卷积与第二阶段普通卷积各自提取到的不同尺度的特征进行特征融合,使模型能够获取足够多的特征信息,进而完成去噪任务。(2)为了在训练数据不足的真实噪声数据集上达到更加良好的去噪效果,将本文提出的去噪网络模型与元学习思想相结合,并划分出合成噪声子任务用以元训练,以达到可以使用少量的真实噪声训练样本(例如古文字去噪训练集)完成对去噪网络的训练,进而达到更加理想的去噪效果。文中对本研究提出的MTDNet进行了有效性实验验证。实验结果表明,在SIDD测试集上,MTDNet相较于基线模型UNet,其评价指标PSNR提升2.55,SSIM提升0.09,并且性能优于Dn CNN等其他去噪模型;在甲骨文测试集上,去噪效果仍明显优于其他去噪模型,相较于基线模型UNet,评价指标PSNR与SSIM分别提升3.15和0.16。此外,本文对MTDNet内部添加或修改的各模块进行了消融实验,证明了各模块对去噪任务的有效性。同样,文中对于本研究提出的MMTDNet也进行了有效性实验验证。实验结果表明,在SIDD测试集上,MMTDNet相较于MTDNet,其评价指标PSNR再次提升2.35,SSIM提升0.05;在甲骨文测试集上,MMTDNet相较于MTDNet,评价指标PSNR与SSIM分別进一步提升2.76与0.04。此外,本文对于元学习的泛化性也进行了有效性实验验证。实验表明,与迁移学习和普通的监督学习相比,元学习的泛化性也更占优。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.001287
{DOI}: 10.27162/d.cnki.gjlin.2023.001287
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的单目深度估计研究
{Author}: 赵嘉琪
{Tertiary Author}: 张旺
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 单目深度估计;深度学习;注意力机制;位姿估计;图像重构
{Abstract}: 深度信息对于智能系统感知外部环境和估计自身状态具有重要的应用价值和研究意义。多个3D场景可以投影到相同的2D场景,因此从一幅RGB图像中推断深度信息是一个不适定的问题。传统的深度估计方法,立体匹配(Stereo Matching)和运动恢复结构(Structure from Motion,Sf M),都是建立在多视图几何理论的基础上,同时预测的深度图是稀疏的,无法实现稠密的深度预测,难以应用于无人导航系统、机器人技术等领域中。随着深度神经网络研究的深入,基于深度学习的方法取得了诸多研究成果。深度神经网络可以精准而实时的实现像素级稠密深度预测,辅助提高自动导航的精度。在现有的单目深度估计方法中,存在着深度估计精度不高、物体边界轮廓不清晰、深度估计模型泛化能力差等问题,限制了单目深度估计领域的实体普及化发展。本文研究了基于深度学习的单目深度估计方法的基本理论,提出了分别基于有监督学习理论和自监督学习理论的单目深度估计算法。论文的主要研究内容如下:(1)研究了单目深度估计算法的理论基础。首先介绍了相机的成像模型、成像原理和成像过程中的坐标变换,然后介绍了单目测距的基本方法和相机运动过程中位姿的求解方法。最后从深度学习算法出发,阐述了卷积神经网络(Convolutional Neural Network,CNN)中的卷积,池化,非线性化以及全连接过程。(2)研究了基于有监督理论的单目深度估计算法模型,设计了基于注意力细化金字塔的编码器-解码器结构网络框架。针对卷积操作只作用于局部作用域的局限性,提出了分块跨尺度注意力机制。通过设置合适大小的图像块,将每个尺度下的特征图像拆分为相同大小的图像块,并在全局作用域上对浅层特征和深层特征进行融合。然后,反向拆分操作将经过融合的特征进行还原。针对深度预测结果中缺乏深度细节的问题,提出了金字塔细化模块。还原后的特征和来自较高尺度的经过细化的特征图通过在线细化模块处理,通过融合相应空间位置的特征,以金字塔形式由粗到细的对特征进行细化。(3)研究了基于自监督理论的单目深度估计算法模型,设计了基于尺度聚合和深度重建的类U-Net网络框架。考虑到该结构的特征提取能力较差,在跳跃连接部分嵌入了多尺度特征融合模块。通过添加中间节点,聚合相邻尺度的语义信息和空间信息。针对现有的位姿估计方法存在位姿预测不准确的问题,提出了残差位姿估计网络和深度重建损失用于网络训练。以迭代的方式提取图像序列间的运动信息,并根据迭代的位姿进行图像重建。同时,针对训练过程中影响模型收敛性的异常像素提取问题,提出了阈值分割掩码。通过设置阈值参数,去除运动像素和低纹理区域的像素。本文研究的单目深度估计算法可以实时获取单目图像序列的深度和位姿信息,并以此对单目场景进行三维重建。两种算法模型均在一定程度上丰富了深度图中的语义信息和空间信息,细化了深度图中的物体边界,提高了深度图的质量。在KITTI和NYU Depth V2数据集上的实验和可视化分析结果表明,本文的算法在阈值精度和绝对性相对误差等指标中表现突出,并且保证了算法的运行速度,在室外车辆驾驶场景和室内环境均可以实现高精度的深度预测和准确的位姿预测。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.006780
{DOI}: 10.27162/d.cnki.gjlin.2023.006780
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自动驾驶复杂场景下目标检测研究
{Author}: 宁俊彦
{Tertiary Author}: 王建国
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自动驾驶;复杂场景;深度学习;YOLO;可变形卷积网络
{Abstract}: 近年来,汽车数量增加导致的交通问题层出不穷,由此引发的自动驾驶研究已被国内外众多企业提上日程。随着深度学习的发展,一般简易交通场景下的目标检测精度已可达驾驶标准,但面对复杂场景下的目标检测,道路中存在遮挡目标和小目标检测,通过传统算法无法获取更高精度的检测。因此,本文采用了深度学习为基础的目标检测技术,分析自动驾驶复杂场景下目标检测的重难点,进而研究适用于复杂场景下的目标检测算法。具体的研究工作如下:1)通过对比实验,分析了典型目标检测算法,选择算法改进对象。首先基于当前目标检测中常用的基于深度学习的目标检测技术,通过实验研究和分析了三类经典目标检测算法,分别为Faster Regions with CNN features(Faster R-CNN)、Single Shot Multi Box Detector(SSD)和You Only Look Once Version Five(YOLOv5)。实验结果显示,不论是检测精度还是检测速率上,YOLOv5算法皆优于其它两者,因此本文以YOLOv5为基础框架对复杂场景下的目标检测算法进行研究和改进。2)提出了一种改进的聚类算法。本文改进了传统K-means聚类算法以生成更适合自动驾驶复杂场景下的锚框。改进后的K-means算法解决了原本K-means算法中初始聚类点选取随机而导致的最终结果与最准确聚类相差较大问题,缓解了传统聚类算法的局部最优的问题。改进后的K-means算法所生成的锚框可获得更好的泛化能力,针对本文可适用于复杂场景下的目标检测。3)重构了一种更倾向于对正样本和难分类样本的损失函数模型。在One-Stage类型算法中,由于未采用FPN网络对目标进行粗筛,因此在目标检测中会面临正负样本不均衡问题,而复杂场景下的小目标数量上升进一步加剧了该问题。由此本文将损失函数中的分类损失和置信度损失中引入焦点损失(Focal Loss),针对不易识别样本进行加权学习,以此缓解小目标检测精度不足问题。同时,采用CIOU loss作为边界框回归损失以达到预测框与真实框更为准确的差距,从而缓解复杂场景下同一区域目标密集而导致的遮挡目标漏检问题。同时,本文将CIOU引入NMS算法中,用以准确识别密集区域目标边界框。4)重构了一种目标检测网络模型,提出了一种面向自动驾驶复杂场景的目标检测算法。本文提出的面向自动驾驶复杂场景的目标检测算法,用于解决YOLOv5算法在复杂场景下遮挡目标漏检率较高问题。本文首先在神经网络结构上,在backbone主干网络中引入DCN(Deformable Convolutional Networks)网络,其次,采用CIOU Loss作为本文算法的回归损失函数中的边界框回归损失,用以解决遮挡目标预测框与真实框定位差距较大问题。对比实验结果表明,本文提出的复杂场景下的目标检测算法在保证实时性的情况下在复杂数据集COCO和KITTI上检测精度提升了2.9%。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000562
{DOI}: 10.27391/d.cnki.gxagu.2023.000562
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的盲人出行辅助装置的设计与实现
{Author}: 朱凯东
{Tertiary Author}: 方刚
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;盲人出行;目标检测;目标跟踪;边缘计算设备
{Abstract}: 盲人因为视觉障碍,导致日常出行非常不便,如何更好的帮助盲人出行成为了社会关注的焦点。目前市面上针对盲人出行推出的产品主要有导盲仗、手持式导盲仪、穿戴式导盲设备和导盲机器人等,这些产品虽然能够实现一定的辅助作用,但其反馈装置大多数是语音或者振动的形式,盲人只能被动的听从提示,由于产品技术尚未成熟及高昂的成本,导致这些产品无法在市面上流行起来。针对这一问题,本文提出一种基于计算机视觉的盲人出行辅助装置,该装置可以将盲道形状分割出来并通过舵机旋转的方式将盲道形状信息传达给盲人,同时基于轻量化目标检测算法和目标跟踪技术,实现避障和跟随功能。本文主要工作如下:(1)本文针对传统图像处理方法分割速度慢的问题,提出采用感兴趣区域的方式,将原始输入进行裁剪,降低计算量。对于传统滤波在盲道分割算法中降噪效果不好和去阴影问题,引入均值漂移滤波方法,并根据灰度分布直方图提出一种图片去阴影策略。改进后的盲道分割方法速度提升4倍,分割精度和去阴影的视觉效果都明显提升。(2)对于检测模型,本文将YOLOv8-Nano的Neck特征融合部分,分别进行剪枝处理、对C2f模块引入PConv,相较于YOLOv8-Nano原始模型,在平均精度损失小于1%的情况下,速度分别提升1.5%、3.4%。此外,本文还对跟踪模型进行简化,并引入ELAN和基于ELAN改进的P-ELAN进行对比实验,相对于ResNet18特征提取网络,在测试集上准确率浮动1%的情况下,训练时间分别减少30%、33%,模型复杂度分别降低74.5%、82.8%,模型参数量降低78.0%、89.5%,推理速度提升81.2%、96.2%。(3)本文基于Jetson Nano边缘计算平台和Arduino单片机设计了一款可穿戴式盲人出行辅助装置。该装置能够将盲道分割结果通过点阵判断盲道形状并利用舵机旋转将盲道信息传达给盲人,同时加入目标检测和目标跟踪算法模型,实现了盲道再现、障碍物检测和人员跟随功能。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.002151
{DOI}: 10.27040/d.cnki.ggzdu.2023.002151
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Vision Transformer的图像分类算法研究
{Author}: 朱哲峰
{Tertiary Author}: 綦科
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像识别;Vision Transformer;多尺度特征融合;高效自注意力;局部增强
{Abstract}: 图像分类任务的本质是根据图像的语义信息对不同类别图像进行区分,是计算机视觉的核心,是目标检测、图像分割等其他高层次视觉任务的基础。近几年基于自注意力机制的Transformer模型相比于卷积神经网络表现出不俗的竞争力,但现有的Vision Transformer模型在图像分类任务上的应用仍有不足之处。因此,为了进一步提升Vision Transformer在图像分类中的性能,本文主要进行了以下两方面的研究:本文基于Vision Transformer提出了一种多尺度特征融合的图像识别框架FFT(Feature Fusion Transformer)。在最初的Vision Transformer模型中,模型并未充分利用单个图像块的内部结构信息,导致模型难以学习到高分辨率图像的局部细节特征。为了弥补这一不足,本文抽取了卷积神经网络中不同卷积层所输出的特征图,并设计了FFT Block将相同感受野下不同特征层的嵌入向量进行合并,成功融合了不同尺度下的图像特征信息。相关实验表明,该框架能关注到图像中更加细致微小的特征,为图像识别提供了更加丰富的特征信息,有效提升了图像识别的准确率,在Tiny Image Net、Cifar10和Cifar100这三个数据集上的Top-1准确率相较于基线模型分别有6.5%、3.7%、7.8%的提升。本文提出了一种优化计算复杂度的ESA(Efficient Self-attention)模块和用于局部增强的LE(Locally Enhanced)模块。由于Vision Transformer模型内部的点积注意力计算量过于庞大,极大的减慢了模型的推理速度,这种高额的计算量和时间复杂度成为了模型发展的瓶颈。为了优化Vision Transformer的计算复杂度,本文设计的ESA模块通过对Class Token与Patch Token的注意力强度进行排序,只计算注意力强度较高的Token,并添加了注意力矩阵跨层复用的设计,以进一步减少模型计算量。本文还加入了并行卷积LE模块,卷积计算能捕获局部信息,结合自注意力捕获的全局信息,为图像识别提供更加丰富的特征信息。相关实验表明,在Tiny Image Net数据集上,ESA模块和LE模块相结合后相较于基线模型的Top-1准确率有1.2%的提升,并在推理速度上有19%的提升。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.001486
{DOI}: 10.27040/d.cnki.ggzdu.2023.001486
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 红外与可见光图像融合算法研究及应用
{Author}: 庞忠祥
{Tertiary Author}: 刘桂华
{Publisher}: 西南科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像融合;图像增强;深度学习;迁移学习;目标检测
{Abstract}: 红外图像受环境干扰小,满足全天候工作需要,然而其通常呈现出低对比度,细节纹理不丰富的缺点。可见光图像在低光照、烟尘、雾霾等环境下难以展现热目标信息。因此,将红外与可见光图像进行融合,生成既有显著性目标和高分辨率纹理细节的融合图像,能为后续视觉任务提供更丰富的语义信息。考虑可见光图像能提供相对丰富的背景特征,而低质量红外图像难以准确描述热目标的细节纹理,对后续的融合会产生较差的结果。针对上述问题,本文围绕红外与可见光图像融合展开以下研究:针对低质量红外图像存在细节模糊、低对比度等问题,本文提出了一种用于红外图像增强的并行多特征提取网络,以提高红外图像表达,丰富细节纹理,从而促进融合图像质量提升。该模型主要包括结构特征映射网络和双尺度特征提取网络,分别用于建立全局结构特征权重和生成目标增强映射。实验验证,本文方法在BSD200和真实红外图像上取得了最佳效果,PSNR与SSIM分别为35.42d B、35.72d B和0.95、0.96,且对不同对比度因子的低质量图像,本文方法也具有良好的增强效果。目前多数红外与可见光图像融合算法在融合过程中通常需要对源图像进行分解,这样易导致融合图像细节模糊和显著性目标丢失。为解决该问题,本文提出了一种基于深度卷积特征提取的图像融合算法。该算法直接对源图像进行特征提取,生成七组融合权重,采用像素最大值策略实现异源图像融合。所有实验均在公共数据集上进行,主、客观实验结果均表明,本文方法能有效地融合红外与可见光图像中的重要信息,突显融合图像的细节纹理。在EN和CC指标上,本文算法较Dense Fuse分别提升了3.31%和3.33%。本文进一步验证了红外图像增强操作对融合任务具有积极的促进作用,同时融合图像具备更好的显著性检测效果和深度估计结果。此外,本文还验证了红外与RGB图像融合的实验效果。最后本文将融合图像应用于目标检测任务,在M3FD数据集上使用YOLO-v7检测算法对可见光图像、红外图像及融合图像进行目标检测。综合“傍晚”、“夜间”、“烟雾”等场景实验结果,验证了融合图像具有更好的适用性,其中灰度融合图像的m AP达75.77%,相比于可见光和红外,分别提升了4.58%和14.51%;RGB融合图像的m AP为79.19%,较可见光和红外分别提升了9.30%和19.68%。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2023.000049
{DOI}: 10.27415/d.cnki.gxngc.2023.000049
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于交通视频的多目标检测和跟踪算法研究
{Author}: 樊新川
{Tertiary Author}: 陈春梅;姜赞成
{Publisher}: 西南科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 车辆检测与跟踪;YOLO;MobileNetv3;FairMot;ByteTrack
{Abstract}: 随着底层硬件的蓬勃发展,计算机性能不断提升,这为基于大数据拟合的人工智能算法提供了强劲动力。这些算法已经被广泛应用于社会的各个领域,如智能机器设备,从而提高了人们生活和工作的效率。对于我国复杂庞大的交通系统,智慧交通管理系统虽然得到一定的发展,但是仍然存在视频信息获取效率低、速度慢、人工参与度高等不足。因此,在交通管理系统中应用更高效、准确、快速和低成本的人工智能算法,实现系统智能化,这对社会发展具有十分重大的意义。人工智能算法中针对视频的多目标检测和跟踪算法是智能交通系统中重要的一环,可以实现交通场景中目标的定位、识别和跟踪。尽管基于深度学习的多目标检测算法和多目标跟踪算法已经受到学术界广泛的关注,但是目前的研究成果还存在算法开销高昂以及目标相互遮挡和目标消失后重新识别困难等问题,这些问题制约了相关研究的推广应用。针对这些问题,本文提出了两个解决方案:第一,提出基于YOLO框架的轻量化高精度车辆目标检测算法,保障了车辆检测的精度并大幅降低算法开销。第二,提出基于Fair Mot框架的车辆多目标跟踪算法,很好地解决了目标遮挡和目标消失后的重识别问题。上述两方案能部署于低成本的小型计算机设备,更高效快速处理交通视频。针对方案一,本文设计了基于YOLO框架,以Mobile Netv3网络为主干网络,并对下采样和通道注意力机制进行了改进,以精准地提取目标特征并降低不必要的开销。此外,本文还设计了特征金字塔和单阶段无头融合的结构,能够充分利用纵横多尺度信息增强算法对多尺度目标进行检测。最后采用了SIOU作为回归损失和SoftNMS进行冗余框处理,提高了算法的精度。经过设计和改进,本文提出的算法在MS COCO数据集和UA-DETRAC交通监控数据集上得到了显著的实验效果,即模型的参数量和计算量大幅降低了64.98%和57.14%。同时,在MS COCO数据集上,保障了m AP@0.5为58.6%的高精度;在UA-DETRAC交通数据集上,提高了m AP@0.5的指标,达到了70.5%的准确率,相较于原算法提升了3.52%,FPS也提升了14.4%。可见,本文提出的方案一解决了算法高开销低精度的问题。针对方案二,本文基于FairMot框架结合上述方案一,创新地提出了一种多任务检测网络。该检测网络采用可形变卷积融合网络多尺度信息,从而形成重识别任务分支。并在跟踪部分引入了Byte Track中的低置信度再匹配策略来降低算法开销和提高跟踪精度。在UA-DETRAC交通监控数据集上进行实验,结果表明:与原Fair MotDLA34相比,本文提出的改进算法在参数量方面下降了43.05%,FPS提升了10.28%,MOTA提升了0.57%,IDs提升了7.93%。综上,本方案更充分地利用了卷积神经网络从交通监控视频中提取到的特征,以此提高了算法的可靠性和稳定性。本文算法部署在NVIDIA AXIVAR SERIES嵌入式平台上,完成了算法应用验证实验。在UA-DETRAC和自制交通监控场数据集上,未作任何加速的情况下,本文目标检测算法的速度达到15fps,多目标跟踪算法的速度达到3.67fps(相比于Fair Mot提升了55.5%)。这对智慧交通的检测任务和车辆流向判断等任务具有一定的现实意义和应用价值。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2023.000938
{DOI}: 10.27415/d.cnki.gxngc.2023.000938
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视频监控多目标检测和追踪算法研究与应用
{Author}: 李智
{Tertiary Author}: 钟宝荣
{Publisher}: 长江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;多目标跟踪;YOLOX;ByteTrack
{Abstract}: 基于深度学习的多目标检测和追踪算法是一种利用卷积网络实现目标检测和跟踪的技术。在视频监控领域,这种算法可以帮助智能监控系统更加准确地识别和跟踪目标,提高监控效率和准确率。同时它可以广泛应用于交通安全、城市管理、公共安全等领域。本文主要以室内场景的行人多目标检测和追踪为背景,针对当前多目标检测算法和追踪算法存在的因目标遮挡和错位导致漏检和ID切换以及目标检测和追踪速度较慢、精度不足等问题,通过对YOLOX的目标检测算法的网络结构进行改进并融合注意力机制,将改进后的目标检测算法称为YOLOX-P目标检测算法,并且基于该算法结合ByteTrack目标跟踪器设计一个针对室内行人目标检测场景的行人多目标检测和跟踪算法。本文主要的工作内容如下:(1)将基于深度学习目标检测和跟踪算法进行分析并做了整体性的综述和分类,对于其中较为著名的一阶段目标检测算法YOLO系列算法进行了详细的介绍和说明,然后分析了在视频监控场景下对行人的目标检测和跟踪的常见的问题,包括目标的尺寸变换较大、远距离监控目标较小以及由于目标的遮挡和错位等情况所导致的目标漏检、误检等问题。(2)针对以上提到的问题以最新的YOLOX系列算法为基础,分别从网络结构、损失函数等方面提出了一系列的改进措施,包括引入注意力机制,在骨干网络输出后加入CBAM融合注意力模块,替换FPN为BiFPN,增加对输入图像的特征提取能力,改进损失函数,使用DIoU Loss和Focal Loss来提升网络精度,并将改进后的网络命名为YOLOX-P。在人群监控数据集基础上,筛选1000多张真实监控图像,进行数据集的搭建和标签的制作,并且将改进后的YOLOX-P网络在该数据集上进行消融实验并同原网络模型进行对比,验证改进网络的有效性。(3)将改进后的YOLOX-P目标检测算法结合最新的目标跟踪算法ByteTrack在MOT17数据集上进行训练,通过与其他检测器的对比实验,验证在视频监控领域改进的YOLOX-P结合ByteTrack算法的有效性。
{URL}: https://link.cnki.net/doi/10.26981/d.cnki.gjhsc.2023.000346
{DOI}: 10.26981/d.cnki.gjhsc.2023.000346
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的智能仓储管理系统研究
{Author}: 吴奕飞
{Tertiary Author}: 张桦
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智能仓储管理系统;织物缺陷分类;火情目标检测;深度学习
{Abstract}: 随着计算机视觉技术在工业领域的广泛使用,仓储管理已经成为重要的应用领域。智能仓储的核心技术之一就是基于人工智能的计算机视觉算法,这些算法的应用能够有效地保障仓储货品质量和仓库安全。通过收集仓储作业过程中产生的视觉信息,进行智能处理与分析,能够有效提高人工操作的效率和正确率。纤纺类应急救灾物资是应急救灾物资的重要组成部分,其目前储备的仓库管理普遍使用人工检查和视频监控的方式完成运行维护工作,低效率的同时带来较高的人力成本。近年来,基于深度学习的目标识别算法快速发展,为实现纺织品智能仓储的产品缺陷检测和火情检测提供技术保障。因此,通过研究基于深度学习的目标检测算法,构建纺织品智能仓储管理系统,实现质量问题和安全问题的自动检测对智能仓储管理降低成本、增加工作效率具有重大意义。本文选取织物出库缺陷检测和仓储火情检测的问题开展基于深度学习的智能仓储管理系统研究,通过计算机视觉技术解决质量管理和安全管理的自动化需求。本文主要工作如下:(1)提出了一种基于YOLOF的织物缺陷检测方法,用于检测复杂背景下的织物缺陷目标。该方法通过单级特征检测替代YOLO中多尺度特征融合架构,大幅提高了检测效率,可以更好地适用于工业环境下的实际操作情况。通过YOLOF网络与其他方法对比,实验结果表明所选取的方法在织物缺陷分类具有更高的平均精度均值,能够有效提高缺陷检测正确率。(2)提出了一种基于Mobile Netv2的仓储火情检测方法,用于实现更精准的仓库内火焰目标检测。该方法通过Mobile Netv2模块对YOLOv3网络进行改进,在减少网络计算量的同时保证了较低的信息损耗。改进后的YOLOv3和其他模型进行对比,实验结果表明搭载了Mobile Netv2模块的YOLOv3网络能有效提升检测的平均准确率和查准率,有效提升了发现火灾的能力,降低了仓储发生火灾的风险,同时降低了火灾误报率。(3)进行了基于深度学习的智能仓储管理系统研究,包括出入库管理、智能作业、安控管理等功能。将基于YOLOF的织物缺陷检测、基于Mobile Netv2的仓储火情检测算法部署在智能仓储管理系统中进行实际应用,验证本文算法在实际仓储作业流程中的可行性,实现更高效的仓储作业,并有效解决安全问题。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2023.000980
{DOI}: 10.27075/d.cnki.ghzdc.2023.000980
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的茶叶嫩芽识别定位研究与系统开发
{Author}: 张奋云
{Tertiary Author}: 陈丰农
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;茶叶茶芽;识别定位
{Abstract}: 茶叶具有很高的经济价值。在茶叶生产过程中,茶芽采摘环节至关重要,采摘的茶芽质量将直接影响后续成品茶的品质。对茶叶嫩芽进行快速识别与定位,对于实现茶芽的智能化采摘具有重要意义。本研究基于计算机视觉技术对茶芽进行了分割识别,二维定位以及三维定位的研究,并在此基础上开发了相应的系统,为后续实现茶叶的智能化采摘提供前期基础。论文的主要研究内容和结论如下:(1)建立高效的茶叶嫩芽的分割识别模型。该方法采用了改进的轻量级Deep Lab V3+模型,使用Mobile Net V2网络作为特征提取网络,融合多注意力机制,并采用Focal Loss损失函数进行类别不平衡修正。通过消融实验与分割模型对比试验,该模型的m Io U达到88.02%,m PA达93.17%,FPS达到59.01,模型的分割精度与速度均有提升,不但有效去除背景干扰,还能够对茶芽图像中的背景与茶芽进行识别与分割。(2)建立茶叶嫩芽的二维定位模型。基于YOLOv7算法构建茶芽二维定位模型。在模型训练前,先得到去除背景干扰的茶芽分割数据集。选用多个YOLO系列模型分别对茶芽进行训练。实验结果表明YOLOv7的模型效果最好,m AP达到94%,能够满足茶芽定位需求,最后在YOLOv7模型基础上进行采摘点计算,得到茶芽采摘点二维坐标。(3)基于RAFT算法构建茶芽三维定位模型。通过茶芽二维定位预测模型获取茶芽的二维像素坐标;再将茶芽双目图像进行双目立体校正,后通过RAFT立体匹配算法计算茶芽双目图像的深度信息,最后通过坐标系转换得到茶芽三维世界坐标,构建茶芽三维定位模型。通过对比RAFT与SGBM立体匹配算法,利用两个单目相机搭建的双目系统得到茶芽采摘点的三维坐标,证明三维定位方法的可行性。(4)茶芽识别定位系统开发。从茶芽智能化采摘的实际需求出发,设计了基于Pyqt5的茶叶嫩芽识别定位系统,实现了茶芽分割识别,二维定位和三维定位功能。最后对系统识别定位的精度与速度进行测试验证,结果表明,茶芽分割准确率为86.60%,茶芽最终定位准确率可达84.85%,茶芽识别速度可达32.5ms/个,二维定位速度可达39.1ms/个,三维定位速度可达129.2ms/个,基本满足茶芽识别定位要求。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2023.000565
{DOI}: 10.27075/d.cnki.ghzdc.2023.000565
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的道路缺陷检测与识别系统设计
{Author}: 李稳稳
{Tertiary Author}: 张平均
{Publisher}: 福建工程学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 道路缺陷检测;图像处理;深度学习;YOLOv5s
{Abstract}: 随着我国交通运输业的迅速发展,公路里程数不断攀升,道路安全运行要求越来越高,基于道路检查与养护的需求与日俱增。目前道路缺陷状况调查与评估大多采用人工检查和半自动化检测方式,该方式存在效率低、危险系数高且检测标准易受人为主观性影响等问题。本文设计了一套基于机器视觉的道路缺陷检测与识别系统,该系统可以获取道路缺陷的类别、特征参数与定位信息,这些信息可以方便工作人员后期对道路进行科学化养护提供数据支撑。首先,道路裂缝与坑洼缺陷是最主要的两类道路病害,目前研究道路缺陷检测无适用公开图像数据集,根据图像采集的标准原则、来源与预处理完成图像数据集的构建。对道路缺陷分类识别算法进行了研究,选择经典的VGG16、Res Net50与MobileNetV3网络模型,通过实验仿真对比分析三种网络模型对道路缺陷图像分类识别的性能影响,结果表明Mobile Net V3网络模型具有分类精度高与参数量小的优点,满足道路缺陷分类识别需求。其次,对道路坑洼缺陷的参数提取进行了研究。针对特征明显只含有坑洼缺陷的图像,采用灰度化、OSTU自适应二值化、形态学处理与边缘轮廓提取得到量化后坑洼目标区域的参数信息,进一步实现对坑洼损坏度的等级划分,通过坑洼缺陷检测,验证了该方法的有效性。再次,对道路裂缝缺陷的参数提取进行了研究。针对只含有裂缝缺陷的图像,提出一种改进的YOLOv5s目标检测算法,命名为YOLOv5s-DA,通过在原网络模型结构Backbone区域中引入SCConv模块有助于提升原模型的主干网络特征信息提取能力,同时在原网络模型结构Neck区域中引入SE-Net模块有助于提升原模型的高层特征信息提取能力,实验结果表明:改进的目标检测算法具有检测精度高且检测效果好的优点;采用改进后的YOLOv5s-DA目标检测算法,获取量化后裂缝目标区域的外围边界框参数信息,进一步实现对裂缝缺陷损坏度的等级划分,通过裂缝缺陷检测,验证了该方法的有效性。最后,对车载道路缺陷检测系统进行设计。该系统可以实现道路图像采集、分类识别、参数提取、4G通信、位置定位与地图显示功能,使用Qt界面完成系统检测与识别结果以及定位地图可视化展示。车载道路缺陷系统测试结果表明:该系统可以检测与识别出坑洼与裂缝缺陷类别,并完成缺陷类型的参数提取与等级划分。
{URL}: https://link.cnki.net/doi/10.27865/d.cnki.gfgxy.2023.000250
{DOI}: 10.27865/d.cnki.gfgxy.2023.000250
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于ViT的图像分类算法研究
{Author}: 黄谟昊
{Tertiary Author}: 黄梦醒
{Publisher}: 海南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像识别;图像分类;视觉Transformer;迁移学习;数据增强
{Abstract}: 随着深度学习技术的发展,基于卷积神经网络的图像分类技术已经趋于成熟,由自然语言处理领域引入的Transformer网络为计算机视觉领域的发展提供了新的技术路线。为了尽量保留原始Transformer模型特点而引入的Vision Transformer模型,其结构在处理图像信息的方法具有一定的缺陷,如其简单粗暴的图像分块方法会丢失部分图像信息,不利于图像特征的学习。本文深入学习深度学习技术,结合卷积神经网络基础对ViT网络进行分析,并基于该网络作图像分类研究。主要工作如下:1.通过不同网络模型的选择及对比实验,分析迁移学习方法对训练效果的不同影响。基于卷积神经网络和Transformer类网络设计了一系列对比实验,并在Image Net子集花分类数据集和Food-101数据集上进行训练。每个网络均使用在Image Net上的预训练权重,分析不同分类任务中不同网络的分类效果,并比对不使用预训练权重时各网络的训练效果,实验表明迁移学习的方法对训练效果的提升很大。2.基于数据增强的方法研究在噪声干扰条件下和扩充数据集的条件下网络的训练效果变化。通过引入随机噪点和扰动对原始花分类数据集进行数据增强处理,并基于卷积神经网络和Transformer类网络在新数据集上进行训练分析。实验表明Transformer类网络对局部噪声的扰动具有更强的鲁棒性,自注意力机制计算方法对比卷积计算方法更具优势,而ViT的图像分块操作不利于复杂图像特征的提取。3.设计了一种改进的HFE-ViT网络模型,给出基于该网络模型的图像分类算法,并在flower Aug数据集、Food-101数据集上进行训练和仿真实验。该网络模型中,其层级特征提取结构替换ViT的图像分块操作,并且仿真实验说明层级特征提取结构提升了ViT的训练效果,训练准确率和测试准确率都得到提升。
{URL}: https://link.cnki.net/doi/10.27073/d.cnki.ghadu.2023.000249
{DOI}: 10.27073/d.cnki.ghadu.2023.000249
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的晶圆表面缺陷检测系统研究
{Author}: 曹芸玉
{Tertiary Author}: 王丽君
{Publisher}: 华北水利水电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 晶圆;AOI系统;缺陷检测;机器视觉
{Abstract}: 晶圆制造是半导体产业链的上游核心环节,对半导体产业的发展起着重要的支撑作用。为了减少不合格晶圆继续加工带来的成本负担,提高集成电路等产业的产品性能,对晶圆表面进行快速高效的缺陷检测以提高晶圆出厂良率非常必要。基于视觉的晶圆表面缺陷检测技术近年来在半导体的缺陷检测中引起了广泛重视,并在相关领域取得不少成果。然而基于深度学习的晶圆表面缺陷检测方法在算法模型和实际工程应用中仍有较大的研究空间。本文以搭建晶圆表面缺陷检测AOI系统的检测平台为基础,对晶圆表面缺陷检测算法进行改进和研究,结合实际工程项目中的检测难点,着重进行算法模型改进以提高系统缺陷检测的速度和精度。本文的主要研究内容在于首先分析检测算法的理论基础和检测机制,比对不同模型的结构差异,并结合同一个数据集下各模型的检测效果分析模型性能,为后续模型改进提供思路;然后分析来自实际项目的缺陷确定晶圆缺陷的成因和类型,根据不同视觉方案下的缺陷成像效果搭建系统的机器视觉系统以便在检测过程中获取高质量样本;分析晶圆AOI系统的常规检测流程并搭建检测系统的机械结构模型;针对现有模型存在的体积过大不易部署、对晶圆表面缺陷的整体检测精度不高等问题进行算法改进,通过对骨干网络进行轻量化、采用高效的特征融合机制、给特征添加注意力等方式完成算法改进;最后为了验证算法的有效性建立样本数据集,通过样本扩充避免由数据集过小引起的过拟合现象,另外为了便于操作设计了基于Py Qt5的人机交互界面。本文工作丰富了晶圆表面缺陷视觉检测中的检测方法,主要成果和创新如下:(1)通过对现有目标检测算法的性能对比,分析模型检测性能不佳的可能原因,为模型改进提供思路。对基于区域选择的双阶段目标检测算法和基于回归的单阶段目标检测算法进行详细分析,在同一个数据集VOC-2007上进行模型训练与测试,综合比对模型的检测精度与速度,实验表明YOLOv5网络模型具有更好的表现性能,因此选取YOLOv5网络作为本文算法改进的基本结构。(2)为了获得更高质量的检测样本,进行晶圆检测平台的搭建。分析晶圆生产工艺流程,对常见的晶圆表面缺陷进行分类;综合考虑四类晶圆表面缺陷在不同光源条件下的成像情况、晶圆尺寸和成本等因素,完成视觉方案设计和对光源、相机和镜头等的选型;根据晶圆表面缺陷视觉检测过程的工艺需求,完成包括Z轴模组、上料三轴和U轴承片台等机械结构设计,搭建完整的检测平台模型。(3)为了提高模型对晶圆表面缺陷的检测精度和速度,基于当前深度学习在目标检测领域取得的一系列成果,提出针对晶圆表面缺陷特征的算法改进。首先针对模型体积过大导致现场部署困难和检测速度低等问题提出对模型骨干网络的轻量化处理,改进后模型的参数量降低30%;其次针对模型对小目标检测精度不佳的问题提出一种高效的特征融合机制,在不增加参数的前提下实现更多特征的融合,提升了小目标的表达;最后向模型中添加注意力机制,从空间维度和通道维度分别赋予特征不同权重以提高模型对待检测目标的关注度。上述改进使得模型参数量降为原来的90%,计算量减少9.4%,推理速度约有23%的提升,检测精度为92.3%,对四种缺陷的检测性能均有较好表现,整体有9.8%的提升。(4)数据集建立和GUI界面设计。通过数据增强和数据平衡等方式对现有晶圆数据样本进行扩充,最终获得总数据量为7510的数据集,有效解决因数据量过小导致的过拟合问题,同时降低了样本不均衡对模型精度的影响。另外基于Py Qt5完成包括登录注册、模型训练及结果查询等功能的人机交互界面设计。综上所述,本文以晶圆生产制造过程中对其表面进行缺陷视觉检测的实际需求为导向搭建视觉检测系统,提出了用于晶圆表面缺陷检测的方法并验证其有效性,具有一定的理论价值和工程意义。
{URL}: https://link.cnki.net/doi/10.27144/d.cnki.ghbsc.2023.000297
{DOI}: 10.27144/d.cnki.ghbsc.2023.000297
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的小型零件尺寸测量系统
{Author}: 李小菁
{Author Address}: 广东省计量科学研究院;
{Journal}: 自动化与信息工程
{Year}: 2023
{Volume}: 44
{Issue}: 02
{Pages}: 11-15
{Keywords}: 机器视觉;图像处理;尺寸测量;小型零件
{Abstract}: 针对目前大多数小型零件尺寸测量采用人工方式存在效率低、精度差的问题，设计一套基于机器视觉的小型零件尺寸测量系统。该测量系统的硬件部分由工业相机、远心镜头和背光光源等组成；测量软件实现小型零件图像平滑滤波、自适应阈值二值化、感兴趣区域自动提取、亚像素边缘特征提取和最小二乘法曲线拟合等功能。通过对短U弯制小型零件进行测量实验，验证了该测量系统可实现小型零件多个几何量参数的一键快速测量，最大误差为0.021 mm，测量精度可达0.02 mm。
{ISBN/ISSN}: 1674-2605
{Notes}: 44-1632/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz_vMUuPGGePXmgF1683YvPzvtA1lltGF-ssmqVcRW6GuGugzf2PXaILX3ITdF7ZGfblirHxFQWcxzBP6XcY_zg8MZvwjheXmI8HmWIQunHKbt5RElBFlIdtNr4P3PzEJiJu3J0pIrESAp2dpGWIp1X28PY_OMRqSUgP6BDtoZW3QpC16f_ci2F9ta4fStsNvE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在智能化农业机械中的应用研究
{Author}: 王莎莎
{Author Address}: 黑龙江工商学院;
{Journal}: 南方农机
{Year}: 2023
{Volume}: 54
{Issue}: 10
{Pages}: 47-49
{Keywords}: 计算机视觉技术;智能化;自动化;农业机械
{Abstract}: 计算机视觉技术是当前各领域普遍应用的一项现代化技术，其应用前景比较广阔。随着农业机械逐渐走向智能化和自动化，计算机视觉技术应用于智能化农业机械之中已经成为一种趋势，对农业机械自动化、智能化生产的实现发挥重要作用。为了研究计算机视觉技术在智能化农业机械中的科学应用，笔者首先对计算机视觉技术进行简要介绍；其次，分析了智能化农业机械所包含的主要技术类型，即绿色维修、人机协同以及机械自动化；最后，探讨智能化农业机械中计算机视觉技术的具体运用，将计算机视觉技术应用于田间作业机械、农作物收获机械以及农产品加工机械等机械之中，可产生较高的经济效益和环境效益。研究结果表明，在智能化农业机械中合理运用计算机视觉技术，可以进一步提升农业机械的精准度和自动化水平，对提升智能化农业机械的整体质量以及作业效率发挥着重要作用；科学运用计算机视觉技术，将极大地降低农业机械对生态环境的影响，满足绿色农业的发展需求，促进农业产业现代化。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyKHBFmQoeGI5qXcerDNI18rbcN6-X5pyOH7uI6LdsGfVVs2NZL1_bLykpPPuHUGIRo5eBtEz4RzApgA4gvOk6YIbQYDH_367Tk4eO-s9fl0B1NY6UEkLdgFH0rkikOhz0duftfp6JEfzVm2WOT1-A-62nGJDJdyH9OeIinawAJJ-t4XF0IzgUH0TDMU4GtGJw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的动物目标识别与跟踪方法研究
{Author}: 孔令昀
{Tertiary Author}: 卢光辉
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 动物目标检测;动物目标跟踪;目标检测评价方法;注意力机制
{Abstract}: 动物目标检测与跟踪作为计算机视觉领域中一个热门的研究问题,已经持续了很长时间。随着计算机硬件和深度学习技术的不断发展,动物目标检测与跟踪的研究也越来越受到关注。动物目标检测和跟踪的挑战在于动物的外貌、形状、颜色和动作可能会发生很大的变化,而且不同的物种之间也存在很大的差异。此外,由于生态环境复杂多变,例如光照、天气和遮挡等因素都会对图像质量和动物识别造成影响,使得动物目标检测和跟踪变得更加困难。近年来,随着深度学习技术的发展,特别是目标检测和跟踪算法的不断改进,动物目标检测和跟踪的性能得到了很大提升。yolov5目标检测算法和基于目标检测的Deep SORT多目标跟踪算法在行人跟踪领域已经取得了优秀的成果,但在动物目标跟踪领域相关研究比较有限。本文对yolov5和Deep SORT算法在动物目标检测跟踪过程中的问题进行了深入研究,并针对这些问题进行了优化改进,本文主要的研究内容如下:(1)针对使用交并比(Intersection over Union,Io U)指标衡量检测准确度时出现的对小型目标不敏感的问题,引入了一种基于Wasserstein距离的目标检测评估方式,并基于此方式对yolov5训练过程中的目标定位损失进行了优化改进。此外,将坐标注意力机制与yolov5的特征金字塔结构进行了融合,以增强网络对动物目标的特征提取能力,从而提高检测准确率。在本文所构建的数据集内进行了实验,平均精度指标提高了2.8个百分点,能有效提高检测效果。(2)针对Deep SORT算法在动物目标跟踪过程中的轨迹误匹配问题,使用Shuffle Net作为表观特征提取网络,并在其基础上添加了ECA注意力机制来优化网络的特征提取能力。在轨迹匹配方面,使用综合考虑了目标框重合程度以及目标框之间距离的DIo U(Distance-Io U)进行了匹配环节的改进。在自制数据集上进行了实验测试,MOTA(Multiple Object Tracking Accuracy)指标提升了3.7%,MOTP(Multiple Object Tracking Precision)指标提升了2.6%,结果表明本文的改进方式能够有效的改善动物目标跟踪过程中的轨迹消失以及目标身份ID切换等问题。(3)基于现实生活中如生态保护、农业养殖等一些可能存在的场景,设计实现了一个动物检测跟踪系统,并将本文提出的动物目标检测跟踪算法进行了实际应用。该系统能对视频或直播流中出现的动物目标进行检测和跟踪,同时对跟踪结果进行可视化展示,还为用户提供了便捷的历史记录管理功能。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001145
{DOI}: 10.27005/d.cnki.gdzku.2023.001145
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的疲劳驾驶检测系统的研发
{Author}: 彭兆伟
{Tertiary Author}: 骆东松;谈应明
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 疲劳检测;SSD模型;面部特征;头部姿态
{Abstract}: 据统计,约有25%的交通事故是机动车驾驶员在疲劳状态下驾驶机动车造成的。为了降低因疲劳驾驶导致的交通事故发生频率,本课题设计开发出一套基于机器视觉的疲劳驾驶检测嵌入式系统,通过机器视觉这种非接触式检测手段监测驾驶员的驾驶状态,当系统检测到驾驶员处于疲劳驾驶状态,则及时语音告警,提醒驾驶员注意,达到减少交通事故的目的。本课题具体研究内容如下:(1)改进了传统的SSD(Single Shot Multi Box Detector)模型为OSSD(Optimized Single Shot Multi Box Detector)模型用于检测驾驶员人脸区域。根据系统的实际需求,改进SSD模型的基础网络,加入组规范化形成OSSD模型的基础网络,既加快了神经网络的训练速度又解决了批处理较小时误差增大的不足;改进SSD模型对特征图的处理,OSSD模型主动放弃抽取前两个特征图,使得模型忽略对小物体的检测,在保证对驾驶员人脸检测精度的情况下降低了模型的计算量,提高了系统的实时性。训练结果显示,OSSD模型对驾驶员面部检测的正确率为92.3%。(2)综合考虑基于面部特征和头部姿态的疲劳驾驶检测方法的联系,使用图像处理开源库Dlib(Dependable Lists Incorporated Bellwood)标记人脸特征点;改进的眼睛纵横比算法判断驾驶员眼睛状态;嘴巴纵横比算法判断驾驶员嘴巴状态;多点透视算法计算驾驶员头部姿态信息。通过对摄像头的精心挑选,降低了光照变化对成像的干扰,为Dlib库精准标记人脸特征点提供了基础,有利于系统对驾驶员眼睛,嘴巴和头部姿态的检测。系统使用驾驶员的单位时间眼睛闭合百分比,打哈欠频率、时长以及低头时间三个指标判定驾驶员的驾驶状态,降低了系统误判的可能性。(3)开发嵌入式硬件系统和软件流程。本文综合比较市面上流行的图像处理芯片,充分考虑实际情况,选择了RK3399Pro芯片作为嵌入式产品的处理器。系统以RK3399Pro核心板为主,设计出符合实际需求的外围电路,实现了对驾驶员面部信息的采集、处理、分析和语音告警功能。设计系统程序流程时,充分考虑到实际应用场合,使用了较多的判断语句,在满足条件的前提下减少系统对图像的处理环节,提高系统实时性。最后,实际测试基于机器视觉的疲劳驾驶检测嵌入式软硬件。实验结果表明,本课题开发的嵌入式系统能够低延迟的准确地检测出驾驶员的眼睛状态,打哈欠频率、时长和头部姿态;能够完成对驾驶员驾驶状态的检测以及对处于疲劳驾驶状态的驾驶员发出语音告警的功能。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2023.000993
{DOI}: 10.27206/d.cnki.ggsgu.2023.000993
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的高反光金属表面缺陷检测与分类方法研究
{Author}: 甘富升
{Tertiary Author}: 白金平
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 高反光金属面;反光消除;缺陷快速检测;缺陷分类;小样本学习
{Abstract}: 高反光金属制品在航空航天、汽车、机械等领域有着广泛的应用,其表面质量直接影响了产品的性能和安全性。传统的人工目测方法效率低下,准确度不高,容易受到人为因素的影响。基于机器视觉的自动化检测技术可以克服这些缺点,实现对高反光金属表面缺陷的快速、精确的检测识别。然而,高反光金属表面具有特殊的光学特性,如镜面反射、高光噪声等,给缺陷检测带来了很大的挑战;同时因为工业领域良品率较高,缺陷样本数量少,给缺陷分类工作增加了困难。因此,研究针对高反光金属表面缺陷检测和小样本分类的有效方法具有重要的理论意义和实际价值。本文针对高反光和缺陷少的特性,从以下几个方面展开工作:1.高反光消除。针对高反光问题,本文首先从光源入手,分析和实验不同参数的光源对样本的影响效果,最终选择蓝色圆顶光源作为本文光源;由于光源容易受环境因素影响,因此在软件算法层面进行补充研究,采用多曝光融合算法,通过对选定的曝光时间拍摄的多张图像进行加权融合,得到最终的反光消除的图像。2.图像预处理。反光消除后,对图像进行预处理。首先进行滤波算法的实验和对比,选择高斯滤波作为本文滤波算法,以此来让图像降噪,使得前景和间隙背景更好分割;然后对不同分割算法进行对比实验,选择效果更优的自适应阈值分割算法来进行图像分割,提高有用信息的权重,进而提高后续边缘检测的效率。3.缺陷快速检测。预处理后,通过对多种像素级边缘检测算法的实验对比,选择Canny算子作为基础算子;然后基于像素级边缘检测得到的信息,对几种亚像素边缘检测算法进行了实验对比,并提出了基于插值-拟合的亚像素边缘检测算法来进行精度更高的边缘提取。然后基于灰度共生矩阵进行特征分析,通过特征值的计算和实验,确定其中五种特征值作为缺陷快速检测判断的依据;最后通过特征值和阈值比较的方式,完成快速缺陷检测的流程设计。4.小样本分类。缺陷检测出来后,根据数据量少的特点,选择基于小样本学习的关系网络模型作为基础模型,并参考网中网模型思想,对关系网络模型进行改进,同时对激活函数和损失函数进行了改进,最后基于关系网络和改进关系网络,通过mini-Image Net数据集和本文数据集进行训练,完成缺陷分类的任务。本文在项目方提供的数据集上进行实验验证,实现了在小样本情况下,对高反光缺陷数据的快速、准确检测,且分类准确率也在92%以上。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003580
{DOI}: 10.27005/d.cnki.gdzku.2023.003580
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5和DeepSORT的目标检测与跟踪算法研究
{Author}: 李奇武
{Tertiary Author}: 杨小军
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多目标跟踪;YOLOv5;DeepSORT;卡尔曼滤波;匈牙利算法
{Abstract}: 多目标跟踪在计算机视觉领域中是重要的研究方向之一。深度学习技术的不断进步和社会需求对技术的驱动,多目标跟踪在智能交通、安防、无人机巡检和自动驾驶等领域发挥着极为关键的作用。在近十年,多目标跟踪算法的性能不断在提高,但在现实的复杂场景中准确检测和定位目标同时保证跟踪的鲁棒性仍然是一个值得研究的课题。本文以基于检测的行人小目标跟踪为研究主线,在已有目标检测和跟踪算法的基础上,进行针对性的改进,以提高算法的鲁棒性和准确率,本文主要研究内容如下:(1)针对复杂场景中的小尺寸目标在图像中分辨率低、难以提取到具有鉴别力的特征同时易受环境因素影响,而且现有目标检测算法大都面向常规尺寸目标设计,对小尺寸目标检测效果较差的问题,本文以YOLOv5m作为基线模型,在此基础上对网络进行针对性的设计,首先加入小尺寸目标检测层提高浅层与深层特征信息的融合,加强网络对小尺寸目标的特征的提取能力;其次通过融合CA注意力模块帮助网络定位感兴趣的目标;最后在基线模型的基础上将原来分类和定位任务耦合的检测头改进为解耦头,加快网络的收敛,提高检测精度。通过在Vis Drone2019数据集上实验可知,本文改进后的模型在Precision、Recall和m AP上都有了显著的提升,同时与目前主流的检测算法进行横向对比,充分证明了本文改进策略的有效性。(2)针对Deep SORT算法中存在的卡尔曼滤波器对所有检测目标采取统一的噪声测量尺度,没有考虑到检测质量对轨迹预测的影响,而且Deep SORT算法中数据关联策略缺少对低置信度检测框的合理利用的问题,本文首先以改进后的YOLOv5m作为多目标跟踪方法的检测器,对原Deep SORT算法的目标运动建模部分进行改进,采用噪声尺度自适应的卡尔曼滤波算法(NSA-KF)来获得更精确的运动状态;其次,采用全尺度特征提取模型OSNet替换Deep SORT中的简单的特征提取网络,来提取更具区分度的特征,缓解目标因遮挡导致的ID跳变的问题,提高跟踪的鲁棒性;最后对数据关联部分改进,提高低置信度检测框的利用,降低了漏检,提高了轨迹的连贯性。通过在Vis Drone-MOT数据集上对比实验可知,本文基于改进YOLOv5m和Deep SORT的行人小目标跟踪算法在跟踪准确度和鲁棒性上都得到了提升,体现了本文算法的有效性。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.000224
{DOI}: 10.26976/d.cnki.gchau.2023.000224
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 热轧带钢表面缺陷检测算法研究与实现
{Author}: 赵钰寒
{Tertiary Author}: 李迅波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 表面缺陷检测;深度学习;YOLOv5s;迁移学习
{Abstract}: 在工业生产过程中,热轧带钢的表面缺陷产生是不可避免的。为确保热轧带钢产品质量,及时检测表面缺陷并发现问题已成为一项重要任务。在传统热轧带钢生产过程中,通常采用红外、超声波、漏磁等技术对表面缺陷进行检测,然而这些技术存在依赖人工经验、高成本和普适性差等缺点。随着智能技术的发展,基于深度学习的机器视觉方法已广泛应用于智能工业的表面缺陷检测。这种方法具备成本低、安全性好、效率高和灵活性强等优势。针对上述情况,本文旨在改进YOLOv5s和Effnet+Soft Max算法,用于检测热轧带钢的表面缺陷缺陷任务。本文的主要创新点和工作如下:1)对YOLOv5s算法进行了改进,包括优化IOU损失函数、改进标签分配过程、添加注意力机制和优化卷积层模型以实现轻量化。改进后的YOLOv5s算法在热轧带钢的表面缺陷检测任务中,训练平均精度值m AP＿0.5达到了97.2%,相比未改进前提高了10个百分点,并且在掩盖、融合、连接以及细微缺陷检测上均取得了比改进前更好的表现。使用Effnet+Soft Max作为分类算法,研究不同损失函数和优化器对算法性能的影响,并选择性能最佳的交叉熵损失函数和Adam W优化器,分类准确率达到98.2%。最后,使用迁移学习解决热轧带钢表面缺陷检测中的小样本问题。2)基于上述改进后的YOLOv5s算法和Effnet+Soft实现了一个面向热轧带钢表面缺陷检测任务的一站式深度学习缺陷检测软件,该软件具有数据标注、模型训练和缺陷检测等功能。在实际应用中,用户可以直接选择采集好的图像进行标注,对训练算法的各项超参数进行调整以优化训练效果,并查看训练结果的统计信息等。软件在实际使用中,Soft Max分类准确率达到了96.1%,改进后的YOLOv5s的m AP＿0.5达到了97.1%。这些结果较好地复现了本文研究算法的准确率,并极大地提升了使用效率。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004549
{DOI}: 10.27005/d.cnki.gdzku.2023.004549
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的三维点云分类分割方法研究
{Author}: 田帅华
{Tertiary Author}: 刘慧
{Publisher}: 北京建筑大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;机器视觉;三维点云;门控网络;挤压激励;注意力机制;分类分割
{Abstract}: 机器视觉是机器人从复杂空间环境中识别工作对象的关键技术。在机器人系统中常用的Kinect深度相机或激光扫描传感器能够获取目标的三维信息,这使得机器人完成更加复杂的如组装、拆卸、抓取等工作任务成为可能。但是,这也对机器人系统处理三维信息的能力如三维定位、工作对象尺寸测量、估计等提出更高要求。随着深度学习在机器视觉中的发展,三维点云高效提取变得十分重要。原始的三维点云数据具有噪声、稀疏和无序等特点,对其分类分割具有一定的难度,且对于局部信息特征的提取存在一定困难。
本文以PointNet网络及PointNet++网络为基础,分析二者之间的差异,着重研究PointNet++网络的特征提取能力;分析软阈值挤压激励、通道门控、注意力机制等模块关于主要特征的强调机理,提出改进的PointNet网络;研究门控网络抑制无关特征信息,强调网络中重要特征信息,自适应地校准网络内部的特征响应,增强局部信息特征的提取等机理,以门控网络(Gate Net)为基础,将这种思想引入深度学习三维点云分类分割网络中,以提高分类分割精度,提出一种改进的PointNet++网络G-PointNet++。
本文在斯坦福大学公开的ShapeNet数据集上进行实验验证改进的PointNet网络。结果表明,三种强调机制对原网络的改进,使三维点云的分割精度(均交并比)较PointNet原网络分别提高了0.24%、0.68%、0.93%。该改进方法为后续解决机器人在组装、拆卸、抓取等任务中对工作对象的尺寸精确估计奠定了基础。接着,采用公开的Model Net、ShapeNet和S3DIS数据集作为训练样本对改进的PointNet++网络G-PointNet++进行训练、测试及消融实验验证。实验结果表明,本文所提出的G-PointNet++网络,在Model Net10上的总体分类精度(OA)达到95.5%,在Model Net40上的总体分类精度(OA)达到93.2%,在ShapeNet上的每类均交并比(m Io U)达到85.5%,在S3DIS上的均交并比(m Io U)达到60%,上述结果均优于PointNet++网络,训练时间更快,且在Model Net40上总体分类精度与Point Cloud Transformer网络相当。改进的网络G-PointNet++显著提高了原始三维点云数据分类分割的性能。该网络在稳定性、分类分割准确率、分类分割速度、分类分割均交并比等方面均有所提高。
{URL}: https://link.cnki.net/doi/10.26943/d.cnki.gbjzc.2023.000780
{DOI}: 10.26943/d.cnki.gbjzc.2023.000780
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的室内人体跌倒检测研究与实现
{Author}: 徐源
{Tertiary Author}: 李晓;黄武胜
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;跌倒检测;YOLOv5;姿态估计
{Abstract}: 老年人跌倒事件是老龄化社会面临的一个严重问题,它不仅会影响老年人的健康和生活质量,也给家庭和社会带来沉重负担。深度学习技术能够通过对人体行为数据进行学习和训练,从而获得人体特征信息。论文工作来源于广东某实习基地项目,通过运用深度学习技术提取包括姿态、位置等关键信息,以能及时、准确地检测老年人的跌倒,并立即预警。因此论文工作具有理论和实践应用价值,以及显著的社会效益。深度学习技术应用到跌倒检测领域已成为当前理论研究和应用实践热点,近年来取得一定的成果。但经深入调研和分析发现,现有算法存在有效特征选取不足、目标检测位置不准确或姿态估计检测到无人区域的问题,以及算法计算量大等局限性。论文解决了上述三个问题,着重于解决前两个问题。论文工作旨在针对老年人室内环境下的跌倒检测,基于改进的目标检测与姿态估计相结合的算法进行人体跌倒检测,设计并实现了一个室内人体跌倒检测原型系统。论文主要开展了以下工作:第一,提出了一种新的结合改进YOLOv5和OpenPose的室内跌倒检测算法。首先,对YOLOv5进行了改进,添加了坐标注意力机制以适应室内人体目标、引入GSConv轻量级卷积模块和简化损失函数以减少参数量和计算量。其次,针对Open Pose的计算量和功耗问题,使用了深度可分离卷积替代传统卷积。然后,将改进后的YOLOv5用于检测人体目标,并将人体位置信息输入到Open Pose中进行关键点检测和姿态提取,进而判断是否发生跌倒。实验结果表明,论文算法在保持原有精度的同时提高了检测速度。第二,设计并实现了基于PyQt5的室内人体跌倒检测原型系统。采用面向对象系统设计理论和方法完成了需求分析、系统设计、数据库设计、系统实现和测试。通过需求分析,明确了系统的功能性和非功能性需求。在确定系统设计准则后进行了系统架构设计,由输入源选择、跌倒检测和输出检测记录三个功能模块组成。采用时序图、类图和流程图完成了各功能模块的结构设计,并使用My SQL数据库进行了数据库设计。系统实现采用C/S结构,使用Python和Py Qt5进行开发。在遵循GB/T25000.51-2016的测试规范基础上,进行了系统的功能性、安全性、易用性、实时性等指标测试,测试结果满足系统设计要求。第三,丰富跌倒数据集。鉴于目前可用于跌倒检测的数据集较少且类型单一,在公开数据集基础上自建了一批室内人体跌倒检测数据集,包含约9000张图片的数据集,为后续研究奠定基础。在实际生活中,跌倒是在复杂环境中产生的,因此使用三维数据进行姿态估计会更全面。项目工作仅使用了二维姿态估计进行跌倒检测,未来将引入三位三维姿态估计到跌倒检测中。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.001746
{DOI}: 10.27684/d.cnki.gxndx.2023.001746
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 混凝土3D打印的机器视觉检测研究现状与展望
{Author}: 陈权要;周燕;周诚
{Author Address}: 华中科技大学国家数字建造技术创新中心;华中科技大学土木与水利工程学院;
{Journal}: 土木建筑工程信息技术
{Year}: 2023
{Volume}: 15
{Issue}: 05
{Pages}: 1-8
{Keywords}: 混凝土3D打印;机器视觉;缺陷检测;质量控制;深度学习
{Abstract}: 受打印材料、打印装备、打印工艺及环境条件的影响，混凝土3D打印成形质量控制较难，且传统的人工检测手段效率低下，因此，亟需寻求新的检测途径。机器视觉技术作为一种非接触式检测方式，已逐步开始应用在混凝土3D打印缺陷检测中。为此，本文从混凝土3D打印几何形貌与精度、层间变形与稳定性及表面缺陷三个方面，综述了机器视觉技术在混凝土3D打印缺陷检测中的研究现状，以期为混凝土3D打印质量控制及发展提供借鉴。
{ISBN/ISSN}: 1674-7461
{Notes}: 11-5823/TU
{URL}: https://link.cnki.net/doi/10.16670/j.cnki.cn11-5823/tu.2023.05.01
{DOI}: 10.16670/j.cnki.cn11-5823/tu.2023.05.01
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的水泥厂人员安全穿戴和吸烟行为检测
{Author}: 贺旭
{Tertiary Author}: 蓝章礼
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;安全穿戴检测;吸烟检测;YOLOv5;TensorRT
{Abstract}: 生产安全是工厂正常生产秩序的重要保障,水泥厂作为国民经济中起着重要作用的物资生产基地,其生产安全至关重要。然而在生产过程中,人员违规穿戴和吸烟现象时有发生,对生产安全和员工身体健康造成了一定的威胁,加之水泥厂的厂区面积较大、环境复杂,采用人工进行检查和提醒难度较大、效率不高。因此,本文提出了一种基于改进YOLOv5的水泥厂人员安全穿戴和吸烟行为检测方法。主要开展了以下几个方面的研究:1)基于改进YOLOv5的安全穿戴检测。针对重叠衣物这一难题,使用了新的标注方式来突显衣物的主体特征从而避免了复杂环境下的影响。并且进行了算法上的调整以适应修改后的数据集。其中包括添加Coordinate Attention和修改NMS为Soft-NMS。通过Coordinate Attention,增强了空间位置信息和特征之间的关联性,以提高特征表示的质量和效率。通过Soft-NMS调整目标框的得分,以更好地处理目标堆叠的问题。实验结果表明,相较于使用原始YOLOv5,改进后的算法在安全穿戴检测中m AP有4.7%的提升。2)基于改进YOLOv5的吸烟检测。针对形状狭长的烟支,为了提高检测准确度,从两个方面入手:优化数据集的标注框和改进算法。在数据集标注方面,适当地增加了标注框的范围,以提高目标的特征信息,从而增强模型的分类和定位能力。在算法改进方面,本文采用了decoupled head技术。将目标的定位与分类分开,通过分离这两个任务,可以减少定位检测框时的误判,避免定位不准确的检测框反过来诱导神经网络学习错误。此外,还采用了为小目标增加检测头的方式,来进一步提高检测的准确性。实验结果表明,改进后的烟支检测算法相较于原始YOLOv5算法m AP提高了6.6%。3)基于Tensor RT加速的模型部署。针对多任务带来的多模型部署问题,同时也为了降低改进模型的算力开销,本文使用Nvidia提供的Tensor RT加速本文所提出的算法,并且使用Triton Server托管多个模型。通过多模型并行运行的方式,有效地提升深度学习应用的推理效率。实际测试表明,基于硬件的加速算法效率得到了68%的提升。针对水泥厂人员安全穿戴和吸烟行为,本文设计的目标检测算法和网络结构优化,可以在处理监控图像时具有更好的性能,并通过使用GPU并行计算等技术,加速了模型的推理速度,可以满足实时监测的需求,有较好的算法性能和适应性。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2023.000342
{DOI}: 10.27671/d.cnki.gcjtc.2023.000342
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果品质分级方法综述
{Author}: 王晓云;乔豪杰;刘凤丽;郭金玉;崔猛飞
{Author Address}: 沈阳理工大学机械工程学院;沈阳化工大学信息工程学院;
{Journal}: 成组技术与生产现代化
{Year}: 2023
{Volume}: 40
{Issue}: 01
{Pages}: 6-13
{Keywords}: 机器视觉;水果品质;外部品质;分级方法
{Abstract}: 为促进水果品质分级检测技术的发展，对国内外基于机器视觉的水果品质分级研究现状进行综述，并对水果的外部品质分级方法进行概述，提出了现阶段水果分级方法存在的问题和研究方向。水果分级是保证水果品质的重要前提。基于机器视觉的水果品质分级相比于人工与简易机械分级，具有分级准确、分级效率高、无损伤接触等特点，能够满足水果分级的市场要求。
{ISBN/ISSN}: 1006-3269
{Notes}: 41-1226/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvynVGMCrIt9P3KAfn7arAyLjmLktc_Pg3qQzW3HLaxt4edg1qTh6GLCS0422EYgWg6J8BqwTeO6SP_00knHvA-UYM0y-LD4HvC_ppAWp_QuUbrYKu0zLpR37oJReIGItE_EUt9CefAjGOa7-ZkEZ50ziU5EGR2uCMszGo4iGJO5NRk2KfOr_tJVGavmf3esJQU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLO v5-OBB与CT的浸种玉米胚乳裂纹检测
{Author}: 宋怀波;焦义涛;华志新;李嵘;许兴时
{Author Address}: 西北农林科技大学机械与电子工程学院;农业农村部农业物联网重点实验室;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 03
{Pages}: 394-401+439
{Keywords}: 玉米胚乳裂纹;YOLO v5;CT扫描;旋转目标检测;机器视觉
{Abstract}: 浸种是玉米生产中重要的播前增种技术，对浸种过程中裂纹的高效检测是分析玉米胚乳裂纹变化规律的基础，是优良品种性状选育的关键之一，尚存在内部胚乳裂纹不可见、自动化检测程度不高等困难。基于CT扫描技术，在YOLO v5n检测网络的基础上，设计了YOLO v5-OBB旋转目标检测网络，其中OBB为有向目标边框，该网络使用旋转矩形框代替普通矩形框，并在Backbone部分加入位置注意力模块（CA）,同时采用倾斜非极大值抑制算法（Skew-NMS）进行非极大值抑制得到最终预测框，以此实现长宽比大、方向不一的玉米胚乳裂纹检测。经过300次迭代训练，模型在测试集上的精确率P为94.2%,召回率R为81.7%,平均精度（AP）为88.2%,模型内存占用量为4.21 MB,单幅图像平均检测时间为0.01 s,与SASM、S2A-Net和ReDet旋转目标检测网络相比，AP分别提高15.0、16.9、7.0个百分点，单幅图像平均检测时间分别减少0.19、0.22、0.46 s,同时YOLO v5-OBB模型内存占用量分别为SASM、S2A-Net和ReDet模型的1.50%、1.43%和1.73%,与采用水平矩形框标注的YOLO v5网络相比，AP提高0.6个百分点，模型大小减小0.19 MB,单幅图像平均检测时间不变，两者均为0.01 s。将YOLO v5-OBB网络获取裂纹目标框坐标信息后得到的裂纹长度与在DragonflyEZ软件中得到的裂纹真实长度相比，两者绝对误差为0.04 mm,相对误差为0.93%。对不同CT灰度分布情况下玉米胚乳裂纹检测结果表明，该模型对较小灰度、较大灰度、混合灰度3种玉米胚乳裂纹图像的P分别为100%、100%、93.3%,R分别为100%、82.4%和79.8%,AP分别为99.5%、91.2%和86.8%。结果表明，所设计模型能有效实现玉米胚乳裂纹的检测，同时模型鲁棒性高，内存占用量小，可为玉米浸种过程胚乳裂纹的自动监测提供借鉴。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxXOM4Ck1dcuvtjVMkAhen-jpXrDucnw6UeRAJxzj7hpdwYpaN8c1rY111ELEueqb6iT475LrljZpt4JHdvJV7zeXIgxFZ2HWSMfI7aion_Th2wG14raiwfKQ2GTNUjp5c9F6uyeb25taSuQCyJq-KZmHVuTev5tL5iQ-bkOQuNsWUW261z9kf1lQ9CIRzsGnA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 带钢表面缺陷检测方法研究进展
{Author}: 李跃;王子铭;李鑫林;岳强
{Author Address}: 安徽工业大学冶金工程学院;
{Journal}: 钢铁研究学报
{Year}: 2023
{Volume}: 35
{Issue}: 08
{Pages}: 950-962
{Keywords}: 表面缺陷;检测方法;机器视觉;深度学习
{Abstract}: 带钢是一种重要的钢铁材料，工业生产过程中带钢表面会产生各种不同的缺陷。带钢表面缺陷对产品有重要影响，其特征复杂、多样且不易获取，因此带钢表面缺陷检测一直是研究的重点内容。对带钢表面缺陷检测技术方法的研究进展进行了论述与分析。结合带钢表面缺陷种类，对传统的带钢表面检测方法如人工检测、红外检测、涡流检测和漏磁检测等优缺点进行比较分析，得出这些方法存在检测速度低、无法达到实时在线检测和需要人为干预等缺点。最后对机器视觉的检测方法开展了归纳总结，对基于深度学习的机器视觉识别表面缺陷的原理和方法进行了详述并对未来发展趋势进行了展望。
{ISBN/ISSN}: 1001-0963
{Notes}: 11-2133/TF
{URL}: https://link.cnki.net/doi/10.13228/j.boyuan.issn1001-0963.20220363
{DOI}: 10.13228/j.boyuan.issn1001-0963.20220363
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向多天气退化图像恢复的自注意力扩散模型
{Author}: 秦菁;文渊博;高涛;刘瑶
{Author Address}: 长安大学信息工程学院;
{Journal}: 上海交通大学学报
{Year}: 2024
{Volume}: 58
{Issue}: 10
{Pages}: 1606-1617
{Keywords}: 计算机视觉;扩散模型;图像恢复;Transformer;天气退化图像
{Abstract}: 复杂天气下的图像恢复对后续高级计算机视觉任务具有重要意义.然而，多数现有图像恢复算法仅能去除单一天气退化，鲜有针对多天气退化图像恢复的同一模型.对此，结合去噪扩散概率模型和视觉Transformer,提出一种用于多天气退化图像恢复的自注意力扩散模型.首先，利用天气退化图像作为条件来引导扩散模型反向采样生成去除退化的干净背景图像.其次，提出次空间转置自注意力噪声估计网络，利用退化图像和噪化状态来估计噪声分布，包括次空间转置自注意力机制(STSA)和双分组门控前馈网络(DGGFFN).STSA利用次空间变换系数实现有效学习特征全局性长距离依赖的同时，可显著降低计算负担；DGGFFN利用双分组门控机制来增强前馈网络的非线性表征能力.实验结果表明，在5个天气退化图像数据集上，相比近来同类算法All-in-One和TransWeather,本文算法所得恢复图像的平均峰值信噪比分别提高3.68和3.08 dB,平均结构相似性分别提高2.93%和3.13%.
{ISBN/ISSN}: 1006-2467
{Notes}: 31-1466/U
{URL}: https://link.cnki.net/doi/10.16183/j.cnki.jsjtu.2023.043
{DOI}: 10.16183/j.cnki.jsjtu.2023.043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂场景中人体姿态估计算法研究
{Author}: 代燕
{Tertiary Author}: 宋井宽
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 人体姿态估计;复杂场景;关系建模;数据扩充;课程学习
{Abstract}: 人体姿态估计任务旨在从图像或视频数据中捕捉多个人体实例以及骨架上稀疏的关键点位置,如膝盖和肩膀。由于关键点位置可用于简洁生动地描绘人体静态属性/运动信息,该任务已成为计算机视觉中一项热门、基础的研究课题,支撑着人机交互、安防监控等众多下游应用。近年来,随着深度学习的发展和大规模数据集的发布,姿态估计性能有了飞跃式的提升。尽管主流方法在简单场景中识别较好,但实际应用中的“复杂场景”对当前估计技术带来了巨大挑战。其中,“复杂场景”即指包含截断行人、混淆背景、密集人群、严重遮挡或极端姿态的数据样本。现实场景的复杂多变会严重影响到模型识别精度,然而这类细分困难场景又是将姿态估计推向实际部署所必须解决的核心挑战。鉴于此,本文重点研究复杂场景中人体姿态估计算法,从推理模型、姿态数据和学习策略出发提升模型在复杂场景中的鲁棒性和泛化性。此外,本文还研究下游骨架动作识别任务中的关键科学问题,以推进以“人”为中心的视觉任务走向实际应用。主要工作包括:1.从推理模型层面,本文针对密集人群所带来的实例难区分问题,研究如何构建适用于拥挤场景的姿态估计模型。首先,本文针对密集人群中“一框多人”问题所导致的模型判别混淆,提出激活给定检测框中所有人体关键点。接着,本文设计一种基于关键点关联关系建模的姿态估计网络,旨在消除干扰关键点所带来的负面影响。进一步地,针对拥挤场景下遮挡和畸变姿态的识别问题,本文引入一种基于人体结构图谱的姿态解析器,将关键点连接性的常识约束加入到估计过程以帮助推理。最后,基于主流数据集的可靠实验表明,所提模型明显优于当时最先进的姿态估计模型。2.从姿态数据层面,本文针对现有数据集和训练图像的固有缺陷,分别研究姿态数据扩充技术和学习目标优化以克服这两大数据缺陷所导致的模型偏差。首先,本文定义一种数据集指标“实例复杂度”,并系统分析主流数据集的固有缺陷,即实例复杂度不均衡和现实场景不充足问题。接着,本文提出一种全视角数据生成策略,通过构建多样姿态池和丰富背景池随机模拟生成有效样本,以帮助训练更稳健的姿态估计器。此外,本文针对训练图像的固有缺陷,即前景-背景不均衡问题,设计一种自适应类别感知的损失函数,通过细分关键点区域的像素类型并自适应地设置其调节因子来帮助均衡损失分布。最后,基于主流数据集的广泛实验证明,所提方法可以为各类姿态估计器带来较大的性能改进。3.从学习策略层面,本文针对现有传统学习策略导致模型在复杂场景下的识别退化问题,研究如何通过优化现有学习策略实现高效训练。首先,本文分析发现传统训练策略随机组织和平等对待所有数据样本,这完全忽视了样本困难性差异。一旦在简单样本主导的数据集进行训练,就会导致对于困难样本的识别退化。接着,借鉴人类由易到难组织材料的学习范式,本文设计一种模型感知的课程学习策略,包括难度感知的课程组织和模型感知的课程调度,进而充分挖掘现有模型的识别潜力。最后,在主流数据集上进行的可靠实验证明,所提学习策略的有效性和泛化性,尤其是针对困难姿态的识别。4.从下游任务层面,本文针对骨架动作识别任务在推理阶段要求输入所有骨架形式的严格约束,研究单模态下构建完备动作表征的方法。首先,本文分析发现动作识别模型倾向于从所有骨架序列中获得互补线索,但现实典型情况是仅能获捕捉到一部分数据形式的输入。鉴于此,本文提出一种自适应跨数据形式的新型学习范式,约束每个模型自适应地模仿来自各种单骨架序列模型的有用表征,并将这些知识整合到一个动作识别模型中,以消除对所有骨架形式的严格要求并促进动作识别精度。最后,基于主流数据集的实验表明,所提学习策略可大幅提升动作识别精度并创造单模型动作识别新记录。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.000205
{DOI}: 10.27005/d.cnki.gdzku.2023.000205
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向海洋的水下图像处理与视觉技术进展
{Author}: 陈炜玲;邱艳玲;赵铁松;魏宏安;程恩
{Author Address}: 福州大学福建省媒体信息智能处理与无线传输重点实验室;中国福建光电信息科学与技术创新实验室(闽都创新实验室);厦门大学水声通信与海洋信息技术教育部重点实验室;
{Journal}: 信号处理
{Year}: 2023
{Volume}: 39
{Issue}: 10
{Pages}: 1748-1763
{Keywords}: 水下图像处理;质量评价;机器视觉;智慧海洋
{Abstract}: 水下观测是探索海洋最直观的手段之一。受水下光学特性、声学特性以及杂波、水生生物等的影响，水下观测中所采集的图像并不总能满足观测需求。如何对水下图像进行有效的处理、分析与应用是一个具有挑战性的课题。尽管图像处理与计算机视觉技术已在大气环境中得到广泛研究，但鉴于成像原理、应用背景等方面的差异，针对大气自然图像提出的算法无法直接移植到水下任务中，而针对水下场景提出的视觉应用仍存在对任务背景考虑不足、泛化性差等缺陷。本文面向光学图像以及声学图像这两类水下观测的主要手段，从图像特性入手，首次以任务为导向、以需求为脉络，通过梳理国内外成功的水下图像处理、质量评价案例，对水下观测方案的工作思路进行了更完备的总结与分析。此外，本文围绕水下机器视觉应用探讨其发展进程，详细讨论与展望了相关领域的前景与优化方向，为突破海洋视觉应用的瓶颈，建设智慧海洋系统带来新思路。
{ISBN/ISSN}: 1003-0530
{Notes}: 11-2406/TN
{URL}: https://link.cnki.net/doi/10.16798/j.issn.1003-0530.2023.10.003
{DOI}: 10.16798/j.issn.1003-0530.2023.10.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与Faster-RCNN的Delta机器人工件识别检测
{Author}: 张宇廷;王宗彦;李梦龙;赵鹏宇
{Author Address}: 中北大学机械工程学院;山西省起重机数字化设计工程技术研究中心;
{Journal}: 机床与液压
{Year}: 2023
{Volume}: 51
{Issue}: 05
{Pages}: 35-40
{Keywords}: 并联机器人;深度学习;Faster R-CNN;图像处理
{Abstract}: 针对传统并联机器人在工作环境中存在抓取不精确、定位与分类识别效率低下的问题，提出一种基于机器视觉与Faster-RCNN神经网络的工件识别检测技术。采用Delta机器人实验平台采集图像，进行图像的预处理操作并将其添加至网络训练集。通过Python3.7-torch1.7搭建深度学习中的Faster R-CNN卷积神经网络，作为基本框架训练工件图像数据集。最后将训练后的卷积神经网络得到的工件检测结果与原实验工件识别系统对比。结果表明：改进后的识别平均精确度比原有识别系统有所提高，反应时间缩短，并且能识别不同类型的工件。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxWS4QpjWW_oFYkxjikzEojCJIqasUIUkwZYUossJadD8T4IOdJJDHi7coWLQzcAnfKu_O2s8yztoZYiZ7cvmSWJKmat-Tjbqdf0Fe0_r8AKAwM5O_0A58RZ-xn7eHUUoIDKa81EhkeYbWHS3cCRnl9EazmIIG9zD8FXmasfuVBKmIviKmtZQUe3aD3NuuPRH8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种自适应交通信号灯系统
{Author}: 殷玲;许永康
{Author Address}: 广东交通职业技术学院;
{Journal}: 物联网技术
{Year}: 2023
{Volume}: 13
{Issue}: 03
{Pages}: 94-96
{Keywords}: 交通信号灯;机器视觉;通信技术;图像传感器;车辆统计;自适应
{Abstract}: 交通灯是一种基础交通设施，在极大程度上改善了交通路口的通行秩序。交通出行以安全、便捷为主，但因车流量日渐增长、天气变化多端，现有的交通灯已经越来越不能满足当下的交通需求，特别是节假日和上下班时间，城市车流量的不平衡性和交通疏导方案的不足，造成了交通资源的极大浪费以及严重的交通拥堵。另因恶劣天气能见度太低，造成的交通事故也不计其数。为了提高交通资源利用率，提高人民群众的交通出行效率和交通安全保障，文中提出一种自适应交通信号灯系统，通过图像传感器实时获取交通路口的车辆图像；根据不同相位的车流量，合理设计红绿灯的配时方案，自动调节红绿灯的时长；同时传感器将检测到的天气情况传送到控制中心，通过数据智能分析自动调整交通灯的可见度、穿透度、亮灯时间，能有效防止拥堵，避免资源浪费、环境污染，保障交通畅通，并尽可能减少交通安全事故发生。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2023.03.028
{DOI}: 10.16667/j.issn.2095-1302.2023.03.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的钢桥面板裂纹识别方法
{Author}: 劳武略;崔闯;张登科;罗纯坤;张清华;宋松科
{Author Address}: 西南交通大学桥梁工程系;四川省交通勘察设计研究院有限公司;
{Journal}: 中国公路学报
{Year}: 2023
{Volume}: 36
{Issue}: 03
{Pages}: 188-201
{Keywords}: 桥梁工程;钢桥面板裂纹;特征计算;计算机视觉;目标检测;语义分割
{Abstract}: 钢桥面板疲劳开裂为常见的钢桥病害，准确快速地发现并确定钢桥面板裂纹几何特征对降低运维成本、制定运维策略具有重要意义。针对传统人工巡检效率低、检测环境恶劣等问题，提出了基于计算机视觉的钢桥面板裂纹及其特征识别方法。采用目标检测网络YoloV5和图像语义分割网络U-Net++相结合的方法识别裂纹。根据2个网络的结构特性标注图像中的目标后生成数据集，并分别对网络中的参数进行训练。利用训练后的YoloV5与U-Net++分阶段对待测裂纹图像进行检测与分割，并通过阈值分割优化U-Net++分割结果，再通过骨架化后得到裂纹骨架线；在确定裂纹形貌后，采用YoloV5识别出的标定块求解透视变换矩阵与像素尺度系数，然后对裂纹骨架线进行图像矫正并确定裂纹几何特征。研究结果表明：YoloV5可准确检测出裂纹与标定块，且检测稳定性好；通过优化U-Net++训练时输入的像素尺寸，提高了U-Net++训练的收敛速度，网络损失由0.121降至0.096;求解透视变换矩阵时，使用所有角点坐标拟合该矩阵的最小二乘解可提高图像矫正标定的精度；当图像采集距离较远、角度较大时，角点投影误差增大，且该误差对角度更为敏感；不同图像采集距离、角度下裂纹特征计算误差最大为7.2%,表明识别精度及稳定性均较高。所提出的钢桥裂纹特征识别方法可准确计算裂纹几何特征，具有一定的实用价值。
{ISBN/ISSN}: 1001-7372
{Notes}: 61-1313/U
{URL}: https://link.cnki.net/doi/10.19721/j.cnki.1001-7372.2023.03.015
{DOI}: 10.19721/j.cnki.1001-7372.2023.03.015
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Mediapipe的幻影成像装置自然手势交互系统设计
{Author}: 孟杰;杨鹏程;杨朝;李小成
{Author Address}: 西安工程大学机电工程学院;
{Journal}: 国外电子测量技术
{Year}: 2023
{Volume}: 42
{Issue}: 03
{Pages}: 116-122
{Keywords}: 幻影成像;人机交互;手势识别;Mediapipe;非极大值抑制算法
{Abstract}: 针对博物馆中幻影成像虚拟展示装置的交互需求，设计了一种自然手势的计算机视觉交互系统。利用单目相机对自然手势进行动作采集，针对不同身高人群手部活动范围，计算了单目相机最优捕获位置，实现了140～190 cm人群高度的手势识别。采用Mediapipe机器学习框架对捕获的手势图像实时遍历，获得单帧手掌的标定位置。结合21个特征关节点的手掌模型，使用非极大值抑制算法对自遮挡的手掌进行识别，根据欧氏空间距离判别阈值和单个手指曲率对指间动作做出分类，定义幻影成像常用5种交互动作，通过坐标关系建立了指尖和模型特征点之间的实时映射。实验结果表明，所设计的交互系统，系统识别准确率达到98%,满足幻影成像系统中手势控制虚拟模型的要求。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2204392
{DOI}: 10.19652/j.cnki.femt.2204392
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器学习在计算机视觉处理中的应用
{Author}: 王三超;刘朋朋
{Author Address}: 河南科技职业大学;
{Journal}: 集成电路应用
{Year}: 2023
{Volume}: 40
{Issue}: 03
{Pages}: 336-337
{Keywords}: 机器学习;计算机视觉处理;影像样式的界定;合成图像
{Abstract}: 阐述机器学习与计算机视觉处理技术的特点，机器学习在计算机视觉处理中的应用策略，包括定义图像内容、影像样式的界定、生成合成图像。
{ISBN/ISSN}: 1674-2583
{Notes}: 31-1325/TN
{URL}: https://link.cnki.net/doi/10.19339/j.issn.1674-2583.2023.03.147
{DOI}: 10.19339/j.issn.1674-2583.2023.03.147
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手语识别系统设计
{Author}: 高辉
{Tertiary Author}: 徐军
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手语识别;注意力机制;关键点估计;编码-解码结构
{Abstract}: 手语作为聋哑人与社会沟通的桥梁,在社交领域发挥极其重要作用,尤其对于聋哑群体参与正常交流有着极其重要的意义。手语识别方法从早期基于肌电信号为主逐渐过渡到基于图像和视频为主,肌电信号的采集和处理存在信号干扰、设备成本高等问题,利用深度神经网络对手语图像和视频进行分析和分类,具有更高的准确性和稳定性。随着人工智能技术发展,基于深度学习的手语识别作为新型的人机交互方式,拥有广阔的应用空间和研究价值。因此,本文通过提取图像中人体骨骼关键点作为手语识别特征信息,设计基于Transformer的手语识别模型,开发手语识别应用平台,实现手语识别任务。首先,设计手语识别方案,深入研究手语特征提取模型和手语翻译模型,对Continuous SLR100手语数据集进行扩充,增加复杂环境下手语数据。将手语视频转化为图像序列,通过帧间差分法,提取手语视频关键帧,剔除手语过程中静止帧和过度帧,减少模型计算量,提高手语识别速度。其次,通过Mediapipe获取手语视频关键帧中上肢和手部骨骼关键点,对骨骼关键点进行数据增强,将骨骼关键点坐标进行二维对象归一化处理,得到骨骼关键点特征向量作为手语翻译模型的输入,消除复杂背景环境对手语特征的干扰,提高手语识别的准确度。然后,优化Transformer手语翻译模型,将基于骨骼关键点的手语特征向量序列输入到Transformer中,获取连续手语中上下文时序信息,实现手语翻译功能。设计对比实验,分别从骨骼关键点提取、特征归一化方法、特征提取模型、手语识别模型四个方面进行横向和纵向对比,验证本文提出手语识别方法合理性和有效性。最后,本文通过Py Qt5设计手语识别系统,实现手语与自然语言双向翻译功能,建立聋哑人与社会之间沟通平台,为手语识别技术应用提供了可行性方案。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2023.000303
{DOI}: 10.27063/d.cnki.ghlgu.2023.000303
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉算法的图像处理技术分析
{Author}: 陈琦
{Author Address}: 德州职业技术学院;
{Journal}: 电子技术与软件工程
{Year}: 2023
{Volume}: 
{Issue}: 05
{Pages}: 178-181
{Keywords}: 计算机视觉算法;图像处理技术;图像矫正
{Abstract}: 本文以计算机视觉算法为基础，针对图像处理技术展开研究，对现有图像校正效果进行有效改善，并给出以计算机视觉算法为基础的针对性处理技术。基于此，分别对计算机视觉算法、图像处理技术中的图像类别特征和专业技术特点展开说明，经研究论证，以计算机视觉算法为基础的计算机视觉显示系统和图像畸变矫正功能使用效果良好，具备进一步研发价值和推广价值，希望本次研究可以为同领域工作者提供合理参考。
{ISBN/ISSN}: 2095-5650
{Notes}: 10-1108/TP
{URL}: https://link.cnki.net/doi/10.20109/j.cnki.etse.2023.05.039
{DOI}: 10.20109/j.cnki.etse.2023.05.039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的农业机器人自主作业设计
{Author}: 孙丹
{Author Address}: 常州市高级职业技术学校;
{Journal}: 南方农机
{Year}: 2023
{Volume}: 54
{Issue}: 06
{Pages}: 128-130
{Keywords}: 机器视觉;机器人;农业;自主作业
{Abstract}: 随着我国城市化的发展和人口老龄化的加剧，从事农业生产的人数逐渐减少，农业生产成本的上升导致农产品价格上涨。因此，开发廉价、灵活和多功能的自主农业机器人尤为重要。因此，笔者在阐述农业机器人自主作业研究开发的意义和价值的基础上，分析了农业机器人自主作业的设计过程，并设计了一款物美价廉的农业机器人。仿真结果表明，该农业机器人可以根据农作物的生长情况灵活管理农作物，可以进行浇水、施肥和除草等作业，解放了劳动力，提高了农业生产效率。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyoqhb0Y7MYn6Dw1QGqTM556RRCVcqftQe1Rt3qHFRAVbA8hA_gZHs4R2wYwmEce_u6nZkda8lt1EfWVfIEFkrUJ52JHR3o3hpW0vRPxoh2D1PCyVAteLkUU9Ys4r-4h8Cz4tXMSUuVbI5m_fWE79MDVc5u4ljE3D4sNZovldOBIGb2ooz-vpGJaRIdWEvZPGw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾分拣系统设计
{Author}: 陈美玲;朱温涵;刘佳成;郑阳
{Author Address}: 南京工业大学浦江学院;东北大学研究生院秦皇岛分院;佳木斯大学;
{Journal}: 现代信息科技
{Year}: 2023
{Volume}: 7
{Issue}: 04
{Pages}: 18-21+28
{Keywords}: 机器视觉;树莓派;卷积神经网络;Arduino
{Abstract}: 由于人们生活水平的不断提高，随之产生的生活垃圾也不断增多。为解决靠人力进行垃圾分类效率低下的问题，对自动垃圾分拣系统进行研究，并设计一种基于机器视觉的垃圾分拣系统。使用搭载有摄像头的树莓派作为主控单片机，利用卷积神经网络来分辨摄像头所拍摄垃圾的类型，借助Arduino控制舵机自动开合垃圾桶，实现垃圾分类。经过测试分析，系统的准确精度均能达到70%以上，准确精度较好，籍此人们能够轻松处理生活垃圾。
{ISBN/ISSN}: 2096-4706
{Notes}: 44-1736/TN
{URL}: https://link.cnki.net/doi/10.19850/j.cnki.2096-4706.2023.04.005
{DOI}: 10.19850/j.cnki.2096-4706.2023.04.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 金属棒材表面缺陷的机器视觉检测方法研究
{Author}: 马晓雄;熊晓燕;兰媛;乔葳
{Author Address}: 太原理工大学机械与运载工程学院;新型传感器与智能控制教育部(山西省)重点实验室;
{Journal}: 机械设计与制造
{Year}: 2023
{Volume}: 
{Issue}: 04
{Pages}: 196-200+205
{Keywords}: 金属棒材;缺陷检测;机器视觉;非下采样剪切波变换
{Abstract}: 针对传统金属棒材表面缺陷人工检测方法速度慢、效率低，工作环境差，且工人长时间工作导致的视觉疲劳会造成漏检，错检的问题，提出一种计算量小且稳定性高的检测算法。首先，采用同态滤波与CLAHE对使用检测系统采集的原始图像进行预处理；然后，利用保持平移不变性的非下采样剪切波变换（NSST）对预处理后的图像进行分解，对分解得到的高频成分采用各向异性扩散与改进的自适应gamma校正进行滤波与图像增强；同时，将低频成分与二维高斯函数作卷积运算，从而达到均匀背景的目的；最后通过NSST重构可得到质量较高的原始图像，结合形态学运算及Sobel算法实现划痕缺陷数量、尺寸及位置的检测。实验表明，算法的缺陷检测准确率为93.8%，平均检测时间为0.673s，可满足工业要求。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20230222.011
{DOI}: 10.19356/j.cnki.1001-3997.20230222.011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 驾驶员安全带检测方法研究综述
{Author}: 徐国新;李雷孝;何嘉彬;高昊昱
{Author Address}: 内蒙古工业大学数据科学与应用学院;内蒙古自治区基于大数据的软件服务工程技术研究中心;海南大学网络空间安全学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 17
{Pages}: 48-66
{Keywords}: 驾驶员安全带检测;计算机视觉;图像处理;深度学习;目标检测
{Abstract}: 驾驶员安全带检测作为计算机视觉的一个具体应用领域，目前基于计算机视觉相关技术的驾驶员安全带检测方法以节约人力、实时监督、高精度等优势逐渐成为研究热点。对近年来驾驶员安全带检测方法进行了系统性的分析和总结，对驾驶员安全带检测背景和传统传感器检测方法进行了简要说明；介绍了数字图像处理和机器学习的相关方法，分析总结其优缺点；重点分析和总结了深度学习的方法，从模型训练常用方法、卷积神经网络和衍生的目标检测算法的发展历程及其在驾驶员安全带检测中的应用三个方面进行介绍；对当前研究仍面临的问题以及进一步的研究方向进行了总结和展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230217.1433.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 单幅RGB图像计算光谱成像的深度学习研究综述
{Author}: 姜中敏;张婉言;王文举
{Author Address}: 上海理工大学;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 10
{Pages}: 22-34
{Keywords}: 计算机视觉;深度学习;光谱图像;计算光谱成像
{Abstract}: 为解决传统的光谱成像方法成本高、图像采集时间较长的问题，深度学习被引入计算光谱成像来研究如何从单幅RGB图像中重建光谱，为各种计算机视觉应用提供辅助信息。当前对基于深度学习的单幅RGB图像计算光谱成像方法还未有全面、系统的深入认识与研究。为此针对计算光谱成像所使用的深度学习算法和网络模型进行了系统的归纳、分析和对比。基于CNN(convolutional neural networks)、GAN(generative adversarial networks)、注意力和Transformer四个类别详细梳理了近几年重建性能优异的有监督学习方法；基于自编码器和领域自适应两类别分析、探讨、比较了热度较高的无监督学习方法。同时列举了算法常用数据集和评估指标，对未来的研究趋势和发展方向进行了展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20230214.1421.018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉技术和深度学习的隧道掌子面岩体裂隙自动识别方法研究
{Author}: 罗虎;Miller Mark;张睿;方勇
{Author Address}: 西南交通大学土木工程学院;四川川交路桥有限责任公司;
{Journal}: 现代隧道技术
{Year}: 2023
{Volume}: 60
{Issue}: 01
{Pages}: 56-65
{Keywords}: 掌子面图像;岩体裂隙;卷积神经网络;计算机视觉技术
{Abstract}: 对掌子面图像的裂隙识别和特征提取进行研究，首先根据隧道中光照不足和光线不均匀的特点，对掌子面图像集进行包含多种光照处理措施在内的数据增强；通过Unet网络识别掌子面轮廓，其平均交并比和平均相似度为91%和93%；利用形态学操作使掌子面轮廓边缘平滑，消除噪点。然后利用拆分-拼接策略处理高分辨率掌子面图像，通过DeepCrack网络模型迁移学习识别岩体裂隙，其平均交并比和平均相似度为61%和75%。利用Zhang-Suen算法和8邻域标记算法进一步对识别结果进行细化、骨架化和连通域分析。最后，通过控制点标记和腐蚀标记法计算每条裂隙的像素级长度和倾角。
{ISBN/ISSN}: 1009-6582
{Notes}: 51-1600/U
{URL}: https://link.cnki.net/doi/10.13807/j.cnki.mtt.2023.01.006
{DOI}: 10.13807/j.cnki.mtt.2023.01.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的CoreXY结构写字机器人设计
{Author}: 徐振中;周洁;孙立辉
{Author Address}: 吉林化工学院信息与控制工程学院;
{Journal}: 自动化与仪器仪表
{Year}: 2023
{Volume}: 
{Issue}: 01
{Pages}: 226-230
{Keywords}: 写字机器人;CoreXY结构;机器视觉;Bresenham算法;QT
{Abstract}: 针对目前写字机器人存在的智能化水平低、难以独立运行等问题，在常规写字机器人的基础上，利用机器视觉和嵌入式技术设计了基于机器视觉的CoreXY结构写字机器人。该写字机器人的机械结构采用CoreXY运动结构，硬件电路由主机、从机、运动驱动、图像采集、人机交互等模块构成，软件设计采用了带有梯形加减速过程的Bresenham直线插补算法、基于OpenCV的文字识别算法以及结合QT设计的上位机控制软件。测试结果表明，该设计能够正确进行文字识别以及准确完成写字。
{ISBN/ISSN}: 1001-9227
{Notes}: 50-1066/TP
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.1001-9227.2023.01.226
{DOI}: 10.14016/j.cnki.1001-9227.2023.01.226
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的弱光图像增强算法研究综述
{Author}: 李恒烜;雒芬
{Author Address}: 河南理工大学;
{Journal}: 信息与电脑(理论版)
{Year}: 2023
{Volume}: 35
{Issue}: 02
{Pages}: 70-72+176
{Keywords}: 深度学习;计算机视觉;弱光图像增强
{Abstract}: 弱光图像增强旨在使隐藏在黑暗中的信息可见,以提高图像质量,在夜间目标检测和行为识别等计算机视觉任务中广泛应用。首先,从有监督和无监督两个角度出发,梳理了基于深度学习的弱光图像增强代表性算法,结合实现原理分析了其优缺点。其次,总结了常用的训练数据集和测试数据集。最后,讨论了目前已有算法存在的问题和未来可能的发展趋势。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzD9VPHInipaMwHRCxFnFBeMd9Byy43zVpSzSnDxZnqPFB9n5V8_kjvwL5wf6u9DCAprS9l6U5vyEO7Ts5ufsBG_gmT_nMAXz9JmqlHAXLqww7onq94JALiMbG6SIyb_oqEZsznd2aq3DclSjoEYyv0YXcIar9IFT1Vk5eFA2NU_gZkZKAOHYWfACI5voqt0DI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 人工智能在计算机视觉和网络安全中的应用
{Author}: 叶聪
{Author Address}: 苏州信息职业技术学院;
{Journal}: 电子技术
{Year}: 2023
{Volume}: 52
{Issue}: 01
{Pages}: 240-241
{Keywords}: 人工智能;计算机视觉;网络安全;智能流量监测
{Abstract}: 阐述人工智能的发展过程，人工智能在计算机视觉和网络安全中的应用，对网络中的访问数据进行甄别、专家系统、数据挖掘、智能流量监测、有效识别复杂的动态图像，保障网络的可靠与安全。
{ISBN/ISSN}: 1000-0755
{Notes}: 31-1323/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvztGFOPs5EqxYg8o17rb1oDmOvyXYj152lrnPIVuq0aDKbJkstW59-S099XMDqRGAtxz8PcC90HhS5wT_A4PHwYHFmfmAUIYdz6hmU5tDXFiWLnhO_6lIzDZIJirFdZxAPevxBKgOQE6QGNiugeAENF8j5S0qLIKTgY5dduTi81YpM__beNcVefN9gMuRyb3as=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉中的终身学习综述
{Author}: 陈一驰;陈斌
{Author Address}: 中国科学院成都计算机应用研究所;中国科学院大学计算机科学与技术学院;哈尔滨工业大学(深圳)国际人工智能研究院;哈尔滨工业大学重庆研究院;
{Journal}: 计算机应用
{Year}: 2023
{Volume}: 43
{Issue}: 06
{Pages}: 1785-1795
{Keywords}: 深度学习;终身学习;计算机视觉;灾难性遗忘;稳定性-可塑性困境
{Abstract}: 终身学习（LLL）作为一种新兴方法打破了传统机器学习的局限性，并赋予了模型能够像人类一样在学习过程中不断积累、优化并转移知识的能力。近年来，随着深度学习的广泛应用，越来越多的研究致力于解决深度神经网络中出现的灾难性遗忘问题和摆脱稳定性-可塑性困境，并将LLL方法应用于各种各样的实际场景中，以推进人工智能由弱向强的发展。针对计算机视觉领域，首先，在图像分类任务中将LLL方法归纳为四大类型：基于数据驱动的方法、基于优化过程的方法、基于网络结构的方法和基于知识组合的方法；然后，介绍了LLL方法在其他视觉任务中的典型应用和相关评估指标；最后，针对现阶段LLL方法的不足之处进行讨论并提出了LLL方法未来发展的方向。
{ISBN/ISSN}: 1001-9081
{Notes}: 51-1307/TP
{URL}: https://link.cnki.net/urlid/51.1307.TP.20230116.1742.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CiteSpace的内表面缺陷检测研究进展与趋势
{Author}: 盛强;郑建明;刘江山;史卫朝;李海涛
{Author Address}: 西安理工大学机械与精密仪器工程学院;陕西科技大学机电工程学院;
{Journal}: 光谱学与光谱分析
{Year}: 2023
{Volume}: 43
{Issue}: 01
{Pages}: 9-15
{Keywords}: 无损检测;缺陷检测;内表面;机器视觉;图像处理
{Abstract}: 为分析内表面缺陷检测的发展历程、趋势和研究动态，通过对WoS和CNKI数据库中该领域相关文献的检索，共搜集相关文献英文4 708篇，中文818篇，利用可视化分析软件CiteSpace对文献数据开展共现分析、聚类分析等知识图谱研究，分析内表面缺陷检测领域在国家、机构及研究人员层面的分布现状及合作情况，梳理研究热点和前沿趋势。研究发现内表面缺陷检测研究具有明显的多学科交叉属性，主要涉及分析化学、材料科学、光谱学、仪器仪表、机械工程和计算机等学科。近几年WoS数据库相关主题收录文献年增长率超过10%, CNKI年增长率超过20%,中美两国为本领域研究最为活跃的国家，两国发文量约占总发文量的40%,中国学者在无损检测、图像处理等领域的研究明显落后于国外学者，但在机器视觉和深度学习领域实现赶超。按照研究路线可将相关研究分为基于声光电热磁的检测和基于视觉成像的检测两类，其中前者包括采用不同技术手段获取光谱、超声和电磁图像并借助图像处理技术实现缺陷检测，而后者主要基于视觉图像进行缺陷识别和分类，目前已成为该领域主要的研究热点。内表面缺陷检测发展历程分为缺陷识别、缺陷分类、缺陷分析三个阶段，2000年以前主要借助声光电热磁信号或图像实现缺陷的识别和判定，2000年以来，支持向量机技术大幅提高了缺陷分类的效率和准确度，近十年来随着对缺陷分析及测量需求的不断出现，基于机器视觉的缺陷定位与测量逐渐成为发展趋势，缺陷检测对象也逐渐向深孔和小尺寸孔内表面发展。
{ISBN/ISSN}: 1000-0593
{Notes}: 11-2200/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzwkg-zbh8g4PwBH9FzW8eMC5erqNMzGcMMpK6NxmuYArbI6-bB33zJ2VHg8UeNo34rKmemGyMh4b9wrCkfLUogRIGLucymVefaHlxtW3ECdGVIKSW0K70IL-Gb4CnK2kmn0BdIDSTCUQ3sAv_rgc5ZCwNqkRLarJtj2D-CGwo1zxI3AXfPzh9V-eXly8b-KpQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Halcon的相机标定方法研究与精度验证
{Author}: 李晓晓;杨涛;雷进;孙付春;吴昊荣
{Author Address}: 成都大学机械工程学院;成都农业科技职业学院机电信息学院;成都大学电子信息与电气工程学院;
{Journal}: 技术与市场
{Year}: 2023
{Volume}: 30
{Issue}: 01
{Pages}: 8-13
{Keywords}: 机器视觉;单目相机;Halcon;标定;测量
{Abstract}: 机器视觉已经在现代工业测量领域中得到了广泛应用，而相机标定直接影响机器视觉的测量精度。通过搭建相机视觉实验平台，在分析了单目相机标定原理基础上，以GB050-2-7×7型圆点标定板为实验对象，利用Halcon软件对圆点标定板进行相机标定实验并验证测量精度。当采集的标定板图像数量为16时相机标定精度最优，此时相机的平均偏差为0.0707mm。在进一步测量实验中测量出标定板上7个特征圆点的直径平均值为1.9491mm,6个特征圆点之间的间距的平均值为2.0632mm，测量精度都高于0.1mm，验证了Halcon软件标定结果的测量准确性。
{ISBN/ISSN}: 1006-8554
{Notes}: 51-1450/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxIw8VATIJIi8PyYmcuB2ie0eM8i1BKYztZpN1w1FJ0pQRFElIi9ewqY1Eq-VP5TjGNgMUNcilqo6iSIWH9U94MvuPK8MretOsgaRJWsRHlo2IgFc07PwTffBGCmCJ5oolwVnUM7V4tTaiRSXu61-AZ38w6SBpYSJ6WOv1mB-n8CRv2LJ-PBH5QjlZOV83nAFU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的手机玻璃盖板缺陷检测与分拣系统
{Author}: 贺旖琳;陶肖
{Author Address}: 复杂环境特种机器人控制技术与装备湖南省工程研究中心;2湖南理工职业技术学院;
{Journal}: 工业控制计算机
{Year}: 2022
{Volume}: 35
{Issue}: 12
{Pages}: 74-75+79
{Keywords}: 机器视觉;缺陷检测;智能控制;手机玻璃
{Abstract}: 针对目前手机玻璃盖板依赖人工视觉检测、效率低、误检及漏检率高的问题，提出一种基于机器视觉的手机玻璃盖板表面缺陷检测与分拣系统。结合机器视觉和机器人优势，在构建系统的硬件框架基础上，对工业产线上的手机玻璃图像采集与处理、特征提取与分类，实现手机玻璃以行业外观检测标准检测与分拣，从而提高工业生产自动化及产品检测精准度。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxwp-jj-qHs5QuOPl57feEk16vyRGiV7_xS2MZuF0wzRJgsFWsNveJXap4sQs5uLrcDJKjQ7xOWhEEveJI1m2PgjPQ8YahGu6ayfKYV50SD-myIvaKiJGQQb6e3ynOu4lRJZosARKgr6GYYJFQ2-fXeV0lrgNfpug-7FkryZMeF9QBXxu8MdQwnmGBh7d6kJK4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于高斯混合模型的水果分类识别方法研究
{Author}: 郑如新;孙青云;马素慧;徐鹏;程冬
{Author Address}: 南京林业大学机械电子工程学院;河北科技师范学院机电工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 12
{Pages}: 16-19
{Keywords}: 机器视觉;HALCON;分割;识别;高斯混合模型
{Abstract}: 对于水果的识别分类，目前大部分还是使用人工去完成分类，但是由于长期的重复劳动会使人工受到劳动强度和视觉疲劳的影响，容易造成错误，难以适应产业的发展。因此，为了提高水果识别分类的效率，使得水果分类能够更加的智能化、自动化，在此应用机器视觉技术针对水果识别分类展开研究。通过搭建水果图像采集平台系统，使用HALCON图像处理软件对水果进行了阈值分割和特征提取等操作，成功实现了水果与背景的分割，最后使用gmm（高斯混合模型）算法分类器对水果进行训练。实验表明：该方法能够准确有效的识别并区分出水果，在检验训练完成的分类器结果准确率为100%,100%,100%,90%,83%，验证了将高斯混合模型应用在水果分类识别方面的有效性。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw_aspXKLw3-EY8rTwwGggOPcUwxZae8KE7WOntdL5MAx3IoOUnG68nYG2lNz64OmyafYddDRdRCzCP5xoVYHpz_ZmLQbmF8G98qUQEKt16ATYAlTdiSw6JY2fpU6cfrtCu-cM4BSvuHC0HgcvPwEtHJRvlKqdjcz3ettx5tK2yg0kcNLtZSPjayQSk2jIiwE8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的三轴机械臂分拣装置设计
{Author}: 姜超群;张爱华;赵佳冉;娄成龙;李建军
{Author Address}: 中原工学院电子信息学院;
{Journal}: 物联网技术
{Year}: 2022
{Volume}: 12
{Issue}: 12
{Pages}: 67-70
{Keywords}: 三轴机械臂;机器视觉;运动状态;FPGA;EmguCV;USART
{Abstract}: 针对当前市场上视觉抓取装置操作复杂、移植难度大的问题,本文介绍了一款基于机器视觉的三轴机械臂分拣装置的设计方案。利用单目相机对运动状态下的物体进行图像数据采集,然后对物体图像数据进行处理,从而确定待检测物体的形状和位置,由运动控制模块控制三轴机械臂实现物体的分拣操作。系统基于.Net Framework平台进行软件开发,本装置的硬件部分基于STM32和FPGA设计运动控制模块、基于STM32设计抓取模块和传动模块、基于EmguCV库设计图像采集模块。该装置可在手动模式和自动模式下进行运动状态物体的准确抓取与分拣放置。最后,本文在装置自动模式下对不同运动速度、不同形状、不同颜色的物体进行分拣测试,平均成功率达到96%。结果表明,文中设计的方案具有可行性和有效性。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2022.12.019
{DOI}: 10.16667/j.issn.2095-1302.2022.12.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和深度学习的建筑垃圾智能识别研究
{Author}: 许文稼;蒋庆斌;刘钢洋
{Author Address}: 常州机电职业技术学院电器工程学院;中国矿业大学化工学院;
{Journal}: 电子器件
{Year}: 2022
{Volume}: 45
{Issue}: 06
{Pages}: 1489-1496
{Keywords}: 建筑垃圾;机器视觉;目标检测;深度学习;图像识别
{Abstract}: 针对当前建筑垃圾分选中存在的分选效率不高、自动化程度较低等问题，提出了一种基于机器视觉和深度学习的建筑垃圾智能分选系统并对检测识别过程进行了详细研究。该系统采用背景建模法对建筑垃圾进行检测定位，可以有效避免运输皮带抖动、磨损和光照变化等情况，提高检测精度和定位速度。此外该系统基于ResNet卷积神经网络模型对建筑垃圾进行分类识别，并通过迁移学习方法对建筑垃圾分类模型的训练效率进行了优化，将模型的分类准确率提高到了99.47%,有助于更好地实现建筑垃圾的智能化分选。
{ISBN/ISSN}: 1005-9490
{Notes}: 32-1416/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxCImhQxY2GfazHTZTAOgs15Vzseh-T8xh9q6Aogjt5yhGbOf-9VkmBUJbc_DkYM_WDkALGuhdf06MHMOcdUDjI15JL-7QUAGBBG9wOEoi9wL781ZumV6C-dZ7yBnMwHt-6UqM674SLe6Ovp8nYFymoVrW8zN13lutdfJkmtbvSLnQRo-yPvYEnlYXpsQsEbAA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CMOS传感器和机器视觉的核辐射探测技术研究
{Author}: 鄢章发
{Tertiary Author}: 张朝晖
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: CMOS传感器;核辐射探测;机器视觉;核辐射亮斑;移动辐射源定位
{Abstract}: 核技术广泛应用于工业、农业、医学、能源、环境以及材料改性等领域,同时也给公众安全带来了一定的风险。使用互补金属氧化物半导体(Complementary Metal Oxide Semiconductor,CMOS)传感器进行核辐射探测是一个新的研究方向。现有的基于CMOS传感器的核辐射探测方法局限于遮光条件和静态场景,没有考虑运动物体等干扰因素的影响。本文开创性地研究了 CMOS摄像头在动态场景下的核辐射探测技术,包括以下几个方面:
1、辐射环境下CMOS成像中的核辐射亮斑特征研究,包括形态特征、像素值特征和帧间非重复性特征,为核辐射亮斑信息提取和亮斑识别提供数据支撑和理论支撑。
2、动态场景下核辐射亮斑提取方法研究,首次实现动态场景下的核辐射亮斑信息提取。本文提出了基于帧差法和形态学处理的核辐射亮斑提取方法,其中包括在保留亮斑信息前提下的差分噪声去除算法和运动物体去除算法。
3、核辐射亮斑识别方法研究,提出基于图像融合和卷积神经网络的核辐射亮斑识别模型。为解决动态场景下的标准辐射亮斑数据集获取困难以及无法标注的问题,本文提出了基于局部总像素最大值的图像融合方法,该方法能够保留辐射亮斑信息和差分背景信息。
4、动态场景下CMOS摄像头核辐射探测的灵敏度提升方法研究。本文通过CMOS传感器的量子效率曲线和以及对核辐射亮斑的RB通道值分析,提出了长波通滤光方法,以提升使用CMOS摄像头进行核辐射探测的灵敏度。
5、动态场景下使用多个CMOS摄像头进行移动辐射源定位的方法研究。本文在对辐射帧计数与辐射源距离之间的关系研究基础上,提出了基于斜率表示的目标距离和辐射帧计数的相关性计算方法和辐射源归因算法模型,实现了移动辐射源的定位。
基于本文研究,能够实现在动态场景下的核辐射实时探测和移动放射源的定位,有望建立一套基于CMOS监控摄像头的低成本广覆盖的核辐射监测系统,应用于核电站、医院、矿场、入境口岸等需要核辐射监测和视频安全监控的场景,为国土安全和城市安全提供保障。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2023.000153
{DOI}: 10.26945/d.cnki.gbjku.2023.000153
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属表面缺陷检测方法综述
{Author}: 王慧菁;杨长辉;吕庆
{Author Address}: 重庆理工大学机械工程学院;
{Journal}: 微纳电子与智能制造
{Year}: 2022
{Volume}: 4
{Issue}: 04
{Pages}: 71-81
{Keywords}: 图像处理;缺陷检测;深度学习;金属表面
{Abstract}: 金属材料广泛应用于装备制造、机械电子等支柱性产业中,金属表面缺陷检测对工业生产中产品质量的控制至关重要,机器视觉作为自动检测技术在该方面应用甚广。本文首先对金属表面缺陷检测技术的现状进行讨论。其次,针对金属表面缺陷检测中的机器视觉方法,从传统算法和深度学习两个方面进行阐述,针对传统机器视觉方法主要讨论阈值分割、边缘检测、聚类等,并对各种方法进行对比;深度学习方法主要聚焦在缺陷检测和缺陷分割两个方面,对金属表面缺陷检测的一些主流算法和网络模型进行总结。最后,分析了机器视觉在金属表面缺陷检测中存在的困难和挑战,对未来的发展做出了展望。
{ISBN/ISSN}: 2096-658X
{Notes}: 10-1594/TN
{URL}: https://link.cnki.net/doi/10.19816/j.cnki.10-1594/tn.2022.04.071
{DOI}: 10.19816/j.cnki.10-1594/tn.2022.04.071
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器之眼：从操作图像到智能视觉
{Author}: 施畅
{Author Address}: 暨南大学新闻与传播学院;
{Journal}: 南京社会科学
{Year}: 2022
{Volume}: 
{Issue}: 12
{Pages}: 135-144
{Keywords}: 操作图像;智能视觉;人工智能;机器视觉;视觉政治
{Abstract}: 机器之眼聚焦“机器如何观看”的议题，20世纪以来其研究范式从操作图像逐渐转向智能视觉。操作图像即机器自动感知、生成的功能性图像，涉及科学图像与监控图像两大研究传统。操作图像意味着超越目视的机器感知，临床医学要求其实现感知的深度，现代军事要求其实现感知的广度。人工智能时代，机器之眼从原本的“延伸感知”发展为“理解现实”,从而进阶为脱离甚至取代人眼的智能视觉。智能视觉的本质在于通过图像聚合、图形识别及数据汇编，从而实现机器对图像的自动化译读。智能视觉的识别功能基于对不甚重要之物的否定和排除，而当人们有针对性地屏蔽、欺瞒它时会造成“盲视”效应。更值得警惕的是人类对机器之眼的“盲视”,隐形图像令人迷惑，算法黑箱令人费解，在一个日益透明的世界我们需要保持对人工智能的批判性审视。
{ISBN/ISSN}: 1001-8263
{Notes}: 32-1302/C
{URL}: https://link.cnki.net/doi/10.15937/j.cnki.issn1001-8263.2022.12.015
{DOI}: 10.15937/j.cnki.issn1001-8263.2022.12.015
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的物体分拣系统设计
{Author}: 马泽明;俞晓丹;邓雨晴;高铭玮;李文元;王楚壹
{Author Address}: 南通理工学院;
{Journal}: 科学技术创新
{Year}: 2022
{Issue}: 36
{Pages}: 159-162
{Keywords}: 视觉技术;搬运机器人;无线控制网
{Abstract}: 为提升搬运机器人的智能化程度和可靠性，增强智能搬运机器人和视觉技术的结合能力，根据企业的生产需求，基于实验室的科研项目，实现将视觉技术、搬运机器人和无线控制网相结合，设计了一种智能搬运机器人的实验平台。使用STM32F103作为智能搬运机器人的核心控制板，利用视觉完成路径的识别和目标物体的识别，通过ZigBee无线通信技术实现上位机和主控制的通信，并在上位机中设计控制界面显示智能搬运机器人的运行状态。实验表明，智能搬运机器人能够完成路径和目标物的寻找、抓取和搬运功能，上位机界面能够实现对智能机器人的监控。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwk78FH5i4rmJSwRjZVamnrvmTt_HpKBXy9WMoXCStc3a7JVjFicT3xqCGszF7pawbxr79Rc3eqCwH1Hh_sHSXk0yAatx_HPNj8XBs0UyMe2-_s3iEF7bJFWlWvkRyJEd2Pjf3rEwb6x4dTwzdomRKHW6YXCZmo8ZIocUxES0iSvHL3h83KEK1QyvBNALBQH_A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于单目摄像头的室内老人跌倒识别研究
{Author}: 卫金金
{Tertiary Author}: 李晓飞
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 跌倒识别;YOLOv5;样本不均衡;注意力机制;特征融合
{Abstract}: 根据中国第七次全国人口普查数据,2020年中国人口达14.1亿,65岁及以上人口占比达13.5%,我国人口老龄化进程加快,居家养老将成为未来主要养老模式之一,该模式中异常跌倒是独居老人的最大威胁之一。针对跌倒的事前预防、事中检测、事后评估研究已经成为当前研究热点之一。随着智能视频分析技术的发展,如何快速且准确地识别出监控视频中独居老人异常跌倒行为具有重要的研究意义。本文基于YOLOv5算法提出了一种视频跌倒监控系统方案,最大化利用采集的监控视频,通过跌倒判断和人脸识别,在跌倒发生时及时将老人身份以及跌倒图像报告给家属和医疗机构,便于医疗机构根据跌倒者身份及时采取相应的救护措施。本文的主要研究内容如下:(1)对YOLOv5跌倒识别算法的数据加载策略进行改进,将跌倒识别任务转化为独居老人视频序列目标检测行为分析任务。针对样本不均衡问题(正常行为的样本数会远大于跌倒的样本数),本文采取了数据重采样的方法,根据不同类别的标签数,在训练时分配不同的类别权重和样本采样频率。另外,本文还在输入端改进了数据增强方式。实验表明,改进的训练样本加载策略可以使得模型的平均精度提升2%。(2)对YOLOv5跌倒识别算法的网络结构进行改进,针对原始YOLOv5s模型识别准确率欠佳的问题,本文在其颈部网络嵌入坐标注意力模块,通过不同方向上的通道加权方式,使网络聚焦于待检测目标区域,以提取目标更多的细节信息,并将该模块引入到改进的双向加权特征融合方式中。另外,本文还改进了原始YOLOv5模型的损失函数,舍弃原始的CIo U损失函数,使用alpha-Io U损失函数。实验表明,改进后的网络模型与原始模型相比较,在不添加很大计算成本的情况下,提高了模型的检测性能,满足系统对检测精度和速度的要求。(3)基于本文所改进的YOLOv5算法,设计和实现了一种新型的视频跌倒监控系统方案,采集室内环境下的监控视频,可以实现跌倒动作与身份信息的识别功能,检测精度较高并且具有实时性,满足日常使用要求,达到预期设计要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001125
{DOI}: 10.27251/d.cnki.gnjdc.2022.001125
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向交通复杂目标场景的机器视觉检测技术研究
{Author}: 滕婷婷
{Tertiary Author}: 刘胜美;张晖
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智慧交通;机器视觉;目标检测;先验驱动
{Abstract}: 随着计算机视觉技术的迅猛发展,基于神经网络的机器视觉检测技术取得了突破性的进展,其中基于深度学习的交通目标检测算法逐渐进入到广大研究人员的视野中。然而时间不断变换,天气环境多变,目标种类多样等问题对智慧交通场景下的多目标检测(特别是精准检测)提出了严峻挑战。因此,本文基于一种三维场景空间的思想方法,使用深度卷积神经网络模型YOLOv3作为基础模型,提出两种精准检测算法研究智慧交通多目标场景下的机器视觉检测技术。主要工作如下:一、首先围绕交通目标检测算法,对智慧交通系统、机器视觉技术进行概述;然后对深度卷积神经网络、经典目标检测模型以及目标检测评价指标进行了详细介绍。二、提出先验驱动的交通复杂多目标自适应精准检测算法:首先构建面向三维场景的目标检测模型,以实现在特定时间、特定天气场景下某一类目标的精准检测;然后根据先验知识选择多维度模型,从而在特定时间、特定天气场景下精准地检测某一类目标;最后进行多目标自适应联合检测(即多维度模型融合),主要包括多维度模型融合的流程以及阈值自适应调整机制,以实现智慧交通复杂场景下多目标的精准检测。通过实验将先验驱动的交通复杂多目标自适应精准检测算法与YOLOv3算法对比,实验结果表明:提出的算法可以实现在智慧交通复杂场景下多目标的精准检测且评价指标均有所提升。三、提出面向交通复杂多目标的分层分级联合精准检测算法:首先构建面向单维场景的三类目标检测模型,相较于面向三维场景的目标检测模型构建,降低了成本;然后进行多目标分层分级联合检测,主要包括分层联合检测流程以及分级联合检测机制,以实现智慧交通复杂场景下多目标的精准检测。通过实验将面向交通复杂多目标的分层分级联合精准检测算法与YOLOv3算法对比,实验结果表明:提出的算法可以实现在智慧交通复杂场景下多目标的精准检测且评价指标均有所提升。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001561
{DOI}: 10.27251/d.cnki.gnjdc.2022.001561
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于特征融合网络的低质量图像增强技术研究
{Author}: 段炼
{Tertiary Author}: 唐贵进
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;计算机视觉;低照度图像增强;水下图像增强
{Abstract}: 图像增强是计算机视觉及图像处理领域的一项重要研究内容。由于成像所处环境的不同,在夜间、背光、雾霾以及水下等条件下由图像采集设备采集到的图像通常为不同程度损坏的低质量图像。对低质量图像进行增强处理可以提升图像的整体色彩,凸显图像中物体的细节特征,以此提高图像质量,为后续高级视觉任务提供有效的数据质量保证。本文主要针对自然场景低照度图像及水下场景降质图像进行研究,根据这两类低质量图像的不同特征,开展的主要工作包括:针对自然场景低照度图像,提出一种基于多层次背景融合的残差网络。通过联合不同层次的图像内容与其对应的背景信息来对图像进行增强,使得模型在对图像中某一特征进行增强的过程中能够参考目标特征周围的环境语义信息。同时通过一项复合损失函数从色彩、结构以及平滑度三个方面共同约束网络对于低照度图像的增强过程,使得增强结果更加接近真实图像观感,同时避免了低照度图像增强中常见的局部过增强现象。在LOL、LIME及DICM数据集上的测试验证了本文所提出的低照度图像增强算法能有效提升图像的亮度,避免图像局部过增强或失真的现象。与其它自然低照度图像增强算法相比,本文方法的增强结果在客观质量评价指标上存在4%以上的性能提升。针对水下场景降质图像,提出一种多信息通道输入的特征融合网络。通过三种不同的经典算法对水下图像做预处理得到对应的三幅预处理图像,使用水下图像与三幅预处理图像共同作为网络的输入以弥补水下图像存在颜色通道丢失的特点,同时在三项复合损失中的色彩损失上引入加权思想以应对水下图像由于不同通道失真不同进而颜色偏差巨大的特征,使增强后的图像在颜色分布上具有更佳的表现。在EUVP与UFO-120数据集上的实验验证了本文所提出的水下图像增强算法能有效还原水下图像的真实色彩,并保证图像细节特征的清晰程度。与其它水下图像增强算法相比,本文方法的增强结果在客观质量评价指标上存在5%以上的性能提升。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001539
{DOI}: 10.27251/d.cnki.gnjdc.2022.001539
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MSRCP与改进YOLO v4的躺卧奶牛个体识别方法
{Author}: 司永胜;肖坚星;刘刚;王克俭
{Author Address}: 河北农业大学信息科学与技术学院;河北省农业大数据重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 01
{Pages}: 243-250+262
{Keywords}: 躺卧奶牛;个体识别;机器视觉;改进YOLO v4
{Abstract}: 奶牛的躺卧率可以反映奶牛的舒适度和健康情况，躺卧奶牛的个体识别是自动监测奶牛躺卧率的基础。本文提出了一种基于改进YOLO v4模型识别非限制环境下躺卧奶牛个体的方法。为实现对躺卧奶牛全天的准确个体识别，首先对18:00—07:00的图像采用MSRCP(Multi-scale retinex with chromaticity preservation)算法进行图像增强，改善低光照环境下的图像质量。其次，在YOLO v4模型的主干网络中融入RFB-s结构，改善模型对奶牛身体花纹变化的鲁棒性。最后，为提高模型对身体花纹相似奶牛的识别准确率，改进了原模型的非极大抑制(Non-maximum suppression, NMS)算法。利用72头奶牛的图像数据集进行了奶牛个体识别实验。结果表明，相对于YOLO v4模型，在未降低处理速度的前提下，本文改进YOLO v4模型的精准率、召回率、mAP、F1值分别提高4.66、3.07、4.20、3.83个百分点。本文研究结果为奶牛精细化养殖中奶牛健康监测提供了一种有效的技术支持。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.s.20221130.1659.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的施肥施药机器人的研究与开发
{Author}: 张康迪
{Tertiary Author}: 毛建东
{Publisher}: 北方民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 农业机器人;机器视觉;图像增强;农田导航;导航线检测
{Abstract}: 应用自主导航技术的智能农业机器人对提高农业生产效率和质量、减轻劳动强度、缓解农业生产劳动力不足以及推动我国农业现代化建设具有重要的促进作用。本文研发的基于机器视觉的施肥施药机器人可以实现田间自行走施肥施药作业,并通过微信小程序远程控制机器人工作状态。本文主要研究内容如下:(1)硬件系统设计与实现。硬件设计为功能实现提供基础。针对农田实际的作业环境,选取了履带田园管理机作为本文的机器人底盘,设计并研发了施肥系统和施药系统。根据需要的功能,确定了控制系统上、下位机的主控芯片选型,设计并安装了相关的电源电路、继电器控制电路等硬件电路。(2)图像预处理算法的研究与开发。针对光照不均和阴影等因素的影响,选取了MSRCR算法用于消除干扰,增强图像质量。分析了多种颜色空间下各分量灰度提取结果,选取I1I2I3正交空间下的I2分量用于图像灰度特征提取,完成了图像预处理,为后续算法提供了清晰无干扰的预处理图像。(3)视觉导航算法的研究与开发。在预处理图像基础上提取导航线、解算导航参数并最终实现自主导航。选取中值滤波法消除噪声。使用OTSU法进行阈值分割,并对处理结果进行形态学处理,进一步消除斑点和孔洞。使用最大连通域算法,实现道路区域的提取。对提取结果进行边缘检测和道路中心点提取,在此基础上,采用最小二乘法,对道路中线进行高精度的拟合。最后基于导航线数据解算出导航参数,并根据导航参数控制机器人,实现了自主导航。(4)基于微信小程序的控制系统开发。为实现机器人的远程控制,开发了基于微信小程序的远程控制系统。阐述了MQTT协议的基本原理,选取其作为微信小程序控制系统的通信协议,搭建了基于阿里云的MQTT服务器。针对功能需求,对微信小程序功能模块进行了开发,并制作了相应的操作界面,实现了基于微信小程序的远程控制。(5)实验结果与分析。为证明研究实际效果,便于后续系统优化,对微信小程序控制系统、导航参数获取效果和机器人导航控制系统进行了实验。实验结果表明,微信小程序控制系统可以按照要求实现远程控制行驶、施肥和施药功能;导航参数可以准确表示当前的偏移角度和偏移距离,误差较小;机器人导航控制系统误差满足预期的精度要求,适用于实际的农田作业环境。误差分析结果表明,机器人视觉导航系统偏移角度的平均误差为3.42°,最大误差为7.71°,标准差为3.39°,系统误差为5.19°,随机误差为1.70°;偏移距离平均误差为4.69cm,最大误差为9.76cm,标准差为4.67cm,系统误差为6.15cm,随机误差为2.30cm。本文研发的基于机器视觉的施肥施药机器人对于减轻劳动强度,提高农业自动化和智能化水平具有一定的促进意义。
{URL}: https://link.cnki.net/doi/10.27754/d.cnki.gbfmz.2023.000091
{DOI}: 10.27754/d.cnki.gbfmz.2023.000091
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的鸡蛋裂纹识别技术研究
{Author}: 王贵鹏
{Tertiary Author}: 谢芳;张涛
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 鸡蛋;裂纹;机器视觉;图像处理
{Abstract}: 目前,我国鸡蛋加工企业普遍依赖于外国设备检测鸡蛋表面裂纹,高昂的检测费用阻碍了企业发展,因此研究鸡蛋裂纹识别技术,对我国鸡蛋加工行业具有重要经济意义。基于此,本文具体的研究内容如下所示:首先,搭建了鸡蛋图像采集平台,该平台利用辊轮传输链,实现了鸡蛋水平运动与自转运动同时发生,获取到鸡蛋表面完整图像。在分析研究鸡蛋蛋壳以及内容物(蛋黄、蛋清)透光性之后,确定了工业相机、镜头型号以及光源照明方式。其次,对采集到的鸡蛋图像进行数据预处理,构建出裂纹鸡蛋与完好鸡蛋的分类数据集。将支持向量机(SVM)分类方法应用于识别裂纹蛋与完好蛋,综合准确率达84.4%;将基于YOLO目标检测算法应用于裂纹图像检测模型,经训练以及调优准确率达95%,优于SVM分类方法,最终确定本文以目标检测算法做为裂纹识别方法。最后,在目标检测算法基础上融合目标跟踪算法,实现了基于视频的鸡蛋裂纹检测。使用一段生产线鸡蛋运输视频作为测试视频,验证了基于改进的深度学习图像识别算法模型准确性,算法平均准确率为89.7%、平均精度为94.5%,帧每秒(FPS)达到12帧每秒,满足实时检测要求。对鸡蛋裂纹目标的检测以及跟踪有了更具鲁棒性的效果。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2022.000050
{DOI}: 10.27831/d.cnki.gxjxy.2022.000050
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于DETR的自动驾驶汽车交通标志识别系统研究
{Author}: 徐浩东
{Tertiary Author}: 王建锋;刘思行
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;交通标志检测;注意力机制;机器视觉;自动驾驶
{Abstract}: 交通标志识别是自动驾驶系统中的关键一环,也是机器视觉领域长久以来的热点问题。交通标志中包括道路信息、限速警告、驾驶环境等一系列重要语义信息,在无人驾驶汽车的路径规划、车速调节和驾驶安全等方面起到关键作用。因此,实时精准地在全天候条件下检测路面交通标志对自动驾驶汽车的发展具有重要的意义。交通标志识别的精准与否直接影响自动驾驶安全行驶的问题,然而在复杂多变的自然环境下,例如曝光、反光以及图像模糊的情况难以检测;交通标志牌因常年暴露室外导致部分标志牌表面出现褪色损坏的现象,现有算法的检测性能难以达到预期。除此之外,自动驾驶汽车基于视觉的路面检测任务较为繁多,具有高计算量的需求,目前大多算法在实时性方面的表现还有待提高。因此,针对上述交通标志识别算法的准确性和实时性,本文提出了基于深度学习的目标检测算法,并对于检测任务中的关键部分提出了以下改进方法:1.对检测到的交通标志进行局部的图像增强手段,提高交通标志牌所在区域的对比度、饱和度等,使得交通标志与图像背景形成鲜明对比,在检测过程中优化感兴趣区域(region of interest,ROI),为后续识别环节奠定基础。2.在机器视觉的目标检测任务中引入注意力机制(Attention),注意力机制的引入可以在神经网络预测过程中用来强调或选择待处理目标对象的重要信息,并且抑制无关信息。本文将端到端的目标检测算法Detection Transformer(DETR)用于交通标志识别任务中,这种方法的优势在于免去了非极大值抑制(Non-Maximum Suppression,NMS)后处理过程,在提升预测性能的同时大幅降低了计算开销。3.替换DETR模型中用于特征提取的主干网络,改为利用深度可分离卷积构建的Mobile Netv2网络,提高算法的实时推理速度,结合通道剪枝和层剪枝方法,进一步压缩模型体积。最后,本文将训练好的神经网络模型进行量化处理,将模型参数中高精度数据类型转换为INT8类型数据,提高算法的推理速度,将算法部署在车载相机上构建自动驾驶汽车交通标志识别系统并进行相关实验。实验结果表明本系统在复杂路面的交通标志检测任务上预测性能有着显著提升。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2022.000053
{DOI}: 10.27831/d.cnki.gxjxy.2022.000053
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的车牌识别系统方法研究
{Author}: 陈子言;丁杨军
{Author Address}: 武汉东湖学院;南京审计大学;
{Journal}: 信息记录材料
{Year}: 2022
{Volume}: 23
{Issue}: 12
{Pages}: 42-44
{Keywords}: 图像预处理;车牌定位;字符分割;车牌识别
{Abstract}: 针对现实场景中车辆运动模糊、车牌倾斜、自然光照以及阴雨天气等环境影响导致的识别精度低问题，本文设计并实现了一种基于计算机视觉的车牌识别系统。该系统对采集的车牌图像进行灰度化、边缘检测和二值化等预处理，减小定位难度；通过图像识别处理算法进行车牌定位、字符分割和字符识别。经实验验证，车牌识别系统字符识别准确率为94.98%，在识别准确率方面达到了符合预期的表现，基本满足了日常实际应用的需求。
{ISBN/ISSN}: 1009-5624
{Notes}: 13-1295/TQ
{URL}: https://link.cnki.net/doi/10.16009/j.cnki.cn13-1295/tq.2022.12.054
{DOI}: 10.16009/j.cnki.cn13-1295/tq.2022.12.054
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水产养殖计数研究综述
{Author}: 张涵钰;李振波;李蔚然;杨普
{Author Address}: 中国农业大学信息与电气工程学院;农业农村部国家数字渔业创新中心;农业农村部智慧养殖技术重点实验室;农业农村部农业信息获取技术重点实验室;
{Journal}: 计算机应用
{Year}: 2023
{Volume}: 43
{Issue}: 09
{Pages}: 2970-2982
{Keywords}: 水产养殖;人工计数;无损计数;机器视觉;深度学习
{Abstract}: 养殖计数是水产养殖过程中的重要环节，计数结果为水产动物的饲料投喂、养殖密度调整和经济效益估算等方面提供重要依据。针对传统人工计数方法耗时费力且易造成较大误差的问题，大量基于机器视觉的方法与应用被提出，极大地推动了水产品无损计数的发展。为深入了解基于机器视觉的水产养殖计数研究，整理和分析了至今三十多年来国内外的相关文献。首先，从数据采集方面对水产养殖计数展开综述性介绍，并对机器视觉所需数据的获取方法进行概括；其次，从传统机器视觉和深度学习两方面对水产养殖计数方法进行分析与总结；然后，对各种计数方法在不同养殖环境的实际应用进行对比分析；最后，从数据、方法和应用三方面总结了水产养殖计数研究的发展难点，并提出了计数方法研究和装备应用的未来发展方向。
{ISBN/ISSN}: 1001-9081
{Notes}: 51-1307/TP
{URL}: https://link.cnki.net/urlid/51.1307.tp.20221129.2335.007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在植物病害识别上的研究进展
{Author}: 孙亮;柯宇航;刘辉;胡义钰;冯成天;刘文波;王真辉;张宇;郑服从
{Author Address}: 中国热带农业科学院橡胶研究所/农业农村部橡胶树生物学与遗传资源利用重点实验室/省部共建国家重点实验室培育基地—海南省热带作物栽培生理学重点实验室/农业农村部儋州热带作物科学观测实验站;海南大学植物保护学院;
{Journal}: 热带生物学报
{Year}: 2022
{Volume}: 13
{Issue}: 06
{Pages}: 651-658
{Keywords}: 植物病害;计算机视觉技术;图像处理技术;深度学习
{Abstract}: 随着农业和现代化信息技术的交互、联结和碰撞，农业逐渐趋于现代化、智能化和数字化，近年来运用计算机视觉技术对植物病害进行诊断得到广泛应用，比传统方法更加迅捷、精确。分别从图像采集、图像预处理、图像分割、图像特征提取、病害识别和分类5个方面进行阐述，总结了植物病害图像识别技术的要点及存在问题，并对其未来发展进行了展望，为计算机视觉技术在植物病害识别上的应用和研究提供依据。
{ISBN/ISSN}: 1674-7054
{Notes}: 46-1078/S
{URL}: https://link.cnki.net/doi/10.15886/j.cnki.rdswxb.2022.06.016
{DOI}: 10.15886/j.cnki.rdswxb.2022.06.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在猪行为识别中的应用进展
{Author}: 字吉湖;谭利辉;赵永聚;陈小川
{Author Address}: 草食动物科学重庆市重点实验室动物科学技术学院西南大学;重庆智略创志科技有限公司;
{Journal}: 现代畜牧科技
{Year}: 2022
{Volume}: 
{Issue}: 11
{Pages}: 26-28
{Keywords}: 猪;机器视觉;行为识别;图像处理;目标检测
{Abstract}: 猪的行为是猪健康状态的外在表现，当猪在正常的生存环境下，会表现出站立、活动、进食、饮水等正常的行为，当生存环境不适宜时，猪的行为可能出现异常。随着机器视觉、深度学习技术的发展，猪的行为识别可借助机器视觉—视频监控等方式来完成。该文就机器视觉在猪行为识别中的应用现状进行综述，展望了机器视觉在实现自动化健康养殖中的应用前景。
{ISBN/ISSN}: 2095-9737
{Notes}: 23-1592/S
{URL}: https://link.cnki.net/doi/10.19369/j.cnki.2095-9737.2022.11.006
{DOI}: 10.19369/j.cnki.2095-9737.2022.11.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的RGB图像目标位姿估计综述
{Author}: 王一;谢杰;程佳;豆立伟
{Author Address}: 华北理工大学电气工程学院;唐山市金属构件产线智能化技术创新中心;唐山贺祥智能科技股份有限公司;
{Journal}: 计算机应用
{Year}: 2023
{Volume}: 43
{Issue}: 08
{Pages}: 2546-2555
{Keywords}: 6自由度位姿估计;位姿估计数据集;位姿估计评价方法;深度学习;计算机视觉;工业机器人
{Abstract}: 6自由度（DoF）位姿估计是计算机视觉与机器人技术中的一项关键技术，它能从给定的输入图像中估计物体的6DoF位姿，即3DoF平移和3DoF旋转，已经成为机器人操作、自动驾驶、增强现实等领域中的一项至关重要的任务。首先，介绍了6DoF位姿的概念以及基于特征点对应、基于模板匹配、基于三维特征描述符等传统方法存在的问题；然后，以基于特征对应、基于像素投票、基于回归和面向多物体实例、面向合成数据、面向类别级的不同角度详细介绍了当前主流的基于深度学习的6DoF位姿估计算法，归纳整理了在位姿估计方面常用的数据集以及评价指标，并对部分算法进行了实验性能评价；最后，给出了当前位姿估计面临的挑战和未来的重点研究方向。
{ISBN/ISSN}: 1001-9081
{Notes}: 51-1307/TP
{URL}: https://link.cnki.net/urlid/51.1307.TP.20221117.1124.004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的焊缝表面缺陷图像智能识别机制
{Author}: 薛彬
{Tertiary Author}: 吴志生
{Publisher}: 太原科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 焊接质量;焊缝表面缺陷智能识别;机器视觉;图像滤波算法;特征提取;深度学习
{Abstract}: 在中国智能制造业快速发展的今天,焊接质量是保障产品质量的关键因素,而焊接环境、焊接材料、焊接工艺、焊接电源参数、焊接操作方法等因素均可能导致焊缝表面出现各种缺陷,若未被检出会严重影响产品质量。传统的检测方法精度低、性能差,已无法达到智能制造的要求。基于机器视觉的表面缺陷检测方法具有精度高、处理速度快、处理智能化等特点,是焊缝表面缺陷检测的主要发展趋势。开展基于机器视觉的焊缝表面缺陷图像智能识别机制研究有利于避免漏检、错检等问题,提高检测精度、效率和成功率,减少次品率,对生产过程的智能化发展具有指导意义。针对焊缝表面图像中存在的噪声问题,提出了一种基于邻域绝对差值比较的改进滤波算法。该算法通过求取每个像素点与其四邻域的像素绝对差值,并与设定阈值进行比较的方法来判断噪声点、边缘点、非噪声点,并通过权重矩阵与以噪声点为中心的同尺寸像素矩阵进行卷积运算,得到取代原噪声点的像素值,达到滤除噪声的目的。该算法不但能够准确有效的判断和滤除图像噪声点,而且可以避免边缘点的干扰,不会把边缘点当作噪声点滤除,有效的保护了焊缝表面图像的纹理特征。为验证所提滤波算法的有效性,采用系数法来建立评价指标体系,计算得到裂纹、气孔、划痕、夹杂物四种表面缺陷图像的系数均大于0.7,满足进行试验的先决条件。然后对含有不同浓度(16%、32%、48%)椒盐噪声的焊缝表面缺陷图像进行滤波试验,再通过峰值信噪比(PSNR)和均方误差值(MSE)两个性能评价指标对滤波效果进行评价分析,同时还提取了焊缝表面缺陷图像的不变矩特征和纹理特征进行分析。经分析,采用所提滤波算法对不同椒盐噪声含量的焊缝表面缺陷图像进行滤波处理,其MSE值始终能够控制在一个较小的范围内(18.396～22.946),PSNR值也非常稳定(34.524d B～35.484d B),图像几乎没有失真,质量较好。为将焊缝表面缺陷与背景图像分离,提出了一种改进的微小缺陷阈值分割算法。该算法充分考虑了缺陷目标与同一区域背景像素的相似性,在目标分割过程中,通过分割一个小区域,在小区域内查找缺陷目标,然后确认该缺陷小目标是否为所要搜索的目标。该算法解决了由于焊缝表面图像光照不均匀和材料本身反射所造成的缺陷目标和背景之间的对比度不明显的问题,能够分割出占用像素较少、峰值信噪比较低的微弱缺陷。建立焊缝表面缺陷图像智能识别系统对金属焊缝的缺陷面积、焊缝宽度和余高进行检测。采用“中值滤波-腐蚀运算-Canny算子”的图像处理算法,再通过感兴趣区域分割、相机标定、缺陷轮廓提取,实现焊缝缺陷的面积计算,测量误差低于5%。根据激光三角法原理,通过结构光标定、图像预处理、基于Hessian矩阵算法的中心线提取、中心线修复、亚像素级角点检测,获取了焊缝宽度和余高,最大偏差分别为0.107mm和0.009mm。同时,开发了两款软件,能够实现焊缝图像处理基本算法的调用、焊缝表面缺陷的自动识别、缺陷等级判断和原因分析。通过深度学习进行焊缝表面缺陷分类识别,建立了气孔、裂纹、未熔合和正常焊缝四种类型共5299图片的数据集,并进行了标准化处理。搭建了卷积神经网络模型,包括2个卷积层、2个池化层、2个全连接层和1个softmax回归层,采用Re LU作为激活函数。随机抽取数据集70%的图像进行网络模型训练,将系统损失值降到0.002,准确率达到100%,生成网络模型model.ckpt。最后从数据集其他30%中任意抽取图像,对网络模型进行多次测试,识别准确率达到95%以上。针对透明焊缝表面缺陷中的划痕、裂纹、砂砾夹杂、气泡、表面凹陷五种缺陷的特点,采用侧面照射和斜上方照射两种打光方式搭建设备进行图像采集,提出了一种“二值化降噪-高斯滤波-二值化增强”的焊缝表面缺陷特征提取算法和一种基于长宽比和缺陷中心像素特征的分类方法,实现了对透明焊缝表面缺陷的分类识别,测量精度达到了0.01mm,相对误差低于2%。针对光学元件透明焊缝表面缺陷检测方法做了理论研究,通过高斯平滑曲线进行滤波处理,采用Plessey算法进行角点的提取和匹配,完成图像的拼接融合、缺陷、的特征提取和面积计算。采用检测精度、图像清晰度、检测准确率以及判别正确率四个指标进行缺陷面积测试,通过灰度平均梯度验证图像清晰度,再通过有无光照两种环境验证检测准确率。试验结果表明,所提方法的判别正确率达到90%以上。
{URL}: https://link.cnki.net/doi/10.27721/d.cnki.gyzjc.2022.000004
{DOI}: 10.27721/d.cnki.gyzjc.2022.000004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv3与改进VGGNet的车辆多标签实时识别算法
{Author}: 顾曦龙;宫宁生;胡乾生
{Author Address}: 南京工业大学计算机科学与技术学院;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: S2
{Pages}: 542-548
{Keywords}: 计算机视觉;车辆识别;多标签识别;目标检测;深度学习
{Abstract}: 为了能快速、有效地识别视频中的车辆信息，文中结合YOLOv3算法和CNN算法的优点，设计了一种能实时识别车辆多标签信息的算法。首先，利用具有较高识别速度和准确率的YOLOv3实现对视频流中车辆的实时监测和定位。在获得车辆的位置信息后，再将车辆信息传入经过简化与优化的类VGGNet多标签分类网络中，对车辆进行多标签标识。最后将标签信息输出至视频流，得到对视频中车辆的实时多标签识别。文中训练与测试数据集来源为KITTI数据集和通过Bing Image Search API获取的多标签数据集。实验结果证明，所提方法在KITTI数据集上的mAP达到了91.27，多标签平均准确率达到80%以上，视频帧率达到35fps，在保证实时性的基础上取得了较好的车辆识别和多标签分类效果。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwjh7O9leKQShgDW3iM84cUUJVgjiUugviaJk8MjXEdNb4gHRUaveNWJ3OM1yZ-DB445AjtwMhUO-i_TR-LUsQ8n0Fnc-84NVpIMgs4CmlRtcJB78XJto6QMyfk6SUJJgQROVxZvDOCCJkRhV7eckIe3cxuZILZvR_Y1M_A3QbJTke0Z-ZJF_yWlawrUDzMRDs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的全元素赛道智能小车实验系统设计与应用
{Author}: 俞洋;李峰;缪奕扬
{Author Address}: 江苏理工学院电气信息工程学院;
{Journal}: 中南民族大学学报(自然科学版)
{Year}: 2022
{Volume}: 41
{Issue}: 06
{Pages}: 689-696
{Keywords}: 机器视觉;智能小车;实验系统;复杂工程问题
{Abstract}: 设计了一种在全元素赛道上自动行驶的智能小车实验系统.采用TC264D单片机作为核心控制单元，CMOS摄像头获取车体前方的赛道信息，单片机进行图像处理获得赛道中线，计算方向偏差后控制舵机打角调整小车行驶方向；采用模糊控制实时调整舵机PD控制参数，进一步实现路径方向实时调整的闭环控制.实验结果表明：智能小车能够在全元素赛道上稳定行驶，可以设计出满足复杂工程问题要求的多种实验方案，具有在智能小车创新设计实验和本科工程教育中推广与应用的价值.
{ISBN/ISSN}: 1672-4321
{Notes}: 42-1705/N
{URL}: https://link.cnki.net/doi/10.20056/j.cnki.ZNMDZK.20220608
{DOI}: 10.20056/j.cnki.ZNMDZK.20220608
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉交互技术的采摘机器人系统设计
{Author}: 苏文芝
{Author Address}: 济源职业技术学院;
{Journal}: 农机化研究
{Year}: 2023
{Volume}: 45
{Issue}: 08
{Pages}: 228-230+234
{Keywords}: 采摘机器人;草莓采摘;机器视觉;末端执行器
{Abstract}: 以草莓采摘作业过程为研究对象，对草莓自动采摘时出现的损伤现象进行分析，提出一种利用机器视觉交互实现草莓准确识别定位的自动采摘系统，并搭建草莓采摘机器人电气控制模块和机械模块，同时进行系统验证试验。结果表明：在相同的作业环境条件下，在图像采集时进行光源辅助，能够有效提高采摘作业可靠性；通过对不同条件下采摘作业时间进行统计，得出草莓采摘机器人完成单个草莓采摘作业的时间约为10s。此采摘系统可为智能化采摘机器人的设计提供技术参考。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2023.08.002
{DOI}: 10.13427/j.cnki.njyi.2023.08.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5深度学习的茶叶嫩芽估产方法
{Author}: 徐海东;马伟;谭彧;刘星星;郑永军;田志伟
{Author Address}: 中国农业大学工学院;中国农业科学院都市农业研究所;
{Journal}: 中国农业大学学报
{Year}: 2022
{Volume}: 27
{Issue}: 12
{Pages}: 213-220
{Keywords}: 茶叶估产;茶叶嫩芽识别;机器视觉;YOLOv5
{Abstract}: 针对丘陵地区小规模茶园估产难度高，估产手段少等问题，采用基于YOLOv5的目标检测算法和田间抽样调查法，对丘陵地区小规模茶园估产问题进行研究。在茶园中随机抽取9个有代表性的茶叶生长点；使用目标检测算法识别抽样点茶叶嫩芽数目；利用最小二乘法拟合茶叶嫩芽产量与数目间的线性关系；结合抽样点识别出的嫩芽数目、抽样点面积、线性拟合关系和茶园整体面积估算出茶园茶叶嫩芽产量。结果表明：1)基于YOLOv5的目标检测算法对茶叶嫩芽识别的精度为99.02%，平均准确率为90.14%;2)茶叶嫩芽数目和产量间有高度线性关系，决定系数R2为0.999 8;3)通过算法估计的茶叶嫩芽产量与实际采收产量相对误差为29.56%。本研究能够较为方便的估算出茶园茶叶嫩芽产量，在茶叶生长时期为农户提供产量相关的数据支持，便于茶叶生产的前期管理。
{ISBN/ISSN}: 1007-4333
{Notes}: 11-3837/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxLgmQhoRX5UM52o0Wu0fd6_KPRkGQ-5WuKJ1q2YLjRdr_VjBmpMpBy3Nr7cpw_TlNXxj4pbwHkRF6FXOtbyGFMjMvGskiBwJ1vdXidaf3hRMgN95B5cmwPeYqYvVXJu7FdfPIySoE-nSNgvfhMVavrh2lUdIlPBu8w9abYY4gQMk3Za7GL6AnYXgSHwaXFgD8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向不同模态的图像显著性检测模型理论与方法研究
{Author}: 梁艳花
{Tertiary Author}: 秦贵和
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度学习;显著性目标检测;多模态;特征提取与融合;端到端学习;编码器-解码器结构
{Abstract}: 视觉显著性(Visual Saliency)是视觉感知与场景理解的重要研究内容,涉及认知神经科学、认知心理学、计算机视觉等多个学科。一个场景的显著性区域通常具有人类感兴趣的物体或目标,是能够在较短时间内吸引人视觉注意力的区域。显著性目标检测的目的就是找出给定自然图像中那些感兴趣的目标或区域的过程。近几年来,显著性目标检测已经成为一个热门的研究方向,吸引了越来越多研究者的关注。作为一项基础且重要的视觉任务,显著性目标检测被引入到图像处理中,用于自动定位、预测和挖掘符合人类认知的重要视觉信息,过滤不重要的背景信息,提高信息的处理效率,降低模型计算量。同时,显著性检测能够提供有效的先验性引导信息,可以被应用于弱监督语义分割、目标跟踪、图像编辑等任务中,辅助它们的实现。此外,随着软硬件技术的迅速发展,显著性检测技术在自动驾驶、工业机器人、人机交互等尖端领域也发挥越来越重要的作用。由此可见,显著性检测算法的研究具有广泛的应用前景和深远的科学意义。根据处理图像模态的不同,显著性目标检测衍生出多个不同的子分支,包括以RGB图像为输入的单模态显著性检测;以RGB和深度图为输入的多模态RGB-D显著性检测;以RGB和热红外图像为输入的多模态RGB-T显著性检测;以全聚焦和焦点堆栈为输入的多模态光场显著性检测等。在显著性检测领域,基于RGB图像的研究已经取得了较大的进展。但是,仍然存在显著目标结构分割不完整,提取的目标边缘粗糙、模糊等问题。而相较于RGB单模态显著性检测任务,针对多模态显著性检测的研究还需要进一步深入展开。特别地,当前对基于RGB-T和光场的显著性检测还处于研究初期。基于此,本文依托有效的深度学习理论,围绕上述四种不同输入模态的显著性检测展开相关研究,致力于提出精确、鲁棒的检测算法。具体来说,本文的主要工作和贡献如下:1.语义与细节协同学习的RGB显著性检测算法SDCLNet为了获得精确的显著性预测图,目前的方法主要聚焦于在类U-Net结构中集成多层特征,或引入边缘信息辅助监督。与现有方法关注的重点不同,本文研究了语义和细节在显著性检测中的不同作用,将显著性检测任务分解为内部语义估计和边界细节预测两个并行的子任务,并通过显式约束对各子目标进行优化。具体地,首先采用具有附加层的主干网作为共享编码器,从每幅RGB图像中提取多尺度特征。然后,设计了两个非对称解码器。其中,语义解码器生成粗糙语义掩模,细节解码器生成细粒度的目标边界。最后,一个协作学习块自适应地选择判别特征进行显著性预测。通过这种方式可以有效地融合语义特征和细节信息,生成准确、一致的显著性图。在六个基准数据集上的实验结果表明,所提模型生成的显著性图在主观视觉感知和客观评价指标方面均具有有效性和优越性。2.跨模态多重增强金字塔结构的RGB-D显著性检测算法CMPNet深度图包含几何线索,可以提供有价值的补充信息进而提高显著性检测的性能。现有基于RGB-D的显著性检测方法多采用早期融合、晚期融合或中间融合的方式来探索RGB图像与深度图之间的相关性。然而,这些融合策略未能充分捕捉跨模态和多尺度融合特征。为此,本文提出了一种基于多流结构的多模态增强金字塔网络用于RGB-D显著性检测。具体地,RGB、深度图和它们的组合首先被作为三流主干网的输入以显式地捕获两种模态的个性和共性。然后,设计的跨模态多增强块鼓励来自三个源的跨模态特征在每个网络层上进行综合交互,从而形成多模态金字塔特征。此外,为了将注意力集中在高层语义特征和低层空间结构特征上,提出了一个多尺度特征注意力块来处理不同层。最后,通过跨层融合注意块集成不同层的特征,生成预测的显著性图。实验结果表明,所提算法在五个具有挑战性的基准数据集上的性能优于同时期的其他算法。3.多模态交互注意及双解码的RGB-D/T显著性检测算法MIA-DPD基于RGB的显著性检测算法在处理目标轮廓模糊、前景与背景对比度低等具有挑战性的场景时表现的并不令人满意。为了缓解这一问题,基于RGB-D或RGB-T的显著性检测任务被提出。然而,当前它们通常被视为两个独立的视觉任务。而且,其中大多数方法直接从主干网中提取和融合特征。本文探索了这两个任务之间的潜在共性,提出了一个端到端的统一框架用于RGB-D和RGB-T的显著性检测。具体地,多模态交互注意模块有效地从每个模态中捕获丰富的多层上下文特征,作为特征编码和跨模态解码之间的桥梁。联合注意力引导的跨模态解码模块和多级特征渐进解码模块分别从多源特征和不同层次的融合特征中逐步集成互补特征。分别在RGB-D和RGB-T基准数据集上的实验结果表明,所提算法相较于已有算法在检测精度和模型泛化性方面表现良好。4.双重引导增强的光场显著性检测算法DGENet利用光场数据作为输入的显著性检测模型还没有得到深入研究。现有的深度显著性模型通常将多焦点图像作为独立的信息,单独提取其特征。这类方式可能比较繁琐,且过于依赖设计良好的网络结构。此外,它们没有充分挖掘信息的跨模态互补性和跨层次连续性,很少考虑显著边缘线索。基于上述分析,本文提出了一种考虑空间内容和明确边界线索的双重引导增强网络。具体地,所提模型包含两个关键组件:循环全局引导聚焦模块和边界引导语义积累模块。前者用于提取焦切片和RGB图像在不同网络层间的有效压缩信息,学习到的全局上下文特征通过渐进的反向注意驱动策略引导网络关注显著区域。后者引入显著边缘特征引导显著目标特征的积累,生成边界清晰的显著性图。在三个基准光场数据集上的实验结果表明,所提算法优于同时期的2D、3D和4D方法,而且能更有效地保证目标轮廓的完整性和锐利性。综上,本文从处理图像模态的不同提出一系列数据驱动的模型和方法,并采用理论分析与实验相结合的方式验证了它们的有效性。这些算法的提出丰富了视觉显著性检测领域的研究,为不同模态的图像显著性检测的发展起到了一定的促进作用。此外,本文给出了当前针对不同模态的显著性检测算法面临的问题与挑战,并展望了该领域未来的研究趋势。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.007785
{DOI}: 10.27162/d.cnki.gjlin.2022.007785
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的鱼类摄食行为识别及精准养殖研究
{Author}: 黄平
{Tertiary Author}: 万海斌
{Publisher}: 广西大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 精准投喂;摄食强度分类;图像处理;卷积神经网络;循环神经网络
{Abstract}: 高密度循环水养殖模式下,根据养殖鱼类的昼夜活动节律、摄食规律制定精准养殖策略是提高养殖效益的主要途径,提高饵料的利用效率,精准投喂是关键。传统的鱼类养殖主要采用人工或使用投料机定时定量的喂养方式,忽略了养殖环境对鱼类摄食的影响,未将鱼类的实际摄食需求作为投喂的参考因素,存在饵料投喂不足或投喂过量的情况,投喂不足引起鱼类营养不良,投喂过量导致饵料浪费、水质污染。本文以浮游型鱼类鲤鱼为研究对象,通过建立鱼类群体行为监测系统,实现了鱼类养殖过程的实时、长时监测。同时提出了一种融合近红外深度图时空特性的鱼类摄食强度的量化方法,通过对鲤鱼摄食强度的量化来精准评估鱼群的摄食欲望,根据鱼群的摄食欲望和养殖环境因素制定了一种基于模糊控制的投喂策略,实现了鱼类的精准养殖,本研究主要有如下几个方面:
(1)构建了一套多数据融合的鱼类群体行为监测系统,该系统由深度相机和上位机组成,深度相机作为前端成像设备,利用深度相机的近红外光主动成像技术克服了因养殖环境光照不足而引起的图像成像质量较差的问题。采用基于距离特征的图像处理方法对获取的深度图像进行预处理,实现了鱼群目标与背景分割,利用深度视频实现养殖过程的可视化监测。其次,提出了基于帧间差分法的鱼类群体行为强度的评估量化方法,该方法通过鱼类群体活动行为引起视频帧间像素值的变化量来评估鱼类群体行为强弱,使用此方法既可以对鱼类摄食强度进行量化也可对鱼类因缺氧、水质污染、饥饿等因素引起的应激行为进行评估,通过上位机对获取的深度视频数据的实时处理,获得了一种具有时空特性鱼类群体行为强度的序列数据,将此序列数据存储到数据库中,养殖过程中的鱼类群体活动行为被完整记录,与传统视频存储的方法相比,数据表所需存储空间更小,数据读取和分析更为便捷。
(2)鱼类摄食欲望是精准投喂控制的关键因素,鱼类摄食欲望的强弱可通过鱼类摄食强度来判别,而鱼类摄食强度可根据鱼群摄食图像或鱼群摄食行为强度数据来表征,本研究基于鱼群摄食深度图像设计了一种卷积神经网络识别模型,基于鱼群摄食行为强度序列数据设计了一种循环神经网络识别模型。试验分析表明,本研究所提出的两种方法在工厂化养殖环境下对鱼群摄食状态识别精度较高,两种识别的方法平均准确率为98%以上,为准确判断鱼类摄食欲望提供依据。
(3)以鱼群的摄食欲望和养殖环境作为主要决策因素,利用模糊控制理论计算每次投料总量,并采用基于鱼类摄食欲望反馈的投喂控制的方法来实现饵料的精准投喂,最终实现鱼类的精准养殖。
{URL}: https://link.cnki.net/doi/10.27034/d.cnki.ggxiu.2022.002497
{DOI}: 10.27034/d.cnki.ggxiu.2022.002497
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于宽带相位运动放大与机器视觉的结构振动频率识别
{Author}: 孔烜;罗奎;邓露;易金鑫;殷鹏程;冀伟
{Author Address}: 湖南大学土木工程学院;湖南大学工程结构损伤诊断湖南省重点实验室;中铁第四勘察设计院集团有限公司;兰州交通大学;
{Journal}: 土木工程学报
{Year}: 2023
{Volume}: 56
{Issue}: 10
{Pages}: 105-117
{Keywords}: 桥梁工程;模态识别;宽带相位运动放大;振动频率;机器视觉;非接触式;亚像素模板匹配
{Abstract}: 为了解决现有视觉技术难以准确测量结构微小振动的问题，该文提出了一种基于宽带相位运动放大(BPMM)和亚像素模板匹配算法的结构振动测量和频率识别方法。首先，利用相机拍摄结构的振动视频图像，并对图像中的噪声进行初步去除。其次，在不需要结构频率先验信息的情况下，在包含所有感兴趣频率的宽频带内进行滤波，选取合适的放大倍数进行微小振动视频的放大处理，再利用亚像素模板匹配算法从放大后的视频中提取结构的位移时程响应。最后，对提取的结构位移进行归一化处理，得到结构的实际位移时程响应，利用快速傅里叶变换(FFT)获取结构的振动频率。结果表明：BPMM算法既能实现结构微小振动位移幅值的放大，又能有效去除微小振动视频中的噪声，提高了图像的信噪比，从运动放大后的视频图像中可以准确地识别结构的振动频率。通过3层框架结构的室内试验和实桥试验对该文方法进行了验证，识别误差分别在1%和5%以内。该文方法可在不需要结构频率先验信息的情况下实现微小振动的盲放大处理，具有噪声鲁棒性好、计算量小及适用性强等优点，为结构微小振动测量提供了一种新思路，具有良好的应用前景。
{ISBN/ISSN}: 1000-131X
{Notes}: 11-2120/TU
{URL}: https://link.cnki.net/doi/10.15951/j.tmgcxb.22060550
{DOI}: 10.15951/j.tmgcxb.22060550
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向空间应用的视觉位姿估计技术综述
{Author}: 周芮;刘延芳;齐乃明;佘佳宇
{Author Address}: 哈尔滨工业大学航天学院;
{Journal}: 光学精密工程
{Year}: 2022
{Volume}: 30
{Issue}: 20
{Pages}: 2538-2553
{Keywords}: 计算机视觉;图像处理;位姿估计;深度学习;空间任务
{Abstract}: 随着人工智能的发展，基于计算机视觉的目标识别、位姿估计技术受到了广泛关注。目前，在交会对接等空间任务中，基于计算机视觉的合作目标位姿估计技术已取得广泛应用。但在非合作目标的视觉位姿估计问题上，由于空间中存在杂散光背景、表面包覆层反射、光照强度变化剧烈等因素，导致特征提取困难、位姿估计易发散、存在累计误差等难题，这些也是亟待解决的热点问题。本文首先总结了空间任务中计算机视觉技术的发展及应用；然后，对视觉位姿估计技术进行概述，以深度学习算法作为切入点，系统地归纳了目标识别及位姿估计算法；最后，综述了深度学习在空间任务中的研究进展，并在任务需求和研究现状分析的基础上，针对空间任务的特殊性，讨论了一些未来的发展趋势。
{ISBN/ISSN}: 1004-924X
{Notes}: 22-1198/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy-czPG31t2_P1yN-fJLLUzbZiPz_32Ms40zl7ZhWzrHCf4v0aHHaYscMsbLYP0vhMMlqsHhR59UdUZiMQf6E6CmxkgVktjj-DDS3CGoS-rkLNupP2bZ-uh8o9x_xPyCWYRQrCYjzoAYuf6LnPPDetukoptQSVj4gzYRlRaoYPdoN1VnzmsOLXNGc4FGebA2GA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在电力安全监控中的应用综述
{Author}: 王刘旺
{Author Address}: 国网浙江省电力有限公司电力科学研究院;
{Journal}: 浙江电力
{Year}: 2022
{Volume}: 41
{Issue}: 10
{Pages}: 16-26
{Keywords}: 机器视觉;目标检测;目标分割;目标跟踪;安全监控
{Abstract}: 视频监控对保障电网安全稳定运行起着不可忽视的作用。随着人工智能技术的发展，机器视觉在电力安全监控中表现出巨大的应用潜力。首先概述了机器视觉领域主要关注的目标检测、目标分割、目标跟踪三大任务；然后从设备状态、人员状态、环境状态三个角度出发，总结分析了机器视觉技术在输变电设备状态检测、人员状态判别、重要区域环境状态监测三大典型应用场景的应用及研究进展；最后就机器视觉技术在电力安全监控领域落地应用存在的问题进行分析并提出了相关建议。
{ISBN/ISSN}: 1007-1881
{Notes}: 33-1080/TM
{URL}: https://link.cnki.net/doi/10.19585/j.zjdl.202210003
{DOI}: 10.19585/j.zjdl.202210003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的刚体位姿估计方法综述
{Author}: 郭楠;李婧源;任曦
{Author Address}: 东北大学计算机科学与工程学院;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 02
{Pages}: 178-189
{Keywords}: 计算机视觉;刚体目标;位姿估计;位姿优化;深度学习
{Abstract}: 刚体位姿估计旨在获取刚体在相机坐标系下的3D平移信息和3D旋转信息，在自动驾驶、机器人、增强现实等快速发展的领域起着重要作用。现对2017-2021年间的基于深度学习的刚体位姿估计方向具有代表性的研究进行汇总与分析。将刚体位姿估计的方法分为基于坐标、基于关键点和基于模板的方法。将刚体位姿估计任务划分为图像预处理、空间映射或特征匹配、位姿恢复和位姿优化4项子任务，详细介绍每一类方法的子任务实现及其优势和存在的问题。分析刚体位姿估计任务面临的挑战，总结现有解决方案及其优缺点。介绍刚体位姿估计常用的数据集和性能评价指标，并对比分析现有方法在常用数据集上的表现。最后从位姿跟踪、类别级位姿估计等多个角度对未来研究方向进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20221019.1803.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与无人机的结构动位移测量方法
{Author}: 韩怡天;冯东明;吴刚
{Author Address}: 东南大学混凝土及预应力混凝土结构教育部重点实验室;东南大学智慧建造与运维国家地方联合工程研究中心;
{Journal}: 振动与冲击
{Year}: 2022
{Volume}: 41
{Issue}: 19
{Pages}: 1-7
{Keywords}: 位移测量;模态参数识别;无人机(UVA);机器视觉;相机运动修正
{Abstract}: 针对基于视觉的结构位移测量方法中相机分辨率不足或测量基站位置选取困难等局限，提出一种结合机器视觉与无人机的结构动位移测量方法。以静止激光灯投射在结构表面的激光光斑为参考，设计算法自动检测目标测点和激光光斑位置，逐帧计算并更新比例因子，估计并消除无人机自身的运动，从而计算目标测点的绝对位移；为验证该方法的准确性，设计一个小型框架模型试验，随后又将此方法应用于大型地震模拟振动台试验。结果表明，利用无人机进行视觉测量得到的位移响应与激光位移计和加速度计测得的参考数据具有良好的一致性，在结构动位移测量和模态参数识别上均能较好地应用。
{ISBN/ISSN}: 1000-3835
{Notes}: 31-1316/TU
{URL}: https://link.cnki.net/doi/10.13465/j.cnki.jvs.2022.19.001
{DOI}: 10.13465/j.cnki.jvs.2022.19.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智慧渔业中的机器视觉技术应用研究现状
{Author}: 魏巍宏
{Author Address}: 厦门海洋职业技术学院海洋机电学院;
{Journal}: 河北渔业
{Year}: 2022
{Volume}: 
{Issue}: 10
{Pages}: 36-39+44
{Keywords}: 智慧渔业;机器视觉;信息参数化;图像分析
{Abstract}: 通过整理分析国内外相关文献资料，从鱼类摄食行为识别与精准饲喂、鱼体参数识别与测量、鱼群病害诊断与防治3个应用角度，对机器视觉技术在智慧渔业领域的研究现状进行详细阐述，并对基于机器视觉技术的智慧渔业系统的优缺点和适用场景进行了总结，最后提出了复杂水体环境下的鱼体分割和鱼体交叠等方面的研究趋势和发展方向。
{ISBN/ISSN}: 1004-6755
{Notes}: 13-1145/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwsxy5JBu2KE0L7RyJN1zvGIU9Fa6ml9r_5fOe67lMnTTohJQGg_jcqp7Ti0UKhf1sBH5d1tzMftcbytW7iFlA8SD-LslwHrfqEyrCkpXyglHJ8HG5S9TJo-TTWfJMIRXVslgmM3kUCP4iPSd5NBZl1hg4jEWwoyCjgsk5N8RDp8rcTJA9JzAz73C5-En8Yzco=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的SOP芯片引脚缺陷检测系统
{Author}: 王建冲;高军伟;张炳星;刘佳浩
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 工业仪表与自动化装置
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 32-37
{Keywords}: 机器视觉;改进的边缘检测;连通域标记;灰度投影;缺陷检测
{Abstract}: 针对传统工业中SOP芯片引脚缺陷检测速度慢、精度低等问题，设计了一个基于机器视觉的SOP芯片引脚缺陷检测系统，通过MATLAB软件调用CCD相机采集芯片图像，采用改进的Canny边缘检测等算法实现引脚边缘的连接，采用连通域标记和灰度投影算法对得到的二值芯片引脚图像进行缺陷检测并完成GUI界面的设计。由实验数据可知，系统对芯片引脚缺陷检测的正确率为99.6%,测量误差在±0.03 mm之内，满足了工业生产中SOP芯片引脚缺陷检测实时性和准确性的需求。
{ISBN/ISSN}: 1000-0682
{Notes}: 61-1121/TH
{URL}: https://link.cnki.net/doi/10.19950/j.cnki.cn61-1121/th.2022.05.006
{DOI}: 10.19950/j.cnki.cn61-1121/th.2022.05.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的图像处理技术研究
{Author}: 张立坤
{Author Address}: 黑龙江东方学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 19
{Pages}: 189-191
{Keywords}: 计算机视觉;图像处理技术;畸变矫正算法
{Abstract}: 随着科技的不断发展，计算机视觉图像处理技术被广泛应用于检测等多个领域，为现代社会发展提供了大力支持。基于此，简单介绍了计算机视觉图像处理技术的特点，研究了计算机视觉图像处理技术。为了降低畸变对图像处理的影响，设计了一种矫正算法，以期为改善图像处理效果提供支持。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzf6tBpsrXCGx5SOExmfAKNIbKpBZFsXVwOzF_9sFyv0ho_dMRG_Hnm7YaJ-C4fjwxgj5C7npGX6SIUZrM8fDOy9wDd5o8unu69-_dLPxS1cQCmP7_J8RS8f8jfXuUcqfVeAN4D0fDld-y5HBl73OF9goHNZWySv8_T6zD4_mflzyKSmB5C-Rdv3btBC_wOgvE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于HALCON的汽车牌照识别技术研究
{Author}: 岩淑霞
{Author Address}: 苏州健雄职业技术学院;
{Journal}: 机械工程与自动化
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 28-30
{Keywords}: 机器视觉;HALCON;车牌识别
{Abstract}: 车牌识别在智慧交通系统中发挥着非常重要的作用，基于HALCON机器视觉软件设计了汽车牌照识别系统。车牌图像的识别过程主要包括图像的加载与预处理、ROI的确定、寻找算子和确定参数。对含有较复杂汉字的车牌照片进行了识别实验，实验结果表明所提出的算法识别精度较高，达到了应用要求。
{ISBN/ISSN}: 1672-6413
{Notes}: 14-1319/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyHHnmnc_1LSQk_CiVc9Ko5rntbWHwjNzydhpdHhN1o_-gZo82RerGkhoYtxZv6Fycqujfhgn0kZQQzGQHc1VjjUs3Wrk8eShcAtiwOF6RSr11nklutFRrWfaBUScf9A1NTpkqHUQzWpGZi5AWXHW38WQv4aBelacsPFpPz2UAVeeViWh1526WRYpSsyX0yXCQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和深度学习的车辆碰撞预警算法研究
{Author}: 申海洋;霍魁;王德喜
{Author Address}: 巢湖学院电子工程学院;山西大学物理电子工程学院;科大智能科技股份有限公司;
{Journal}: 山西大学学报(自然科学版)
{Year}: 2023
{Volume}: 46
{Issue}: 03
{Pages}: 617-627
{Keywords}: 碰撞预警;机器视觉;霍夫变换;深度学习
{Abstract}: 车辆行驶中，常因跟车过近引发碰撞事故，针对这一问题，研究提出一种基于机器视觉和深度学习的车辆碰撞预警算法。首先，利用图像处理方法对车道线进行检测，根据不同车速设置不同范围的安全区域。再利用深度学习卷积神经网络对视野中车辆目标进行检测，当目标侵入安全区域时发出碰撞预警提示。实验结果表明，文章算法能有效地对潜在碰撞威胁进行预警，对碰撞威胁检测的查准率和查全率有着较好的表现。将其应用在车辆驾驶中可有效地提高行车安全，具有实际应用价值。
{ISBN/ISSN}: 0253-2395
{Notes}: 14-1105/N
{URL}: https://link.cnki.net/doi/10.13451/j.sxu.ns.2022075
{DOI}: 10.13451/j.sxu.ns.2022075
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的零件尺寸测量及分析
{Author}: 曹丽芳;黄志辉;张元;邹杰;彭辰晨;焦祥
{Author Address}: 无锡职业技术学院;
{Journal}: 南方农机
{Year}: 2022
{Volume}: 53
{Issue}: 19
{Pages}: 134-137
{Keywords}: 机器视觉;尺寸测量;图像处理分析;算法设计;连接块
{Abstract}: 课题组设计的基于机器视觉的零件尺寸测量系统以尼龙材质注塑成型、后期经铣床加工制成的U形连接块为研究对象，测量其上表面面积、周长以及加工孔半径。课题组优先选用5×5平滑滤波器进行图像预处理，利用Roberts算子进行边缘检测分割，再利用数学形态学算法(开运算、闭运算)锐化边缘，最后利用标板给予的标定系数，将图像上零件尺寸的像素值转换成物理空间的实际测量尺寸。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxzQVbevyV5pe2m6VEx4_Y4heE8XugaL81PYe0hIgVOgfP9zNzABpeYO-IpYaIgmo9yLGqsKE47W6mOJBcbmQYyC4nP3zUwnovOlRXs0otW2F5GYsr0s8hkZAHAByXHAufZBfcdrlBa_uT0vl4Shm1I4kP677Wugy2rlhVwR8TaK2WCFWq5zdOnpVLBAfG-y_Y=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的数字图像处理系统设计
{Author}: 许春和;孙培刚;张全禹;罗永辉
{Author Address}: 绥化学院;
{Journal}: 大众标准化
{Year}: 2022
{Volume}: 
{Issue}: 19
{Pages}: 128-130
{Keywords}: 机器视觉;数字图像;系统设计
{Abstract}: 数字图像技术在多个领域得以广泛应用，为了提升图像处理效果，文章基于机器视觉技术，提出数字图像处理系统设计，借助该技术，从不同模块进行设计，如数字图像收集器、数字图像清晰度指标、图像编辑、图像设置等，通过规范处理数字图像，促进其质量的提升，从而实现预期目标。
{ISBN/ISSN}: 1007-1350
{Notes}: 14-1101/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw1mOAJ1gpGikh5nbL2VWseldVxlTQHY7S6ZbTzcPYIv0EaKJP46xZy1ER7TxtM1XMTHcJasq44NpVnFUkzGlscC1P30SVHVYsjeCPE1JAB-kWXkLMCwkFYB1pgFa_wJM_vg7UuC-F0ZXT9JuuqFXEJoKQ__rwBJkrXt-p89HyDEBBaZT4OYspH_cmR2p8C26k=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向复杂场景的单图像深度去雨技术研究
{Author}: 韦炎炎
{Tertiary Author}: 汪萌;张召
{Publisher}: 合肥工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 单图像去雨;深度学习去雨;图像复原;无监督学习与自动雨生成;多退化类型去雨;语义分割信息引导去雨
{Abstract}: 单图像去雨技术主要研究如何从具有复杂分布的雨图中提取出雨纹信息,同时复原出干净背景,这对提升底层视觉感知和高层认知理解能力具有重要意义。和传统的单图像去雨方法相比,基于深度学习的单图像去雨技术已取得突破性进展。但是由于雨图分布的多样性与复杂性,以及应用场景的日益复杂化,单图像去雨领域仍有一些挑战性问题亟待解决:(1)现有图像去雨方法大多采用监督学习方式,即训练数据为合成的配对数据,但是合成数据的雨分布与真实雨分布存在很大差异,导致其在真实场景中的泛化性较差;(2)现有研究大多集中于消除单一类型的雨退化,无法同时处理多种类型的雨退化(如雨纹、雨滴和雨雾等),导致其在真实场景中的鲁棒性不足;(3)现有研究大多只是单纯考虑单图像去雨任务,忽略了与高层视觉任务的交互和联系,导致去雨结果在后续高层任务上的性能欠佳。本文将上述三个挑战性问题归纳为复杂场景中的真实场景去雨泛化性差、多退化类型去雨鲁棒性差,以及去雨与高层任务间缺协同交互。三个问题联系紧密且难度由浅入深,从单一雨退化场景拓展到多种雨退化场景,进而拓展到底层和高层任务协同场景。针对上述问题,本文系统提出相应的创新策略,主要贡献总结如下:(1)针对深度监督去雨方法过度依赖合成的配对数据,以及合成数据和真实数据分布差异过大导致的模型泛化性差的问题,本文在第三章重点探讨基于非配对数据的无监督深度去雨模式,系统提出了一种基于无监督雨纹注意力检测器的单图像去雨与雨生成算法Derain Cycle GAN。该方法充分利用了Cycle GAN的循环结构和迁移学习能力来进行无监督模式下的训练学习;设计了一种无监督雨纹注意力检测器(URAD),通过同时关注有雨图和无雨图来增强雨纹信息检测能力。在无监督模式下,该方法可学习到真实场景雨图的分布,因此模型具有强大的泛化能力。此外,还提出了一种新的可自动生成多样化雨纹的合成方式,生成的雨纹具有更加复杂的形状和方向,可以帮助现有监督方法更好地泛化到真实的雨图上。(2)针对现有大部分深度去雨方法只能处理单一雨退化类型(如雨纹或雨滴),以及在真实场景上的去雨鲁棒性不足的问题,本文在第四章重点探讨多种雨退化现象的处理方法,系统提出了一种可处理多种雨退化类型的鲁棒性单图像去雨方法Rad Net。该方法首先设计了一个轻量级的鲁棒注意力模块RAM,采用的通用注意力机制可同时关注雨纹和雨滴;此外,提出了一个基于双通道残差密集块的多尺度深度复原模块DRM,可用于精确去除雨纹。该模型具有强大的鲁棒性,不仅可以处理不同类型的雨退化现象,包括雨滴、雨纹,或两者兼而有之,还可以有效处理不同的数据范式,包括单一类型、叠加类型和混合类型。(3)针对现有深度去雨方法大多只关注底层复原效果,忽略了与高层语义信息进行交互,导致复原结果在后续高层任务上性能不足的问题,本文在第五章重点探讨图像去雨与语义分割任务的协同交互,系统提出了一种基于高层语义分割信息引导的单图像去雨方法SGINet。该方法设计了一种三阶段去雨方式,先基于设计的全分辨率模块FRM来预测没有上下文语义损失的粗糙去雨图像,然后利用预训练好的语义提取模块SEM提取粗糙去雨图像中的语义信息,再通过语义交互模块SIM实现语义分割信息引导下的去雨。通过衔接去雨和语义分割任务,该方法可同时取得更好的去雨结果和高层语义分割结果。此外,还基于Cityscapes数据集构建了合成雨图数据集Cityscapes＿syn和真实雨图数据集Cityscapes＿real,可用于同时评价图像去雨任务和语义分割任务的性能。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000062
{DOI}: 10.27101/d.cnki.ghfgu.2022.000062
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾分类检测系统设计
{Author}: 曹胡锴;刘致轩;雷丹;肖书浩;孟凡非
{Author Address}: 武昌首义学院机电与自动化学院;
{Journal}: 电子制作
{Year}: 2022
{Volume}: 30
{Issue}: 19
{Pages}: 55-58
{Keywords}: 机器视觉;深度学习;ResNeXt101;卷积神经网络;垃圾分类
{Abstract}: 随着人们的生活水平不断地提高，日常垃圾的急剧增加，绝大部分的垃圾都可以通过回收再重新利用起来，避免了资源的极大浪费。本文使用百度深度学习平台PaddleX开发出基于机器视觉的垃圾分类检测系统，该系统训练模型时使用了华为云垃圾分类挑战赛开源数据集。该系统运用ResNeXt101卷积神经网络，实现了数据集和图像预处理、基于PaddleX的垃圾分类训练过程、试验过程所用到的计算机环境配置以及网络模型部分参数设置的研究。实验结果表明：该模型具有很好的鲁棒性，垃圾种类的识别准确率达到99%以上。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2022.19.018
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2022.19.018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的图像转换方法
{Author}: 李茹
{Tertiary Author}: 刘光辉
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像转换;深度学习;生成对抗网络;细节保持;信息融合
{Abstract}: 近年来,随着计算设备的快速发展以及计算能力的提高,计算机视觉获得了广泛的关注。图像转换是计算机视觉中的新兴领域,旨在学习不同视觉域之间的关系并实现不同域之间的映射。图像转换的研究广泛应用在社会生产、生活的各个方面。例如,电视电影的视觉效果制作时可以使用图像转换生成指定风格的图像或视频、极大减少人工绘制的时间;在智能交通领域和安全监控领域可以将图像从输入域转换到标签域、更好的定位人或车辆;在医学领域,转换后的图像可以更好地定位病灶区域。研究生成图像质量高的方法是当前图像转换的主要研究方向。图像转换方法需要在学习目标域图像特性的情况下保持源域图像的内容,但当前图像转换方法存在重要内容丢失问题、有效信息获取能力较弱问题、多输入信息融合时的鬼影问题以及光照失真问题。近几年,生成对抗网络(Generative Adversarial Networks,GAN)的快速发展为图像转换提供了新的思路。GAN的网络设计自由度较高,且在生成多样性、可解释性数据方面表现出优异的性能。本文选择生成对抗网络作为基础框架,针对当前图像转换中存在的问题,开展了相关研究。首先设计基于单输入的局部显著性图像转换算法解决细节丢失问题,之后在此框架基础上引入图像重组作为预训练任务感知图像内容信息,然后将单输入扩展为多输入,设计基于图像融合的多输入图像转换算法解决鬼影问题,设计基于本征分解的多输入图像转换算法解决光照失真问题。主要工作如下。第一、针对图像转换过程中重要内容丢失问题,将显著性检测引入到图像转换算法中,保证生成的图像在显著性区域也有很好的细节保持。在经典GAN框架基础上,引入一个与生成器并行的显著性检测网络,生成显著性掩码图。该掩码图一方面优化显著性网络,另一方面约束生成器来保持输出图像在显著性区域的内容。相比经典的图像转换方法,该框架转换结果的FID(Fréchet Inception Distance)指标提升约15%。第二、针对图像转换过程中有效信息获取能力较弱的问题,提出使用图像重组作为预训练任务感知图像内容信息,并将图像重组网络参数迁移至图像转换网络提升其性能。对于图像重组任务,设计基于GAN的双分支框架分别关注局部信息和全局信息,有效重组打乱的图像块。之后,训练基于图像重组网络参数的图像转换网络。实验结果证明:迁移图像重组网络训练参数到基于显著性检测的图像转换框架中,可得到FID指标约8%的提升。第三、针对图像转换过程中多输入信息融合时的鬼影问题,设计基于多输入的生成器和基于最小池化模块的判别器,保证网络从多输入获取更多场景信息的同时有效处理场景中动态物体带来的鬼影问题。生成器实现多输入单输出的转换,输出结果的内容信息比任何一张输入都更加丰富。基于最小池化模块的判别器解决特征融合过程中动态物体带来的模糊与鬼影问题。与基于图像重组的单输入转换方法相比,可得到FID指标约11%的提升;相较于经典多输入图像转换方法,该框架取得最高的PSNR值。第四、针对图像转换过程中光照失真的问题,提出基于本征分解的多输入图像转换框架,使网络更好的关注图像转换过程中的场景光照信息。输入图像中场景光照信息的丢失会生成不合理的结果。本征分解将图像分解为反射图和阴影图,其中阴影图可以有效表示光照信息在场景中形成的高光和阴影。基于生成对抗网络的多输入图像转换框架先使用两个编码器提取反射图和阴影图的特征,之后再设计两个解码器分别将特征恢复为目标图像和光照图,光照图用来约束目标图像高光与阴影信息的保持。与基于图像重组的单输入转换方法相比,FID提升约4%;与经典多输入图像转换方法相比,FID值提升约10%。本文借助生成对抗网络拟合源域和目标域的数据分布,解决图像转换方法中的关键问题,实现高质量的图像转换,为图像转换研究提供了新的探索方向。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004807
{DOI}: 10.27005/d.cnki.gdzku.2022.004807
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 小样本实例分割综述
{Author}: 周雪茗;黄定江
{Author Address}: 华东师范大学数据科学与工程学院;
{Journal}: 华东师范大学学报(自然科学版)
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 136-146
{Keywords}: 小样本学习;实例分割;计算机视觉
{Abstract}: 实例分割是计算机视觉领域中的一项重要任务,近年来元学习和小样本学习的发展推动了小样本与计算机视觉任务的结合,突破了对人工标注难、标注成本高的目标检测与分类瓶颈.虽然在小样本图像分类、小样本语义分割和小样本目标检测上都取得了较大的发展,但是基于小样本学习的实例分割近年来才成为研究热点.从小样本实例分割的相关概念出发,对现有小样本实例分割方法,按照基于锚框和无锚框两类分别进行了系统性的概述,并介绍了小样本实例分割常用的数据集及评价指标.通过对算法性能和优缺点的分析对比,以及研究现状的整理归纳,对小样本实例分割未来发展方向和面临的挑战进行了展望.
{ISBN/ISSN}: 1000-5641
{Notes}: 31-1298/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw5FOev8ueJRhVVTAVNwLQVIW0c0AB3mF5SO9gYQ4-HpfNGPL_j1XWzD5X9es37Q-3I0RfIKlxUI6lpLc3rI9HqESbXm-wsU8VjXodBxSOTRmlA6EIP8-hTI6ZS78lnk1kqoTORZtuC8R1YSgHDEc0mPHwY5koIL_9aHo6dnpsCsMLJskFqesftJx8aUqprGbw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Transformer的小目标车辆精确检测算法
{Author}: 谢光达;李洋;曲洪权;孙再鸣
{Author Address}: 北方工业大学电气与控制工程学院;北方工业大学信息学院;华北电力大学控制与计算机工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 18
{Pages}: 364-371
{Keywords}: 机器视觉;车辆检测;小目标;图像增强;视觉Transformer
{Abstract}: 智能交通系统的建立离不开车辆检测技术。目前的主流方案是使用卷积神经网络（CNN）架构进行车辆检测，然而在复杂交通场景中，远距离小目标像素点少，CNN的下采样机制导致提取的特征缺乏充足的上下文信息，因而小目标检测面临极大挑战。针对这个问题，提出了一种基于视觉Transformer的小目标车辆检测算法。所提算法通过改进Transformer的线性嵌入模块，补充小目标的线性嵌入信息；对图像进行层级构建，每层仅对局部进行关系建模，同时扩大感受野，代替CNN提取出更强有力的小目标车辆特征，实现端到端的精确检测。在UA-DETRAC车辆数据集上进行验证，实验结果表明，改进后的车辆检测算法提高了对远距离及严重遮挡情况下小目标的检测性能，检测精度达到99.0%。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwjo9y6FL74826aIDz29-_eULH0ajeSFddRVEqm6XLlzjj4n0dPboDzX02Z5uGyzEOVPb2HqLSQrHDfHDP2dFEQacoI0hpUDcq9GiIXZzK05dTTBLjPcRSTHzrVIOjE4FVLLrln6Hn9VHvVhMiJXTudVmbvheAUVzrqh1V55HwBfDAHiYeIHsfezGyd2oWzukQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在木制品制造中的应用
{Author}: 王祺;冯鑫浩;史诗琪;杨兆哲;詹先旭;吴智慧
{Author Address}: 南京林业大学家居与工业设计学院;江苏省林业资源高效加工利用协同创新中心;中国林业科学研究院林产化学工业研究所;德华兔宝宝装饰新材股份有限公司;
{Journal}: 木材科学与技术
{Year}: 2022
{Volume}: 36
{Issue}: 05
{Pages}: 17-24
{Keywords}: 机器视觉;木材工业;木制品;深度学习;缺陷检测;质量管控
{Abstract}: 在概述机器视觉国内外研究现状的基础上，分析基于机器视觉技术的图像采集、特征提取、识别分类等理论与算法研究；重点阐述机器视觉在木制品原材料树种识别、原木检尺和锯材分等、木制品缺陷检测、木制品表面颜色分析等领域的应用，并结合当前家居企业生产制造的发展现状，提出机器视觉在木制品制造领域的发展趋势，为木制品智能制造提供技术基础。
{ISBN/ISSN}: 2096-9694
{Notes}: 10-1732/S
{URL}: https://link.cnki.net/urlid/10.1732.S.20220922.1054.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的图像处理与尺寸检测研究
{Author}: 陈键
{Author Address}: 安徽电子信息职业技术学院信息工程学院;
{Journal}: 河南工程学院学报(自然科学版)
{Year}: 2022
{Volume}: 34
{Issue}: 03
{Pages}: 61-64
{Keywords}: 机器视觉;图像处理;尺寸检测;相机
{Abstract}: 传统的工业零件质量检测方法一般都需要人工参与，工作效率低，成本高，测量精度不高，不符合高度自动化的要求。为了提高检测效率与准确度，设计了基于机器视觉图像处理的工业零件尺寸检测系统。该系统主要包含3个模块：电气控制模块、图像处理模块、上位机显示模块。对采集到的图像进行灰度化、去噪、二值化、图像分割预处理，使用Canny算子进行亚像素级边缘提取，对提取到的轮廓进行联合、分割和曲线拟合，对相机完成标定和畸变矫正，得到像素尺寸与实际尺寸的比例关系。系统调试结果表明，图像处理得到的信息与实际零件尺寸信息相符。
{ISBN/ISSN}: 1674-330X
{Notes}: 41-1397/N
{URL}: https://link.cnki.net/doi/10.16203/j.cnki.41-1397/n.2022.03.006
{DOI}: 10.16203/j.cnki.41-1397/n.2022.03.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 利用机器视觉的手写数字识别系统设计研究
{Author}: 徐云;杨承翰;高磊
{Author Address}: 浙江理工大学信息科学与工程学院;
{Journal}: 自动化仪表
{Year}: 2022
{Volume}: 43
{Issue}: 09
{Pages}: 10-13
{Keywords}: 机器视觉;手写数字;识别模型;卷积神经网络;特征提取;模型训练;视觉传感器
{Abstract}: 针对手写数字识别模型偏大、嵌入式系统芯片运算量有限等问题，开展基于机器视觉的手写数字识别系统设计研究。采用STM32H743VIT6作为主控芯片，利用OV7725视觉传感器、LCD显示屏等构建基于机器视觉的手写数字识别系统原理样机。提出优化的卷积神经网络算法对手写数字图像进行特征提取、模型训练，获得TFlite手写数字图像识别模型。将该模型经压缩与加速处理后布署到设计的手写数字识别原理样机中，并对手写数字进行识别试验。试验结果表明：设计的基于机器视觉的手写数字识别原理样机的平均识别正确率约为98.4%,识别速度约为0.3 s。设计的手写数字识别原理样机可靠性和准确率较高，能够满足手写数字识别的要求。该研究为机电控制系统中手写数字识别的应用提供了新思路。
{ISBN/ISSN}: 1000-0380
{Notes}: 31-1501/TH
{URL}: https://link.cnki.net/doi/10.16086/j.cnki.issn1000-0380.2021100030
{DOI}: 10.16086/j.cnki.issn1000-0380.2021100030
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进VGG16卷积神经网络的烟丝类型识别
{Author}: 牛群峰;袁强;靳毅;王莉;刘江鹏
{Author Address}: 河南工业大学电气工程学院;河南中烟工业有限责任公司安阳卷烟厂;
{Journal}: 国外电子测量技术
{Year}: 2022
{Volume}: 41
{Issue}: 09
{Pages}: 149-154
{Keywords}: 烟丝识别;机器视觉;深度学习;VGG16;残差模块
{Abstract}: 为改善人工分拣烟丝效率低下，分类效果差导致香烟品质难以得到保证的现象，提出一种将机器视觉和深度学习相结合的烟丝类型识别方法。实验采集了4种烟丝图像并经过预处理以后送入以VGG16为基础改进的Light-VGG网络模型中进行分类，改进包括减少VGG16中卷积核个数以优化网络结构；增加残差模块以提升模型学习能力；使用全局池化代替全连接层，大幅减少网络参数量，应对网络过拟合。Light-VGG相比VGG16参数量减少96.5%,预测时间减少20.3%,在自建烟丝数据集中准确率达到95.5%,也明显高于其他神经网络(AlexNet、VGG13、GoogLeNet),实现了快速、准确识别烟丝类型的目标。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2203982
{DOI}: 10.19652/j.cnki.femt.2203982
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度卷积神经网络的图像语义分割算法研究
{Author}: 余兵奇
{Tertiary Author}: 焦李成;屈嵘
{Publisher}: 西安电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 语义分割;整体可变形卷积网络;整体增强可变形卷积网络;定向池化;定向场景解析网络;定向全卷积神经网络
{Abstract}: 图像分割是计算机视觉领域中的基本任务,在自动驾驶汽车、医学影像分析、地理信息系统、遥感图像处理等方面发挥极其重要的作用。近年来,随着深度学习的快速发展,基于卷积神经网络的方法成为图像处理领域的研究热点,同时也面临不少挑战,如缺乏标注数据、背景复杂、目标分布多样、受噪声干扰等问题。本文从卷积网络的基本架构出发,围绕可变形卷积网络的内部运行机制,池化单元整合特征的方式,金字塔场景解析网络中的金字塔池化模块,以及全卷积神经网络的特征提取方式等方面进行深入的研究。主要研究内容如下:1.针对可变形卷积网络(Deformable Conv Nets)中的空间支持(Spatial Support)可能会超出感兴趣区域(Region of Interest,Ro I),导致特征受到图像不相关内容影响的问题,提出一种新的网络:整体可变形卷积网络(Entire Deformable Conv Nets)。整体可变形卷积网络包含一个新的模块:整体可变形卷积单元(Entire Deformable Convolution),来替换可变形卷积网络中的可变形卷积单元(Deformable Convolution)。整体可变形卷积单元通过改变偏移量的分配方式来避免偏移量之间的相互干扰,有助于空间支持更好地聚集在感兴趣区域,增强了模型的几何变换能力。整体可变形卷积网络继承了原始算法的优点,并且获得了更好的性能。实验结果表明,与原始算法相比较,本文提出的算法增强了网络对几何形变的建模能力,有效地提升了网络的分割精度。2.增强可变形卷积网络(More Deformable Conv Nets)是可变形卷积网络的一个改进版本。同样,由于其空间支持可能会偏离感兴趣区域,导致特征受到图像不相关内容影响的问题,提出一种新的算法:整体增强可变形卷积网络(Entire More Deformable Conv Nets)。整体增强可变形卷积网络包含一个新的模块:整体调制可变形卷积单元(Entire Modulated Deformable Convolution),来替换增强可变形卷积网络中的调制可变形卷积单元(Modulated Deformable Convolution)。整体调制可变形卷积单元通过改变偏移量的分配方式来避免偏移量之间的相互影响,有利于空间支持更好地聚集在感兴趣区域。整体增强可变形卷积网络继承了原始算法的优点,并且获得了更好的性能。实验结果表明,与原始算法相比较,本文提出的算法显著的提高了网络对于几何变换的建模能力,有效地提高了网络的分割结果。3.针对金字塔场景解析网络(Pyramid Scene Parsing Network,PSPNet)中金字塔池化模块(Pyramid Pooling Module)对于输入数据尺寸限制的问题,提出一种新的算法:定向场景解析网络(Oriented Scene Parsing Network,OSPNet)。定向场景解析网络使用定向池化模块(Oriented Pooling Module)来替换金字塔池化模块,为网络提供更可靠的全局和局部特征表示。定向池化模块克服了金字塔池化模块的固有缺点,简化了整体网络的设计。定向场景解析网络为像素级的预测提供了一个卓越的框架,并实现了更加优越的性能。同时,针对池化操作可能会丢失相邻采样窗口之间区域的上下文信息的问题,提出一种新的池化策略:定向池化(Oriented Pooling)。定向池化将不同方向的子特征图融合在一起,大大增强特征平移不变性的能力,并且可以覆盖更多的上下文信息和纹理特征。定向池化可以很容易地集成在卷积神经网络中,可以像平均值池化或最大值池化一样方便使用。首先,我们采用分类实验和分割实验验证了定向池化的有效性,我们提出的池化性能更加优越,结构更加简单。然后,通过分割实验验证了定向场景解析网络的语义分割模型的有效性,并且获得了比金字塔场景解析网络更加优异的性能。4.针对全卷积神经网络在建模时对于细节信息不够敏感,导致分割结果比较平滑不够精细的问题,提出一种新的算法:定向全卷积神经网络(Oriented FCN)。我们使用定向池化层来替代全卷积神经网络中的常规池化层,提升了网络的特征提取能力,增强了网络的特征变换不变性,有助于获得更多的上下文信息和纹理特征。在下采样过程中,定向池化层可以减少冗余信息,增强了模型的鲁棒性和普及性。定向全卷积神经网络以简单、深入和端到端的方式处理密集预测任务。实验结果表明,定向全卷积神经网络在准确性和效率方面得到了显著的提升。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.003441
{DOI}: 10.27389/d.cnki.gxadu.2022.003441
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的答题卡识别系统设计
{Author}: 王子民;赵子涵;冯梦婷;张秀文;叶慧雯;杨玉东
{Author Address}: 淮阴工学院电子信息工程学院;南京工业大学计算机科学与技术学院;
{Journal}: 南京理工大学学报
{Year}: 2022
{Volume}: 46
{Issue}: 04
{Pages}: 443-450
{Keywords}: 机器视觉;答题卡识别;最大矩形框检测;抠图;RGBA颜色空间
{Abstract}: 为降低成本与实现答题卡的自动化识别，设计了基于机器视觉的答题卡识别系统，对图像提取、区域划分及识别算法分别进行研究。通过形态学操作、轮廓检测、仿射变换等技术，实现对答题卡图像的提取；基于最大矩形框检测算法，实现答题卡的区域划分；利用透明通道(Alpha通道)对标准答案与待识别答案填涂区域进行抠图，将处理后的图像匹配叠加；利用叠加图像的RGBA颜色空间特性、同步头的灰度投影结果与指针算法共同完成答题卡的识别。试验结果表明，系统的使用与维护成本低、操作方便且具有较好识别效果。
{ISBN/ISSN}: 1005-9830
{Notes}: 32-1397/N
{URL}: https://link.cnki.net/doi/10.14177/j.cnki.32-1397n.2022.46.04.009
{DOI}: 10.14177/j.cnki.32-1397n.2022.46.04.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于窗口自注意力网络的单图像去雨算法
{Author}: 高涛;文渊博;陈婷;张静
{Author Address}: 长安大学信息工程学院;澳大利亚国立大学工程与计算机学院;
{Journal}: 上海交通大学学报
{Year}: 2023
{Volume}: 57
{Issue}: 05
{Pages}: 613-623
{Keywords}: 计算机视觉;单图像去雨;窗口自注意力网络;残差网络;自注意力机制;空洞卷积
{Abstract}: 单图像去雨研究旨在利用退化的雨图恢复出无雨图像，而现有的基于深度学习的去雨算法未能有效地利用雨图的全局性信息，导致去雨后的图像损失部分细节和结构信息.针对此问题，提出一种基于窗口自注意力网络(Swin Transformer)的单图像去雨算法.该算法网络主要包括浅层特征提取模块和深度特征提取网络两部分.前者利用上下文信息聚合输入来适应雨痕分布的多样性，进而提取雨图的浅层特征.后者利用Swin Transformer捕获全局性信息和像素点间的长距离依赖关系，并结合残差卷积和密集连接强化特征学习，最后通过全局残差卷积输出去雨图像.此外，提出一种同时约束图像边缘和区域相似性的综合损失函数来进一步提高去雨图像的质量.实验表明，与目前单图像去雨表现优秀的算法MSPFN、 MPRNet相比，该算法使去雨图像的峰值信噪比提高0.19 dB和2.17 dB,结构相似性提高3.433%和1.412%,同时网络模型参数量下降84.59%和34.53%,前向传播平均耗时减少21.25%和26.67%.
{ISBN/ISSN}: 1006-2467
{Notes}: 31-1466/U
{URL}: https://link.cnki.net/doi/10.16183/j.cnki.jsjtu.2022.032
{DOI}: 10.16183/j.cnki.jsjtu.2022.032
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的PCB缺陷检测方法
{Author}: 廖鑫婷;李泉洲;邱权;徐海;刘振国
{Author Address}: 工业和信息化部电子第五研究所;工业装备质量大数据工业和信息化部重点实验室;
{Journal}: 电子产品可靠性与环境试验
{Year}: 2022
{Volume}: 40
{Issue}: 04
{Pages}: 30-34
{Keywords}: 印制电路板;缺陷检测;深度学习;目标检测模型
{Abstract}: 缺陷检测技术是PCB生产制造中一项不可或缺的质量控制技术，传统的机器视觉检测技术由于人工设计特征和复杂图像处理能力上的局限，无法快速地适应不同型号的PCB或不同的缺陷类型检测。针对上述问题，提出了基于深度学习的PCB缺陷检测方法，其利用深度学习自动提取缺陷特征和自主学习的能力，提高PCB缺陷检测性能和效率。实验结果显示，YOLOv3检测模型的mAP高达98.99%, FPS为71.28，可以快速准确地完成PCB缺陷的定位和分类判别，较好地满足其生产检测需求。
{ISBN/ISSN}: 1672-5468
{Notes}: 44-1412/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwH2mXhKadg16_Zen6gBSan68c5mDUyQnJzaIld-hRa6spSVZTCLrPyZM1rqSgoNUFgCElbXFCOJTv68h8WkG83JGi_-YcizYP-IGBefKzd8aSrWlfIlTlpSe3ihxozX6GoZ25psmntsOQUL1j7LwR3MvaSF2tGWljKrES3ev76_s9IFe9Ibeog7DXGJBRoLE8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 美国计算机视觉技术发展与军事应用
{Author}: 徐晨
{Author Address}: 国家工业信息安全发展研究中心;
{Journal}: 电子元器件与信息技术
{Year}: 2022
{Volume}: 6
{Issue}: 08
{Pages}: 8-12
{Keywords}: 计算机视觉;人工智能;机器学习
{Abstract}: 计算机视觉是人工智能技术的重要组成，与自然语言处理、语音识别并列为机器学习领域的三大热点方向。作为人工智能重要技术，美国已在众多领域开展了计算机视觉技术应用，研究其当前应用情况，可为我国计算机视觉技术军事应用提供借鉴和参考。本文梳理了近年来美军开展计算机视觉应用相关的项目和计划，分析了计算机视觉技术在军事数据处理、图像识别、战场辅助决策和无人系统中的军事应用现状，研判了计算机视觉技术对武器装备建设和作战的影响。
{ISBN/ISSN}: 2096-4455
{Notes}: 10-1509/TN
{URL}: https://link.cnki.net/doi/10.19772/j.cnki.2096-4455.2022.8.003
{DOI}: 10.19772/j.cnki.2096-4455.2022.8.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 生猪体尺检测和体重预估方法研究进展
{Author}: 杜晓冬;李笑笑;樊士冉;闫之春;丁向东;杨季凡;张丽萍
{Author Address}: 新希望六和股份有限公司;中国农业大学动物科技学院;
{Journal}: 中国畜牧杂志
{Year}: 2023
{Volume}: 59
{Issue}: 01
{Pages}: 41-46+56
{Keywords}: 猪;体尺;体重;机器视觉;三维点云
{Abstract}: 本文综述了国内外猪的体尺测量、体重预估的研究进展，以“猪”、“体尺测量”、“体重预估”、“机器视觉”为关键词，对近20年相关文献进行检索，分别从机器视觉、三维点云2个角度对文献进行梳理总结。结果表明：通过机器视觉技术测量猪的体尺、体重方法可以解决传统测量方法中造成猪只应激、人工效率低下等问题，而机器视觉技术中的三维点云重建是未来重点发展的趋势之一，通过点云数据可以直接提取猪的体尺和体积参数，减少外部环境对拍摄造成的影响，可提高检测精度。另外，从社会和经济等角度考虑，将机器视觉技术与养殖行业结合将具有良好的发展前景，未来建立更健全的智能养殖系统，增加更多智能化养殖设备的研发对实现规模化生产、集约化经营的畜牧业至关重要。
{ISBN/ISSN}: 0258-7033
{Notes}: 11-2083/S
{URL}: https://link.cnki.net/doi/10.19556/j.0258-7033.20211224-02
{DOI}: 10.19556/j.0258-7033.20211224-02
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能制造缺陷检测平台研究
{Author}: 韩佳轩;王鲜芳
{Author Address}: 泰国格乐大学国际学院工程管理系;河南工学院计算机科学与技术学院;
{Journal}: 现代电子技术
{Year}: 2023
{Volume}: 46
{Issue}: 08
{Pages}: 49-53
{Keywords}: 缺陷检测;机器视觉;检测平台;机器学习;深度学习;图像识别;目标检测;数据集
{Abstract}: 传统的产品质量检测技术大部分还停留在人工检测阶段，效率低下，且无法保证产品的检测精度。为保证产品质量，提高检测效率，文中将机器视觉技术及深度学习算法应用于工业生产过程，设计一种智能制造检测平台。该平台主要由图像采集装置、数据处理中心和HMI终端组成。其中，图像采集装置主要采用工业相机对制造过程中产品图像进行实时采集；数据处理中心利用深度学习算法模型对制造过程中产品缺陷进行识别，并将检测结果存储于数据库；HMI终端收集检测结果，动态展示缺陷大小、类别及位置信息。使用热轧钢板表面缺陷数据集对检测平台的数据处理及可视化模块进行测试，结果表明，所设计平台可对存在缺陷的产品进行快速识别，并将模型性能指标可视化，满足生产过程中对产品质量缺陷检测的需求。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2023.08.009
{DOI}: 10.16652/j.issn.1004-373x.2023.08.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器学习的果蔬识别研究综述
{Author}: 吴冀豪;常玉祥;汪宇玲;彭思绘
{Author Address}: 东华理工大学信息工程学院;
{Journal}: 机器人技术与应用
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 29-31
{Keywords}: 机器学习;果蔬识别;特征提取;分类识别
{Abstract}: K近邻、人工神经网络、卷积神经网络等传统机器学习技术，以及VGGNet、ResNet及MobileNet等处于当前机器学习前沿的深度学习技术已广泛应用到农业生产领域中，特别是在水果和蔬菜的识别与分类应用中已有较多研究成果。通常果蔬的识别方法是先利用外围设备采集果蔬图像，在对图像预处理后建立果蔬识别模块，再利用上述提到的技术提取图像特征来实现果蔬的自动识别与分类，最后应用到机器人自动果蔬采摘领域。本文阐述了果蔬识别与分类目前面临的制约条件、最新进展，并在不同果蔬数据集上对当前的主流果蔬识别的分类算法进行比较，为进行果蔬自动识别与分类等研究工作提供借鉴和参考。
{ISBN/ISSN}: 1004-6437
{Notes}: 11-3520/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyYrL0KCxVE08VMj_xKvjz1rVi2JjFLnVbtZXEPZSKaXXXQBU3LC2pXVZTrwx_lf4VGLdk7Xh599sQR6nvFtnoRyCunVBPD0AdgDtNP5XqrxWUAylINk_Bc6CyTH9i4DEVEKGIxiJks-tPncv6wEVGwXs3VNPCWGz0plMBOmTcqKlOKZX5Y65Zme8GGEQGtuGg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Harris角点检测算法的应用研究
{Author}: 姚依妮;王玮
{Author Address}: 洛阳科技职业学院智能制造与汽车工程学院;
{Journal}: 智能计算机与应用
{Year}: 2022
{Volume}: 12
{Issue}: 08
{Pages}: 148-151
{Keywords}: 机器视觉;图像处理;特征点;Harris角点
{Abstract}: 角点是机器视觉和图像处理技术中常用的特征点，在降低信息数据量的同时有效保留了图像的重要特征，现已广泛应用于各个领域，用来实现图像处理的特定要求。本文先对Harris角点检测算法原理进行阐述；再详细介绍改进的Harris角点检测算法的应用领域及效果；最后，对Harris角点检测的研究趋势做出总结和展望，为Harris角点检测的研究和应用提供参考。
{ISBN/ISSN}: 2095-2163
{Notes}: 23-1573/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzbiybG5aX-oi7uFlVLVnN8imQv94O9jhUb7Mu7PrlTDbj20R3R16K1jM5IfiRpDr2uLWbbF4tT-UGwk-MtKIwgyDGzfCwT18z4i-ZxSB_g4w9hIfpUJtDAZLcOAt2lRytUf7tWWa3IONVBrIhisHymxx8Vn40zs37wS0pP_mlslpEfIubypvrPtWi8mTsJTXs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于GPS和计算机图像识别的无人机导航系统
{Author}: 王晓光;管港云;徐嘉铭;李俊呈
{Author Address}: 吉林大学公共计算机教学与研究中心;吉林大学电子科学与工程学院;长春理工大学光电工程学院;
{Journal}: 吉林大学学报(理学版)
{Year}: 2022
{Volume}: 60
{Issue}: 04
{Pages}: 955-961
{Keywords}: 无人机;GPS定位;图像处理;目标检测;计算机视觉技术
{Abstract}: 采用GPS和图像识别双定位的方法，利用无人机的PID飞行姿态控制，使用开源计算机视觉库(OpenCV)处理图像，结合应用级联分类器，解决了无人机目标精准检测的问题.综合多种技术设计的定位导航控制系统能快速完成信息的传输与处理，增强了系统功能.在GPS粗略定位后对目标图形的图像捕获、预处理、拟合以及判别完成精准定位，保证了无人机导航控制系统实时高效准确.
{ISBN/ISSN}: 1671-5489
{Notes}: 22-1340/O
{URL}: https://link.cnki.net/doi/10.13413/j.cnki.jdxblxb.2021359
{DOI}: 10.13413/j.cnki.jdxblxb.2021359
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能物料分拣系统设计
{Author}: 袁苑;谢凯
{Author Address}: 江苏省惠山中等专业学校机电工程系;
{Journal}: 工业控制计算机
{Year}: 2022
{Volume}: 35
{Issue}: 07
{Pages}: 44-45+48
{Keywords}: 机器视觉;物料分拣;OpenMV;S7-1500 PLC;HMI
{Abstract}: 基于OpenMV视觉模块和西门子S7-1500 PLC，设计了一种基于机器视觉的智能物料分拣系统。其中，OpenMV通过图像采集，提取待分拣物料特征并进行信息分类处理，将处理数据传输给S7-1500 PLC主控，PLC负责物料分拣过程控制、参数设置以及和HMI界面的数据交互，实现对不同类别物料的分拣。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw0aa7vXrFn1ZtwLEWcL9F2OqE8dDvb7KoTKTlcrPj6vaifkQFo-1a_uwHtymixWT8Edyb2AfmcpdgW469e1E9AssgD_2Ud0PpjpEUqr4TBrEebDl1DtNvdczqjYdr5akdKFVc11KQZVCfIG6svH4p-oE-k8Lr9eLbC2peM6oSQG0uo3M0QJPVBK4mF-sVlfJo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的表面缺陷检测实验系统设计
{Author}: 韩素华;张闯闯
{Author Address}: 徐州开放大学新能源与机电工程学院;中国矿业大学机电工程学院;
{Journal}: 实验室研究与探索
{Year}: 2022
{Volume}: 41
{Issue}: 07
{Pages}: 247-252
{Keywords}: 机器视觉;缺陷检测;轴承套圈;LabVIEW软件;实验样机
{Abstract}: 设计了一种基于机器视觉的表面缺陷检测实验系统。依次对该系统的总体方案、图像采集系统、机械与控制系统、缺陷检测算法和检测软件进行了具体设计，进而制作了实验样机，并针对国标51105型号轴承套圈进行了表面缺陷检测实验。实验数据表明，所设计的轴承套圈表面缺陷检测实验系统的综合检测准确率≥95%,次品漏检率≤5%,能够满足所有的设计要求与技术指标。该系统已应用于轴承及自动控制类课程的实践教学中。实践表明，可有效帮助学生掌握轴承表面缺陷检测、机器视觉、自动控制等领域的相关知识。
{ISBN/ISSN}: 1006-7167
{Notes}: 31-1707/T
{URL}: https://link.cnki.net/doi/10.19927/j.cnki.syyt.2022.07.053
{DOI}: 10.19927/j.cnki.syyt.2022.07.053
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 剪力墙结构智能化生成式设计方法：从数据驱动到物理增强
{Author}: 廖文杰;陆新征;黄羽立;赵鹏举;费一凡;郑哲
{Author Address}: 清华大学土木工程安全与耐久教育部重点实验室,土木工程系;
{Journal}: 土木与环境工程学报(中英文)
{Year}: 2024
{Volume}: 46
{Issue}: 01
{Pages}: 82-92
{Keywords}: 智能化结构设计;生成对抗网络;数据驱动;物理增强;设计评价
{Abstract}: 建筑结构的智能化方案设计是智能建造的重要内容。既有研究提出了基于深度神经网络的剪力墙结构生成式设计方法框架、智能设计算法、设计性能评价方法等，完成了从数据驱动到物理增强的智能化设计方法的发展，但目前尚未有研究针对不同设计条件下数据驱动和物理增强方法的设计能力进行详细对比，且基于计算机视觉与基于力学性能的评价方法尚未有明确的关系，难以有效保证计算机视觉评价方法的合理性。基于深度生成式算法对比和算例分析，开展数据驱动和物理增强数据驱动方法的详细对比，并进一步验证基于计算机视觉评价与基于力学分析评价方法的正相关性。结果表明：数据驱动的方法易受到数据质量与数量的约束，而物理增强数据驱动的方法设计性能更加稳定，基本摆脱数据质量和数量的约束；基于计算机视觉综合评价指标SCV的合理性阈值为0.5，对应力学性能差异约为10%。
{ISBN/ISSN}: 2096-6717
{Notes}: 50-1218/TU
{URL}: https://link.cnki.net/urlid/50.1218.TU.20220720.1117.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的焊缝识别研究现状与发展趋势
{Author}: 张帆;泮佳俊;刘腾;张浩;李佩齐
{Author Address}: 南通大学张謇学院;
{Journal}: 电焊机
{Year}: 2022
{Volume}: 52
{Issue}: 07
{Pages}: 24-33+61
{Keywords}: 机器视觉;焊缝识别;视觉传感器;图像处理
{Abstract}: 机器视觉技术以其高精度、高自动化等特点被广泛用于工业测量、工业检测和识别等领域。概括了几种焊缝识别传感技术，并对传感方式的基本原理和特点进行了分析。详细阐述了基于机器视觉的焊缝识别的具体实现步骤，重点归纳总结了针对不同的噪声和干扰采用相应的滤波和消除方法、焊缝的特征提取与中心线拟合方法等。在国内外焊缝识别研究的基础上，提出了几个有价值的研究方向，包括基于新型测距法及其传感器的焊缝定位、基于卷积神经网络的焊缝类型识别、针对焊后质量检测的三维信息重构和多种干扰因素并存情况下的焊缝识别等。
{ISBN/ISSN}: 1001-2303
{Notes}: 51-1278/TM
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzIJ15NcUKVlqtnvGFXIpc2_kvtjGxOI1V1B_Gd8OJ9CjVhXaxlHjBGOSG8-ZBdmJO7GseHtianuKB_XibI8UWpQ5PTIvrxkui_MTbjFPaZh70sZDu5Q8Nu78oPqKYsd5gagmSpSInbtXCMAzdnummfdjTiYjDO_cM5gbPSZ73p1-SAChLuya8fmQKQX5GRwvk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 齿轮视觉检测仪器与技术研究进展
{Author}: 石照耀;方一鸣;王笑一
{Author Address}: 北京工业大学北京市精密测控技术与仪器工程技术研究中心;河南科技大学河南省机械设计及传动系统重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 74-86
{Keywords}: 机器视觉;齿轮测量;齿轮视觉检测仪器;齿轮精度测量;齿轮缺陷检测
{Abstract}: 相对于接触式测量，机器视觉检测这种非接触式测量具有效率高、信息全、稳定性好、可识别缺陷等优点，在齿轮检测领域得到越来越广泛的应用。近十年来出现了影像仪、闪测仪、CVGM仪器、在线检测设备等多种基于机器视觉技术的齿轮检测仪器，它们既可以实现齿轮综合式测量，又可以实现齿轮分析式测量。回顾了齿轮视觉检测仪器的发展历程和特点，分析了齿轮视觉检测中边缘检测、亚像素定位、特征提取和模式识别等算法的研究和应用进展，总结了机器视觉在齿轮精度测量和齿轮缺陷检测两个方面的技术发展，并指明了齿轮视觉检测仪器与技术的发展前景。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.tn.20220714.1314.367
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的亚像素精度法兰盘尺寸测量方法
{Author}: 焦博;刘国宁;赵孟轩;马光岩
{Author Address}: 郑州大学机械与动力工程学院;
{Journal}: 现代制造工程
{Year}: 2022
{Volume}: 
{Issue}: 07
{Pages}: 121-126
{Keywords}: 机器视觉;亚像素;法兰盘;尺寸检测
{Abstract}: 针对空调压缩机法兰盘尺寸人工测量方式存在效率低、精度难以保证等问题，提出一种基于机器视觉的法兰盘尺寸亚像素级别测量方法，并构建视觉测量系统。对法兰盘图像，先使用转灰度、中值滤波和二值化分割进行预处理，抑制图像噪声，同时提取目标法兰盘区域；再使用Canny算子获取法兰盘边缘像素坐标；然后根据Zernike算法对旋转、尺度等不敏感的特点，使用改进的Zernike矩亚像素边缘检测算法重新定位法兰盘边缘，获取法兰盘边缘的亚像素级别坐标；最后使用最小二乘拟合算法得到法兰盘外圆直径与内孔直径尺寸。实验证明，该检测方法与人工测量方式相比效率高、精度高，能够满足对法兰盘关键尺寸的在线测量需求。
{ISBN/ISSN}: 1671-3133
{Notes}: 11-4659/TH
{URL}: https://link.cnki.net/doi/10.16731/j.cnki.1671-3133.2022.07.019
{DOI}: 10.16731/j.cnki.1671-3133.2022.07.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 动态场景下基于光流和实例分割的视觉SLAM方法
{Author}: 徐陈;周怡君;罗晨
{Author Address}: 东南大学机械工程学院;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 14
{Pages}: 147-159
{Keywords}: 机器视觉;视觉里程计;动态场景;光流;运动物体检测;实例分割
{Abstract}: 为提升动态场景中视觉SLAM(Simultaneous Localization and Mapping)系统的定位精度和鲁棒性，提出一种基于光流和实例分割的视觉SLAM方法。针对动态物体和静态背景光流方向的不一致性，提出一种高实时性动态区域掩模检测算法，从而在ORB-SLAM2原有跟踪线程中实时地剔除处于动态区域掩模中的特征点。利用已有深度图和跟踪线程位姿估计的信息去除相机运动相关光流，然后聚类动态物体自身运动产生的光流幅值，从而实现高精度的动态区域掩模检测，并结合对极几何约束剔除局部建图线程中的动态路标点。在TUM和KITTI数据集上的测试结果表明，在高动态场景下，本文算法相较ORB-SLAM2、Detect-SLAM、DS-SLAM，定位精度平均提升97%、64%和44%。相较DynaSLAM，本文算法在一半的高动态场景中定位精度平均提升20%，这验证了本文算法在高动态场景中提升了系统定位精度和鲁棒性。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://link.cnki.net/urlid/31.1252.O4.20220714.1319.060
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 单相机三维视觉成像技术研究进展
{Author}: 刘兴盛;李安虎;邓兆军;陈昊
{Author Address}: 同济大学机械与能源工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 87-105
{Keywords}: 机器视觉;三维成像;立体视觉;相机运动;光学元件;参数标定
{Abstract}: 机器视觉应用场景复杂化和功能需求多元化给三维成像技术带来巨大挑战。针对复杂环境及受限空间的目标重建和场景感知问题，结构简单且性能可靠的单相机三维视觉成像技术能够提供重要的解决途径。在阐明单相机三维立体视觉成像理论模型的基础上，根据相机运动情况以及采用的反射、折射或衍射等附加光学元件的情况，分类介绍了单相机三维视觉成像系统组成、基本原理和实现方法。从视场范围、空间分辨率、视角灵活性、动态响应性、环境适应性等角度，分析了现有单相机三维视觉成像方法的优越性和局限性。围绕三维重建精度及成像质量提升问题，回顾了相机与附加光学元件未对准参数的主要标定方法。结合单相机三维视觉成像的技术挑战和应用前景，展望了其在实现大视场高分辨率、高动态高实时性、复杂环境适应性等方面的发展方向。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220714.1207.128
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像去雾算法研究综述
{Author}: 陈俊安;陆庚有;谢倩怡;龚智慧;刘建平;彭绍湖
{Author Address}: 广州大学电子与通信工程学院;
{Journal}: 电脑与电信
{Year}: 2022
{Volume}: 
{Issue}: 07
{Pages}: 63-66
{Keywords}: 计算机视觉;图像去雾;深度学习
{Abstract}: 随着人工智能技术的不断发展，计算机视觉在各个领域有着广泛的应用。然而这些应用作用在有雾图像上，其性能将受到严重的影响。为解决此类问题，图像去雾算法研究已受到较多研究者的关注。图像去雾算法是为了处理有雾受损场景、获取细节增强的图像预处理结果图的处理方法。为了研究图像去雾算法的发展现状，将对传统图像处理去雾算法和深度学习去雾算法进行分类。在此基础上，介绍不同算法的优缺点，并总结图像去雾算法的发展展望。
{ISBN/ISSN}: 1008-6609
{Notes}: 44-1606/TN
{URL}: https://link.cnki.net/doi/10.15966/j.cnki.dnydx.2022.07.012
{DOI}: 10.15966/j.cnki.dnydx.2022.07.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 家畜体尺自动测量技术研究进展
{Author}: 初梦苑;司永胜;李前;刘刚
{Author Address}: 中国农业大学智慧农业系统集成研究教育部重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;河北农业大学信息科学与技术学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 13
{Pages}: 228-240
{Keywords}: 机器视觉;图像处理;家畜养殖;体尺测量;目标分割;无损监测
{Abstract}: 家畜体尺参数是评价家畜生产性能的关键指标之一，可为选取优良品种提供重要参考依据。人工测量家畜体尺费时费力、主观性强、有损动物福利。随着计算机技术的应用普及，家畜体尺自动测量技术发展较快，取得了较好的研究成果。该研究从家畜数据采集与预处理、家畜直线体尺测量、家畜围度体尺测量3个方面，阐述了家畜体尺自动测量技术的一般流程、常见技术、研究现状及方法优劣。首先，数据采集与预处理是家畜体尺自动测量的重要步骤，包括家畜图像数据的采集、分析与处理，输出便于体尺测点定位的数据，为家畜直线与围度体尺测量奠定基础；其次，家畜直线体尺测量技术基于数字图像处理和计算机视觉等方法，提取直线体尺测点并计算体尺测量值，是目前家畜体尺自动测量领域的主要研究内容；最后，因家畜围度体尺测量难度较大，其测量方法也是近年来相关领域研究的难点，胸围、腹围等体尺参数是家畜体质量和肉产量的重要参考指标，围度体尺测量主要包括体尺测点定位、围度体尺曲线拟合与尺寸计算。该研究还探讨了目前家畜体尺自动测量领域存在的成本高、自动化程度低、实时性与普适性差等问题，展望了未来该领域发展趋势，以期为开展家畜体尺自动测量技术与方法研究提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwQD9zglxzZEUYpf_yu8biDAsYgvOpSfAeHzxLO5m-elEUqnzz1gcW7RKvd1WLjPhWMp4e3Q5P5hLtVf9d2_EX3K9MDG6YGtMPh8ewH3ZolWCp4jWUZoQjt0KggNvXPAOJOAfLr2V-7zDgSo67YxDhGj-7jISV9Cf6VKHlJyEZYTQclBdRnqV5yPl-V0i4j9mU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的杏鲍菇外观品质分级分选装置研制
{Author}: 周柱
{Tertiary Author}: 陈学永
{Publisher}: 福建农林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 杏鲍菇;HALCON;分级分选;差速分离;图像处理
{Abstract}: 杏鲍菇肉质肥美、营养丰富,有很高的食用、营养及经济价值,是我国工厂化栽培的经济食用菌品种之一,有很大市场潜力。目前行业内通过人工分级分选,工作强度大、分级分选效率低,且品质随工人主观想法产生波动,无法实现规模、统一、高效的分选效果。本课题将机器视觉智能分级分选技术首次应用于杏鲍菇分选行业,提出一种基于机器视觉的杏鲍菇外观品质分级分选装置,可有效解决人工分选效率低、品质波动及人工成本增加等问题,对杏鲍菇产业的应用及发展具有重要的意义。本课题研究内容如下:(1)结合国家及企业相关分级标准,确立杏鲍菇分级依据标准,完成物理特性试验研究。确定各规格杏鲍菇以长度、直径、弯曲度、均匀度、菇帽缺损及菇体色泽等6个特征要素分级标准,完成杏鲍菇相关物理特性试验,利用Solid Works 2018建立杏鲍菇极限外形尺寸模型,确定杏鲍菇质量、外形尺寸、摩擦系数、安全跌落高度及密度等物理特性。(2)基于差速分离原理完成杏鲍菇分级分选装置机械系统设计。对杏鲍菇差速分离原理介绍并建模,利用ADAMS 2018对差速分离模型仿真分析,利用Solid Works 2018完成机械系统虚拟样机设计开发,并搭建测试样机完成原理验证测试试验。(3)完成杏鲍菇图像采集系统搭建及图像处理算法研究。选择图像采集系统关键部件,并完成相机标定校正。对图像校正变换、图像增强、边缘检测及颜色空间转换等算法与原理研究。通过代码运算时间、峰值信噪比及边缘线完整度等指标,确定最佳处理效果算法,并针对传统Canny算子不足,提出一种双边滤波代替高斯滤波作为图像平滑滤波器,Ostu最大类间方差法代替固定双阈值分割的改进型Canny算子。最终选择中值滤波进行图像平滑,一种改进型Canny算子作为边缘检测算法,以最小外接矩形提取长度、直径、弯曲度及均匀度,杏鲍菇RGB图像转换HSV颜色空间,获取H、S、V分量,提取菇帽缺损及菇体色泽。(4)使用HALCON联合C#在.NET平台完成视觉软件界面开发,包括图像采集、图像处理、串口通讯、产品配置及数据库管理等5大模块功能开发。并完成软件及装置工作性能在线测试,结果表明杏鲍菇直径分级精度为83%,其余特征要素可达85%以上,装置整体各规格杏鲍菇分级精度达90%以上。
{URL}: https://link.cnki.net/doi/10.27018/d.cnki.gfjnu.2022.000487
{DOI}: 10.27018/d.cnki.gfjnu.2022.000487
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属垫片表面缺陷检测
{Author}: 姜阔胜;王济广;卢丽子
{Author Address}: 安徽理工大学机械工程学院;深部煤矿采动响应与灾害防控国家重点实验室;
{Journal}: 邵阳学院学报(自然科学版)
{Year}: 2022
{Volume}: 19
{Issue}: 03
{Pages}: 42-48
{Keywords}: 机器视觉;垫片;表面缺陷检测;色差
{Abstract}: 针对人工目检方法在色差垫片表面缺陷检测上存在检测速度慢、漏检和误检等问题，以OpenCV开发的柔性视觉检测系统为载体，提出了一种基于机器视觉的金属垫片表面缺陷检测方法。在被检测垫片图像背景加入有色噪声，根据每个垫片图像的颜色分布自动选取一个最佳阈值，对图像进行阈值处理，自适应分割出金属垫片的表面缺陷，从而精确地检测出存在色差垫片的表面缺陷。验证结果表明：该方法能够完成对色差垫片的自动化在线检测，有效提高检测精度和速度。
{ISBN/ISSN}: 1672-7010
{Notes}: 43-1429/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxPa51H9sPjFef60CQr9B1IvXUsbnmSiEYSa1zH_pwOpSX5awAfASsB0HttuoY1a4Dx0cumgjeuvD4OinxYY93VdCPPWH4o5NkQvNA7OdVPyKc_e10Qugq21-Cg53kAJO1EiLj5Tv3hGJBPiSKKMoWOLst6AJCanqVGeh37qUunRPBDQnUdP4k09Mm_8cI1jBA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的奶牛生理参数监测与疾病诊断研究进展及挑战
{Author}: 康熙;刘刚;初梦苑;李前;王彦超
{Author Address}: 中国农业大学智慧农业系统集成研究教育部重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;浙大宁波理工学院计算机与数据工程学院;
{Journal}: 智慧农业(中英文)
{Year}: 2022
{Volume}: 4
{Issue}: 02
{Pages}: 1-18
{Keywords}: 奶牛养殖;计算机视觉;生理参数监测;疾病诊断;精细畜牧业;智能养殖
{Abstract}: 利用先进的信息技术推动智能养殖业发展已经成为奶牛养殖研究领域的重要目标和任务。计算机视觉技术具有非接触、免应激、低成本及高通量等优点，在畜牧生产中应用前景广阔。本文在阐述了计算机视觉技术在智能化养殖业发展中重要性的基础上，首先介绍了基于计算机视觉的奶牛生理参数监测进展，包括体尺、体温、体重的前沿监测设备、技术和模型参数。然后阐述了奶牛跛行及乳腺炎等疾病诊断的前沿技术发展过程和研究现状。目前，相关技术研究和应用推广存在检测准确性不高，受环境因素影响较大，非标准化养殖场结构制约检测系统普及，以及检测系统成本较高等问题和挑战。最后，本文结合中国养殖业发展现状，针对保证检测准确性、减少环境干扰等问题，就如何提高计算机视觉技术在智能化养殖业中的准确性和普适性提出了相关建议，旨在为中国奶牛养殖业的科学管理和现代化生产提供新方法和新思路。
{ISBN/ISSN}: 2096-8094
{Notes}: 10-1681/S
{URL}: https://link.cnki.net/urlid/10.1681.S.20220623.1532.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的交通标志检测识别系统设计
{Author}: 杨佳义
{Author Address}: 重庆移通学院智能工程学院;
{Journal}: 科技创新与应用
{Year}: 2022
{Volume}: 12
{Issue}: 18
{Pages}: 103-106
{Keywords}: 机器视觉;图像处理;目标识别;BP神经网络
{Abstract}: 针对人机交互中目标识别的问题，设计基于BP神经网络的交通标志检测识别系统。首先，采集自然环境下的原始图像，运用RGB模型转换为HSV模型。然后，应用图像增强处理和滤波腐蚀技术，减少图像的环境噪声。最后，运用BP神经网络模板建立交通标志数据模板库，通过BP神经网络的方式将模板进行训练和数据提取，采用模板匹配识别原始图像交通标志。设计目标识别的GUI人机交互界面，实验测试结果表明，设计系统可以准确识别图像中交通标志并弹窗提醒和语音播报识别结果，设计的目标识别系统快速可靠，能够广泛应用于不同场景。
{ISBN/ISSN}: 2095-2945
{Notes}: 23-1581/G3
{URL}: https://link.cnki.net/doi/10.19981/j.CN23-1581/G3.2022.18.025
{DOI}: 10.19981/j.CN23-1581/G3.2022.18.025
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv4模型的橙果识别与定位方法
{Author}: 刘洁;李燕;肖黎明;李炜琪;李浩
{Author Address}: 华中农业大学工学院;农业农村部长江中下游农业装备重点实验室;农业农村部柑橘全程机械化科研基地;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 12
{Pages}: 173-182
{Keywords}: 机器视觉;识别;定位;橙;YOLOv4;深度学习;RealSense
{Abstract}: 为提高橙果采摘定位精度和作业速度，提出一种便于迁移至移动终端的改进YOLOv4模型，可从RealSense深度相机所成彩色图像中获取果实质心二维坐标，经配准提取对应深度图中质心点深度值，实现果实的三维空间定位。改进YOLOv4模型以Mobile Net v2为主干网络，在颈部结构中使用深度可分离卷积替换普通卷积，实现模型轻量化并提高检测速度。训练后的改进模型对513张独立橙果测试集数据的识别平均精度达97.24%，与原始YOLOv4模型相比，平均检测时间减少11.39 ms，模型大小减少197.5 M。与经典Faster RCNN、SSD模型相比，检测平均精度分别提高了2.69和3.11个百分点，模型大小分别减少了474.5和44.1 M。与轻量化模型YOLOv4-tiny相比，召回率提升了4.22个百分点，较Ghostnet-YOLOv4，平均检测时间减少了7.15 ms。为验证该改进算法实用性，应用改进模型获取果园中78个橙果的位置信息，结果表明：果实二维识别成功率达98.72%，水平方向及垂直方向的平均绝对百分比误差均在1%以内。果实三维定位成功率达96.15%，深度信息平均绝对百分比误差为2.72%，满足采摘机械手精准定位需求。该方法为复杂场景下采摘作业实现提供了鲁棒性强、实时性好、精准度高的目标定位途径。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxwIDiJr1IbVZmzoiA2udjavsAKFgQf3H7EN6EjJlhZkD0Jm2WDYJORgTUaijyzHFYYsaXTMTnyFpKTACuLhoSOHMAv1lV0fN7GygwVgw0RvPfYcaUpaHvki2K_sQT2oWE_OugYETAGwraox6-NgRUIxW3ta3dncFbh5L2iik2ZcmP5gIdjitUMLeNHDx3v_pw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的垃圾分类系统设计
{Author}: 林心宇
{Author Address}: 福建信息职业技术学院;
{Journal}: 今日制造与升级
{Year}: 2022
{Volume}: 
{Issue}: 06
{Pages}: 34-38
{Keywords}: 垃圾分类;深度学习;图像分类
{Abstract}: 随着社会的进步和人们环保意识的加强，对垃圾实行分类处理是实现垃圾减量化、无害化和资源化的重要环节。传统的人工分拣方式效率低、人工成本高，对垃圾的分类也不够精确。随着智能化的广泛应用，利用计算机视觉智能设备进行垃圾分类是当前研究垃圾分类的重点。深度学习计算在计算机视觉领域的成功应用，提高了图像分类的准确率和工作效率。文中从垃圾分类的数据出发，搜集垃圾的种类，建立对垃圾的检测数据集，然后选择合适的算法构建垃圾分类模型，并设计出符合课题要求的新型垃圾分类系统。
{ISBN/ISSN}: 2095-6932
{Notes}: 10-1196/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwyTQohWWPzIYao2JYVo8cAG2JcHO90if_PdhzsNzVJxCw2c2Ccfynv-h9l1s-GZtUuhdtAxmWTJBfmQ-I-FT_rxkxFrqDjqoP32kKcpPWXnwuNJ58zPiVIsi-MgASKPPjedZYt2THelZysvUbi8Nl2Qi_wYvqtY61Os0mQg8472y37LiTkjv7h73kI7eIUT50=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv4模型和单片机的水果蔬菜智能称量系统设计
{Author}: 李亚如
{Tertiary Author}: 孟伟;叶刚
{Publisher}: 北京林业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 果蔬识别系统;智能称量系统;YOLOv4算法;单片机;深度学习
{Abstract}: 水果和蔬菜是人们生活中必不可少的物质,而水果蔬菜种类十分繁多。目前果蔬的分拣和售卖主要依赖于人工,超市或菜市场中散装果蔬称重时常出现排长队现象,既降低了消费者的体验,也违背了人们对便捷生活的追求。本文提出的基于YOLOv4模型和单片机的水果蔬菜智能称量系统是利用计算机视觉技术,通过研究和提取果蔬的图像特征,设计出一种合适的网络结构,提高果蔬检测候选区域的位置精度以及果蔬分类识别的准确率,解决光线明暗、干扰物等外部环境的影响问题,实现复杂背景下果蔬的分类检测,并利用其高效便捷的特性与称重硬件设备相结合,应用于商品零售和实际生产中的一项研究。整个系统分为上位机和下位机两部分,上位机主要是采用本文提出的基于改进YOLOv4模型的检测识别算法进行果蔬检测分类,具体改进包括采用Mobile Net V3替换YOLOv4模型的特征提取网络CSPDarknet53,提高模型速度;在特征提取网络中引入轻量化注意力机制,提高模型的特征提取能力;采用空洞卷积扩大感受野,减少信息丢失,提高YOLOv4模型的目标检测能力。下位机主要包括由STC89C51单片机、HX711压力传感器以及用于显示重量和价格的1602液晶显示屏组成的果蔬称重系统。通过本文设计的基于改进YOLOv4模型的果蔬检测识别算法、基于单片机和传感器的重量自动获取算法以及采用Py Qt5进行图形界面开发的水果蔬菜智能称量系统,可以实现水果蔬菜的智能检测识别、称重和计价功能,有利于新零售环境下智慧市场的建设,提升人工智能对消费者购物体验的积极影响,更好地满足人们对智能便捷生活方式的追求。
{URL}: https://link.cnki.net/doi/10.26949/d.cnki.gblyu.2022.000882
{DOI}: 10.26949/d.cnki.gblyu.2022.000882
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的单阶段目标检测技术研究
{Author}: 宋晨
{Tertiary Author}: 程旭
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;计算机视觉;目标检测;视觉注意力模型
{Abstract}: 目标检测是计算机视觉领域中最基础且最具挑战性的任务之一,包含目标分类和定位。与此同时,目标检测作为图像理解和计算机视觉的基石,它为视频跟踪等任务提供了强有力的特征分类基础。最近,深度学习利用强大的分层特征提取和学习能力表现出更强的鲁棒性。尽管如此,现有方法在面对多尺寸目标检测和密集成群的小目标检测时仍无法取得较好的效果。为解决这些问题,本文旨在研究利用特征融合和重构的方法增强与丰富多阶段特征图中的多尺寸目标信息,利用视觉注意力机制捕捉富感受野下的目标特征信息,增强特征提取网络对小目标的特征表达能力。本文的研究内容如下:(1)针对现有单阶段多锚框SSD算法存在的多尺寸目标检测效率低下和特征图中目标信息冗余的问题,本文提出一种基于特征融合和重构的单阶段多尺度目标检测算法。首先,提出一种多尺度注意力模型,增强浅-中-深层特征图中目标全局语义特征信息。其次设计一种自适应分层特征加权机制,完成多阶段分层特征图的细粒度信息融合。最后,为解决深层特征图中信息冗余的问题,本文提出一种特征图重构模块,对结果特征图进行分割、视觉注意力关注和重组,关注于特征图中重点信息与消除冗余的目标特征。(2)针对现有视觉注意力模型分离通道式空间式注意力导致的图像特征提取不充分与小目标特征提取能力差的问题,本文提出一种特征信息交互注意力模型,设计信息编织结构融合多维度特征图,完成通道式空间式注意力特征图的细粒度融合。在此基础上,提出一种自适应循环特征信息交互注意力模型,多次且重点关注局部特征图,完成目标全局语义特征与局部上下文信息的提取、融合和增强。大量的实验结果表明我们的方法优于现有注意力模型,并在目标检测任务上表现出较好的性能。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.000261
{DOI}: 10.27248/d.cnki.gnjqc.2022.000261
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轨道缺陷智能巡检小车设计研究
{Author}: 李一凡
{Tertiary Author}: 闵永智;陈云峰
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像采集;巡检小车;深度学习;轨面缺陷;扣件缺陷
{Abstract}: 铁路安全是国家经济发展的基础保障,定期轨道检测也成为铁路工作中不可或缺的一部分。我国铁路检测工作除大型轨检车的定期巡检外,各铁路局也将不同轨检设备用于日常检测中以替代人工巡检。大型轨检车检测效率高,但调度不便、造价昂贵。轨检仪等检测设备效率低下,不适用于长线检测。针对以上问题本文将设计基于机器视觉的轨道缺陷智能巡检小车用于完成铁路日常轨道巡检任务,并使用深度学习目标检测算法代替传统检测算法,提升钢轨缺陷检测速度与检测精度。首先,对轨道巡检小车提出总的设计方案。在了解行业背景及铁路巡检车运行原理后确定本文巡检小车基本性能要求与方案。按照巡检小车组成分为图像采集系统,缺陷检测算法和巡检小车加工测试三部分。其次,根据轨道特征设计轨道图像采集系统。使用高速线阵相机作为图像采集核心设备,利用光电编码器控制相机进行图像采集,考虑到外部光照对图像采集影响较大,选择条形光源作为辅助光源保证图像采集质量,使用锂电池为图像采集装置供电并用磁盘阵列存储采集图像。软件部分设计图像式轨检系统采集与显示界面用来显示图像采集结果并在后期轨道缺陷检测中用于数据对比。主要包括参数设置模块、连续显示与保存模块以及文件命名与图像提取三部分。图像采集软硬件设计完成后在实验室搭建图像采集平台测试采集结果,用传送带模拟巡检小车运动状态,测试结果良好,实现了钢轨图像的高速采集。然后,使用深度学习目标检测算法对轨道缺陷进行定位识别。经过数据分析发现钢轨表面缺陷样本数据量较少,深度学习的图像式检测方法准确率高的必要前提是模型训练样本充足,经过网络对比选择基于深度卷积生成对抗网络(Deep Convolutional Generative Adversarial Networks,DCGAN)的钢轨样本扩充方法来解决数据不足的问题。样本充足后训练轨面和扣件缺陷检测的深度学习模型,在分析当前主流深度学习目标检测算法后结合实际对象选择基于候选区域的深度卷积神经网络(Faster Region-Convolutional Nrural Networks,Faster R-CNN)进行缺陷检测,并对生成钢轨样本进行测试,验证其可使用性。最后,设计轨道巡检小车搭载图像采集装置获取轨道缺陷图像并验证缺陷检测算法的准确性。搭建便携式轨道图像采集小车在钢轨测试线路进行图像获取,针对现场采集过程中出现的问题改进后对轨道巡检小车进行3D建模。根据小车荷载与速度要求计算相匹配的电机并控制,然后对车架部分进行静力学仿真验证结构合理性后加工小车。图像采集电气设备与电机安装后在实验室测试结果良好并获取现场钢轨图像。将采集到的含缺陷样本分类后制作轨道表面与扣件的缺陷数据集测试缺陷检测结果。实验结果表明巡检小车图像采集效率高,采集到的钢轨图像清晰、完整、不失真。缺陷检测速度快,精度高,与人工巡检相比减少工作量的同时提高了检测效率,符合设计要求。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2022.000410
{DOI}: 10.27205/d.cnki.gltec.2022.000410
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的水果自动分级系统的设计
{Author}: 杨鹏仙;王惠玲;宗强;陈琳
{Author Address}: 南京科技职业学院电气与控制工程学院;
{Journal}: 石河子科技
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 16-17
{Keywords}: 计算机视觉;图像采集;LabVIEW;自动分级系统
{Abstract}: 利用计算机视觉技术进行水果分级是自动化分级发展的必然趋势。本文设计了一种水果自动分级系统，以工控机为核心，通过工业相机进行图像采集，通过LabVIEW和LabVIEW Vision Assistant软件对采集到图像信息进行处理。该系统可以在人机界面上对系统的参数进行设定，对分级状态进行监视，控制系统各部件动作，完成系统的信号采集、通信、判断、控制等功能，实现水果的自动分级。
{ISBN/ISSN}: 1008-0899
{Notes}: 65-1162/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzXo5SwiAHlIl5cR6tywQpjyyUN5i-7oC-Q9TKPVHrUW3emHLjZRlOY9sltSm8YQB6WF1yCPMNghEp2gxaYueLlHNJRJ1ecXK3Pb1azH_OE0AU8aGXIKXCFD_PsTi3JlfV_lM_eu71bbe2vPkMFGaFVXHkDqPQ1_8a0E-zYC9U7nPS8kxxrg_gOJifdz84Cjvo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Transformer的图像分类网络MultiFormer
{Author}: 胡杰;昌敏杰;熊宗权;徐博远;谢礼浩;郭迪
{Author Address}: 武汉理工大学现代汽车零部件技术湖北省重点实验室;武汉理工大学汽车零部件技术湖北省协同创新中心;武汉理工大学湖北省新能源与智能网联车工程技术研究中心;
{Journal}: 计算机应用研究
{Year}: 2022
{Volume}: 39
{Issue}: 10
{Pages}: 3191-3195
{Keywords}: 机器视觉;深度学习;图像分类;自注意力;Transformer
{Abstract}: 为解决目前ViT模型无法改变输入补丁大小且输入补丁都是单一尺度信息的缺点，提出了一种基于Transformer的图像分类网络MultiFormer。MultiFormer通过AWS(attention with scale)模块，将每阶段不同尺度输入小补丁嵌入为具有丰富语义信息的大补丁；通过GLA-P(global-local attention with patch)模块交替捕获局部和全局注意力，在嵌入的同时保留了细粒度和粗粒度特征。设计了MultiFormer-tiny、-small和-base三种不同变体的MultiFormer模型网络，在ImageNet图像分类实验中top-1精度分别达到81.1%、82.2%和83.2%,后两个模型对比同体量的卷积神经网络ResNet-50和ResNet-101提升了3.1%和3.4%;对比同样基于Transformer分类模型ViT,MultiFormer-base在参数和计算量远小于ViT-Base/16模型且无须大量数据预训练前提下提升2.1%。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2022.03.0133
{DOI}: 10.19734/j.issn.1001-3695.2022.03.0133
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于超声导波和机器视觉的管道缺陷检测方法研究
{Author}: 李靖
{Tertiary Author}: 李忠虎;张鑫宇
{Publisher}: 内蒙古科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 管道缺陷检测;超声导波;机器视觉;全聚焦成像;信息融合
{Abstract}: 管道运输作为一种高效、经济的运输方式,在经济发展中发挥着越来越重要的作用。随着管道运行时间的不断延长,因腐蚀、老化及变形等因素影响而导致的管道泄漏事故频发,这一方面会造成原材料浪费,另一方面也可能会导致环境污染甚至是人员伤亡,因此定期对管道进行无损检测并对管道运行状态进行评价尤为重要,这对保障管道正常运行和减少损失具有重要意义。本文以超声导波和机器视觉检测理论为基础,采用理论与实验相结合的方法,对基于超声导波和机器视觉的管道缺陷检测方法进行研究。超声导波具有可快速实现缺陷定位并能给出总损失率等优点,但是并不能直观反应管道缺陷详细信息,而机器视觉则可直观反映管道缺陷信息,但系统比较复杂且检测效率比较低,不能够快速实现管道缺陷定位。将超声导波与机器视觉检测方法相结合,采用互补融合的方式则可快速进行管道缺陷定位并识别缺陷的大小等信息,可为管道检修提供可靠依据。本文基于超声导波检测理论,选取L(0,1)模态超声导波作为激励模态,用于管道缺陷的检测。首先利用ABAQUS软件建立管道模型,进行数值模拟计算,确定管道的缺陷位置,利用采集到的管道缺陷回波信号对管道缺陷进行轴向定位,使用能量幅值法和圆轨迹曲线法实现管道缺陷的周向定位,并对两种方法进行了分析和比较。研究结果表明,采用幅值能量法只能大致确定缺陷的周向位置,定位精确度不高;而采用圆轨迹曲线法则可较好地对管道缺陷进行周向定位,并且角度越小的缺陷定位精度越高,总体缺陷定位精度在8.5%以内。然后使用全聚焦成像算法实现管道的单缺陷和多缺陷成像,利用中值滤波、希尔伯特变换提取信号包络、信号锐化等信号处理方法提高了管道缺陷的成像精度。利用希尔伯特变换和EMD方法实现管道缺陷回波信号的特征提取,最后使用BP神经网络建立了三输入二输出模型,实现管道周向缺陷大小的辨识。基于机器视觉检测理论,对管道内表面进行图像采集,分析管道内表面缺陷,并实现管道内表面缺陷的三维可视化。将超声导波与机器视觉进行互补式融合,充分发挥各自优势,实现对管道缺陷检测数据全方位、多角度的分析与判断,为后续的管道缺陷检测系统开发奠定基础。
{URL}: https://link.cnki.net/doi/10.27724/d.cnki.gnmgk.2022.000554
{DOI}: 10.27724/d.cnki.gnmgk.2022.000554
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人脸识别的船舶驾驶员疲劳检测系统的研究_
{Author}: 李慧楠
{Tertiary Author}: 于新华
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 船舶驾驶员疲劳检测;深度学习;YOLOv5s轻量级网络
{Abstract}: 海上工作强度大、时间长、昼夜节奏紊乱等因素造成船舶驾驶员身体和精神负荷较大,进而导致疲劳。在疲劳状态下,驾驶员因注意力不集中、动作迟缓等行为,容易引发海上交通事故。因此,研发一个实时监测驾驶员疲劳状态和报警提醒的系统,及时发现和制止疲劳驾驶,对减少水上交通事故,保障驾驶员人身安全和船舶航行的安全具有重要意义。目前,在陆地上的疲劳监测技术已比较成熟,但用于海上环境下的疲劳检测系统还尚不成熟,不能有效避免海上光照、天气、船体晃动等环境因素对图像识别率的影响。为解决以上问题,本文提出了一个基于人脸识别的船舶驾驶员疲劳检测系统。我们的主要研究如下:(1)本文综合陆地上现有的疲劳检测技术的优缺点,研究了一个基于深度学习YOLOv5s轻量级网络结构的人脸识别模型,该模型可有效解决在复杂海上环境下人脸识别率不高的问题,提高人脸检测的准确性和速度。(2)本文通过人脸识别获得的面部特征信息和五官关键点定位,并利用三庭五眼两等分的五官划分方法截取相应的关键区域,研究了一个基于CNN卷积神经网络的分类模型来实现眼嘴部张闭合状态的精准分类。(3)本文利用PERCLOS疲劳判断准则,在获得的眼嘴张闭合状态的基础上,计算眨眼频率和打哈欠频率,结合眼睛注视帧新指标,提高了疲劳检测的准确率。本文设计出了一套体系完整的船舶驾驶员疲劳检测系统并对有关实验进行研究和讨论,在Yaw DD打哈欠视频数据集和实验室模拟的实际场景数据集上测试,识别疲劳准确率达到92%,速度达到每秒76帧,该系统准确率和实时性都达到最优。实验结果表明,本文提出的疲劳检测方法能够有效地检测船舶驾驶员的疲劳状态并及时提醒,具有一定的创造性和实用性。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000630
{DOI}: 10.27049/d.cnki.ggldc.2022.000630
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLO算法的煤矸识别方法与实验研究
{Author}: 刘普壮
{Tertiary Author}: 郭永存
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 煤矸识别;机器视觉;卷积神经网络;YOLO;特征提取可视化
{Abstract}: 近年来,我国大力推进煤炭行业绿色发展,传统的选煤技术和选煤理论面临严峻的挑战,急需更加智能、环保及高效的煤矸分选技术。利用卷积神经网络技术实现煤矸目标高维特征的自动提取,使得选矸机器人能适应复杂环境和煤矸的多样性,基于深度学习的煤矸识别与定位方法,可实时输出煤矸目标检测结果包含煤矸的类别信息和位置信息,提高了煤矸检测系统的准确率和稳定性。主要研究工作如下:(1)设计并搭建煤矸目标识别与定位试验台:煤矸目标检测实验台的整体设计以及平台硬件搭建,设计相机选型、镜头选用、照明方案设计等,通过搭建的目标检测实验台来获取煤矸目标检测数据集,并使用labelImg工具对图像中的煤矸目标进行人工边框标记,为后续煤矸目标检测优化算法的训练制作数据集。(2)轻量化YOLO的煤矸目标识别与定位算法:提出基于卷积神经网络技术的煤矸检测方法,将深度学习方法与煤矸检测问题相结合,实现了对煤矸目标的实时端到端检测;同时轻量化特征提取网络,在原有特征提取网络CSPDarknet53基础上进一步精简网络,提出CSPDarknet27特征提取网络保证煤矸特征的充分提取而降低网络复杂性,可实现煤矸目标实时识别与定位。(3)改进两尺度特征预测:本文采用两尺度特征预测+多尺度特征融合方式进行煤矸特征的提取与目标预测,使煤矸特征提取不同阶段分辨率的煤矸特征图,提取的特征图具备丰富的位置信息和更深层次的语义信息;通过改进该方法,可以减小煤矸目标尺寸变化的影响,进一步提高煤矸目标识别与定位的准确度。(4)实现煤矸特征提取过程可视化:基于类激活映射CAM实现特征提取过程可视化,同时利用CNN可视化探究模型进行煤矸识别的特征区域,进一步探究模型进行煤矸识别的可靠依据。图[37]表[8]参[61]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2022.000323
{DOI}: 10.26918/d.cnki.ghngc.2022.000323
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于局部几何信息的ICP点云配准算法研究
{Author}: 张强
{Tertiary Author}: 刘玉珍;林森
{Publisher}: 辽宁工程技术大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;点云配准;邻域点信息;迭代最近点
{Abstract}: 随着高精度测量传感器的快速发展,用三维点云描绘世界的方式开始被广泛使用。点云配准作为三维点云处理过程中的重要一环,是完成三维重建、虚拟现实、文物修复、智能交通等实际工程的关键技术。ICP算法是应用最广泛的点云配准算法,为解决该算法本身的局限性,并提高点云配准的精度和效率,本文分别从提取特征点、计算描述符、获取匹配点对和精确配准4个方面进行研究,提出了两种点云配准算法:为解决噪声干扰、数据丢失情况下ICP算法鲁棒性差,配准精度和配准效率低的问题,提出改进的基于快速点特征直方图的ICP点云配准算法。首先,融合内部形态描述子和法向矢量角变化来提取点云特征;其次,使用指数函数改进欧氏距离,作为FPFH算法的权重系数,用其进行特征点描述;然后使用双重约束和单位四元数算法完成初始配准;最后,给ICP算法构建双向k维树,并提出用距离计算每个点对的权重,作为ICP迭代误差函数的加权公式。实验数据集用斯坦福模型和两组实际点云,实验结果表明,该算法解决了ICP算法在噪声干扰、数据丢失环境下的局限性。相较于其他算法,实物点云的配准精度至少提高11%。为解决配准部分重叠物体点云时,ICP算法配准精度和配准效率低的问题,提出基于邻域点信息描述与匹配的点云配准算法。首先,在三个半径比例下根据点的曲率变化、测量角度和特征值性质提取特征点;其次,计算改进的法向量夹角、点密度和曲率值,获取多尺度矩阵描述符;然后,为描述符建立k维树获取匹配关系,并提出几何特征约束和刚性距离约束组合,剔除错误点对,实现粗配准;最后,通过k维树改进ICP算法完成精确配准。研究设计了实际物体点云配准和斯坦福模型模拟真实物体配准两组实验,实验结果表明,相较于其他算法,实际部分重叠点云配准中该算法的配准精度、效率至少提高29%、40%;斯坦福模拟实验中,该算法的配准精度、效率至少提高11%、12%。该论文有图55幅,表9个,参考文献69篇。
{URL}: https://link.cnki.net/doi/10.27210/d.cnki.glnju.2022.000630
{DOI}: 10.27210/d.cnki.glnju.2022.000630
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的六自由度机械臂分拣系统设计
{Author}: 陈思宇
{Author Address}: 沈阳理工大学;
{Journal}: 内燃机与配件
{Year}: 2022
{Volume}: 
{Issue}: 11
{Pages}: 43-45
{Keywords}: 机器视觉;LabVIEW;机械臂;模式匹配;Arduino
{Abstract}: 传统的依靠人工进行流水线分拣的工作存在诸多弊端，因此为了解决这个问题，提出了一种基于机器视觉的六自由度机械臂快速分拣系统，该系统选取工业相机作为图像采集设备，上位机在LabVIEW中进行模式匹配来进行颜色识别，然后进行机械臂运动学逆解，从而得到每个关节应旋转的角度，然后利用Arduino与LabVIEW进行串口通讯，进而进行机械臂的运动控制。经实验测试分析，验证了此分拣系统的快速性与准确性，在实际生产中具有较高的理论指导和实际价值。
{ISBN/ISSN}: 1674-957X
{Notes}: 13-1397/TH
{URL}: https://link.cnki.net/doi/10.19475/j.cnki.issn1674-957x.2022.11.033
{DOI}: 10.19475/j.cnki.issn1674-957x.2022.11.033
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉SLAM的AGV建图与导航技术研究
{Author}: 孟特
{Tertiary Author}: 张凤生
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自动导引车;即时定位与地图构建;路径规划;机器视觉
{Abstract}: 自动导引车（Automated Guided Vehical,AGV）作为移动机器人的重要分支,在制造、仓储、港口、危险及特种作业等行业领域应用广泛。即时定位与地图构建（Simultaneous Localization and Mapping,SLAM）作为AGV关键技术,一直是研究的热点。视觉SLAM通过相机获取周围环境信息,完成AGV自身即时定位与环境地图构建,具有信息量大、适用范围广等优点,是目前AGV领域主流的研究方向。本文对国内外AGV发展现状和视觉SLAM研究状况进行了综述与分析。在此基础上,对视觉SLAM的自主定位、地图构建和路径规划算法进行理论分析与实验研究,主要研究内容和结果如下:（1）根据几何光学成像原理,建立相机成像模型,详细分析物像空间的坐标变换关系和相机图像畸变系数的求解。采用张正友标定方法完成深度相机标定,标定效果良好。（2）针对传统ORB算法存在特征点冗余和簇集问题,利用Q＿tree均匀算法对特征提取进行均匀化处理,减少冗余特征点的同时,使特征点在整个图像中的分布更均匀,有效减少后端位姿估计的计算量。在后端位姿估计中,通过将EPn P与ICP算法相结合,提高了位姿估计精度。（3）针对稀疏特征点的稀疏路标地图无法满足路径规划需求的问题,增加稠密建图线程,构建三维稠密点云地图,并在TUM数据集上验证了算法的可行性。（4）针对A*算法在路径规划过程中存在的节点重复搜素,影响最优路径规划效率的问题,将A*算法与跳点搜索相结合,有效筛选出不必要搜索的节点,提高了算法的路径规划效率,对于大规模地图效果明显。最后,以ROS为软件平台,在自主搭建的AGV实验系统上进行实际场景中的AGV建图、路径规划和避障实验。实验表明:改进ORB-SLAM算法构建的实际场景三维稠密点云地图良好,改进A*算法可以规划出完整路径;同时改进A*算法和局部路径规划算法的适应性良好,相互配合可实现AGV实时避障功能。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2022.002213
{DOI}: 10.27262/d.cnki.gqdau.2022.002213
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于线激光的三维重建系统研究
{Author}: 徐仕东
{Tertiary Author}: 毕远伟
{Publisher}: 烟台大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;三维重建;多线激光;点云拼接
{Abstract}: 三维重建技术是计算机视觉的重要研究内容之一。通过线激光扫描被测物体,计算得到被测物体表面的点云数据,然后再将得到的点云数据构建成三维模型是三维重建技术的一大主流方向。线激光扫描重建技术在逆向工程、文物和艺术品数字化存档、缺陷检测等方面有诸多应用。因此,对三维扫描技术的研究与完善具有重要意义。本文主要对基于多线激光的手持式三维扫描重建装置和方法进行了研究。首先,本文分析了基于多线激光的手持式三维扫描重建系统的理论基础。研究了基于相机与线激光的三维测量重建原理,包括相机成像模型、单目单线激光三维测量模型、双目多线激光三维测量模型以及如何将每次重建出的点云数据拼接在一起。然后,针对市场上现有的大多数手持式三维扫描仪都需要在被测物体上粘贴标志点的不便性,本文提出了一种相机拍摄固定标志物的点云自动拼接方法,通过在装置上增加一个定位相机、在被测物体周围放置标定板,扫描过程中使定位相机实时拍摄标定板,获取定位相机与标定板坐标系的位姿关系,将每次重建获得的点云数据转移至统一的世界坐标系内,以实现点云自动拼接。设计了一种由计算机、相机、线激光发射器和标定板组成的基于多线激光的手持式三维扫描重建装置。并且基于本文方法和装置提出完整的三维重建系统算法流程。最后,通过对纸盒、轮胎等物体的三维重建实验,验证了本文提出的方法能自动拼接点云,具有准确、高效、鲁棒性强等优点;验证了本文设计的装置具有成本低、操作简单、适用范围广等优点。
{URL}: https://link.cnki.net/doi/10.27437/d.cnki.gytdu.2022.000047
{DOI}: 10.27437/d.cnki.gytdu.2022.000047
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的移动机械臂分拣系统关键技术的研究
{Author}: 韩松
{Tertiary Author}: 刘晓平
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 分拣系统;移动机械臂;深度学习;目标检测;图像分割
{Abstract}: 随着电子商务的蓬勃发展以及人力成本的不断上升,物流和快递分拣中心对智能化和无人化的需求越来越高。许多分拣中心引入了交叉带分拣系统,大幅提高了快递包裹的分拣效率,降低了运营成本。然而,在许多分拣系统的入口和出口处,仍需使用人力对堆叠包裹进行分拣和整理,严重影响了系统整体的运行速度和分拣效率。为了解决这个问题,实现对复杂场景下堆叠包裹的自动分拣,本文基于机器视觉设计并搭建了移动机械臂分拣系统,并对如何高效、精确和稳定地实现分拣进行了深入研究。(1)为了提高移动机械臂的定位精度,提出了基于多传感器融合的定位算法。首先,对麦克纳姆轮轮系结构的移动基座进行了运动学建模;然后,提出了一种基于卡尔曼滤波的里程计系统,通过电机编码器和惯性传感器的定位信息融合,提高了里程计系统的定位精度和鲁棒性;同时,提出了一种时域滤波算法,将红外图像传感器得到的数据进行后处理,有效降低了外部环境对传感器定位精度的影响;最后,提出一种快速的神经网络模型将里程计系统的定位信息和红外图像的定位信息进行融合,提高了移动基座的定位精度和稳定性。实验证明,本文提出的传感器融合方法有效提高了定位精度和稳定性,满足分拣任务对移动机械臂定位精度的要求。(2)为了实现对堆叠包裹的精确和快速检测,提出了一种轻量化的基于多模态信息融合的目标检测网络(Object Detection Network Based on Multi-modal Information Fusion,OD-MF)。首先,在图像预处理阶段提出了一种新型的双边滤波算法,解决了深度图像的“空洞”问题,为后续工作提供了更加精确的三维几何信息;然后,提出了基于多模态的OD-MF网络模型,将从深度信息中提取出的全局梯度特征作为自注意力模块的输入,对隐式的空间特征信息和多维度网络特征进行学习,提高了堆叠包裹的目标检测精度;为了提高网络速度,提出一种新的通道剪枝策略,利用尺度变量和网络的联合权重对模型进行稀疏化,自动识别并去除不重要的通道,实现了对OD-MF模型的轻量化;最后,通过实验证明了在多模态信息融合和剪枝策略的共同作用下,目标检测的精度和速度同时得到了提升。(3)为了实现对目标包裹的拣选区域的语义分割和遮挡程度的估计,提出了一种基于Swin Transformer的多模态分割网络(Multi-modal Segmentation Network Based on Swin Transformer,MS-ST)。首先,网络模型通过引入Swin Transformer模块,建立了图像各区域之间的联系,更大范围地实现了长距离语义信息交互,提高了模型的表征能力;然后,通过加入频域信息和深度信息,形成多模态融合网络,使其收敛速度和检测精度得到了进一步的提升。同时,提出了一种多任务的网络模型,加入了对目标遮挡程度的估计分支,为后续分拣次序的判定提供了重要的依据;最后,通过实验,证明了本模型显著提高了快递包裹可拣选区域与不可拣选区域的分割精度,并实现了遮挡程度的正确估计。(4)在实现目标精确检测、拣选区域准确分割和遮挡程度正确估计的前提下,针对包裹拣选位姿估计和拣选次序判定的问题,本文提出了最优拣选位姿估计算法和最优拣选次序判定策略。首先,根据拣选区域的重心提出了一种拣选位置的初步确定方法和准则;然后,提出了一种基于随机抽样一致性(Random Sample Consensus,RANSAC)算法的拣选姿态估计算法,得到最优拣选姿态,并根据算法拟合出的拣选平面通过进一步的优化得到了最优的拣选位置;利用多目标包裹的拣选位姿信息和遮挡程度,提出一种新的拣选次序判定策略,该策略最大程度地保证了系统的稳定性;最后,在实验阶段,证明了最优拣选位姿求解算法的正确性和准确性,通过量化指标证明了本文提出的分拣次序判定策略可以充分保证机器人分拣系统的稳定性。(5)本文进行了移动机械臂视觉分拣系统及其软件系统的设计与搭建,并进行了总体的验证实验。通过实验,进一步证明了本文所提出算法的有效性和适用性,验证了分拣系统的准确性和稳定性。同时,证明了本文提出的基于机器视觉的移动机械臂分拣系统可以用于物流中心快递包裹的实际分拣场景。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.000284
{DOI}: 10.26969/d.cnki.gbydu.2022.000284
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的联轴器尺寸测量及表面缺陷检测研究
{Author}: 王亭亭
{Tertiary Author}: 郭忠峰
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;联轴器;尺寸测量;缺陷检测
{Abstract}: 针对某联轴器生产厂家对弹性膜片联轴器的实际生产检测需求,为了改善产品出厂前人工检测效率低、稳定性差的问题,计划将现有的人工产品检测改进为机器视觉检测。本课题将利用机器视觉技术完成对联轴器中心孔的尺寸测量以及边缘凹坑缺陷检测工作,主要研究内容如下:首先,根据产品检测需求确定机器视觉检测系统的整体方案,将整个系统分为照明系统、图像采集系统以及计算机视觉系统三个模块。通过对光源特性及照明方式进行对比,结合尺寸测量及缺陷检测系统的需求特征,制定了不同的照明方案。根据检测系统的需求特点,完成尺寸测量与缺陷检测系统图像采集设备的选型工作,并搭建两组检测试验平台。其次,通过分析世界坐标系、相机坐标系、图像坐标系以及像素坐标系之间的转换关系,在图像采集前对检测系统进行相机标定,获取到相机的内、外参数,进而得到图像像素尺寸与真实物理尺寸之间的比例关系,为后续尺寸测量工作做铺垫。然后,针对联轴器的中心孔尺寸测量需求,先对中心孔的不规则形状进行边缘轮廓提取,并利用二维计量模型理论中的最小二乘拟合法,实现中心孔标准圆形轮廓的高精度拟合。再通过创建中心孔的模板图像,使用模板匹配与仿射变换方法,对新采集的图像进行轮廓匹配,成功实现任意位置的自适应尺寸测量功能。最后,为了实现联轴器的定向区域缺陷检测功能,先对采集到的图像进行二值化和滤波降噪处理,再结合联轴器的缺陷特征,提出闭合性区域填充优化方案,通过对法兰端面上的孔洞进行区域填充,有效排除定向区域外的干扰因素,进而实现法兰边缘轮廓的定向提取,并使用形态学原理对联轴器边缘轮廓进行标准圆拟合,利用轮廓求差法实现定向区域的凹坑缺陷检测。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000470
{DOI}: 10.27322/d.cnki.gsgyu.2022.000470
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低光照图像增强算法研究
{Author}: 于娜娜
{Tertiary Author}: 李晋江
{Publisher}: 山东工商学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 低光照图像增强;深度学习;迭代;LBP特征;注意力机制
{Abstract}: 在夜晚或低光照条件下,由于采集到的光子数较少,信号信噪比较低,导致成像装置无法精确地捕捉到图像的细节和色彩,从而对图像的质量造成很大的影响。这不仅会对人的视觉产生一定的影响,同时也给计算机视觉任务带来了巨大的挑战。低光照图像增强技术可以降低图像噪声、提高图像质量,有较大的研究价值。近年来,低光照图像增强技术已经取得了很大的进步,但是现有的算法增强后的结果仍然出现对比度较低、过度曝光、模糊不清以及噪声等现象。为了解决这一系列问题,本文利用深度学习相关理论,对低光照图像增强进行了相关的研究。文章的工作主要包括以下几个部分:(1)本文设计了一种基于局部二值模式(Local Binary Pattern,LBP)的渐进式特征聚合网络,来完成低光照图像增强任务。LBP特征对光照不敏感,包含丰富的纹理信息。在网络中,使用引导的方式将LBP特征加入到网络的每次迭代中,这有助于恢复低光照图像的细节信息。首先,在双重注意力机制的作用下,提取原始低光照图像中的全局特征信息。其次,在特征聚合模块中,将提取到的不同的特征加以聚合。接下来,使用循环层来共享不同阶段提取的特征,并引入残差层进一步提取更深层次的特征。最后,输出增强后的图像。通过消融实验验证了该方法的合理性,与其他许多先进的方法相比,该方法在视觉比较方面和定量评估方面都具有较大的优势。(2)设计了一种多级模块化网络模型用于低光照图像增强。此任务分为三个阶段:特征提取阶段、特征聚合阶段和图像增强阶段。除去输入层和输出层,网络共有88层,端到端地完成了低光照图像增强的任务。网络从底层向上层抽取了局部和低级的特征,如色彩、纹理等。最后,将全局信息和局部信息逐层合并。该方法解决了现有的低光照图像增强方法存在的一系列问题,并且在多个公共数据集上验证了该方法的有效性。同时,该方法与现有的多个方法进行了图像增强对比。经过大量的实验验证,本文提出的算法可以有效地提高低光照图像的质量,并且在几个定量评价指标方面也优于最先进的低光照增强方法。
{URL}: https://link.cnki.net/doi/10.27903/d.cnki.gsdsg.2022.000135
{DOI}: 10.27903/d.cnki.gsdsg.2022.000135
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的汽车漆面缺陷检测技术
{Author}: 赵健;付琴
{Author Address}: 上海蔚来汽车有限公司;赫比国际有限公司;
{Journal}: 汽车工艺与材料
{Year}: 2022
{Volume}: 
{Issue}: 07
{Pages}: 16-19
{Keywords}: 汽车漆面;缺陷检测;机器视觉;深度学习
{Abstract}: 对基于机器视觉的汽车漆面缺陷检测技术进行了深入研究，分析了隧道式和机器人式缺陷检测系统的优劣势，比较了传统图像算法和深度学习算法的异同点，并通过应用案例来展示漆面缺陷检测系统的运行状态和经济效益，为有意向应用该项技术的企业提供指导和帮助。在实际应用中，缺陷识别准确率可以达到98.5%，一套系统可节约8名操作人员，完全满足汽车漆面缺陷检测的要求，投资回报率高。
{ISBN/ISSN}: 1003-8817
{Notes}: 22-1187/U
{URL}: https://link.cnki.net/doi/10.19710/j.cnki.1003-8817.20220092
{DOI}: 10.19710/j.cnki.1003-8817.20220092
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视觉多目标跟踪方法研究
{Author}: 梁天一
{Tertiary Author}: 骆志刚;蓝龙
{Publisher}: 国防科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉多目标跟踪;基于检测的跟踪;联合检测与跟踪;近邻信息;图卷积神经网络;轨迹片段重识别;样本分配;损失函数;知识蒸馏;模型压缩
{Abstract}: 视觉多目标跟踪是计算机视觉领域的一项重要研究课题,其核心任务是主动发现视频中人们所感兴趣的物体(如行人、车辆等),并不断预测其轨迹,从而可以为自动驾驶、人机交互和智能视频监控等更高级的视觉任务提供支持。由于近些年视觉目标检测技术的快速进步,基于检测的跟踪(Tracking by Detection,TBD)和联合检测与跟踪(Joint Detection and Tracking,JDT)成为解决多目标跟踪问题的两种主流范式。基于检测的跟踪首先使用独立的目标检测器在视频帧中定位目标,然后使用独立的外观、运动及交互关系等模型抽取目标的特征表达进行相似度判别,最终使用关联模型依据相似度关系进行轨迹预测。由于在复杂的跟踪场景中,目标间的相互遮挡、检测器漏检和虚检、光照变化及姿态变化等因素都会对目标特征建模、相似度判别和轨迹关联产生不利影响,因此需要研究更加鲁棒的外观特征模型和关联模型来应对上述问题。联合检测与跟踪的方法将目标检测和重识别(Re-identification)等子模型集成在一个完整的网络结构中,可以同时输出检测响应和目标外观等特征,因此通常具有更好的训练和推理效率,但其除了面临上述多目标跟踪研究中的经典问题外,还需要解决多个子模型联合训练所带来的多任务学习问题,同时其跟踪速度仍有待进一步提升。针对上述关键问题,本文进行了深入调研与分析,结合当前最新的深度学习技术,提出了若干种具备理论创新和实用价值的视觉多目标跟踪方法。本文具体的研究工作和成果主要包括:1.提出了一种利用近邻信息增强外观特征建模的多目标跟踪方法。现有多目标跟踪方法在外观特征建模时只关注个体目标,容易受到遮挡和光照变化等不利因素影响,导致相似度判别及跟踪效果下降。为解决这一问题,本文提出利用目标近邻信息学习更加鲁棒的外观特征。该方法的动机是:诸如行人等目标往往以群体的方式进行活动,因此当其中个别目标的外观发生显著变化时,我们仍可以借助群体中其他成员的信息来识别该目标。为此,本文首先提出了一种基于时空关系的近邻选择算法,通过挖掘轨迹间的时空关系,高效地为跟踪目标选择合适的近邻;随后,本文提出近邻图机制,将目标与其近邻构建为图结构,使用图卷积神经网络进行特征聚合,最终得到融合近邻信息的目标外观特征。在多个基准数据集上的实验证明了该方法的有效性。2.提出了一种多目标跟踪轨迹片段重识别优化框架。该框架以其他跟踪器的结果作为输入,对其中因遮挡和检测器漏检而产生的轨迹片段进行重识别,关联为更加完整的轨迹。具体而言,框架将轨迹片段和它们之间的关系映射为图结构中的节点和边,把轨迹片段间的重识别转化为多标签能量函数优化问题,最优解是图中属于相同目标的节点得到相同的标签。本文使用基于图割的α扩展算法来求解该能量函数,并创新性地使用标签惩罚机制限制标签分配数量,从而达到更好的重识别效果。本文还提出了一种基于空间变换网络的外观模型和一种基于层次聚类思想的后处理方法,用来优化外观特征建模和轨迹片段关联。公开数据集上的实验表明了该框架的有效性。3.提出了面向多目标跟踪中检测与重识别联合训练的样本分配方法和损失函数。在检测与重识别联合训练的过程中,现有工作往往直接套用目标检测中的样本分配方法和损失函数,然而这些方法没有考虑重识别任务的特点,导致联合训练偏向于检测任务,同时容易产生模糊样本分配(即同一个正样本被分配给多个实例)。为解决此问题,本文首先提出一种具有身份感知(Identity-aware)的样本分配方法,该方法能根据训练样本的检测代价和重识别代价,自适应地进行正负样本划分以满足两个任务的特点,并能在提供充足正样本的同时避免模糊分配。此外,本文还提出了一种新的损失函数,该函数将重识别信息与聚焦损失(Focal Loss)相结合,使具有较强身份判别性的样本在损失中占有更高比重,从而引导训练更加关注这类有利于重识别任务的样本。MOT16/17/20三个数据集上的测试表明,所提方法能有效改善联合训练中的偏向性问题,从而显著提升跟踪器性能。4.提出了一种基于知识蒸馏的多目标跟踪模型压缩方法。当前多目标跟踪方法为获得较高的准确性,往往采用层数较深、参数较多的网络结构,一定程度上牺牲了跟踪速度。为实现准确性和速度之间更好的平衡,本文首次提出利用知识蒸馏技术对多目标跟踪模型进行压缩,使用更加轻量级的网络作为学生,通过蒸馏学习向大网络(教师)学习特征表达与标签预测,从而获得接近大网络的性能。在面向特征学习的蒸馏过程中,本文运用空间注意力机制引导学生网络关注特征图的前景区域,同时创新性地提出建模学生和教师在空间与通道注意力方面的差异,使用差异信息优化特征学习。在基于软标签(Soft Label)的蒸馏中,本文提出利用教师网络知识构建前景掩码,使用前景掩码过滤低质量软标签,降低其对蒸馏学习的影响。在多个基准数据集上的实验表明,本蒸馏方法可将学生网络的跟踪准确性(MOTA)提升至领先水平,同时速度优于教师网络20.0%～27.4%,参数量减少28.5%～87.1%。
{URL}: https://link.cnki.net/doi/10.27052/d.cnki.gzjgu.2022.000036
{DOI}: 10.27052/d.cnki.gzjgu.2022.000036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度神经网络中的后门攻击与防御研究
{Author}: 李少锋
{Tertiary Author}: 朱浩瑾
{Publisher}: 上海交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 人工智能安全;后门攻击;数据投毒攻击;自然语言处理;联邦学习
{Abstract}: 随着现代信息技术所能提供的算力越来越强,能够处理的数据越来越多,为深度学习技术的突破提供了可能。自2006年开始,基于深度神经网络的人工智能模型迅猛发展,与移动互联网、物联网等应用场景深度融合,这些丰富的应用场景反过来又激发了深度学习发展的新浪潮。随着深度学习技术的快速发展和在各个行业中的广泛应用,其安全性一直受到广泛地关注。然而,现阶段深度学习技术所表现出的不可解释性、数据强依赖性等局限,为其在各种场景中的落地应用带来了巨大的安全风险。在深度学习模型从开发到部署应用的整个生命周期中均存在着各种各样的安全问题,在模型的训练阶段存在着训练数据被污染的风险,此类攻击称为数据投毒攻击。该攻击旨在恶意扰动模型的决策边界,使得训练出来的模型存在内在的缺陷。在深度学习模型的部署运行阶段,由于深度神经网络决策过程易受微小扰动的影响,攻击者可以发起对抗样本攻击等造成模型决策结果的错误。部署以后的深度学习模型还可能泄露用户的重要隐私信息,通过对模型输入输出等各类信息的深度挖掘和关联分析,攻击者能够还原出训练该模型时使用的用户隐私数据。此外,深度学习模型也存在着通过黑盒查询、测信道分析等手段被窃取的风险,从而带来严重的知识产权纠纷等问题。在上述深度神经网络所面临的众多安全威胁中,后门攻击是一类特殊的数据投毒攻击,该攻击只会对模型原有的性能产生轻微的影响,因此不会对用户的正常使用产生影响。同时该攻击会通过后门特征在决策边界之间建立起一条快捷通路,当后门特征出现在输入样本中时,模型中的快捷通路被激活,模型的决策会忽略其他的输入特征而仅关注后门特征,导致模型表现出攻击者设定好的目标行为。本文面向人工智能安全中的后门攻击问题,以人眼视角下后门触发器设计的不可见性为研究目标,首先在图像分类任务中基于图像隐写和正则化约束提出了一类新型的不可见后门攻击方法。其次,在自然语言处理系统中基于同形字与文本生成技术在三种主流自然语言处理任务上设计了更加隐蔽的后门攻击。最后针对联邦学习系统中的后门攻击,从合作博弈的视角进行了分析,并提出了基于Shapley值的检测框架。其主要贡献如下所述。首先,针对传统的图像处理系统中后门攻击触发器的不可见性差,隐蔽性不足的问题,本文基于神经网络易受人类无法察觉的微小扰动的干扰这一特性,提出并设计了两种新型的不可见后门攻击方式。本文基于图像结构相似度(SSIM)和人眼感知相似度(LPIPS)提出了两种后门攻击不可见性度量指标,量化地度量了两类新型后门攻击对人类的不可见程度。本文提出的不可见后门攻击建立了后门攻击不可见性与后门攻击成功率之间的平衡,能够同时做到更好的隐蔽性和更高的实用性。最后,研究了本文提出的两类后门攻击在目前主流的后门攻击检测技术下的有效性,以及对相应的防御技术进行了探讨。其次,在自然语言处理领域,随意变化一个单词序列中的单词很容易因为破坏了语法语义规则而被人眼所识别。此外,如果在单词内部增加、减少字母或者更改字母的顺序等扰动方式也极易被人眼所察觉。因此,想要在文本域上设计出既足够“罕见”从而可以作为后门信号,又能作为一种不可见微小扰动来保持污染后文本的可读性以及上下文的一致性是非常困难的。这使得自然语言处理中大多数现有的触发器设计仍然停留在仅保证后门攻击的有效性上,还未深入地思考过其隐蔽性的问题。本文系统地探索了现代自然语言处理系统中的“后门攻击”问题,提出基于同形字以及文本生成技术的后门触发器设计方法。相对于以往攻击,该攻击能够将触发器以隐蔽的方式嵌入到输入文本中,具有自然流畅,且能够契合上下文语义的特点,能够使得人类检查人员难以察觉。同时本文首次将后门攻击扩展到神经机器翻译、问答系统等当前常用的自然语言处理系统中,揭示了这些系统面临的严重安全威胁。并对自然语言处理中后门攻击的防御问题进行了研究。最后,针对基于联邦学习的分布式训练架构在电子医疗应用中的优势以及存在的后门攻击威胁,本文给出了联邦学习下后门攻击的防御技术。并从实际应用的维度分析了基于联邦学习的电子医疗场景下,恶意本地用户发起后门攻击的过程,影响以及结果。最后给出了在合作博弈下基于Shapley值的后门攻击检测算法。本文在多种机器学习任务上(包括图像域的乳腺癌诊断任务和文本域的阿尔茨海默症检测任务)验证评估了本文检测算法的有效性和性能。
{URL}: https://link.cnki.net/doi/10.27307/d.cnki.gsjtu.2022.000030
{DOI}: 10.27307/d.cnki.gsjtu.2022.000030
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于光谱及成像技术的欧李果品质无损检测研究
{Author}: 王斌
{Tertiary Author}: 贺俊林
{Publisher}: 山西农业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 欧李果;可见/近红外光谱技术;高光谱成像技术;信息融合技术;品质检测;无损检测
{Abstract}: 欧李果为我国特有的水果,因果实中富含活性钙且易被人体吸收,又被称为“钙果”。果实色泽鲜艳、风味独特、营养丰富,且具有高保健、高抗性的特点,被赞誉为“超级水果”。随着消费者对欧李果内部品质和外观品质的关注度越来越高,为降低检测成本、保障欧李果品质、提高欧李果附加值及产品系列化,探索有效的欧李果品质无损检测方法具有重要意义。本研究以欧李果为研究对象,利用可见/近红外光谱技术、高光谱成像技术及信息融合技术结合化学计量学和深度学习方法对欧李果内部品质、外部缺陷和成熟度进行快速无损检测研究。主要研究内容与结论如下:(1)基于可见/近红外光谱技术建立欧李果光谱信息与SSC、硬度和类黄酮含量的定量预测模型。对比分析6种光谱预处理方法(MSC、S-G(5点)、MSC+S-G(5点)、De-T、MA、MF)对欧李果SSC、硬度和类黄酮含量的PLSR模型预测效果的影响。采用UVE、CARS、RC、SPA、UVE-SPA和UVE-CARS方法提取单一品质指标的特征波长,分别建立线性(PLSR)和非线性(LS-SVM、2D-CNN)预测模型。结果表明,欧李果SSC指标的预测,MSC-UVE-CARS-PLSR模型预测效果最佳,其Rp、RMSEP和RPD 分别为 0.8579、0.9059 和 1.8766;欧李果硬度指标的预测,De-trending-CARS-LS-SVM 模型预测性能最佳,其 Rp、RMSEP 和 RPD 分别为 0.9092、0.9169和2.1485;欧李果类黄酮含量指标的预测,S-G(5点)-SPA-LS-SVM模型预测性能最优,其Rp、RMSEP和RPD分别为0.9102、1.0613和1.8656。为后续开发欧李果内部综合品质指标无损检测软件提供研究基础。(2)探究了基于高光谱成像技术对欧李果完好样本和缺陷样本(锈斑、虫害、裂纹)进行无损检测研究的方法。从光谱信息角度(945～1675nm),对比5种预处理方法(SG、SNV、MSC、BC、De-T)建立的PLS预测模型,原始光谱经De-T方法预处理后建立的PLS模型性能最好。采用RC、SPA和CARS算法提取特征波长,分别建立基于全波段光谱和特征波长的线性(PLS-DA)和非线性(BPNN、LS-SVM)检测模型,并对其完好样本和缺陷样本(锈斑、虫害、裂纹)进行判别。结果表明,基于全波段光谱建立的LS-SVM模型对预测集样本的整体判别准确率最高(88.57%);基于CARS算法提取特征波长建立的LS-SVM模型判别准确率最高,其校正集和预测集的判别准确率分别为86.35%和91.43%。(3)提出了一种端对端的卷积神经网络光谱定性分析模型(1D-CNN),并将其应用于判别欧李果缺陷类别。为验证模型的有效性,比较了该模型与传统最优模型(RC-PLS-DA、CARS-BPNN、CARS-LS-SVM)的判别准确率,得出 1D-CNN 训练模型最优,该模型对校正集和预测集判别准确率分别为96.83%和95.24%。通过混淆矩阵得到该模型对锈斑果、裂纹果、虫害果和完好果的判别准确率分别为91.30%、95.24%、90.48%和100.00%,平均分类准确率为94.26%。(4)基于高光谱成像技术从图像识别的角度分析了欧李果完好样本和缺陷样本的检测效果。基于CARS算法选择的13个特征波段,采用PCA和MNF算法提取特征图像,比较得出PCA算法识别效果较好;提出Imfill算法和Canny边缘检测算子与Regiongrow算法和Bwareaopen算法相结合对欧李果缺陷特征区域进行识别。研究得出,该缺陷识别算法对预测集的整体识别准确率为91.43%。采用GLCM和Tamura两种方法提取欧李果特征图像感兴趣区域的纹理特征参数,利用PCA算法对纹理特征参数进行降维,比较基于特征光谱、纹理特征、光谱信息融合纹理特征建立的LS-SVM模型对欧李果缺陷类别的判别结果。对比可知,基于特征光谱融合纹理特征建立的LS-SVM模型判别效果最好,其校正集和预测集判别准确率分别为96.19%和94.29%。(5)为了研究高光谱成像技术对不同成熟时期欧李果内部品质的预测效果,以不同成熟时期欧李果为研究对象,基于945～1675nm范围内的光谱信息,对比5种预处理方法(S-G、SNV、MSC、BC、De-T)对欧李果SSC、硬度和类黄酮含量的线性PLSR和非线性LS-SVM模型预测效果的影响。比较了 SPA、CARS、UVE、RF、UVE-SPA和UVE-CARS算法对线性MLR和非线性LS-SVM模型预测效果的影响。结果表明,在同一种算法下,非线性LS-SVM模型的预测性能普遍优于线性MLR模型,且模型更加稳定。对欧李果SSC而言,SPA-LS-SVM模型预测结果最优,其Rp、RMSEP和RPD分别为0.8526、0.9703和1.9017;欧李果硬度的最佳预测模型是UVE-CARS-LS-SVM,其Rp、RMSEP和RPD分别为0.7879、1.1205和2.0221;对欧李果类黄酮含量的预测,SPA-LS-SVM模型预测效果最优,其Rp、RMSEP和RPD分别为0.9104、1.9039和2.6101。(6)基于高光谱成像技术对光谱信息和图像特征(纹理+颜色)信息进行数据融合,同时实现对欧李果样本的成熟度和类黄酮含量的检测研究。以特征光谱、图像特征、光谱信息融合图像特征作为定性判别模型(PLS-DA、LS-SVM)和定量预测模型(MLR、LS-SVM)的输入变量,分别建立成熟度判别模型和类黄酮含量预测模型,并采用粒子群算法(PSO)优化最优判别和预测模型。结果表明,采用特征光谱融合图像特征建立的LS-SVM模型其成熟度判别效果和类黄酮含量预测结果均为最好,其中,PSO-LS-SVM模型对预测集成熟度的判别准确率为96.25%,类黄酮含量预测模型的Rp、RMSEP 和 RPD 分别为 0.9389、1.8723、2.6541。(7)研究了高光谱成像技术对不同成熟时期欧李果的定性判别。基于945～1675nm范围内的光谱信息,对比5种预处理方法(SG、SNV、MSC、BC、De-T)建立的PLS-DA和LS-SVM模型对不同成熟时期欧李果的判别结果。经De-T方法预处理后建立的LS-SVM模型判别结果最好(校正集为87.92%、预测集为88.75%),较原始光谱建模判别准确率分别提高了 3.34%和1.25%。分析利用欧李果类黄酮含量和不同成熟时期特征波长结合PLS-DA和LS-SVM模型对不同成熟时期欧李果判别。研究表明,基于不同成熟时期特征波长所建模型判别结果优于欧李果类黄酮含量特征波长的判别结果,且非线性LS-SVM模型更适用于对不同成熟时期欧李果的判别。建立的SPA-LS-SVM模型判别结果最优,所选特征波长个数(19个)占全光谱的8.26%,其校正集和预测集的判别准确率分别为85.00%和87.50%。(8)为实现不同贮藏周期欧李果类黄酮含量无损检测及其可视化,利用高光谱成像技术采集了贮藏期欧李果在895～1700nm的高光谱图像。提取每个样本感兴趣区域的平均光谱信息,并利用蒙特卡罗交叉验证(Monte carlo cross validation,MCCV)算法剔除异常样本(8、61、80和207号)。基于波长范围945～1675nm(230个波长)结合不同的预处理方法,建立欧李果类黄酮含量的PLSR模型,得出BC-PLSR模型的预测结果最优。采用5种有效波长选择算法(x-LW、CARS、UVE、UVE-SPA、UVE-CARS)提取特征波长,分别建立基于全波长和特征波长的线性MLR和非线性LS-SVM预测模型。分析得出,基于UVE-CARS组合算法提取的特征波长(9个波长)建立的LS-SVM模型对类黄酮含量具有最好的预测能力和鲁棒性(Rp=0.9357,RMSEP=2.0107,RPD=2.2809)。最后,利用BC-UVE-CARS-LS-SVM模型预测样本中每个像素点的类黄酮含量,并结合样本的空间信息建立了类黄酮含量的可视化分布图。研究结果表明,高光谱成像技术与化学计量学算法相结合可用于预测贮藏期欧李果类黄酮含量的变化,为贮藏期间欧李果品质的在线实时监测以及开发多光谱成像系统提供了理论依据。
{URL}: https://link.cnki.net/doi/10.27285/d.cnki.gsxnu.2022.000592
{DOI}: 10.27285/d.cnki.gsxnu.2022.000592
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉感知的行为识别关键技术研究
{Author}: 郑振兴
{Tertiary Author}: 安高云
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 行为识别;计算机视觉;多模态学习;视频理解;时空特征学习
{Abstract}: 随着移动设备和通信网络的发展,每天海量的视频数据被采集、传播和保存。视频已成为信息的主要载体,理解和分析视频中的人体行为具有重要的现实意义。行为识别作为视频理解的重要分支,旨在通过分析视频数据,利用特定算法,对视频包含的人体行为进行分析和识别。基于计算机视觉技术的人体行为识别算法是近年来的研究热点之一。计算机视觉技术通过模拟人类的视觉信息处理过程,赋予计算机感知环境的能力和人类视觉功能,为人体行为识别研究提供了理论基础和算法支撑,相关研究具有重要的理论意义和广泛的应用价值。由于人体的非刚体特性和行为模式的高维复杂性,行为识别仍然面临众多难点与挑战。本文基于拓扑知觉理论、注意力机制、特征整合理论、双通路理论等视觉感知理论,结合卷积神经网络、特征金字塔、特征融合、特征选择、多模态学习等计算机视觉技术,提出了多种有效的行为识别模型。主要创新性成果如下:(1)基于拓扑知觉理论,提出了一种多尺度特征学习框架,从空间、时序和频谱角度分别提取行为的多尺度特征。空间金字塔以低计算成本构建自底向上的结构,并使用横向连接融合卷积神经网络中不同层次的图像特征,输出语义丰富的行为表观特征。时序金字塔使用多个时序关系推理层重复计算行为表观特征,建模不同时间尺度的行为时序关系,通过聚合多种时序关系得到不同时间尺度的行为时序特征。除多尺度的行为时空特征外,谱特征金字塔同时利用卷积神经网络和谱变换算法的优点,利用谱变换算法处理不同时间跨度的卷积神经网络特征,以金字塔的形式从微观和宏观角度建模行为的长期时序关系,解决行为时序错位问题。实验结果证实三种特征金字塔均能有效地从多种尺度描述行为特征,提升模型的准确率。(2)基于注意力机制,提出了一种全局与局部内容感知的行为识别网络,利用统计注意力机制和学习注意力机制感知视频中与行为相关的重要区域。该网络采用三支路结构,包括两条注意力支路和一条全局池化支路,分别处理局部行为细节信息和全局行为信息。每帧视频图像由骨干网络提取特征后,统计注意力机制和学习注意力机制分别通过特征图的统计信息和可学习注意力模块两种方式计算图像中的重要元素,捕捉行为细节信息。同时全局支路以相同权重处理不同输入区域的特征,获取行为全局信息。最后,两条注意力支路通过正则化损失函数,在全局信息的引导下,使用循环神经网络建模包含行为全局与局部信息复合特征的时序关系。模型通过深度交互行为的全局与局部信息,可提取鲁棒的行为时空特征,并在多个行为识别数据集上取得了领先的性能。(3)基于特征整合理论,提出了一种协作式多层次特征选择行为识别网络,利用卷积神经网络特征的空间、通道、层次化三个固有特性,从位置和通道两个维度自适应地选择不同层次特征。该网络主要包含特征匹配模块、位置特征选择模块、通道特征选择模块和时序金字塔模块。位置特征选择模块使用位置注意力机制逐位置选择不同层次特征中同一空间位置的特征向量。通道特征选择模块使用通道注意力机制逐通道选择不同层次特征中同一通道位置的特征图。特征选择网络融合位置特征选择模块和通道特征选择模块的输出,能根据行为内容,选择具有不同感受野的位置特征和不同模式的通道特征,以提升行为特征的表征能力,并有效提高不同场景下的行为识别准确率。(4)基于双通路理论,提出了一种多模态语义引导的行为识别网络,利用文本包含的语义内容作为额外监督信息,引导行为特征的学习过程。其中文本通路自动学习文本内容并作为输入,计算行为的语义特征,视觉通路将视频数据作为输入,学习行为的视觉特征。为加强不同模态之间的特征交互,本文使用多模态信息交互模块处理文本内容的语义特征和视频图像的视觉特征,得到包含语义信息和视觉信息的行为复合特征。本文将单模态视频分类问题转换成多模态视频和文本匹配问题,通过缩小多模态特征匹配矩阵和标签矩阵的差异来增加成对多模态特征间的相似度。同时,本文使用监督对比学习进一步缩小同类但不同模态样本的特征距离,以获得更具判别力的行为特征。实验结果表明所提出的多模态语义引导的行为识别网络能有效利用文本语义信息来显著提升多种单模态行为识别网络的性能。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000121
{DOI}: 10.26944/d.cnki.gbfju.2022.000121
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 结合心理学和深度学习模型的图像情感分析方法研究
{Author}: 杨景媛
{Tertiary Author}: 丁金闪;高新波
{Publisher}: 西安电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 心理学模型;深度学习模型;图像情感分类;图像情感分布学习
{Abstract}: 随着社交网络的逐步兴起,随着多媒体技术的高速发展,图像已经成为日常生活中人们表达自我和理解他人的重要媒介。目前,大多数计算机视觉任务都集中在教会机器像人类一样“看”,很少关注机器如何才能像人类一样“感受”,而认识人类情感是通向强人工智能的必经之路。由此,图像情感分析应运而生,主要目的是理解人类对不同视觉信息产生的情感体验。作为计算机视觉领域的重要课题,图像情感分析的进展将会推动相关领域的研究(如图像美学质量评价、风格化图像描述生成等),也会为相关应用带来积极影响(如舆情监测、意见挖掘、心理疾病诊疗等)。近年来,得益于深度学习模型强大的表征能力,图像情感分析方法的性能得到了显著提升。然而,现有方法大多集中在设计一个通用的网络来预测情感,很少关注图像情感特有的心理学先验信息。情感是人类的高级认知过程,图像情感分析也因而极具挑战,更需要不同学科知识的交叉融合。鉴于此,本文结合心理学模型和深度学习模型,设计网络模拟人类情感认知过程,针对抽象性、歧义性和主观性三大挑战,对图像情感分析问题进行深入研究,并提出相应解决算法。
概括起来,本文取得的研究成果主要包括以下四个方面:
1.提出了一种基于多激励感知的图像情感分类方法。现有基于深度学习的图像情感分类方法虽然取得了优越的性能,但是其中大多数做法都是对整幅情感图像直接提取通用特征,并没有考虑到人类认知中情感唤起这一特有过程。针对这一问题,受到“激励-机体-反馈”心理学模型启发,本文提出了多激励感知网络模拟情感唤起过程,用于解决图像情感分析抽象性这一挑战。基于心理学相关研究,本文选取颜色、物体和人脸作为情感激励,并设计三个特定网络有针对性地从不同的激励中提取情感特征。除此以外,本文设计了一种层级交叉熵损失,用于区分简单负样本和困难负样本。该方法在图像情感分类常用数据集上的表现始终优于现有方法,可视化结果也证明了多种激励在情感唤起过程中的重要性。
2.提出了一个场景-物体关联推理网络用于图像情感分类。近来,图像情感分类方法逐步由全局转向局部,希望从细节中捕获更多情感线索。然而,不论全局还是局部,将特征不加关联地直接映射到情感类标上,都是低估了情感的抽象性。针对这一问题,受到心理学研究的启发,本文提出了一个场景-物体关联推理网络,试图从物体-物体、物体-场景的关联中推断情感,用于解决图像情感分析抽象性这一挑战。具体而言,本文首先基于语义概念和视觉特征搭建起情感图,并利用图卷积神经网络对该图进行关联推理,得到了情感增强的物体特征。为了进一步关联物体与场景,本文设计了一种基于场景的注意力机制,利用场景特征引导物体特征进行融合。在图像情感分类常用数据集上,该方法始终保持优异的性能,对情感物体概念和情感物体区域的可视化进一步证实了物体、场景和情感之间的强相关性。此外,本文方法被推广应用到了相关领域的潜在数据集中,并取得了不错的效果。
3.提出了一种环状结构的表征方法用于图像情感分布学习。大部分图像情感分析的研究都集中在单类标情感分类任务上,然而在现实中,用类标分布来描述一幅图像的情感更加合理。由此,不少研究者转而研究图像情感分布。与一般的类标分布任务不同,情感类标之间存在内在联系。针对这一问题,基于Mikels心理学模型,本文提出了一种环状结构的表征方法来描述任意一种情感分布,旨在消除情感类别间的歧义性。首先,本文构建了一个情感圆环,可以将任意情感状态映射为其上的一个情感向量,并在该向量上定义了三种属性(极性、类别、强度)和两种特性(可加性、相似性)。此外,本文设计了渐进环状损失,用于由粗到细地约束情感向量。该方法在多项指标上的表现始终优于现有最优图像情感分布学习方法,对渐进环状损失的消融实验也证实了其中各部分设计的有效性。
4.提出了一种基于主观性驱动的图像情感分布学习方法。现有方法大多从整体的角度来预测图像情感分布。然而,情感是主观的,不同个体面对同一张图像时可能会产生不同的情感,而情感分布正是由不同个体投票产生的有差异性的情感描述。针对这一问题,基于“对象-评估-情感”心理学模型,本文提出了主观性评估-匹配网络模拟人群情感投票过程,用于解决图像情感分析中主观性这一挑战。该网络主要包含两个阶段:主观性评估和主观性匹配。在主观性评估网络中,为了保留每个个体独特的情感体验,本文结合注意力机制建立情感记忆模块,并设计主观性损失确保不同个体间情感体验的差异性。主观性匹配网络主要由匹配损失构成,旨在将有序的个体预测值与无序的情感标注值实现一一匹配,该问题被建模为一个二分图匹配问题并通过匈牙利算法找到了最优解。在图像情感分布常用数据集的多项指标上,本文方法始终保持优异性能,对不同个体情感记忆的可视化实验进一步证实了主观性对于图像情感研究的重要意义。
综上,本文结合心理学和深度学习模型,对图像情感分析问题进行探究,提出了四种模型。第一个模型从多种激励的融合中预测情感。第二个模型在此基础上进一步实现了场景-物体的关联推理,是从孤立到关联的过程。前两个模型研究的问题是图像情感分类,主要解决的挑战是抽象性。第三个模型通过建立环状结构来更好地进行情感表征,目的是消除歧义性。第四个模型从主观性角度模拟了人群情感投票过程,主要解决了主观性挑战。后两个模型研究的问题是图像情感分布学习。总结来说,本文的四个模型是从孤立到关联,从分类到分布,从共性到个性。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.000036
{DOI}: 10.27389/d.cnki.gxadu.2022.000036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视觉特征学习关键技术研究
{Author}: 范丽丽
{Tertiary Author}: 赵宏伟
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉特征学习;度量学习;判别性;高效性;泛化性;样本不平衡
{Abstract}: 随着计算机技术的飞速发展,以及嵌入式摄像头等各类数码设备的流行,网络和生活生产中无处不在的视觉数据呈现出井喷式增长,使得图像数据的精准检索、分类和检测等计算机视觉研究越来越活跃。与此同时,也让基于此运用的各种新兴视觉产业看到了曙光。深度学习凭借其在计算机视觉领域所展现的优秀数据建模能力,得到了研究者的广泛关注。深度学习在数据建模中的优势体现在视觉特征学习上,通过快速地获取高判别性特征学习能够满足不同的应用需求。因此,如何快速而准确地获取计算机视觉任务中的判别性特征是深度学习研究的重点、难点和热点。在计算机视觉任务中,对于基于深度学习的视觉特征学习,其关键问题在于如何保证特征表达的判别性、大规模图像视觉任务中模型算法的高效性和在噪声等场景下模型算法的泛化性,这些问题相互交叠,为优秀的视觉特征学习带来挑战。而优秀特征的快速提取又受到了样本挖掘、网络模型和损失函数的多重影响。基于上述问题,本文将利用深度学习模型,从样本挖掘、网络函数和损失函数优化这三个切入点出发,解决视觉特征学习存在的关键问题。现将该博士论文的主要创新点总结如下:1.针对目前流行的损失函数之一的深度度量学习框架,本文提出了基于结构分布熵排序的深度度量学习方法。该算法聚焦于损失函数优化过程中,由于忽略特征空间分布信息,而造成的特征表达判别性弱的问题。对于正样本,该算法为样本学习一个超平面,而不是让其空间距离无限接近,以保留其内部的相似性结构;对于负样本,通过提出分布熵排序学习的概念,引入了基于视觉特征空间的分布熵权重来保持负样本类间特征结构分布的一致性。该算法提高了深度视觉特征表达的判别性,与此同时,算法的有效性在地标类图像检索的计算机视觉任务中得到了有效验证。2.针对目前流行的样本挖掘和模型优化的深度度量学习框架,本文提出了基于优化一致性保持的深度度量学习算法,主要解决样本挖掘中,基于启发式观察的超参数调整造成的时间消耗问题,以及模型优化过程中因网络优化的方向与损失函数降低方向不一致而造成的算法效率低的问题。该算法包含了能够自动设置边界阈值的基于最近邻决策边界的前k个“错位”样本挖掘算法(Top-k Misplaced Samples,Top-k MS)。除此之外,还有基于特征空间和检索结果的全局优化算法(Feature Space and Retrieval Results,FSRR),保证了视觉特征学习的高效性,并在大规模遥感图像检索的计算机视觉任务中得的了有效验证。3.针对深度网络模型的改进,本文提出了两种算法,分别是基于残差关注分频卷积的集成模型算法和基于域自适应和增强特征的集成模型算法。其中基于残差关注分频卷积的集成模型算法聚焦于前景和背景不平衡的图像中,大量的低频信息造成的存储量增加和计算冗余问题,以及图像类别数目不平衡下的关注偏差问题。通过对不同频率空间信息重新整合,并关注高频信息,以降低网络的存储和计算量。与此同时,通过设计平衡损失函数来减少类别和类别数目不平衡的影响,实现了深度视觉特征学习的判别性和高效性;基于域自适应和增强特征的集成模型算法旨在噪声背景以及因季节和天气导致亮度变化的场景中,提高深度特征学习模型的泛化性。该算法通过构建具有噪声的数据集和设计基于亮度值差异的图像增强方法,减少噪声和亮度变化对特征学习的影响,提高算法的泛化性;通过将特征增强模块引入特征金字塔和分层增强网络中,提高小目标深度特征的判别性。两种算法的有效性在路面裂缝检测的计算机视觉任务中得到有效验证。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.002224
{DOI}: 10.27162/d.cnki.gjlin.2022.002224
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于特征融合的RGB-D视觉显著性物体检测算法研究
{Author}: 吴佳佳
{Tertiary Author}: 韩广良
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: RGB-D显著性物体检测;跨模态多图学习模型;吸收马尔可夫链;多模态多尺度注意;网络轻量化
{Abstract}: 视觉显著性物体检测是当今计算机视觉领域的一个重要研究方向,其核心任务是通过模拟人类的视觉注意机制,从复杂的视觉场景中快速定位到最具有价值的区域,有选择地过滤掉其它非重要信息。该技术的这种特性使得它在现实生活中有着非常广泛的应用价值,如,自动驾驶、人机交互、智能监控、目标跟踪、环境感知等。近年来,随着深度传感器设备的快速发展和普及,人们可以很容易地获取场景中的RGB信息和相应的深度数据。以此为契机,更加符合人类视觉感知系统的RGB-D视觉显著性物体检测逐渐成为研究的焦点。然而,受制于深度成像技术和环境光照变化等影响,获取的深度图质量往往参差不齐。这使得如何减小低质量深度图的干扰,有效利用具有丰富空间结构的深度信息,成为该领域的一大研究难点。此外,受益于深度学习在计算机视觉领域上的突破性成果,采用深度学习进行RGB-D显著性检测逐渐成为该领域的主流方向。尽管深度学习在该领域取得了巨大的进展,但是也面临着另一大挑战,即大多数现有的显著性检测方法往往以较高的计算成本和参数量为代价获取高精度的检测性能,严重制约了算法的实际应用。因此,提高多模态特征的融合质量以及构造轻量级的显著性检测模型具有重要的研究意义。本文以探索更加符合人类双目视觉感知机理的RGB-D显著性检测模型为主要目标,针对显著性模型构建过程中的多模态特征有效提取和融合优化,以及模型轻量化等问题,进行了一系列相关研究。本文主要的工作内容及创新性研究成果具体总结如下:(1)针对传统基于手工设计特征算法的多模态特征融合不充分问题,以及边界接触问题,提出了一种基于深度信息引导的双边吸收马尔可夫链的多阶段显著性检测模型。该模型从低、中、高三个层次逐步整合优化颜色和深度信息,提取显著性线索,充分利用了深度信息的显式和隐式属性。具体地,模型首先显式地结合颜色和深度信息以构建初始的二阶稀疏图,并基于背景先验和区域对比度先验生成低水平的显著性线索。然后,构建了一个双边吸收马尔可夫链模型计算中层的显著图,在该层,为了有效解决边界接触和多模态融合问题,分别设计了背景种子筛选机制和跨模态多图学习模型,利用低级的显著性线索从图的连接方式和亲和矩阵对初始图模型进行改进。同时在该图模型中引入了非局部连接,增强显著性区域的一致性。最后通过构建基于深度引导的优化模块对中层的显著性结果进一步优化,得到最后的显著性预测图。一系列定量和定性的评价结果,证明了所提出模型的有效性和鲁棒性。(2)针对复杂场景下显著性物体难以描述的问题,提出了一种基于渐进引导融合网络的RGB-D显著性检测模型。该模型主要包括四类子模块,通过自上而下的方式不断地对它们进行交替级联,以不断增强和优化多模态特征的融合,逐步挖掘和整合有价值的信息。具体地,模型首先利用卷积神经网络分别提取多个层次的颜色和深度模态特征。然后,通过在每一层构建一个多模态多尺度注意融合模块,来充分挖掘在不同模态下和在不同尺度下的特征的互补性,实现最优的特征融合。其次,为增强浅层特征的语义表达能力,构建了多模态特征细化机制,利用高层融合特征引导浅层原始的RGB特征和深度特征的增强。最后,设计了残差预测模块进一步抑制背景元素,预测最终的显著性结果。相关数据集上的定性和定量对比分析结果,充分验证了所提模型的有效性和鲁棒性。另外,该模型在取得先进性能表现的同时,还能够较好地应对基于RGB图像和热红外数据的RGB-T显著性检测任务,表现出了优越的可迁移性。(3)针对网络模型复杂化、参数量大、占用计算资源多等实际应用问题,构建了一个轻量级的跨模态感知网络用于RGB-D显著性检测。为提升轻量级骨干网络的特征表示学习能力,设计了互注意增强模块并嵌入到深度特征编码流中,利用深层的语义特征以及模态间的相关性强化RGB和深度特征的表示能力。同时,提出了选择性相互调制融合模块和高层引导的特征细化机制来保证算法的运行效率和精确度。大量定性和定量的数据对比结果,证明了所提出模块的有效性以及整体算法的优越性、实时性和鲁棒性。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000034
{DOI}: 10.27522/d.cnki.gkcgs.2022.000034
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 圆柱型锂电池外观缺陷检测方法研究
{Author}: 郭绍陶
{Tertiary Author}: 苑玮琦
{Publisher}: 沈阳工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 圆柱型锂电池;凹坑;灰度分布曲线;凹凸曲线段;机器视觉
{Abstract}: 锂电池的用途十分广泛,已经在电子时代得到普遍应用,新能源汽车产业的出现,更是大大推动了锂电池的发展。作为新能源汽车核心的组成部分,圆柱型锂电池的质量至关重要。近年来由于锂电池的热失控,导致电动汽车起火爆炸等事件偶有发生,使得圆柱型锂电池的安全性问题受到广泛关注。圆柱型锂电池制作工艺比较复杂,各个环节操作不当都会使其表面产生划痕、凹坑或膜破损等缺陷。其中凹坑是比较严重的表面缺陷,会直接影响电池组焊接效果,存在一定安全隐患。因此对圆柱型锂电池表面进行凹坑缺陷检测具有重要意义。目前圆柱型锂电池的表面缺陷检测主要依靠人工目检法,这种方法检测效率低、检出率低,很难满足自动化生产的需求。基于机器视觉的圆柱型锂电池表面缺陷检测方法的研究很少,对于背景亮度不均匀、反光不均匀、明暗对比度小的轻度凹坑的研究仍处于空缺状态。本文主要针对圆柱型锂电池圆周面和端面上具有不同深度的凹坑缺陷检测问题进行深入研究,提出了基于机器视觉的解决方案。在强干扰信号下的轻度凹坑是本文的重点研究对象。本文的主要工作如下:(1)圆周面图像沿着轴向和周向亮度不均匀,明暗对比度低的轻度凹坑极易受浅脏污等干扰的影响,使得轻度凹坑自动检测十分困难。本文在对凹坑图像特征进行深入分析之后发现,凹坑在图像的轴向方向上存在一定的灰度突变,而且与干扰在灰度分布曲线中的形态不同,所以提出了基于灰度差分模型和曲率变化量的凹坑检测算法。首先采用自定义的对光照分布和干扰不敏感的灰度差分模型计算轴向灰度分布曲线上的突变,同时结合本文设计的凹凸曲线段合并算法,可以确定凹坑候选区域,排除了圆周面本身反射不均和浅脏污带来的波动;最后利用定义的曲率变化量来量化灰度分布曲线的波形特征,进一步排除干扰。对现场采集的图像进行了测试,结果表明亮度不均匀没有对凹坑提取产生影响,也没有因干扰而产生误检。该方法不仅可以有效解决亮度不均匀对凹坑检测的影响,还可以解决圆周面轻度凹坑难以检测的问题。(2)因为光照不均匀和金属表面反射不均匀,端面的金属表面图像背景不均匀,并且存在大量亮点暗斑等强噪声,轻度凹坑与背景的对比度较弱,微弱的信息容易被噪声掩盖,所以使用灰度阈值分割方法很难同时提取出凹陷程度不同的凹坑信息。针对上述问题,本文提出两种端面凹坑检测算法。方法一:本文提出了基于双高斯纹理滤波模板和极值点韦伯对比度的凹坑检测算法。首先为了在降噪的同时保留凹坑的灰度突变特征,本文根据凹坑在灰度分布曲线中的形态,定义了双高斯纹理滤波模板,将其与图像进行卷积;最后根据凹坑局部变化显著的特征,采用定义的极值点韦伯对比度来增强凹坑信息与干扰信息的差异性,通过提取灰度分布曲线上局部变化显著的像素点,实现了从复杂的图像中分割出凹坑区域的目的。对现场采集的图像进行了测试,结果表明该算法可以提高轻度凹坑的检出率,降低误检率。但是该算法存在如下问题:该算法没有检出高度较小且局部对比度很低的凹坑缺陷;由于位于金属表面边缘的凹坑区域只有亮区域,不存在灰度突变特征,所以出现了漏检;距离较近的多条亮色划痕与背景形成了较大的对比度,导致被误检为凹坑。方法二:针对方法一存在的问题,本文通过融合锂电池多张图像信息的方法,进一步提出了基于平均偏差特征和凹凸曲线段特征的凹坑检测算法。首先根据凹坑成像原理,通过对同一个锂电池的6张图像进行空域平均和剔除异常值方法来建立基准面图像,同时结合基于凹凸曲线段的空间滤波方法,用来剔除信息强度较强的干扰噪声,该滤波算法不受窗口尺寸限制;其次根据误差分析理论,计算出灰度分布曲线的平均偏差,以体现轻度凹坑和位于金属表面边缘的凹坑信息;因为低频分量可以反映图像整体特征,所以使用本文设计的凹凸曲线段合并算法可以在不改变灰度值的前提下,体现出凹坑的内部差异性;然后提取出凹凸曲线段峰谷差、峰峰差和宽度比;最后采用BP神经网络方法建立检测模型来实现凹坑检测。通过对现场采集的图像进行测试,结果表明该算法解决了方法一存在的问题。本文为覆膜表面缺陷和金属表面缺陷检测技术提供了新的思路和方法。本文提出的凹凸曲线段合并算法适用于强干扰信号下微弱信号的在线检测问题,可以应用于其它表面上有明暗差异性的缺陷检测问题,具有较好的应用价值和工程应用前景。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.001264
{DOI}: 10.27322/d.cnki.gsgyu.2022.001264
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv7的跌倒检测算法研究
{Author}: 黄万里
{Tertiary Author}: 任先平
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;跌倒检测;深度学习;YOLOv7
{Abstract}: 随着65岁以上的老年人在中国人口中所占的百分比不断地增大,老年人的健康问题也越来越引起人们的重视,而老年人跌倒则是导致老年人健康受损的一个主要因素。一种能够及时准确有效地检测出老年人是否发生跌倒的系统设备就显得特别有意义。由于基于计算机视觉的跌倒检测系统有着实时性快、造价低廉、多项任务并行等多项优点,利用其制成的检测跌倒系统就成为了科研人员重点研究的项目,在这一领域中,YOLO系列算法对跌倒检测的效果较好,但YOLO系列算法当中在科研方面仅仅只有YOLOv5算法以及更早一代的跌倒检测方面的探究,没有YOLOv6和YOLOv7算法在跌倒检测方面的研究,并且YOLOv6致力于工业需求,并不符合跌倒检测的要求,因此本文提出了一种基于改进YOLOv7的跌倒检测算法研究,该系统可以检测视频或者图像中的跌倒目标,还可以避免将指定区域的躺倒目标识别为跌倒目标,最终能够将系统检测到的跌倒结果反馈在系统的图形化界面上。本文主要研究内容如下:(1)分析目标检测算法,从算法各个方面进行对比,通过各种不同的渠道搜集数据,筛选合适图片,使用数据增强丰富样本,构建出自己的数据集,标注了跌倒和站立两个类别,使用YOLOv7网络模型针对自制的数据集进行训练,该模型在Io U设置为0.5的情况下,跌倒和站立目标的m AP值达到了86%,有良好的检测跌倒效果。(2)鉴于多层卷积操作使得图像在深层特征图上的关键信息减少以及图像关键特征信息提取不完善,本文通过借鉴注意力机制和膨胀卷积的思路,设计了三个模块嵌入到网络模型中,可以对跌倒目标的关键特征给予更多的重视,还能够增加感受野,提高老人跌倒检测算法的效率。改进点的具体方案是在YOLOv7的网络结构上依次嵌入三个自设的模块,分别是注意力模块(Atten)、自适应均值模块(AAM)和特征增强模块(FEEM),把改进后的模型与没改进前的YOLOv7训练模型的检测结果进行了对比,实验结果显示,当三种模块同时嵌入到YOLOv7中时,使得最终训练出的模型对于跌倒和站立目标的m AP值提升到了87.6%,大大提高了检测精度。(3)由于人物的跌倒和躺倒状态在特征上难以进行区分,本文将沙发和床的区域进行划分,当在指定区域检测到人物躺倒或者跌倒时设定为站立,能够有效地避免对人物躺倒状态的误判。(4)将改进后的模型在视频图像上进行跌倒检测,并将测试结果显示在系统界面上,能够较好的实现对人体跌倒的自动检测。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2023.000335
{DOI}: 10.27800/d.cnki.gjhdx.2023.000335
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5模型的安全帽佩戴检测
{Author}: 李然
{Tertiary Author}: 房俊龙;李明颖
{Publisher}: 东北农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 安全帽;目标检测;YOLOv5;MobileNetv3;卷积注意力机制
{Abstract}: 随着社会经济的不断发展,电力资源已经成为我国主要能源之一。在电力作业中,安全是作业人员最重要且最基本的要求。而电力施工中,往往因为工作人员安全意识薄弱,未规范佩戴安全帽导致事故的发生,所以,及时发现并督促工作人员规范佩戴安全帽,是电力作业中至关重要的一项工作。因此,实现电厂安全帽的智能化佩戴检测具有重要意义。在过去,电力作业现场通常是利用人工的方式对电厂作业人员的安全帽佩戴情况进行检查和监督,但是这种形式不但效率相对较低,而且无法确保多区域的覆盖。现如今,视频监控技术和计算机视觉技术已经逐渐应用在生活中的各个领域,同时安全帽佩戴识别技术也是近年来国家倡导的跨领域结合技术。因此本文提出一种针对安全帽的改进型目标检测模型MCJ-YOLOv5(M:Mobile Netv3;C:CBAM;J:检测层),具体内容如下:(1)目前针对安全帽的研究相对较少,没有可以使用的公共数据集。因此,本文首先采用自行采集数据集的方式对安全帽数据集进行搭建,根据研究需求,本文通过网络爬虫和视频分帧的方式对安全帽数据进行采集,共获得佩戴安全帽和未佩戴安全帽两类目标数据2171张。为扩张数据集,将采集到的数据经过旋转、翻转、增加噪音、饱和度、亮度等方式进行数据增强,最后经过筛选,得到两类目标数据集共6513张作为此次数据集的样本。(2)配置实验环境,根据对目前主流的几种目标识别算法进行学习,通过对不同算法的原理和结构进行对比分析,本文最终选取YOLOv5作为本实验的基础安全帽识别网络模型,用先前制作好的实验数据集进行训练。经过实验对比分析,YOLOv5模型的精度和检测速度与其他主流目标检测模型比更适合本次安全帽检测实验。(3)在电力作业场景下,由于目标尺度多变,因此目标检测模型要确保检测精度的前提下,实时性也必须满足实际的应用要求。本文提出了MCJ-YOLOv5目标检测模型,通过引入轻量级网络结构Mobile Netv3替换原YOLOv5的CSPDarknet53主干网络结构,以此降低模型大小,提高模型的检测速度,其次在主干网络中引入卷积注意力机制模块(CBAM),以此提高模型的特征提取能力,最后为了提高电厂环境中对小目标的检测性能,本文在原模型的基础结构上再增加一层检测层,进一步提高模型的特征提取能力,从而加强模型对小目标的检测性能和应对复杂密集场景的能力。利用自制的安全帽数据集对优化后的YOLOv5模型进行训练测试,其中模型的均值平均精确度(m AP)值达到91.5%、模型大小达到23.5MB、模型的检测速度为48帧/s、改进后的YOLOv5算法虽然比原模型在检测精度上降低了0.4%,但是模型大小和检测速度分别降低和提高了151.6MB和6帧/s,经过实验对比分析,改进后的MCJ-YOLOv5目标检测模型比改进前的YOLOv5目标检测模型更适合对电厂从业人员是否佩戴安全帽进行实时检测。
{URL}: https://link.cnki.net/doi/10.27010/d.cnki.gdbnu.2022.001021
{DOI}: 10.27010/d.cnki.gdbnu.2022.001021
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目立体视觉的实时三维重建系统研究
{Author}: 赵双赫
{Tertiary Author}: 史宝全;王福海
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目立体视觉;标志点;实时检测;三维重建;GPU
{Abstract}: 计算机视觉技术经过几十年的飞速发展,已经成为社会生产生活中不可或缺的一部分。双目立体视觉技术作为计算机视觉技术的重要组成部分,是目前最接近人眼视觉系统的视觉技术。通过在两个不同方位采集被测物体的图像,双目立体视觉技术可以根据图像中的视差求取被测物体的三维信息。双目立体视觉技术具有稳定性高,实用性强,成本低廉等优点,因此被广泛应用于工业测量、视频监控、移动机器人等领域。这些场景都需要在尽可能短的时间内得到物体准确的三维信息,要求高实时性和准确性。本文针对工业场景下的实时三维测量需求,对双目立体视觉关键技术进行了系统研究,研究内容及成果如下:
(1)研究了双目立体视觉成像模型、相机畸变模型及相机标定等关键技术,实现了一种基于十字标定靶标的十参数相机标定方法。首先,对单目相机成像模型进行了研究,分析了不同类型的畸变对相机成像的影响;其次,对双目立体视觉的成像模型进行研究,分析了空间点的三维重建原理;最后,以十字靶标作为标定物,实现了基于十参数畸变模型的双目相机标定。实验结果表明,本文标定方法的重投影误差在0.02个像素以内。
(2)提出了一种基于GPU的标志点并行识别技术,实现标志点的实时检测。首先,对标志点识别算法进行了系统研究;其次,采用CUDA编程实现了标志点识别算法中关键技术的并行计算,包括标志点图像的并行二值化、连通域的并行检测、亚像素边缘的并行检测、椭圆中心的并行拟合等;最后,对标志点实时检测算法展开实验,实验结果表明在图像分辨率为2448×2048,标志点数量为96的情况下,基于GPU的并行标志点识别算法相较于基于CPU的串行算法加速比最高可达101.7,从而实现标志点的实时检测。
(3)设计并搭建了一套基于双目立体视觉的实时三维重建系统,实现物体变形的实时检测。系统硬件部分主要包括相机、镜头、信号控制盒、计算机等。系统软件利用C++、MFC及CUDA进行开发,主要包括相机标定、图像采集、数据处理、结果显示等模块。实验结果表明,当系统分辨率为2448×2048,测量距离为2.5m时,系统三维重建的精度可达0.25mm,三维重建的速度可达70FPS,重建效率优于国内外已报道的同类双目立体视觉系统,可以满足工业场景下的实时三维测量需求。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.002084
{DOI}: 10.27389/d.cnki.gxadu.2022.002084
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于结构光的焊接机器人焊缝图像识别算法研究
{Author}: 李昱
{Tertiary Author}: 于微波;闫明毅
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 焊缝识别;结构光;深度学习;焊缝特征提取;机器视觉
{Abstract}: 焊接制造技术是工业生产过程中非常重要的一部分,是衡量工业化水平的重要指标,使用工业焊缝机器人来提高焊接生产的效率是未来的一个趋势。使用机器视觉来引导工业机器人焊接已经达到了很高的关注度。用于焊缝定位的结构光视觉传感器具有非接触和快速检测等优点。根据实际研究发现,目前基于视觉的焊缝检测系统存在实时性低、普适性不足等缺点,特别是由于焊接材料表面光滑,具有较高的反射效应,使得焊缝特征不明显,使得工业焊接机器人定位精度不足,焊接效果不稳定。首先,完成焊缝图像特征识别与提取平台的设计与搭建和主要部件的选型。依据三角测量原理选取最优测量方式,基于线结构光视觉设计,选择合适的焊缝定位传感器,并完成视觉系统对焊接平台的主要部件选型。选用安装搭建方式固定工业相机与线性激光发生器的位置关系,完成了结构光视觉平台的设计与搭建。其次,为了提取焊缝图像特征信息,通过研究分析不同的图像处理方法,简化预处理流程。提出基于PSPnet网络的焊缝图像处理算法对焊缝图像进行预处理,使用采集到的四种典型焊缝的原始图像,完成数据集制作,并训练PSPnet网络模型,完成了焊缝图像分割处理,提取出清晰的结构光条纹图像。然后,针对焊缝图像特征点提取方法进行了研究。通过分析比较不同的图像中心提取算法,确定Steger算法提取结构光条纹中心线;根据T型焊缝、V型焊缝、搭接焊缝、对接焊缝的焊缝图像特点,提出用Center Net网络进行四种典型焊缝的特征点识别与提取,对比传统的特征点识别算法的识别精度与提取速度,本文所用的Center Net算法,在求得焊缝特征点的同时,还拥有不俗的图像处理效率。最后,根据本文研究的内容完成实验系统的设计与调试,并通过多组焊缝识别的提取结果与验证集中的标准点进行对比。最终实验结果表明,像素坐标X轴的平均误差为0.877pixel,Y轴的平均误差为0.705pixel.
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000452
{DOI}: 10.27805/d.cnki.gccgy.2022.000452
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: Delta并联机器人目标识别与抓取技术研究
{Author}: 赵鹏宇
{Tertiary Author}: 王宗彦
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: Delta并联机器人;动态抓取;机器视觉;工件识别;工件定位
{Abstract}: 随着机器人技术水平的不断提高,机器人替代人工进行生产操作已经成为可能。Delta并联机器人具有高速、重复定位精度高、成本低的特点,是目前机器人领域发展的主要方向之一。我国高精度并联机器人的技术水平相对落后,大部分并联机器人分拣系统无法对物品进行分类识别,一旦物品种类、位置、位姿发生变化就无法完成指定工作。为了使机器人可以实时掌握物品的种类、位置等信息,本文引入了机器视觉技术,利用Delta机器人进行动态工件抓取,围绕Delta机器人动态抓取与机器视觉识别定位完成的主要工作如下:(1)对Delta机器人的抓取系统与机器视觉系统进行了综合分析。首先介绍了Delta并联机器人的结构,经对比确定了机器人的末端执行器。然后选择了机器视觉系统的硬件,介绍了本文的开发环境。最后为了提升机器视觉系统的精度研究了相机标定技术。(2)针对工件识别定位问题,提出了基于Hu矩和最小外接矩形的图像快速识别定位算法。首先对图像处理的流程进行研究,选取了合适的图像预处理方法。分析对比了基于SIFT和基于Hu矩的工件识别方法,由于后者快速准确所以选择后者作为本文的工件识别算法。之后对工件定位进行研究,提出了一种基于最小外接矩形的工件定位方法。(3)针对Delta机器人进行动态抓取时存在的问题,研究了Delta机器人、传送带与视觉系统三者的关系,并对三者进行标定,使抓取系统可以精准运行。针对连续帧图像工件重复进入的问题进行了研究,分析了一种基于时间与位置的图像去重复算法,最后针对Delta机器人的动态抓取模型进行了研究,通过分析运动路径选取了合适的模型。(4)搭建了实验平台。说明了平台主要硬件型号和Delta机器人的工作性能。之后对软件层进行了分析,设计了视觉识别系统的软件界面。随后进行了系统标定实验通过多次标定最大程度上减小了动态抓取的位置误差。最后进行了动态抓取实验,实验结果表明本文的抓取误差在1mm左右,抓取过程稳定性好可连续运行,满足实际生产需要。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.000743
{DOI}: 10.27470/d.cnki.ghbgc.2022.000743
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的行人跌倒检测研究
{Author}: 朱亚琴
{Tertiary Author}: 曹建荣
{Publisher}: 山东建筑大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 跌倒检测;多行人场景;CenterNet算法;特征匹配;YOLOv4-tiny
{Abstract}: 目前我国已经进入了人口老龄化社会,跌倒是威胁老年人身心健康的常见因素之一。随着科学技术的发展,研究人员尝试利用更先进的深度卷积技术检测行人的跌倒行为,尽可能减少跌倒对老年人的伤害。由于监控设备在日常生活中的广泛应用,基于计算机视觉的跌倒检测算法更具有研究意义和价值。然而传统的基于计算机视觉的跌倒检测方法大多适用于单个行人简单场景,难以适用于多行人且环境复杂的实际场景中。针对以上问题,本文分别提出了基于关节点特征的跌倒检测算法和一种基于行人姿态估计与跟踪相结合获取每个行人目标的连续视频帧并输入至YOLOv4-tiny跌倒检测模型进行跌倒检测的算法,并将YOLOv4-tiny跌倒检测模型部署于Jetson Nano硬件终端实现真实场景下的跌倒检测。本文的主要工作如下:(1)针对网络计算量大导致行人姿态估计速度慢的问题,本文提出了基于改进的Center Net行人姿态估计算法。采用深度可分离卷积替换Hourglass-104网络中残差模块的普通卷积,减少整个网络模型计算量。实验表明,改进后的Center Net算法能够提高行人姿态估计的速度,也进一步减少了行人跌倒检测过程所需的时间。(2)针对多行人场景中行人间遮挡导致行人跟踪不准确的问题,提出了基于特征匹配的行人跟踪算法。根据行人质心的变化预测行人位置,通过判断行人是否有重叠遮挡,进一步确定是否需分割出非遮挡区域作为特征区域并提取行人颜色特征,根据行人所处的不同状态(遮挡或非遮挡),选择不同的特征匹配方式进行跟踪。在不同场景下进行了实验,结果表明,基于特征匹配的行人跟踪算法可以处理行人遮挡导致的跟踪错误问题,减少多行人场景中行人遮挡对跌倒检测准确率的影响。(3)针对现阶段缺少多行人跌倒数据集的问题,本文通过多种方式采集多行人跌倒图像数据,建立了一个具有4300张图像的多行人跌倒数据集用来训练和测试跌倒模型。(4)本文分别提出了基于关节点特征的跌倒检测算法和基于YOLOv4-tiny的行人跌倒检测算法。在自建多行人跌倒数据集上对YOLOv4-tiny模型进行训练,调整参数得到适合本文多行人复杂场景及单个行人简单场景的跌倒检测模型,并部署于Jetson Nano硬件终端实现实际场景下的跌倒检测。实验表明基于YOLOv4-tiny的跌倒检测算法在公开的单个行人简单场景数据集和自建多行人复杂场景数据集中准确率分别为95.51%和91.67%,比基于关节点特征的跌倒检测算法更能适用于实际场景中,具有一定的优越性。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2022.000571
{DOI}: 10.27273/d.cnki.gsajc.2022.000571
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv3目标检测算法的改进研究
{Author}: 白佳乐
{Tertiary Author}: 樊永生
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;交并比;多尺度模块;数据增强;注意力机制
{Abstract}: 目标检测作为计算机视觉的核心研究任务之一,被广泛应用于各个领域,如:交通检测、医疗诊断、安全保障等,一直是研究学者广泛关注的研究课题。随着人工智能技术的不断发展,基于深度学习的目标检测算法成为当前目标检测的主流算法,其中YOLOv3算法作为深度学习目标检测算法中最受关注的算法之一,具有检测效率高、泛化能力强、鲁棒性好等优点。但是,随着检测任务的复杂度越来越高,YOLOv3算法的检测精度已经不能满足应用的需求。鉴于此,本文对YOLOv3算法进行研究,在主干特征提取网络、候选框筛选阶段等方面加以改进,实现复杂目标任务的快速准确检测。本文主要研究内容如下:(1)分析YOLOv3算法的检测过程,通过在YOLOv3算法主干网络Darknet-53中引入Res2Net模块,在单个残差块内对特征信息重新分层与组合,构建了新的残差结构,使得网络在进行特征提取时能更加充分的利用上下文信息,提取到更细粒度的特征。在预测框回归部分,使用降低预测框置信度的方式取代原算法中的筛选方式,降低多目标漏检情况的概率;同时在筛选预测框的损失函数中加入对两个框之间的距离、重叠率、长宽比的惩罚项,提高预测框定位精度。在Pascal VOC数据集进行实验,结果表明:改进后,算法的m AP值从78.3%提升到81.7%,验证了改进方案的合理性。(2)分析SE模块和CBAM模块两个注意力机制模块,将其与改进后的残差结构整合,构建新的注意力残差模块,提高网络对重要信息的关注度,进而提升模型的检测效果,并分析现有的数据增强策略,对本文实验所用数据集进行处理,提高了改进后模型的泛化能力。采用Pascal VOC数据集进行实验分析:引入注意力机制和数据增强后,算法的检测效果进一步提升,m AP由原来的81.7%提高到83.6%,验证了改进方案的合理性。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.001125
{DOI}: 10.27470/d.cnki.ghbgc.2022.001125
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的室内目标检测与测距系统研究
{Author}: 郭海洲
{Tertiary Author}: 李自立
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目视觉;立体匹配;目标检测;测距
{Abstract}: 获取工作场景周围物体的详细信息是室内服务机器人进行运动规划和完成具体工作的基础,是实现室内服务机器人智能化的关键。对工作环境中物体的类别、位置和距离信息的获取可以让室内服务机器人针对得到的目标信息做出合适的反应。为了使室内服务机器人实现同时获取特定目标的类别、位置和距离信息的功能,本文对双目立体视觉技术与目标检测技术进行深入研究,结合室内服务机器人的工作场景和实际的应用需求,设计并实现了可在嵌入式系统上运行的基于双目视觉的室内目标检测与测距系统。本文的主要工作如下:1.基于摄像头的成像和双目立体视觉测距的原理,结合双目立体视觉测距的需求,选择合适的摄像头标定方法对双目摄像头进行标定,并使用标定得到的双目摄像头参数对双目图像进行立体校正以满足立体匹配算法的使用要求。2.对双目立体匹配算法的应用场景适用性进行研究,分析不同立体匹配算法的优缺点。为了提升立体匹配算法的抗噪声能力,保证在具体应用场景下算法的适用性和测距的准确性,对基于Census变换的立体匹配测距算法进行了有针对性的改进。主要改进在于:优化Census变换计算方法,采用设置阈值的方式选择Census变换的参考值,提升算法的抗噪声能力;在初始匹配代价中融入图像梯度信息,提升立体匹配效果;减少代价聚合路径提升运行效率;优化测距视差的选取,提升测距的可靠性。3.对目标检测算法进行研究,针对室内服务机器人实时检测和测距需求,综合考虑整个目标检测与测距系统的实现难易度和运行效率,本文采取了合适的轻量目标检测算法。从开源的MS COCO数据集中筛选常见室内目标种类制作新的数据集,训练目标检测模型并对模型进行评估。4.整合系统实现获取目标位置和类别的同时获取距离信息,完成嵌入式部署并进行实验分析。通过Open CV调用模型实现目标检测功能,减少在嵌入式设备部署时的环境依赖。模拟室内服务机器人的工作场景,对系统的目标检测效果与测距准确性进行实验验证,并测试系统在嵌入式设备上的运行效率。实验表明,本文设计的系统实现了预定的设计目标,使用制作的数据集训练得到模型m AP为53.8%,在5米内的测距误差小于6%,在嵌入式设备的平均运行速度可达27FPS,满足室内服务机器人在室内场景应用的需求。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.001014
{DOI}: 10.27036/d.cnki.ggxsu.2022.001014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 小麦麦穗的目标检测与杂草分类识别研究
{Author}: 薛媛
{Tertiary Author}: 林和;韩立刚
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;图像识别;目标检测;杂草;小麦麦穗;深度学习;卷积神经网络;数据增强
{Abstract}: 目的——在农业的发展历程中,提高农作物的品质、产量和经济效益是工作的重点,对杂草控制和去除是一项必须的工作。除草之后有利于农作物获取到充足的养分、水分和生长空间,使得农作物的生长提供了保证,维持了农作物的高产。如何在大规模的图像数据集中对农作物小麦麦穗进行准确的目标检测,对后续小麦产量和小麦育种提供了方便,这对于农业的发展有着重要的意义。因此,本文将采用图像识别技术对不同种类农作物和杂草的分类研究及农作物小麦麦穗进行目标检测研究,并且开发了一个小型的植物分类和检测系统,以便后续的学习与研究工作的进行。方法——在不同种农作物和杂草分类阶段,提出了使用图像识别分类技术来提取不同植株的特征,并对不同种农作物和杂草进行分类研究。本文中首先对已预训练VGG16、VGG19、Inception V3、Res Net50这四个模型进行迁移学习,然后搭建了一个深度为9层的卷积神经网络来与上述的四个模型进行比对实验效果,并且解决数据集中不同种农作物与杂草的图像数据集不均衡的问题主要采用的是数据增强的方法。另外,还将采用验证集以及测试集来评估识别分类模型的能力。在农作物小麦麦穗目标检测阶段,为了更快、更准确的检测出图像中的小麦麦穗,对图像中农作物小麦麦穗进行特征提取主要采用Res Net101和VGG16算法,采用Faster R-CNN算法对农作物小麦麦穗进行检测,从而构成了Res Net101+Faster R-CNN的模型和VGG16+Faster R-CNN的模型,然后将实验结果进行比对分析。在检测过程中扩增图像数据集主要采用数据增强的方式,实验过程中采用的是3-Fold交叉验证方法,极大程度上降低了随机划分数据带来的实验偶然性。除此之外,还对目标检测“一阶段”方式的最新代表模型YOLOv5进行实验,与上述两个模型进行比对研究。最终,对实验结果进行展示、比对和分析。研究结果——在不同种农作物和杂草分类阶段,在创建好的训练集上训练VGG16、VGG19、Inception V3和Res Net50这四种网络模型,得出实验结果较好的网络是VGG19模型。然后结合VGG19网络模型,本文设计了9层网络模型用来提升农作物与杂草的分类效果。对本文的模型进行实验,探讨得出本文设计的网络模型的效果要优于VGG19。最后,基于本文所设计的网络框架以及上述四个模型探讨在训练集、验证集和测试集上各个模型的准确率和损失率,并得出本文构建的9层网络模型性能较好。在农作物小麦麦穗目标检测阶段,采用基于Res Net101和VGG16的Faster R-CNN的模型和YOLOv5模型,对训练后的目标检测精度和目标定位损失的结果进行比对,可以得出基于Res Net101的Faster RCNN模型的训练结果明显高于基于VGG16的Faster R-CNN的模型。最后,再与YOLOv5进行比较。通过比对发现,YOLOv5的m AP值与Faster R-CNN算法相差不大,但是目标定位损失远远低于Faster R-CNN算法。所以,YOLOv5算法并且对小目标检测的效果比较突出,可以很好的解决农作物小麦麦穗相互遮挡的问题。研究的局限性——在不同种农作物和杂草分类阶段,采用图像识别分类技术对不同种农作物与杂草进行特征学习还比较粗浅,并且本文模型对相似性较高的植物幼苗在细微之处的特征学习还存在着缺失,需要进一步研究。并且,研究目标主要包括五种农作物和五种杂草,研究目标的范围较小,需要进一步扩充数据集。在农作物小麦麦穗目标检测阶段,由于小麦麦穗图像重叠,风向会使图像模糊,从而造成检测的准确率较低,需要进一步提高。系统的功能比较单一,界面比较简单,需要在后续的工作中进行优化。实际影响——与传统方法比对而言,将图像识别分类技术应用到农作物的培育和生产中,可以有效的控制杂草对农作物造成的损失,减少了除草剂的使用和控制杂草所用的时间,有利于生态环境的可持续发展。在对小麦麦穗的检测过程中,可以高效的估算出小麦的各种性状,如密度、健康状况和麦穗的数量等,使得其在小麦产量估算、小麦育种和作物管理等方面具有重要的应用价值。研发了一个可视化的系统,对后续研究和学习都有很好的帮助作用。独创性——提出了使用图像识别分类技术对不同种农作物和杂草进行分类,从而可以有效除草,弥补了传统田间杂草防治方法繁琐、防治精度不高、费时且费力的缺陷。采用深度学习的方法有效区别不同植物幼苗,有效进行杂草去除。采用图像识别分类技术来提取和学习图像中小麦麦穗的特征,用Faster R-CNN算法和YOLOv5算法目标检测算法对农作物小麦麦穗进行目标检测,从而定位出图像中小麦麦穗的位置,有利于准确的进行产量估算等。开发了植物分类检测系统,有助于不同人群对该方面的学习与研究。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.003496
{DOI}: 10.27204/d.cnki.glzhu.2022.003496
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 西部陇药的中药材图像识别与分类研究
{Author}: 张文龙
{Tertiary Author}: 林和;曾庆钱
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;图像识别;中药材;数据预处理;数据增强;全局平均池化;特征融合
{Abstract}: 目的——随着近几年中医药事业的发展,中药材成为了中医药事业不可或缺的一部分,国民对中药材重要性的认识也逐步提高了起来,但是市面上中药材的质量参差不齐,伪劣产品数见不鲜,并且传统的鉴别方法主要依靠专业人士,其存在效率低下,主观性强且成本高,非专业人士难以鉴别等各种问题。因此,随着深度学习技术的发展,将其引入到中药材鉴别方法中会解决以上的诸多问题,本文将使用深度学习技术完成对中药材的分类和鉴别。方法——由于传统的中药材鉴别方法具有主观因素和不稳定因素,本文提出了使用卷积神经网络对中药材进行提取特征并进行分类鉴别。使用数据增强扩充中药材数据量,通过数据归一化、灰度化等预处理操作,提高中药材的图像质量,最后搭建合适的卷积神经网络模型;并且为了进一步提高网络模型的识别率,对模型进行了一系列的优化操作,通过引入全局平局池化、特征融合和ELU激活函数等方式优化原始网络模型。最终,对实验的结果进行比对、研究和分析,并且使用深度学习框架Tensor Flow来完成相关实验。研究结果——本文对搭建的不同深度的网络模型的结果进行比对,当模型为14层时,模型的分类准确率最优。当对模型引入全局平局池化、特征融合和ELU激活函数的准确率进行比对后,得到的结论为网络模型引入特征融合后,模型的识别率显著提高,能满足国民日常生活的需要。研究的局限性——可进行分类的中药材的类别有限,本文只研究了几种特定的中药材,并没有完成大规模的药材识别,对其他中药材无法完成识别。实际影响——将卷积神经网络技术应用到中药材图像识别分类中,不仅可以提高分类识别的准确率,并且进一步简化对应的分类识别流程,完成对中药材的分类识别,获得了分类效果较好的模型,能够满足人民在日常生活对鉴别中药材的需求。独创性——利用归一化、灰度化、降噪和数据增强对数据集中的图片进行处理,对图像的分辨率进行了提高;使用深度学习技术对处理后的图像进行识别分类研究,并且对所提出的网络模型进行改进,在提高识别率的同时提高了模型的性能。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.003442
{DOI}: 10.27204/d.cnki.glzhu.2022.003442
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的天气图像分类方法研究
{Author}: 邹永龙
{Tertiary Author}: 马樱;查利君
{Publisher}: 厦门理工学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 天气图像分类;深度学习;迁移学习;注意力机制
{Abstract}: 日常生活当中人类的各项活动都会受到天气现象的影响,自动驾驶、智慧交通、智能安防等智能应用要想保持稳定高效的工作状态离不开实时且准确的天气信息。天气图像分类指的就是通过识别单张图像得到所处位置的天气信息,对于常规的图像分类问题,现在已经有许多方法可以很好地解决了。但是,天气图像的分类仍然存在着一些困难和挑战。比如,学术界和工业界现有可供学习使用的天气图像数据集数量和种类都太少,无法满足研究需求;天气图像分类模型的训练需要大量标注样本做支撑,同时使用高级计算设备训练很长时间才能得到一个性能不错的模型;研究人员往往过分关注基本天气类型图像分类,而忽视了对人们而言可能更重要的天气图像细分类问题。基于上述问题和挑战,首先,本文构建了一个包含更多类别并且更加接近真实情况的五类天气图像数据集,该数据集包含晴天、阴天、雨天、雪天和雾天这五类常见的天气类型,每类1000张标注好的图像。同时在五类天气图像数据集的基础上,本文还构建了用于灾害天气图像细粒度分类任务的灾害天气图像数据集。其次,针对现有天气图像分类方法准确率不高,同时模型训练速度慢的问题,在深度卷积神经网络的基础上引入迁移学习方法,能够大幅度缩短模型训练时间并且也能获得较好的分类效果。最后,针对灾害天气图像细分类问题,本文提出了一种基于优化卷积神经网络的灾害天气图像细分类方法。按照一定的标准将雨天、雪天、雾天这三类灾害天气重新划分为大雨、小雨、大雪、小雪以及大雾、小雾这六个细分类别,并且采用5种方式对它们进行数据增强,使得各个天气类别数量达到一致。然后采取用Swish激活函数代替Re LU激活函数、使用小卷积核堆叠替换大卷积核、添加CBAM注意力机制这3种方式优化卷积神经网络,实现对灾害天气的细分类。
{URL}: https://link.cnki.net/doi/10.27866/d.cnki.gxlxy.2022.000065
{DOI}: 10.27866/d.cnki.gxlxy.2022.000065
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的智能机器人感知与抓取技术研究
{Author}: 王皓乾
{Tertiary Author}: 高瑞贞
{Publisher}: 河北工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;双目视觉;点云数据;三维感知;智能机器人
{Abstract}: 三维感知技术在工业生产和日常生活中具有广泛的应用价值。目前,工业机器人主要应用在特定或相对稳定的工作环境中,重复执行示教动作完成既定工作任务。近年来,计算机视觉和深度学习等人工智能技术得到了飞速发展,为工业机器人实现三维感知和智能运动提供了技术支撑。本文利用双目视觉技术和深度学习技术对目标物体进行三维重建和智能感知并结合工业机器人抓取应用进行研究,主要完成了以下工作:首先,研究了单、双目相机理论模型和相机畸变模型,设计并搭建了平行光轴双目视觉实验平台。针对SGBM半全局立体匹配算法的不足提出了阈值限制、可靠视差值填充和双边滤波器处理三步优化法。利用双目视觉进行三维重建,获得环境对象的点云数据,并对点云数据进行预处理,同时基于点云数据轮廓形心点求解机器人抓取点的空间坐标。其次,分析了深度学习感知模型的基本原理和两种典型网络,描述了深度学习感知模型的特征提取过程,并结合本文的三维环境对象感知目标选取了合适的深度学习网络开展智能机器人环境感知研究。然后,针对环境对象三维重建点云数据设计了基于图注意力机制的深度学习网络架构GA-PointNet++。通过引入自注意力系数和邻域注意力系数机制,将不同的邻域点云数据给予不同的注意权重。感知精度实验和鲁棒性实验结果表明,设计的网络架构在不同数据集测试集上的识别准确率分别达到了 94.7%和91.3%;针对较少数量点的点云数据同样能够保持较为良好的鲁棒性,所提算法够精准感知目标对象点云数据,具有较好的网络性能。最后,设计并搭建了由6轴ABB串联机器人、双目视觉系统和深度学习感知系统构成的智能机器人感知与抓取实验平台。采用Eye-to-Hand模型完成手眼标定,并建立了机器人与目标物体间的欧拉角与四元数转换关系,将目标物体位置信息发送到机器人。将三维重建后的点云数据输入到预训练好的模型中进行点云识别,同时ABB机器人进行感知与抓取实验,实验结果表明,本文所提方法能够实现目标对象的准确感知与抓取。
{URL}: https://link.cnki.net/doi/10.27104/d.cnki.ghbjy.2022.000014
{DOI}: 10.27104/d.cnki.ghbjy.2022.000014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的仪表读数识别研究与应用
{Author}: 魏志涛
{Tertiary Author}: 孙顺远;王旭辉
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;仪表读数识别;图像降噪
{Abstract}: 传统仪表在生产生活中应用非常广泛,而且传统仪表示数的自动读取对仪表检验和工业过程监测具有重要意义。但目前传统仪表主要依赖人工读数,存在诸多限制,相比于人工读数,利用机器视觉技术进行读数识别不仅效率高、成本低、数据可视化,还能够为传统工厂的现代化改造、仪表测量精度的检验以及长期运行仪表性能的抽查提供一种实际可行的方案。为实现传统仪表示数的自动读取,本文提出基于机器视觉技术的仪表示数自动识别方案,并针对工业环境下仪表图像所受的主要噪声,对图像进行对应的去噪方法的研究,以及针对仪表表盘区域的自动检测、指针式仪表与数字式仪表示数的自动识别、仪表自动读数系统的软硬件实现进行了研究。课题主要研究内容可以分为以下几部分:(1)针对不均匀光照图像的阈值分割问题,提出一种基于二次移动平均法估计背景光照的改进二值化方法。该方法利用二次移动平均预测法对一维图像空间的灰度序列进行趋势预测,根据预测趋势寻找前景与背景的分界点以此进行背景估计,然后利用背景差法分离出目标图像,最后采用最大类间方差法进行全局分割获得分割结果。经测试分析,相较于其他阈值分割方法,该算法在分割效果与分割速度之间取得了有效均衡。(2)针对仪表表盘位置的识别与定位进行研究,利用仪表轮廓的内部信息与轮廓间的嵌套关系,提出基于仪表轮廓的表盘显示区域寻找算法。经实验验证,算法不受仪表的形状、位置和大小的影响。针对数字式仪表示数识别提出对应的算法,通过对仪表图像进行二值化、数字区域定位、倾斜校正、字符分割、粗略匹配、精确匹配等步骤,有效实现字符识别。经实验验证,识别方法计算量小且识别率较高。针对传统指针式仪表的示数识别,提出一种基于刻度轮廓拟合的指针式仪表自动识别算法。算法通过仪表图像预处理、仪表椭圆拟合、指针位置检测、刻度线位置排序和仪表示数计算等步骤,实现指针式仪表的读数识别。经实验验证,算法具备较强的抗干扰能力,读数误差小,满足实时要求。(3)根据读数识别系统的实际要求分析了系统的总体架构与识别流程,其中重点分析了仪表读数识别模块的需求。然后根据仪表读数识别模块的需求,设计了相应的硬件结构与软件框架,针对软件框架进行了功能设计并通过Qt Creator和Open CV编程实现了模块的软件设计。最后将本文改进的仪表示数自动识别算法应用到识别模块中并做出相应的测试实验,实现了对仪表示数的自动检测,让整个检测过程实现可视化。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.001133
{DOI}: 10.27169/d.cnki.gwqgu.2022.001133
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视觉SLAM系统研究及应用
{Author}: 伍子嘉
{Tertiary Author}: 彭勇;俞晓
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视觉SLAM;移动机器人;轻量级目标检测网络;Tensor RT;光流法
{Abstract}: 移动机器人如果要在未知环境中实现自身的精确定位,离不开同步定位与地图构建技术(Simultaneous Localization and Mapping,SLAM)。当SLAM系统使用的传感器为相机时,该系统可被称之为视觉SLAM系统。目前大多数视觉SLAM系统运行时都假设外部环境是静态的,但在实际应用场景中显然无法满足该假设。针对传统的视觉SLAM系统在动态环境中易受移动目标影响,导致系统定位精度下降的问题,本文提出将深度学习中的目标检测技术融入视觉SLAM系统,有效提升了视觉SLAM系统在动态环境下的定位精度,同时获得了环境的语义信息。由于传统的深度学习网络对硬件资源要求较高,本文面向不同的硬件平台,构建了不同的轻量级目标检测网络,使得基于深度学习的视觉SLAM系统在低算力乃至嵌入式平台上也可以实时运行。具体研究工作如下:(1)针对当前基于深度学习的目标检测网络运行时对硬件要求过高,难以实时运行的问题,本文在CPU与GPU平台分别构建了轻量级的目标检测网络。对于CPU平台,本文通过对比常见的轻量级网络,提出将Mobile Net V3轻量级网络作为目标检测网络YOLOv5s的主干网络,最终构建出一个轻量级的目标检测网络Mobile Net V3-YOLOv5s,使得网络模型参数量减少了51.88%,在CPU上检测速度提升了53.06%。对于GPU平台,为充分发挥GPU并行计算的优势,本文提出利用Tensor RT对YOLOv5系列进行网络融合加速,实验表明,相比原YOLOv5s网络,融合后的Tensor RT-YOLOv5s网络显存使用量减少了39.84%,同时网络推理速度获得了12倍的提升。最后,本文在校园实际道路环境中对YOLOv5s、Mobile Net V3-YOLOv5s、Tensor RT-YOLOv5s这三种网络进行了检测效果对比测试。(2)针对当前的视觉SLAM系统在动态环境中工作时定位精度不高、鲁棒性不足的问题,本文在上述(1)研究的基础上,提出将Mobile Net V3-YOLOv5s轻量级目标检测网络与光流金字塔融入视觉SLAM系统。使得SLAM系统前端提取ORB特征点的同时可有效剔除图像中的动态特征点,仅利用静态目标上的特征点进行帧间匹配求解相机位姿,提高了系统在动态环境下的定位精度。将本文算法应用于动态环境,在TUM动态数据集上的测试表明,相比ORB-SLAM3,位姿估计精度提升了80.16%,相比其他适用于动态环境的SLAM算法在实时性与精度上各有部分提升。综上所述,本文的研究成果能有效减少动态目标对视觉SLAM系统定位精度的影响,且系统中的轻量级目标检测网络可以实时地获取语义信息,为将深度学习技术融入视觉SLAM系统的研究及应用提供了新思路,对在嵌入式平台上应用视觉SLAM技术有一定参考价值。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000234
{DOI}: 10.27169/d.cnki.gwqgu.2022.000234
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人脸微表情识别技术研究
{Author}: 陈汤慧
{Tertiary Author}: 高美凤;张石磊
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 微表情识别;卷积神经网络;迁移学习;光流;运动放大
{Abstract}: 随着社会各方面需求增多,以及信息化技术和人工智能的发展,微表情识别领域受到越来越多研究人员的关注。微表情作为一种自发的、不具有欺骗性的面部表情,可以在心理治疗、刑事审讯、公共安全等领域提供强有力的判断依据。持续时间短、运动幅度小是微表情的显著特点,也是微表情识别的难点所在。此外,由于数据采集过程难以捕捉自发性微表情且人脸数据涉及个人隐私,现有的公开数据集样本数量比较少。针对上述问题,本文主要研究了基于视频运动放大技术、卷积神经网络、多运动特征融合的方法来提高深度学习模型的微表情识别准确率。具体而言,主要研究内容如下:(1)针对微表情运动幅度小、数据集样本少的问题,提出了一种基于迁移学习的卷积神经网络用于微表情识别。通过添加投影变换和通道注意力机制来改进宏表情识别网络模型,构建新的网络模型以适应微表情识别任务。投影变换重整了输入特征,不仅能够产生更具有区分性的特征,还减少了网络参数。通道注意力机制帮助网络进一步关注和选择有助于微表情分类的信息,所提网络模型训练参数少、计算量小,可以有效避免过拟合情况。为了增强迁移学习时微表情与宏表情之间的相似性,对微表情进行自适应运动放大,对宏表情进行强度缩小。最后在多个微表情数据集上进行验证实验,结果证明了所提方法的有效性。(2)针对受年龄、光照变化影响较大的单一光流特征存在噪声导致识别准确率下降的问题,提出了一种多运动特征融合的双流卷积神经网络用于微表情识别。将不容易受到年龄、光照变化影响的人脸关键点特征图和光流特征进行融合,构建多运动特征融合的双流卷积神经网络,在网络末端加入分类融合决策,以此来提高网络模型的识别准确率。针对微表情数据集标签给出的动作单元信息未被利用以辅助微表情识别的问题,根据动作单元和人脸关键点之间的紧密联系,对人脸关键点特征图进行加权。最后在一系列微表情数据集上进行实验,结果表明了所提方法能够提高识别准确率。(3)受突如其来的新冠肺炎疫情和学术科研压力的双重影响,在读研究生患抑郁症和具有自杀倾向的人数明显增加。为了将本文研究内容落实于实际应用场景,建立了江南大学微表情(Jiangnan University’s Micro-Expressions,JNUME)数据集,搭建了面向研究生的情感状态分析系统。该系统具有单样本微表情识别、微表情数据管理、受试者信息管理以及个人情感状态分析等功能,并将本文提出的微表情识别算法应用于单样本微表情识别和个人情感状态分析模块。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000593
{DOI}: 10.27169/d.cnki.gwqgu.2022.000593
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 立体仓库智能检测与控制系统的研究
{Author}: 赵继红
{Tertiary Author}: 葛广英
{Publisher}: 聊城大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自动化立体仓库;机器视觉;堆垛车;MCGS组态软件;VisionBank视觉检测软件;模板检测;深度学习;目标检测
{Abstract}: 随着互联网的发展,物流业也迅速崛起,由于场地和劳动力的限制,产品的仓储成为重要问题。近些年,可编程控制器与堆垛机等研究领域的发展,推动了自动化立体仓库的发展,有效解决了产品的仓储问题。此外,工业生产中少数企业实现了产品仓储与智能机器视觉检测的集成,集成的一体化流水线操作不仅能够实现产品的存储到传递,而且能够准确、高效地检测产品缺陷,大大提高工作效率。本文使用SFI4.0-MINI工业4.0设备,利用STEP7软件与图像处理软件,设计了一种基于立体仓库智能检测与控制系统,该系统主要分为两大部分:一是自动化立体仓库的设计,二是通过智能相机检测系统检测齿轮的尺寸与缺陷,以及利用深度学习来实现齿轮的缺陷目标检测。本文主要内容如下:1.自动化立体仓库由西门子S7-200 SMART ST30作为核心控制器,采用相对寻址方法,使目标精准到位;其堆垛车模组由伺服电机、减速机、X、Z轴直线模组与气动抓手组合而成;并使用顺序功能图法对PLC进行编程,实现了堆垛机的出库、入库等操作。2.上位机监控系统的设计采用昆仑通态MCGS组态软件,通过上位机实现了堆垛机出库、入库操作;选择手动、自动控制操作;气动抓手动作方式与显示工作状态等操作。3.将梯形图下载到PLC中,组态界面下载到MCGS运行环境内,对立体仓库系统进行整体调试。完成了上位机控制堆垛机运行的目标,达到了预期要求。4.齿轮图像的采集由输送带将载有齿轮的托盘输送到智能相机检测工位与双远心视觉检测工位,利用相机、双远心镜头并在环形光源的作用下采取自动拍照,采集齿轮图像。5.利用Vision Bank视觉检测软件对齿轮进行尺寸测量与缺陷检测。分别对采集的齿轮图像进行预处理、特征定位、圆定位、圆检出、斑块检出、计数与斑块面积等操作测量出齿轮的齿顶圆直径、齿底圆直径,最后利用模板检查工具,检测齿轮是否存在缺陷。6.利用了Alex Net、VGG-16、SSD、YOLOv3四种经典神经网络模型对采集到的齿轮图像进行基于深度学习的缺陷目标检测,并对四种检测结果进行了对比,结果验证了YOLOv3对于小目标的目标检测准确率更高。
{URL}: https://link.cnki.net/doi/10.27214/d.cnki.glcsu.2022.000423
{DOI}: 10.27214/d.cnki.glcsu.2022.000423
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的七自由度机械臂抓取与避障研究
{Author}: 沈业全
{Tertiary Author}: 刘霞
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机械臂;运动学;RRT;机器视觉;ROS;相机标定
{Abstract}: 近些年来,随着各国工业战略的提出,机械臂行业得到了快速发展。传统机械臂大多数还停留在第一代或第二代,需要人类手动进行路径规划,并且其大多数是低自由度,无法在复杂多变的环境下自主完成任务。因此,本文设计了一套基于机器视觉的七自由度机械臂自主抓取与避障方案,在ROS机器人系统下通过视觉获取目标物体与障碍物的位置与姿态,选取本文改进的RRT算法协助机械臂完成抓取任务,主要进行了如下研究:首先,利用连杆参数对机械臂进行建模,推导了机械臂的正、逆运动学方程,在求解机械臂逆运动学方程时提出了腕-肘-肩的简化模型,并且对机械臂的正、逆运动学方程进行了验证。接着,研究了碰撞检测算法与路径规划算法,分析了RRT、RRTconnect、RRT*算法的原理,提出了本文改进的RRT算法,对RRT算法加入了双向搜索、贪婪思想、动态步长和随机点产生的优化,大大减少了算法运行时间以及路径长度。其次,分析了针孔摄像机的模型,对Kinect相机进行了相机标定和手眼标定,求出相机坐标系与机械臂底座坐标系的变换矩阵,研究分析了点云去噪算法、分割算法、配准算法的原理与步骤。接着,搭建了ROS机器人软件平台,设计了抓取系统的整体框架,将RRT算法与本文改进的RRT算法插入到OMPL运动规划器中,完成了这两种算法的对比仿真实验,进一步验证本文改进RRT算法的优越性。然后,对抓取场景点云进行点云去噪,利用RANSAC算法与K均值聚类算法得到场景下物体的点云文件,通过SAC-IA粗配准算法成功找到目标物体的点云文件,对目标物体点云与模板点云进行ICP精准匹配,将配准得到的旋转平移矩阵用四元数来表示,计算出目标点云的质心,从而得到抓取场景下目标物体的位置与姿态。最后进行了抓取避障实验,成功规划出一条无碰撞的路径,完成目标物体的抓取。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2022.000138
{DOI}: 10.27800/d.cnki.gjhdx.2022.000138
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: AGV导航系统中视觉SLAM定位与建图方法的设计与实现
{Author}: 韩玉虎
{Tertiary Author}: 郑飂默;李伦兴
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: SLAM;计算机视觉;定位与建图;特征匹配;AGV
{Abstract}: 当前正是中国由制造业大国向制造业强国转向的关键时期,需要不断的提高制造业的智能化水平,AGV是智能制造的重要工具,可以极大的提高生产和生活效率,降低工业成本,具有非常重要的研究价值。在很多产品的工业生产过程中,需要频繁地进行物料运输,相比于使用人工运输的方式,使用AGV可以提高物料运输的效率并降低成本。AGV经过多年的发展,在各个行业也得到了广泛的应用,其导航系统也由最传统的固定轨道导航演变为电磁导航和激光导航,但考虑到灵活性以及成本等因素,电磁导航和激光导航依然不是最佳的导航方法。近几年随着深度学习的出现,学术界对于计算机视觉技术研究火热,同时带动了视觉SLAM技术的快速发展,也出现了许多经典的视觉SLAM方案。为了更好的发挥AGV的灵活性和自主性,本文基于经典的SLAM的技术方案开展用于AGV导航系统的视觉SLAM定位和建图方法的设计和实现工作,提出了一种基于特征点法和光流法融合的定位方案。该方案可以有效的避免特征点的误匹配,为后续的位姿估计、后端优化以及稠密建图奠定了良好的数据基础。此外,鉴于AGV导航对于稠密地图的需求,本文提出了一种基于极线匹配的稠密建图方案,首先利用双目相机进行极线匹配构建初始局部地图,然后利用前后多帧进行深度滤波以使得地图点的位置收敛于可接受的状态值,最后通过点云滤波进行点云的下采样和外点的去除并通过相对位姿变换关系实现局部稠密地图到全局地图的融合工作。针对提出的SLAM定位和建图方案,本文采用模块化的方法对其进行实现,通过在KITTI数据集和本地进行实验,证明了本文所提出的用于AGV导航系统的视觉SLAM定位和建图方法的可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000038
{DOI}: 10.27587/d.cnki.gksjs.2022.000038
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的数控刀具磨损检测
{Author}: 苏进发
{Tertiary Author}: 刘建春;邹朝圣
{Publisher}: 厦门理工学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;在机检测;图像处理;边缘提取;立铣刀状态监测
{Abstract}: 在铣削加工中,定期掌握刀具加工状态的变化,及时更换失效刀具,可减少由刀具失效引起的停机,显著提升加工质量。与传统人工检测和离线仪器检测相比,基于机器视觉的立铣刀磨损在机检测方法有效避免了装卸刀具导致的安装误差与检测迟滞,有利于提高检测效率和检测精度;目前的在机视觉检测方法多数将检测装置搭建在数控加工中心内部,一定程度上实现了在机检测,但未充分考虑加工干涉与镜头污染问题。为解决上述问题,本文基于伸缩式菱形连杆机构的直线传方式,提出了搭建在加工中心侧面观察窗外部的立铣刀磨损在机视觉检测方案,由连杆机构带动图像采集装置进入或退出数控机床,通过三维模型设计、零部件选型、加工装配等步骤搭建检测装置,并结合立铣刀磨损在机检测流程设计了控制系统方案,实现与加工中心外部相对独立的立铣刀磨损在机检测,有效解决了加工干涉与镜头污染问题。对于立铣刀磨损检测算法的研究,检测系统通过自适应混合滤波去噪、对比度增强等预处理,采用均值迭代法、最大类间方差法进行图像分割,获得磨损区域二值图像,融合Canny算子与基于Zernike矩的亚像素边缘进行磨损轮廓提取,基于图像平面创建立铣刀磨损轮廓模型,结合最小二乘法对原始切削刃进行边界重构,求取立铣刀的磨损量,反馈刀具磨损状态,实现立铣刀磨损快速检测。在机检测系统的控制软件集成了机构运动控制、立铣刀图像采集与处理、数控通信控制等功能。通过PLC控制检测机构运动;通过立铣刀图像采集与处理分析,完成立铣刀磨损检测;通过与CNC系统通信完成立铣刀磨损补偿反馈。最后,选取5把立铣刀开展铣削实验,将检测系统与天准-VMC322影像测量仪两者的测量结果对比。结果表明,检测系统的测量偏差小于0.01mm,综合平均准确率达到96%。
{URL}: https://link.cnki.net/doi/10.27866/d.cnki.gxlxy.2022.000040
{DOI}: 10.27866/d.cnki.gxlxy.2022.000040
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于DeepLabV3+模型的街景影像语义分割方法研究
{Author}: 杜梓维
{Tertiary Author}: 刘波
{Publisher}: 东华理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像语义分割;DeepLabV3+模型;加权损失函数;特征融合;注意力机制
{Abstract}: 随着科学技术的发展,基于深度学习的图像语义分割技术在人们的日常生活中应用越来越广泛。在城市道路场景中,高精度的语义分割技术能为智能车辆的规划决策提供重要信息,是辅助车辆安全行驶的重要保障。因此,本文基于DeepLabV3+模型在道路场景中对语义分割方法展开研究,从模型本身出发,分析了城市道路场景图像中的分割难点,并对DeepLabV3+模型的编码器-解码器结构进行了测试与改进,有效提升了模型的分割效果。本文具体的工作内容和创新点如下:(1)针对小样本街景影像数据集训练数据少、类别不均衡问题,本文采用了模型迁移和加权损失函数方法来缓解和改善这一问题。实验结果表明,通过模型迁移方法训练的模型能够更快的收敛,且模型的鲁棒性和泛化能力更好;模型迁移方法结合加权损失函数训练模型,能够有效改善小尺度目标对象的识别率和分割精度,提高模型的整体分割效果。(2)针对DeepLabV3+模型主干特征提取网络参数量巨大、不利于实际应用的问题,本文使用了目前常见的卷积神经网络作为主干网络进行特征提取,探究了Res Net50、Res Ne Xt50、Mobile Net V2分别作为特征提取网络下DeepLabV3+模型的分割性能。通过调整输出步长来减少下采样过程中的特征损失,提高了模型的分割效果。当输出步长调整为8倍时,DeepLabV3+模型的分割效果最好;考虑到模型实际应用,通过实验对比分析,当输出步长调整为16倍时,DeepLabV3+模型的参数量、复杂度和分割精度之间最为平衡。(3)针对DeepLabV3+模型在小尺度物体及目标边界信息细节表现较差问题,本文对DeepLabV3+模型原有解码器结构进行了改进。主要工作体现在以下方面:一是利用全局卷积模块、边界细化模块从浅层网络进一步提取街景影像的局部特征,特征融合了更多细节信息的GCN-DeepLabV3+、GCNG-DeepLabV3+模型在图像分割的细节方面获得了更好的表征能力。二是利用卷积块注意力模块在通道和空间维度上对浅层网络提取到的局部信息进行特征映射,增加了注意力机制的CBAM-DeepLabV3+模型提取到了更加关键的局部特征,改善了在小尺度目标对象和边界细节上的分割效果。实验结果表明,本文改进解码结构后的DeepLabV3+模型能够更好的应用于城市道路场景的语义分割任务。
{URL}: https://link.cnki.net/doi/10.27145/d.cnki.ghddc.2022.000087
{DOI}: 10.27145/d.cnki.ghddc.2022.000087
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 无人驾驶车辆在复杂环境下的目标检测算法研究
{Author}: 吴书博
{Tertiary Author}: 陈丽
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自动驾驶;计算机视觉;目标检测;YOLO;卷积神经网络
{Abstract}: 近些年来,计算机技术飞速发展,汽车制造水平也在稳步提升,无人驾驶汽车已然成为当今的技术热点,在不久的未来必将成为主流。而环境感知作为自动驾驶技术最为关键的环节,是实现安全自动驾驶的前提和保障。基于无人驾驶车辆在复杂交通场景下的目标检测作为自动驾驶环境感知的一大重要任务,需要同时检测汽车行人等多种目标,还要面临目标之间的遮挡、光照不足、极端天气下保持高精度和高检测速度等诸多挑战。基于深度学习的目标检测算法具有精度高、通用性强、任务迁移能力强、工程开发、优化和维护成本低等优点,成为复杂交通场景下目标检测任务的有效解决方法。本文以YOLOv4目标检测算法为基础,对其提出改进和优化。首先使用深度可分离卷积和倒残差结构进行对网络进行轻量化改进,减少了YOLOv4算法的参数量和计算量,在损失一小部分检测精度的情况下使检测速度得到大幅提升。并将注意力机制融入到YOLOv4网络中,在三个不同检测层嵌入CBAM,使算法能够在训练过程中更加关注目标本身,最终在不影响检测速度的同时提高了检测的精度。然后对不同输入尺寸对于目标检测算法性能的影响进行了实验探究和分析,综合考虑检测速度和精度两方面后选取出了对于算法性能最为均衡的输入尺寸。接着用K-means++算法对KITTI数据集进行聚类分析,得到了尺寸更加适合的锚框以替代原算法中的锚框。最后针对训练时出现的正负样本不平衡问题,在YOLOv4损失函数的基础上引入了焦点损失函数,有效提高了小目标以及难分类目标的检测精度。最终本文改进的YOLOv4算法在KITTI测试集上进行了测试,结果表明准确度达到了82.98%,并且检测速度为38.4FPS,满足实时检测的要求。最后使用国内交通目标数据集SODA10M进行了实验,验证了本文改进算法的泛化性和有效性。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000957
{DOI}: 10.27322/d.cnki.gsgyu.2022.000957
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的焊缝缺陷检测系统研究
{Author}: 唐茂俊
{Tertiary Author}: 袁庆霓
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 焊缝缺陷检测;机器视觉;图像增强;深度学习;系统开发
{Abstract}: 由于焊接工艺的复杂性和工艺干扰的随机性,焊缝成型过程中会产生难以预测的焊接缺陷,这些缺陷会严重降低焊接部件的机械性能,从而导致严重的后果。因此,对焊缝的缺陷进行检测是至关重要的,但是传统人工检测效率低、成本高,且易受主观影响。本文利用机器视觉模拟人工检测焊缝缺陷,对机器视觉三大核心领域技术:图像采集、图像处理与分析展开深入研究,开发基于机器视觉的焊缝缺陷检测系统,提高焊缝缺陷检测自动化水平以及检测效率。主要工作如下:在贵州某企业完成了机器视觉平台的设计与搭建,采集到焊接系统生产的焊接产品焊缝图像4586张。针对采集图像质量不佳的问题,提出了一种自适应分割的动态直方图均衡图像增强算法。该方法使用变换函数处理整个直方图,并将直方图拆分为多个子直方图,使得每个子直方图具有可控的灰度级动态范围,避免了图像的特征丢失。为了验证算法的有效性,引入图像评价指标对主流算法进行对比分析,实验结果表明:本文改进算法在三种评价指标上表现最优且从效果图看出图像细节最丰富。针对原始算法小目标检测精度低下且速度缓慢等问题,提出了一种改进FasterRCNN算法的缺陷检测方法。该方法使用K-means聚类算法优化锚框,提出解耦分类细化结构实现再分类以减少网络误报率,建立特征金字塔实现特征融合以提高小目标检测精度。在Co Co2017公共数据集和自采氩弧焊焊缝缺陷数据集对改进算法进行有效性验证,结果表明,本文算法相比原始Faster-RCNN算法召回率提高了9.7%,准确率提高了11.1%。通过模型剪枝技术对改进网络进行压缩,模型大小降低了40%左右。实验结果表明:改进并剪枝后的算法准确率达到93.1%、召回率达到90.5%、FPS为20,满足产品工程实际中的缺陷检测要求。基于上述研究,开发了焊缝缺陷检测系统并在工程实际中运行。设计了系统总体架构、系统类图与数据库;构建了模型库提高系统泛化能力,使用SORT目标跟踪算法提高了跟踪的准确率。将系统投入贵州某企业中使用,系统检测准确率达到94.27%,漏检率为0.98%,每张图片检测速度为0.65s,具有一定性能优势,能够有效满足实际生产需要。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.001036
{DOI}: 10.27047/d.cnki.ggudu.2022.001036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的施工现场人员行为安全监测方法研究
{Author}: 王志伟
{Tertiary Author}: 赵雪峰
{Publisher}: 大连理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 工程施工;安全监测;机器视觉;深度学习
{Abstract}: 建筑业是一个高危行业,施工安全事故时有发生,大量的施工安全事故造成了难以挽回的生命财产损失和恶劣的社会影响,这和施工现场的特点有很大关系。复杂的施工环境,同时存在多个工种,人员流动大,不同的机械同时作业都增加了安全风险。分析统计数据,人为失误是造成我国房屋市政工程生产安全事故的主要因素之一。当前,新兴技术快速发展,基于快速发展的计算机技术、传感技术、信号处理技术以及人工智能等技术,以计算机作为运行平台,进行自动、实时、快速的施工现场监测系统走进人们的视野并被广泛研究。这使得我们可以借助新的技术快速、准确的对监控数据进行处理,对复杂施工现场的安全状态和建筑物在建设、运营期间进行长期在线监测,及时发现各种事故隐患并快速反馈,协助管理人员进行监管,保证施工现场安全。本文主要进行了以下几个方面的研究:(1)提出了一种基于生成对抗神经网络和卷积神经网络在复杂背景下目标识别的方法,将两种神经网络结合使用,使用生成对抗神经网络对数据进行预处理,对影响识别精度的复杂背景进行优化,生成模拟数据,得到高质量的数据集。再使用卷积神经网络对混凝土施工过程中具体行为进行目标检测。经过对比实验验证,该方法可有效提高目标检测平均精确度。(2)提出了一种基于人体骨骼关节点姿态估计和卷积神经网络的人体动作行为识别的方法,该方法可以提高有典型行为动作的小目标识别精度。该部分分为两块,第一部分介绍了人体骨骼关节点姿态估计的经典算法Open Pose,并使用该算法对工人行为进行估计,筛选出具有典型动作的危险行为。第二部分介绍卷积神经网络Faster R-CNN算法,并使用此算法对经过筛选的数据进一步检测,识别出人员危险行为。(3)最后综合上述研究内容,提出了充分使用现场已有设备,基于施工现场监控视频和机器视觉相关技术构建实时监测平台的方法,该平台可以同时对多路监控摄像头展开实时监测,及时检测、反馈,便于施工人员进行现场管理,提高工作效率。还提出了一种基于卷积神经网络的数据储存优化方法,提高了储存空间的利用率。本文重点关注施工现场人员不安全行为,探究施工现场人员不安全行为的监测方法,搭建监测平台进行智能化监测,为施工管理人员提供必要协助,全方位多角度对施工现场进行数字化管理,对实现建筑工地智能化管理具有重大意义的。
{URL}: https://link.cnki.net/doi/10.26991/d.cnki.gdllu.2022.003277
{DOI}: 10.26991/d.cnki.gdllu.2022.003277
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的跌倒检测研究
{Author}: 曹家栋
{Tertiary Author}: 肖燕彩
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 跌倒检测;HOG特征;SVM;YOLO;Alphapose;时空卷积图;人体关键点
{Abstract}: 随着中国人口老龄化程度加深,“空巢老人”的现象越来越普遍,老人的健康问题受到更多的关注。在老人日常生活中,意外跌倒是造成老年人受到伤害的主要原因。针对老人的跌倒检测逐渐形成了一个热门的研究领域,老年人口的迅速增长也为此类产品和技术提供了非常大的需求和市场。基于机器视觉式的跌倒检测方案由于安装方便、应用广泛,成为当前跌倒检测的研究热点。本文对基于机器视觉式的老人跌倒检测过程中的相关算法进行深入研究。主要研究内容包括以下几个方面:(1)制作了跌倒检测数据集。本文使用的数据集包括公开数据集Le2i和UR Fall Detection Dataset跌倒检测数据集,另外,还有部分自制数据集。这些数据集中场景和数量不均衡,为了解决这一问题,对数据集进行了随机增强处理,并合并了不同的场景组成了混合数据集。选择了精准率和召回率作为人体目标检测评价指标,准确率和跌倒检测错误率作为跌倒检测模型的评价指标。(2)研究了基于传统机器学习的跌倒检测算法。提出了一种HOG(Histogram of Oriented Gradients)特征和支持向量机算法相结合的跌倒检测方案。在人体目标检测方面,使用HOG结合SVM(Support Vector Machines)分类器进行目标检测。在跌倒检测方面,提出了两级SVM分类器进行跌倒检测,第一级SVM分类器剔除日常生活中正常行为,第一级SVM无法识别的行为输入第二级SVM进行跌倒检测以识别跌倒行为。第一级SVM分类器使用线性核,准确率较高,第二级SVM分类器使用RBF核,分类器准确率较高,使用粒子群算法对RBF核函数的SVM分类器进行参数寻优,其跌倒检测准确率达到85.8%,提升了4.5%。(3)研究了基于深度学习的跌倒检测算法。通过对比目前单阶段和双阶段目标检测算法,确定了使用YOLO目标检测算法,并使用Dense Net算法思想改进了YOLO网络模型,实验证明改进后的模型检测精度更高,且参数没有明显增加。在人体姿态估计方面,对人体关键点提取进行了研究。对于Alphapose人体姿态估计算法在目标存在遮挡的情况下导致的人体骨架关节点检测不全的问题,提出几何约束和时间约束的关键点补齐算法对Alphapose算法进行优化,检测精度提升了0.3%。利用时空卷积图进行了跌倒检测算法研究,针对该算法在环境干扰下导致的关节点轨迹波动的问题,利用Kalman滤波算法对其进行优化,关节点轨迹准确率提升了2.2%,最终跌倒检测实验准确率达到91.3%。(4)使用Qt5设计了跌倒检测系统。跌倒检测系统包括登录、跌倒检测、结果导出以及跌倒警报等功能界面,并在不同光照条件和遮挡等影响下对HOG+SVM跌倒检测算法和深度学习的跌倒检测算法进行了对比实验。通过实验表明,本文提出的两种跌倒检测方案都可以达到较高的检测准确率,可以满足老人跌倒检测需求。基于深度学习跌倒检测方案受光照和遮挡影响较小,整体要优于传统机器学习算法的跌倒检测方案。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.001410
{DOI}: 10.26944/d.cnki.gbfju.2022.001410
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的车辆识别方法及其应用研究
{Author}: 罗云钟
{Tertiary Author}: 李志勇
{Publisher}: 四川农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 数字乡村;视频监控;车辆识别;车辆再识别;深度学习
{Abstract}: 视频监控作为治安管理的重要环节,在数字乡村建设中发挥着重要作用。目前,部分乡村地区已经通过车辆识别、人脸识别等视频智能分析技术逐步建设数字乡村平台,实现重点区域的全覆盖、重点人员强监控、重保场所易管控的综合治理,持续利用信息技术为乡村振兴赋能。然而,车辆识别任务的实际应用场景较为单一,例如在停车场、小区入口进行车牌识别,复杂场景下的车辆识别及其应用研究较少。主要原因是在复杂环境下获取的车辆图像的质量差异较大,同时各项识别任务之间对输入车辆图像的需求不一致,导致各项车辆识别任务之间难以兼容。针对这个问题,本文提出一系列车辆识别方法,包括车辆属性识别、车辆车牌识别以及车辆再识别,主要研究内容如下:(1)基于分类的车辆属性识别方法研究。针对光照等环境因素对车辆识别造成较大影响的问题,本文将Efficient Net-B4作为主干网络,对10种车辆颜色以及930种车型进行分类研究,颜色识别的Top1和Top5准确率分别达到了94.7%和99.8%,车型识别的Top1和Top5准确率分别达到了93.3%和97.8%。(2)基于目标检测的车牌识别方法研究。针对在不同视角、不同距离拍摄的不限定场景下,无法较好识别小目标车牌区域以及倾斜车牌字符识别较难的问题,本文将车牌识别流程分为车辆检测、车牌检测与校正、车牌字符识别。首先利用YOLOv3对车辆进行检测,并根据检测框纵横比调整车辆框大小,以此缩放车牌大小便于车牌检测;其次利用扭曲平面目标检测网络(Warped Planar Object Detection Network,WPOD-Net)实现车牌检测与校正;最后通过合成车牌数据集训练车牌字符识别的改进YOLO网络。该方法对不同视角下的车牌识别任务具有较强的鲁棒性,车牌字符识别的平均精度均值(mean Average Precision,m AP)达到了99.54%。(3)基于区域软划分注意力的车辆再识别方法研究。不同的两辆车从相同视角观察,视觉信息可能非常相似;而同一辆车,从不同视角看,视觉信息却差异较大,因此难以区别车辆身份。本文提出利用区域软划分注意力机制自动为车辆区域生成软掩码,并利用空间多样性损失规范注意力机制学习不同的车辆区域特征,将不同车辆区域的特征对齐之后进行特征比较,从而解决因视角引起的车辆特征差异问题。在无需额外注释的情况下,该方法与需要额外注释的先进方法取得相当的效果。
{URL}: https://link.cnki.net/doi/10.27345/d.cnki.gsnyu.2022.000755
{DOI}: 10.27345/d.cnki.gsnyu.2022.000755
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件识别与定位方法研究
{Author}: 吴云飞
{Tertiary Author}: 江明;柳贺
{Publisher}: 安徽工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 工业机器人;机器视觉;图像处理;模板匹配;工件识别;工件定位
{Abstract}: 随着“中国制造2025”的提出,工业机器人与机器视觉的研究与应用取得了迅速发展。传统的工业机器人系统因缺乏感知判断能力而无法解决目标种类和位置的变化的问题,而装配视觉传感器的工业机器人可以提高对目标识别和位置判断的感知能力,实现对目标的识别和定位,更能满足工业需求。为了解决传统工业机器人无法对目标工件的种类识别与位置判断的问题,本文设计了一种基于机器视觉的工件识别与定位系统。本文以工业机器人为载体,对基于机器视觉的工件种类识别和定位技术做出了研究探讨,使工业机器人可以完成对目标工件的抓取打磨工作。论文对单目相机的标定和手眼标定方法做出研究,其次对图像预处理方法进行优化改进,然后对传统边缘提取算法提出改进,最后使用基于工件形状的模板匹配方法实现对工件的识别定位。本文的主要研究内容有:(1)在相机标定方面,本文对相机成像涉及的各坐标系之间转化关系进行研究,分析了张氏标定法及九点法手眼标定的原理,并通过实验计算出工业相机的内外参数和畸变系数,以及相机坐标系与机器人基坐标系等转换关系矩阵。(2)为了降低光照、噪声等外在因素的影响,本文提出一种改进的图像预处理方法,对高斯滤波算法进行优化改进,并设计了一种新的混合滤波算法,实现去除光照和噪声对图像的影响。其次针对传统边缘特征提取方法的不足,对Canny边缘算子进行优化改进,并结合数学形态学和小波融合算法提出了一种改进的边缘提取方法,实现对目标工件边缘轮廓的提取。(3)针对目标工件的特性,本文设计了一种基于目标轮廓的模板匹配方法,首先,采集含有目标工件的图片,用改进的图像预处理方法对其进行处理,去除光照和噪声等干扰因素的影响,然后分割出含工件的感兴趣区域,用改进的边缘提取算法完成对区域中工件轮廓信息的提取并将其制作为模板,用模板遍历整个被测图像,根据相似性度量完成对工件种类的识别以及确定抓取点的像素坐标,通过相机标定和手眼标定参数,实现像素坐标和世界坐标的转换计算,完成对目标工件的识别与定位。此外,还通过离线编程软件实现工业机器人的轨迹规划,引导机器人完成工件的抓取打磨工作。最后,通过仿真和实物实验对本文设计的视觉系统可行性进行验证分析,实验结果表明,本文设计的视觉系统能有效完成对目标金属铸件的种类识别与定位。
{URL}: https://link.cnki.net/doi/10.27763/d.cnki.gahgc.2022.000151
{DOI}: 10.27763/d.cnki.gahgc.2022.000151
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体姿态估计的羽毛球运动训练系统的设计与实现
{Author}: 石传寿
{Tertiary Author}: 赵小虎
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人体姿态估计;羽毛球训练;人体姿态描述;姿态相似度计算
{Abstract}: 当今中国正处于从体育大国迈向体育强国的重要阶段。体育强国战略提出,2035年我国参加体育锻炼的人数将达到45%以上。羽毛球运动对运动场地和运动器材的要求不高,且在运动过程中无身体对抗,已然成为我国国民普及的运动项目。羽毛球亦属竞技性的运动项目,运动者掌握羽毛球运动的基础动作至关重要。初学者没有专业的教学指导不仅难以提高自身的竞技水平,也可能导致身体出现不同程度的损伤。据相关统计显示,羽毛球专业学生的损伤率达到94.12%,并且对技术动作掌握不好是造成损伤的主要原因。在运动过程中运动员由于缺乏科学指导而导致的运动水平提升慢以及身体伤病问题亟待解决,这引起了学界的广泛研究。但是现有的羽毛球训练系统存在各种弊端,例如实时性不足、动作评估准确度低等,导致系统难以普及应用。近年来计算机视觉技术被广泛应用于各种人体姿态估计与行为识别任务中,本文将计算机视觉技术应用于羽毛球运动教学中,对羽毛球挥拍动作的识别与标准程度评估进行研究,主要研究内容如下:(1)提出一种基于改进OpenPose的轻量级人体姿态估计模型。首先,将VGG19特征提取网络替换为轻量型的MobileNet网络,并将模型内部的7×7的卷积核结构改造为由一个1×1的卷积、一个3×3的深度可分离卷积与一个膨胀系数为2的空洞卷积组成的串联结构,实现了模型的轻量化,将模型的性能提升3倍;然后,通过自制羽毛球挥拍动作数据集对改进后的模型进行训练;最后,在公共数据集上与其他优秀模型以及原模型进行对比实验,结果表明,本文模型对人体手臂的骨骼点识别准确率相较于原模型提升3.57%。(2)提出一种羽毛球挥拍动作的标准程度评估方法。首先,对视频中人体进行跟踪识别,本文使用了粒子滤波算法获取预测过程中非平稳模型参数,摆脱了非线性模型的高斯限制,实现了准确的人体跟踪;然后,定义了八种挥拍动作的标准评价指标,考虑到羽毛球挥拍动作的特殊性,提出了人体姿态的稀疏表示模型,使用三种姿态间距离度量方式进行姿态间的相似度计算,通过对结果的分析,选择了马氏距离算法作为本文姿态相似度计算方法;最后,设计了羽毛球动作的评分公式,并对动作评估系统的精确度与时效性进行实验验证,实验证明本文所提出的动作评估系统在保证精度的前提下,时效性提升了2.98倍。(3)依托于上述研究内容,开发了基于人体姿态估计的羽毛球训练系统,实现了对羽毛球挥拍动作的实时分析结果展示的功能。通过对系统的功能、性能以及稳定性进行测试,结果表明本系统可以达到预期的效果。本文包括图46幅,表24个,参考文献74篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000302
{DOI}: 10.27623/d.cnki.gzkyu.2022.000302
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的三维重建算法的研究与实现
{Author}: 杨硕
{Tertiary Author}: 谢晓尧;刘嵩
{Publisher}: 贵州师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 三维重建;深度图;多视图几何;计算机视觉;轻量级网络
{Abstract}: 随着逆向工程技术的发展,三维重建已融入到医疗影像、文物数字化、测绘等多个行业。使用站立式三维扫描仪或手持式扫描仪进行三维重建作业,不仅设备笨重、价格昂贵而且对应用场景有较高要求,严重限制了三维重建技术的应用范围。基于图片的三维重建技术是通过模仿动物视觉来获取场景的深度图像,并进行三维模型拟合,达到重建的效果。相对于传统的重建方法,该技术使用的设备轻便、价格便宜、应用场景要求不高,且重建效果有较好表现。随着深度学习的发展,基于深度学习的三维重建已成为了目前基于图片的三维重建研究领域的一个重要热点。本文通过对现有基于深度学习的三维重建方法进行分析,针对现有网络模型中内存消耗严重、效率低下、无法满足大场景重建的需求等问题,提出一种高效的多视图几何三维重建网络模型(high efficiency multi-view stereo network,H-MVSNet)。H-MVSNet通过搭建轻量级的特征提取模块,利用改进的门控循环单元(gated recurrent unit,GRU)模块进行正则化,使用列文伯格-马夸尔特法(Levenberg-Marquardt,L-M)层细化深度图,优化了网络模型,减少内存消耗,提升了网络效率,同时H-MVSNet采用了将原始图片序列和预测的粗深度图进行融合的方法,改善了深度图的生成质量,提高了三维重建模型的效果。H-MVSNet在DTU数据集的测试中,生成的三维模型与原模型的精度误差0.327mm,计算一张深度图仅需0.44s,内存消耗低至2.46GB。在Temples and Tanks数据集测试上来看略优于之前的网络。本文对所提出的方法进行定量和定性的评估,实验结果表明,HMVSNet有效地提高了三维重建的精度和准确度,提高了计算效率,能够满足在大规模三维重建的需求,可以有效地提高轻量级神经网络在三维重建应用的质量;通过消融实验,进一步表明该模型在解决内存消耗严重、网络利用率低下的问题上具有更好的效果。
{URL}: https://link.cnki.net/doi/10.27048/d.cnki.ggzsu.2022.000761
{DOI}: 10.27048/d.cnki.ggzsu.2022.000761
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视频语义分割方法研究
{Author}: 庄嘉帆
{Tertiary Author}: 王子磊
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度学习;视频语义分割;光流估计;半监督学习
{Abstract}: 视频语义分割是计算机视觉领域的基础任务,旨在为每帧图像上的像素点进行语义类别标记,从而获取对周围场景的像素级语义解析,在智能交通、自动驾驶等领域具有广泛且迫切的应用需求。不同于图像数据,视频数据一方面蕴含了丰富的时序信息,反映了物体的运动规律,可以为语义分析提供重要先验,但另一方面视频内容往往更加复杂且数据量更大,难以获取完整数据标注,导致模型学习更加困难,实际部署时计算资源消耗巨大。因此,视频语义分割研究在利用视频数据优势的同时也要解决其带来的学习挑战。近年来,深度学习在视频语义分割领域取得了广泛成功,但在实际应用场景中,目前基于深度学习的视频语义分割方法仍然存在不足。根据应用场景的不同,现有方法可以大致分为两大类。针对效率优先场景,现有方法利用光流建模关键帧与当前帧之间的像素级关联,通过特征传播技术复用关键帧特征,避免当前帧的特征提取操作,从而提升计算效率。针对精度优先场景,现有方法同样利用特征传播技术将相邻帧特征对齐至当前帧,然后通过融合多帧特征提升语义分割精度。可见,基于光流的特征传播是现有方法的核心技术。然而,在实际应用场景中,光流难以处理常见的纹理不足、遮挡等情况,容易产生错误结果,导致现有视频语义分割方法会面对以下两点挑战:1)在效率优先场景中,关键帧特征在特征传播过程中会发生扭曲,直接导致分割结果出错;2)在精度优先场景中,错误的光流估计结果会导致相邻多帧特征无法准确对齐,使得特征融合过程中会引入噪声,直接影响特征质量。除了上述两种典型场景,由于标注成本限制,标注稀缺场景在实际应用中也非常普遍,而现有方法通常是基于深度学习技术进行构建的,依赖大量标注视频样本参与训练,因此无法适用于标注稀缺场景,导致大量无标注视频数据无法有效利用,并且模型容易出现过拟合问题,影响模型性能。本文针对这些典型应用场景中存在的关键问题进行了深入研究,结合深度学习技术提出了一系列算法,主要的研究工作及创新点如下:(1)针对效率优先场景中现有方法存在的特征扭曲问题,提出了一种基于扭曲感知的特征矫正方法。该方法利用图像域与特征域共享扭曲模式的特性,从图像域实现对传播特征扭曲区域的准确定位,并利用轻量级模型从当前帧提取必要信息,并对扭曲区域进行针对性矫正。实验结果表明,在不额外引入过多计算量的前提下,该方法的分割精度大幅超过现有方法,尤其是在传播距离较大的情况下。(2)针对精度优先场景中现有方法存在的多帧特征无法准确对齐问题,提出了一种基于时空融合与记忆强化的特征增强方法。该方法从优化多帧特征融合与探索单帧特征强化两个角度入手。一方面,该方法提出了一个基于Transformer的时空融合模块,可以自适应融合不同时空位置的像素特征,避免了容易出错的光流估计过程;另一方面,该方法提出了一个记忆强化模块,从训练样本中保存典型特征(边界特征与类别原型),在推理过程对易错特征进行调整,使其往对应的类别原型方向偏移,提高特征的可判别性。实验结果表明,该方法在不同的基线分割模型上均可以带来显著的分割精度提升。(3)针对标注稀缺场景中现有方法存在的无标注数据无法有效利用与模型过拟合问题,提出了一种基于帧间特征重构的半监督学习方法。该方法利用无标注帧特征对标注帧特征进行重构,并使用单帧语义标注监督重构特征的学习,从而实现为无标注数据间接提供准确语义监督的目的。该方法本质上利用了视频数据的内容相关特性,有效利用无标注视频数据辅助模型训练,缓解模型过拟合问题。实验结果表明,与现有的半监督学习方法相比,该方法可以获得显著的分割精度提升,尤其是在标注样本稀缺的情况下。综上所述,本文对视频语义分割任务进行了深入研究和探索,结合典型应用场景的特点,针对在实际使用过程中存在的难点问题,分别提出了基于深度学习技术的针对性解决方案。相比于现有工作,大量实验表明,本文所提出的方法可以在不同的应用场景中显著提升分割精度,缓解算法对大量标注数据的依赖,有效推动视频语义分割算法的技术落地,具有重要的应用价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.000491
{DOI}: 10.27517/d.cnki.gzkju.2022.000491
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于LabVIEW机器视觉的智能车库系统设计
{Author}: 樊源盛;李微;闫凯达
{Author Address}: 天津理工大学电气工程与自动化学院;
{Journal}: 自动化与仪表
{Year}: 2022
{Volume}: 37
{Issue}: 05
{Pages}: 6-10
{Keywords}: LabVIEW;STM32;嵌入式系统;车牌识别;最短路径规划;智能车库
{Abstract}: 当今“停车慢，停车难”依旧是人们需要解决的难题。为解决此问题，研究了在大型场合中如何对寻找车位的车辆进行智能无人化最短路径的规划与引导。首先参考多类大型场所，建立了贴合实际的车库模型；其次采用了基于LabVIEW的视觉模块，自动对入库车辆进行车牌信息采集与识别；再次编写了以Floyd算法为核心的最短路径规划程序，以及使用了“STM32主控制器-AT89C51单片机”控制系统，控制MAX7219LED点阵、HC-SR04超声波传感器分别进行路径指示和车位检测；最后进行了智能车库模型的实地数据测试和方案优化。为解决“停车慢，停车难”的难题提供了可行的建议。
{ISBN/ISSN}: 1001-9944
{Notes}: 12-1148/TP
{URL}: https://link.cnki.net/doi/10.19557/j.cnki.1001-9944.2022.05.002
{DOI}: 10.19557/j.cnki.1001-9944.2022.05.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CNN的高精度手写体数字识别
{Author}: 李凯鹏;刘刚;李帅;万仁兵
{Author Address}: 江西师范大学;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 10
{Pages}: 67-70+75
{Keywords}: 机器视觉;CNN;手写体数字识别;测试准确率
{Abstract}: 近年来，人工智能和机器学习已成为国内外学者重要研究的领域。基于此，笔者探讨基于卷积神经网络（Convolutional Neural Networks,CNN）的高精度手写体数字识别，并将卷积内核大小、滤波器的数量、池化层的种类以及优化器的类型作为变量，通过改变这些变量做对比实验，检测模型训练和测试的准确率。实验结果表明，当卷积内核设置为3×3，三层卷积层滤波器的数量分别为32、64、128，使用最大池化层，选择Adam作为模型优化器的情况下，网络能够达到100%的训练准确率和99.55%的测试准确率，实现了高精度的手写体数字识别。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxs1cdViubguSchRIz1NF3MB8UQ8mSzSoI2AwYNbjq9lO8tyZtIxT0j4FNDYDMaR9dyvTCE2PyOmvVR3e94_NvfxMQKAzMma4wl2UEZUKmhT8FMJoPnbOb7vf1CZ8GjaigFwFfi1q6zxfM1l8RgtSGSjRwWPjmN6fiZ2mRLVC8Ab9UiNAwYZDPtPYAAWQyA9z0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的皮肤病图像分割与分类研究
{Author}: 陈奕希
{Tertiary Author}: 邝先验
{Publisher}: 江西理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 皮肤癌;深度学习;卷积神经网络;图像分割;图像分类
{Abstract}: 皮肤癌是一种对人们生命安全造成极大威胁的一种癌症,而在皮肤癌中最为致命的黑色素瘤是一种皮肤色素性恶性病变,具有不易发现、死亡率高的特点,对其进行早发现、早治疗就愈显重要。然而在现今诊疗过程中,通常依赖专业医生的临床经验,通过查看病变区域的大小、颜色、纹理等信息进行判断病变种类或者病变区域,这种相对主观的判断在面对多样性的皮肤疾病容易出现误诊现象,对于医疗资源会造成浪费。因此,通过计算机辅助皮肤病诊疗,帮助医生精确判断病变种类以及病变区域就非常重要,也能够使得黑素瘤等严重的皮肤疾病得到更快更专业的治疗,提高患者存活率。基于以上背景,本文基于深度学习对皮肤病图像进行分割与分类的研究,主要内容如下:(1)针对皮肤病图像边界模糊、病变区域大小不一的现象,基于U-Net卷积神经网络进行改进,提出一种皮肤病图像分割算法。将模型中编码结构使用Res Net50网络进行替换,得到带有多层次的语义信息特征层。随后采用不同倍率上采样将其尺寸统一,并在通道维度上联结进行特征融合。将上一步操作的输出经过信息融合模块,改善直接进行卷积操作造成的信息丢失现象,最后通过协同注意力模块筛选更重要特征。经过实验结果表明在ISBI2016黑素瘤病变检测挑战赛的官方数据集中,Jaccard Index分割性能指标达到了87.17%,相比U-Net模型提高了2.37%,并且其他指标也取得了全面超越。(2)针对皮肤病变区域存在毛发遮挡时分割效果不佳现象,设计一种基于双重注意力机制的皮肤病变图像分割网络。首先对图像通过Res Net50网络获得不同尺寸大小的特征层,对所提取特征进行多重特征融合,随后进入编码解码路径再进行多重特征提取,最后通过空间与通道注意力模块得到最终输出。在ISBI2016数据集上进行对比实验以及消融实验,实验结果表明所构建网络对于被毛发等物体遮挡的图像有着优秀分割结果。此外,实验各项指标分别为:准确率96.19%、敏感度93.32%、特异性97.32%、Dice系数93.26%和Jaccard指标87.36%,优于现有模型以及竞赛中所提出的模型算法。(3)针对皮肤病不同种类病变之间相似度高,病变种类易出现错误判断现象,设计一种轻量级皮肤病图像分类网络。网络中采用深度可分离卷积使得模型参数减少,并通过堆叠带有残差结构的瓶颈块加深网络深度。此外对下采样过程进行重新设计,将卷积层与池化层相结合,获得了具有更丰富特征信息的特征层。所提出模型在HAM10000数据集上取得了86.03%的分类准确率,优于现有分类模型,并且模型参数量也具有优势。
{URL}: https://link.cnki.net/doi/10.27176/d.cnki.gnfyc.2022.000184
{DOI}: 10.27176/d.cnki.gnfyc.2022.000184
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 马铃薯外部品质分级方法综述
{Author}: 姜宏;于永波;章翔峰;陈宇彤
{Author Address}: 新疆大学机械工程学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 14
{Pages}: 5519-5527
{Keywords}: 马铃薯;分级;机器视觉;机器学习;深度学习
{Abstract}: 马铃薯的外部品质决定了其附加经济效益，高效准确的外部品质分级可将经济效益最大化。通过梳理马铃薯外部品质分级的现有研究成果，综述了人工分级，机械分级和机器视觉分级的研究进展。重点论述了机器视觉分级方法，按照大小特征、形状特征、缺陷特征3个方面将机器视觉分级方法做出了详细的分类和评述。最后总结了3种方法各自存在的优点和不足，并为机械分级和机器视觉分级提供了新的研究思路。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzp_aarfWvxY0UfE5q3yNWPKOzkCF35yVjBR3026V5OV7TD7a__MqM-MzIDNCSLjt2_M4_rzb7jW6llK6tw9BiYz43O5DVyuQ9ro76sPK1qWVpRYoFNUV4ceNmWSu8YSIp9yfJp3S_VRNlyaykREJX4PpoogmUQjZ8Rl6qwvLsvPl7hvVs96ceIc0UKW3dDqjU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的航拍场景行人检测方法研究
{Author}: 何圆
{Tertiary Author}: 孔令讲;程建
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 行人检测;小目标检测;YOLOv5;特征金字塔;模型轻量化
{Abstract}: 行人检测一直以来都是计算机视觉和视觉目标检测领域的研究热点,其广泛应用于人群计数、智能安防、自动驾驶等应用领域。近年来,以低空无人机视角的行人检测逐渐受到关注,主要得益于无人机拍摄范围广且几乎不受外界干扰的特点。然而无人机的拍摄视角和高度很难保持一致,故航拍场景下的行人检测依然具有诸多挑战,如远距离小目标检测、背景复杂以及运动模糊等。另外,无人机的机身空间小导致其承载的算力有限,这对算法的复杂度也带来了挑战。基于上述背景,针对行人小目标易漏检的难点,开展了航拍场景下行人小目标检测方法研究,并利用剪枝算法对检测模型进行了轻量化处理。本文的主要研究工作如下:(1)针对航拍图像中大量的远距离行人小目标易漏检的问题,本文从多尺度检测的角度出发,添加微小尺度目标预测头改进YOLOv5的检测网络;从分类的角度,采用单标签数据集训练模型;改进后的算法P-YOLOv5能专注于检测航拍场景的行人目标,有效改善了小目标漏检的问题。与基线模型YOLOv5s相比,PYOLOv5算法在单标签的Vis Drone2019数据集上将行人目标的AP50提升了6.3%。(2)针对当前无锚框目标检测方法在行人检测任务中存在准确度不够高,尤其是航拍图像中小尺度行人目标检测性能较差的问题,本文引入多尺度特征融合网络FPN、可变形卷积改进CenterNet算法的特征提取网络,以增强整体网络对小尺度目标的特征提取能力和对形变目标的建模能力;为进一步提高算法定位行人目标的能力,本文还引入空间注意力机制,且在预测分支增加IoU分支以实现预测框的精确回归。在VisDrone2019数据集上,FPN的嵌入将行人目标的检测精确度AP50提高了4.7%;空间注意力机制的加入将行人目标的检测精确度AP50提高了2%。(3)针对无人机设备部署目标检测器时存在算力不足的问题,本文研究了两种轻量化网络模型的方法。首先研究了GhostNet、EfficientNet Lite等轻量级模型,用以替换YOLOv5的骨干网络实现模型轻量化;其次介绍了EagleEye剪枝算法,并用其对第三章改进的P-YOLOv5网络进行了剪枝。EagleEye高效且有竞争力,能将YOLOv5模型的参数量和计算量降低40%,仅牺牲1.2%的精确度。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004683
{DOI}: 10.27005/d.cnki.gdzku.2022.004683
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的采摘机器人目标识别定位研究应用进展
{Author}: 孔翰博;王克强;蔡肯;林钦永;陈楚君
{Author Address}: 仲恺农业工程学院;
{Journal}: 电子技术与软件工程
{Year}: 2022
{Volume}: 
{Issue}: 10
{Pages}: 160-165
{Keywords}: 采摘机器人;特征提取;机器视觉;定位技术
{Abstract}: 本文为解决农业采摘过程中低效等问题，而实际发展应用中却存在诸多的问题和挑战，问题的主要数据来源是实际环境中目标识别和定位的检测精度，稳定性和广泛性。针对这些问题，本文综述了近年来目标识别与定位的研究进展。在特征提取、机器学习、深度学习和多类摄像机及其视觉系统的支持下，在光照、遮挡和风速等不稳定因素中提高检测精度，极大地提高了采摘机器人在实际环境中的适应性和采摘过程的效率。最后总结了采摘机器学习人在进行识别系统定位及自身的应用的挑战及未来的发展研究方向。
{ISBN/ISSN}: 2095-5650
{Notes}: 10-1108/TP
{URL}: https://link.cnki.net/doi/10.20109/j.cnki.etse.2022.10.037
{DOI}: 10.20109/j.cnki.etse.2022.10.037
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度卷积神经网络的智能仓储管理系统研究与应用
{Author}: 祝星馗
{Tertiary Author}: 蒋球伟
{Publisher}: 中国电子科技集团公司电子科学研究院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 仓储管理系统;计算机视觉;图像识别;卷积神经网络;智能化
{Abstract}: 在中国军事现代化程度日益增强的大背景下,军用物资的品种、数量也在日益增多,军事仓库的战略地位也更加的凸显。为了适应现代化战争的需求,仓储管理系统的机械化、自动化与智能化必不可少。当下部队中很多仓库仍旧处于机械化初级阶段,信息化水准低下造成了军队仓库的管理水平相对落后、管理效率难以提升,以及运营成本高的窘境。本文以某部队后勤仓储管理自动化工程为项目背景,根据当前仓储管理工作中面临的问题对客户提出的要求进行了分解,并结合实际情景对整个仓储管理工作过程加以总结,将深度学习算法和仓库管理工作中的各种任务紧密结合促进了仓库管理向智能化发展。本文对深度神经网络算法以及仓储管理系统的各个模块进行了功能的详细设计与实现,主要工作如下:(1)调研了仓储管理领域的发展现状,结合深度学习中的计算机视觉方向目标检测技术对仓储部分功能实现智能化,包括智能盘点、物资识别、人员入库检测、安全监控、烟雾火点检测等功能。以Faster R-CNN、YOLOv5、Swin transformer等最新的深度学习目标检测网络为基础,研发了针对于仓库环境的WOLO目标检测网络。该网络使用了复杂的数据增强操作、transformer模块的注意力机制、大分辨率的特征图检测层、可缩放的网络结构来解决仓库环境下的特殊光照、物资尺寸多变、物资遮挡、各个任务对算法的速度与精度要求不一等问题。(2)使用Pytorch深度学习框架,基于YOLOv5实现了 WOLO目标检测网络,并针对仓库管理中的不同任务,收集使用了 6个不同的数据集对WOLO模型进行训练、测试,对WOLO的不同模块进行消融对比实验。实验证明WOLO对类似仓库环境下的图像检测效果非常优秀,WOLO的每个模块都对其性能提升做出了贡献。(3)通过对用户的软件需求进行条分缕析,本文首先理清了仓库管理系统的功能要求、性能需求;然后对仓库系统进行了系统架构的设计和功能结构的搭建、对管理系统的每个子模块进行流程分析与设计;最后采用B/S模式研发并实现了智能仓储管理系统软件。
{URL}: https://link.cnki.net/doi/10.27728/d.cnki.gdzkx.2022.000068
{DOI}: 10.27728/d.cnki.gdzkx.2022.000068
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在农业中的应用：农田杂草智能识别
{Author}: 梁倍源
{Author Address}: 广西工业职业技术学院;
{Journal}: 中国果树
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 134
{Abstract}: <正>杂草与农作物竞争生长空间及水分、养分资源，是影响作物产量和农产品品质的主要因素。化学除草需要大面积喷洒除草剂，虽然高效但也造成生态污染。随着图像采集处理装置、图像处理技术的迅猛发展，机器视觉在农业的应用领域得以不断扩展。机器视觉的核心技术是图像分析，在精确快速识别田间杂草、保护生态中的作用不可小觑。
{ISBN/ISSN}: 1000-8047
{Notes}: 21-1165/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxwgn1vHKwqEzOVQKLirREV3K9NfOZ9HsAbXQ6F-Jl35uR_2yQFcILLPqggI-IB6oaZt3iBvCkMraJMY-LUv1A5Yb96OFq8Sy3nnn4ZE3mO20WKHheiQDL9rn5-Jqgbywo_3sroyb98MAolA90RToEpeidWoSUY7NBeg8INXMjQ0I4Fy3cvxf3m86UGvNXGLKE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的弱监督图像视觉语义理解方法研究
{Author}: 张哲
{Tertiary Author}: 于哲舟
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 计算机视觉;语义理解;弱监督学习;语义分割;目标检测
{Abstract}: 图像视觉语义理解是图像处理任务中的研究热点。现有基于深度卷积神经网络的图像视觉语义理解方法,往往需要使用大量包含详细目标轮廓的细粒度标注数据。然而,这些详细标注数据的获取需要耗费大量时间和经济成本,限制了图像视觉语义理解方法的性能提升及其在复杂场景下的泛化能力。针对这一问题,研究人员放宽训练数据的标注精度,提出采用图像级标注数据来训练弱监督视觉语义理解模型。然而,图像级标注仅能提供图像中目标的类别,缺少目标位置及轮廓信息,使得弱监督图像视觉语义理解方法在复杂自然场景下的实现成为新的难点。本文主要针对图像视觉语义理解中的语义分割和目标检测两个任务开展深入研究,在图像级标注数据监督下,优化网络结构,实现对目标较为完整的位置轮廓信息挖掘。本文的主要工作和贡献如下:(1)提出基于空洞卷积像素关系的弱监督图像语义分割方法。针对图像级标注数据训练的模型只关注图像中目标判别性区域而导致的像素级伪标签不完整的问题,在分类模型中引入多空洞率的空洞卷积单元以及自注意力机制,在扩大感受野的同时自适应地增强目标区域并抑制其他不相关区域,生成高质量的像素级伪标签,进而训练语义分割模型。实验结果表明,该方法能够有效改善伪标签精度,在PASCAL VOC 2012的验证集和测试集分别达到了65.3%和66.2%交并比的良好性能。(2)提出单阶段注意力引导增强弱监督图像语义分割方法。针对两阶段弱监督语义分割方法导致的模型训练复杂度增加问题,将分类模型与分割模型融合至同一框架,在图像级标注的监督下,以端到端训练的方式直接生成分割图。提出注意力引导模块,以自底向上的方式指导模型学习空间和语义信息。同时,提出上下文注意力模块,捕捉网络模型不同层之间产生的特定类特征图之间的远程上下文依赖关系,自适应地增强对象区域并抑制噪声的产生。实验表明,该方法相比于其他端到端的弱监督语义分割方法在分割准确性上有明显提升,在PASCAL VOC 2012的验证集和测试集分别实现了66.1%和66.3%交并比的分割性能。(3)提出基于候选区域自监督注意力学习的弱监督目标检测方法。在图像级弱监督下,大多数目标检测方法只能检测出图像中的显著目标部分,并且对同一图像不同仿射变换的检测结果不稳定。为解决以上问题,提出自监督注意力学习模块,通过一致性正则化损失减少原始特征注意力图与均衡注意力图之间及其仿射变换产生的注意力图之间的差异。在候选区域选择阶段,自适应选择高置信度目标候选区域作为正例,同时只选择特定类别的目标候选区域作为难负例(Hard Negative),从而促进弱监督检测模型训练。实验结果表明,该方法提出的各个模块对检测小目标以及多个相邻同类别目标等方面的性能均有明显提升,在PASCAL VOC2007和PASCAL VOC 2012数据集上分别获得了54.8%和53.4%的平均精度均值,以及72.6%和71.4%的正确定位率。综上所述,本文针对弱监督图像视觉语义理解中语义分割和目标检测任务展开研究,提出相应的模型和方法,对后续弱监督图像视觉语义理解方法的研究具有一定的理论意义和广泛的应用价值。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.000021
{DOI}: 10.27162/d.cnki.gjlin.2022.000021
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多目标检测与分类算法的研究
{Author}: 程璐飞
{Tertiary Author}: 郭东伟
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;深度学习;自制数据集;注意力机制;垃圾分类
{Abstract}: 近些年随着深度学习的快速发展,各种目标检测相关算法喷涌而出,带动了目标检测在军事、安全、交通等领域的广泛应用。目标检测的关键任务是针对待检测目标的定位和分类。目前应用于人脸识别的目标检测算法的检测精度可以达到99%以上,但是在一些复杂场景和小目标物体的检测精度却不尽如人意。因此对基于深度学习的多目标检测与分类算法的研究,尤其针对一些复杂场景下目标检测相关算法的研究仍具有十分重要的现实意义。目标定位与分类作为目标检测的基本任务,一阶段目标检测算法可将二者当作一个回归问题加以解决,二阶段目标检测算法在一阶段目标检测算法的基础上增加了筛选候选框的过程,在检测精度方面与一阶段目标检测算法相比较高,但是检测速度比较慢,模型稍复杂。本文采用目标检测通用评价指标作为算法优劣的评判标准,对一阶段二阶段目标检测算法在检测复杂场景中的小目标的检测效果进行分析,并开发设计一种针对此种情况的目标检测器。本文的主要研究工作如下:(1)目前学术界暂无合适的包含复杂场景的目标检测数据集,同时响应国家垃圾分类的号召,制作了包含47个类别45910多张图片的生活垃圾数据集TrashSet。基于TrashSet进行复杂场景下目标检测算法的研究与设计。(2)将不同类型的主干特征提取网络与通用目标检测器相融合,并设计消融实验分析比较不同的主干特征提取网络在复杂场景下对小目标的检测效果,探究差异背后的原因和逻辑。(3)将在深度学习领域表现出色的注意力机制添加到主干特征提取网络中,设计消融实验探究通道和空间两个维度的注意力机制在目标检测器中的性能差异,探究注意力机制在目标检测算法中产生效果的深层次原因。(4)解决了一阶段目标检测算法中存在的正负样本不均衡产生的影响损失函数收敛的问题,对目标检测器的损失函数进行修改。Focal Loss函数在BCELoss函数的基础上,添加了类别平衡因子和样本难易区分因子,可以有效解决一阶段目标检测算法中存在的问题。本文将损失函数中的BCELoss函数采用Focal Loss进行替代,设计实验验证此种变换的实验效果。为了验证复杂场景下上述相关目标检测算法改进的有效性,本文基于TrashSet数据集设计了完善的消融实验进行验证。对消融实验结果进行分析,证明了本文设计的目标检测器及进行的算法改进在复杂场景下依然具有很好的检测效果,可以得出本文进行的基于深度学习的多目标检测与分类的算法研究具有一定的学术价值与应用意义。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.002970
{DOI}: 10.27162/d.cnki.gjlin.2022.002970
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的手机屏幕缺陷检测方法研究
{Author}: 张钟磊
{Tertiary Author}: 张晋东
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;图像处理;深度学习;缺陷检测
{Abstract}: 近年来,科技进步和网络普及使得手机用户的数量不断增加,手机屏幕的生产需求量巨大。而手机屏幕缺陷检测作为生产的一个重要环节,其品控和质检问题备受关注。传统的质检方式主要靠质检员用肉眼来识别生产缺陷,不仅效率低下,而且对于一些小型或微型缺陷难以用肉眼辨别。机器视觉的兴起为手机屏幕的缺陷检测提供了新思路,人们将机器视觉相关算法应用到手机屏幕缺陷检测,一定程度上解放了人力,提高了检测效率。然而,机器视觉的应用场景有限,只能应用于低噪声、光照充足的场景中,算法稳定性差且调参量大。随着深度学习理论的快速发展,人们发现深度学习在缺陷检测任务中表现的越来越出色,检测速度快、准确率高,应用场景也更加广泛。因此,本文结合深度学习对手机屏幕缺陷检测方法进行研究,实现一个能够精准识别手机屏幕缺陷以及缺陷种类的算法。本文的主要工作内容如下:(1)本文提出了适合手机屏幕缺陷的改进的手机屏幕整体缺陷检测算法。首先对手机屏幕缺陷图像进行多种图像预处理操作,解决图片本身中存在的噪声、模糊等问题,实现对手机屏幕是否存在缺陷的初步判定。(2)针对本文存在的小样本问题,本文提出了基于滑动窗口算法的改进的图片分割算法;提出了一种基于ACGAN算法的手机屏幕缺陷虚拟样本的生成方法;提出了基于数据增强的方式生成新的缺陷样本方法,对手机屏幕缺陷数据集进行了扩充。(3)基于改进的Faster RCNN和YOLO v5算法,本文提出了适用于手机屏幕缺陷检测的深度学习方法。本文改进了NMS方式和ROI Pooling方式,本文简化了主干网络,并引进了注意力机制,从而达到了对手机屏幕缺陷检测更好的识别效果。本文通过实验验证了提出的基于计算机视觉的手机屏幕缺陷检测方法的效果,实现了对手机屏幕缺陷的初步判断,手机屏幕缺陷种类检测的准确率达到了98%以上,单个缺陷检测耗时0.012s。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.006562
{DOI}: 10.27162/d.cnki.gjlin.2022.006562
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉Transformer的视频动作识别方法研究
{Author}: 景彦豪
{Tertiary Author}: 王峰
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视频动作识别;视觉Transformer;骨骼点动作识别;深度学习
{Abstract}: 视频动作识别是计算机视觉领域中重要的研究内容之一。近年来,基于Transformer的模型已经成为计算机视觉领域的研究重点。基于Transformer的视频动作识别任务依旧面临着严峻的挑战:首先,视频中包含了丰富的信息,光流以及骨骼特征都可以被运用到模型中,如何在Transformer中有效运用这些信息,是目前研究的一个难点;其次,视频模态与自然语言模态有巨大的区别,视频数据建模方式的选择,将在很大程度上影响模型的表现;最后,如何获取视频中的细节信息,过滤掉视频中的冗余信息,进行视频细粒度的动作分类也是一个重要难点。本文结合视觉Transformer技术与双通路卷积神经网络的设计理念,提出了多种模型来研究视频动作识别。本文的主要工作包括:1.提出了融合骨骼特征的视觉Transformer(SF-ViT)的动作识别方法。本文通过Transformer模型的token化手段,完成了视频的RGB输入与骨骼点输入的嵌入,并有效融合RGB与骨骼特征,建立空间-时间Transformer结构来实现视频的动作分类。验证了骨骼数据与RGB融合在Transformer架构中的可行性。2.提出了双通路视觉Transformer(TP-ViT)的动作识别方法。本文创造性地将空间通路一分为二,在不同通路输入不同的视频采样,通过横向连接融合两个通路的特征。利用第二通路来捕获更多时间维度的语义信息,提升了模型的性能表现。3.提出了屏蔽采样与非对称自注意力预训练方法。本文通过屏蔽采样来使第二通路具备细节获取的能力,以完成细粒度动作分类的任务。同时本文通过构建非平衡的图像重建网络对第二通路进行预训练,这种预训练能够与屏蔽采样的方法相适应,在缩短训练时间的同时,提升其正确捕获视频细节的能力。本文的方法在Kinetics和FinGym数据集上完成相关实验。在模型结构优化的过程中,本文提出的方法获得了不断提升的实验表现,取得了优于当前主流方法的实验结果,同时验证了本文方法的有效性。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.003692
{DOI}: 10.27149/d.cnki.ghdsu.2022.003692
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于姿态估计和边缘计算的泳池溺水预警研究
{Author}: 张修念
{Tertiary Author}: 许武军
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 溺水预警;姿态估计;目标检测;深度学习;边缘计算
{Abstract}: 游泳是一项深受大众喜爱的健身运动,但是也一直存在着不容忽视的隐患。目前,泳池溺水事故的频发受到越来越多人的关注和重视。传统的救生员人工监视泳池的方式不仅消耗大量人力,而且容易因为各种不确定因素导致监视效果不好出现疏漏,造成生命与财产的重大损失。因此,开发泳池的智能监控预警系统意义重大。针对上述问题,本论文设计并开发了一种基于边缘计算平台与计算机视觉(CV)的泳池溺水预警系统。通过对游泳者在水下的行为进行监测和识别,实时预测并显示其发生溺水的可能,当达到警戒值时立即发出警报,从而减少泳池溺水事件的发生。本系统的研究具体从以下几个方面展开:首先在系统实现方面,选择了NVIDIA具有机器学习能力的单板计算机(SBC)Jetson Nano作为控制器实现边缘计算,其自带了CUDA、cu DNN、Tensor RT等组件,功耗小且推理效率高。另外增配无线网卡,采用Wi-Fi实现信息的传递,外接摄像头传感器并设计执行器预警模块实现系统的交互与反馈。其次在泳池溺水预测模型上,选择基于计算机视觉相关技术任务进行设计。先利用多人姿态估计算法对图像中的游泳者进行关键点标记恢复人体位姿,降低泳池内环境对人体检测的干扰;之后在其基础上利用深度学习方法完成泳池内的目标检测任务,通过训练大量样本得到理想的检测器模型。对比介绍了三种常见算法生成的检测模型,进行平均精度均值(m AP)和帧频(FPS)的性能分析。选用的目标检测算法通过对姿态估计模型的调用完成姿态标记,可以更好地实现游泳者溺水状态的预测。考虑到系统对于实时性的需求,本论文还对选择的Open Pose姿态估计算法和目标检测算法进行了轻量化的改进,修改其网络结构减少模型参数,并加入面向边缘的卷积块(ECB)和坐标注意力(CA)等模块提高模型性能,使其在边缘计算平台上的实时输出帧率大大提高,成功构建出系统最优溺水检测模型。最后在数据集的获取上,使用防水摄像头采集充足的水下样本,并制作成数据集对模型进行训练和测试。由于训练的时间成本较大,实验选择将复杂的训练部分放在具有24G显存的NVIDIA Tesla M40平台上进行,再将训练好的模型部署到边缘计算平台上实现实时推理,训练及推理均采用Py Torch框架。基于姿态估计和边缘计算的泳池溺水预警系统能够通过水下摄像头采集图像,实时监测游泳者的安全,预测危险行为并发出警报。结果显示,本系统原型对水下溺水行为的推断准确率较高,且在Jetson Nano上的帧率可达6.70fps,当判断为溺水状态时能够自动发出警报,为游泳者安全提供了保障,也为泳池工作人员减轻了负担。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.001659
{DOI}: 10.27012/d.cnki.gdhuu.2022.001659
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的物流分拣系统研发
{Author}: 化云朋
{Tertiary Author}: 宋瑞宏;王维新
{Publisher}: 常州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器学习;手眼标定;工业机器人
{Abstract}: 随着国家提倡智能制造,越来越多的机器人等辅助分拣工具被用到分拣上面。但是大部分用到的机器人还是需要人工示教,并不能充分提高分拣效率和机器人的灵活性。将带有机器视觉的机械手技术,使用在物流分拣任务中会大大提高分检效率。如何让机械手移动到视觉系统识别出物体的位置,并准确抓取是本文主要解决的问题。对于上述问题,本文以VS2019作为开发平台,用LS3-B401S-V1爱普生机械手作设计了一套面向物流行业的小型物流产品的分拣系统。针对基于视觉的机器人分拣系统的工作距离短,工作视野大的特点,选用的LS3-B401S-V1爱普生机械手、海康的MV-CE050-31GM的相机,海康的MVL-MF3528M-8MP的镜头。构建了带有机器视觉功能的分拣平台。针对目标的定位问题,提出了手眼标定算法,使用规格7乘7的标定板。标定板的直径是1.875mm,左上角有一个三角区,是用来标识标定板的方向。标定板的厚度是1mm,利用机器人末端的移动让相机在不同的13个位置拍照,利用Halcon软件对图像进行处理并创建姿态和得到描述文件的内参和和外参。对于机器视觉软件的开发问题,使用Halcon和C#共同开发上位机端的程序,实现了对目标的定位,分类等问题。使用RC+7.0开发机器人和上位机通讯程序,实现了上位机与机器人之间的通讯。可以进行收发数据,同时编写了机器人的控制程序,实现机器人的运动控制。最后在搭建的分拣平台上放置不同形状的目标,启动软件并完成基于机器视觉的自动分拣实验。
{URL}: https://link.cnki.net/doi/10.27739/d.cnki.gjsgy.2022.000426
{DOI}: 10.27739/d.cnki.gjsgy.2022.000426
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的农作物产量品质监测及模型可解释性研究
{Author}: 陈博謇
{Tertiary Author}: 魏凯华
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;注意力机制;作物分类;目标检测;模型可解释性
{Abstract}: 我国作为农业大国,如何提高作物产量和品质一直是我国农业生产中的重点难点问题之一。高效准确的作物监测方法是实现绿色可持续植保的重要基础,也是近年来的热点课题。虽然传统机器学习方法在多种农业场景中实现了对农产品的自动监测,但在特征选择上依旧需要人为干预,并且需要在不同农业场景下对模型进行较大的调整,导致检测和识别效率低下。随着深度学习技术和计算机设备的快速发展,深度学习技术以效率高、泛化性强以及鲁棒性好等特点被广泛应用于作物监测及病虫害识别等众多农业领域。尽管深度学习技术在作物识别与检测方面都取得了较好的效果,并且在作物产量和品质检测方面也越来越受到重视,但依旧面临着诸多挑战。如在深度学习模型的训练过程中,学者们通常只是对农产品简单拍摄,而在图像采集过程中忽略了作物本身的特性;模型针对农业小目标检测的能力有待提高;深度学习模型虽然优点众多,但模型的黑盒特性,导致农学研究者对其内部的运行机制了解不足。针对上述问题,本文首先利用荧光检测技术,以VGG和Res Net模型为基础,提取了西湖龙井、毛峰等5种知名茶叶的叶绿素荧光特征,最终获得95%的最佳茶叶分类准确率。进一步分析荧光、白光以及单通道图像分类结果,证实了结合深度学习分类模型的荧光检测技术确实有助于提升模型性能,提高茶叶分类的准确率,从而降低人工分类成本,缓解茶叶市场以次充好的现象。此外,虫害精准检测对于作物产量和品质监测至关重要,有效的虫害检测模型可以辅助农业生产中的虫害预防工作,并对作物产量品质提升具有重要指导作用。因此,我们以作物生长过程中收集的虫害数据为研究对象,研究了基于注意力机制的虫害检测模型。以YOLOv5模型为基础,引入多种注意力模块和Transformer模型对YOLOv5模型进行改进,最终模型的最高m AP达到51.2%,并且在虫害的预测类别分数以及小目标虫害检测方面都得到较大提升。最终得到高精度虫害检测的Swin-YOLOv5模型,以及快速虫害检测场景的New＿YOLO＿CBAM模型。该研究对于指导虫灾的精准判断、虫灾的预警与防治以及提高作物产量和品质等农业工作具有重要意义。针对目前深度学习在农业应用中的黑盒现象,以水果病害叶片为研究对象,设计了三组分类实验,利用VGG和Res Net模型进行分类,Res Net模型明显更好,其准确率分别是99.11%、99.40%、99.89%。随后在Res Net分类模型中应用CBAM模块提高模型的特征提取能力,并通过Grad CAM可解释性算法对结果进行分析,证实了模型在不同分类任务中对特征关注点不同,并且Res Net50-CBAM模型和Grad CAM算法相结合所呈现的结果更易于人们理解,使得模型可解释性更强。可解释性算法有利于提高模型的透明度和可信度,帮助农业学者更好的理解模型内部运行机制,从而提高学者对现代化计算机视觉技术的快速应用与扩展。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.000821
{DOI}: 10.27075/d.cnki.ghzdc.2022.000821
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的道路安全头盔佩戴检测算法研究
{Author}: 胡光喆
{Tertiary Author}: 孙伟
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;安全头盔佩戴检测;图像处理;YOLOv5
{Abstract}: 国内城市道路交通路网的建设和布局不断完善,极大地丰富了人们的出行方式,电动车因其优越的通勤便利性,在出行方式中占有较大比重。2020年6月,公安部发布“一盔一带”政策,将对未佩戴安全头盔的骑行人员做出处罚。因此对骑行人员安全头盔佩戴进行自动化和智能化检测,对于提高道路安全头盔佩戴监管效率,减轻现场交管人员的工作强度具有重要意义。本文以城市道路中骑行人员为对象,展开基于深度学习的安全头盔佩戴检测研究,主要研究内容如下:(1)针对安全头盔佩戴检测数据集缺失问题,本文提出了基于图像增强和类别重组法的数据集构建方法。首先,基于道路场景采集以电动车骑行人员为对象的数据集原始图像。其次,为了提高安全头盔佩戴检测数据集多样性及模型泛化能力,提出在数据集中加入色彩抖动、随机抠取等图像增强方法。此外,针对数据集中佩戴安全头盔和未佩戴安全头盔两类样本数量相差较大问题,提出以类别重组法对样本数量进行平衡。最后,根据安全头盔佩戴情况对图像进行标注,并按照8:2将数据集划分为训练集和测试集,最终构建成稳定有效的安全头盔佩戴检测数据集。实验结果表明,本文安全头盔佩戴检测数据集能够有效提升模型的检测精度,较好的完成安全头盔佩戴检测任务。(2)针对YOLOv5s算法对数据集中部分目标检测精度不高、检测效果较差等问题,本文提出了基于多尺度特征融合和注意力机制的优化算法。首先,通过衡量安全头盔佩戴检测难度,选用YOLOv5s作为本文检测任务的基准网络模型。其次,针对图像中小目标较难检测问题,提出在多尺度特征融合部分增加小目标特征检测层,提高对小目标的特征提取能力;然后,为了获取图像中关键特征,提高模型整体特征提取能力,提出在网络模型中融合CA注意力机制;最后,针对上述优化方法带来的模型复杂度增加问题,提出用Ghost模型压缩模块降低模型复杂度,提高算法推理速度。实验表明,本文的优化模型能够快速、有效实现安全头盔佩戴检测。(3)针对安全头盔佩戴人工查检效率低、工作区域大等问题,本文开发了基于道路监控的安全头盔佩戴检测系统。该系统主要实现了图像检测、实时视频检测、监控点切换以及违规记录查询等功能。此外为了防止目标误检以及使检测系统适用不同道路场景,在系统中嵌入了ROI区域调整功能,通过ROI区域调整,能够对图像、视频中的任一区域实现特定区域检测。该系统的开发有效提升了安全头盔佩戴检测的自动化水平,为道路交通智能化和数字化监管奠定了基础。本文中包含图73幅,表8个,参考文献81篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000199
{DOI}: 10.27623/d.cnki.gzkyu.2022.000199
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人脸识别的智能猫眼系统的研究
{Author}: 林华
{Tertiary Author}: 谭安辉
{Publisher}: 浙江海洋大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智能猫眼;机器视觉;主成分分析(PCA);人脸识别
{Abstract}: 随着社会的不断发展,人们对居家安全方面的问题不断重视,各种智能门禁系统、居家安防设备等智能化软硬件设备的应用也越来越广。近年来利用传统猫眼进行开锁、用专门的设备通过猫眼对屋内情况进行反窥等不安全事件的频繁反生,加上传统猫眼功能单一,传统猫眼已逐渐被具有人脸识别功能的智能猫眼所取代。智能猫眼由于设备体积普遍较小,硬件能力有限,各种复杂的神经网络模型的算法无法很好地在这样的硬件设备上运行。而且目前市面上大多数该类型的智能猫眼设备基本都采用基于Web端的应用接口或者通过软件开发相应工具包的方式来实现人脸识别的功能,导致相关应用只能以外部调用的方式运行,不能进行内部优化提升。同时,楼道的光线等环境因素也会大大影响到人脸识别的准确性。针对上述情况,本文主要通过对硬件和软件进行优化来改善和解决以下几个主要问题:1.设备硬件性能和人脸识别算法相适应、匹配的问题;2.人脸训练样本问题;3.灯光等环境因素影响人脸识别准确性的问题。根据系统的需求,在硬件和软件方面提出相应的方案,并进行针对性的优化提升,其中硬件部分以基于全志A64主控芯片的开发板为基础,针对不同的功能模块进行原理图及PCB设计,并且进行调试。整个系统软件部分的功能则通过Open CV来完成。在人脸检测方面,重点研究了人脸Haar特征和Adaboost级联分类器的原理,以及训练级联分类器的原理,运用基于人脸Haar特征的Adaboost级联分类器完成了人脸与人眼的检测定位功能。最后设计了基于主成分分析(PCA)的人脸识别模型,并且通过对获取的人脸图像进行预处理以及后期的人脸验证,提高了人脸识别的准确率。
{URL}: https://link.cnki.net/doi/10.27747/d.cnki.gzjhy.2022.000358
{DOI}: 10.27747/d.cnki.gzjhy.2022.000358
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的三维重建技术研究
{Author}: 武小凯
{Tertiary Author}: 任晶秋;褚立
{Publisher}: 东北石油大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目立体视觉;相机标定;立体匹配;SIFT;区域生长
{Abstract}: 随着计算机视觉的快速发展,三维重建技术在视觉导航、医学影像、文物修复、工业检测等多个领域内得到了广泛的应用。其中,基于双目视觉的三维重建具有设备简单、精度合适、价格低廉等优点,使其成为了新的研究热点。本文主要针对双目立体视觉三维重建技术中的摄像机标定、立体校正、立体匹配、三维重建等问题进行研究。本文主要工作内容如下:本文首先分析了双目立体视觉的两种结构模型以及获取空间点三维坐标的基本原理,确定选用双目平行结构模型作为本文研究对象。采用张正友平面标定法对双目摄像机进行标定,并根据获得的摄像机参数信息对双目摄像机进行立体标定与立体校正。接着深入研究了Harris算法和SIFT算法的基本原理。针对SIFT算法计算复杂,运行时间长,存在误匹配等情况,对SIFT算法进行了一定的改进:使用多尺度Harris算法提取的特征点作为本文特征点,并对特征点生成96维特征向量描述符;采用BBF原则改进的K-D树寻找匹配点的最近邻,并采用最近邻与次近邻的比值作为匹配依据;为了降低误匹配率,本文采用双向匹配策略与RANSAC算法等措施对匹配对进行筛选。实验证明,本文改进算法在匹配精度与匹配速度上均有所提升。然后采用改进SIFT算法与区域生长相结合的立体匹配算法,以改进SIFT算法所提取的高质量特征点对作为区域生长的初始种子点,以NCC作为相似性测量进行区域生长策略,得到稠密的视差图。经过实验证明,本文算法保证精度的同时,有效提升了匹配速度。最后,通过本文立体匹配算法得到的视差图和摄像机标定得到的参数信息,实现了对现实场景的三维重建,证明了本文算法的有效性。
{URL}: https://link.cnki.net/doi/10.26995/d.cnki.gdqsc.2022.000570
{DOI}: 10.26995/d.cnki.gdqsc.2022.000570
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于树莓派的道路病害检测识别算法研究与应用
{Author}: 陈学仕
{Tertiary Author}: 漆为民
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 道路病害;深度学习;目标检测;YOLOv5-RepVGG;树莓派
{Abstract}: 随着家用车越来越多,城市道路越来越拥挤,而且道路常年高负载工作,这样会造成道路路面的损害,出现各种道路病害。交通部门要快速检测到这些道路病害,并要及时对其进行养护,不然更加会造成人们出行交通不便利,容易造成交通事故。早期道路病害仅仅针对路面裂缝和路面凹坑为主。随着交通运输量的增大,路面指引标志成为人们遵守交通规则和安全行驶的重要一部分。因此,路面指标污损也是新的道路病害,需要及时进行处理,安全指引人们在城市道路上驾车行驶。传统路面保养是人工检测方法,交通检查人员定期检查路面,发现了道路病害才会对路面进行修补,这样方法不及时,效率低,道路保养成本高,并且交通部门已经无法承担起这么大的工作量。研发人员开始研究机器视觉方法,对道路病害图片进行检测识别,经过一些年发展,减轻了公路定期检查人员的工作量,但是机器视觉方法存在易受环境条件影响识别效率低,检测道路病害类别少,成本高。因此,道路病害识别检测仍是一个实际工程问题。本文利用人工智能深度学习方法,通过计算机视觉技术对道路病害进行识别检测,对道路病害的精确度和速度进行算法研究设计,实现在对道路病害检测达到实时性。针对当前交通部门的需要,该道路病害识别检测系统可以实现对城市道路路面情况实时处理,检测并识别其中的道路病害,并按不同的道路病害发送相应的警告,并要求该系统可以部署在机动车行车记录仪、路面监控摄像头等上,通过车联网技术和通信技术上传云平台,这样极大减轻公路检查人员的工作量,也极大节约了成本,更能够及时对道路进行保养,减少交通安全事故的发生。道路病害检测识别系统,主要研究内容如下:(1)深度学习计算机视觉最关键的是数据集的来源,本文是在城市道路上拍摄视频,然后提取图片,之后对图片进行一次初步筛选,从而获得包含道路病害的图片。在有用图片上在进行数据增强操作。在这些数据集使用labelimg标注工具进行标注。完成了全部数据集的采集,共2400张图片。将这些数据按照8:2分成训练集,验证集用于网络的训练。(2)深度学习目标检测算法发展已有十年时间,主要分为单阶段目标检测方法和双阶段目标检测方法。分析了两种目标检测方法的原理结构和各自优缺点。本文采用算法是基于YOLOv5s的目标检测方法对道路病害进行识别定位。(3)通过对YOLOv5s的主干特征提取网络和特征融合部分进行了改进,命名为YOLOv5-RepVGG模型。实际结果表明,YOLOv5-RepVGG模型在召回率、所有类别标签的平均精确率(m AP)都要优于YOLOv5s算法。基于YOLOv5s的轻量级网络在在召回率、所有类别标签的平均精确率(m AP)要远远低于YOLOv5-RepVGG模型,在训练时间上好于YOLOv5-RepVGG模型。(4)基于YOLOv5s的轻量级网络相比较YOLOv5-RepVGG模型在训练时间上检测网络是有着速度优势,但是YOLOv5-RepVGG模型进一步减少了参数量和计算量,提高了道路病害检测系统推理时的计算效率。(5)本文基于Pytorch深度学习框架将YOLOv5-RepVGG网络模型训练出的权重部署到树莓派嵌入式中。首先需要将由Pytorch模型生成的pt格式先转成onnx格式,再由onnx格式转成OpenVINO格式(OpenVINO格式模型可以英特尔二代神经计算棒进行加速),部署在树莓派嵌入式平台,其次通过python程序或者C++程序使用OpenVINO格式的模型权重对图片或者视频进行推理进行速度测试,结果显示算法可以达到23.81FPS的处理速度,满足实时性要求。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2022.000180
{DOI}: 10.27800/d.cnki.gjhdx.2022.000180
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习框架在计算机视觉领域的应用
{Author}: 杜宇宁;刘其文
{Author Address}: 百度深度学习技术平台部;
{Journal}: 中国安防
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 34-40
{Abstract}: <正>一、引言近些年,人工智能作为新一轮科技革命和产业变革的重要驱动力量,在加速传统产业升级和促进新兴产业发展中发挥着越来越重要的作用。深度学习是这一次人工智能浪潮的核心技术,得益于硬件芯片和软件算法的高速发展,深度学习在产业应用方面取得了突飞猛进的进展。
{ISBN/ISSN}: 1673-7873
{Notes}: 11-5538/TU
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzVsr2dUTePmy3YnKK1iHbTASb7KwB32L__ZEDlIMTxLfWvT2XdHxxDzwazyOTl8LwacbW5yPo2y79HFzphHKhbNupshsELGZkkRtGXv_YMJ0EHXEPp3j_jxWtStedvzVn35Dm1WutcNFKOgmjLRXqpmQ7f6LbguqBO5KEbXaylwa2EL7f6NZhGMdBhtJj5ARA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的X射线管道焊缝气孔缺陷检测技术研究
{Author}: 欧阳昌青
{Tertiary Author}: 方黎勇
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: X射线;缺陷检测;LSTM网络;YOLO网络
{Abstract}: 管道的安全性能与其焊缝质量密切相关,从家用燃气管道到战略能源管道,焊接缺陷可能会引发管道爆炸,造成严重经济损失甚至人员伤亡。因此,必须对焊缝缺陷进行严格的检查。X射线检测具有准确、直观、无损等特性,是目前应用最为广泛的焊缝无损检测方法之一。但X射线检测结果目前主要依赖于人工评片,人工评片具有操作繁琐、工作强度大、检测结果不一致等缺点。而现有的缺陷自动化检测算法则普遍存在精度低、速度慢等问题,且大量阈值参数依赖于手工选取,智能化程度相对较低。针对上述问题,为提高焊接缺陷检测质量与自动化水平,提出了基于深度学习的X射线焊接缺陷检测算法,主要工作如下:(1)提出了一种基于LSTM网络的焊缝区域定位方法,根据焊缝成像特点,构造Intensive曲线将二维问题降维成一维序列问题,通过LSTM网络从序列中学习焊缝边界特征,实现焊缝区域定位,进而将检测范围大幅缩小,提升了233%的计算速度。(2)提出了一种基于YOLO改进的缺陷目标检测算法,基于残差学习策略重新设计了前级特征提取网络以保证实时检测速度;优化了用于引导网络参数训练的损失函数,降低了计算复杂度并提升了缺陷检测精度。(3)设计并实现了焊缝缺陷自动化检测原型系统,使工作人员可以通过客户端图形界面,借助服务器的强大算力,通过云计算快速获得焊接缺陷检测结果并可视化显示,提高了X射线像片的评估效率。为验证检测效果,构建了一个包含1200张X射线检测图片的实验数据集,经实验,本文提出的算法缺陷召回率为99.3%,单张图像平均检测时间为32毫秒,能够满足精度和效率的检测要求。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000864
{DOI}: 10.27005/d.cnki.gdzku.2022.000864
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的驾驶员疲劳状态检测预警技术
{Author}: 王红君;白浩;赵辉;岳有军
{Author Address}: 天津理工大学电气电子工程学院;天津农学院工程技术学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 12
{Pages}: 4887-4894
{Keywords}: 计算机视觉;疲劳检测;perclos值;人脸检测
{Abstract}: 疲劳驾驶是造成交通事故的主要原因之一，为提高驾驶员疲劳驾驶状态的智能化检测水平，提出一种基于计算机视觉的面部多特征疲劳驾驶检测算法，采用多线程优化后的Dlib(图像处理开源库)实现对驾驶员面部的定位与追踪，利用Dlib开源库中的人脸关键点检测器对驾驶员面部关键特征点进行提取，实时计算驾驶员眼部的纵横比和嘴部长宽比，并以视频流数据集作为实验样本计算出相关阈值，有效提高了检测算法的普适性，在此基础上，计算出眨眼频率、闭眼次数、眼睛闭合时间百分比以及打哈欠频率这4个反映驾驶员疲劳状态的指标，并利用数学方法进行指标实时融合，根据融合指标的数值对驾驶员疲劳状态进行分级，最终通过实验验证该疲劳检测系统的准确性。结果表明：所提出的综合疲劳指标能够准确反映在不同环境和光照下驾驶员的疲劳状态和发展趋势，驾驶员疲劳判定的正确率达到97.5%以上。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxyknY1Pn8P1AjnoKhI-LkZsAbgDYHU7BdWMO2XeDD4c4UAFnvy0wYSG8QWcTUb9PcdgVT26qzBNOy7akG7ZceWbblR2TUkoTjG8dCqLZH9Dl2Xqwn17eW5ADKcNxzLo0WifwdcQ34IkKW2dIp1IIZozlFzSRX84OaMqNDlSjyocvr8hX3ZDPeSjDge4jQB3zQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能垃圾分类实验平台设计
{Author}: 李祺;曾明;卢向哲;聂为之
{Author Address}: 天津大学电气自动化与信息工程学院;天津大学电气工程与自动化国家级虚拟仿真实验教学中心;
{Journal}: 实验室研究与探索
{Year}: 2022
{Volume}: 41
{Issue}: 04
{Pages}: 68-73
{Keywords}: 垃圾分类;迁移学习;图像数据集;智能垃圾桶
{Abstract}: 针对前端垃圾分类采集的需求，研发了基于机器视觉的智能垃圾分类实验平台。该平台使用“视觉检测与智能桶分离”及“桶盖与桶身分离”的机构设计，采用树莓派CM4、STM32F103控制板及云平台组建云边协同的控制系统。通过构建大规模单物品垃圾图像数据集GarbageNet,设计基于深度跨连接网络的垃圾分类算法，实验平台对10大类垃圾识别率达97.2%。同时，面向实验教学需求，开发了通用图像分类模型实验架构，并设计了基于迁移学习的实验内容，在实验教学过程中取得良好成效。
{ISBN/ISSN}: 1006-7167
{Notes}: 31-1707/T
{URL}: https://link.cnki.net/doi/10.19927/j.cnki.syyt.2022.04.014
{DOI}: 10.19927/j.cnki.syyt.2022.04.014
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 大田甘蓝作物行识别与对行喷雾控制系统设计与试验
{Author}: 韩长杰;郑康;赵学观;郑申玉;付豪;翟长远
{Author Address}: 新疆农业大学机电工程学院;北京市农林科学院智能装备技术研究中心;国家农业智能装备工程技术研究中心;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: 06
{Pages}: 89-101
{Keywords}: 大田甘蓝;机器视觉;精准施药;作物行识别;轨迹追踪
{Abstract}: 对行喷雾技术可提高农药的利用率，有利于保护环境和减少农药残留。本文搭建基于机器视觉的大田甘蓝对行喷雾控制系统。通过改进的ExG算法提取颜色信息，采用最大类间方差法和形态学的开闭运算分割作物与背景。提出甘蓝作物行定位与多作物行自适应ROI提取方法，在条带分割的ROI内基于限定阈值垂直投影对特征点集进行采集，通过最小二乘法对特征点集进行线性拟合得到作物行中心线。利用中心线几何关系得到作物行偏移信息，根据对行机构的运动特性建立对行偏移补偿模型，并设计基于PID轨迹追踪算法的对行喷雾控制系统。试验结果表明，实验室作物行识别准确率为95.75%,算法平均耗时为77 ms。在田间试验中，识别算法在时间段09:00—11:00、14:00—16:00内测试效果最佳，识别偏差均值保持在2.32 cm以下。针对不同范围的杂草测试中，算法平均识别成功率为95.56%,说明算法具有较强的鲁棒性。在与其他识别算法对比测试中，本文算法平均耗时最短，识别成功率最高，能够为实时作业提供视觉引导。在对行喷雾控制系统田间试验中，对行准确率达到93.33%,对行控制算法可将对行偏差控制在1.54 cm,满足田间实际应用要求。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20220422.1345.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 浅谈机器视觉在数据中心发展应用
{Author}: 尹航
{Author Address}: 中国电子工程设计院有限公司;
{Journal}: 智能建筑与智慧城市
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 18-20
{Keywords}: 人工智能;机器视觉;图像识别
{Abstract}: 机器视觉作为人工智能中的一个重要分支，在科技、医疗、军工等各个方面有着显著应用。文章从机器视觉发展历程入手，结合人工智能时代机器视觉应用的现状，总结机器视觉的应用趋势，展望图像识别智能技术在数据中心的应用。
{ISBN/ISSN}: 2096-1405
{Notes}: 10-1392/TU
{URL}: https://link.cnki.net/doi/10.13655/j.cnki.ibci.2022.04.004
{DOI}: 10.13655/j.cnki.ibci.2022.04.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金银花图像识别处理算法研究
{Author}: 郑如新;孙青云;肖国栋
{Author Address}: 南京林业大学机械电子工程学院;天津微深科技有限公司;
{Journal}: 中国农机化学报
{Year}: 2022
{Volume}: 43
{Issue}: 04
{Pages}: 153-159
{Keywords}: 机器视觉;图像处理;金银花识别;Canny算法;边缘检测
{Abstract}: 运用机器视觉和图像处理的方法可实现金银花的自动化采摘，提高采摘效率。首先通过摄像机对金银花进行图像采集，将采集到的金银花图像进行中值滤波处理，有效消除图中的噪音；然后对金银花图像进行RGB和HSV颜色分割，找出金银花与背景区分最明显的分量B;再对分量B进行阈值分割处理，设定阈值，将金银花从背景中提取出来，运用形态学运算，使图像更加饱满；最后运用Canny算法，对金银花图像进行边缘检测研究，通过对Canny算法进行改进，使之达到更好的边缘检测效果。结果表明：通过阈值分割的金银花识别率为79.17%,传统Canny算法识别率为66.67%,改进的Canny算法识别率为93.75%,能够满足后续金银花采摘机器人的实时作业要求。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2022.04.022
{DOI}: 10.13733/j.jcam.issn.2095-5553.2022.04.022
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Two-Stage的目标检测算法综述
{Author}: 王彦雅
{Author Address}: 河北经贸大学信息技术学院;
{Journal}: 河北省科学院学报
{Year}: 2022
{Volume}: 39
{Issue}: 02
{Pages}: 14-22
{Keywords}: R-CNN;计算机视觉;卷积神经网络;深度学习;Two-stage;目标检测
{Abstract}: 近年来，深度学习领域出现了许多优秀的算法，特别是Two-Stage（两阶段）目标检测模型R-CNN(Region-CNN)的产生，基本取代了传统目标检测算法，极大地提高了检测模型的综合性能。本文详细介绍了目前流行的Two-Stage算法，并对它们的流程、特点、效率以及优缺点等方面进行了综述，最后对目标检测领域存在的问题以及未来研究方向提出了建议。
{ISBN/ISSN}: 1001-9383
{Notes}: 13-1081/N
{URL}: https://link.cnki.net/doi/10.16191/j.cnki.hbkx.2022.02.003
{DOI}: 10.16191/j.cnki.hbkx.2022.02.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CNN与Transformer的无人机图像目标检测研究
{Author}: 祝星馗;蒋球伟
{Author Address}: 华北计算技术研究所系统七部;
{Journal}: 武汉理工大学学报(信息与管理工程版)
{Year}: 2022
{Volume}: 44
{Issue}: 02
{Pages}: 323-331
{Keywords}: 深度学习;无人机图像检测;卷积神经网络;目标检测算法;计算机视觉
{Abstract}: 针对无人机航拍图像中存在的密集目标、背景复杂、小目标检测困难、图像尺寸大等问题，提出了卷积神经网络(CNN)与Transformer相结合的无人机图像目标检测算法。该算法在YOLOv5网络的基础上结合了Transformer结构打破了CNN感受野的局限性，凭借自注意力机制捕获全局的依赖关系。同时采用了大尺度的特征图，使用加权双向特征金字塔网络(BiFPN)增强了特征的传播与重用，让网络对小目标的检测能力大大提高。最后使用数据降维与滑动窗口的方法减少网络的内存消耗与计算量。在VisDrone无人机数据集上的实验结果表明所提算法在满足实时性的基础上，平均精确率比YOLOv5网络提高约7%,达到了最先进的42.48%,展现了模型对无人机图像的优秀检测性能。
{ISBN/ISSN}: 2095-3852
{Notes}: 42-1825/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw4Neg7-kbRT06IKqhJYkqOQb4M9hitiGsPktM_CPIUjhAR1-_a7REjHW9ympiYxnWNzcjhL94fdDfXUaZPb-ZcAOKC67f0q6c9QGCScGwB8F5Rk-n8owZkd5jo2q6a3ahW6PuEe8rbps-8OhF6WDe9kHjxOdonCchPdu4eZ1G956ZVPcK-dUXvCGu-quXwxLc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的施工危险区人员入侵识别研究
{Author}: 李瑛
{Tertiary Author}: 巨永锋
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;施工安全管理;机械识别;注意力机制;YOLOv5;单目测距
{Abstract}: 随着我国交通建设的快速发展,道路维修、桥梁维护和隧道监测等施工规模不断壮大,随之而来的安全事故频繁发生,其中不符合安全要求的人员入侵到施工危险区域而引发的安全事故占比较高,此类事故的发生不仅对生命安全构成极大威胁,还会严重影响相关企业的经济效益。本文将计算机视觉技术应用到施工安全管理中,分别提出施工区域危险目标识别和危险距离检测的方法,让施工区域在无人值守或安全警示设施发生故障的状况下,及时对未安全着装和接近危险源的人员做出安全提示,以免发生不必要的人员伤亡。主要研究内容如下:(1)为了更精准地识别出施工现场未安全着装的人员和施工机械这两类危险目标。首先,采用一种基于PCA三通道色彩抖动方式丰富样本数据,其次,将自适应注意力机制引入到YOLOv5检测算法中,引导模型更好地聚焦于人员目标与机械目标的通道特征,同时采用混合精度训练、改变非极大值抑制、Warmup预热和余弦退火调整学习率等方式对YOLOv5的训练效率和测试精度做出进一步优化。最后,结合自建数据集训练并测试改进的YOLOv5检测模型,实验结果表明,改进后的算法对比原始算法,平均精确率和召回率都有所提高,在施工密集场景及小目标场景中均有较强的泛化能力。(2)为了更准确地完成施工现场人员和机械危险源间的深度距离判别,对单目相机目标测距方式进行研究。针对传统相机标定过程繁琐及抗干扰性差的缺陷,提出一种基于生长棋盘格角点检测的修正方案,该方案通过设定角点原型求得卷积响应、Mean Shift寻找局部最大值、精细化处理亚像素角点信息、优化能量级函数等方式实现一步式标定,能满足实时性要求的同时提高标定精度。根据相机标定参数和成像机理,建立了相对完整的单目视觉危险距离判别模式,并通过实验证明了测距模型的有效性。(3)为了更直观地展示对危险目标的预警效果,针对交通工程施工中易造成机械伤害的动态危险区域,总结出一套划分规则,并结合不同类型施工人员和机械间的深度距离,判断人员的安全状态,最终通过Py Qt5设计GUI交互界面,对施工危险区域人员入侵识别预警进行系统验证。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2022.001462
{DOI}: 10.26976/d.cnki.gchau.2022.001462
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智能医疗领域标准发展分析
{Author}: 张虹;周航;马玉骁
{Author Address}: 中国电子技术标准化研究院;
{Journal}: 信息技术与标准化
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 49-55
{Keywords}: 智能医疗;标准化;医用机器人;计算机视觉;超高清视频;触控率专利
{Abstract}: 介绍了智能医疗涉及的主要技术领域，并通过医用机器人、计算机视觉、超高清视频、触控屏4个主要技术领域的研究案例，对其国际国内标准发展现状的分析，提出在智能医疗领域要在标准和专利两方面同时加大研发投入，抢占标准制定的制高点，不断推进创新驱动，为促进产业发展贡献标准化价值。
{ISBN/ISSN}: 1671-539X
{Notes}: 11-4753/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy9hfTEWfP36bOYkh-J8ovNYvOOYRyn3anjelWVlce7duYM3HIZQtgcFnedMqvvs61MU4-ijxI0REayn8G85t4kXWc4qQPxCCS0VwEjfwyaUm5yPJfJwZdFwmff3JleWVr--L15huD-nPYDBmqV3TIWmx1eSxBI0k8Mnds7cBENebw54svGN1ZLIewW4AkWY7U=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合注意力机制的个体猪脸识别
{Author}: 谢秋菊;吴梦茹;包军;尹辉;刘洪贵;李欣;郑萍;刘文洋;陈刚
{Author Address}: 东北农业大学电气与信息学院;农业农村部生猪养殖设施工程重点实验室;东北农业大学动物科技学院;朝阳市建平县畜牧技术推广总站;朝阳市凌源市种畜场;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 07
{Pages}: 180-188
{Keywords}: 机器视觉;图像处理;注意力机制;猪脸识别;DenseNet
{Abstract}: 随着机器视觉技术的发展，猪脸识别作为猪只个体识别方法之一受到广泛关注。为了探索非接触式的猪只个体精准识别，该研究通过深度学习模型DenseNet融合CBAM(ConvolutionalBlockAttentionModule)，建立改进的DenseNet-CBAM模型对猪脸进行识别。将DenseNet121模型进行精简，然后将CBAM注意力模块嵌入到精简的DenseNet121分类网络之前，以加强对关键特征的提取，实现猪脸图像的分类。以随机采集的1 195张猪脸图像作为数据集对本文模型进行测试。结果表明，DenseNet-CBAM模型对个体猪脸识别的准确率达到99.25%，模型参数量仅为DenseNet121的1/10；与ResNet50、GoogLeNet和MobileNet模型相比，DenseNet-CBAM的识别准确率分别提高了2.18、3.60和23.94个百分点。研究结果可为智能化养殖过程非接触式个体识别提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwFDTwGqw0o5fVCxHBeVWoYKysbzuQJphdLXG1K_IN9OjG9Zh1bw6N6O38wtOQZpTXKkWyR3U-3GCabh1x1S-JN06LwRzqqOfntLgOrVlbv4yzb-K4W_quAhrHcb9D1V00AoH3EBwfaO0Zy-3tdKu2eePGvlee8n2EEzZ8GYMUwoY8cgGK8ZZC4pUUW2h91_e4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的复杂背景人行桥振动识别
{Author}: 朱前坤;崔德鹏;刘艺;杜永峰
{Author Address}: 兰州理工大学;
{Journal}: 土木工程学报
{Year}: 2023
{Volume}: 56
{Issue}: 06
{Pages}: 75-86
{Keywords}: 计算机视觉;运动估计;运动放大;模态分解;桥梁振动
{Abstract}: 基于振动的桥梁健康监测是以定量方式评估桥梁安全性能的有效工具，针对在使用传统接触式传感器时，实现大型结构的高空间分辨率测量难以达成，并且固定接触式传感器在超过主体结构的寿命时还可能缺乏可靠性。文章建立一套非接触桥梁振动识别系统，系统对基于相位的运动估计(PME)进行改进，结合2DGabor小波并抽出相位中与积分无关的变量，提出新的表示方法用于提取相位信息。系统利用改进的PME对结构表面的自然目标进行追踪，进而识别全场结构的振动信息；再通过模态分解离散出结构有效振动信号，将高频微小信号通过基于相位的运动放大(PMM)技术进行放大，最终识别出完整的结构振动信息。为应对城市复杂环境下桥梁振动识别的困难，消除环境对相机振动的影响，文中提出利用模态分解剔除环境对相机振动的影响和其他噪声，进而提取出有效的桥梁振动信息。通过在实验室桥梁模型上进行三种不同工况的试验和户外人行桥斜拉杆测试，验证系统对桥梁振动识别的可行性。在模型试验中，系统识别得到的时域和频域信息与激光位移传感器对比的误差都小于0.80%;户外人行桥斜拉杆测试中，系统识别的结果与接触式高频加速度传感器对比的误差小于2.0%,比桥梁挠度仪的可靠性更高，且利用模态分解离散出拉杆的各阶瞬时频率，由此表明系统鲁棒性强且经济性好，具备广泛的应用前景。
{ISBN/ISSN}: 1000-131X
{Notes}: 11-2120/TU
{URL}: https://link.cnki.net/doi/10.15951/j.tmgcxb.22010024
{DOI}: 10.15951/j.tmgcxb.22010024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的结构变形监测和构件损伤识别
{Author}: 李向雄
{Tertiary Author}: 杜永峰;杨忠平
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 超长隔震结构;计算机视觉;隔震支座变形;损伤识别;深度学习
{Abstract}: 近年来,结构健康监测逐渐成为土木工程研究领域的重要分支之一。监测在建设期以及服役期间的结构健康状况对于发现问题和防止灾难性结构故障是非常必要的。由于隔震技术在抵抗地震作用表现出良好的性能,越来越多的土木工程基础设施采用隔震技术。隔震结构利用减小隔震层的水平刚度对上部结构起到了隔离保护的作用,让地震作用下的大部分能量消耗在隔震层。隔震支座作为隔震层的主要构件,对隔震支座的变形监测是指导施工进度和评判结构实际受力的有效依据。传统的接触式位移测量方法受维度、精度、操作和安装繁琐等限制,采用基于计算机视觉的非接触测量方法可有效克服传统方法的不足。本文提出一种基于计算机视觉的位移监测系统,以网络摄像头为采集设备,采用基于颜色匹配的技术,实现目标位移测量。将该系统在西部某大型航站楼进行了验证与应用,用于该结构的隔震支座变形监测,并对监测到的隔震支座变形与温度数据进行分析。使用计算机视觉识别方法对民用基础设施进行状态评估在土木工程领域展现出巨大的潜力,包括结构构件的识别和定位,以及结构损伤的检测和量化。然而,由于这些方法需要大量的训练数据,获取这样的数据集具有挑战性。现有的数据集需要人工标注图像,本文利用大规模合成图像数据集“东海道数据集”用于结构构件和损伤的语义分割。通过训练全卷积神经网络的语义分割算法,然后利用合成图像对网络进行测试,验证了数据集的有效性。本文的主要研究内容包括以下几个方面:(1)为了需要满足严寒地区超长隔震结构由于温度变化及其它因素引起的隔震支座变形的功能需求,根据其工程现场条件,以及大型航站楼隔震结构的特点,为其设计并安装一套长期温度变形监测系统,实时记录隔震支座的变形,为上部结构施工和受力提供参考依据。(2)提出一种基于计算机视觉的位移监测系统,以网络摄像头为采集设备,采用基于颜色匹配技术,实现目标位移测量。将该系统在西部某大型航站楼进行了验证,用于该隔震结构的隔震支座变形监测,并对隔震支座的变形与温度的监测数据进行分析。(3)利用基于计算机视觉的合成环境生成的图像和相关的实况注释对结构构件和损伤进行语义分割。为了从给定的原始图像数据中训练桥梁结构构件和构件损伤像素的语义分割模型,提出了一种基于全卷积神经网络的构件和损伤自动分割方法。对原始数据集进行预处理后,将数据集输入到Deep Labv3plus和FCN全卷积神经网络中进行模型训练。然后使用性能较好的模型对测试图像进行预测,实现对结构构件和结构损伤的自动化识别。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2022.001443
{DOI}: 10.27206/d.cnki.ggsgu.2022.001443
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 相机标定的精度影响实验分析
{Author}: 翟溢章;宿洁华;张士恒;吴恩启
{Author Address}: 上海理工大学机械工程学院;库柏电子科技(上海)有限公司;
{Journal}: 电子设计工程
{Year}: 2022
{Volume}: 30
{Issue}: 07
{Pages}: 82-86
{Keywords}: 机器视觉;相机标定;精度;误差;因素分析
{Abstract}: 相机标定是机器视觉中的必要步骤，标定效果直接影响后续的测量精度。在张正友标定方法的基础上，对棋盘格尺寸、标定图片数量、棋盘格打印方式3个方面进行实验分析，实验过程中通过控制变量法进行对比实验。实验结果表明，棋盘格尺寸选择10～15 mm时标定效果较好；当棋盘格角点数目相同时，棋盘格尺寸越大，标定所需的图片数量越多；当棋盘格尺寸相同时，角点数目越多，标定所需的图片数量就越少；彩印的标定棋盘格在有效焦距、主点坐标以及重投影误差方面都比普通打印的精度高，且与实际值的误差维持在5个像素内，波动较小。实验结论为提高相机标定精度提供了有效参考。
{ISBN/ISSN}: 1674-6236
{Notes}: 61-1477/TN
{URL}: https://link.cnki.net/doi/10.14022/j.issn1674-6236.2022.07.017
{DOI}: 10.14022/j.issn1674-6236.2022.07.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于单目RGB图像的三维手势跟踪算法综述
{Author}: 张继凯;李琦;王月明;吕晓琪
{Author Address}: 内蒙古科技大学信息工程学院;内蒙古自治区模式识别与智能图像处理重点实验室;内蒙古工业大学信息工程学院;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: 04
{Pages}: 174-187
{Keywords}: 人机交互;虚拟现实;RGB图像;三维手势跟踪;计算机视觉
{Abstract}: 鉴于人机交互(Human-Computer Interaction, HCI)系统和虚拟现实(Virtual Reality, VR)系统的应用需要，三维手势跟踪领域的理论和方法研究已成为国内外广泛关注的热点课题之一。近年来，基于计算机视觉的三维手势跟踪算法迅速发展，其中成本较低且较为普遍的单目RGB相机最具潜力，它是三维手势跟踪应用得以照进现实的重要工具和途径，成为了研究者们的研究重点。为了解在此基础上的手势跟踪算法的发展现状，辅助该领域的研究者们进行更深入的探索，文中首先在与传统方法的对比中引出了基于单目RGB图像的三维手势跟踪算法，并将其分为判别法、生成法和混合法3类，概括了其相应的优缺点；其次讨论了RGB图像特点对三维手势跟踪的影响，并归纳了缓解图像深度模糊性的方法；然后根据分类着重分析了以RGB为输入数据的代表性算法，通过可视化的性能评估指标比较了相关算法的具体优势和不足；最后总结了当前三维手势跟踪算法面临的难题并对未来的发展进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyasPKzerXbPq4nOu8SJMet5SpcQYkY9gi6Siac7SE_zNKZJTvwBaAHo00zq0QN8zdP6Q5CMP6FyX_k5bOgipUDdh_vEaRVa6E8P7GyuLJADr3yD-_EFZdYmnc6uQfdVLkPrQZMj-zu0Z5exsA-sIy0Qz-bOvgbcDsrt9FeXFbAYc0jfr4d3EgoKC7fQOmeu2s=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的芯片字符识别系统
{Author}: 杨桂华;唐卫卫;戴志诚;卫嘉乐
{Author Address}: 桂林理工大学机械与控制工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 05
{Pages}: 105-110
{Keywords}: 机器视觉;HALCON;灰度值投影;字符分割;字符识别
{Abstract}: IC芯片表面的字符主要包括厂商名称和序列号，这些字符对于芯片的制造和应用具有重要现实意义，针对芯片表面印刷字符的检测，基于HALCON视觉软件开发平台研发了一套芯片字符识别系统。首先，采用灰度值投影法获得字符区域的行和列坐标分割点，进行字符分割。然后，利用形状匹配技术对欲检测芯片图像进行定位与校正，采用BP神经网络分类算法实现字符的识别。通过不同算法的对比实验分析，实验结果表明单张图片检测时间为42 ms,完整字符与缺陷字符的分割准确率均为100%,字符识别率达到99.5%。本系统能有效快速、准确的对IC芯片表面字符进行识别，检测精度满足要求。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108506
{DOI}: 10.19651/j.cnki.emt.2108506
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于光谱和图像的小麦表型信息感知方法研究
{Author}: 周磊
{Tertiary Author}: 裘正军
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 小麦;表型分析;光谱分析;机器视觉;深度学习;便携式传感器
{Abstract}: 小麦是三大粮食作物之一,精准高效的信息感知方法对小麦生产和粮食安全具有重要意义。小麦表型信息感知在品种选用、作物养分状态评估、农产品品质检测发挥关键作用。传统农业生产模式中,育种选种过程主要靠人工,存在效率低、易疲劳等弊端,无法满足农业现代化进程中对自动化、智能化信息感知的要求;作物理化指标监测、食品成分分析依赖破坏性实验,难以满足无损、绿色的检测需求。近年来,计算机视觉、光谱成像等技术为小麦信息感知提供了无损检测方案,人工智能算法可将数字信号与农作物、农产品内外部生理指标或产品质量安全等级进行关联耦合,为小麦表型分析提供了新的机遇。本文结合光谱分析、机器视觉、深度学习、嵌入式系统等技术,对小麦种子表型分析、叶片养分评估、植株品种鉴别、小麦混合粉成分分析等信息感知方法展开研究,具体如下:（1）基于高光谱成像的小麦种子表型分析方法。针对光谱扫描过程中种子样本相互粘连、光谱数据冗余信息多而导致表型分析效率低的问题,提出了面向粘连移除的种子图像分割方法Seed Net以及卷积神经网络特征选择算法CNN-FS。获取了30个品种的小麦种子,使用线扫描光谱仪器采集光谱图像。Seed Net通过语义分割模型区分图像中的粘连区域、轮廓和种子主体区域,对去除粘连后的前景提取连通域,生成分割结果图。该方法使用相对简单的语义分割实现了种子实例分割,计数和分割精度均超过传统的分水岭分割、U-Net及Mask RCNN。粘连分割后可得到种子个体的光谱曲线用于品种鉴别。CNN-FS方法通过自主设计的特征选择层和带有稀疏惩罚的损失函数,实现小麦类别相关的重要光谱波段筛选,降低特征维数;基于该方法筛选的特征构建模型,在30类种子鉴别任务中可达90%的精度,超过基于现有的特征选择方法建立的分类模型。（2）小麦叶片SPAD和含水率检测方法及传感器。采集叶片图像,使用RGB颜色特征和偏最小二乘回归反演SPAD值,遍历叶片区域像素形成SPAD分布图;将光源、传感单元、控制器等封装成便携式SPAD传感器,对小麦叶片SPAD值检测的平均误差约为1.1 SPAD,单次测试平均耗时小于5秒,实现了叶片SPAD非接触式检测和分布可视化。构建了基于NIR光谱模块的叶片含水率检测传感器,通过卷积神经网络（CNN）和信息融合方法建立含水率评估模型。对200个叶片样本进行建模和测试,实验结果显示RMSE=0.79 SPAD,R2=0.94,单次测量平均用时约3秒,实现了快速无损的叶片含水率检测。（3）基于冠层信息的小麦品种鉴别方法。通过无人机等多种方式采集五个品种小麦在不同生长阶段的植株冠层图像,构建了含有6400张800*800分辨率图像的样本数据集,采用Res Net、Vision Transformer等深度学习分类器构建品种鉴别模型,采用Grad-CAM算法对深度学习模型的判断依据进行可视化并解释其合理性。结果表明Res Net模型达到最高判别精度（87%）,其中针对抽穗期植株的鉴别准确率可达90.56%,但早期生长阶段的识别率仅46.71%。本文进一步使用NIR光谱技术对早期生长阶段的植株进行识别,基于PLSDA和1D CNN算法建立判别模型,分类准确率提升至77.5%。（4）基于NIR光谱的小麦粉鉴别及混合粉解析方法。获取了十二种食品粉末,采用DLP NIRNano光谱模块采集了样本的NIR光谱曲线。基于深度学习与度量学习的融合设计可扩展的粉末类别鉴定方法。首先使用六类粉末信息建立六分类模型,引入余弦相似度匹配替换初始六分类模型的线性分类器;通过向特征匹配库增加非常少量的六个新类别的参考样本,使分类模型在不重复使用先前的训练数据集重新训练或微调模型的情况下能够对新增类别的样本进行准确识别,结果表明该方法鉴别十二种粉末的精度为97.86%。而后,制备了280个含小麦粉、玉米粉、大米粉、奶粉的多元混合粉末并采集NIR光谱,研究了基于PLSR和CNN多元回归的混合物中各成分比例解析模型;结果表明CNN多元回归模型优于传统的PLSR方法,测试集上R2和RMSE的均值分别为0.976%和0.035。将NIR传感单元、树莓派、检测模型组合形成便携式小麦粉检测装置,单次粉末鉴定或成分解析耗时约3秒。（5）小麦表型信息分析处理的软件。基于Python语言和Flask工具包开发了B/S架构的用户服务软件,采用浏览器与服务器进行数据通讯的方式解决对Windows、i OS、安卓、Linux等异构平台的兼容性问题。服务程序监听来自用户的数据请求,解析请求中附带的参数,驱动传感设备执行数据采集、分析和存储,并将处理结果整合生成HTML界面向用户反馈。用户可通过手机浏览器控制本文开发的叶片SPAD传感器、叶片含水率检测传感器和粉末检测设备,访问获取到的原始光谱和图像数据以及对应检测结果。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001599
{DOI}: 10.27461/d.cnki.gzjdx.2022.001599
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的输电线路小目标检测和缺陷识别方法研究
{Author}: 徐昊
{Tertiary Author}: 杨强
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 输电线路巡检;小尺寸目标;数据增广;目标检测;目标分类
{Abstract}: 近年来,随着现代社会对电力的依赖日益增加,不间断供电的电力线路巡检已成为供电保障不可或缺的要素。在电力行业保质增效的工作愿景目标下,原本采用人工为主的输电线路巡检方式将逐步被无人机巡检、机器人巡检等新技术所替代。随着深度学习的发展,特别是机器视觉技术的更新迭代,机器视觉逐渐被引入到输电线路目标检测和缺陷识别领域中。目前,输电线路无人机巡检中图像检测和缺陷识别存在两方面的难题:(1)小目标检测困难。常用的机器视觉框架在小尺寸目标上的检测效果不佳,对小尺寸目标的特征提取与不同尺度特征融合存在缺陷。(2)缺陷识别和分类困难,缺陷集和正常集分布不均匀,分类依据的语义信息差别有限,浅层位置特征和深层语义特征融合效果不佳。本文面向输电线路无人机巡检工作任务,研究了基于深度机器视觉的输电线路小目标数据增广方法,改进了常见目标检测框架YOLOv5使其对小目标的检测效果得到优化,同时探索了输电线路缺陷识别分类方法。本文的研究内容包括:·提出了基于对抗生成和随机增广的小目标数据集增广与重构模式。从小目标数据集扩展的角度,针对小目标数据集分布不均、小目标边缘检测信息模糊、小目标语义特征信息稀疏的问题,提出针对输电线路小目标的基于对抗生成算法的超分辨率生成网络EL-ESRGAN,融合了计算机视觉领域GridMask和随机擦除算法的随机思想,对输电线路小目标数据集进行增广与重构,实现小尺寸目标的边界清晰化和语义特征扩增。·设计了基于主干网络调整的YOLOv5s目标检测改进模型。从目标检测网络的角度,针对通用目标检测器对小目标检测表现不佳的问题,提出基于Transformer编码器和Swin Transformer编码器的预测头改进,引入卷积块注意力模型,并通过加权双向特征金字塔网络改善了目标检测器对输电线路小目标检测的精确度。通过实验证明,本文提出的改进模型,比同等规模的YOLOv5m模型在各种尺寸目标检测m AP和参数量指标上更加优秀,并通过对比试验证明了每个模块的有效性。·提出了基于显著性图数据增广和增强特征金字塔的缺陷分类网络。从缺陷数据有效增广和目标分类器设计的角度,针对常规数据增广方式对缺陷部位语义信息的随机遮挡导致网络泛化能力降低的问题,提出基于嵌套U型网络显著性图检测的缺陷数据增广手段;针对目标分类网络ResNet34中浅层位置特征和深层语义特征融合效果不佳的问题,提出基于深层语义嵌入的增强特征金字塔分类网络,并通过对比实验证明了方案在分类准确度和F-Score指标上的优势。基于上述研究,本文实现了输电线路巡检图像中小目标数据增广与目标检测的算法改进,重点针对小目标检测性能进行检测网络特异化改进,同时实现了输电线路缺陷图像数据增广和缺陷分类网络改进。本文为输电线路巡检的智能运维提供了理论方法借鉴,具有明确的工程应用价值和科学研究意义。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.002166
{DOI}: 10.27461/d.cnki.gzjdx.2022.002166
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于嵌入式系统的跌倒监测系统设计
{Author}: 郭子彧
{Tertiary Author}: 蔡利民
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 嵌入式系统;跌倒检测;深度学习;YOLOv5;密集连接网络
{Abstract}: 随着社会的进步和科技的日益发达,人们在平时生活中的安全意识也在日益增强,特别是在老龄化日趋严峻的今天,独居老人在室内外活动时的安全要求日益提高,针对这一社会现象本文通过运用嵌入式技术、网络通信技术以及整合采用深度学习的目标检测算法的行为识别模块,完成了一套轻量化的嵌入式跌倒检测系统,该系统集成了视频监控、网络通讯和跌倒检测等多个功能。首先,提出了一个在嵌入式平台上运行深度学习算法模型的设计方案。但是通常情况下,深度学习算法模型的训练过程不适合在嵌入式设备上进行。故本文的模型训练过程是在PC平台Windows10的环境下进行的,然后将训练好的算法模型移植到嵌入式平台设备上以实现调用和运行。具体方案如下:在硬件平台上选择了搭载S5P6818芯片的X6818开发板,并连接摄像头获取监控画面,再由开发板上运行的视频服务器完成对于视频流的检测算法调用和监控画面的传输。与此同时,为了保证视频服务器和训练好的算法模型能够部署在嵌入式设备上运行,本文将Linux系统移植到了开发板上,并且部署了适合于嵌入式设备的算法推理框架MNN以保证移植后的算法模型的正常运行。接着是对模型的训练,在windows10平台基于PyTorch学习框架,对各类跌倒行为进行了分类整理,基于自己拍摄和网络上收集的534张图片,使用Label Img标注工具,完成了跌倒行为数据集的制作。之后通过改变网络宽度和网络深度对YOLOv5(You Only Look Once)算法模型轻量化处理,进一步减少了网络参数和计算量,提高了检测推理的速度。由于模型轻量化后,无法避免出现检测精度降低的问题,考虑在此基础之上对网络结构进行优化处理,采用了基于密集连接网络思想的方法改变了算法网络结构,改进后的模型与原模型进行了对比实验,新模型经过更少的迭代测试次数达到了最佳性能,召回率提高了1%,精度提高了0.96%,在置信度设为0.5的条件下,m AP达到0.962。最后对系统的各个功能模块以及系统整体功能进行测试,对于跌倒检测算法模型移植到开发板上的检测速率,在运行过程中平均速率达到16fps,且在最后的跌倒行为检测实验环节,检测成功率达到98%,基本符合跌倒监测系统的总体要求,为下一步研发工作做好铺垫,并具备相当的实际使用价值。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2022.000140
{DOI}: 10.27800/d.cnki.gjhdx.2022.000140
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的自动分类垃圾桶设计
{Author}: 朱炜义;王喜社;吴冠林
{Author Address}: 桂林电子科技大学机电综合国家级实验教学示范中心;
{Journal}: 产业与科技论坛
{Year}: 2022
{Volume}: 21
{Issue}: 07
{Pages}: 51-53
{Keywords}: 机器视觉;图像识别;自动分类
{Abstract}: 实施垃圾分类可促进资源回收利用，但人工进行垃圾分类效率低、成本高且执行困难[1]。本文设计一种基于机器视觉的自动分类垃圾桶，能够对投入的一个或者多个垃圾进行识别并自动分拣。运用MobileNet V1图像分类算法对投入的垃圾进行垃圾类别的判定，运用opencv库通过sobel算子计算梯度、canny边缘检测等算法进行垃圾的框选，并将类别和坐标信息传输给机械臂等分拣机构，使其对垃圾实现精准分拣，实现垃圾自动分类[2],促进垃圾分类制度的可实施性。
{ISBN/ISSN}: 1673-5641
{Notes}: 13-1371/F
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz0q7ZETmt-Rk8JJihIMJ8oRo9P3iiEN3Mj-wW1yK4RdzyxNfnEPiLPyNnmXG7tO502uMIYvZbevJtfb27w7XRi_CltZvRNzQK5_3ReFmXkAaociDvjExbJU6s4ezIi2hL4XgH9V3AfzSNmJNXgXtPUtHHtEXOKHWpKqCbCQj-A06JN-00KpCsLM8gCtmXPQHo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种面向图像相似度计算的改进哈希算法
{Author}: 夏雨轩;曲海成;关茜文
{Author Address}: 辽宁工程技术大学软件学院;
{Journal}: 智能计算机与应用
{Year}: 2022
{Volume}: 12
{Issue}: 04
{Pages}: 110-113+120
{Keywords}: 图像匹配;计算机视觉;机器学习;哈希方法;抗几何攻击;相似度计算;轮廓提取;汉明距离
{Abstract}: 图像相似度计算是图像匹配中的一个关键性问题，在网络搜索引擎和计算机视觉等领域有着广泛的应用。传统的哈希算法包括感知哈希、均值哈希、差异值哈希，采用离散余弦变换、主成分分析等方法处理图像，存在着方块效应等问题，为了解决传统算法的不足，本文提出一种基于Gabor小波图像轮廓提取和特征提取相结合的图像相似度计算方法。首先对待检测图像进行Gabor小波处理，提取出图像轮廓；然后使用固定阈值二值化增强图像轮廓；接着提出了一种幸存点提取的方法对图像再处理，得到图像的指纹；最后，提出一种比较所述指纹的方法，对2张图像的指纹全相联映射作商，若商值与1的距离小于设定阈值则记作0,反之记作1,得到一串由0、1组成的数，判断汉明距离，若小于自适应阈值，则认为2张图像相似。实验结果表明，本文提出sHash方法在图像发生视觉变换、光照变换、旋转变换下均能保持良好的相似度计算准确率，在主观视觉和客观指标上，均取得了较好的结果。
{ISBN/ISSN}: 2095-2163
{Notes}: 23-1573/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwQnCbS5lZaA5VRyRtyLjB3dbmBIU9PhmbZa4Lw4YnNZ6bYCEnywHfeIx7H5OzfpV46uOAsmbLc1RTdO0DAab5IgNpjzFm_schsNgLtPT7gWtsHu_JIFysKc1EYmT_NQpro1b6pN27eEX7a1X6lyuYa5CIYg_2HagJJkSTwSJxNneI0CI8DGzuJPNHsY4_cZQQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像和视频超分辨率的研究
{Author}: 张东阳
{Tertiary Author}: 申恒涛
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 超分辨率;注意力机制;卷积神经网络;特征学习
{Abstract}: 图像和视频的超分辨率(Super-Resolution,SR)算法研究是计算机视觉领域的一个重要问题,它能恢复原始数据由于远距离传输、压缩等造成的数据分辨率损失。通过对低分辨率数据的超分辨率重建,可以获得高分辨率的数据内容,极大改善视觉效果。在多媒体时代,图像和视频是我们日常接触最多的数据,为了提升降质数据的视觉效果,产业界以及学术界都致力于利用大数据的优势发展新型的超分辨率算法。得益于深度学习的快速发展,利用卷积神经网络构建深度模型被广泛地运用在最新的超分辨率算法中。相对于传统的基于手工特征的算法,基于卷积神经网络的超分辨率模型摆脱了复杂的调参过程,仅仅需要输入数据就能恢复出更优的细节特征,具有很强的可适应性。虽然卷积神经网络的引入为SR算法带来显著的收益,但由于深度学习模型动态推理能力差,算法复杂度高,注意力机制不清晰等问题依然有待解决,如何更加高效地提升超分辨率模型的运行效率和效果仍面临着巨大的挑战。本论文以深度学习的超分辨率模型为基础,针对现有算法面临的问题,从卷积神经网络的注意力机制,模型轻量化,真实场景的可适应性,三维卷积的应用这个四个角度出发对超分辨率模型理论和方法进行深入研究,主要贡献总结如下:(1)从卷积神经网络的注意力机制角度出发,本论文为超分辨率模型设计出一种新颖的核注意力模块。通过在运行中动态选择合适的卷积核,该机制使网络能够根据不同尺度的输入内容动态调整卷积核感受野的大小。在此基础上,本论文使用残差连接和组连接的方式对多个核注意模块进行叠加,形成了一种新的超分辨率模型,它能对不同接受域下的信息进行筛选,以此学习到更多有区别的表达。因此,本论文所提出的模型对多尺度特征更加敏感,通过预先定义上采样模块,使得单个网络能够同时处理多个尺度的超分辨率任务。本论文还综合对比了其它具有代表性的注意力机制,比如通道注意力机制和空间注意力机制,显示出本论文提出的基于核注意力机制的优越性,并在一定程度上为超分辨率模型的结构设计提供了可解释性。(2)从模型轻量化的角度出发,本论文设计出一个新颖的轻量级图像超分辨率模型,名字叫渐进式特征融合网络。为了充分利用特征图,本论文提出了一种新的渐进式注意力块作为网络的主要组成块。该模块采用多个具有像素注意力的并行连接路径,它能显著提高各层的感受野范围,从而帮助网络提取到图像中有用的信息和学习到更有鉴别性的特征表示。此外,在该网络中,本论文还利用多尺度的像素注意力机制构建出简洁高效的上采样模块。以上所有模块都保证了网络可以从注意力机制中受益,同时其自身又足够轻量级。在此基础上,本论文还提出了一种基于余弦退火学习的训练策略,它能训练出更具表达能力的模型,在不改变模型结构的情况下提高复原图像的质量。(3)从真实的应用场景出发,构建可适应卫星遥感图像的超分辨率模型。当前,超分辨率模型在真实场景下的可适应性研究是目前的难点问题。针对遥感图像的超分辨率重建,本论文提出了一种新型的混合高阶注意力网络。该网络由两部分组成:用于特征提取的浅层网络和用于细节恢复的具有高阶注意力机制的深层网络。在浅层网络中,本论文在所有跳转连接中用通道加权拼接代替元素级加法,这大大促进了信息流动。在深度网络中,不同于传统的一阶统计(空间或通道注意力),本论文设计出新颖的高阶注意力模块来恢复丢失的细节。最后,本论文引入了频率感知连接来集成浅层和深层网络。实验证明,本论文所提出的方法在遥感图像超分辨率上能提供当前最好的性能。(4)从三维卷积的角度出发,研究针对视频超分辨率模型的高效算法。与以往的基于光流的运动补偿方法不同,本论文提供了一种利用卷积分解原理实现的高效三维卷积模块来捕捉帧间依赖。在分解后,用三组一维的卷积核代替了传统的三维卷积核,从而使模型在保持较小运算量的同时充分利用输入图像序列的时空信息。此外,本论文还提出了一种新颖的动态多分支网络,它在特征融合阶段采用新颖的动态重建策略,使网络能从多个分支中自适应地确定时间相关的最佳信息。不同于简单的特征相加或者拼接,该动态策略能极大提升视频超分辨率的性能。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000241
{DOI}: 10.27005/d.cnki.gdzku.2022.000241
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉引导的工业机器人无序抓取系统设计
{Author}: 王连庆;钱莉
{Author Address}: 上海工程技术大学机械与汽车工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 03
{Pages}: 86-89+196
{Keywords}: 机器视觉;图像处理;CCD相机;手眼标定;视觉定位技术
{Abstract}: 随着近些年“智能制造”理念的提出，自动化工厂对于无人数字化生产的需求越来越多。过去的技术早已不能满足如今工厂的要求。随着工业机器人与机器视觉行业迅速发展，大大降低了生产中的人工参与度，实现了真正意义上的无人化工厂，视觉行业的出现也扩大的工业机器人的应用领域，对整个自动化行业逐步走向智能化有着十分重要的作用。构建了一套针对无序来料的定位系统，该系统可以引导机械手对无序物料精确抓取，并进行有序摆放。整个系统由机械手、CCD相机、计算机，光源及软件算法构成。首先通过标定获取相机的内外参，机械手和相机之间的转化矩阵，其次通过光源配合CCD相机对物料，物料盒进行取像，利用图像处理算法，定位算法，对物料和物料盒进行定位。将定位结果通过通讯协议传输给机械手端，机械手完成对物料的无序抓取与有序摆放。最后我们通过雅马哈YK500-600XGL机械手，大华工业相机，研华工控机进行实验，实验结果符合预期期望。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxypIWktDwHXdSqmissMgKHb1_zYjG_hh7IOFZgfF8mkWlxWBGXesRdSmypPZkTNC2cJNnwVYYjvZWXtjyYbFNIL9G4VywESIUVq_F7M5ftNfnPnb92ti3cQFpi9-oZGvlueH2fWOk_sMxPczyUnxnw9mL_no9RRVzEjZzd5XY2eJ83xpF1BEH0cP7a9vFt8fU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像识别的智慧餐饮管理系统
{Author}: 钟良堂;谭昊;廖瑾睿;谢文姬;陈乐平;车向前
{Author Address}: 广东海洋大学数学与计算机学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 06
{Pages}: 175-179
{Keywords}: 智慧餐饮管理系统;计算机视觉;推荐系统;SpringBoot
{Abstract}: 针对目前高校就餐排队时长、计费细则缺失与缺乏高效计费系统等问题，笔者以某高校食堂菜品为样本，基于Vue、微信小程序、SpringBoot技术设计一个基于图像识别的智慧餐饮管理系统。实践表明，该系统能够稳定运行，可以为管理者提供决策支持，达到预期设计要求。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwvMocKnpGzgdjbuqGb5F3jTCOjjI5sFv0lyiJDbt7Mjf57k0eCP4Jx4WJoA1WE6GLtFj5PXMA0hHiOSYoA1kZ5J5E4-cpsIbiyFp_OWhmte4JDf3yZMBqOwd9zqEwSGS2fKaQ7J2OFygP5S9kQIEMIN8l8Va9cT0ToCSbRwAIIOE4d9BP9roI4QnaVgfU9r_E=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv4模型剪枝的番茄缺陷在线检测
{Author}: 梁晓婷;庞琦;杨一;文朝武;李友丽;黄文倩;张驰;赵春江
{Author Address}: 上海海洋大学信息学院;北京市农林科学院智能装备技术研究中心;北京市农林科学院信息技术研究中心;湖南省农业装备研究所;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 06
{Pages}: 283-292
{Keywords}: 机器视觉;模型;番茄缺陷;YOLOv4;模型剪枝
{Abstract}: 为解决番茄缺陷检测过程中的精确性和实时性问题，该研究提出一种基于模型剪枝的番茄表面缺陷实时检测方法。采用模型剪枝的方法在YOLOv4网络模型基础上进行模型优化，首先将3个连续检测工位采集的RGB图像拼接生成YOLOv4网络的输入图像，然后采用通道剪枝和层剪枝的方法压缩YOLOv4网络模型，从而减少模型参数，提高检测速度，最后提出一种基于L1范数的非极大值抑制方法，用于在模型微调后去除冗余预测框，从而精准定位图像中的缺陷位置，并将模型部署到分级系统上进行实时检测试验。结果表明，该研究提出的YOLOv4P网络与原YOLOv4网络相比，网络模型尺寸和推理时间分别减少了232.40 MB和10.11 ms，平均精度均值（Mean Average Precision,mAP）从92.45%提高到94.56%，能满足实际生产中针对缺陷番茄进行精准、实时检测的要求，为番茄分级系统提供了高效的实时检测方法。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyCeiak2XJqvAtzND8dZqy3WjE9ruT4jD2Gv3o7Ww8D_sDs35T_ekGfAH5ESIx19-QaorQ8k_Kyk8kasFXwZa437Up8oeH-1Fm5VXGvUyUOIip-d3xyD05r-XVP1XfhsSkM6KPjQQdiB-gMITehAyUkoHrDAqJagHIl8Jotl2gWV17EYHzG3jgqYnjRYJeKPek=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆形零件尺寸参数测量
{Author}: 陈怡然;廖宁;刘超
{Author Address}: 重庆工程学院大数据与人工智能学院;贵州航天电器股份有限公司;
{Journal}: 工具技术
{Year}: 2022
{Volume}: 56
{Issue}: 03
{Pages}: 109-113
{Keywords}: 机器视觉;图像分割;数学形态学;最小二乘法
{Abstract}: 针对圆形零件尺寸传统测量方法存在测量效率低、一致性差及同心度参数不易测量的问题，设计一种基于机器视觉的圆形零件特征参数测量系统。采用阈值分割法对灰度图像进行阈值分割以提取特征目标，利用数学形态学方法对二值图像进行腐蚀、膨胀操作，避免纤细、重叠的噪声干扰；通过最小二乘法对内、外圆弧轮廓点进行拟合，得到圆心和半径参数，通过欧式距离计算出同心度参数。实验测试显示，系统精度达到0.01mm,与采用测量仪相比，视觉测量方法更适合大批量非接触式测量。
{ISBN/ISSN}: 1000-7008
{Notes}: 51-1271/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy_zQIV5UTUYy_vEa5fu5PG_qMTJFgl1JkQLJOv1RGpwFK-i6Ye1zBjPXSpMhfBO-0SKYTavfACnu4avQDq0b-wKZuCJLmuZZ1OFwQmaPVdTd4id3dNKijv0QEsmDgnqEwJy90bjj5Cwpf1sOCiW4RTM5yrJlB2HsTA-Wq7ZWx9qa_9wPqwFF7d_weLtFGDuN4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CiteSpace的计算机视觉文献大数据可视化分析
{Author}: 陆安永;杨会勤;杭鹏;黄梦园;费驰;齐金山
{Author Address}: 淮阴师范学院计算机科学与技术学院;贵州大学明德学院;
{Journal}: 淮阴师范学院学报(自然科学版)
{Year}: 2022
{Volume}: 21
{Issue}: 01
{Pages}: 30-36
{Keywords}: 计算机视觉;CiteSpace;神经网络;文献计量;可视化图谱;图像处理
{Abstract}: 随着科技的高速发展，计算机视觉被广泛应用于各个领域，且计算机视觉领域的研究呈上升趋势．本文从计算机视觉技术及其基本应用原理、应用领域等方面进行了阐述；然后运用信息可视化软件，以2000-2020年间近3万篇文献为研究对象进行可视化处理，绘制出该领域的聚类分析、共现分析等科学知识图谱；利用文献计量法从国家、学科、研究机构等热点分布突现文献，同时分析得出计算机视觉在科研合作、研究热点、学术影响等发展趋势．研究结果表明该领域存在着文献发表数量不多、各个国家和机构之间的合作不够紧密、研究主要集中在基础性学科等现状，提出加大研究力度、加强合作关系、进一步将研究价值实际化的建议．
{ISBN/ISSN}: 1671-6876
{Notes}: 32-1657/N
{URL}: https://link.cnki.net/doi/10.16119/j.cnki.issn1671-6876.2022.01.008
{DOI}: 10.16119/j.cnki.issn1671-6876.2022.01.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属工件尺寸测量
{Author}: 李执;闫坤;傅琪;刘威
{Author Address}: 桂林电子科技大学信息与通信学院;
{Journal}: 仪表技术与传感器
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 92-97
{Keywords}: 机器视觉;卡尺工具;Ramer算法;Tukey算法;尺寸测量
{Abstract}: 针对多孔金属工件人工测量步骤繁杂、精度低问题，提出了基于机器视觉的金属工件尺寸精密测量方法。首先对目标进行灰度化、增强、滤波等预处理，再提取区域轮廓，针对轮廓定位分割问题，提出了基于Ramer算法逼近的两步轮廓分割方法，并引用全局轮廓分割参数S对轮廓进行分类。为提高直线和圆的边缘点定位准确性，提出了基于卡尺工具的边缘点检测方法，最后采用基于Tukey拟合算法对直线和圆形进行测量，计算得到亚像素精度尺寸。实验证明该方法可以提高测量精度且效率高。
{ISBN/ISSN}: 1002-1841
{Notes}: 21-1154/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzOMKwSrOPrW0oTJaGz5suOgs-36gycAmGIzVz7x7TBuWWG6XY4j13qTk6N9sGVgwn8fsh-fQtPKnccHbszZ9OdaWHeva2ggxJholIAJzBuR0S0E13QmSTDPoYYtts8pxPGgqfbAt8BL1VsaBjfXBiTIuGp4ANkL4DPPFWthFce9V-xuqCdwn6nGmr_U3V2HrI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的步态识别算法及系统实现
{Author}: 赵桂杰
{Tertiary Author}: 李玺;杨玉春
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;步态识别;R-Conv;多尺度融合;智慧园区
{Abstract}: 随着社会的发展以及安全需求的增长,生物特征识别技术受到广泛关注。其中步态识别是一种新兴的生物特征识别技术,通过行走姿态进行身份认证。与人脸识别相比,其具有远距离非接触采集的优势,与行人重识别相比,其具有不受衣着颜色干扰的优势,因此在监控安防领域存在巨大潜力。然而在实际场景系统应用中步态识别只能作为辅助手段,其识别精度受一些外界因素的影响,例如相机视角变换、行人外观变化以及步态数据分割效果不佳等,这给步态识别任务带来了巨大挑战。针对以上问题,本文研究和设计步态识别模型,用来提取更鲁棒的轮廓特征以及更丰富的时序运动特征,并在园区网络监控场景下设计具有实用性和实时性的工程应用,本文就此真实复杂场景下的步态识别问题开展研究:1.本文提出了多尺度融合残差步态识别网络Res Gait,包含水平局部特征提取模块HLFE和多尺度融合模块MSF两部分。研究发现行人背包或持物体行走时会影响局部形状和运动特征,而换衣和视角变化会影响近乎一半的形状和运动特征,因此认为同时使用局部部分特征和全局特征效果会更好,本文设计了卷积残差层R-Conv,其由水平分块卷积和普通卷积并行构成,而HLFE模块是由多个不同的R-Conv层构成。其次当行人的外观轮廓发生变化时并不影响行人时序运动信息,因此需要提取更加精细化的时序运动特征,MSF模块通过使用两个时间特征聚合器对HLFE模块的两个不同尺度输出进行时序特征提取,最后对不同尺度的特征融合从而得到最终的步态特征。最后在目前使用最广泛的公共数据集CASIA-B进行充分的消融和对比实验,该算法达到了91%的平均精度,表现优于现有算法。2.进一步,本文以提出的步态识别算法Res Gait为核心进行系统工程设计,以园区场景下的网络监控系统为基础,实现园区智能步态识别系统。本文首先对功能需求进行分析并设计整体架构,硬件方面设置和标定摄像头、配置交换机和服务器,软件方面将目标检测追踪、人体属性识别、行人分割、步态识别匹配等深度学习算法进行训练,并进行算法和工程上的优化,达到兼顾准确率和效率的要求,其次进行数据库和前端Web交互界面开发,实现目标行人识别匹配、轨迹运动动画可视化、人体属性分析以及随人员分析等功能。最后进行了详细的功能测试以及对算法的精度和效率的性能评估,该系统达到了园区智能监控场景下实时性和实用性的要求。本文提出了更鲁棒的步态识别算法并达到了较好的性能,并在提出算法的基础上实现了园区网络监控场景的步态识别系统工程应用,同时发现在现实场景中的挑战更多,还需学术界和工业界进一步的研究探索。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.000193
{DOI}: 10.27461/d.cnki.gzjdx.2022.000193
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 利用卷积块注意力机制识别人体动作的方法
{Author}: 高德勇;康自兵;王松;王阳萍
{Author Address}: 兰州交通大学电子与信息工程学院;甘肃省人工智能与图形图像工程研究中心;甘肃省轨道交通装备系统动力学与可靠性重点实验室;
{Journal}: 西安电子科技大学学报
{Year}: 2022
{Volume}: 49
{Issue}: 04
{Pages}: 144-155+200
{Keywords}: 机器视觉;动作识别;注意力机制;感兴趣区域;卷积长短时记忆网络
{Abstract}: 针对动作识别任务中注意力模型在关注图像序列中的感兴趣区域时，更多侧重于通道间的相关性而忽视了特征的空间位置信息，因而缺乏对视频中动态区域的精准辨识能力，提出基于注意力机制和卷积长短时记忆网络的动作识别方法。首先，使用ResNet-50网络获取视频帧的特征表示，并利用卷积块注意力模块，先通过通道注意力分配特征图在不同卷积通道上的资源，再以空间注意力去分析不同特征图中显著元素的空间位置关系。从而实现对卷积特征图权值的优化调整，抑制或降低与动作无关区域带来的影响。同时，考虑到长短时记忆网络(LSTM)在处理时空数据时丢失了图像帧的空间结构信息，而卷积长短时记忆网络(ConvLSTM)借助卷积操作挖掘了图像中的空间相关性，对视频属性的完整性表示做了进一步的补充。因而，使用卷积长短时记忆网络对特征的序列信息进行建模并获得帧级别的预测，最终综合所有帧的预测共同确定视频的类别。在三个公开数据集上的实验结果表明，所提方法能够有效地突出视频中关键性区域，在一定程度上提升了动作识别的准确率。
{ISBN/ISSN}: 1001-2400
{Notes}: 61-1076/TN
{URL}: https://link.cnki.net/doi/10.19665/j.issn1001-2400.2022.04.017
{DOI}: 10.19665/j.issn1001-2400.2022.04.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在智能化纺纱生产中的应用现状
{Author}: 徐伟锋;胡俊武;祝新军;叶佳佳
{Author Address}: 绍兴职业技术学院;振德医疗用品股份有限公司;
{Journal}: 棉纺织技术
{Year}: 2022
{Volume}: 50
{Issue}: 05
{Pages}: 71-74
{Keywords}: 机器视觉;棉纺织;智能化;在线检测;深度学习
{Abstract}: 探讨机器视觉在智能化纺纱生产中的应用情况与发展趋势。分析了棉纺智能化纺纱生产流程，从原棉异纤检测、梳理棉网在线检测、细纱加工检测和筒纱加工检测等重要方面，对机器视觉检测的应用原理、方法和产品进行了阐述与总结。指出：基于机器视觉的检测技术可将机器视觉感知数据与生产信息数据共享，通过数据驱动，提高纺纱质量和生产效率。认为：机器视觉在智能化纺纱生产中的应用可加速棉纺企业转型升级和智能化改造的进程。
{ISBN/ISSN}: 1000-7415
{Notes}: 61-1132/TS
{URL}: https://link.cnki.net/urlid/61.1132.TS.20220303.1854.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉与BIM的裂缝可视化管理方法
{Author}: 熊琛;陈立斌;李林泽;许镇;赵杨平
{Author Address}: 深圳大学中澳BIM与智慧建造联合研究中心;深圳大学土木与交通工程学院;北京科技大学土木与资源工程学院;
{Journal}: 图学学报
{Year}: 2022
{Volume}: 43
{Issue}: 04
{Pages}: 721-728
{Keywords}: 裂缝识别;建筑信息模型;裂缝可视化;矢量化;计算机视觉
{Abstract}: 对结构表面裂缝进行持续检监测与管理对保障结构安全具有重要意义。为实现结构裂缝自动识别与管理，提出了一种基于计算机视觉与建筑信息模型(BIM)的裂缝识别、矢量化处理与可视化管理方法。首先基于深度学习的图像识别方法，从相机拍摄的结构表面图像中提取出裂缝形态的栅格图像；其次，提出了一种裂缝形态栅格图像的自动矢量化方法，获取裂缝形态关键点坐标；最终，使用Dynamo程序实现裂缝BIM模型的自动建模与可视化。该方法可以获取裂缝的拓扑形态信息，并显著降低裂缝信息的存储数据量与可视化难度。通过开展BIM构件的碰撞分析，还可准确识别裂缝属于结构中的哪个构件，将裂缝所属的构件编号信息与裂缝宽度信息作为裂缝图元参数写入BIM模型，实现裂缝矢量化与裂缝BIM模型自动化建模与管理，为大范围、大批量的裂缝自动化检监测与管理提供参考。
{ISBN/ISSN}: 2095-302X
{Notes}: 10-1034/T
{URL}: https://link.cnki.net/urlid/10.1034.T.20220303.1844.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CMOS传感器的采摘机器人计算机视觉系统研究
{Author}: 魏宏飞;张季萌
{Author Address}: 河南工业职业技术学院;
{Journal}: 农机化研究
{Year}: 2022
{Volume}: 44
{Issue}: 12
{Pages}: 221-224+229
{Keywords}: 采摘机器人;视觉系统;COMS传感器;仿真模拟;图像增强
{Abstract}: 为了提高采摘机器人计算机视觉系统的性能、简化机器人视觉系统的硬件结构，将COMS传感器引入到了采摘机器人视觉系统的设计上，并通过对图像处理系统的集成实现了传感器采集图像的增强处理，为果实定位提供了更加可靠的数据。为了验证COMS传感器在视觉系统中使用的可靠性，通过仿真模拟的方法对比了多种传感器，结果表明：COMS传感器与CCD、激光扫描得到的定位数据相吻合，可靠性较好。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2022.12.017
{DOI}: 10.13427/j.cnki.njyi.2022.12.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的割草机器人作业控制研究
{Author}: 徐晨
{Author Address}: 重庆工商职业学院;
{Journal}: 农机化研究
{Year}: 2022
{Volume}: 44
{Issue}: 12
{Pages}: 235-238
{Keywords}: 割草机器人;计算机视觉;图像采集;特征比对
{Abstract}: 以割草机器人作业过程为研究对象，分析了机器人作业的环境特点，建立特定的环境参数模型，并运用计算机视觉算法进行作业环境的自动化识别。试验结果表明：割草机器人视觉系统所包含的目标识别算法和边界特征导航算法，对割草机器人作业过程中的目标识别准确率达到95%以上，控制指令发出至作业过程的平均反应距离不大于20mm,能够实时准确地进行割草作业过程自动控制。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2022.12.015
{DOI}: 10.13427/j.cnki.njyi.2022.12.015
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目立体视觉技术的水下机器人避障系统研制
{Author}: 谢起楠
{Tertiary Author}: 蔡文郁
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自主水下航行器;双目视觉技术;三维流函数;避障算法
{Abstract}: 海洋是生命的发源地、运输的要道、能源的宝藏和战略布局的必争之地。水下航行器作为探索海洋资源的重要手段之一,已经成为世界各大国海洋科技竞争的重要研究方向之一。但是,水下机器人的核心技术仍然存在许多科学瓶颈难以突破。一方面,水下环境感知是首当其冲需要解决的问题,基于声学感知的传统水下感知设备,不仅设备造价昂贵,而且在近距离区域感知效果不佳。另一方面,水下避免碰撞和路径规划是水下机器人完成探索任务的基础,现有的水下避障算法在理论研究上研究颇丰,但是缺乏真实场景的落地实现。针对传统的声学探测方案在近距离水域感知不灵敏的问题,本文采用了一种基于双目立体视觉技术的水下障碍物定位方法。该方法采用暗通道先验算法清晰化纹理模糊的水下场景图像,采用YOLO-V3目标识别算法实现水下机器人障碍物识别能力,然后采用双目视觉立体匹配算法计算障碍物的视差。水池实验证明,基于双目立体视觉技术的水下障碍物定位方法在近距离应用时误差在10%左右,从而验证了所研究方法可以实现水下障碍物近距离定位。针对水下机器人的避障问题,本文提出了一种模拟流体绕流运动的三维流函数避障算法。该算法将传统的二维流函数避障算法扩展到三维空间,使其能够灵活的适用在水下的避障场景。本文分析了避障流线的斜率,论证了算法所得曲线具有平滑性的特点。针对流函数固有的滞点问题,论文提出了一种基于虚拟障碍物法的解决方法。水下机器人避障过程中的能量损耗公式,证明了所述算法具有低能耗的特点。在MATLAB上对所述算法进行了验证,结果证明该算法不仅具避障平滑度好、能量消耗低以及避障效率高的特点,而且具有占用物理内存少、算法复杂度低和移植性好等优势。本文提出的基于双目立体视觉技术与三维流函数避障算法相结合的方案,在水下机器人避障实验进行了测试。实验结果表明,三维流函数避障算法可以规划有效的水下避障路线,水下机器人实际运动轨迹与算法规划的避障路线逼近,因此可以实现较好的避障效果。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.000039
{DOI}: 10.27075/d.cnki.ghzdc.2022.000039
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度卷积神经网络的垃圾检测与识别
{Author}: 程自帅
{Tertiary Author}: 林志赟;王博
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 垃圾分类;目标检测;模型轻量化;特征融合;系统架构
{Abstract}: 社会物质生产水平和人口数量的不断攀升共同导致了垃圾总产量的扩增。对垃圾检测并识别、进行垃圾分类,以改善处理环节的自动化水平逐渐成为了上述背景下的时代关注,有着巨大的社会及经济价值。因此,本文提出了一种垃圾检测与识别算法,并针对其终端部署权衡速度与精度做出改善进而构建了包含投放垃圾人员人脸身份识别在内的完整微型监管系统。主要包括如下方面工作:(1)针对当前垃圾检测数据集规模小且多为分类数据集本研究无法直接使用问题。首先,基于华为垃圾数据集构建了初始数据集;其次,编写自动化脚本对该数据集充分分析并完成了结果可视化;最后,提出了一种基于爬虫技术的数据扩充策略及数据半智能标注方法进行数据扩充。最终构建了共包含44个种类、34395个目标及标注的垃圾检测数据集,为后续研究提供了良好的数据基础。(2)针对本研究场景下算法在终端部署时硬件限制及实时性约束并权衡准确率要求。首先,选定YOLOv5作为基线网络并引入Ghost模块对网络主要单元Bottleneck CSP结构进行轻量化改进;其次,对算法原检测头分支结构进行重新设计并对收益贡献较少部分采用轻量化卷积模块进行替换,同时重新设计了检测头锚框;最后,针对部分轻量化改进的副作用,在骨干网络特征图尺寸变化的每个阶段融入注意力机制以提升网络精度。最终提出了YOLOv5-4DWGA算法且与原YOLOv5在同等对比下,m AP提升2.95%,检测速度提升了28.15%。(3)设计并实现了一个垃圾检测与识别系统,该系统包括垃圾识别与检测模块、身份验证模块、界面显示模块。首先,完成了系统的整体架构设计并将YOLOv5-4DWGA垃圾检测与识别算法进行嵌入;其次,利用基于Res Net的人脸检测和基于Landmardks的关键点提取实现了人脸识别并引入质心追踪算法对其改进完成了身份验证模块;最后,利用Py Qt5实现了界面显示模块,尽管界面比较简单但仍为后续系统的更新提供基础模块构件。最终完成了整个微型系统的开发,为算法的落地提供了支撑。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.000364
{DOI}: 10.27075/d.cnki.ghzdc.2022.000364
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的地铁轨道障碍物检测系统设计
{Author}: 樊成栋
{Tertiary Author}: 汪惠芬;刘长安
{Publisher}: 南京理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;轨道识别;障碍物检测;卷积神经网络
{Abstract}: 当前轨道交通在城市公共交通系统中扮演者重要的角色,随着城市轨道交通的快速发展,地铁是涵盖了城市地区各种地下与地上地路权专有、高密度、高运量地城市轨道交通系统。我国现已开通地铁里程达6000公里,作为城市人口出行的一种重要交通工具,其极大地缓解着城市地面交通的压力。因此,确保地铁列车的行驶安全不仅有助于维护地铁的正常运营,更对保障乘客的生命财产安全有着至关重要的作用。地铁轨道环境中可能存在的障碍物是影响地铁列车行驶安全的重要因素之一,地铁的行驶环境又可能使列车驾驶员难以及时做出有效反应,这无疑对地铁列车的安全行驶构成威胁。因此,实现对地铁轨道障碍物的实时检测,就可以在一定程度上保障地铁列车的行驶安全。本文在对当前国内外的基于机器视觉的障碍物检测技术研究的基础上,根据地铁行驶环境的实际特点和障碍物检测的实际需求,研究适应于本文实验环境下的障碍物检测算法,搭建检测系统架构以及系统功能模块。该系统采用车载单目机器视觉的方式,通过对获取视频帧图像的分析,首先对轨道区域进行识别,再对该目标区域内的障碍物进行检测。具体包括以下内容:(1)地铁轨道区域边界识别。首先对获取的视频帧图像进行图像预处理,减小原始图像数据的噪声干扰;其次对处理后的图像进行边缘检测,提高算法的处理效率与检测准确率。在以上处理中,分析对比多种处理与检测算法,最终选择在本实验环境下最优的算法以识别轨道区域边界。(2)地铁轨道障碍物检测算法。本文从算法实时性及检测准确性量方面对已有的帧间差分算法进行改进,完成障碍物检测。同时,对卷积神经网络在本障碍物检测任务中进行实际应用,并比较二者的检测性能。(3)障碍物检测系统的设计。主要包含检测系统的硬件系统组成和软件系统设计。硬件系统包括视频图像采集设备、视频图像处理设备以及视频图像显示设备,同时详细设计了检测软件的架构、系统流程以及功能模块。通过上述研究,在实验环境下对本系统进行了实验验证分析,结果表明,本文的检测算法以及检测系统能够较好的实现对轨道障碍物的检测,具备一定的实时性与准确性。
{URL}: https://link.cnki.net/doi/10.27241/d.cnki.gnjgu.2022.000010
{DOI}: 10.27241/d.cnki.gnjgu.2022.000010
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的城市排水管道内部缺陷检测方法研究
{Author}: 张力
{Tertiary Author}: 侯迪波
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 城市排水管道;缺陷识别;机器视觉;数据集预处理;网络结构搜索;错误集中机制
{Abstract}: 一个城市的排水管道与公共卫生、安全、环境、经济利益等密切相关,如果排水管道发生堵塞或者破裂等问题,会导致严重的后果,甚至导致城市的整体瘫痪,因此对城市排水管道进行高效准确的检测是城市建设一项非常重要的环节。由于排水管道内部空间狭小,且环境复杂,人工巡检效率低并伴随着一定的危险性。近年来,随着机器人技术的发展,出现了管道机器人来代替人工进行管道内作业。国内很多城市都是开始通过管道机器人进行管道内部图像的拍摄然后由专业工程师进行人工识别,但是随着管道规模的不断扩大,人工的方式无法进行及时准确的判别,基于此本文开展了基于机器视觉的城市排水管道内部缺陷识别方法的研究。论文的主要工作与技术创新点主要包括:(1)针对管道图像包含多种不同性质的噪声、图像中细节部分亮度不高、以及数据集表现出很严重的长尾效应,对管道数据集进行预处理。预处理分为图像层面和数据集层面两部分。对数据集中的原始图像,通过基于低秩恢复的方法进行去噪处理,基于Retinex的图像增强算法提高图像的对比度。为消除数据集中因长尾效应带来的负面影响,采用上下文编码器生成新的图像样本。(2)针对城市排水管道缺陷识别领域中不同样本识别难度差异巨大,包括不同类别的样本以及相同类别不同程度的缺陷,以及训练集中包含错误标签样本等问题,设计一套缺陷识别模型构建方法。采用渐进式的网络架构搜索方法构建一种专门用于城市排水管道缺陷识别的模型结构。除此之外,设计了一种基于错误集中机制的训练策略以及相应的三阶优化框架,模型在训练过程中会根据其在验证集中的性能,为不同的训练样本分配不同的训练权重,从而提高识别模型的性能。(3)在多种不同的场景中验证上述构建的模型的性能,首先在单缺陷场景中证明模型可以准确的识别当前图像是否包含缺陷以及缺陷的具体类别,该场景中识别的缺陷为四种在实际城市排水管道中发生频率最高的缺陷。然后测试模型在多缺陷场景中的性能,虽然无法自动识别出图像中存在的其他缺陷,但是可以给出图像中存在每种缺陷的概率,后期很容易判别出其他缺陷。最后考虑到实际生活中会出现其他的缺陷,对模型进行改进,使其可以识别更多的缺陷。总体而言,为解决城市排水管道内部缺陷检测,提出了一种基于机器视觉的缺陷识别方法。首先对管道图像数据集进行预处理,再基于处理好的数据集,采用渐进式的网络结构搜索方法,并配合本文提出的基于错误集中机制的训练策略,构建一个管道缺陷识别模型,最终得到的识别模型可以很好的识别实际管道图像中的缺陷。本文的研究工作有效提高了基于机器视觉的城市排水管道缺陷检测的效率和准确率,为城市排水管道检测提供了技术支持。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001786
{DOI}: 10.27461/d.cnki.gzjdx.2022.001786
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MAML算法的YOLOv3目标检测模型
{Author}: 沈震宇;朱昌明;王喆
{Author Address}: 上海海事大学信息工程学院;华东理工大学信息科学与工程学院;
{Journal}: 华东理工大学学报(自然科学版)
{Year}: 2022
{Volume}: 48
{Issue}: 01
{Pages}: 112-119
{Keywords}: 计算机视觉;图像识别;特征提取;目标检测;小样本学习
{Abstract}: 作为典型的一体化卷积神经网络，YOLOv3模型的网路传输途径简单，检测速度相对较快，但检测精度较低。当遇到新的目标在训练数据集中存在的样本较少时，模型检测会更加不准确，甚至会出现检测不到的情况。本文基于与模型不相关的元学习算法（MAML）改进了YOLOv3主干网络的结构，使其具有内循环和外循环的梯度下降，在初始参数基础上进行多步的梯度调整，达到仅用小样本数据就能快速收敛的目的。实验结果表明，该方法使得YOLOv3模型的检测精度提升了5.24%，且可以使梯度下降保持稳定，有效地满足YOLOv3模型在小样本数据训练情况下识别目标位置的精准性和泛化性。
{ISBN/ISSN}: 1006-3080
{Notes}: 31-1691/TQ
{URL}: https://link.cnki.net/doi/10.14135/j.cnki.1006-3080.20201128002
{DOI}: 10.14135/j.cnki.1006-3080.20201128002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机械手夹持角自动化控制系统
{Author}: 吴德刚;赵利平;陈乾辉
{Author Address}: 商丘工学院机械工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 02
{Pages}: 187-190
{Keywords}: 机器视觉;机械手;夹持角控制
{Abstract}: 为缩短机械手元件到达预设位置所需的消耗时长，避免夹持角出现过度增大的行为状态，设计基于机器视觉的机械手夹持角自动化控制系统。根据夹持器机械元件所处运动状态，控制角位置传感器的连接灵敏度，再借助拉压力控制结构，完成对夹持力作用形式的按需调节，实现自动化控制系统硬件结构应用平台环境的搭建。在此基础上，抓取必要机械手运行图像，遵循机器视觉原理，完成预处理，再联合运动学函数，执行力控制切换操作，实现基于机器视觉的夹持力控制，完成机械手夹持角自动化控制系统的设计与应用。实验结果表明，在电机驱动速度等于2000PPS、4000PPS、6000PPS的情况下，机械手元件到达预设位置所需的消耗时长均不会超过9.5s，与双闭环控制系统相比，更符合有效控制夹持角行为状态的应用需求。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyZ9H3pgAIlAdf2oVSex3xuyQ1Le1WhG074yupu5S2dFgP0m1D3H4c7wkjhl6MZBzQNs_QHVF5uzZ6if0ll20CqMXO0roiWvfTU8e1pkTRqpawzPn8rmGcZGvJSkv12mBNfFK-59Je5pfuTG_byS2Cq5JltAke4Tnx5zgZvCzsPsfEo4Kc2Z-G3uWnFecflD2k=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于生成对抗网络的图像去雾算法
{Author}: 仲伟峰;赵晶
{Author Address}: 哈尔滨理工大学自动化学院;黑龙江省复杂智能系统与集成重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 04
{Pages}: 337-345
{Keywords}: 机器视觉;图像处理;循环生成对抗网络;有雾图像;光学模型
{Abstract}: 近几年在图像去雾领域中基于深度学习的方法层出不穷，利用循环生成对抗网络（CycleGAN）设计图像去雾算法。在CycleGAN中，通过对生成器进行改进来达到预期的处理效果。在生成器的编码网络和解码网络中选用Leaky ReLU和tanh两种激活函数，并对转换网络的残差块进行减少数量处理和加权优化处理。本设计能够更好地展示单幅有雾图像的清晰度和细节方面，峰值信噪比、结构相似性及信息熵等客观评价指标都得到了提升。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyk4kzt55pOcQLt_QXoL1-7Xcgynf8MumkmxxmhYwinVogM4n9jG3GQjLmUb2m5eGMIIsKXf14LfcBAOKpMIt8z8w7-EpYLe7-Ly1gu5Wsoi1WoWc7WOv7I2io1ZVb5_ahQ8XoH5x1AXIj2snu5F4xKdgviaKRvqvXOTu7ho_E7n_nfDj3vidBZkutZ40gtCng=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉技术的壳体表面缺陷检测研究
{Author}: 高文彬;庄申乐;王秀剑;周敏;宋冉冉;张成雷
{Author Address}: 山东龙立电子有限公司;临沂大学;
{Journal}: 机电元件
{Year}: 2022
{Volume}: 42
{Issue}: 01
{Pages}: 42-46
{Keywords}: 机器视觉;壳体;缺陷;BP神经网络
{Abstract}: 以自行研制开发的深海水密圆形连接器外壳体为例,本文提出了一种基于机器视觉技术的壳体表面缺陷检测方法,阐述了机器视觉技术在壳体表面缺陷图像的处理过程及特征值提取过程,并在深海水密圆形连接器产品研发中连接器壳体缺陷检测进行应用。最后,构造了运用BP神经网络进行壳体表面缺陷识别的分类器,实现了壳体表面缺陷的准确识别与分类。
{ISBN/ISSN}: 1000-6133
{Notes}: 51-1296/TM
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxZnB7_uNq8275WiBCca1X2DVn6_16IANptZujHz9HLfnRQ21V_V5zUPk7hfjRgybw9LBbwyIGcqtZb9GborsNB56GN1fsCbvWpoGDD9FeUIbKneobGj8UVB23b9_0IqFCDak6tDZ3d0E-cxCPFdnfPXuLqEX5ET4TaQ8rMRsxJ1xmI5z7Ms4kzX19oD3uIaCg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 显著性物体检测研究综述：方法、应用和趋势
{Author}: 李婉蓉;徐丹;史金龙;黄树成
{Author Address}: 江苏科技大学计算机学院;
{Journal}: 计算机应用研究
{Year}: 2022
{Volume}: 39
{Issue}: 07
{Pages}: 1941-1950
{Keywords}: 显著性物体检测;视觉注意;关注点预测;目标建议;深度学习;弱监督学习
{Abstract}: 显著性物体检测旨在快速定位图像中的显著性目标，可用于目标检测和识别、关键点定位、视觉跟踪、语义分割等计算机视觉任务中。为梳理显著性检测研究的发展脉络，从方法、应用领域和研究方向等方面分析显著性检测的研究现状和发展趋势。首先，阐述了显著性检测与相关研究的区别和联系；然后，分析了目前主流的显著性物体检测算法的流程、创新点、性能和适用性；接下来，介绍了显著性检测领域数据集的发展和演化；最后，展望了显著性检测研究的发展趋势并总结了显著性检测的主要应用领域。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2021.12.0645
{DOI}: 10.19734/j.issn.1001-3695.2021.12.0645
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉布料瑕疵检测方法综述
{Author}: 韩济阳;曹江涛;王贺楠;姬晓飞
{Author Address}: 辽宁石油化工大学信息与控制工程学院;沈阳航空航天大学自动化学院;
{Journal}: 辽宁石油化工大学学报
{Year}: 2022
{Volume}: 42
{Issue}: 01
{Pages}: 70-77
{Keywords}: 瑕疵检测;布料检测;目标识别;计算机视觉;图像处理
{Abstract}: 长久以来，布料的瑕疵检测工作一直由质检员完成，瑕疵判别过程受主观因素影响大,存在检测效率低、成本高等问题。随着计算机视觉技术的发展，基于视觉技术的布料瑕疵检测系统逐渐成为取代人工质检的重要解决方案。针对基于视觉技术的布料瑕疵检测，从行业发展情况、通用检测标准、系统整体结构、检测算法的关键技术等方面进行了综述，介绍了目前市面上已经存在的基于视觉技术的布料瑕疵检测产品，分析了目前常用的瑕疵检测标准与检测系统的基本结构，梳理并对比了近年来图像处理与深度学习技术在布料瑕疵检测领域的研究现状。最后，总结了各方面尚待解决的关键问题，并探讨了未来可能的发展方向。
{ISBN/ISSN}: 1672-6952
{Notes}: 21-1504/TE
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvytz0oIGQ_mcCovMLjY6ONGZYFJAdX-s0k7AxXJcMgdNnXUE0wTwHLy3aCnIpLW7n3HkATldhowCXJmz1AuISToZO5XK-9OU8IO3-R2JT-UZ7l5UCPjFgSPNjMVSn_p49PyaTbis5BtMiZOREJYV0M1aqGFAQ4Yqs5G-LWFEUy-98fqJ7lrw7b0ZMp9hnSYBKA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉：理论与应用专题序言
{Author}: 高新波;苗启广;公茂果;陶建华;孟德宇;夏勇
{Author Address}: 重庆邮电大学;西安电子科技大学;中国科学院自动化研究所;西安交通大学;西北工业大学;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: 02
{Pages}: 1-3
{Abstract}: <正>计算机视觉技术是人工智能技术的重要组成部分,也是计算机科学与信号处理研究的前沿领域。计算机视觉经过近年来的不断发展,在交通、医学、工业等多个领域得到了广泛应用。我国计算机视觉领域的研究者众多,研究成果在国际上具有很大的影响力,及时、集中、全面地报道计算机视觉相关理论、应用实践的最新成果与进展,以便研究人员快速、系统地了解新技术的发展动态和脉络,是策划本次专题的初衷。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvytz0oIGQ_mcCovMLjY6ONGZYFJAdX-s0lN0VWm72RGpDiCzqBYkrPx3gw7U4JEbfiCdPblg5A2iHyDevvNsLPMFEHxN1k79mtEiLultYSfxHE1I_9ruKvSvM2KvkzbpJN5ThuFWGcCLzP-227p1dqPDhwBQoR876DC1mVx5wrOoaVq3PW1b9-22CVkGridVIE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于相位光流法的结构振动微小位移测量
{Author}: 王浩林;刘源;王芸
{Author Address}: 长安大学信息工程学院;
{Journal}: 计算机系统应用
{Year}: 2022
{Volume}: 31
{Issue}: 02
{Pages}: 358-365
{Keywords}: 位移测量;计算机视觉;基于相位的光流;运动放大
{Abstract}: 随着数码相机的成本降低和普及,基于计算机视觉的非接触式结构健康监测技术越来越受到重视.传统的接触式测量仪器可能导致轻质结构上的质量负荷,并且在大型土木结构上安装和维护成本高且耗时,特别是对于长期应用.作为一种替代的非接触方法,使用数码相机的计算机视觉方法成本相对较低、灵活.针对传统光流方法在微小位移测量精度和稳定性不足的问题,本文提出了一种改进的基于相位的光流法来计算结构的振动位移.在这种方法中,通过引入基于相位的视频运动放大方法中构造的部分复数可操纵滤波器,与视频序列图像的卷积得到结构的局部空间相位信息.接着通过基于相位的光流法计算结构振动的像素位移.最后通过降噪处理和比例因子法将像素位移转换为真实位移.实验室简支梁振动实验结果证明,本文的方法相比于其他光流方法在微小位移计算上具有更高的精确度和稳定性.
{ISBN/ISSN}: 1003-3254
{Notes}: 11-2854/TP
{URL}: https://link.cnki.net/doi/10.15888/j.cnki.csa.008439
{DOI}: 10.15888/j.cnki.csa.008439
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于结构光视觉和光照模型的焊缝表面质量检测
{Author}: 余佳杰;周建平;薛瑞雷;许燕;夏磊
{Author Address}: 新疆大学机械工程学院;
{Journal}: 中国激光
{Year}: 2022
{Volume}: 49
{Issue}: 16
{Pages}: 170-178
{Keywords}: 激光技术;焊缝表面质量检测;图像处理;光照模型;机器视觉
{Abstract}: 为实现焊缝表面质量的自动检测，本团队设计了一种焊缝表面质量自动检测方法。首先对焊缝图像进行处理，提取出焊缝的中心线，并通过最小二乘法和K均值聚类算法提取焊缝特征点，进一步测量得到熔宽、余高等焊接参数；然后根据中心线数据建立三维光照模型，依据亮度的强弱与分布设立亮度特征，并根据亮度特征针对无缺陷焊缝以及咬边和气孔焊缝进行了识别。结果表明，所提焊缝表面质量检测方法对焊缝的自动识别准确率较高，而且稳定性高，效果好。
{ISBN/ISSN}: 0258-7025
{Notes}: 31-1339/TN
{URL}: https://link.cnki.net/urlid/31.1339.TN.20220211.1726.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于生成式对抗网络的图像修复研究进展
{Author}: 杨元英;王安志;何淋艳;任春洪;欧卫华
{Author Address}: 贵州师范大学大数据与计算机科学学院;
{Journal}: 计算机技术与发展
{Year}: 2022
{Volume}: 32
{Issue}: 02
{Pages}: 75-81+87
{Keywords}: 生成式对抗网络;图像修复;生成器;判别器;自编码器
{Abstract}: 图像修复是图像处理的一个重要问题，目的是利用计算机视觉技术自动恢复退化图像中损坏或丢失的部分，被广泛应用于影视特技制作、图像编辑、数字化文物保护等领域。近几年，以生成式对抗网络(GAN)为代表的深度学习技术在计算机视觉和图像处理领域大获成功，基于GAN的图像修复逐渐成为主流，受到了广泛关注。针对图像修复的关键问题，文章对GAN和基于GAN的修复方法进行理论分析，首先整理分析了传统的基于人工特征的经典图像修复方法，其次总结了近年来基于GAN的代表性图像修复算法，并进行归纳分类，探讨了各类方法的特点和局限性。然后对图像修复模型常用的评价指标和公开数据集进行整理和分析，最后阐述了图像修复面临的挑战，对图像修复技术未来的发展方向进行展望。
{ISBN/ISSN}: 1673-629X
{Notes}: 61-1450/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwnGIlYGKgQnsrAMhZAy2pBV5qGFo8tq43U6q8eg-peqqFeE1YRNSnAKwr73RrSTMOWUWj3vSD_20aywEa_SotE6Zz1OpE2yzTd43g3rANIAQ-IF-NQj6HgrHuXBK3G3i9-eemoKTnc-f_V4ob1ryx6iE7Pkhd-kVTgM_dAwqJzwWryl01R5Gx0173VMTkB8AI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉算法的图像处理技术研究
{Author}: 谢晓旦
{Author Address}: 无锡旅游商贸高等职业技术学校;
{Journal}: 无线互联科技
{Year}: 2022
{Volume}: 19
{Issue}: 03
{Pages}: 103-104
{Keywords}: 计算机视觉;数字图像处理;梨果检测分级
{Abstract}: 图像处理技术是在计算机技术不断发展过程中所衍生出的用途较为广泛的技术类型,将其用于水果检测分级当中,能够提升水果检测分级效率,优化水果检测分级标准,达到控制人工检测分级成本的目的,保障水果行业利润提升。文章从计算机视觉角度讨论数字图像处理方法,并以梨果检测分级作为数字图像处理研究对象,分析通过图像采集和预处理,提取梨果图像的特征,将各项数据传输到分级系统当中,最终达到检测水果等级的目的。
{ISBN/ISSN}: 1672-6944
{Notes}: 32-1675/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyAOZ4FFqQnAfVTFRylBBqIllybfLiYoxYZLv_-uMF6cMcEI-pM5r4vfbBiR3oFh8WVJPO_gN4DzhHT3dhrOVIqaLbn0XKtMS83PjAe2NRzPIX5_LvgZwf6H5e-6su-5zejrIqoyuYl_IIGL99GQSWFS-HQ8gFPjg-A5kctn5YQqQ3nlkt1xIRUJvBsBtpr4zM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Xception-TD的中华传统刺绣分类模型构建
{Author}: 周泽聿;王昊;张小琴;范涛;任秋彤
{Author Address}: 南京大学信息管理学院;江苏省数据工程与知识服务重点实验室;金陵图书馆;
{Journal}: 数据分析与知识发现
{Year}: 2022
{Volume}: 6
{Issue}: Z1
{Pages}: 338-347
{Keywords}: 数字人文;计算机视觉;迁移学习;Xception
{Abstract}: 【目的】将人工智能方法引入数字人文领域中，探讨如何解决中华传统刺绣图像分类背景下刺绣数据集较小、图像特征表示不足以及识别准确率不高等问题，为非物质文化遗产数字保护智能化提供方法支撑。【方法】将深度学习技术运用到刺绣图像上，利用图像处理技术提取其相应的特征，采用迁移学习的方法，对Xception模型进行微调改进，进而提出一种基于Xception-TD的中华传统刺绣分类模型，并探讨全连接层的数量与维度以及dropout取值对模型性能的影响。【结果】实验结果表明，针对中华传统刺绣分类的问题，通过微调的方法，发现提高全连接层数量以及增大全连接层维度可以得到更好的刺绣图像特征表示并产生更好的效果。基于Xception-TD中华传统刺绣模型准确率达到0.968 63，均优于基准模型。在进一步刺绣多分类的问题上，准确率也均优于基准模型。【局限】本文数据集仅来源于百度图片与少量人工标记，数据来源不够丰富。【结论】基于迁移学习，并结合微调能够有效提升刺绣分类的准确率。
{ISBN/ISSN}: 2096-3467
{Notes}: 10-1478/G2
{URL}: https://link.cnki.net/urlid/10.1478.G2.20220125.1801.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的室内定位系统设计与实现
{Author}: 周字辉;朱晓强;曾丹
{Author Address}: 上海大学通信与信息工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 02
{Pages}: 43-47
{Keywords}: 无感知;室内定位;计算机视觉;投影变换
{Abstract}: 现在传统的室内定位技术大多需要在被定位物体上安装标签或者终端设备，在一些特定场合存在很大的局限性。为此提出了一种基于计算机视觉的室内定位系统。该系统通过目标检测算法检测出特定物体并获取其图像坐标，经过目标点判定算法判断该物体是否在待定位区域内，最后通过投影变换算法获取到该物体对应的地图坐标。在被定位物体无感知的情况下，完成对其定位且定位误差在1 m以内。为了方便用户直观地观察，采用网页的形式，将实际地图与物体位置显示在终端设备上。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2107977
{DOI}: 10.19651/j.cnki.emt.2107977
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的轮胎表面缺陷检测系统的研究与应用
{Author}: 孙贺;刘胜波;冷于浩;刘默嘉;丁涵
{Author Address}: 青岛中导辰远智能科技有限公司;
{Journal}: 工业控制计算机
{Year}: 2022
{Volume}: 35
{Issue}: 01
{Pages}: 29-30+34
{Keywords}: 机器视觉;轮胎;图像采集;缺陷分析;检测系统
{Abstract}: 在传统的轮胎表面缺陷依靠人工检测,存在劳动强度高、受人的主观影响大以及效率低下的问题。针对这一现象,研究了一种基于机器视觉的轮胎表面缺陷3D检测系统。该系统依靠机器视觉系统获取检测轮胎的表面图像,然后创建3D模型、判定缺陷类型,最终实现实时自动预警,为轮胎生产商提供一种自动化检测方案。系统集成了先进的技术、软件和工具,配套的信息管控系统可以对轮胎型号和生产数据进行采集、存储、分析,以便在生产过程中实现更高效、更可靠的质量控制,具有较高的实际应用推广价值。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzhhY4VsMflg8oNGiMSHwRB5ftQ4EfHYYVIZEfoBbm2RZp1nM7zHJI8Y3r5TnhjrsGua68eIwwBnhQOulHbYm-gfKYvh0zCr5VgW_7yCYpOA_ZvZMVwAmQmpyKSD-dGeglY0Pe7j0hdImxwBGihUQGY1_BX2BmC0D3QZpcFKT7okQYYK3B_sOHiv6feMfujcBQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的动态环境运动目标智能识别研究
{Author}: 徐尉豪
{Author Address}: 郑州大学;安东大学;
{Journal}: 激光杂志
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 29-32
{Keywords}: 运动目标;动态环境;自动识别;机器视觉;测试平台;识别误差
{Abstract}: 运动目标自动识别是当前的一个重要研究课题,当前运动目标识别方法存在耗时长、效率低、准确性差等缺陷,为了解决当前动态环境运动目标识别过程存在的缺陷,提高运动目标识别正确率,提出了基于机器视觉的动态环境运动目标自动识别方法。首先研究了运动目标识别进展,分析运动目标识别效果不理想的原因,然后引入机器视觉技术提取运动目标识别的特征向量,并对特征向量进行归一化处理,最后采用机器学习算法根据特征向量进行运动目标识别的分类器,并在Matlab 2019平台上实现运动目标自动识别实验。静态环境中基于机器视觉的运动目标识别正确率和拒识率分别为96.73%和3.27%,动态环境中识别正确率和拒识率分别为93.8%和6.58%,静态环境中识别耗时最高为3.58 s,动态环境中为5.79 s,相对同类运动目标自动识别方法,本方法的运动目标自动识别效果更优,验证运动目标自动识别方法的优越性。
{ISBN/ISSN}: 0253-2743
{Notes}: 50-1085/TN
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.jgzz.2022.01.029
{DOI}: 10.14016/j.cnki.jgzz.2022.01.029
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和激光雷达的车辆智能导航系统
{Author}: 盛鸿宇;王飞
{Author Address}: 北京联合大学机器人学院;河北工业大学电子信息工程学院;
{Journal}: 激光杂志
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 169-173
{Keywords}: 机器视觉;激光雷达;车辆智能导航系统;系统设计
{Abstract}: 常规的车辆智能导航系统无法准确计算其与前方障碍物之间的距离,因此,基于机器视觉和激光雷达设计了车辆智能导航系统。在车辆智能导航系统的硬件设计中,设计视觉传感芯片外围电路,配置视觉传感芯片电路元件参数,保障视觉传感装置的稳定运行,设计激光雷达温度补偿装置,保证激光雷达装置的电路稳定。在车辆智能导航系统的软件设计中,去除图像噪声,转换运动中的图像数据,设计车辆智能导航算法。设计实验测试该系统的视觉智能,在与常规三种系统的对比中,该系统可以在距障碍物约1.12 m时转弯,而常规的三种系统在障碍物前约1.61 m、1.63 m和1.76 m时就必须转弯,设计的导航系统减少了车辆的行驶距离。由此可见,该系统实现了车辆智能导航系统对机器视觉的优化。
{ISBN/ISSN}: 0253-2743
{Notes}: 50-1085/TN
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.jgzz.2022.01.169
{DOI}: 10.14016/j.cnki.jgzz.2022.01.169
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人自动分拣系统设计
{Author}: 刘黎明;王雪斌
{Author Address}: 贵州水利水电职业技术学院;
{Journal}: 自动化应用
{Year}: 2022
{Issue}: 01
{Pages}: 97-100
{Keywords}: 机器视觉;工业机器人;自动分拣系统
{Abstract}: 经济的发展推动了我国工业自动化进步,自动分拣是工业自动化中的一部分,传统的工业机器人自动分拣系统的分拣精确度较低,无法满足目前的工业化生产需求,因此基于机器视觉设计了新的工业机器人自动分拣系统。硬件部分设计了CCD图像采集器和运动控制卡,软件部分首先处理了工业机器人自动分拣图像,其次基于机器视觉识别了自动分拣工件类型,最后设计了工业机器人自动分拣程序,实现了工业机器人自动分拣。进行系统测试的结果表明,设计的工业机器人自动分拣系统的分拣精确度高,分拣效果较好,具有有效性,有一定的应用价值,可以作为后续工业机器人自动分拣研究的参考。
{ISBN/ISSN}: 1674-778X
{Notes}: 50-1201/TP
{URL}: https://link.cnki.net/doi/10.19769/j.zdhy.2022.01.026
{DOI}: 10.19769/j.zdhy.2022.01.026
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的红枣外部品质检测技术研究进展
{Author}: 李聪;李玉洁;李小占;喻国威;刘鑫;马本学
{Author Address}: 石河子大学机械电气工程学院;农业农村部西北农业装备重点实验室;
{Journal}: 食品工业科技
{Year}: 2022
{Volume}: 43
{Issue}: 20
{Pages}: 447-453
{Keywords}: 机器视觉;红枣;外部品质;检测技术
{Abstract}: 近年来，具有快速、准确、客观和无损等特点的机器视觉技术已经被广泛用于农产品外部品质检测，以解决人工检测中存在的人力成本高、标准不统一和效率低等问题。在红枣加工和销售过程中，外部特征是影响其品质的重要因素，快速准确地对红枣外部品质检测能有效保障食品品质及安全、提高企业生产效率。本文综述了机器视觉技术在红枣外部品质检测中的应用，针对缺陷、大小、纹理、颜色和综合外部品质等指标总结了机器视觉检测方法的特点、存在的问题并阐明了其发展趋势，为我国红枣高效、快速检测分级装备的研发提供参考。
{ISBN/ISSN}: 1002-0306
{Notes}: 11-1759/TS
{URL}: https://link.cnki.net/doi/10.13386/j.issn1002-0306.2021090322
{DOI}: 10.13386/j.issn1002-0306.2021090322
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的列车部件故障诊断方法综述
{Author}: 刘子仪;李兆新;陈建强;李书盼;陆其波;宋威宏
{Author Address}: 西南交通大学电气工程学院;华南理工大学电子与信息学院;广州地铁集团有限公司;
{Journal}: 计算机应用与软件
{Year}: 2022
{Volume}: 39
{Issue}: 01
{Pages}: 1-9+52
{Keywords}: 机器视觉;列车部件故障诊断;图像配准;故障检测;3D检测
{Abstract}: 基于机器视觉的列车部件故障诊断方法提高了人工巡检的速度和准确率,是近年来机器视觉技术的研究热点之一。通过对机器视觉技术在列车故障诊断方面的研究成果的回顾,对其中的图像配准和故障诊断等关键技术进行综述,总结相关原理、优缺点、国内外发展现状。3D技术的发展为列车故障诊断提供了新的研究方向。对3D检测技术的原理及其在列车部件故障诊断方面的应用进行详细介绍。对目前列车部件故障诊断研究中存在的问题和未来发展趋势进行总结和展望。
{ISBN/ISSN}: 1000-386X
{Notes}: 31-1260/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxLu-d4T-chloaDmfzYTmBd4oSrUUpLK77W0_A-oW_iLyaHGzIEyFcPcfz7eF5sTlHn7LVZJ51uVgDf4JtAHX9KqOy8h5rimodjQf8v7Cm1iWIQY66aP8b3Lfa--V-BUbRBfX25jBWeTiUGMo58PxlVQeKLKkbeL21PTLcSHOPXHieG78erc8zlw6o6GzRqTLU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于光电检测技术的电缆表面缺陷实时监测系统研究
{Author}: 刘秀婷
{Author Address}: 无锡学院理学院;
{Journal}: 信息技术与网络安全
{Year}: 2022
{Volume}: 41
{Issue}: 01
{Pages}: 69-74
{Keywords}: 电缆表面缺陷;实时监测;机器视觉;图像处理
{Abstract}: 基于光电检测技术开发了电缆表面缺陷实时监测系统。在硬件结构方面,系统采用半环形LED白光源照射电缆,利用线阵CCD相机采集电缆表面图像。在软件算法方面,提出一种改进的ROI (Region of Interest)算法精确定位电缆区域,利用一种基于改进双边滤波的图像差分算法建立背景模型,改进一种基于CV-Kmeans区域分类自适应滤波窗口算法来凸显电缆表面缺陷特征。研究结果表明,基于光电检测技术研发的电缆表面缺陷实时监测系统的识别能力较高,整体监测准确率不低于97.0%。
{ISBN/ISSN}: 2096-5133
{Notes}: 10-1543/TP
{URL}: https://link.cnki.net/doi/10.19358/j.issn.2096-5133.2022.01.011
{DOI}: 10.19358/j.issn.2096-5133.2022.01.011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv3-Tiny的番茄苗分级检测
{Author}: 张秀花;静茂凯;袁永伟;尹义蕾;李恺;王春辉
{Author Address}: 河北农业大学机电工程学院;河北省智慧农业装备技术创新中心;农业农村部规划设计研究院设施农业研究所;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 01
{Pages}: 221-229
{Keywords}: 机器视觉;图像处理;穴盘育苗;幼苗分级;目标检测;YOLOv3-Tiny;自适应特征融合
{Abstract}: 为了提高番茄苗分选移栽分级检测精度，该研究提出了YOLOv3-Tiny目标检测改进模型。首先建立了番茄穴盘苗数据集，使用K-means++算法重新生成数据集锚定框，提高网络收敛速度和特征提取能力；其次为目标检测模型添加SPP空间金字塔池化，将穴孔局部和整体特征融合，提高了对弱苗的召回率；同时加入路径聚合网络（PANet），提升细粒度检测能力；引入了SAM空间注意力机制，提高对番茄苗的关注，减少背景干扰；增加了ASFF(Adaptively Spatial Feature Fusion)自适应特征融合网络，能够使目标检测模型对多个级别的特征进行空间滤波；采用CIoU损失函数策略，提高模型收敛效果。改进的YOLOv3-Tiny目标检测模型经过数据集训练，在测试集上能够达到平均精度均值为97.64%，相比YOLOv3-Tiny模型提高了3.47个百分点。消融试验验证了网络结构改进和训练策略是有效的，并将改进的YOLOv3-Tiny目标检测算法与5种目标检测算法进行对比，发现改进的YOLOv3-Tiny目标检测模型在重合度阈值为50%的条件下平均精度均值为97.64%。单张图像处理时间为5.03ms，较其他目标检测算法具有明显的优势，验证了该模型能够满足番茄苗分级检测精度要求，可以为幼苗分选检测方法提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwYwZ6Pkccs47EFsZ90nhOOtqQLx4rSaanpvJ2y2IG8QhezPQntzcuSdKmKk5GMRo268DsiUm3b65usGroMZM-7B6bwesoMfR0OJ-k4JfkeZlK9SFS_Cyq8uy3YGG1Vgi5hTYm0vPxgdqxKz-M7uCtfs16IitrnXE3Wt9mwx6UZpo2bIhpgQLyuL-UR-UG5LjI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向工业应用场景的深度学习缺陷检测方法研究
{Author}: 蒋羽
{Tertiary Author}: 赵春晖
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 缺陷检测;两阶段网络;无监督学习;特征重构;轻量化
{Abstract}: 缺陷检测是工业生产制造过程中不可或缺的关键环节,其检测的精度和速度将直接影响产品质量、生产效率和制造成本。随着工业4.0的提出,主观性强、效率低、精度差、成本高的人工检测方式逐渐被自动化检测方式所取代。而基于传统机器视觉的自动检测技术存在特征提取能力有限、实时性低、鲁棒性和环境适应性差等问题,已不能完全满足现代工业生产需求。近年来,飞速发展的深度学习技术为工业应用场景下的缺陷检测提供了新的解决思路。以卷积神经网络为代表的深度学习模型基于数据驱动的方式实现特征的自主学习,具有高效的特征提取能力以及强大的特征表达与泛化能力,在复杂的工业环境下具有更强的鲁棒性和更高的检测精度。本文开展了面向工业应用场景的深度学习缺陷检测方法研究,旨在提高模型对噪声的抗干扰性,降低对标注数据的依赖性以及实现模型轻量化设计。致力于解决工业应用场景下微小缺陷易受噪声干扰、训练数据不均衡且标注成本高、模型检测速度实时性不足等问题。具体研究内容如下:1.针对工业应用场景下微小缺陷的检测易受到复杂环境、纹理等噪声影响的问题,提出了一种基于分割分类两阶段网络的有监督缺陷检测方法,实现了对隐裂、划痕等微小缺陷的快速判别和精准分割。该方法的分割模块基于U-net分割网络进行架构改进,改进后的M型网络架构有效提升了模型对缺陷特征的学习和提取能力。并在跳跃连接处嵌入空间注意力模块,有效抑制环境噪声和纹理背景的干扰。该方法的分类模块基于迁移学习的思想,有效复用由分割模块编码器提取的多尺度特征,以实现缺陷的判别。所提方法有效解决了由于图像中缺陷像素和背景像素分布不均衡导致模型训练无效收敛的问题,仅需要少量缺陷标注样本进行有监督学习即可实现精准的缺陷检测。基于光伏组件数据集的实验验证了所提方法的有效性和优越性。2.针对工业应用场景下缺陷样本数据短缺、类型不确定性以及收集与标注成本高等训练数据问题,提出了一种基于卷积自编码器多尺度特征重构的无监督缺陷检测方法,有效弥补了有监督检测算法的局限性。该方法仅使用易于获得的正常样本数据进行训练,首先基于预训练网络提取图像的多级特征,然后进行多尺度特征融合得到深度特征,并基于所提的shuffle-CAE实现特征重构,最后通过深度特征的重构误差实现缺陷的判别和分割。实验结果表明,所提方法具有较好的通用性,在MVTec AD数据集的15类工业产品缺陷检测任务中均实现了较高精度的判别和分割。3.针对当前大多数基于重构和基于嵌入相似性的无监督模型在检测速度上较难满足工业应用场景下生产实时性需求的问题,提出了一种基于多级知识蒸馏的轻量化无监督缺陷检测方法。该方法基于多级特征匹配和通道对齐两种知识蒸馏策略,在师生网络的架构下实现由教师网络到学生网络的特征迁移,通过度量师生网络之间多级特征图的嵌入相似度误差实现快速高效的缺陷判别和分割。基于MVTec AD数据集的实验结果验证了所提方法在保证缺陷检测精度的同时,满足了工业检测实时性的需求。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.002054
{DOI}: 10.27461/d.cnki.gzjdx.2022.002054
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉系统中基于图像三维建模
{Author}: 陈红;谭明德;肖瑶;乔闹生
{Author Address}: 湖南文理学院国际学院;
{Journal}: 中国科技信息
{Year}: 2022
{Volume}: 
{Issue}: 01
{Pages}: 53+55
{Abstract}: 本文首先阐述了国内外学者对计算机视觉中基于图像建模的机理研究及其应用,提出该领域需要进一步探索与完善。在此基础上,简要地概述了计算机视觉系统中基于图像三维建模。首先论述了计算机视觉系统形成三维场景的机理,然后分析了基于计算机视觉系统的图像信息获取与整合的必要性,最后从三维场景提取变成目标物体、目标物体转化为三维模型两个方面论述了模拟计算机视觉过程的三维模型提取和转化。
{ISBN/ISSN}: 1001-8972
{Notes}: 11-2739/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyK5flfL29Zqr7q6fGduZ_EXCErHan7vbZwBlLTSIMjy7rtGpbudmWou7M2pbhw3SL6ROZlnkNWxtk5W2fBkbxBeTDjmEcXJL6o1TxPZY6BAexVsIHKIX6WnL9WI3nEzd28srpOCc0RTTlEOlAWaqHHNuAhySR-HdjDsyUYw8Zhhg5FIo2lGQpoz8jS7GQzZ-I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

 