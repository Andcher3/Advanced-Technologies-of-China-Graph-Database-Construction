{Reference Type}: Journal Article
{Title}: 深度学习下的单阶段通用目标检测算法研究综述
{Author}: 王宁;智敏
{Author Address}: 内蒙古师范大学计算机科学技术学院;
{Journal}: 计算机科学与探索
{Pages}: 1-32
{Keywords}: 目标检测;深度学习;计算机视觉;单阶段;YOLO;DETR
{Abstract}: 近年来，目标检测算法作为计算机视觉领域中的核心任务，逐渐成为热门研究方向。它使得计算机能够识别和定位图像或视频帧中的目标物体，广泛应用于自动驾驶、生物个体检测、农业检测、医疗影像分析等领域。随着深度学习的发展，通用目标检测算法从传统的目标检测方法转变为基于深度学习下的目标检测方法。其中深度学习下的通用目标检测算法主要分为单阶段目标检测与两阶段目标检测，本文以单阶段目标检测为切入点，根据采用经典卷积与Transformer两种不同架构，对首个单阶段目标检测算法YOLO系列（YOLOv1～YOLOv11、YOLO主要改进版本）、SSD等和以Transformer为基础架构的DETR系列的主流单阶段检测算法进行分析总结。主要包括介绍各个算法的网络结构以及其研究进展，根据各个算法的结构归纳出其特点优势以及局限性，概括目标检测领域主要通用数据集与评价指标，分析各算法以及其改进方法的性能，讨论各算法在不同领域的应用现状，最后展望单阶段目标检测算法在未来的研究方向。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.tp.20250117.2303.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度强化学习的视觉导航方法综述
{Author}: 高宇宁;王安成;赵华凯;罗豪龙;杨子迪;李建胜
{Author Address}: 信息工程大学地理空间信息学院;智慧中原地理信息技术河南省协同创新中心;智慧地球重点实验室;北京卫星导航中心;
{Journal}: 计算机工程与应用
{Pages}: 1-15
{Keywords}: 视觉导航;深度强化学习;样本效率;泛化;计算机视觉
{Abstract}: 传统的视觉导航方法对高精度地图的依赖性较高，且存在难以避免的误差积累问题，在面对复杂动态环境中的导航任务时往往表现不佳。基于深度强化学习的视觉导航方法通过模拟人类自身的导航方式，能够直接根据视觉信息以端到端的方式实现指定目标的安全导航，是视觉导航领域新兴的研究热点。为探讨深度强化学习视觉导航方向的最新研究问题，直观对比该方向最新方法，首先介绍了深度强化学习导航方法的背景和理论，然后聚焦近五年该方向的主要研究问题从数据利用、策略优化和场景泛化三个方面对重要方法进行了总结分析，最后给出了对于此类方法目前研究情况和未来研究问题的思考，在总结最新研究动态的同时为相关方法未来的研究提供参考。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20250102.1733.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的多视图立体视觉综述
{Author}: 樊铭瑞;申冰可;牛文龙;彭晓东;谢文明;杨震
{Author Address}: 中国科学院国家空间科学中心;中国科学院大学;国科大杭州高等研究院;
{Journal}: 软件学报
{Year}: 2025
{Issue}: 04
{Pages}: 1692-1714
{Keywords}: 深度学习;计算机视觉;三维重建;多视图立体视觉
{Abstract}: 多视图立体视觉在自动驾驶、增强现实、遗产保护和生物医学等领域得到广泛应用.为了弥补传统多视图立体视觉方法对低纹理区域不敏感、重建完整度差等不足,基于深度学习的多视图立体视觉方法应运而生.对基于深度学习的多视图立体视觉方法的开创性工作和发展现状进行综述,重点关注基于深度学习的多视图立体视觉局部功能改进和整体架构改进方法,深入分析代表性模型.同时,阐述目前广泛使用的数据集及评价指标,并对比现有方法在数据集上的测试性能.最后对多视图立体视觉未来有前景的研究发展方向进行展望.
{ISBN/ISSN}: 1000-9825
{Notes}: 11-2560/TP
{URL}: https://link.cnki.net/doi/10.13328/j.cnki.jos.007248
{DOI}: 10.13328/j.cnki.jos.007248
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Transformer的DETR目标检测算法研究综述
{Author}: 李沂杨;陆声链;王继杰;陈明
{Author Address}: 广西师范大学计算机科学与工程学院广西多源信息挖掘与安全重点实验室;广西师范大学教务处;
{Journal}: 计算机工程
{Pages}: 1-20
{Keywords}: 计算机视觉;目标检测;DETR算法;视觉Transformer;图像分割
{Abstract}: 目标检测领域中，卷积神经网络（CNN）长期占据主导地位，并以其准确性和可扩展性在学术界得到广泛认可。目标检测领域先后涌现出多个代表性模型，如R-CNN系列（包括FastRCNN、FasterRCNN等）和YOLO系列。随着Transformer在自然语言处理领域的成功，研究者开始探索将其用于计算机视觉，由此产生了如ViT和Swin-ViT等视觉骨干网络。2020年，Facebook团队为减少目标检测任务中的先验知识和后处理，推出了基于Transformer的DETR，一种端到端目标检测算法。尽管DETR在目标检测领域展现出潜力，但也存在诸如收敛速度慢、准确性较差、目标查询的物理意义不明确等缺点。这促使诸多研究人员对该算法开展了进一步的研究和改进。本文旨在分析整理总结针对DETR的改进探索，并分析他们的优势与不足，同时对利用DETR开展的前沿研究和细分应用领域进行概括，最后给出DETR在计算机视觉领域的未来展望。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0069312
{DOI}: 10.19678/j.issn.1000-3428.0069312
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多目标跟踪算法研究
{Author}: 胡瑞聪
{Tertiary Author}: 邱季
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;目标检测;行人重识别;卡尔曼滤波器
{Abstract}: 近年来,计算机视觉领域的研究取得了长足进展,多目标跟踪作为基础视觉任务之一,不仅需要检测视频序列中感兴趣的目标实例,还需要持续跟踪和维护其运动轨迹,这在诸如智能安防、智慧城市、自动驾驶等应用场景中具有重要价值。然而,真实场景下的视频数据往往存在目标遮挡、重叠、存在小目标等复杂情况,这为多目标跟踪任务带来了严峻挑战,迫切需要研究人员针对性地提出有效的解决方案。因此,本文针对上述多目标跟踪问题,开展了优化目标算法,改进跟踪时的匹配策略研究,主要工作内容如下:(1)为解决多目标跟踪过程中小目标对象跟踪失败的问题,在YOLOX算法的基础上,在特征融合阶段,采用来自4个不同尺度的特征层,涵盖从高分辨率到低分辨率的丰富特征信息。与此同时,通过采用上下文跳跃连接的方式,将深层次的语义特征与浅层次的细粒度特征进行有效融合,并融合坐标注意力机制,从而增强网络了对小目标对象的友好度。为了验证模型有效性,使用CrowdHuman图像数据集进行了实验,实验表明模型在各项指标中均取得优异的结果,说明了算法设计的有效性,有效解决了小目标对象跟踪失败的问题。(2)本文在已有基础上进一步提出一种以观测为核心融合重识别的多目标跟踪方法,当目标重叠发生身份切换时,采用基于目标外形的IoU匹配帮助目标正确匹配。并采用新的匹配策略,以观测为核心融合重识别,从而有效找回跟踪中丢失的目标,提升算法性能。为全面评估算法的性能,在权威的MOT17和MOT20数据集上进行了大量实验测试。实验结果表明,该算法在多项评估指标上均展现出优异表现,验证了算法设计的有效性。(3)采用本文提出的多目标跟踪算法设计并实现了一个公共场所人群智能监控系统,用于对公共场所人群进行智能监控。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2024.000048
{DOI}: 10.27035/d.cnki.ggxmc.2024.000048
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向深度学习的图像数据增强综述
{Author}: 杨锁荣;杨洪朝;申富饶;赵健
{Author Address}: 计算机软件新技术国家重点实验室(南京大学);南京大学计算机科学与技术系;南京大学人工智能学院;南京大学电子科学与工程学院;
{Journal}: 软件学报
{Year}: 2025
{Volume}: 36
{Issue}: 03
{Pages}: 1390-1412
{Keywords}: 深度学习;图像数据增强;图像识别;泛化性能;计算机视觉
{Abstract}: 深度学习已经在许多计算机视觉任务中取得了显著的成果.然而,深度神经网络通常需要大量的训练数据以避免过拟合,但实际应用中标记数据可能非常有限.因此,数据增强已成为提高训练数据充分性和多样性的有效方法,也是深度学习模型成功应用于图像数据的必要环节.系统地回顾不同的图像数据增强方法,并提出一个新的分类方法,为研究图像数据增强提供了新的视角.从不同的类别出发介绍各类数据增强方法的优势和局限性,并阐述各类方法的解决思路和应用价值.此外,还介绍语义分割、图像分类和目标检测这3种典型计算机视觉任务中常用的公共数据集和性能评价指标,并在这3个任务上对数据增强方法进行实验对比分析.最后,讨论当前数据增强所面临的挑战和未来的发展趋势.
{ISBN/ISSN}: 1000-9825
{Notes}: 11-2560/TP
{URL}: https://link.cnki.net/doi/10.13328/j.cnki.jos.007263
{DOI}: 10.13328/j.cnki.jos.007263
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的PCB缺陷检测算法研究综述
{Author}: 杨思念;曹立佳;杨洋;郭川东
{Author Address}: 四川轻化工大学计算机科学与工程学院;人工智能四川省重点实验室;企业信息化与物联网测控技术四川省高校重点实验室;四川轻化工大学自动化与信息工程学院;
{Journal}: 计算机科学与探索
{Pages}: 1-19
{Keywords}: PCB;缺陷检测;机器视觉;机器学习;深度学习
{Abstract}: 印刷电路板（Printed Circuit Board， PCB）作为电子产品的核心组成部分，其质量直接影响产品的可靠性。随着电子产品朝着更轻、更薄、更精密的方向发展，基于机器视觉的PCB缺陷检测面临诸如微小缺陷难以检测等挑战。为深入研究PCB缺陷检测技术，根据其发展历程对各阶段的算法进行了详细探讨。首先，指出了该领域面临的主要挑战，并介绍了传统PCB缺陷检测方法及其局限性。接着，从传统机器学习和深度学习两个角度系统回顾了近几年PCB缺陷检测所采用的方法及其优缺点。随后，对PCB缺陷检测算法常用的评价指标和主流数据集进行了归纳，并对近三年在PCB Defect、DeepPCB和HRIPCB三个数据集上的最新研究方法进行了性能比较，分析了产生差异化的原因。最后，基于当前现状和亟待解决的问题，对未来的发展趋势进行了展望，旨在为后续相关研究提供参考。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20241204.1549.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度神经网络在人体姿态估计中的应用综述
{Author}: 郝鹤菲;张龙豪;崔洪振;朱宵月;彭云峰;李向晖
{Author Address}: 北京科技大学计算机与通信工程学院;解放军总医院第八医学中心呼吸与危重症医学部;
{Journal}: 计算机工程与应用
{Pages}: 1-22
{Keywords}: 人体姿态估计;计算机视觉;深度神经网络;评价指标
{Abstract}: 人体姿态估计是计算机视觉领域的重要研究方向，在教育教学、临床诊断、人机交互等多场景均有重要应用。随着深度神经网络提出及发展，其以强大的特征学习能力、大规模并行处理等优势，广泛应用于人体姿态估计，并大幅提高估计结果准确度和识别效率。以人体姿态估计为研究对象，梳理近5年相关领域100余篇包含RNN、CNN、GAN、前沿网络模型等深度神经网络及其变体架构的代表性文献。此外，汇总梳理近5年常用数据集，并阐释模型常用评估指标。最后，总结现阶段人体姿态识别领域面临的挑战，并展望未来研究，以进一步探讨深度神经网络在人体姿态估计中的应用潜力。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20241122.0857.002
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于YOLO系列的目标检测研究进展综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2024年第二十八届网络新技术与应用年会论文集
{Author}: 杨子房;袁家政;徐成;姚登峰
{Author Address}: 北京联合大学北京市信息服务工程重点实验室;北京联合大学机器人学院脑与认知智能北京实验室;北京开放大学;
{Secondary Title}: 中国计算机用户协会网络应用分会2024年第二十八届网络新技术与应用年会
{Place Published}: 中国山东威海
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2024
{Pages}: 5
{Keywords}: 计算机视觉;目标检测;YOLO;单阶段;图像特征
{Abstract}: 目标检测是一项复杂的计算机视觉任务,涉及从图像或视频中识别和定位多个目标。目标检测在许多领域都有广泛的应用。由于其广泛的应用和最近的技术突破,研究人员对目标检测不断进行深入研究,并提出了很多目标检测模型。目标检测方法分为3类:基于手工设计的特征的方法、基于传统机器学习分方法和基于深度学习的方法。而基于深度学习的目标检测又分为单阶段和两阶段两种算法。主要介绍单阶段的目标检测模型YOLO系列,概括了YOLO系列模型的发展历史及其特点和不足之处,并提到了一些现在模型在一些特定场景下检测效果差的问题。最后,针对目标检测模型现有的问题提出了一些改进策略,例如修改模型结构、改进损失函数等以提升模型的检测性能和精度。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2024.047826
{DOI}: 10.26914/c.cnkihy.2024.047826
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于无人机航拍的风力发电机叶片表面缺陷检测综述
{Author}: 宋晔;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2024
{Volume}: 45
{Issue}: 10
{Pages}: 1-25
{Keywords}: 无人机航拍;风力发电机叶片;缺陷检测;机器视觉;深度学习;数据集
{Abstract}: 风力发电在能源转型中占重要地位。风力发电机叶片是接收风能的关键部件，其缺陷检测是维持发电机运行的基本保障。无人机航拍与机器视觉的结合能有效检测叶片表面缺陷。本文综述了近年来基于无人机航拍的风力发电机叶片表面缺陷检测方法。首先概述了风力发电机叶片特点与缺陷分类。其次对比了4类风力发电机叶片表面缺陷检测方法，阐明了无人机航拍结合视觉检测方法的优势及技术流程。然后概述了基于传统图像处理与机器学习的航拍叶片表面缺陷检测方法，包括表面图像拼接、缺陷的分割和特征提取与分类方法。综述了基于深度学习的航拍叶片表面缺陷检测方法，包含缺陷分类、识别与分割的深度学习网络。随后梳理了叶片表面缺陷数据集以及性能评价指标。最后指出该领域面临的挑战并对其解决方法进行了展望。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2413145
{DOI}: 10.19650/j.cnki.cjsi.J2413145
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于卷积神经网络的农作物病虫害检测研究进展
{Author}: 蔡国庆;吴建军;祝玉华;甄彤;李智慧;连一萌
{Author Address}: 河南工业大学信息科学与工程学院;
{Journal}: 山东农业科学
{Year}: 2024
{Volume}: 56
{Issue}: 11
{Pages}: 170-180
{Keywords}: 农作物病虫害检测;卷积神经网络;深度学习;计算机视觉
{Abstract}: 农作物病虫害是全球农业生产的严重威胁之一，易造成巨大的经济损失。引入机器视觉和机器学习方法进行农作物病虫害检测，不仅可以提高病虫害检测的效率，而且有助于及时采取防治措施，降低损失。卷积神经网络(CNN)作为深度学习的代表技术之一，在计算机视觉领域的图像识别、物体识别等方面应用广泛，在农作物病虫害检测方面也取得了一些成果。本文概述了基于CNN检测农作物病虫害的技术要点、发展历程，综述了该技术的主要研究方向与进展，总结了目前研究中存在的主要问题并提出相应的解决策略，旨在为CNN在农业上的应用提供理论依据，并为农业生产管理的智能化提供技术支撑。
{ISBN/ISSN}: 1001-4942
{Notes}: 37-1148/S
{URL}: https://link.cnki.net/doi/10.14083/j.issn.1001-4942.2024.11.023
{DOI}: 10.14083/j.issn.1001-4942.2024.11.023
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉对抗攻击研究综述
{Author}: 秦颖鑫;张可佳;潘海为;巨亚昊
{Author Address}: 计算机科学与技术学院哈尔滨工程大学;
{Journal}: 计算机工程
{Pages}: 1-29
{Keywords}: 深度学习;计算机视觉;对抗攻击;数字域;物理域;对抗样本
{Abstract}: 深度学习引领人工智能蓬勃发展，被广泛用于计算机视觉，在图像识别，目标检测，目标跟踪，人脸识别等复杂任务上取得了突破性进展和显著的成果，展现出其卓越的识别和预测能力。但深度学习模型的脆弱性和漏洞也逐渐暴露，以卷积神经网络为代表的深度学习技术对精心设计的对抗样本极为敏感，容易对模型的安全性和隐私性造成影响。文中首先总结了对抗攻击的概念，对抗样本产生的原因以及相关术语；概述了数字域和物理域中几类经典的对抗攻击策略，对其优缺点进行了分析；其次，专注计算机视觉，从数字域和物理域两个方面，分别总结了目标检测，人脸识别，目标跟踪，单目深度估计，光流估计中对抗攻击的最新研究进展以及常用于研究的各种数据集；并简单介绍了现阶段对抗样本的防御和检测方法，归纳了对抗样本防御和检测方法的优缺点，阐述了不同视觉任务对抗样本防御的应用实例；最终，基于对抗攻击方法的总结，探索并分析了现有计算机视觉对抗攻击的不足和挑战。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0069826
{DOI}: 10.19678/j.issn.1000-3428.0069826
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 小型无人机视觉传感器避障方法综述
{Author}: 王家亮;董楷;顾兆军;陈辉;韩强
{Author Address}: 中国民航大学计算机科学与技术学院;中国民航大学信息安全测评中心;中国民用航空局空中交通管理局航空气象中心;
{Journal}: 西安电子科技大学学报
{Year}: 2025
{Volume}: 52
{Issue}: 01
{Pages}: 60-79
{Keywords}: 无人机;避障传感器;计算机视觉;事件相机
{Abstract}: 无人机自主飞行避障技术是无人机安全飞行和应用中最为基础和关键的技术，也是当前无人机领域的研究热点。随着深度学习在计算机视觉方向的应用，以及事件相机等视觉传感器技术的迅速发展与不断完善，基于视觉传感器的无人机自主飞行避障方法取得一定的进步，但目前有些研究方法在复杂场景下仍存在很大的挑战以及存在一些列亟待解决的问题，在精准性、实时性以及算法鲁棒性方面仍有改进空间。首先介绍无人机避障的相关概念及问题难点；然后将基于视觉传感器的避障算法根据采用的硬件及技术手段，具体划分为传统避障方法、基于深度学习避障方法、基于处理事件流的避障方法、基于传感器融合避障方法，和基于视觉避障的决策层避障方法，并分别介绍每类避障方法相关研究进展与研究成果，以及分析各类避障方法的优缺点；最后总结现有无人机避障算法存在的问题，并对未来研究工作进行展望。
{ISBN/ISSN}: 1001-2400
{Notes}: 61-1076/TN
{URL}: https://link.cnki.net/doi/10.19665/j.issn1001-2400.20241008
{DOI}: 10.19665/j.issn1001-2400.20241008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于RGB与骨骼数据的人体行为识别综述
{Author}: 李仝伟;仇大伟;刘静;逯英航
{Author Address}: 山东中医药大学医学信息工程学院;
{Journal}: 计算机工程与应用
{Pages}: 1-26
{Keywords}: 行为识别;计算机视觉;RGB数据;骨骼数据;特征提取;深度学习
{Abstract}: 人体行为识别是计算机视觉领域中的重要研究方向，在人机交互、医疗康复、自动驾驶等领域具有广泛应用和重大意义。由于其方法的重要性和前沿性，对该领域进行全面、系统地总结具有极其重要的意义。本文深入探讨了基于RGB和骨骼数据模态的人体行为识别方法。按照特征学习方式的不同，分为基于传统机器学习的手工特征提取方法和基于深度学习的深度特征提取方法。首先，介绍了行为识别的基本流程，并总结了公开数据集。然后，详述了基于RGB和骨骼数据模态的识别方法。对于RGB数据，分析了基于2D CNN、RNN和3D CNN的特征提取方法。对于骨骼数据，介绍了自上而下和自下而上的姿态评估算法，重点分析了基于RNN、CNN、GCN、Transformer和混合神经网络的分类算法。最后，展望了未来深度学习在人体行为识别中的五个研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20241024.1414.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的基础设施表面裂纹检测方法研究进展
{Author}: 胡翔坤;李华;冯毅雄;钱松荣;李键;李少波
{Author Address}: 贵州大学公共大数据国家重点实验室;清华大学机械工程系;浙江大学流体动力基础件与机电系统全国重点实验室;
{Journal}: 计算机工程与应用
{Year}: 2025
{Volume}: 61
{Issue}: 01
{Pages}: 1-23
{Keywords}: 结构健康监测;裂纹检测;计算机视觉;深度学习
{Abstract}: 民用基础设施在长期使用后容易发生物理结构或性能状态的改变，对其功能和使用安全造成一定的损害，因此，对这类设施的结构健康监测是十分必要的。裂纹检测是结构健康监测中极其重要的一部分，及时检测并识别这类损伤，能有效避免事故的发生。基于计算机视觉的表面裂纹检测方法操作简单、检测速度快、准确率高，被广泛应用于民用基础设施的表面裂纹检测。从图像分类、目标检测、语义分割三个不同的检测方向综述了基于深度学习的基础设施表面裂纹检测方法，总结了常见的数据采集方法和常用的公共裂纹数据集。最后讨论了基于深度学习的基础设施表面裂纹检测方法存在的困难与挑战，并展望了未来可能的发展方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20241017.1318.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉Transformer(ViT)发展综述
{Author}: 李玉洁;马子航;王艺甫;王星河;谭本英
{Author Address}: 桂林电子科技大学人工智能学院;广西高校人工智能算法工程重点实验室(桂林电子科技大学);
{Journal}: 计算机科学
{Year}: 2025
{Volume}: 52
{Issue}: 01
{Pages}: 194-209
{Keywords}: 计算机视觉;模式识别;Vision Transformer(ViT);深度学习;自注意力
{Abstract}: 视觉Transformer(Vision Transformer, ViT)是基于编码器-解码器结构的Transformer改进模型，已经被成功应用于计算机视觉领域。近几年基于ViT的研究层出不穷且效果显著，基于该模型的工作已经成为计算机视觉任务的重要研究方向，因此针对近年来ViT的发展进行概述。首先，简要回顾了ViT的基本原理及迁移过程，并分析了ViT模型的结构特点和优势；然后，根据各ViT变体模型的改进特点，归纳和梳理了基于ViT的主要骨干网络变体改进方向及其代表性改进模型，包括局部性改进、结构改进、自监督、轻量化及效率改进等改进方向，并对其进行分析比较；最后，讨论了当前ViT及其改进模型仍存在的不足，对ViT未来的研究方向进行了展望。可以作为研究人员进行基于ViT骨干网络的研究时选择深度学习相关方法的一个权衡和参考。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20241012.1011.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向无人机航拍图像的目标检测研究综述
{Author}: 李琼;考月英;张莹;徐沛
{Author Address}: 北京市科学技术研究院信息与人工智能技术研究所;中国科学院自动化研究所智能系统与工程研究中心;
{Journal}: 图学学报
{Year}: 2024
{Volume}: 45
{Issue}: 06
{Pages}: 1145-1164
{Keywords}: 无人机航拍图像;深度学习;计算机视觉;目标检测;多尺度目标
{Abstract}: 随着无人机和计算机视觉技术的快速发展与深度融合，面向无人机航拍图像的目标检测研究受到越来越多的关注，已广泛应用于精准农业、动物监测、城市管理、应急救援等领域。与普通视角下拍摄的图像相比，无人机航拍图像具有视野更广、目标尺寸显著缩小、视角和尺度灵活多变等特点，无法完全适用普通视角下的目标检测方法。基于此，首先详细回顾了普通视角下目标检测方法的研究进展，包括传统方法、深度学习方法和基于大模型的方法，随后综述了现有目标检测方法针对无人机航拍图像目标检测中的图像质量下降、尺度和视角变化、小目标检测难度大、复杂背景及遮挡、大视场中的不均衡，以及实时性要求高等6大难点问题提出的创新策略和优化方法。此外，归纳总结了无人机航拍图像目标检测数据集，并在2个具有代表性的数据集上对现有方法进行性能分析。最后，根据无人机航拍图像目标检测领域仍存在的问题，展望了未来可能的研究方向，为无人机航拍图像目标检测的发展和应用提供参考。
{ISBN/ISSN}: 2095-302X
{Notes}: 10-1034/T
{URL}: https://link.cnki.net/urlid/10.1034.T.20241011.1317.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉-语言预训练模型的零样本迁移学习方法综述
{Author}: 孙仁科;许靖昊;皇甫志宇;李仲年;许新征
{Author Address}: 中国矿业大学计算机科学与技术学院;矿山数字化教育部工程研究中心;
{Journal}: 计算机工程
{Year}: 2024
{Volume}: 50
{Issue}: 10
{Pages}: 1-15
{Keywords}: 零样本学习;视觉-语言预训练模型;零样本迁移;多模态;计算机视觉
{Abstract}: 近年来随着人工智能(AI)技术在计算机视觉与自然语言处理等单模态领域表现出愈发优异的性能，多模态学习的重要性和必要性逐渐展现出来，其中基于视觉-语言预训练模型的零样本迁移(ZST)方法得到了国内外研究者的广泛关注。得益于预训练模型强大的泛化性能，使用视觉-语言预训练模型不仅能提高零样本识别任务的准确率，而且能够解决部分传统方法无法解决的零样本下游任务问题。对基于视觉-语言预训练模型的ZST方法进行概述，首先介绍了零样本学习(FSL)的传统方法，并对其主要形式加以总结；然后阐述了基于视觉-语言预训练模型的ZST和FSL的区别及其可以解决的新任务；其次介绍了基于视觉-语言预训练模型的ZST方法在样本识别、目标检测、语义分割、跨模态生成等下游任务中的应用情况；最后对现有的基于视觉-语言预训练模型的ZST方法存在的问题进行分析并对未来的研究方向进行展望。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0070036
{DOI}: 10.19678/j.issn.1000-3428.0070036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的车辆检测方法研究进展
{Author}: 游昊;吕文涛;叶丹;邓志江
{Author Address}: 浙江理工大学浙江省智能织物与柔性互联重点实验室;杭州数页科技有限公司;麦田能源股份有限公司;
{Journal}: 无线电工程
{Year}: 2025
{Volume}: 55
{Issue}: 02
{Pages}: 230-245
{Keywords}: 深度学习;车辆检测;计算机视觉;无锚点检测器;遥感图像;注意力机制
{Abstract}: 基于深度学习的车辆检测方法近年来取得了显著进展，深度学习模型的引入使得车辆检测在精度和效率方面取得了巨大的提升。针对车辆检测的难点进行了归纳概述；重点综述了目前应用于不同场景和其他因素影响下的基于深度学习的车辆检测方法，包括基于区域方法、基于单阶段方法和基于注意力机制方法等，对每种方法进行了整理介绍，分析所能解决的问题；对主流的车辆开源数据集和车辆检测的评价指标进行了介绍；对车辆检测算法已解决的问题和待改进的难点分别进行了总结；对后续的相关研究方向进行了展望，包括引入多模态信息、跨时空车辆检测等方面。将进一步推动基于深度学习的车辆检测技术的发展，使其在实际应用中发挥更大的作用。
{ISBN/ISSN}: 1003-3106
{Notes}: 13-1097/TN
{URL}: https://link.cnki.net/urlid/13.1097.TN.20240918.1541.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉检测技术在工业自动化领域的应用
{Author}: 刘振兴;寇爽
{Author Address}: 开封技师学院;
{Journal}: 造纸技术与应用
{Year}: 2024
{Volume}: 52
{Issue}: 03
{Pages}: 46-48
{Keywords}: 机器视觉;工业检测;自动化
{Abstract}: 机器视觉技术在工业检测和自动化领域中发挥着日益重要的作用。它通过模拟人类视觉系统，实现对产品尺寸、外形、表面缺陷的精确检测，以及装配位置的准确判断，从而提高产品质量控制的效率和精度。在工业自动化方面，机器视觉技术应用于自动分拣系统、机械臂的引导与控制，显著提升了生产效率和灵活性。未来，机器视觉技术将朝着智能化和多模态集成的方向发展，以满足更复杂和精确的工业需求。
{ISBN/ISSN}: 2097-2520
{Notes}: 23-1616/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxvTTEJ7dFPAPN7-9yPbELOCf_Ced9rsJr2ZbpCFTxnp9Hn5Z1pQ5zakzi12TrjGX_WVymHqBELth-63gzmHtYbuZkmZcl2o7wD2y7fiWQTjHTw9yS8Ip9AcrRK-PeelmqwZDW89YQg_oJiTBQmfdoxQK9BkwE0Z63cgd7m_PsnmO7mBzU3Wly7jzKPKGrGVrs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络与先验知识的钢铁材料金相图谱智能识别
{Author}: 王炫东
{Tertiary Author}: 孟惠民
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 金相组织;纹理分析;图谱识别;机器学习
{Abstract}: 钢铁材料的宏观力学性能受其微观组织的直接影响,从而使得微观组织的表征成为材料生产与研发的核心环节。金相分析作为一种常用的微观组织表征技术,随着计算机视觉技术特别是卷积神经网络的发展,其识别与解析工作正逐步从传统的依赖人工的半自动方法向更加智能化、定量化和高效化的方向发展。目前,钢铁材料微观组织图像的智能识别领域仍面临若干挑战。首先,缺乏高质量、高分辨率、种类齐全且标注完善的图谱数据库,限制了大规模数据挖掘的潜力;其次,现有的研究通常仅依赖于深度学习技术来实现固定的功能,不足以应对复杂的材料图谱识别场景,同时,知识驱动的先验经验与数据驱动的算法模型尚未得到有效的结合;再次,当前的深度学习建模方法通常仅是直接移植成熟的算法模型,而没有针对材料的组织纹理等特点进行必要的改造或创新;最后,现有的建模方法往往只针对单一批次、单一场景、单一类型的照片进行识别,还没有形成面向通用场景的系统化识别工作。本文针对这些问题,以钢铁材料的微观组织金相图谱为研究对象,借助材料学的先验知识,并基于卷积神经网络技术,探索了一种快速、便捷且可通用的金相智能识别与定量化表征方法体系,具体研究内容分为以下三方面:(1)针对当前图谱识别工作中尚未建立有效的标准数据库,以及缺乏先验知识指导的局限性,本工作设计并开发了基于金相图谱特征的材料匹配模型。首先通过收集、制作等方法构建了一套常见钢铁材料金相图谱数据库,并规定了图谱对应的数据结构,将材料体系、成分区间、热处理状态、组织信息描述等内容作为特征纳入到数据库中,为后续系统性数据挖掘提供数据基础。针对钢铁材料金相图谱的特点,提出了“组织纹理”的概念以及相应的基于深度学习的特征提取与特征匹配算法模型,可对新输入照片与数据库照片进行相似度匹配,并给出输入照片对应材料的成分、热处理工艺、组织描述等隐含信息,并为进一步的组织分割提供组织类别指导。使用了 4个不同成分体系的钢铁材料金相照片作为案例以验证方法的准确性,结果表明对材料体系与组织类别判断均正确。(2)针对当前金相图谱定量化统计所涉及的语义分割任务中,手动标记过程费时费力、每次建模仅能针对单一场景等瓶颈,本文针对钢铁材料金相图谱组织纹理在图像中的呈现特点,设计了无池化层的深度学习语义分割模型,经过多个案例验证其准确率高于目前常用的U-Net模型。在建模方面,提出了一套轻量化标注与快速建模方法,针对单一场景,经案例验证准确率高达96.92%,可在30分钟内完成建模,相比现有建模方法效率大大提高,需要人工参与的标注工作量显著降低。同时,开发了面向通用场景的组织纹理检测器方法,对数据库中并未出现过的复杂金相组织照片实现了 87.52%的分割准确率。(3)针对当前金相智能分析领域尚未形成系统化识别工作的研究现状,本工作通过GUI界面设计与实现,研发了一套钢铁材料金相图谱智能分析系统,为材料实验与科研人员提供了智能化辅助分析工具。首先开发了金相照片亮度均衡性调整的预处理算法,可有效解决视场内背景亮度不均衡造成的干扰问题。将已开发的材料匹配模型与通用场景的组织分割模型进行封装并在系统中部署。系统共包含图像导入、材料匹配、组织分割、图谱上传、结果纠错、一键报告六大功能模块。使用两个复杂的铁素体-珠光体-贝氏体组织案例对系统进行测试验证。结果表明系统各功能均能正常运行,在与用户交互过程中能够不断学习与自我迭代,经学习后对复杂案例照片的分割准确率达到了 81.77%,在另一案例中对上贝氏体的识别结果与专家标注结果基本一致,证明了系统智能分析结果的有效性。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2024.000470
{DOI}: 10.26945/d.cnki.gbjku.2024.000470
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机械臂抓取系统设计
{Author}: 张孟旭;高向川;尹丽楠;王建辉
{Author Address}: 郑州大学信息工程学院;郑州慕速物联科技有限公司;
{Journal}: 计算机应用与软件
{Year}: 2024
{Volume}: 41
{Issue}: 08
{Pages}: 22-27
{Keywords}: ROS;机器视觉;系统设计;机械臂抓取
{Abstract}: 以六自由度的Kinova机械臂和Realsense深度相机等硬件为基础，设计基于机器视觉的机械臂抓取系统。针对传统模板匹配法不具有旋转不变性的问题，将颜色识别算法应用于目标识别中。建立机器人系统参数化模型，对图像预处理并通过颜色识别算法得到目标的质心坐标，通过D-H参数法建立机械臂运动学模型，利用逆运动学求解出关节角度进而完成抓取。通过实验数据表明，该系统具有较高的可行性。
{ISBN/ISSN}: 1000-386X
{Notes}: 31-1260/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy8yKIvoic5K5WGk4orMt9EsCXryzQHKUkKJnGrrBDQ8_lMFqP-AByY-yo_MQJN7dEUQKmd-G0eSJuct_z9t_G3RlyD4N68K4_XYabFzkIaDkrmPSRQQNoIlvEoPA6S3dMWqp8ydv8ZQCmwFzmSWOaLmR9gjS0bbBkYjQe4Zn_BgrcVSgjl_UIwTtxxA_D1GO4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像修复方法研究进展
{Author}: 陈文祥;田启川;廉露;张晓行;王浩吉
{Author Address}: 北京建筑大学电气与信息工程学院;建筑大数据智能处理方法研究北京市重点实验室;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 22
{Pages}: 58-73
{Keywords}: 图像修复;计算机视觉;深度学习
{Abstract}: 图像修复是通过算法或技术对受损或缺失的图像进行恢复和修复的过程，是计算机视觉领域的研究热点之一。梳理了近些年基于深度学习的图像修复方法的发展脉络，将其分为单模态图像修复方法和多模态图像修复方法。单模态图像修复方法分为基于卷积自编码的图像修复方法、基于GAN的图像修复方法、基于Transformer的图像修复方法和基于扩散模型的图像修复方法，而多模态图像修复方法分为基于文本引导的图像修复方法、基于音频引导的图像修复方法、基于视频引导的图像修复方法和基于多模态融合的图像修复方法。对比分析了各类方法的原理和优缺点，介绍了常用数据集和评价指标，评估了代表性方法在常用数据集上的性能表现，并对该领域目前存在的挑战和未来的发展方向进行了分析和展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20240802.1447.007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 目标检测综述：从传统方法到深度学习
{Author}: 郭虎升
{Author Address}: 山西大学算机与信息技术学院;计算智能与中文信息处理教育部重点实验室(山西大学);
{Journal}: 新兴科学和技术趋势
{Year}: 2024
{Volume}: 3
{Issue}: 02
{Pages}: 128-145
{Keywords}: 计算机视觉;深度学习;目标检测;技术演变
{Abstract}: 目标检测是计算机视觉领域中一个基础而富有挑战性的研究领域，近年来由于其广泛的应用前景，引起了学术界和工业界的极大关注。本文阐述了目标检测技术的历史进程和最新发展，尤其关注了从传统图像处理技术向基于深度学习模型的演进过程。文章详细探讨了深度学习时代的部分标志性算法，并评估了这些算法在实际场景中的表现和优势。本综述还深入分析了目标检测当前面临的一系列挑战，包括多尺度目标的检测、遮挡处理问题及满足实时处理的需求等。针对这些挑战，我们探讨了目前的解决策略以及未来的研究方向。最后，本文展望了目标检测技术的未来发展趋势，特别关注了如自监督学习和算法优化等前沿技术的潜在影响。
{ISBN/ISSN}: 2097-1486
{Notes}: 14-1408/N
{URL}: https://link.cnki.net/urlid/14.1408.N.20240918.0929.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向通用目标检测的YOLO方法研究综述
{Author}: 米增;连哲
{Author Address}: 内蒙古师范大学计算机科学技术学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 21
{Pages}: 38-54
{Keywords}: 深度学习;计算机视觉;目标检测;YOLO方法
{Abstract}: 作为深度学习时代首个单阶段目标检测算法，YOLO以其强大且独特的范式在计算机视觉领域掀起了一股热潮，并成为目标检测算法的里程碑式成果,至今为止仍是在速度与精度之间实现最佳平衡的典型算法，广泛应用于自动驾驶、智能视觉系统等工业领域。过去的八年里，在深度学习技术的驱动下，YOLO方法有了快速发展并对整个目标检测领域产生深远影响。从技术进化角度深入调查YOLO方法相关工作，对最初的YOLO v1到最新的YOLO v9与YOLO v10每一次迭代创新和贡献进行全面总结，根据不同时间节点的和技术的重大改进将YOLO方法分为早期基础YOLO、标准版本YOLO、标准改进YOLO和独特改进YOLO四部分，详细介绍每个时期改进方法的独特视角。此外，总结评估YOLO方法的数据集与指标，收集了不同版本YOLO、同一版本YOLO不同型号的详细实验结果，从宏观层面与微观层面归纳YOLO的发展变化，通过分析揭示各版本YOLO之间的开发框架、骨干网络架构、先验框使用情况等技术的差异和内在联系，强调了YOLO在速度与准确率之间平衡的重要性。最后通过系统的梳理，凝练YOLO方法未来的发展趋势。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20240705.1328.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向无人机自主着陆的视觉感知与位姿估计方法综述
{Author}: 马宁;曹云峰
{Author Address}: 南京航空航天大学航天学院;
{Journal}: 自动化学报
{Year}: 2024
{Volume}: 50
{Issue}: 07
{Pages}: 1284-1304
{Keywords}: 自主着陆;无人机;机器视觉;着陆场检测;位姿估计;信息融合
{Abstract}: 自主着陆技术是制约无人机(Unmanned aerial vehicle, UAV)自主性等级提升中极具挑战性的一项技术.立足于未来基于视觉的无人机自主着陆技术的发展需求,围绕其中的核心问题——着陆场检测与位姿估计,对近十年来国内外无人机自主着陆领域中基于视觉的着陆场检测与位姿估计方法研究进展进行总结.首先,在分析无人机自主着陆应用需求的基础上,指出机器视觉在无人机自主着陆领域的应用优势,并凝练出存在的科学问题;其次,按不同应用场景划分对着陆场检测算法进行梳理;然后,分别对纯视觉、多源信息融合的位姿估计技术研究成果进行归纳;最后,总结该领域有待进一步解决的难点,并对未来的技术发展趋势进行展望.
{ISBN/ISSN}: 0254-4156
{Notes}: 11-2109/TP
{URL}: https://link.cnki.net/doi/10.16383/j.aas.c230557
{DOI}: 10.16383/j.aas.c230557
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的景区智能垃圾桶设计
{Author}: 郑宜健;孟小源;申文元
{Author Address}: 山东科技大学机械电子工程学院;
{Journal}: 机械设计
{Year}: 2024
{Volume}: 41
{Issue}: S1
{Pages}: 43-50
{Keywords}: 机器视觉;垃圾分类;深度学习;卷积神经网络;智能垃圾桶
{Abstract}: 随着我国经济快速发展，人们的生活水平不断提高，假期出游成为了首选，进而导致了越来越多的景区垃圾的产生，引发很多问题。为了解决垃圾外溢污染、垃圾难以正确分类及无接触扔垃圾的问题，设计了一种可进行垃圾分类与满溢报警等功能的智能垃圾桶，主要包括硬件电路设计与垃圾识别模型。智能垃圾桶应用光电开关与推杆电机的配合，当人靠近时，光电开关控制推杆电机推动垃圾桶桶盖打开，通过计算选定了推杆电机的型号为LA-T8-12-15-100/155-64；运用超声波传感器检测桶盖与桶内垃圾的距离，距离小于设定的距离时，通过GSM短信报警模块进行短信通知；运用OpenMV来进行垃圾分类，使用不同的设备采集每一类垃圾的数据集来训练模型，最后，通过Softmax激励函数将分类值转换成概率值；为了避免数据集样本过少导致的过拟合现象，采取了迁移学习和数据增强的方法，该方法训练出来的模型在OpenMVIDE软件中进行仿真试验，识别准确率达到90%以上，结果表明，可以有效地进行垃圾分类。经过原型机测试以上功能均可实现。
{ISBN/ISSN}: 1001-2354
{Notes}: 12-1120/TH
{URL}: https://link.cnki.net/doi/10.13841/j.cnki.jxsj.2024.s1.007
{DOI}: 10.13841/j.cnki.jxsj.2024.s1.007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于卷积神经网络的人脸识别
{Author}: 刘航;孔维泽;牟卓晶;朱亚茹
{Author Address}: 华北电力大学;
{Journal}: 科学技术创新
{Year}: 2024
{Issue}: 14
{Pages}: 65-69
{Keywords}: 人脸识别;计算机视觉;卷积神经网络;深度学习
{Abstract}: 人脸识别是计算机视觉领域中的一项重要技术，具有广泛的应用场景，如安全监控、身份验证、社交网络等。本文采用深度学习技术提出了一种基于卷积神经网络（CNN）的人脸识别模型，通过训练大量的数据实现了人脸的高精度识别。本文首先详细描述了卷积神经网络模型的设计和实现过程。然后使用ReLU激活函数增加模型的非线性，通过反向传播算法进行实练，最后在公开人脸数据集上对模型进行训练和测试，达到了100%的正确率。实验结果表明，该模型在识别率、鲁棒性和泛化能力等方面都表现出了优异的性能。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxpWOxxa7nsl8INetoxaeHgRbzunJfJXE7xzirPFerUfxmOvrhhxv2u5dLb9N9u0OG7G244BqO83rbJnd3tpKivMB96UbNB9JUArfAYWVs1x5GdElQv5lSEWI3bCy84AeUCdXu6eBM2gLpVxBp5wPnNwOF_2N_N5Z9Jf21sBH630QOePtTYK6_3OqozbSgXlpk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的YOLO系列物体检测算法研究综述
{Author}: 毛少华;王文东
{Author Address}: 延安大学数学与计算机科学学院;
{Journal}: 延安大学学报(自然科学版)
{Year}: 2024
{Volume}: 43
{Issue}: 02
{Pages}: 88-95
{Keywords}: 物体检测;YOLO;计算机视觉;深度学习
{Abstract}: 随着深度学习的发展，YOLO物体检测算法成为计算机视觉领域的研究热点，因其优秀的检测速度和平均检测精度，在物体检测领域被广泛的应用。对YOLO算法的发展历程进行了详细的论述。首先，从网络结构入手，详细的总结并分析了YOLOv1-v8算法的原理，归纳了YOLO算法的损失函数以及每个版本的改进措施，对YOLO算法的应用场景进行了分类，主要分为农业、交通和工业三大类领域；其次，分析了YOLO物体检测算法常用的数据集；最后，针对YOLO算法的特点以及结合最新的相关文献，提出了YOLO物体检测算法未来的研究方向。
{ISBN/ISSN}: 1004-602X
{Notes}: 61-1230/N
{URL}: https://link.cnki.net/doi/10.13876/J.cnki.ydnse.230044
{DOI}: 10.13876/J.cnki.ydnse.230044
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 分割一切模型SAM的潜力与展望：综述
{Author}: 王淼;黄智忠;何晖光;卢湖川;单洪明;张军平
{Author Address}: 复旦大学计算机科学技术学院;中国科学院自动化研究所;大连理工大学信息与通信工程学院;复旦大学类脑智能科学与技术研究院;
{Journal}: 中国图象图形学报
{Year}: 2024
{Volume}: 29
{Issue}: 06
{Pages}: 1479-1509
{Keywords}: 通用人工智能(AGI);计算机视觉;图像分割;视觉基础模型;分割一切模型(SAM);大型语言模型(LLM)
{Abstract}: 随着基于对比文本—图像对的预训练（contrastive language-image pre-training,CLIP）方法或者模型、聊天生成预训练转换器（chat generative pre-trained Transformer,ChatGPT）、生成预训练转换器-4(generative pre-trained Transformer-4,GPT-4)等基础大模型的出现，通用人工智能（artificial general intelligence, AGI）的研究得到快速发展。AGI旨在为人工智能系统赋予更强大的执行能力，使其能够自主学习、不断进化，解决各种问题和处理不同的任务，从而在多个领域得到广泛应用。这些基础模型在大规模数据集上进行训练后，能够成功应对多样的下游任务。在这一背景下，Meta公司提出的分割一切模型（segment anything model,SAM）于2023年取得重要突破，在图像分割领域获得了优异的性能，以至于被称为图像分割终结者。其原因之一是，通过SAM数据引擎方法用三阶段采集的、包含1 100万图像和超过10亿掩码的分割一切—十亿（segment anything 1 billion,SA-1B）图像分割数据集，同时保证了掩码的品质和多样性，继续导致在分割领域的突破。在SAM开源后不久，科研人员提出了一系列改进的方法和应用。为了能全面深入了解分割一切模型的发展脉络、优势与不足，本文对SAM的研究进展进行了梳理和综述。首先，从基础模型、数据引擎和数据集等多个方面简要介绍了分割一切模型的背景和核心框架。在此基础上，本文详细梳理了目前分割一切模型的改进方法，包括提高推理速度和增进预测精度两个关键方向。然后，深入探讨分割一切模型在图像处理任务、视频相关任务以及其他领域中的广泛应用。这一部分详细介绍了模型在各种任务和数据类型上的卓越性能，突出其在多个领域的泛用性和发展潜力。最后，对分割一切模型未来的发展方向和潜在应用前景进行了深入分析和讨论。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxZxWFBXQIH7Tonozb-Hh5Ji778-gs-8U161KYGIgtLSmoPLutz6Ko2C4y2QESsLYTqrMm7IKiJUF99Nn_JaDyWtVvVX0A1QaCt306BV4MQ738_0aUnhWflQRwlhzPQ8x_cZPuI2tLAH--oHQZX36OEZd_UvhbxWTw5hg-z-aj08SYyBTBSXhNdaYfbBiugXKI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于ROS平台的视觉引导机械手抓取技术研究
{Author}: 王凯
{Tertiary Author}: 宫妍;Ren Di
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: ROS;深度学习;YOLO;机械手抓取;RRT
{Abstract}: 随着工业自动化和机器人技术的发展,机械手的抓取技术变得越来越重要。由于传统的抓取技术依赖于预先编程的固定模式,缺乏灵活性和适应性。本文在Robot Operating System（ROS）框架下开发一种基于机器视觉的机械手抓取技术。通过整合深度学习算法,提升算法对目标物体的检测和机械臂的抓取能力,有助于提高工业自动化水平,减少人工,增强工作效率。（1）考虑到实验室抓取环境较为理想,但实际工厂环境复杂多变,构建一个高仿真度的工厂环境数据集,采用了一系列数据增强技术,不仅解决了前期数据冗余而造成的模型退化,而且提升了模型在实际应用中的抗干扰能力,为本次研究提供了有力的数据支持。（2）针对工厂实况环境较为复杂,目标物体与环境类间区别不明显以及可能存在遮挡和重叠等情况,对现有的YOLOv5s和YOLOv8n引入EMA高效多尺度注意力机制,以获取不同尺度下的图像特征。添加OTA损失和更改IoU,更为全面地考虑了目标物体之间的遮挡和重叠关系,进一步提高了目标检测的准确性。（3）针对机械臂进行路径规划时,路径质量不高、搜索效率较低、收敛速度较慢等问题。对传统的RRT（Rapidly-exploring Random Tree）算法引进概率采样策略,避免算法陷入局部最优解,提高了全局搜索能力。同时引入了贪心策略和三次B样条,减少了不必要的搜索和冗余动作,解决了机械臂在执行路径时出现抖动或不稳定的情况,最终生成一条高质量,高舒适性的抓取路径。（4）针对传统相机与机械臂之间的校准存在扩展性差,不灵活,实时性差等问题。本文采用了基于ROS的校准方法,采用cameracalibration算法做相机标定,用handcalibration算法做手眼标定。两种算法都通过消息传递进行通信,使其能够在系统中实时运行。不仅保证了相机与机械臂之间的准确关系,而且方便了后续的开发和扩展。综上,本文制作了一套适于特定场景的下的数据集,共计2000张;改进了YOLOv 5s和YOLOv8n目标检测算法并对其做了消融实验,使整体的mAP提升了2.5%;优化了 RRT算法,提高了机械臂抓取效率和成功率;完成了相机标定与手眼标定,确保了整个系统的绝对误差小于4mm,最终的抓取成功率在90%以上。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2024.000468
{DOI}: 10.27787/d.cnki.ghrbs.2024.000468
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多模态信息融合的显著目标检测算法研究
{Author}: 蒋秀蓉
{Tertiary Author}: 田辉
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 显著性目标检测;模态信息互补;运动显著性;时空正则化约束;动态信息增强
{Abstract}: 显著性目标检测(Salient Object Detection,SOD)指通过智能算法理解和模拟人类视觉注意机制,精准定位并分割最能代表场景信息的显著目标区域。在大数据时代背景下,显著性目标检测一方面可以将有限的计算资源分配给场景中的关键部分,提高视觉信息处理效率;另一方面能够对场景做出符合人类视觉认知规律的理解和反应,改善视觉信息处理质量。作为一项基础且重要的研究课题,显著性目标检测被广泛应用于计算机视觉、计算机图形学和人机交互等领域,尤其在场景理解、图像/视频处理以及视觉注意力研究方面具有重要的学术意义和应用价值。然而,由于动态背景、不规则运动以及噪声等视觉场景固有的复杂性,以及模糊、低光照、前/背景相似等可见光模态本身的局限性,导致显著性目标检测面临着巨大的挑战。本文从深入挖掘单一 RGB模态潜在信息、以及融合不同模态信息,两个方向出发,围绕视觉显著性目标检测开展了三个方面的研究工作,主要创新点包括:(1)针对视频场景中动态背景、间歇运动以及遮挡伪装等挑战,本文提出了一种时空正则化约束的运动显著性目标检测算法。为了同时约束显著目标的时空连续性和前景稀疏性,设计了一种结构稀疏诱导范数,将目标的结构信息和运动信息集成到一个统一的稀疏低秩矩阵分解框架中;基于立方体概率模型和时间相干测量,确定目标的时空运动轨迹,增强不规则运动目标和背景之间的区别,进一步辅助矩阵分解。基于改进的交替优化增广拉格朗日乘子法和Douglas-Rachford单调算子分裂法,对运动目标模型进行了有效求解。实验结果表明,该方法在抑制动态背景和噪声的同时,在分离不规则运动显著性目标方面取得了较好的结果。(2)针对低光照、前/背景相似导致单一RGB模态显著性目标检测性能受限的问题,本文提出了一个跨模态互补的RGB-D/T显著性目标检测算法。由于深度/红外图像通常包含清晰且连续的目标边缘信息,RGB图像丰富的颜色和纹理特征使得目标主体更加突出。基于深度、红外的共性特征,以及跨模态的差异化特征,设计了空间信息互补的跨模态融合显著性目标检测模型。通过标签解耦实现显著目标区域特征分离,促使RGB模态关注目标的核心主体,深度/红外模态增强目标的轮廓边缘;基于注意力机制设计了特征交互模块,使得跨模态的显著特征能够相互补充、灵活调整。在RGB-D和RGB-T基准数据集上的实验结果表明,所提算法的精确性和泛化能力优于同期的其他算法。(3)针对低光照、低对比度以及目标轮廓模糊等挑战场景,本文提出了一个事件流引导的RGB-E显著性目标检测算法。为了充分提取事件数据中显著目标的高动态特性,设计了基于矩阵长短时记忆模型(Matrix Long Short-Term Memory,Matrix-LSTM)的异步事件信号表征模块,通过时间域窗口机制,学习显著目标的全局时间特征和局部高动态特征;随后,采用CNN-LSTM混合神经网络建模,实现RGB图像与离散事件的跨模态融合。基于公开RGB SOD数据集生成了相应的模拟事件数据,支持所提算法的端到端有监督学习;此外,为了进一步验证所提算法在真实数据上的有效性,采用DAVIS346 Color事件相机,构建了 RGB-E测试数据集。在模拟和真实数据集上的大量实验表明,通过引入高动态事件数据,所提算法能够有效地提高目标结构的完整性和边界的精细化,取得更好的检测性能。综上,本文从不同模态的图像/视频数据入手,提出了一系列显著性目标检测算法,并采用理论分析与实验相结合的方式验证了它们的有效性。这些算法的提出丰富了视觉显著性检测领域的研究,对多模态信息融合的显著性目标检测的发展起到了一定的促进作用。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.000132
{DOI}: 10.26969/d.cnki.gbydu.2024.000132
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: YOLO系列目标检测算法综述
{Author}: 徐彦威;李军;董元方;张小利
{Author Address}: 吉林财经大学管理科学与信息工程学院;吉林财经大学人工智能研究中心;长春理工大学经济管理学院;吉林大学计算机科学与技术学院;
{Journal}: 计算机科学与探索
{Year}: 2024
{Volume}: 18
{Issue}: 09
{Pages}: 2221-2238
{Keywords}: YOLO算法;目标检测;计算机视觉;特征提取;卷积神经网络
{Abstract}: 近年来，基于深度学习的目标检测算法是计算机视觉研究热点，YOLO算法作为一种优秀的目标检测算法，其发展历程中网络架构的改进，对于提高检测速度和精度起到了重要作用。对YOLOv1～YOLOv9的整体框架进行了横向分析，从网络架构（骨干网络、颈部层、头部层）、损失函数方面进行了对比分析，充分讨论了不同改进方法的优势和局限性，具体评估了改进方法对模型精度的提升效果。讨论了数据集的选择与构建方法、不同评价指标的选择依据，及其在不同应用场景中的适用性和局限性，深入研究了在五个应用领域（工业、交通、遥感、农业、生物）YOLO算法的具体改进，并对检测速度、检测精度及复杂度之间的平衡进行探讨。分析了YOLO在各领域的发展现状，通过具体实例总结YOLO算法研究中存在的问题，并结合应用领域的发展趋势，展望YOLO系列算法的未来，详细探讨了YOLO算法的四个研究方向（多任务学习、边缘计算、多模态结合、虚拟和增强现实技术）。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20240611.1631.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态学习的图文信息融合方法的研究及应用
{Author}: 岳潭
{Tertiary Author}: 胡宗海
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 多模态学习;信息融合;多媒体信息处理;图文隐式关联
{Abstract}: 多媒体信息处理是电子科学与技术领域的重要组成部分之一。物质世界中,信息通过多媒体,多种模态源的方式进行传递和交互。这些信息可以通过不同的电子传感设备收集,输入进计算机中进行信息处理。随着深度学习技术的飞速发展,众多模型在目标检测,文本分类,语音识别等单模态任务上达到了出色的性能。然而,在人类交互和物质世界信息传递的方式中更多的是多种模态的输入和输出。近些年,众多研究者开始关注基于深度学习的多模态信息处理技术。相比于单模态模型,多模态模型更加关注不同模态数据的联合处理及融合决策,主要从多模态信息联合表征,多模态语义信息对齐,信息融合,多模态特征映射等几个关键技术点进行优化和改进,以提高多模态信息的处理性能。目前,多模态学习技术虽在多个领域得到广泛应用,但仍面临一些研究挑战:1)多模态数据问题:在一些难以收集大量多模态数据的领域,特别是需要高质量多模态数据互补信息的场景中,多模态学习数据集质量无法满足训练需求。2)多模态模型迁移问题:现有的基于预训练模型构建的多模态模型在应用于特定下游任务时,因目标域与预训练域的数据分布差异可能导致过拟合。3)多模态信息隐式关联性问题:大量的多模态任务中存在图文隐式关联的数据(即无法直观地看出图文之间明显的关联性),导致在图文信息融合、细粒度化语义对齐等关键技术点上表现不尽人意。上述问题表明在数据集构建、模型结构以及多模态信息语义关联上需要进一步的优化和研究,以提升模型的整体性能和在真实场景下的应用效果。基于此,本课题关注图文多模态信息处理,并重点聚焦多模态联合表征,多模态语义信息对齐,信息融合三个关键技术点进行了相关的研究。针对研究挑战1,本课题收集并构建了两个高质量数据集,用于多模态模型高效训练并建立基线标准;针对研究挑战2,本课题提出了基于混合融合方法的图文信息融合模型,通过模型融合结构的改进解决模型迁移的过拟合问题;针对研究挑战3,本课题提出基于知识融合的多模态隐式信息关联模型,结合概念知识,为模型补充先验知识以更好地建立隐式信息的关联。并且,本课题将研究成果与实际应用相结合,开发了基于多模态学习的学术论文智能信息处理系统。在本文中,对以上四个部分的内容进行详细介绍。1.首先,本课题选择论文细粒度化分类与反讽隐式情感检测这两个具体且典型需要进行多模态信息处理的领域,构建了 PaperNet与SarcNet两个高质量数据集。两个数据集均包含多模态数据,其中PaperNet数据集关注于多模态论文细粒度化分类领域,随着科技论文数量的激增,对研究人员而言,专业的细粒度论文自动分类变得越发重要。由于细粒度化的论文分类需要较高的专业知识,标注成本极高,目前领域内缺乏细粒度化的多模态论文分类数据集。本课题为高效提取PDF格式的论文文档数据,开发了创新的动态权重结构化解析框架 DWSA(Dynamic Weighting Structural Analysis),用以提取文档中文本和图像信息,并实现文本信息的结构化解析。所构建的PaperNet数据集涵盖了计算机视觉(CV)和自然语言处理(NLP)两大领域,提供了 2个粗粒度类别和20个细粒度类别的层级化分类标签及图文多模态数据。而SarcNet数据集侧重于多模态隐式情感检测领域,由于反讽语言表达的隐晦性,导致早期仅使用文本数据进行反讽检测的任务具有挑战,社交网络的兴起促进了多模态数据的使用以提升反讽语言的检测效率,而目前现有的多模态反讽数据集严重缺乏中文语料,此外本课题研究也发现了现有的多模态反讽数据集在图文标注方法上的问题。基于此,本课题提出了包含中英文的多语言、多模态反讽检测数据集SarcNet。该数据集由3,335个图像-文本对组成,包括图像、文本和多模态(图文匹配对)的三种独立标签,共超过10,000个标签,以便更精确、合理地评估单模态和多模态模型的性能。在两个高质量多模态数据集上,本课题也使用多个主流模型进行实验评估,建立了基线标准。2.基于上述研究工作收集的数据集与领域内其他公开基准数据集,针对研究挑战2,本课题提出并训练了一个基于混合融合方法的图文信息融合模型MreNet。在分类任务中,基于深度学习的预训练模型由于其在大规模数据集上的预训练以及优秀的网络初始化权重,往往能够在多个应用场景下展示出色的性能。然而,当面临预训练数据集与目标任务数据集的数据分布差异较大时,尤其是在细粒度分类任务上,模型容易出现过拟合,从而影响性能。为了解决模型迁移问题,本研究提出了多模态正则化集成学习网络模型(MreNet),该模型提出图文信息联合表征、跨模态细粒度化语义信息对齐和信息决策融合三个模块进行模型结构改进,并通过注意力机制进行特征融合,以及利用正则化和集成学习方法以减少参数量和提升模型泛化能力。通过在本课题收集的数据集和公开基准数据集上的实验,MreNet在PaperNet共4个数据集上取得了 82.92%的平均准确率,相较DSS基线模型提高了 3.43%,证明了 MreNet在解决过拟合问题及增强模态内信息表征方面的有效性。3.针对于图文信息隐式关联性挑战,本课题提出了基于知识融合的多模态隐式信息关联模型,以处理多模态反讽隐式情感检测任务。反讽的语言表达形式在社交网络中普遍存在,随着社交网络的发展,研究者们开始关注多模态反讽检测模型。目前现有的工作更多关注于结合注意力机制和图神经网络等结构来优化模型性能,而本课题在研究中发现改进模型结构对显式关联性的图文数据有效,但对隐式关联性数据的效果有限。本课题从一个新的视角开展研究,关注之前方法忽视的且对人类判断反讽重要的两个因素:先验知识和跨模态语义冲突。基于此,本课题创新性地提出KnowleNet模型。同样的,该模型也从图文多模态联合表征、高维空间隐式语义对齐和信息融合三个主要方面进行改进。该模型结合了 ConceptNet知识库的先验知识和两个跨模态语义相似性检测模块,同时引入对比学习以优化正负样本的高维语义空间分布。本项研究在公开基准数据集上进行了大量实验及可视化展示,其中在推特反讽数据集上KnowleNet模型达到了 88.87%的准确率,相较基线模型CMGCN提高了 1.64%,证明了所提出方法的有效性。4.最后,基于以上的研究成果,本文介绍了自主研发的论文智能信息处理系统PaperMaster。该系统是对以上多模态信息处理技术的应用可行性验证,系统包含一个论文数据库,且支持在线开源论文的自动获取。系统还采用细粒度分类技术对大领域内的论文进行进一步精确划分,并进行智能结构化解析,提高研究人员和学生检索效率。PaperMaster系统实现了智能论文管理,提供结构化输出,推荐相似论文,并包含论文评论与情感分析推荐功能,使用户能够更有效地找到所需论文并与他人分享评论。通过多个落地场景的实际检验,证明了本文中所提出技术的可行性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.000111
{DOI}: 10.26969/d.cnki.gbydu.2024.000111
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO面向复杂工业环境下的小目标检测算法研究
{Author}: 裴加彬
{Tertiary Author}: 吴晓明
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 小目标检测;YOLOv5;工业安全;SPD-Conv;GAM注意力机制
{Abstract}: 在工业环境中,工人的安全防护意识薄弱,由于复杂的工业环境和监控摄像头的距离、角度等问题,易出现大量的小目标与被遮挡目标,给不安全行为检测带来了困难。对于复杂工业环境下小目标检测来说,物体尺寸小,可利用特征较少,容易出现定位误差,导致物体检测不准确和目标漏检的问题。本文以提高网络特征信息提取能力为出发点,克服尺度变化和复杂背景造成的检测困难,同时降低预测框与真实框之间的位置偏差。对YOLOv5模型进行方法研究,提高对小目标的检测能力,更好地保障工业人员的安全。本文的主要研究内容如下:
1.本文提出了一个小目标检测模型SGD-YOLOv5,重新设计了YOLOv5的骨干网络,与Space-to-depth(SPD-Conv)相结合,来缓解小目标特征信息丢失的问题,更好的提取特征信息,以提高对低分辨率和小目标的检测精度。其次,随着特征信息的减少和维度的变化,本文在YOLOv5的骨干网络和颈部网络之间,构建了结合Global Attention Mechanism(GAM)注意力的不同通道维度之间的信息交互机制,来获取更多的特征信息,扩大感受野,捕获全局特征信息,提高模型性能。最后,为了缓解分类和定位的空间错位的问题,本文提出将YOLOv5的头部采用并行分支的解耦头(Decoupled head),把分类任务与回归任务分离,提高模型对小目标的定位能力,同时加速模型收敛。
2.本文收集并整理了安全帽佩戴数据集(SHWD)和吸烟行为检测数据集(SBDD),并使用数据增强方法提高了数据集多样性。本文与基线模型在增强的SHWD和SBDD数据集上进行了实验对比。同时,在公开数据集SODA-D和Vis Drone2021 DET上评估了SGD-YOLOv5对小物体的检测能力。实验表明,SGD-YOLOv5在SHWD和SBDD上优于基线模型。在SODA-D数据集上,与TPH-YOLOv5相比,AP和Recall分别实现了18.3%至19.2%和11.9%至13.3%的改进。在Vis Drone 2021-DET数据集上,m AP@0.5与YOLO-Drone相比,实现了从35.45%到35.70%的改进。
3.基于以上研究,本文开发了一个能够在复杂工业环境下对小目标进行检测的实时系统,能够对工业环境下不安全行为进行检测。根据不同不安全行为的数据集进行模型的训练,获得模型权重,进行部署。检测系统的能够对图像、视频等格式的数据流进行检测,可搭载实时检测摄像头。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000257
{DOI}: 10.27278/d.cnki.gsdqc.2024.000257
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO的密集小目标检测算法研究
{Author}: 陈好男
{Tertiary Author}: 孙涛
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 计算机视觉;深度学习;密集小目标检测;YOLO
{Abstract}: 基于深度学习的YOLO系列目标检测算法因出色的实时检测性能而被广泛应用。然而,该系列算法对于密集小目标的检测仍然是一个挑战。默认YOLO算法更适合检测多尺度目标,对密集小目标检测性能较低,难以达到预期效果。本文分别基于经典YOLOv5和YOLOv7算法做出改进,用于提高密集小目标检测性能,主要研究内容如下:
针对经典算法对密集小目标检测精度低、漏检率高的问题,基于YOLOv5算法进行改进:设计模型剪枝优化,减少部分参数和冗余计算,一定程度上避免非重要目标信息融合带来的信息覆盖;设计特征融合扩展网络,减少在深层卷积对密集小目标漏检的问题,同时提高位置信息的准确性,有效提升检测精度。在实验环节更新了边界框损失函数使预测框的位置更接近真实框位置,开启了马赛克数据增强提高图像中密集小目标丰富度,经过广泛的评估表明,提出算法的检测精准度有显著提升,损失有明显下降。
针对跨数据集多种类密集小目标检测鲁棒性差的问题,基于YOLOv5算法进行改进:设计基于预测锚框的优化型解耦检测模块,将检测过程进行分支,改为短程并行运算,用于提高定位和分类准确性,适用于跨数据集检测性能提升;设计特征提取扩展网络,弥补特征提取阶段密集小目标可用性特征少的问题,补充了更多边缘和位置信息。通过在多个官方开源密集小目标数据集进行广泛评估,实验结果显示,提出算法相较于默认算法在多个性能评价指标上有所突破,一定程度上反映了改进算法在跨数据集多种类密集小目标检测的鲁棒性。
为进一步提升算法检测精确度和减小模型权重体积,降低在微小型设备的部署难度,基于YOLOv7算法进行高效轻量型改进:提出新的高效层模块用于特征提取网络尾部,降低了模型复杂度和提升了深层卷积中的密集小目标的语义清晰度;设计路径聚合扩展网络,改善了浅层卷积与深层卷积跨路径聚合效果;此外,专为微小型设备部署设计了通道缩放的轻量型版本,进一步缩小了模型权重体积。实验证明,改进的轻量型和常规型算法均有效缩减了模型权重体积,在检测精确度方面实现更高的突破。
最后,基于上述改进的算法,设计了一款密集小目标检测部署系统用于验证算法实际使用时的有效性,为未来部署工作的研究奠定了一定的基础。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000042
{DOI}: 10.27278/d.cnki.gsdqc.2024.000042
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO的道路目标检测算法研究
{Author}: 李树壮
{Tertiary Author}: 翟双
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: YOLO算法;目标检测;稀疏残差网络;双模态特征融合;光流法
{Abstract}: 随着计算机视觉技术的飞速发展,目标检测技术在智能交通、工业检测领域有了广泛的应用。其中道路目标检测因交通驾驶安全的需要成为研究热点。然而,实时道路交通环境的复杂性和图像识别设备的限制导致检测图像存在差异,特别是小目标如远处行人、车辆等,其尺寸小、分辨率低等问题进一步增加了检测难度。传统的手工特征提取方法在处理复杂道路场景时面临挑战,而深度学习技术的兴起为道路目标检测带来了突破。
尽管深度学习算法在目标检测方面取得了显著进展,但现有算法在识别车辆、行人、交通标志等关键要素时,往往仍需驾驶人员的辅助干预,无法完全实现自主决策。此外,在光照不均匀的环境中,图像帧的质量可能受到影响,导致目标检测算法的准确性下降,且现有算法对于特殊目标及小目标的检测能力仍显不足,增加了智能驾驶系统在实际应用中的风险。因此,由各种原因导致的道路交通事故仍然时有发生,亟需更为精确、鲁棒的目标检测算法来提升智能驾驶系统的安全性与可靠性。本文通过利用双模态稀疏网络提高图像对比度,增加输入细节,并通过改进YOLOv8算法的骨干网络（Backbone）和颈部网络（Neck）等操作提高道路目标尤其是小目标检测的精确率,具体研究内容如下:
（1）针对光流法在车辆移动过程中因光照不均导致的目标检测误差较大的问题,提出了一种基于改进稀疏残差网络的目标检测算法,其网络模型包含了图像预处理、特征提取和特征融合三个模块,创新性地将稀疏残差网络输入端分为两个分支,分别为稀疏残差分支和空洞卷积分支,这两个分支作为输入视频帧的特征提取和融合模块,经过不同尺度的卷积核多尺度提取后输入至下一模块;针对视频帧图像细节不足的问题,利用基于多权值的联合损失函数进行图像细节恢复,使用残差网络,在保证图像原始结构的情况下,对图像进行分割和重建,从而更好的实现图像细节恢复功能;同时提出改进的核主成分分析法,对融合后即将输入光流场的特征进行降维处理,解决算法冗余的问题;利用实时性较高的YOLOv5算法的后处理模块改进光流估计算法,提高光流场对图像的处理速度。实验结果表明,在公开数据集上进行测试,本文方法的PSNR（Peak Signal-to-Noise Ratio）值为29.6756,SSIM（Structural Similarity Index）值为0.8766,均高于同类目标检测增强算法,检测平均精度较YOLOv5算法提高2.09,具有较高的准确性。
（2）针对一般的单模态目标检测算法在道路小目标检测中容易受到背景噪声等因素的影响,导致小目标识别精度较低,出现错检漏检等情况。本文提出一种基于YOLOv8的双模态小目标检测算法。首先对输入的一一对应可见光和红外光图像进行双模态特征提取,提出特征加权模块,创新性地赋予二者权重,通过该权重计算出二者融合的最佳比例后对提取的特征进行加权融合,解决双模图像简单一比一融合后二者缺点易凸显的问题。然后对融合后的特征进行全局注意力机制加强,增强小目标与背景的对比度,加强后的特征经过SPPF模块进行空间金字塔池化,通过联合损失函数在保留小目标轮廓的同时保留小目标的图像细节,以解决小目标在检测过程中仅识别出位置不能识别出种类的问题。最后经过处理的特征进入骨干网络和颈部网络改进的YOLOv8检测模块,通过引入卷积Pcov和GSConv改进C2f中的卷积以选择性地提取双模态融合特征信息,以实现对道路小目标的检测增强。实验结果表明,本文算法在红外光和可见光双模输入时AP0.5为76.5,较YOLOv5-s提升5.0,较YOLOv8提升2.9,FPS较YOLOX提升10Hz,与YOLOv8持平,因此本文与其他同类算法相比,对道路小目标有更高的识别精度,可以有效减少小目标错检漏检概率。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2024.000656
{DOI}: 10.27805/d.cnki.gccgy.2024.000656
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习实时语义分割综述
{Author}: 高常鑫;徐正泽;吴东岳;余昌黔;桑农
{Author Address}: 华中科技大学人工智能与自动化学院;类脑智能系统湖北省重点实验室;北京三快科技有限公司(美团);
{Journal}: 中国图象图形学报
{Year}: 2024
{Volume}: 29
{Issue}: 05
{Pages}: 1119-1145
{Keywords}: 实时语义分割;模型轻量化;高效模块设计;计算机视觉;深度学习
{Abstract}: 语义分割是计算机视觉领域的一项像素级别的感知任务，目的是为图像中的每个像素分配相应类别标签，具有广泛应用。许多语义分割网络结构复杂，计算量和参数量较大，在对高分辨率图像进行像素层次的理解时具有较大的延迟，这极大限制了其在资源受限环境下的应用，如自动驾驶、辅助医疗和移动设备等。因此，实时推理的语义分割网络得到了广泛关注。本文对深度学习中实时语义分割算法进行了全面论述和分析。1）介绍了语义分割和实时语义分割任务的基本概念、应用场景和面临问题；2）详细介绍了实时语义分割算法中常用的技术和设计，包括模型压缩技术、高效卷积神经网络（convolutional neural network,CNN）模块和高效Transformer模块；3）全面整理和归纳了现阶段的实时语义分割算法，包括单分支网络、双分支网络、多分支网络、U型网络和神经架构搜索网络5种类别的实时语义分割方法，涵盖基于CNN、基于Transformer和基于混合框架的分割网络，并分析了各类实时语义分割算法的特点和局限性；4）提供了完整的实时语义分割评价体系，包括相关数据集和评价指标、现有方法性能汇总以及领域主流方法的同设备比较，为后续研究者提供统一的比较标准；5）给出结论并分析了实时语义分割领域仍存在的挑战，对实时语义分割领域未来可能的研究方向提出了相应见解。本文提及的算法、数据集和评估指标已汇总至https://github.com/xzz777/Awesome-Real-time-Semantic-Segmentation，以便后续研究者使用。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxeNw9HKzy8XGB7r8Gqw3OWu8LS48Diz0CB0MYjtusD6OlMNv7vq2OOSLVcT24SXiEUaXNBLIlfnckjDj4qf4WZQ8lLdakHb12LKROPsD4jv5XA8wfwCD63Oj4fDzOrBaPSU7lI7chGg5vnFqozUNziBHC35TtNayV8VQqoeugbzfYWGT9ANkUIwIQcdFh2cVY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的PCB表面缺陷检测研究综述
{Author}: 徐一奇;肖金球;汪俞成;顾逸韬;赵红华
{Author Address}: 苏州科技大学电子与信息工程学院;苏州市智能测控工程技术研究中心;苏州科技大学物理科学与技术学院;
{Journal}: 微电子学与计算机
{Pages}: 1-15
{Keywords}: PCB;缺陷检测;机器视觉;深度学习
{Abstract}: 印刷电路板（PCB）是几乎每种电子产品中必备的组件，其优劣直接影响了电子产品的质量。随着集成电路和半导体技术的快速发展，PCB也趋于精小化。因此，对PCB中的缺陷进行高精度和快速检测成为了一大挑战。本文对PCB的各种缺陷检测方法进行了分析研究，详细讨论了传统的基于图像处理、基于机器学习和基于深度学习的缺陷检测方法，对它们的算法性能，优点和局限性进行比较，总结了PCB缺陷检测领域当前面临的挑战并展望未来缺陷检测的研究趋势。
{ISBN/ISSN}: 1000-7180
{Notes}: 61-1123/TN
{URL}: https://link.cnki.net/urlid/61.1123.TN.20240514.1043.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 涉水视觉
{Author}: 李学龙
{Author Address}: 西北工业大学光电与智能研究院;智能交互与应用工业和信息化部重点实验室(西北工业大学);
{Journal}: 电子学报
{Year}: 2024
{Volume}: 52
{Issue}: 04
{Pages}: 1041-1082
{Keywords}: 涉水视觉;涉水光学;多模态认知计算;机器视觉;图像视频信号处理;地外海洋
{Abstract}: 地球表面有约71%的面积被江河湖海等水体覆盖，陆地上的成像也会受到云雪雨雾等水体影响，但是，当前常见的机器视觉科研工作和应用系统基本只围绕空气和真空介质中的视觉任务展开，涉及不同形态水体的视觉工作没有得到系统的研究.涉水视觉（water-related vision）作为涉水光学技术在视觉领域的具象化体现，重点研究光与水的物质相互作用及跨介质传播过程中，涉水视觉影像信号智能处理与分析方面的科学问题，以及先进智能涉水视觉装备研制方面的工程技术问题.本文从“为什么大海是蓝色的？”这一具有普适意义的问题出发，系统介绍了水对光的吸收、散射、衰减作用机理，对涉水视觉任务造成的影响，以及现有的涉水图像处理与解析方法 .本文基于水体光学特性及成像退化机理，介绍了团队在探索涉水成像和图像解析等涉水视觉关键技术及装备方面的成果，先后研制了全海深超高清相机“海瞳”、全海深3D相机、全海深高清摄像机等，形成了从色彩、强度、偏振、光谱等全方位、体系化的水下观测解析装备研制能力，填补了我国全海深光学视觉技术的空白，推动了我国涉水视觉领域技术的升级，应用价值和社会效益显著.
{ISBN/ISSN}: 0372-2112
{Notes}: 11-2087/TN
{URL}: https://link.cnki.net/urlid/11.2087.TN.20240506.1337.060
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉水果分拣设备的设计与研究
{Author}: 惠宇龙
{Tertiary Author}: 万宏强;寇学锋
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 分拣设备;机器视觉;PLC控制;人机交互
{Abstract}: 随着生活质量的提高,人们对水果的需求量也逐渐增大,水果产业已成为了继粮食和蔬菜后的第三大产业。但随着水果产值升高,分拣任务越来越繁重,目前水果分拣主要以人力分拣为主,存在主观性强、效率低等问题影响水果分拣质量。针对以上问题,本文将机器视觉技术应用于水果分拣设备,提高水果分拣效率、保证分拣质量,具体研究内容如下:
1)结合水果分拣设备的要求,确定整体机械结构设计方案。根据功能不同将水果分拣设备划分为整理、分拣和收集单元,根据苹果重量等基本信息计算整体设备基本尺寸参数,为机构设计提供理论依据,验证了水果分拣设备的合理性,并分别对三个单元利用Solidworks软件建立三维模型。
2)在机器视觉模块,设计了图像采集方案,对三种滤波方法利用PSNR信噪比选择滤波效果较好的滤波方法对图像进行滤波,并利用最大类间方差法(Otsu)对图像进行阈值分割并结合形态学闭运算消除苹果图像中因反光造成的孔洞,得到阈值分割图。对阈值分割图采用Canny算子提取苹果图像的边缘轮廓,通过最小外接圆法计算得到苹果像素半径,利用标定试验得到的标定系数计算出苹果实际半径。将图像模型从RGB颜色模型转换为HSV颜色模型,以H分量分布情况检索符合范围的像素完成苹果表面色泽度的计算,结合苹果色泽度和果径大小对苹果进行等级分级。
3)控制系统与人机交互设计。设计控制系统实施方案,根据控制方案完成了硬件的选型以及I/O端口的分配。运用博图软件编写了控制程序以及PLC、HMI触摸屏和上位机间的TCP/IP的通信方法,设计分拣系统人机交互界面,并与控制程序的数据进行交互,实现在触摸屏上便可实时控制设备的启停和显示水果等级及PLC与上位机通讯信息,使设备控制智能化。
4)试验验证与分析。在博图软件的PLC SIM仿真器中联合人机交互界面对整体控制程序进行仿真;通过视觉测量与人工测量对比试验,验证了苹果果径大小识别的准确性,误差范围在±1.4mm;对分拣设备整体分拣正确率进行试验验证,对试验结果分析得出水果分拣设备分拣正确率高达94%。
论文结合机器视觉技术实现了对苹果果径大小和表面色泽度两个特征分拣,通过对机械模块、机器视觉模块和控制模块的设计完成了水果分拣设备样机的搭建,并进行试验验证设备分拣的正确率。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000691
{DOI}: 10.27391/d.cnki.gxagu.2024.000691
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像匹配:方法、应用与挑战
{Author}: 孔庆群;吴福朝;樊彬
{Author Address}: 中国科学院自动化研究所;中国科学院大学;北京科技大学智能科学与技术学院;
{Journal}: 计算机学报
{Year}: 2024
{Volume}: 47
{Issue}: 07
{Pages}: 1485-1520
{Keywords}: 图像匹配;特征点匹配;稠密匹配;三维重建;视觉定位;同时定位与建图;深度学习
{Abstract}: 图像匹配旨在建立图像之间的点对应关系,是许多计算机视觉任务的关键环节.近年来,随着深度学习技术的发展,图像匹配方法已从以手工设计特征为主转变为基于深度网络的方法,基于深度学习的图像匹配方法在多个标准数据集上展现出卓越的性能,推动着多个相关应用的发展.围绕图像匹配涉及的若干关键问题,如:特征点检测、特征点描述、稠密点匹配、误匹配去除,本文对深度学习图像匹配方法进行了系统性总结.首先分析了领域内基于深度学习的典型方法和关键技术,随后介绍了与图像匹配密切相关的几个典型应用并给出其现状分析,最后,根据对图像匹配领域技术发展的分析总结,结合作者在该领域的长期研究积累,本文给出了目前图像匹配所面临的主要挑战以及未来发展趋势.
{ISBN/ISSN}: 0254-4164
{Notes}: 11-1826/TP
{URL}: https://link.cnki.net/urlid/11.1826.tp.20240428.1815.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进COF-YOLO v8n的油茶果静态与动态检测计数方法
{Author}: 王金鹏;何萌;甄乾广;周宏平
{Author Address}: 南京林业大学机械电子工程学院;
{Journal}: 农业机械学报
{Year}: 2024
{Volume}: 55
{Issue}: 04
{Pages}: 193-203
{Keywords}: 油茶果;机器视觉;COF-YOLO v8n;计数;产量估计
{Abstract}: 针对自然环境下油茶果存在严重遮挡、近景色、小目标等现象，使用YOLO网络存在检测精度低、漏检现象严重等问题，提出对YOLO v8n网络进行改进。首先使用MPDIOU作为YOLO v8n的损失函数，有效解决因为果实重叠导致的漏检问题；其次调整网络，向其中加入小目标检测层，使网络能够关注小目标油茶以及被树叶遮挡的油茶；最后使用SCConv作为特征提取网络，既能兼顾检测精度又能兼顾检测速度。改进COF-YOLO v8n网络精确率、召回率、平均精度均值分别达到97.7%、97%、99%,比未改进的YOLO v8n分别提高3.2、4.8、2.4个百分点，其中严重遮挡情况下油茶检测精确率、召回率、平均精度均值分别达到95.9%、95%、98.5%,分别比YOLO v8n提高4.0、9.1、4.6个百分点。因此改进后COF-YOLO v8n网络能够明显提高油茶在严重遮挡、近景色、小目标均存在情况下的识别精度，减小油茶的漏检。此外，模型能够实现动、静态输入条件下油茶果计数。动态计数借鉴DeepSORT算法的多目标跟踪思想，将改进后COF-YOLO v8n的识别输出作为DeepSORT的输入，实现油茶果实的追踪计数。所得改进模型具有很好的鲁棒性，且模型简单可以嵌入到边缘设备中，不仅可用于指导自动化采收，还可用于果园产量估计，为果园物流分配提供可靠借鉴。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxu7Byxc2P-gcrekH_wnKhaP5l31vkUNOPFeQCcipbrpf55lNIuqehnZL8AtH8lUgWsIpAlcxhsNoUlypXfhQAeYVcjLXafI1OBXB0MmOsMj3Wq-NnzeakjPfVWYNIw1o3wOgyLIupA-yht04wL7V3gDUoYzSuSTSZM3C53NlMxvSQoZTub_6fVTIRFo19ftAI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 目标检测数据集研究综述
{Author}: 李林;王家华;周晨阳;孔思曼;孙践知
{Author Address}: 北京工商大学,计算机与人工智能学院;
{Journal}: 数据与计算发展前沿(中英文)
{Year}: 2024
{Volume}: 6
{Issue}: 02
{Pages}: 177-193
{Keywords}: 目标检测;数据集;行人检测;人脸检测;计算机视觉
{Abstract}: 【应用背景】目标检测是计算机视觉的基本研究问题之一，目标检测数据集是评估目标检测方法性能的基础。【目的】对目标检测领域发展过程中产生的数据集进行分析和介绍可以有效地揭示目标检测数据集的特点、发展趋势以及检测研究面临的主要问题，从时间和领域的角度展现目标检测数据集的现状，一定程度上也可以为研究人员提供数据集使用参考。【方法】主要从目标检测领域通用数据集和包含行人检测、人脸检测、交通道路场景目标检测、航空遥感检测、文本检测多个应用场景的特定领域数据集两个角度出发，关注数据集的挑战性，列举分析应用最为广泛且具有差异的数据集，给出不同场景数据集的图像示例并分析其主要挑战。【结论】对目标检测领域数据集进行介绍的同时，也揭示了目标检测数据集的重要意义、不同场景下的挑战性和特点以及构建目标检测数据集的主要挑战与未来发展趋势。
{ISBN/ISSN}: 2096-742X
{Notes}: 10-1649/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz06ZS3rIhmG-rRXMwnwQRzuEda684-l89OPFBUaAUquVwtAbNEJWDDsqXRiErPfdD2BJPk6XnFPGh-iDrC60JI-COU3PkXMkNjt8FStANluAoVbA3No_t5jicXK-Y6ouVMiUhp7cSpDjS6I0SWO1Nnw2lC14ezrShP6pHTNBiO3z9gr9BG7j7zKcg6Cjt9loc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 目标检测中注意力机制综述
{Author}: 任书玉;汪晓丁;林晖
{Author Address}: 福建师范大学计算机与网络空间安全学院;
{Journal}: 计算机工程
{Year}: 2024
{Volume}: 50
{Issue}: 12
{Pages}: 16-32
{Keywords}: 注意力机制;计算机视觉;深度学习;DETR模型;目标检测
{Abstract}: Transformer在自然语言处理中表现出优越的性能激励了研究人员开始探索其在计算机视觉任务中的应用。基于Transformer的目标检测模型DETR将目标检测视为一个集合预测问题，引入Transformer模型来解决目标检测任务，从而避免了传统方法中的提案生成和后处理步骤。最初的DETR在训练收敛和小物体检测方面存在速度慢、效率低的问题。为了解决这些问题，研究人员进行了多方面改进，提升了DETR的性能。对DETR的基本模块和增强模块进行深入研究，包括对主干结构的修改、查询设计策略和注意力机制的改进，同时对各种检测器进行比较分析，评估它们的性能和网络架构，探讨了DETR在计算机视觉任务中的潜力和应用前景以及目前存在的局限性和面临的挑战，并对相关模型进行分析与总结。根据目标检测发展的现状，分析注意力模型的优势与局限性，并对注意力模型在目标检测领域的研究方向加以展望。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0068553
{DOI}: 10.19678/j.issn.1000-3428.0068553
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv8和注意力机制的琼脂糖凝胶电泳条带识别研究
{Author}: 袁建飞
{Tertiary Author}: 彭永康
{Publisher}: 景德镇陶瓷大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: YOLOv8;卷积注意力机制;琼脂糖凝胶电泳条带;目标检测
{Abstract}: 近年来,深度学习技术在计算机视觉领域取得了显著的进展,特别是在目标检测方面。YOLO（You Only Look Once）系列算法是其中的佼佼者,以其高效的检测速度和准确的识别率而著称。注意力机制也是深度学习领域另一个重要的研究进展,它通过模拟人类视觉系统的注意力分配机制,使模型能够更加专注于输入信息中最相关和最具判别性的部分,从而提高模型的表征能力和泛化性能。同时,在生物医学领域,琼脂糖凝胶电泳是一种广泛应用的实验技术,用于分离、鉴定和分析DNA或RNA片段。通过这种技术,研究者可以获得关于遗传物质的大小、数量和质量的宝贵信息。然而,传统的琼脂糖凝胶电泳条带识别方法通常依赖于人工视觉检查和手动标注,尤其在面对大量样本或复杂条带模式时,既耗时又易出错。因此,开发一种自动化、高效且准确的琼脂糖凝胶电泳条带识别系统具有重要的实践意义。
首先,本文对YOLOv8算法在模型结构、损失计算、数据增强策略等方面进行了详细的分析,然后,向YOLOv8模型中添加注意力机制模块。注意力机制可以帮助模型更好地关注目标区域,并抑制无关信息的干扰,本文选择了卷积注意力机制（Convolutional Block Attention Module,CBAM）作为本研究的注意力结构。CBAM包含通道注意力分支和空间注意力分支,可以分别在通道维度上和空间维度上学习每个特征的权重,从而增强网络神经元对目标相关特征的响应。最后,本文使用采集到的琼脂糖凝胶电泳图像作为数据集,并按照80%训练集、10%测试集和10%验证集的比例进行划分,对比了不同模型在相同参数设置下对验证集的性能表现,包括YOLOv8和本文提出的YOLOv8+CBAM模型:YOLOv8+CBAM模型查准率高达95.7%（对dna条带查准率高达99.1%）,相较于原YOLOv8模型,性能提升0.9%;查全率为78.7%,相较于原YOLOv8模型,性能提升7.2%;在mAP0.5和mAP0.5:0.95两指标上,性能分别达到90.1%和65.9%,相较于原YOLOv8模型,分别提升3.8%和3.8%。实验表明,YOLOv8+CBAM对琼脂糖凝胶电泳图像中的条带能进行有效识别,且证明了注意力机制有助于提高模型在琼脂糖凝胶电泳图像的条带识别方面的性能和泛化能力。
综上所述,本研究提出了一种基于YOLOv8和注意力机制的琼脂糖凝胶电泳条带识别方法,并通过实验验证了其有效性和优越性。该方法可以为生命科学领域的研究人员提供更准确、高效和自动化的条带识别工具,有助于推动相关领域的研究进展和应用发展。
{URL}: https://link.cnki.net/doi/10.27191/d.cnki.gjdtc.2024.000118
{DOI}: 10.27191/d.cnki.gjdtc.2024.000118
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在现代农业生产中的研究现状
{Author}: 秦韬;庄卫东
{Author Address}: 黑龙江八一农垦大学工程学院;
{Journal}: 现代化农业
{Year}: 2024
{Volume}: 
{Issue}: 04
{Pages}: 90-93
{Keywords}: 智慧农业;机器视觉;作物识别
{Abstract}: 近年，智慧农业的这个定义频繁出现在农业领域。智慧农业把现代信息技术和智能农机装备跨界深度融合形成了全新的农业生产方式。在智慧农业中机器视觉发挥着不可或缺的角色。文章主要介绍机器视觉技术在作物病虫草害识别、作物生长信息监测、果蔬识别定位以及农业机器人视觉导航等方面国内外的研究进展，并提出目前机器视觉在智慧农业应用中的不足，为未来的研究提供理论参考。
{ISBN/ISSN}: 1001-0254
{Notes}: 23-1137/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzFNMC8-90LMn8zL2hL4656jE2zp_OvTEWEwNjxQ9IM15-lDcQs8fzDbUBFHJuDLZ2ehqB9AbxOl2SINEb1-NnXh3CNq9FBjlfvSVQRpey4FfVLKhSW8JEluTC4p6pSIrY-TL0cL481ATos1Zzz7tceB0nSF_mv66_Y8A6qxkAjQW-AmxQ5nDfdwTK8V8aRVig=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于BERTopic的计算机视觉领域热点技术主题及演化分析
{Author}: 王蓝蓝;刘艳丽
{Author Address}: 中国科学院文献情报中心;中国科学院大学经济与管理学院信息资源管理系;
{Journal}: 科学观察
{Year}: 2024
{Volume}: 19
{Issue}: 02
{Pages}: 46-60
{Keywords}: Bertopic;计算机视觉;热点主题;演化分析
{Abstract}: [目的/意义]当前人工智能发展迅猛，计算机视觉作为人工智能的重要分支之一，其新的热点技术主题不断涌现。通过对计算机视觉领域的前沿热点主题演化进行分析，可以深入了解计算机视觉领域的热点技术、发展方向和演化路径，为相关研究和实践提供指导和参考。[方法/过程]基于德温特专利数据库中计算机视觉相关专利数据，采用BERTopic模型提取主题，并采用基于BERT的DTM模型进一步对主题进行演化分析，总结近年计算机视觉的研究前沿及热点主题。[结果/结论]计算机视觉领域的热点研究主题主要集中在自动驾驶、多模态人工智能、人机交互和三维建模等领域，计算机视觉整体表现出巨大的发展空间与潜力。
{ISBN/ISSN}: 1673-5668
{Notes}: 11-5469/N
{URL}: https://link.cnki.net/doi/10.15978/j.cnki.1673-5668.202402005
{DOI}: 10.15978/j.cnki.1673-5668.202402005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的零件表面缺陷检测系统的设计
{Author}: 徐立青
{Author Address}: 陕西铁路工程职业技术学院;
{Journal}: 石河子科技
{Year}: 2024
{Volume}: 
{Issue}: 02
{Pages}: 43-45
{Keywords}: 汽车零件;机器视觉;表面缺陷检测
{Abstract}: 针对汽车零件表面质量高效率、高精度检测的需求，本文利用机器视觉检测系统采集零件表面图像，并整体设计了机器视觉检测系统，通过对比分析确定高速CCD相机为图像采集装置，选择LED光源为照明光源，并设计了光源补偿方式正交试验，通过试验确定了红色LED光源环形照明方式为本装置的打光方式。
{ISBN/ISSN}: 1008-0899
{Notes}: 65-1162/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy02DaYYQYk6vHmvKNVDz9ZqDQeCKaKhCkO_trLPaRQLtIDhFVVShmrfAbQrCv5l29kN79oLg_KkrdHmXBKXd5ds7h2RwM1xoHX98FvbeJqQjEI0IXzD-fxmcuAL31t3VSW256L_xq9_wgIXeVjiYOC68uZ5u6YRvhirz6h0Jn0e9vQA-Ayw-nui9ri9_DBLQE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的工业金属表面缺陷检测综述
{Author}: 伍麟;郝鸿宇;宋友
{Author Address}: 北京航空航天大学软件学院;
{Journal}: 自动化学报
{Year}: 2024
{Volume}: 50
{Issue}: 07
{Pages}: 1261-1283
{Keywords}: 表面缺陷检测;计算机视觉;金属表面缺陷;自动化检测
{Abstract}: 针对平面及三维结构金属材料的工业表面缺陷检测,概述了视觉检测技术的基本原理和研究现状,并总结出视觉自动检测系统的关键技术包括光学成像技术、图像预处理技术与缺陷检测器.首先介绍了如何根据检测对象的光学特性选择合适的二维、三维光学成像技术;其次介绍了图像降噪、特征提取、图像分割和拼接等预处理技术的重要作用;然后根据缺陷检测器的实现原理将其分为模板匹配、图像分类、图像语义分割、目标检测和图像异常检测五类,并对其中的经典算法进行了归纳分析.最后,探讨了工业场景下金属表面缺陷检测技术实施中的关键问题,并对该技术的发展趋势进行了展望.
{ISBN/ISSN}: 0254-4156
{Notes}: 11-2109/TP
{URL}: https://link.cnki.net/doi/10.16383/j.aas.c230039
{DOI}: 10.16383/j.aas.c230039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的太阳能电池片缺陷检测算法综述
{Author}: 刘玉淇;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 光学精密工程
{Year}: 2024
{Volume}: 32
{Issue}: 06
{Pages}: 868-900
{Keywords}: 太阳能电池;缺陷检测;机器视觉;深度学习;检测网络
{Abstract}: 太阳能电池片（Photovoltaic, PV）表面缺陷检测是光伏组件生产中不可或缺的流程。基于机器视觉的自动缺陷检测方法因其高精度、实时性、低成本等优点得到了广泛应用。本文综述了基于机器视觉的太阳能电池片表面缺陷检测方法的研究进展。首先，阐述了太阳能电池片表面成像方式，列举了典型缺陷类型。然后重点分析了基于传统机器视觉算法及基于深度学习算法进行太阳能电池片表面缺陷检测的原理。将传统机器视觉算法分为图像域分析法、变换域分析法进行综述；从无监督学习、有监督学习和弱监督及半监督学习三个方面分别概述了近几年来基于深度学习的太阳能电池片表面缺陷检测的研究现状。对太阳能电池片表面缺陷检测各种典型方法进一步细分归类和对比分析，总结了每种方法的优缺点。随后，介绍了9种太阳能电池片表面缺陷图像数据集及缺陷检测性能评价指标。最后，系统总结了太阳能电池片缺陷检测常见的关键问题及其解决方法，对太阳能电池片表面缺陷检测的未来发展趋势进行了展望。
{ISBN/ISSN}: 1004-924X
{Notes}: 22-1198/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxGMzefifTdmrM0hZTQ-iMmR75fRPI1-uk8YYdvf3HvGM3hmv3eH-zqtowQo_BFBrLxA7PD1ppRl-WAZ4q2VzJv7eVcB6Ttu7j9Atu0D6WPR5EkBi78sJb6JJqzZQOnnV49tSqhwy5kFLcv2qSaMv0VnoCwSVexgAynL6CVxj8Of4bagXsWk6vVsLJ9sy2t2ks=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的小车跟随行驶系统设计
{Author}: 张晨亮;张亚周
{Author Address}: 海军航空大学航空基础学院;
{Journal}: 物联网技术
{Year}: 2024
{Volume}: 14
{Issue}: 03
{Pages}: 118-119+122
{Keywords}: 机器视觉;循迹;智能小车;Arduino单片机;L298N;Open MV4;光电开关;PID
{Abstract}: 本系统以Arduino单片机为主控器,利用直流减速电机提供动力,PWM控制L298N实现调速,利用Open MV摄像头识别路线完成循迹。领头小车和跟随小车装有蓝牙模块用于车间通信,跟随小车车前装有光电开关以实现避障和跟随功能。两车利用PID循迹算法实现小车沿黑线前进,采用区域色块识别算法实现停车线的判断。经测试,小车功能稳定,传感器识别准确,很好地实现了设计要求。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2024.03.028
{DOI}: 10.16667/j.issn.2095-1302.2024.03.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于少样本学习的表面缺陷检测方法综述
{Author}: 陈丽;殷湘婷;靳启帆;姜晓恒;酒明远;徐明亮
{Author Address}: 郑州大学计算机与人工智能学院;国家超级计算郑州中心;郑州大学体育学院(校本部);
{Journal}: 郑州大学学报(理学版)
{Pages}: 1-12
{Keywords}: 缺陷检测;少样本学习;机器视觉;深度学习
{Abstract}: 工业场景中,缺陷样本少且标注缺陷耗时耗力,这限制了机器视觉方法应用于表面缺陷检测。对基于少样本学习的工业品缺陷检测方法进行梳理,从图像采集、图像处理、缺陷检测三方面介绍了基于机器视觉的工业品缺陷检测技术。将缺陷检测方法分为传统表面缺陷检测方法和基于少样本深度学习的缺陷检测方法。传统表面缺陷检测方法基于人工提取的特征识别缺陷,分为缺陷分割,人工特征提取,缺陷识别三部分。基于少样本深度学习的工业品缺陷检测方法包括数据增强、迁移学习、模型微调、半监督学习、弱监督学习、无监督学习方法等。然后,介绍了常用的缺陷检测数据集和检测结果评价标准。最后,讨论了基于少样本学习的表面缺陷检测存在的问题和未来研究方向。
{ISBN/ISSN}: 1671-6841
{Notes}: 41-1338/N
{URL}: https://link.cnki.net/doi/10.13705/j.issn.1671-6841.2023239
{DOI}: 10.13705/j.issn.1671-6841.2023239
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的岩石裂隙识别表征与软件研制
{Author}: 李元海;徐晓华;朱鸿鹄;杨硕;唐晓杰;赵万勇
{Author Address}: 中国矿业大学深地工程智能建造与健康运维全国重点实验室;中国矿业大学力学与土木工程学院;南京大学地球科学与工程学院;徐州工程学院土木工程学院;
{Journal}: 岩土工程学报
{Year}: 2024
{Volume}: 46
{Issue}: 03
{Pages}: 459-469
{Keywords}: 岩石裂隙;深度学习;图像分析;裂隙分离;裂隙表征
{Abstract}: 岩石裂隙特征是评判岩体结构及其完整性的核心指标，也是评估岩石工程安全稳定性的重要因素。针对岩石裂隙识别，采用深度学习方法，通过引入混合注意力机制对Unet模型进行了改进，有效提高了岩石裂隙识别的精度。针对交叉岩石裂隙的分离与特征提取，提出了一种基于迹线方向判定的裂隙分离与表征算法，依据裂隙分离的结果形式，采用重合追踪法或断裂追踪法分离交叉裂隙骨架，继而使用微分累加法、方框法、线性回归法求得裂隙的长度、宽度及倾角等几何特征指标。基于提出的算法，研制了一套具有图形用户界面的岩石裂隙图像智能识别与表征软件系统，实现了从深度学习模型参数选择、模型训练、裂隙识别、量化分析到结果可视化的完整功能。最后对岩石裂隙识别与分离表征算法的性能进行了评判，结果表明，改进Unet模型对复杂分布的裂隙识别效果最好，其总体识别性能要优于其他网络；骨架分离算法对常见类型交叉裂隙能够取得预期结果，表征算法对分离裂隙与交叉裂隙的表征精度高，对实际岩石裂隙图像的应用效果较好。研究成果可为基于计算机视觉的岩石工程试验与岩体结构检测技术研发提供参考依据。
{ISBN/ISSN}: 1000-4548
{Notes}: 32-1124/TU
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvysfHNpoya3fe8ejQndXsx8cs_97uO3gslf0hP-6QhOHdBxpixSLmh9eNyEi_JEB48lyK9yqUBddL_IKgiZs3rHFKtZ4GUOgfckS9GY8Q_RDnh-x7QpcYkBpQCWBOnD_US8wtyV9iXH7itzw_xti5g51Yln_JNewSQwFLkq89tZeI_9Glrk0RtmXwqbArLiCV4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的小麦锈病图像识别和遥感监测研究
{Author}: 常升龙
{Tertiary Author}: 赵春江
{Publisher}: 河南农业大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 小麦锈病;深度学习;锈病识别;无人机遥感;病情监测
{Abstract}: 小麦是中国三大粮食作物之一,小麦产量关系着国家粮食安全,对社会稳定和国民经济发展具有至关重要的意义。病害会对小麦产量产生重大威胁,锈病是小麦最主要的病害之一,也是小麦田间管理中的主要防治对象。在当前的小麦病害田间管理中存在“识别不准确、发现不及时、防控不精准”等问题。本研究探索使用现代化信息技术改造传统的病害识别和监测手段,以帮助农民及时、精准地防控小麦锈病。分别采集了小麦锈病的叶片水平图像和冠层水平无人机遥感图像,进行了基于深度学习的病害图像识别分类、发病中心遥感检测和发病区域遥感分割及其严重度分级评估。主要研究结果如下:
(1)混淆因素分析和注意力机制有助于提高小麦锈病图像识别精度。表型形态是造成三类锈病相互混淆的主要因素,本研究使用混淆矩阵查找出主要错分类别及其数量,综合分析导致分类错误的具体原因。据此针对性地改进数据集、模型结构和学习策略,分别创建了WRD(Wheat Rusts Dataset,小麦锈病数据集)、WDD(Wheat Disease Dataset,小麦常见病害数据集)和PDD(Poaceae crops Disease Dataset,禾本科作物常见病害数据集)三个数据集,提出了新的适用于小麦锈病图像识别的模型Imp-Dense Net。最终实现了小麦三类锈病的精准识别:Top-1 accuracy=98.32%(WRD)。消融实验结果表明,针对初步分类结果和三类锈病表型形态特征提出的名为PPRN的图像处理算法,对于提升分类精度的贡献度最大,达到5.19%,表明其可保障图像在模型内部各卷积层间流动时的特征稳定性。对于DenseNet模型结构的综合改造(SE注意力机制、SPPNet和因式分解思想的融入)效果也较明显,其对于分类精度提升的贡献度达到4.68%。证明了合适的卷积神经网络(Convolutional Neural Networks,CNN)模型可在学习锈病图像特征时实现有效的自我迭代,进而快速准确地识别病害类型。同时通过类激活热力图(Grad-CAM)及卷积计算焦点踪迹变化分析,可视化地呈现了模型改造的效果。通过与新兴模型的性能对比实验,证明了Imp-Dense Net的优越性能。通过对数据类别和数量的逐步扩充,实现了对小麦、玉米和水稻等禾本科粮食作物的常见病害的高精度、自动化识别分类,精度分别为:Top-3 accuracy=97.30%(WDD)和Top-5 accuracy=96.60%(PDD),验证了Imp-Dense Net的稳健性。
(2)提出一种优化的目标检测算法,可提供条锈病发病中心分布情况,实现了全田视角的早期预警。通过无人机和多光谱、可见光等多种机载传感器提取了试验田的多种光谱信息。针对遥感图像中早期条锈病发病中心小且多的特征,设计了小目标特征增强算法,实现了其功能模块(ESCD),并融入Yolov5目标检测模型进行结构改造。结合使用Vari Focal Loss损失函数和Swish激活函数,进一步加强了对小型发病中心的检测。结果表明新构建的Yolo-EVS模型检测精度达到95.53%(m AP),图像推理时间达到约15.9 ms/帧。在预测时间只比原模型慢了0.4 ms/帧的情况下,检测精度提高了10.02%。通过人工调查及目视解译,统计出试验田中发病中心总数为1628个,而通过Yolo-EVS模型预测的发病中心数目为1607个,发病中心数目召回率达到了98.71%(Recall)。结果表明所改进的算法和模型有效改善了大田中小型发病中心的漏检和误检情况,实现了对小麦条锈病发病中心的全田视角高精度、快速目标检测。同时也证明了通过无人机获取RGB图像进行小麦条锈病发病中心早期预警的可行性,且具有流程和操作简单、灵活且成本低的优势,具备推广应用价值。
(3)提出一种语义分割算法,可结合地理信息实现小麦条锈病发病区域实例分割,结合可见光大气阻抗指数(VARI)可实现各个发病区域的严重度分级评估。实验过程中验证了多模态数据可作为制作发病区域语义分割标签的有效参考,并验证了多分支二分类和集成学习框架对语义分割精度提升的正向作用:发病区域总体实例分割精度达到94.13%(mean F1-score),较单分支多分类的mean F1-score值提升了10.72%,总体分割精度提升了6.39%(mean F1-score)。实现了小麦条锈病发病区域的精确实例分割的同时,其发病区域数目召回率达到96.03%(Recall),发病区域轮廓逐像素检测的准确率达到93.00%(F1-score),发病区域与非发病区域轮廓分割的交并比达到91.02%(FWIo U)。通过叶片水平严重度人工调查,验证了小麦条锈病发病区域实例分割和冠层水平严重度分级评估结果的可靠性,其中严重度评估方面,与316个发病区域地面调查结果的严重度匹配准确度达到94.62%。结合前述发病中心目标检测的结果,实现了小麦条锈病发病区域的中心坐标、发病面积、发病区域轮廓和各个发病区域的严重度等量化数据的自动获取,并实现了有明显颜色梯度区分的发病严重度分级结果自动化制图。最终结果证明了使用VARI指数计算发病区域严重度的方法可行性,同时证明了使用改造的算法(SUNet)进行无人机遥感图像进行小麦条锈病发病区域实例分割在技术和性能方面的可行性和可靠性,可为后续的精准施药作业提供量化数据支撑。
本研究使用深度学习技术对小麦锈病分别进行了叶片水平和冠层水平的识别和监测,在实验中由简单到复杂地融入了图像分类、目标检测和图像分割等当前计算机视觉领域的三大图像处理任务。首先,构建了用于小麦锈病图像分类任务的Imp-Dense Net模型,主要解决作物病害“是什么?”的识别问题。然后,构建了用于小麦条锈病遥感目标检测任务的Yolo-EVS模型,实现对大田中早期发病中心的精确定位和统计计数,降低了小型发病中心的漏检率和误检率,主要解决病害“在哪里?”的定位问题。最后,构建了用于小麦条锈病遥感图像实例分割任务的SUNet模型,实现了发病区域的精细化实例分割和严重度分级评估,为评估全田发病情况和制定防治策略提供更加精准、客观的参数,主要解决了作物病害“怎么样?”的严重度评估问题。本研究不仅提升了小麦锈病识别和监测的自动化和智能化水平,还为其他农作物病害的识别和监测提供了有效参考和方法借鉴。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2024.000004
{DOI}: 10.27117/d.cnki.ghenu.2024.000004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的草莓目标识别与定位方法研究
{Author}: 吴晨波
{Tertiary Author}: 罗强
{Publisher}: 重庆三峡学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 草莓采摘;图像识别;YOLOv8;Azure Kinect;三维定位
{Abstract}: 草莓果实鲜美可口,具有丰富的营养价值,受到广大消费者喜爱,且每年产量巨大。目前草莓收获主要以人工采摘的方式进行,需要耗费大量人力,采摘成本高。随着我国对农业机械化的重视,果蔬自动化采摘概念被提出并不断发展。要想实现草莓自动化采摘,首先要能识别并定位到草莓位置,现如今的图像识别技术,还存在对小目标草莓识别精度不高,复杂草莓生长环境下识别效率低等问题。本文研究自然环境下草莓果实的识别与定位方法,针对草莓果实较小,生长环境复杂的特点改进YOLOv8算法,提高算法对实际生长环境中草莓的检测能力,并使用改进算法与深度相机结合进行三维定位。为草莓采摘机器人视觉系统研究提供参考,以推动草莓的机械化采摘。主要内容如下:(1)实际草莓生长环境中的图像采集及数据集制作。要实现草莓识别功能,需要草莓图像数据集,在草莓园拍照,从不同拍摄距离、不同拍摄角度获取草莓图像,确保在对YOLO算法进行训练时所用数据集具有普遍草莓果实的代表性。并对采集的图片通过自由旋转、加入高斯噪声、加入椒盐噪声的方式进行数据扩充,增加算法对草莓识别的泛化能力并提高抗干扰能力,对图片进行标注,制作出草莓图像数据集。(2)草莓果实识别算法的改进。针对草莓实际生长环境复杂,目标较小的特点,对YOLOv8目标识别算法进行改进,以得到适合现实草莓识别的模型。在YOLOv8算法基础上进行如下改进:删除20×20像素大目标检测层,增加160×160像素小目标检测层,提高算法对小目标检测性能并轻量化网络模型,引入GAM注意力机制模块,提高对小目标检测的精确率,引入SPD-Conv模块,提高对草莓果实的召回率,分析YOLOv8算法中CIOU损失函数的不足,替换为EIOU损失函数,提高模型收敛能力。(3)进行消融试验、对比试验、数据集对比试验、预测结果对比试验、特征提取可视化以充分验证算法改进的有效性。实验结果表明改进模型能有效减少小型草莓漏检,复杂环境下草莓误检的情况,在GPU上对单张草莓果实图像检测时间为17.2ms,模型大小为2460KB。与原YOLOv8n模型进行对比,检测精确率提高1.3%,召回率提高2.1%,m AP值提高1.6%,模型体积缩减59.7%,便于算法模型的移动平台部署。(4)深度相机与图像识别技术结合的草莓果实三维定位。识别到图像中的草莓后,还需进行草莓空间定位。本文介绍了坐标系之间的相互转换原理,为获取Azure Kinect相机的内外参数和相关矩阵,使用MATLAB工具对相机进行标定实验。利用改进的算法识别模型识别彩色图,得到的像素坐标与深度图配准并进行坐标转换,得到草莓果实相对于相机的三维坐标,对三维坐标进行误差分析,发现本文识别定位方法的相对误差小于2%,能满足实际采摘要求。最后在实验室进行草莓采摘试验,以判断识别定位方法的可行性。
{URL}: https://link.cnki.net/doi/10.27883/d.cnki.gcqsx.2024.000303
{DOI}: 10.27883/d.cnki.gcqsx.2024.000303
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的工业缺陷检测研究进展
{Author}: 洪景山;祝颖丹;宋康康;吕东喜;陈明达;胡海根
{Author Address}: 浙江工业大学计算机科学与技术学院;中国科学院宁波材料技术与工程研究所浙江省机器人与智能制造装备技术重点实验室;
{Journal}: 计算机科学
{Year}: 2024
{Volume}: 51
{Issue}: 10
{Pages}: 261-275
{Keywords}: 深度学习;机器视觉;缺陷检测;神经网络
{Abstract}: 基于深度学习的机器视觉技术在工业缺陷检测上具有重要的应用价值，相较于传统方法可显著提高检测质量和效率，同时降低人工成本。通过分析近年来深度学习在缺陷检测方面的研究与应用，归纳其难点与相关的解决方法，将问题分为缺陷数据集在建立过程中存在的问题与检测模型的选择两个方面。首先，在数据层面，针对缺陷的样本少、数据标注类型复杂、数据成像质量低等问题，对应分析了少样本学习，无监督、半监督、自监督、弱监督学习以及数据增强、图像增强、图像翻译的应用；其次，在检测算法模型的选择上，根据模型类型的不同，分为基于CNN、基于Transformer以及混合模型3类进行讨论，同时根据检测任务需求的不同，又分别从图像分类、目标检测、语义分割3个方面展开论述。此外，总结了工业上常用的轻量化模型的设计方法。最后，对该领域未来的发展方向进行了讨论与展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20240221.1709.014
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的土木工程计算机视觉健康监测
{Author}: 方成;于盛鑫;李永刚;贾王龙;杨鹏博;杨欣悦
{Author Address}: 同济大学土木工程学院;中国二十二冶集团有限公司;
{Journal}: 同济大学学报(自然科学版)
{Year}: 2024
{Volume}: 52
{Issue}: 02
{Pages}: 213-222
{Keywords}: 深度学习;计算机视觉;土木工程;全生命周期;健康监测
{Abstract}: 土木工程领域的健康监测对保证工程长期、稳定服务有着重要的意义。相较于传统的监测方法,基于深度学习的计算机视觉技术具有高效、准确等优势。对基于深度学习的计算机视觉技术在土木工程全生命周期健康监测领域中的应用进行系统综述。首先,借助文献可视化软件对该领域文献进行科学计量分析;其次,简要阐述了计算机视觉技术的发展历程,总结了在构建深度学习数据集过程中数据获取、数据处理和数据标注三个重要环节的方法与内容;最后,重点回顾了在施工现场安全管理、在役结构局部损伤检测和结构灾后整体损伤评估等应用场景中基于深度学习的计算机视觉技术的发展历程与工程实际应用价值,并展望了可拓展的应用方向。
{ISBN/ISSN}: 0253-374X
{Notes}: 31-1267/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyCIJOgp6dpQxjphlT3kX9oTrMzO3PK9Tzm68eQGwD1sO7Cd-RuVjdtGzJqaInaMzU_5aNtRCvOc0wVX7DRZAf4Yz95E4lWCK0RQCjC34wFyWB_RvxVdA53505Cq17VH1XBBxi04ysy8MiZetc-O-jeuUW1JiAXloGxx2FWssYbGAMIjSH-627sn7QKGbXX1V0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工件识别和定位系统设计
{Author}: 张家宁;刘星龙;支勇超;张晓萍;张健华
{Author Address}: 苏州大学应用技术学院;苏州特斯迈智能制造股份有限公司;
{Journal}: 科学技术创新
{Year}: 2024
{Issue}: 04
{Pages}: 64-67
{Keywords}: 机器视觉;视觉定位;图像识别;定位;VisionPro
{Abstract}: 目前在制造工业产线上的机械手大多采用人工输入指令控制执行机构运动，只能完成固定模板下的操作，对于一些复杂工况很可能致使机器人运作失败。这一定程度上导致生产成本升高，工作效率低和自动化程度降低。在制造产线中增加机器视觉技术，将机器视觉中的远程检测、图像识别、定位和引导等技术引用到机器控制系统中，使得机器能够自主应对环境变化，可以提高机器工作的智能化和自动化。本文将机器视觉引入工业机器自动化生产线并通过视觉识别与引导实现工件定位和抓取。着重对系统搭建的关键步骤、相机与机器坐标的统一和工件识别算法进行设计和开发。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwz0WbqQlIwhhwxRDAZaoM0VDQKbPDRpaR83QG8ZFNZ6JB6ycTVqmx8UwH-3Ah8dps9_rLtHE-6r0gOUnNQ2X5vjFmh0FtXXQ77Kg3nmshTAQu62q1ldTdyGrkKD-sJ9oz8lxEEkcRAqcTtdfB0qQd-5nMU0-GrzaQmbTK6tPvXZBsh-LOJMfdMDe8IXRIXdXE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 工业机械臂辅助机器视觉的工件识别与定位
{Author}: 刘文婧;卢子航;王建国;王少锋
{Author Address}: 内蒙古科技大学机械工程学院;
{Journal}: 组合机床与自动化加工技术
{Year}: 2024
{Volume}: 
{Issue}: 01
{Pages}: 53-57+62
{Keywords}: 工业机械臂;机器视觉;图像预处理;模版匹配;坐标转换
{Abstract}: 传统的工业机器人系统由于缺乏感知判断能力，很难适应目标种类和位置的变化，而现代工业需要生产不同种类和规格的产品。为此，以多品种小批量生产的零件为背景提出了一种机械臂辅助机器视觉系统，该系统能够实现对工件的图像采集并进行预处理，通过改进的Canny轮廓的提取算法与基于Hausdorff距离的模版匹配完成对不同种类工件进行识别和定位。最后经实验的验证该系统的定位精度在0.35 mm内，基本满足了在实际生产中对小批量生产、不同形状且没有固定夹具的目标工件的抓取、搬运与检测等要求。
{ISBN/ISSN}: 1001-2265
{Notes}: 21-1132/TG
{URL}: https://link.cnki.net/doi/10.13462/j.cnki.mmtamt.2024.01.012
{DOI}: 10.13462/j.cnki.mmtamt.2024.01.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于COF-YOLOv 8n的油茶果静、动态检测计数
{Author}: 王金鹏;何萌;甄乾广;周宏平
{Author Address}: 南京林业大学机械电子工程学院;
{Journal}: 农业机械学报
{Pages}: 1-15
{Keywords}: 油茶果;机器视觉;YOLO v8n;计数;产量估计
{Abstract}: 针对自然环境下油茶果存在严重遮挡、近景色、小目标等现象，使用原YOLO网络存在检测精度低、漏检现象严重等问题，提出对YOLO v8n网络进行改进。首先使用MPDIOU作为YOLO v8n的损失函数，有效解决因为果实重叠导致的漏检问题；其次调整网络，向其中加入小目标检测层，使网络能够关注小目标油茶以及被树叶遮挡的油茶；最后使用SCConv作为特征提取网络，既能兼顾检测精度又能兼顾检测速度。改进后的COF-YOLO v8n网络的P、R、mAP分别达到97.7%、97%、99%，比未改进的YOLO v8n分别提高3.2、4.8、2.4个百分点，其中严重遮挡情况下油茶的P、R、mAP分别达到 95.9%、95%、98.5%，分别比YOLO v8n提高4.0、9.1、4.6个百分点。因此COF-YOLO v8n网络能够明显提高油茶在严重遮挡、近景色、小目标均存在条件下的识别精度，减小油茶的漏检情况。此外，模型能够实现动、静态输入条件下油茶果的计数。动态计数借鉴DeepSORT算法的多目标跟踪思想，将COF-YOLO v8n的识别输出作为DeepSORT的输入，实现油茶果实的追踪计数。所得改进模型具有很好的鲁棒性且模型简单可以嵌入到边缘设备中，不仅可用于指导未来的自动化采收，还可用于果园的产量估计，为果园物流分配提供可靠借鉴。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20240117.0910.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的车用制动盘质量检测技术研究
{Author}: 孔敏
{Tertiary Author}: 庞茂
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 制动盘;机器视觉;光源仿真设计;缺陷检测;尺寸检测
{Abstract}: 车辆制动系统可以起到减速和驻车作用,制动盘作为其重要组成部件,与驾驶安全紧紧相连。制动盘铸造时产生的气孔和裂纹等缺陷会影响到制动盘的寿命,其直径尺寸误差和周向分布的安装孔同心度等关系到制动盘与车辆其他零件装配情况。现在多数工厂中仍然是人工检测制动盘质量,通常在光照良好的环境下仅需人眼识别缺陷,使用游标卡尺或千分尺等机械仪器测量直径尺寸,使用三坐标测量机测量同心度。因此人工检测准确度不高、自动化程度低,而机器视觉技术作为建设智慧工厂的重要环节,在制造行业中应用的比重将会越来越大。本文是基于机器视觉对车用制动盘质量检测技术进行研究,主要从光源仿真优化设计和制动盘缺陷尺寸检测两方面展开,具体研究内容如下:
(1)根据制动盘检测要求完成工业相机选型、镜头选型和光源设计工作,并且根据选型结果搭建视觉检测平台,在采集图像前进行标定。
(2)对于光源仿真优化设计部分,针对制动盘成像特点,首先定义了多种照度均匀度和亮度均匀度计算方法,并以此作为光源设计的评价指标。运用Light Tools软件仿真分析照度均匀度和亮度均匀度与光源曲面结构、条形灯数量、条形灯旋转角度变化关系,然后对比分析仿真结果与搭建的光源的亮度均匀度关系,结果表明二者存在相关性。最后将所设计的光源与市场现有光源采集图像对比,可以明显看出所设计的全遮光侧板三折面型光源均匀度效果最佳,照度均匀度达到0.85。
(3)对于制动盘缺陷检测和尺寸检测部分,首先采用峰值信噪比和结构相似性指数度量评价四种滤波后图像质量,结果表明制动盘成像图像的双边滤波降噪效果好。其次采用最大类间方差法分割降噪后的图像以定位出工作区域。然后对比多种边缘检测算子,发现亚像素Canny算子边缘检测效果最优。最后采用Blob分析方法检测线条型缺陷,采用亚像素Canny算子检测孔洞型缺陷和安装孔等圆孔尺寸轮廓,使用最小二乘法拟合圆,可得到圆孔直径尺寸和同心度,此测量值与人工检测的测量值的误差符合检测要求。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000145
{DOI}: 10.27840/d.cnki.gzjkj.2024.000145
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的电力巡检机器人自动化系统设计
{Author}: 黄松涛
{Author Address}: 国网内蒙古东部电力有限公司通辽供电公司;
{Journal}: 自动化技术与应用
{Year}: 2024
{Volume}: 43
{Issue}: 01
{Pages}: 35-38+43
{Keywords}: 机器视觉;转向电机;电力巡检机器人;自动化系统;CCD摄像机
{Abstract}: 为实现巡检中更低的误检率，设计一种基于机器视觉的电力巡检机器人自动化系统。利用远距离激光雷达配合多种设备，实现机器人的定位导航。根据图像预处理模块能够实现巡检图像的色彩分割、降噪滤波等处理。总控平台模块主要由六部分构成，分别为图像识别单元、核心服务单元等。通过硬件与软件相结合实现机器人的电力巡检功能。实验结果表明，设计的机器人运动指标良好，能够实现高效变电站巡检，同时系统的巡检导航性能良好，巡检误检率较低，说明系统满足设计需求。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2024)01-0035-05
{DOI}: 10.20033/j.1003-7241.(2024)01-0035-05
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: AI机器视觉工件自动检测系统
{Author}: 袁康祥
{Tertiary Author}: 张永炬;李强
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;无序抓取;6D位姿估计;Mask R-CNN
{Abstract}: 随着智能制造的进程不断加快,越来越多的生产商在推进产业链的自动化转型。其中,机械臂抓取与自动化视觉检测最为常见。本文针对无序堆叠场景,设计了一种2D/3D视觉融合的机械臂抓取系统,该抓取系统能够通过双目相机实现对目标物体的识别与定位,为机械臂提供详细的6D位姿。此外,针对工件的自动检测需求,选用汽车单向器设计了一种基于深度学习的单向器缺陷检测系统,提高工件的质检效率。本文主要研究内容如下:
(1)针对机械臂无序抓取与单向器缺陷检测的任务需求,进行基础理论的学习和研究。
(2)针对散乱堆叠的无序堆叠场景,设计一种基于眼在手上,利用双目相机提供RGB图像和深度图像,实现对复杂平面物体的定位和抓取的系统。为充分利用RGB-D的深度信息,基于Mask R-CNN网络结构添加一条深度图像特征提取分支,提高对目标识别与分割的精度。
(3)针对目标对象的位姿的位姿判断,通过深度图与RGB图的配准信息,将Mask映射到场景点云中,从中分割出目标点云。然后,利用Ransac算法进一步分割出工件的平面点云。使用PCA算法计算点云平面的OBB包围框,从而得到目标的6D位姿。最后,根据机械臂手眼标定结果,实现对目标的抓取操作。
(4)以汽车单向器装配为检测对象,设计了一种自动化检测系统,通过工业相机采集零件正面图像。基于分割网络和分类网络,实现对单向器的齿数、铜套、半圆片及倒角检测。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000020
{DOI}: 10.27840/d.cnki.gzjkj.2024.000020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于轻量级视觉模型的垃圾自动分类系统研究
{Author}: 张超军
{Tertiary Author}: 袁斌
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 垃圾分类;嵌入式;深度学习;轻量级模型;模型量化
{Abstract}: 随着社会经济的快速发展和居民生活质量的不断提升,垃圾分类对于提升居民生活环境质量和降低垃圾污染环境具有重要意义。但由于生活垃圾的种类繁多、人们的分类意识不强等原因,导致目前的垃圾分类效果依然不容乐观。近几年,利用机器视觉进行垃圾分类逐渐成为研究的热点,但传统的视觉模型存在网络参数量大、运行时间长、硬件设备成本较高等问题,并不适合在移动端或嵌入式等边缘端设备运行。因此,本文探索了一种更高效的基于Mobile Vi T轻量级视觉模型的智能垃圾分类系统,研究内容主要涉及了机械结构设计、嵌入式硬件和软件设计与开发、物联网小程序设计以及深度学习模型Mobile Vi T训练与量化,具体内容如下:
首先,本文针对机械结构部分创新性地设计了一种可以分类四种占比不同的垃圾、两种工作模式自动切换的智能垃圾分类箱。该垃圾箱利用STM32控制多种传感器和电机,包括距离传感器、人体感应传感器以及步进电机等电子元件。同时,STM32与INA226模块通过IIC协议通信,能够实时检测电源电量并根据剩余电量的不同切换智能垃圾箱的工作模式。树莓派4B采集并识别垃圾图像,通过与MCU串口通信传输识别结果,MCU再根据结果执行分类投放任务。MQTT服务器作为消息代理实现微信小程序与硬件设备的物联网通信,能够提高工作人员的管理效率。
其次,本文基于Tensor Flow深度学习框架构建了轻量级视觉模型Mobile Vi T,并利用自建的20种垃圾数据集进行模型训练,同时引入了迁移学习的思想,进一步提高了模型的训练效率和准确率。与传统Res Net50、Alex Net等模型相比,本文所构建的Mobile Vi T模型的识别准确率达到了98.01%,而且其模型参数量仅有5.6M,远小于Alex Net的61.10M和Res Net50的25.56M。为验证模型对未知的图像数据依然能够准确识别,收集了生活环境中的20种垃圾作为模拟仿真的输入,结果表明能够满足实际应用需求。为使模型Mobile Vi T能够表现出更好的综合性能,对模型进行了量化处理,量化后的模型体积大幅减小,对嵌入式等资源有限的设备表现出了友好性。
最后,搭建智能垃圾分类箱实物用于整个系统的功能和性能测试,主要测试电源电量检测、微信小程序通信和垃圾识别与分类等方面。经过测试,各功能均能够按照预期设计正常工作。其中,在性能测试方面,训练后量化的模型虽然在准确率上相比于仅转换的模型下降了4.0%,但其内存占用降低了70.7%,平均识别时间减少了61.5%,体现了模型量化对于提高其综合性能的重要意义。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000010
{DOI}: 10.27840/d.cnki.gzjkj.2024.000010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的时间序列分类研究综述
{Author}: 任利强;贾舒宜;王海鹏;王子玲
{Author Address}: 海军航空大学;
{Journal}: 电子与信息学报
{Year}: 2024
{Volume}: 46
{Issue}: 08
{Pages}: 3094-3116
{Keywords}: 深度学习;时间序列;神经网络;分类;综述
{Abstract}: 时间序列分类(TSC)是数据挖掘领域中最重要且最具有挑战性的任务之一。深度学习技术在自然语言处理和计算机视觉领域已取得革命性进展，同时在时间序列分析等其他领域也显示出巨大的潜力。该文对基于深度学习的时间序列分类的最新研究成果进行了详细综述。首先，定义了关键术语和相关概念。其次，从多层感知机、卷积神经网络、循环神经网络和注意力机制4个网络架构角度分类总结了当前最新的时间序列分类模型，及各自优点和局限性。然后，概述了时间序列分类在人体活动识别和脑电图情绪识别两个关键领域的最新进展和挑战。最后，讨论了将深度学习应用于时间序列数据时未解决的问题和未来研究方向。该文为研究者了解最新基于深度学习的时间序列分类研究动态、新技术和发展趋势提供了参考。
{ISBN/ISSN}: 1009-5896
{Notes}: 11-4494/TN
{URL}: https://link.cnki.net/urlid/11.4494.TN.20240109.0749.008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的人脸图像编辑与修复方法研究
{Author}: 许王均
{Tertiary Author}: 林志洁
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 生成对抗网络;人脸编辑;人脸修复;计算机视觉
{Abstract}: 人脸图像合成在计算机视觉领域发挥着关键作用,涵盖了广泛的应用,如人脸编辑、人脸修复以及人脸交换等。这些问题涉及计算机视觉和计算机图形学的交叉领域研究。在影视娱乐业、医疗美容、刑事侦查等领域有迫切的应用研究需求。近年来,随着数字图像处理的不断进步,特别是生成对抗网络技术的提升,为人脸合成技术的发展开辟了新的道路。但是仍然存在诸多挑战和问题,例如编辑人脸属性以及人脸图像修复任务中,图像模糊和局部失真等问题亟待解决。本文基于生成对抗网络模型,探讨了人脸图像合成技术的两个主要方向:人脸编辑和人脸修复。主要研究工作内容是:
(1)针对现有人脸属性编辑模型在细节信息的提取方面存在局限,在编辑人脸中指定属性时,存在破坏部分人脸细节或者编辑能力不足,以及属性解耦能力不足等问题,因此提出一种基于融合多重注意力机制的人脸属性编辑方法。基于生成对抗网络框架,在编码器-解码器的卷积层中加入了外部注意力机制,用于建模跨图像区域中处理线性复杂性。在编码器中将门控循环单元结构和加性注意力结合构造新的跳跃连接单元,帮助模型在生成过程中关注重要的特征区域,使生成的人脸更加真实和连贯。对判别器进行改进,在中间特征层加入全局注意机制和空间通道重建卷积,显著增强了判别器在定位空间区域以及与特定属性相关的区域上的能力,对面部编辑精准控制,确保编辑仅应用于与目标属性关联的面部图像区域。实验结果表明,该方法能够提高属性编辑能力和细节保存能力,并且可以增强对编辑属性进行细粒度控制的能力。相比于Att GAN、STGAN和MUGAN,它在编辑属性的准确性和所生成图像的质量方面表现更出色。
(2)针对修复后人脸图像出现纹理丢失、细节缺失,局部失真等问题,提出基于Transformer和GAN的人脸修复模型(Bidirectional Transformer-Enhanced GAN,BLE-GAN)。构建了可学习的双向注意图和Transformer融合的人脸图像修复模块,通过级联多个Transformer模块来构造从浅到深的Transformer信息传播路径,利用Inception、Res2Net以及全局注意力进行多尺度特征提取,网络能鲁棒性地捕获纹理和深度之间的潜在交互信息,进一步提高模型的人脸修复能力。通过与LBAM和RGINP两种修复方法的实验对比分析,实验结果表明,该方法生成的人脸修复图像可以实现损坏区域与周围图像的平滑过渡,避免明显的边缘不连贯性。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000155
{DOI}: 10.27840/d.cnki.gzjkj.2024.000155
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深地工程多维信息感知与智能建造的发展与展望
{Author}: 张茹;吕游;张泽天;任利;谢晶;张安林;严志伟;米欧
{Author Address}: 四川大学水利水电学院;四川大学深地工程智能建造与健康运维全国重点实验室;四川大学深地科学与工程教育部重点实验室;四川大学山区河流保护与治理全国重点实验室;
{Journal}: 煤炭学报
{Year}: 2024
{Volume}: 49
{Issue}: 03
{Pages}: 1259-1290
{Keywords}: 深地工程;人工智能;实时响应;信息解译;数据分析;智能决策
{Abstract}: 随着大数据、云计算、人工智能等数字技术的加速演进，各领域智能化、信息化、数字化已成为未来的大势所趋。深地工程作为国家重大战略科技问题，必然面临智能化升级。然而，深部岩体“三高一扰动”的复杂特征给深地工程智能化转型带来严峻的挑战。为实现深地工程与数字技术的高效融合，研究基于“感知-传送-解译-分析-决策”的智能化实践路径，系统回顾了地下工程中智能感知、实时传输、信息解译、数据分析、智能决策等领域的代表性研究进展，并针对性提出了“多感知、快响应、大数据、优方法、精模型、强平台、易推广”的深地工程智能建造发展方向。研究表明：(1)前沿的深地工程感知技术包括：光纤传感器、MEMS传感器、计算机视觉、自动化机器人等，待数据采集完毕后，通过兼具配置简单、容错能力强、可移动性好等优点的无线通信协议完成数据的实时响应，以实现深地工程监测数据的精准感知与实时传输；(2)深地工程原位监测技术获取的数据类型主要包括图像、波、点云等，对原始数据解译及分析的模型众多，采用新一代的人工智能技术，如：人工神经网络和深度学习技术，可显著提高解译与分析的效率；(3)智能决策系统具备高效的学习能力，能够适应复杂环境下的不确定性，通过循环自主学习，以进行决策问题的智能解答。当前，我国深地工程智能建造的政策与产业体系已基本建立，大量智能建造系统已应用于实践。基于此，从智能感知与信息解译、围岩评价及安全评估、围岩控制与动态修复、平台开发及应用推广等4个方面展望了数智化深地工程的发展方向，进而构建了基于多源信息的深地工程围岩稳定性综合评价与分析系统构想。
{ISBN/ISSN}: 0253-9993
{Notes}: 11-2190/TD
{URL}: https://link.cnki.net/doi/10.13225/j.cnki.jccs.2023.1439
{DOI}: 10.13225/j.cnki.jccs.2023.1439
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的断层识别与曲面重建研究
{Author}: 王子叶
{Tertiary Author}: 韩晓虎;李磊
{Publisher}: 河北地质大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 断层分割;断层重建;合成数据集;图像分割;目标追踪
{Abstract}: 在油气勘探领域,断层作为关键性的地质特征,不仅是油气运移的通道,还能为确定最佳钻井位置提供可靠信息。因此准确识别断层对于地质研究和实际生产意义重大。传统的断层解释工作是采用人工解释的方法,这种方法存在成本高、费时费力等问题,同时解释人员的主观判断也可能会带来误差。随着地震勘探规模的扩大,人工解释方法难以满足如今高精度高效率的需求,因此多种智能化、自动化断层解释方法应运而生。尤其是计算机运算速度的提高以及统计学习算法理论的逐步完善,利用机器学习和深度学习算法智能识别断层特征引起很多学者的关注。本文基于深度学习模型,提出了一种断层分组与曲面重建一体化算法,从二维角度出发对断层实例进行分割,再将不同剖面的断层实例进行组合重建。首先基于Cycle GAN网络,将随机的直线图像作为输入,生成与之匹配的合成断层图像。生成的合成断层图像不仅增加了实例分割网络训练样本的数量,还能够增加样本的多样性,为解决地质数据中样本数量不足的问题提供了新的思路。其次提出了一种基于半监督K均值聚类算法的断层标签制作方法,采用空间密度相似性度量来代替欧式距离,然后通过直线图像中得到的少量标签数据指导合成断层图像中的无标签数据聚类,得到为实例分割网络训练准备的实例标签。最后使用一种轻量级实例分割模型进行训练,并将训练后的模型应用到实际工区的断层预测中。在二维断层实例分割的基础上,将断层剖面看作时间序列,利用相邻剖面间的相似性,将卡尔曼滤波等理论应用于断层实例的追踪,实现快速的断层组合与重建。
{URL}: https://link.cnki.net/doi/10.27752/d.cnki.gsjzj.2024.000258
{DOI}: 10.27752/d.cnki.gsjzj.2024.000258
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的表面缺陷检测技术研究进展
{Author}: 李键;李华;胡翔坤;李少波;乔静
{Author Address}: 贵州大学省部共建公共大数据国家重点实验室;清华大学机械工程系;新疆科技学院信息科学与工程学院;
{Journal}: 计算机集成制造系统
{Year}: 2024
{Volume}: 30
{Issue}: 03
{Pages}: 774-790
{Keywords}: 计算机视觉;深度学习;图像处理;表面缺陷检测
{Abstract}: 随着计算机视觉技术的快速发展，基于深度学习的表面缺陷检测技术实现了爆发式的应用，并逐步成为了主流发展方向。基于深度学习的缺陷检测技术可以近似为计算机视觉任务中的分类、检测、分割等任务，其主要目的是找出物体表面缺陷的类别和所在位置，相较于传统图像处理方法，深度学习在特征提取能力和环境适应能力上优势明显。以缺陷数据标签类型为依据，对近年来基于深度学习的表面缺陷检测技术进行梳理划分，总结目前技术的优点与不足，重点阐述了监督学习下的三种缺陷检测方法。探讨了表面缺陷检测技术面临的小样本以及不平衡样本等关键问题：对于小样本问题目前有结构优化、数据增广、迁移学习等解决方法；针对不平衡样本问题，介绍了近年来热点的无监督、弱监督与半监督学习模型。随后介绍了常用的工业表面缺陷数据集并展现了近年来提出的算法在NEU数据集上的应用效果。最后对进一步的研究工作提出展望，希望能给缺陷检测研究提供有意义的参考。
{ISBN/ISSN}: 1006-5911
{Notes}: 11-5946/TP
{URL}: https://link.cnki.net/doi/10.13196/j.cims.2023.IM28
{DOI}: 10.13196/j.cims.2023.IM28
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv7的轻量级低照度目标检测算法
{Author}: 李昶昱;葛磊
{Author Address}: 南京理工大学瞬态物理重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2024
{Volume}: 61
{Issue}: 14
{Pages}: 365-372
{Keywords}: 机器视觉;低照度;目标检测;轻量级算法;YOLOv7
{Abstract}: 低照度目标检测是目标检测任务中常见的挑战之一。通用的目标检测方法在低照度条件下性能会明显下降，而现有的低照度目标检测方法会造成大量的计算资源消耗，并不适合部署在计算能力受限的设备上。为应对上述问题，提出一种端到端的轻量级目标检测算法LL-YOLO。针对低照度图像中特征信息不明显、难以学习与辨识的问题，设计低照度图像生成算法，通过生成低照度图像来训练检测器，帮助其学习低照度环境下的特征信息；并对检测器网络结构进行调整，减少特征信息在计算过程中的损失，提高模型对特征信息的敏感度。针对低照度图像中特征信息受噪声影响严重的问题，提出聚合周边信息的A-ELAN模块，使用深度可分离卷积与注意力机制捕获周边信息，增强获得的特征信息，减弱噪声的影响。实验结果表明，LL-YOLO算法在低照度目标检测数据集ExDark上平均精度均值（mAP@0.5）达到81.1%，相较直接训练的YOLOv7-tiny算法提高11.9百分点，相比于其他算法具有较强竞争力。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20231225.1150.056
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的目标检测算法综述
{Author}: 郭庆梅;刘宁波;王中训;孙艳丽
{Author Address}: 烟台大学物理与电子信息学院;海军航空大学信息融合研究所;
{Journal}: 探测与控制学报
{Year}: 2023
{Volume}: 45
{Issue}: 06
{Pages}: 10-20+26
{Keywords}: 目标检测;计算机视觉;深度学习;数据集;性能评估指标
{Abstract}: 目标检测在计算机视觉领域中有着举足轻重的地位，主要用于检测图像或视频中是否有目标物体，并能判断出目标物体的类别和位置。随着卷积神经网络不断优化，目标检测算法在速度和精度方面都得到了提升，在智能安防、自动驾驶以及工业检测等方面被广泛应用。以传统目标检测算法和基于深度学习的目标检测算法为主线，剖析传统目标检测算法的发展，并指出其存在的问题，详细阐述了基于深度学习目标检测算法的主要流程、创新点、优缺点以及在数据集上的实验结果，并对其未来的发展进行了展望。
{ISBN/ISSN}: 1008-1194
{Notes}: 61-1316/TJ
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwuVHpHgDjgmwIpWdhhEpeuPOA2SlYdYMOMil_3_-Jz02wLv5jlo8QPRkqbSdRnPquO1q0KWOcbFU4AtsJQOhwKszMLHkNvk7rOm9IeKZznLfdoGUIPY9Lu_9Qdiq90YDlUUFcZTo8apSTgxL4zwW4-MoQJ87Z4KTUALCld8htNRUOM9XtZ81uzt4vOmC1weio=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的丝锥检测系统设计及应用
{Author}: 潘俊杰
{Tertiary Author}: 夏如艇;庞茂
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 机器视觉;丝锥;图像处理;尺寸测量
{Abstract}: 丝锥是应用最为广泛的螺纹刀具,其制造精度不仅影响螺纹孔加工的质量和效率,也直接影响到丝锥本身的使用寿命。因此,对丝锥的测量具有重要意义。目前传统的丝锥测量方法已不能满足工业生产的要求,而基于机器视觉的测量方法具有速度快、精度高、劳动强度低等优点,成为了丝锥测量技术的发展趋势。本文研究基于机器视觉的丝锥测量系统,设计了丝锥几何参数的测量方法。本文的主要工作和成果如下:
(1)分析了丝锥结构特征,对丝锥几何参数测量系统进行总体方案设计。根据丝锥几何参数的测量要求,完成了对相机、镜头、光源等选型,构建了视觉测量系统的硬件平台。
(2)研究了传统的张正友相机标定算法,通过校正镜头畸变和透视偏差,从而获得高精度的标定结果。分析了图像清晰度评价函数,提出一种改进的清晰度评价函数,用于系统聚焦位置的判定。
(3)研究了视觉系统的关键算法。在图像预处理中,采用双边滤波算子降低图像噪声,使用最大类间方差法进行图像分割,利用形态学操作去除干扰。为了快速准确地定位测量区域,构建形状匹配结合仿射变换的算法,同时采用图像金字塔分层搜索策略提高匹配定位效率。采用改进的Zernike亚像素边缘检测算法对边缘进行亚像素细分。在几何基元拟合中,采用迭代重加权最小二乘法,减少了离群点的干扰。
(4)设计了丝锥几何参数的测量方法,实现丝锥芯厚、前角、刃宽、铲背量几何参数的测量。在Qt集成开发环境下,以模块化编程思想进行软件系统开发。通过测量重复性实验和测量对比实验,实验结果表明该测量系统具有较高的测量精度和测量效率。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000175
{DOI}: 10.27840/d.cnki.gzjkj.2024.000175
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉和改进YOLOv5s的鲫鱼病害轻量级无损检测模型研究
{Author}: 陈科
{Tertiary Author}: 蔡海莺;叶章颖
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 水产养殖;鲫鱼病害;无损检测;改进YOLOv5s;轻量级
{Abstract}: 水产养殖是我国农业经济的重要组成部分,对国民经济增长和国际贸易贡献巨大。水产养殖过程中,病害问题影响严重,鱼病一旦爆发传染性强、死亡率高,从而影响水产养殖的经济效益。因此水产养殖过程中鱼病快速精确检测对实际生产具有重要意义。目前鱼病检测手段主要依赖人工,耗时、精确度低且成本高。当前目标检测作为一种计算机视觉技术,在各类病害检测中的应用越来越广泛。但将目标检测应用于鱼病方面仍存在数据集收集困难、数据标注工作量大、实时性要求高等问题。对于上述问题,本研究主要针对四种鲫鱼常见的病害损伤进行探讨,构建适合鲫鱼病害检测的模型,并提升检测效率。具体的研究主题如下:
针对数据集收集困难、数据标注工作量大的问题,本文通过进行鲫鱼攻毒实验和数据采集,获取鲫鱼病害图像数据,通过Label Img软件对鲫鱼病害体表特征进行标注,并通过数据增强的方法,扩充数据集,获得了足够的鲫鱼病害数据集。
为解决鲫鱼疾病诊断对及时性的需求问题,本研究提出了一个以YOLOv5s为基础的轻型模型,这个模型采用Shuffle Net V2替代YOLOv5s的核心部分,并利用反向偏移式连接及通道混合技术进行了网络架构的优化,从而降低了模型的运算负担。通过一系列实验对比,结果显示本模型体积相较原YOLOv5s模型体积减少59930kb,表明了本模型对鲫鱼病害检测轻量化改进的可行性。
针对轻量化后模型精确率下降的问题,本文对轻量化后的模型进行三方面的改进。首要步骤是增加CBAM(Convolutional Block Attention Module)以提升网络的特性表达能力和强化其抗干扰性能;接着为了进一步优化网络的广域适应性和改善对于小目标的识别准确率,我们加入了ASPP(Atrous Spatial Pyramid Pooling)组件;最终,借助全新的损失函数SIOU(Symmetric Intersection over Union)来减少模型的运算负担,更有效地应对嘈杂的数据及失衡的情况。通过一系列实验对比,结果显示改进后的模型病害检测精度可达93.1%,模型体积大小仅为11840 kb,优于当前相关主流模型,为水产养殖鱼类病害无损快速检测提供了技术支撑。
最后,为了方便养殖户使用本模型,实现了一个鲫鱼病害检测系统的界面设计,通过对200张鲫鱼病害图片进行检测,总准确率高达94%,表明了本系统的可行性。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000096
{DOI}: 10.27840/d.cnki.gzjkj.2024.000096
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的目标检测综述
{Author}: 黄治翔;张艺骞
{Author Address}: 西华大学;
{Journal}: 科技资讯
{Year}: 2023
{Volume}: 21
{Issue}: 24
{Pages}: 13-16
{Keywords}: 目标检测;深度学习;计算机视觉;图像
{Abstract}: 目标检测是当前计算机视觉领域的核心问题之一，其任务是找出图像中所有感兴趣的目标，确定它们的类别与位置。由于每张图像中目标的数量、位置各有不同，所以目标检测一直具有极大的挑战力。深度学习的目标检测相对于传统的目标检测来说，效果显著，在一定程度上弥补了传统检测的不足。首先介绍传统目标检测算法，然后分别介绍深度学习算法，最后对当前目标检测领域存在的问题进行总结，并展望未来。
{ISBN/ISSN}: 1672-3791
{Notes}: 11-5042/N
{URL}: https://link.cnki.net/doi/10.16661/j.cnki.1672-3791.2312-5042-0876
{DOI}: 10.16661/j.cnki.1672-3791.2312-5042-0876
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于神经网络的图像风格迁移研究进展
{Author}: 廉露;田启川;谭润;张晓行
{Author Address}: 北京建筑大学电气与信息工程学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 09
{Pages}: 30-47
{Keywords}: 图像风格迁移;深度学习;卷积神经网络;注意力机制
{Abstract}: 图像风格迁移是用风格图像对指定图像的内容进行重映射的过程，是人工智能计算机视觉领域中的一个研究热点。传统的图像风格迁移方法主要基于物理、纹理技术的合成，风格迁移效果较为粗糙并且鲁棒性较差，随着图像数据集的出现和各种深度学习模型网络的提出，涌现了许多图像风格迁移的模型和算法。通过对图像风格迁移研究现状的分析，梳理了图像风格迁移的发展脉络和最新的研究进展，并通过对比分析给出了图像风格迁移未来的研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20231218.1248.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向图像分类的视觉Transformer研究进展
{Author}: 彭斌;白静;李文静;郑虎;马向宇
{Author Address}: 北方民族大学计算机科学与工程学院;图像图形智能信息处理国家民委重点实验室;
{Journal}: 计算机科学与探索
{Year}: 2024
{Volume}: 18
{Issue}: 02
{Pages}: 320-344
{Keywords}: 深度学习;视觉Transformer;网络架构;图像分类;自注意力机制
{Abstract}: Transformer是一种基于自注意力机制的深度学习模型，在计算机视觉中展现出巨大的潜力。而在图像分类任务中，关键的挑战是高效而准确地捕捉输入图片的局部和全局特征。传统方法使用卷积神经网络的底层提取其局部特征，并通过卷积层堆叠扩大感受野以获取图像的全局特征。但这种策略在相对短的距离内聚合信息，难以建立长期依赖关系。相比之下，Transformer的自注意力机制通过直接比较特征在所有空间位置上的相关性，捕捉了局部和全局的长距离依赖关系，具备更强的全局建模能力。因此，深入探讨Transformer在图像分类任务中的问题是非常有必要的。首先以Vision Transformer为例，详细介绍了Transformer的核心原理和架构。然后以图像分类任务为切入点，围绕与视觉Transformer研究中的性能提升、计算成本和训练优化相关的三个重要方面，总结了视觉Transformer研究中的关键问题和最新进展。此外，总结了Transformer在医学图像、遥感图像和农业图像等多个特定领域的应用情况。这些领域中的应用展示了Transformer的多功能性和通用性。最后，通过综合分析视觉Transformer在图像分类方面的研究进展，对视觉Transformer的未来发展方向进行了展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20231214.1551.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的隧道围岩智能识别分级与开挖安全风险研究
{Author}: 黄宏伟;陈佳耀
{Author Address}: 同济大学地下建筑与工程系,岩土及地下工程教育部重点实验室;北京交通大学土木建筑工程学院,城市地下工程教育部重点实验室;
{Journal}: 应用基础与工程科学学报
{Year}: 2023
{Volume}: 31
{Issue}: 06
{Pages}: 1382-1409
{Keywords}: 岩石隧道;机器视觉;图像特征;深度学习;围岩分级;数值模拟;多源异构数据;安全评价
{Abstract}: 岩石隧道建设正逐步进入到长、大、深、难工程阶段.采用新奥法开挖过程中，由于高度不确定性的围岩地质和富有经验的专家数量有限，施工过程面临巨大的围岩质量判别和开挖安全评价挑战.针对岩体结构特征表征模型、精细化分级及评价方法的科学问题，采用现场实测、数据统计、智能算法、数值模拟等手段，提出岩体工作面特征量化提取算法，建立了基于多源异构数据融合的围岩精细化分级模型，开展了复杂地质环境中隧道开挖的安全评价研究.取得了如下主要成果：针对软弱夹层、节理裂隙和地下水的图像语义分割，表观结构图像的分类及围岩的关键特征，基于建立的岩石隧道开挖面摄影图像数据库，应用深度学习算法、超参数与模块优化等方式，实现了特征信息的准确分类和精细化表征；建立了包含岩体几何、环境和物理力学参数的13维多源异构数据库，构建了TPE-GBRT混合预测模型，获取了混合机器学习模型最优化预测的参数组合，实现了围岩分级RMR指标的精准预测；构建了基于离散裂隙网络DFN的岩体地质环境，由此建立基于开挖面信息的3DEC三维隧道模型，应用强度折减法模拟了隧道连续开挖过程，评价了应力应变、剪切滑移等稳定性特征和安全状态.
{ISBN/ISSN}: 1005-0930
{Notes}: 11-3242/TB
{URL}: https://link.cnki.net/doi/10.16058/j.issn.1005-0930.2023.06.003
{DOI}: 10.16058/j.issn.1005-0930.2023.06.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 针对航拍小目标检测的YOLOv7改进方法
{Author}: 刘一诺;张琪;王蓉;李冲
{Author Address}: 中国人民公安大学信息网络安全学院;
{Journal}: 北京航空航天大学学报
{Pages}: 1-10
{Keywords}: YOLOv7;小目标检测;注意力机制;卷积神经网络;计算机视觉
{Abstract}: 针对目前检测技术在航拍小目标检测任务中存在的漏检率和误检率较高的问题，本文提出一种基于改进YOLOv7的航拍小目标检测方法。首先，在主干网络中加入CBAM融合注意力机制，将特征图在空间和通道两方面合理分配网络权重，抑制背景干扰，提升检测精度；其次，引入一种用于低分辨率图像和小目标细化检测的SPD-Conv模块，消除原有卷积模块的跨卷积层和池化层，解决了原始卷积模块中存在的细粒度信息丢失以及对于特征表示学习效率较低的问题；最后，在处理后的DOTA航拍数据集上进行性能评估。实验结果表明，改进的YOLOv7算法在处理后的DOTA航拍数据集上准确率P达到83.7%，召回率R达到78.2%，均值平均精度mAP50达到81.5%，比原始YOLOv7算法精度提升3.1%。说明本文提出的改进算法可以有效降低漏检以及错检率，具有良好性能。
{ISBN/ISSN}: 1001-5965
{Notes}: 11-2625/V
{URL}: https://link.cnki.net/doi/10.13700/j.bh.1001-5965.2023.0411
{DOI}: 10.13700/j.bh.1001-5965.2023.0411
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视频帧序列预测算法研究
{Author}: 晏婕
{Tertiary Author}: 秦贵和
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 深度学习;视频帧预测;渐进式特征融合;特征解耦;模型轻量化
{Abstract}: 视频帧预测是计算机视觉领域中一项重要的研究任务。视频帧预测算法通过观察输入的视频帧序列,在时空维度建模特征,整合并总结输入视频帧的动态规律,以完成对后续视频帧的推演。通过对不同观测对象构建视频类型的数据,视频帧预测算法可以在多个领域得到应用,从而辅助人类更好地进行生产、生活和科研活动。如通过为车辆驾驶场景构建视频帧序列数据,应用视频帧预测算法可以提前预测前方道路变化和行人的运动趋势,从而辅助自动驾驶车辆提前做出决策;将大气分布图序列化为视频,并结合视频帧预测算法推演后续大气变化情况,可以构建针对降水、飓风等极端天气的预警系统。由于其广泛的应用前景,视频帧预测算法的研究具有重要的应用和理论研究价值。本文基于深度学习方法,从不同角度对视频帧预测算法展开研究。具体来说,针对可观测视频帧长度较短的预测任务特点,提出一种时空特征渐进式融合的视频帧预测算法。针对一般化的视频帧预测任务,通过分析视频帧序列数据的特点,提出一种基于维度解耦与注意力机制的视频帧预测算法。针对现有深度神经网络模型轻量化的发展趋势,提出一种多粒度特征与非对称运动模式的轻量化视频帧预测模型。本文的主要研究内容和贡献如下:1.一种时空特征渐进式融合的视频帧预测算法当可观测视频帧长度较短时,对于视频帧预测任务而言,其主要难点在于可用于提取特征信息的视频帧数量有限。当依靠单一主干网络的模型同时建模时空维度特征时,很难充分提取特征信息,这导致预测结果在空间维度上存在模糊问题。针对可观测视频帧长度较短的视频帧预测任务,本文提出一种双流网络结构,分别在时间维度和空间维度进行特征建模。具体而言,模型由两个子网络组成,分别是时间子网络和空间子网络。其中,时间子网络对运动特征进行建模,通过输出的掩码信息最大限度地保留不随时间变化的静态区域特征,从而实现动态前景与静态背景的分离。空间子网络用于捕获空间维度特征,并构建预测结果的外观。随后,为了融合时空特征信息,本文提出一种时空特征渐进式融合算法。根据不同网络层提取特征的侧重点不同,从其对应的特点出发,提出三种不同的特征融合策略:密集特征融合、稀疏特征融合和高层级特征融合,并通过实验分析和验证最有效的特征融合方式。最后,本文使用UCF-101和KITTI数据集来验证和评估所提出模型的性能。与对比方法相比,所提方法在PSNR上取得了最好的效果,体现了所提方法的有效性。2.基于维度解耦与注意力机制的视频帧预测算法现有的视频帧预测算法通过优化卷积长短时记忆模块的内部结构来提升预测结果的质量。然而,这类优化过程通常会引入大量的功能性模块,导致优化后的卷积长短时记忆网络参数量大幅增加。此外,分析发现基于卷积长短时记忆模块的预测模型存在一定的缺陷,如空间位置存在预测偏差和预测结果外观模糊等问题。但其生成的预测结果仍然包含了较为丰富的特征信息,可被用于重建预测结果。综合上述观察,本文提出一种基于维度解耦与注意力机制的多注意力长短时记忆模型。该模型在卷积长短时记忆模块的基础上集成了两个模块,分别为维度解耦模块和通道注意力模块。其中,维度解耦模块对二维空间特征进行压缩,并在分解后的低维空间上构建运动模型,以降低模型建模运动特征的难度,并强化运动模式在时间维度上的传导;通道注意力模块捕获空间整体结构特征在通道维度上的表示,结合注意力机制以强化有效的通道级特征,从而在空间维度上实现对预测结果的整体结构优化,提升预测结果的空间特征表达。与现有方法对比,其预测结果在视觉感知和定量指标上都有所提高,验证了所提方法的有效性。3.多粒度特征与非对称运动模式的轻量级视频帧预测算法为了进一步提升结果的准确率,基于深度学习的网络模型逐渐向更大更深的方向发展。这种进化对硬件设备的存储和算力要求较高,在一般环境下难以部署运行,因而通常引入轻量化算法来平衡模型精度与参数体量大小。现有的轻量化算法主要针对二维图像模型,对三维视频模型的轻量化方法研究较少。基于这一出发点,本文提出一种轻量级视频帧预测算法。所提方法主要包括三个组件:非对称卷积核、细粒度特征提取模块以及粗粒度特征整合模块。非对称卷积核是一种轻量级卷积核,通过对运动方向分解,构建不同方向上的运动模型;细粒度特征提取模块通过增加网络的非线性,提升模型对空间特征的提取能力;粗粒度特征整合模块通过特征直连来整合不同层级特征信息,提升模型对特征的利用效率并缩短误差反向传播路径。实验表明,与卷积长短时记忆基线模型相比,提出的方法不仅精度有所提升,并且显著减少参数数量;与现有方法相比,所提模型可以在精度水平上基本持平,但参数量大幅减小。综上所述,本文从可观测视频帧长度、视频帧预测任务特点以及模型轻量化的角度出发,分别提出对应的视频帧预测算法。在不同数据集上对所提出算法加以实验和对比,分析并验证了所提算法的有效性。最后,结合目前硬件采集设备对数据的扩展和人工智能系统的发展趋势,从应用的角度对视频帧预测领域未来的研究发展方向进行分析与展望。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.007610
{DOI}: 10.27162/d.cnki.gjlin.2023.007610
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人分拣技术探讨
{Author}: 刘畅
{Author Address}: 宁夏职业技术学院;
{Journal}: 大众标准化
{Year}: 2023
{Volume}: 
{Issue}: 22
{Pages}: 42-44
{Keywords}: 工业机器人;机器视觉;分拣技术
{Abstract}: 随着工业4.0的深入发展，工业机器人在生产线的应用越来越广泛。文章基于机器视觉的工业机器人分拣技术展开研究。首先分析了工业机器人的应用现状和发展趋势，接着探讨了基于机器视觉的工业机器人分拣系统的构成和工作流程。随后，对视觉分拣技术的关键环节如摄像机标定、图像预处理以及特征识别和定位进行了深入剖析。最后，展望了基于机器视觉的工业机器人分拣技术的应用前景。
{ISBN/ISSN}: 1007-1350
{Notes}: 14-1101/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwvpHf73VbkbOzbAFIt9SvEh02Pbf9HXScmocxQy8E-982D29T3ysjwh0y-aAIHKaVbeqSWO_sPtPbp4IWUlObkgmd210DQBxqKvwEjZC4RP4edZFN2ad3ELPXysZsVQMNzoP1p3ihEUoyCRl7tOALJkvarBXfivhSLjxCLb2ie_uTka7aTEwDX61nWRYbML7k=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像的野生动物检测与识别综述
{Author}: 柯澳;王宇聪;胡博宇;林琦;李勇;双丰
{Author Address}: 广西大学电气工程学院;
{Journal}: 计算机系统应用
{Year}: 2024
{Volume}: 33
{Issue}: 01
{Pages}: 22-36
{Keywords}: 野生动物;监测;目标检测;图像分类;综述;机器视觉
{Abstract}: 野生动物监测对于野生动物保护和生态系统维护至关重要,而野生动物的检测与识别是实现监测的核心技术.近年来,随着计算机视觉技术的迅速发展和广泛应用,基于图像的非接触式方法在野生动物监测领域引起了广泛的关注,研究人员提出了各种方法来解决该领域的不同问题.然而,野外环境的复杂性使得对野生动物进行精确检测和识别仍具有一定的挑战.为了推动该领域的研究,本文对现有的基于图像的野生动物监测方法进行了综述,主要包括3个部分:野生动物图像获取方法、野生动物影像预处理方法以及野生动物检测与识别算法.文章按照图像数据集和野生动物检测与识别算法的不同处理机制对这些方法进行了探讨和分类.最后,本文对基于深度学习的野生动物监测研究热点与存在问题进行了分析和总结,并对未来的研究重点提出了展望.
{ISBN/ISSN}: 1003-3254
{Notes}: 11-2854/TP
{URL}: https://link.cnki.net/doi/10.15888/j.cnki.csa.009369
{DOI}: 10.15888/j.cnki.csa.009369
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的钢结构表面缺陷智能识别研究综述
{Author}: 姚志东;卢佳祁;熊梦雅;卢炜
{Author Address}: 中冶建筑研究总院(深圳)有限公司;深圳市建筑幕墙智能检测工程技术研究中心;
{Journal}: 建筑结构
{Year}: 2023
{Volume}: 53
{Issue}: 24
{Pages}: 126-135
{Keywords}: 计算机视觉;钢结构表面缺陷;深度学习;智能识别
{Abstract}: 我国是钢结构工程建造量和保有量最多的国家，传统的钢结构缺陷工程诊断方法已无法满足当前的需求。而随着计算机技术的快速发展，将人工智能引入工程诊断领域逐步成为研究热点。根据对国内外研究现状的总结，提供了常见的钢结构表面缺陷基于计算机视觉的智能识别方法的研究综述，并结合国内实际情况总结出一套通用的技术框架。首先总结了表面缺陷智能检测与识别的通用流程，即：图像采集、目标提取和缺陷识别，然后以此为框架介绍了计算机视觉各种方法的内容和原理。接下来分别介绍了钢结构三种常见表面缺陷：高强螺栓缺失与松动、表面锈蚀、表面裂缝智能识别技术最新的研究进展和当前方法的不足。最后讨论和展望了基于计算机视觉的表面缺陷智能识别未来的研究方向。
{ISBN/ISSN}: 1002-848X
{Notes}: 11-2833/TU
{URL}: https://link.cnki.net/doi/10.19701/j.jzjg.20210542
{DOI}: 10.19701/j.jzjg.20210542
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 计算机视觉领域深度神经网络的自适应神经进化方法
{Author}: 帅真浩
{Tertiary Author}: 刘洪波
{Publisher}: 大连海事大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 计算机视觉;神经架构搜索;神经进化;进化算法;深度神经网络
{Abstract}: 计算机视觉领域的理论技术广泛应用于学术研究,工业生产和日常生活中。近年来,得益于人工智能研究的突飞猛进,深度神经网络(Deep Neural Network,DNN)已经成为计算机视觉领域的关键技术。随着计算机视觉应用的不断扩充,高效构建各类型的DNN已成为计算机视觉领域的前沿研究课题,由此可自动构建DNN架构的神经架构搜索方法的研究应运而生。现有的神经架构搜索方法主要专注于单一类型的DNN架构设计,缺乏通用性较高且兼顾DNN性能和规模的方法。为了应对以上问题,本研究提出了一种可自动化构建计算机视觉领域中不同类型DNN架构的神经架构搜索方法。该方法的搜索空间具备自适应性,且其搜索策略基于进化算法,因此被命名为自适应神经进化。主要研究内容如下:1.提出了一种三层级进化搜索空间。计算机视觉领域采用不同类型的DNN处理相应的计算机视觉任务,本研究详细分析了这些不同类型DNN的共性和差异,整合了全局搜索空间高自由度特性和单元搜索空间高效率特性,将进化搜索空间划分为微观组成模块层、介观功能单元层和宏观任务区域层三个层级。根据计算机视觉任务中不同类型的DNN设计需求,三层级进化搜索空间可自适应地调节各层级设置,以实例化对应类型DNN的进化搜素空间。实验结果表明,三层级进化搜索空间可自适应实例化卷积神经网络、生成对抗网络和YOLO网络等类型DNN的搜索空间。2.提出了一种生长型进化搜索策略。该搜索策略首先初始化一群相同的最小规模DNN架构,然后在进化搜索过程中利用多粒度进化操作从各个层级逐步增加DNN规模,以构建需求性能下规模极小的DNN架构。为了应对初始进化群体多样性不足问题,生长型进化搜索策略根据进化群体中个体基因型距离,通过聚类算法将进化群体划分为差异较大的多个进化种群,采用种间隔离和种内竞争的选择策略维护了进化群体的多样性。实验结果表明,生长型进化搜索策略可协同优化不同类型DNN架构的性能和规模。3.提出了一套进化搜索优化方案。方案中,进化超参数动态调整策略根据进化搜索状态适时调整进化搜索设置,保证了进化过程的稳定性;年龄性能混合选择操作通过基于年龄和性能的多重选择操作消除了性能评估的不精确性对进化搜索的潜在误导,平衡了搜索的探索性和勘探性;趋收敛性能评估机制通过优化评估DNN参数趋于性能收敛,大幅降低了计算资源和时间开销。实验结果表明,进化搜索优化方案有效提升了进化搜索的稳定性和效率。
{URL}: https://link.cnki.net/doi/10.26989/d.cnki.gdlhu.2023.000018
{DOI}: 10.26989/d.cnki.gdlhu.2023.000018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Canny算法的物体边缘检测算法
{Author}: 于新善;孟祥印;金腾飞;罗锦泽
{Author Address}: 西南交通大学机械工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 22
{Pages}: 221-230
{Keywords}: 机器视觉;边缘检测;Canny算法;柯西分布;高斯函数
{Abstract}: 针对传统边缘检测方法受高斯噪声、椒盐噪声污染及边缘梯度变化幅度小等因素影响而出现的物体轮廓检测效果不理想、误检率、漏检率高等问题，提出Canny-Cauchy边缘检测算法。该算法是Canny算法的一种改进，首先对椒盐噪声图像进行自适应中值滤波预处理，在清除椒盐噪声的同时保护边缘不被模糊。在滤波器的设计上，该算法使用柯西分布函数的一阶导数作为边缘检测函数，通过对函数采样得到边缘检测滤波器。对所提边缘检测函数按照边缘检测算法的三条设计准则进行理论分析，并在BSDS500数据集上与其他边缘检测算法进行对比实验。实验结果表明：在降噪方面，该算法可以在20%密度的椒盐噪声下保证处理后图像的峰值信噪比大于30 dB，结构相似性大于0.9；在边缘检测方面，该算法比传统Canny算法对白噪声的抑制能力以及对真实边缘的响应能力更强，在BSDS500数据集上的F1分数提升了7.5%，平均准确率提升了10.2%。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230309.1733.054
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于深度学习的人体姿态估计综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会论文集
{Author}: 邹宇翔;何宁;郭宇昕;刘鸿飞
{Author Address}: 北京联合大学北京市信息服务工程重点实验室;
{Secondary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会
{Place Published}: 中国江苏镇江
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2023
{Pages}: 4
{Keywords}: 计算机视觉;人体姿态估计;深度学习;自上而下;自下而上
{Abstract}: 人体姿态估计是计算机视觉领域的一个重要研究方向,它的目标是从图像或视频中准确地估计人体的关节位置和姿态信息。近年来,随着深度学习的快速发展,基于深度学习的人体姿态估计方法取得了显著的进展。本综述将回顾当前主流的基于深度学习的人体姿态估计方法,并探讨它们的优缺点及应用领域,以期为该领域的研究者提供一些有价值的参考和启示。同时,文中也指出了当前面临的挑战,并提出了未来的研究方向,旨在推动人体姿态估计领域的发展,为人体行为分析和相关领域的应用提供更准确、实时和可解释的姿态估计方法。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.055283
{DOI}: 10.26914/c.cnkihy.2023.055283
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智能驾驶汽车机器视觉关键技术分析
{Author}: 范靖;山世玉;林先山
{Author Address}: 广州公路工程集团有限公司;长安大学能源与电气工程学院;
{Journal}: 汽车实用技术
{Year}: 2023
{Volume}: 48
{Issue}: 21
{Pages}: 173-178
{Keywords}: 机器视觉;图像采集;图像处理;图像分析;智能驾驶
{Abstract}: 文章对智能驾驶汽车机器视觉关键技术中的图像采集、图像处理和图像分析三个部分进行研究。在图像采集技术中，重点研究带电耦合器件（CCD）图像传感器和互补金属氧化物半导体（CMOS）图像传感器的特点及其工作原理，并分别介绍基于现场可编程门阵列（FPGA）和数字信号处理机（DSP）的图像采集卡的工作特点及适用环境。在图像处理技术中，对感兴趣区域提取、图像灰度化处理、图像滤波去噪和边缘检测等环节进行研究。在图像分析技术中，重点对比传统的数字图像识别技术和基于深度学习的图像识别技术。结合对三个部分工作原理与特点的研究，对智能驾驶汽车机器视觉技术未来的发展趋势进行展望，提出人工智能化、车联网、车辆通信系统和多传感器化等发展构想。
{ISBN/ISSN}: 1671-7988
{Notes}: 61-1394/TH
{URL}: https://link.cnki.net/doi/10.16638/j.cnki.1671-7988.2023.021.035
{DOI}: 10.16638/j.cnki.1671-7988.2023.021.035
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的目标识别方法的研究进展
{Author}: 朱亚军;陈砆兴
{Author Address}: 兰州石化职业技术大学;
{Journal}: 科技资讯
{Year}: 2023
{Volume}: 21
{Issue}: 21
{Pages}: 21-24
{Keywords}: 机器视觉;模板匹配;目标识别;深度学习
{Abstract}: 随着社会的不断发展，机器视觉系统在各行业已被广泛应用，基于目标检测与目标识别的图像处理方法在机器系统中有了主要的应用途径，总结近年来使用机器视觉研究中用到的目标识别方法，包括Blob分析法、模板匹配法、深度学习法，详细讨论这些目标识别方法的原理、优劣以及在各个领域中的应用。首先介绍了基于机器视觉的目标检测识别的任务、难点和发展现状，其次基于深度学习方法的目标检测识别算法，最后讨论当前实际应用中目标检测识别方法存在的问题和未来可能的发展方向。
{ISBN/ISSN}: 1672-3791
{Notes}: 11-5042/N
{URL}: https://link.cnki.net/doi/10.16661/j.cnki.1672-3791.2304-5042-7176
{DOI}: 10.16661/j.cnki.1672-3791.2304-5042-7176
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的车体车牌检测识别方法的研究及应用
{Author}: 冯吉春
{Tertiary Author}: 金健
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;车辆检测;车体识别;车牌识别;车缘系统
{Abstract}: 近年来,随着汽车驾驶人员的持续增长,道路上的问题和需求变得越来越多,基于视觉的智慧交通技术在日常生活中被越来越普遍的应用。基于机器视觉的车体和车牌检测识别算法是智能交通领域的关键问题之一,检测及识别的正确率对后续智慧交通的研究具有重要影响。然而,行车过程中的视觉场景复杂,常规深度学习模型受环境因素影响较大,且车载嵌入式设备内存和算力有限。本文针对这些问题,提出了一套基于视觉处理的Vehicle-Net车体和车牌检测识别算法,设计和实现了一套基于Vehicle-Net的车缘系统。主要贡献包括:
1.提出了车辆检测算法YOLO-Vehicle。针对车载摄像头受环境因素影响和硬件资源限制,提出了YOLO-Vehicle车体和车牌检测算法。采用轻量级的Faster Net作为主干网络,使用Efficient Rep GFPN替换Neck层末端处理,采用Wise-Io U方法进一步提高目标检测的精度,并添加SimAM注意力机制。在保障mAP值微量损失情况下,参数量减少了79%,模型大小缩小了75.7%。
2.提出了车体识别算法ResNet-Vehicle和车牌识别算法CRNN-Vehicle。针对Res Net网络在含噪声的车体图像上特征学习能力弱和硬件资源限制,本文在Res Net-18基础上采用SENet注意力机制和分组卷积方法,在同水平参数量和浮点运算次数情况下,模型精度提升了1.6%。同时针对CRNN计算量大问题,本文采用GRU替换LSTM卷积和结构优化,在同水准检测精度情况下参数量减少了53%,浮点运算次数减小了57.6%。
3.设计并实现了一套基于Vehicle-Net的车缘系统。通过检测、计算和统计车与车相遇的时间和位置等信息,将行车过程中流失的相遇数据作收集量化。当相遇亲朋、领导或频繁同行者的车辆时,可辅助驾驶员提前采取安全友好的示意或礼让措施,间接减少路怒、飙车等危险行为。同时后端数据形成一定规模后,可辅助交管部门对一些盲区路段的监测。
本文在多个车辆图像数据集(如CCPD、CRPD、Comp Cars、Vehicle Dataset、UA-DETRAC和BIT-Vehicle)上,将所提出的算法与原始方法进行了多次迭代对比,从性能指标和工程化验证的角度,证实了所提算法的有效性。本文实现的车缘系统能够有效的收集路况数据,同时提升了驾驶体验和间接降低了路怒和飙车等危险行为的概率。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.004883
{DOI}: 10.27149/d.cnki.ghdsu.2023.004883
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的桥梁裂缝检测应用及发展综述
{Author}: 宋泽冈;刘艳莉;张长兴
{Author Address}: 云南省公路科学技术研究院;昆明理工大学建筑工程学院;
{Journal}: 科学技术与工程
{Year}: 2023
{Volume}: 23
{Issue}: 30
{Pages}: 12796-12805
{Keywords}: 桥梁检测;机器视觉;裂缝检测;图像处理;深度学习
{Abstract}: 桥梁裂缝是影响桥梁服役性能的关键因素之一，裂缝检测对桥梁养护至关重要。目前大部分检测为人工检测，检测人员通过目视检查裂缝，手动记录裂缝，检测的时间成本高昂。基于机器视觉的桥梁裂缝检测系统利用桥梁表面图像进行裂缝识别，近年来借助人工智能技术使裂缝自动化识别的精度和效率大大提升。详细介绍了基于机器视觉的桥梁裂缝检测系统及其应用，总结了该技术在桥梁裂缝检测中的优势及改进方向。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyJt5LiU4BoASaG7sZl8aT3aZRLHtOD01ezlXiAR-Scyr8tosunbV8gx3cNUxWbU2fAoXAVtDo36vMnQGDUpNen2bM0RvSKKTp-ILY-xRWCj3s1vD6Mzu4-EF6NmK-2JkljXdI6po5AlqWW06b46hviXNB09i8auNnG-3egPf5NXx_P-mZI23SUHzn-Ndb3j-o=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的结直肠息肉图像分割方法研究
{Author}: 苏炎洲
{Tertiary Author}: 程建
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 医学图像分割;息肉分割;特征融合;特征解耦;边缘增强
{Abstract}: 在医学影像学领域,图像分割技术在处理各类图像,如CT、MRI、X光、超声和内窥镜图像等,都具有重要的应用价值。其中,内窥镜下的息肉分割尤为关键,医生需要在检查过程中识别出潜在的结直肠息肉,这对于结直肠癌的早期诊断和治疗至关重要。然而,内窥镜图像分割面临着多重挑战,例如图像边界模糊、尺度跨度大、光照强度不均以及对比度较低等,这些因素使得结直肠息肉的筛查既耗时又需要专业知识。因此,基于计算机视觉的息肉分割方法展现出巨大的潜力,它能够提高息肉的诊断效率,减少误诊和漏诊。本文将直面这些挑战,从息肉本身的难点出发,深入剖析现有方法的优劣,探讨如何运用深度学习的先进技术包括特征增强,特征解耦等策略,以提出一系列创新的解决方案,旨在提升内窥镜图像下息肉分割的准确性和效率。本文的主要内容及成果如下:1.针对息肉边缘分割不准确的问题,本文设计了一个特征对齐与边界优化的息肉分割网络。该结构采纳一种特征融合的新范式,利用学习到的语义偏移场来对齐多级特征,从而显著提高息肉边缘定位的准确性。此外,还设计了一个辅助边界分支,以增强模型对息肉边界的感知,进而提升息肉边界预测的性能。在经过端到端优化后,参考边界图被用作高级语义表征的补充,进一步提高了息肉分割的效果和效率。2.针对内窥镜图像中光照不均和对比度低等问题导致的息肉误分割和错分割,本文提出了一种特征增强金字塔网络(Feature Augmentation Pyramid Network,FAPN)。FAPN采用交叉嵌入模块来高效提取和融合息肉特征,并通过预测校准模块精确定位息肉特征,有效突出感兴趣区域,从而显著减少由光照不均和对比度低造成的影响。此外,其层级特征融合模块生成了更加鲁棒的多尺度息肉特征表征,进一步提高了息肉分割的准确度。经过实验验证,FAPN在多个息肉分割数据集上超过了现有的先进方法。3.针对现行息肉分割技术在特征传输和融合效率方面的局限,本文提出了一种创新的特征校正网络。这个网络的核心目标是优化并校正息肉分割框架中的特征整合和传播机制,从而达到更高效且精确的特征处理。通过引入高效的特征传播增强模块,该网络在所有阶段实现了全尺度特征的精确传递。此外,其独特的门控机制有效加强了特征融合,提高了信息过滤和处理的准确性。4.针对现有息肉分割方法在同时增强息肉的内部一致性和优化边缘表现上的不足,本文提出了一种综合优化息肉特征的方法——特征解耦网络(Feature Decoupled Network,Fe DNet)。Fe DNet通过应用拉普拉斯金字塔中的特征解耦技术,实现了对息肉特征的有效分解和精细优化,从而在提升基线性能的同时,也显著超越了现有的最先进方法,并在多个数据集上展示了其出色的泛化能力。5.针对Fe DNet在区分息肉主体和边缘特征的高低频特征方面的不足,本文提出了自适应特征解耦模块(Adaptive Feature Decoupled Module,AFDM)。AFDM结合傅立叶变换和可学习掩膜,在频域中有效解耦高低频特征,提升了特征解耦的准确性。这一改进使得集成了AFDM的特征解耦网络在多个数据集上展现出更优的性能和泛化能力。综上所述,本博士论文的主要工作是设计并实现一系列的结直肠息肉分割方法,旨在提升内窥镜图像下结直肠息肉的分割准确性和效率。经过广泛的实验验证,这些方法在多个息肉分割数据集上均表现出色的性能,而且展现出优异的泛化性能。此研究为结直肠癌的早期诊断和治疗方面打开了新的视野,具有显著的临床意义。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.005531
{DOI}: 10.27005/d.cnki.gdzku.2023.005531
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多目标追踪算法研究
{Author}: 陈皓然
{Tertiary Author}: 张登银
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;大卷积核;特征融合;多目标追踪;云原生
{Abstract}: 多目标追踪是计算机视觉的重要研究方向之一,近年来随着深度学习的发展,多目标追踪也取得了显著进步。然而,在无人机场景中多目标追踪仍面临着诸多挑战,如目标尺寸小导致检测精度不高、遮挡严重导致身份认定一致性不高、算力资源有限导致不能灵活部署深度学习模型等。针对上述问题,本文主要工作如下:1、针对无人机图像中小目标检测精度不高的问题,本文在YOLOv7的基础上提出了一种基于大卷积核架构的目标检测骨干网络,通过增大模型的有效感受野从而提高模型的特征提取能力,进而提高检测精度。为了减少大卷积核带来的额外参数,本文还采用结构重参数化(Struct Re-parameterization)、深度卷积(Depthwise Convolution)等方法减少模型参数量。2、为了进一步提高模型的实时性,本文分析了不同特征金字塔网络(Feature Pyramid Network,FPN)的特征,并受到Bi FPN(Bi-directional Feature Pyramid Network)结构的启发,在YOLOv7的基础上提出一种改进的特征融合网络。本文提出的特征融合网络通过跨尺度连接(Cross-Scale Connection)增强不同尺度特征图之间的信息交互,相比于其他特征融合网络,能在更少的参数量下融合更多的特征。3、针对OC-SORT方法数据关联能力不强的问题,本文提出了一种改进的OC-SORT方法。一方面,通过使用大卷积核架构的实时目标检测器来提高小目标的检测精度;另一方面,提出了一种利用行人重识别方法(Re-identification,Re-ID)和卡尔曼滤波器(Kalman Filter)级联的方式增强数据关联。通过实验验证,本文方法可以提高密集场景下的身份认定一致性。4、针对无人机场景下算力资源有限的问题,本文设计了一种基于云原生的深度学习容器部署平台,通过搭建轻量级Kubernetes平台,一方面将模型转换为统一推理格式ONNX并封装为Docker容器,解决深度学习框架难以管理的问题,也能减小容器镜像文件大小;另一方面,使用分布式容器镜像仓库和Bit Swap协议来解决传统中心式镜像仓库出口带宽竞争激烈的问题,大幅提高以无人机容器部署场景为代表的边缘端深度学习容器部署效率。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001152
{DOI}: 10.27251/d.cnki.gnjdc.2023.001152
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 轻量化CNN-Transformer的人脸识别网络研究
{Author}: 高佳玮
{Tertiary Author}: 葛琦
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;人脸识别;卷积神经网络;轻量化;Transformer
{Abstract}: 最近新兴的技术是将自然语言处理(Natural Language Processing,NLP)的Transformer技术应用到计算机视觉(Computer Vision,CV)中,称之为视觉Transformer(Vision Transformer,Vi T)。尽管视觉Transformer可以解决卷积神经网络中感受野受限以及丢失上下文信息的问题,但是这种网络结构需要的参数更多,消耗的资源更大。为了解决上述问题,在本文中将卷积神经网络与视觉Transformer混合使用,先利用卷积神经网络对图像进行局部特征提取,将得到的局部表征输入到Transformer结构中进行全局的建模,设计了一个轻量化的CNNTransformer网络,在保证性能的同时,还可以有效减少模型的参数。为提高模型的鲁棒性,本文通过对样本在特征空间的分布进行欧式距离约束和角度约束,利用中心损失(Center Loss)和加性角边缘损失(Additive Angular Margin Loss)联合监督,使得同类样本在特征空间中具有更小的欧式距离,以及距离每个样本的中心有更小的角度。本文工作的贡献主要体现在以下几个方面:(1)验证了Transformer模型应用在人脸识别上的可行性。(2)通过在Transformer模型中引入卷积神经网络大幅降低了网络的参数。(3)构造一个新的联合损失函数,将模型精度在遮挡环境下受到的影响降到最低。本文对提出的每一项具有创新的措施以及改进的方法都进行了实验验证,本文设计的模型在仅仅需要5.3M参数的情况下在LFW和MS-Celeb-1M数据集上分别取得了精度为99.27%和90.07%的成绩,另外在LFW数据集上进行模型鲁棒性测试,当人脸遮挡比例为0.05、0.1、0.15时,模型的精度为98.72%、97.63%、92.91%,与其他模型相比将模型精度受到的影响降到最低。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001313
{DOI}: 10.27251/d.cnki.gnjdc.2023.001313
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多目标同步分类关键技术研究
{Author}: 范昊飞
{Tertiary Author}: 刘宁
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;YOLOv8改进;WiseIoU;MHSA;可变卷积
{Abstract}: 高校及科研单位的实验室都对实验人员的着装有着严格的要求,不按照要求着装的人员轻则影响实验结果,重则造成安全事故。要辨识人员是否遵守了规定着装需要人工监管,会造成人力成本的浪费。目标检测一直是计算机视觉领域的研究热点之一,而且是机器视觉的“智能”所在。随着近些年来深度学习的不断发展,卷积神经网络CNN研究的不断深入,尤其是目标检测领域中的YOLO系列不断更新换代,到2023年,YOLOv8已经问世。本文将深度学习的方法应用到生活实际中,用于识别实验人员的口罩佩戴情况、白大褂穿着情况,以目标检测方法自动识别人员着装是否规范,取代人工监管。本论文建立了一个包含5250张图像以及经标注的口罩、白大褂检测数据集,用于目标检测模型训练和测试,其中训练集、验证集和测试集划分比例为8:1:1。这些数据集图像中包含人员穿着白大褂和佩戴口罩的各种状态,特殊的,还有如白色衣服、口罩佩戴露出口鼻这类干扰项。在同一张图像数据中,同时需要检测面部是否佩戴口罩与身体是否穿戴白大褂两项目标,也需要所用的目标检测网络同步地做出分类,解决2个二分类问题。本文以YOLOv8网络为基础,并对其做出三种改进策略,改进策略包括:1.针对可能的标注低质量问题,回归损失函数CIoU修改为Wise-IoU;2.因为同一张图片存在两项目标识别任务,为了更加细化不同任务提取到的特征,提升训练模型的精度,添加自注意力机制MHSA;3.为了应对未知的几何结构变换,修改传统卷积方式为可变卷积v2。对于原版YOLOv8网络和分别使用每种改进策略,以及联合使用前2种策略,联合使用三种策略,都使用相同的自制数据集进行训练,都分别得到了实验结果。最终的结论是,每种策略使用后,选取F1值、mAP50为评价指标,以及分析混淆矩阵,精度都相对原版的网络有所提高。同时使用3种改进策略,能使得总体性能有较大幅度地提高。YOLOv8是YOLO系列的最新网络,还鲜有在其基础上改进的研究,本文创新性地使用了一些改进策略,并且将其组合使用,在性能提升方面收到了较好的效果,其最终方案能很好地检测口罩佩戴和白大褂穿着情况,在工程实践方面具有实际意义。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001535
{DOI}: 10.27251/d.cnki.gnjdc.2023.001535
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习与计算机视觉的驾驶行为检测系统设计
{Author}: 朱浩
{Tertiary Author}: 沈澍
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多视角驾驶行为图像数据集;多视图学习;深度神经网络;多任务学习
{Abstract}: 我国的汽车保有量已跃居世界第一,汽车驾驶人数增长十分迅速,而根据世界卫生组织于2020年的道路交通事故报告显示,全球每年约有130万人死于交通事故,道路交通事故造成的经济损失约占其生产总值的3%,而驾驶行为分心驾驶和疲劳驾驶造成的交通事故已经超过了全部事故的35%。因此针对分心驾驶和疲劳驾驶的识别检测工作十分必要,本文基于多视图学习和多任务学习建立了多视图分心驾驶行为识别模型和多任务分心驾驶行为和疲劳驾驶特征联合识别模型,并基于疲劳驾驶的疲劳特征确认了疲劳驾驶判定策略,以此实现驾驶行为检测系统,为提高我国道路交通安全贡献自己的一份力量。本文主要工作如下:首先,本文建立了多视角驾驶行为图像数据集NMDA数据集并提出了多视图分心驾驶行为识别模型MMob Net。基于分心驾驶行为识别和疲劳驾驶行为识别两种任务的需求视角不同建立了多视角驾驶行为图像数据集NMDA数据集,并进行了数据集有效性实验,确认了NMDA数据集的有效性和可靠性。以多视图模型MVCNN为模型基础框架,并提出视图注意力机制VAM模块,建立了多视图分心驾驶行为识别模型MMob Net。通过实验后,确认了MMob Net模型对单任务模型的优越性,准确率高出10%以上,同时使用了VAM模块的MMobe Net模型较同类型多视图模型准确率高1.02%,并进行MMob Net的视角组合对比确认视角1、2、3的组合可以在略微降低模型准确率的同时大幅降低数据需求规模。然后,本文确认了疲劳驾驶行为识别方案并提出了多任务分心驾驶行为和疲劳特征联合识别多任务模型MTDFNet。在疲劳驾驶行为识别方案中使用Retina Face作为人脸检测器,采集人脸区域图像分为上下眼部和嘴部图像建立疲劳特征数据集EMFD,建立疲劳特征识别模型MEMNet。以分心驾驶行为识别模型MMob Net和疲劳特征识别模型MEMNet为基础结构,利用多任务学习建立多任务模型MTDFNet。通过实验,确认了训练MTDFNet模型使用的损失函数和loss组合算法,得到了较为优秀的模型准确率,分心驾驶行为识别和疲劳特征识别两个子任务的准确率分别为91.22%和93.30%,较与对应的单任务模型,疲劳特征识别任务虽然降低了0.47%,但更为困难的分心驾驶行为识别任务准确率提高了3.7%,证明了多任务学习可以提高部分子任务性能的特点。最后,本文完成了驾驶行为检测系统的设计与实现工作。基于疲劳特征识别模型MEMNet确认了疲劳驾驶的疲劳特征判定策略并进行了测试,得到了关键参数闭眼帧数占比上限和张嘴时间占比上限。使用Pyqt5作为系统设计框架,建立了可视化界面和包含界面的驾驶行为检测系统并进行了系统测试,结果显示,该系统能够有效地运行。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001164
{DOI}: 10.27251/d.cnki.gnjdc.2023.001164
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 雾霾图像去雾技术与应用研究
{Author}: 张文杰
{Tertiary Author}: 张登银
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去雾;大气散射模型;暗通道先验;一体化去雾网络
{Abstract}: 在雾霾天气的影响下,光学成像设备获取到的图像会出现降质现象,降质后的有雾图像严重降低了图像在各领域中的应用价值。图像去雾技术能够减少或者消除雾霾对图像的负面影响,从而成为图像处理领域的一个重要研究方向。本文针对现有图像去雾算法中存在的问题进行研究,主要工作如下:1、针对暗通道先验算法在部分区域失效、大气光值估计不准确以及去雾图像颜色较暗的问题,本文提出一种改进的暗通道先验图像去雾算法。首先,为了提高大气光值计算的准确性,提出改进的四叉树分割算法,该算法可以有效避免高亮区域以及明亮地面等场景对大气光区域定位的干扰。其次,使用明通道先验补足暗通道先验失效部分,以大气光值作为阈值,对明、暗区域分别进行透射率的求取,得到图像的综合透射率,并使用引导滤波对粗透射率进行修正细化。再次,引入色调修正算法,对去雾图像做亮度增强,使去雾图像更符合人的视觉感受。最后,对比实验结果表明本文算法具有更好的复原效果。2、针对目前基于深度学习图像去雾算法分别估计参数导致参数误差放大,以及现有算法复杂性高的问题,本文提出一种基于深度可分离卷积的一体化网络图像去雾算法。首先,使用深度可分离卷积替换原算法的常规卷积,减少网络参数数量,使网络更加轻量化。其次,针对原网络直接将特征图进行连接,没有突显关键特征信息的问题,设计加权特征融合模块,赋予不同层次特征图不同权重并加权融合。再次,使用多尺度结构相似度(Multi-Scale Structure Similarity,MS-SSIM)和均方误差加权作为损失函数,优化去雾图的对比度、亮度以及色彩饱和度,使复原图像更符合人的视觉感受。最后,对比实验结果表明,本文算法在保证网络模型轻量化的同时,对去雾效果也做了一定的增强。3、结合前文提出的去雾算法,本文设计了一个雾霾天气下的车牌识别系统。首先,对车牌识别进行真实应用场景设计,结合具体场景对该系统做需求分析,明确需要解决的问题。其次,针对现有应用中存在的雾霾天气下车辆车牌信息难以识别这一问题,对车牌识别系统进行了详细的模块设计和功能设计。最后展开对比实验,实验结果表明,本文提出的雾霾天气下的车牌识别系统可以有效识别车辆的车牌信息,具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000167
{DOI}: 10.27251/d.cnki.gnjdc.2023.000167
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像处理与计算机视觉技术在自动驾驶中的应用
{Author}: 王辉
{Author Address}: 江苏联合职业技术学院南京工程分院;
{Journal}: 电子技术
{Year}: 2023
{Volume}: 52
{Issue}: 10
{Pages}: 28-30
{Keywords}: 图像处理;计算机视觉;自动驾驶
{Abstract}: 阐述自动驾驶中的图像处理技术，包括摄像头与传感器技术、图像采集和预处理、特征提取与对象检测、图像识别与分类、实时性与延迟的挑战，探讨计算机视觉算法在自动驾驶中的应用，车道保持与识别、前方障碍物检测与避免识别、交通信号与标志的识别。
{ISBN/ISSN}: 1000-0755
{Notes}: 31-1323/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxh3fEMrmxXfJEfQUeuy7X572_4DTDj3OcBiZIJBThyzp6sHpb9qZYoXUhYZzz11fNkkNP3JJUwTcf7a8ycPBDBOvkO1He07thj-Tm7fiv0o49aiztf6UeUVOGroZiv21dZ0kOpduRsYnOgeXYzUTFXn0ZPUHvFeQ8-DMq8Nxv4AbIOJBC6pRqfx8eFRFETeFs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Transformer的视觉目标跟踪方法综述
{Author}: 孙子文;钱立志;杨传栋;高一博;陆庆阳;袁广林
{Author Address}: 陆军炮兵防空兵学院高过载弹药制导控制与信息感知实验室;陆军炮兵防空兵学院信息工程系;
{Journal}: 计算机应用
{Year}: 2024
{Volume}: 44
{Issue}: 05
{Pages}: 1644-1654
{Keywords}: 计算机视觉;目标跟踪;混合网络结构;深度学习;孪生网络;Transformer
{Abstract}: 视觉目标跟踪是计算机视觉中的重要任务之一，为实现高性能的目标跟踪，近年来提出了大量的目标跟踪方法，其中基于Transformer的目标跟踪方法由于具有全局建模和联系上下文的能力，是目前视觉目标跟踪领域研究的热点。首先，根据网络结构的不同对基于Transformer的视觉目标跟踪方法进行分类，概述相关原理和模型改进的关键技术，总结不同网络结构的优缺点；其次，对这类方法在公开数据集上的实验结果进行对比，分析网络结构对性能的影响，其中MixViT-L(ConvMAE)在LaSOT和TrackingNet上跟踪成功率分别达到了73.3%和86.1%，说明基于纯Transformer两段式架构的目标跟踪方法具有更优的性能和更广的发展前景；最后，对方法当前存在的网络结构复杂、参数量大、训练要求高和边缘设备使用难度大等不足进行总结，并对今后的研究重点进行展望，通过与模型压缩、自监督学习以及Transformer可解释性分析相结合，可为基于Transformer的视觉目标跟踪提出更多可行的解决方案。
{ISBN/ISSN}: 1001-9081
{Notes}: 51-1307/TP
{URL}: https://link.cnki.net/urlid/51.1307.TP.20231017.1418.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 无人机航拍图像中电力线检测方法研究进展
{Author}: 刘传洋;吴一全;刘景景
{Author Address}: 南京航空航天大学电子信息工程学院;池州学院机电工程学院;
{Journal}: 中国图象图形学报
{Year}: 2023
{Volume}: 28
{Issue}: 10
{Pages}: 3025-3048
{Keywords}: 机器视觉;电力线检测;无人机巡检;图像处理;深度学习;语义分割
{Abstract}: 随着各大电力公司对无人机（unmanned aerial vehicle,UAV）巡检的大力推广，“机巡为主，人巡为辅”已成为我国电力巡检的主要运维模式。电力线检测作为电力巡检的关键技术，在无人机自主导航、低空避障飞行以及输电线路安全稳定运行等方面发挥着重要作用。众多研究者将输电线路的无人机航拍图像用于线路设备识别与故障诊断，利用机器视觉的方法在电力线检测技术研究中占据主导地位，也是未来的主要发展方向。本文综述了近10年来无人机航拍图像中电力线检测方法的研究进展。首先简述了电力线特征，阐明了电力线检测的传统处理方法的一般流程及所面临的挑战；然后重点阐述了使用传统图像处理方法及深度学习方法的电力线检测原理，前者包括基于Hough变换的方法、基于Radon变换的方法、基于LSD(line segment detector)的方法、基于扫描标记的方法及其他检测方法，后者根据深度卷积神经网络（deep convolutional neural network,DCNN）的结构不同分为基于DCNN的分类方法及基于DCNN的语义分割方法，评述各类方法的优缺点并进行分析与比较，与传统图像处理方法相比，深度学习方法能更有效地实现航拍图像中的电力线检测，并指出基于DCNN的语义分割方法在电力线目标智能识别与分析中发挥着重要作用；随后介绍了电力线检测的常用数据集及性能评价指标；最后针对电力线检测方法目前存在的问题，对下一步的研究方向进行展望。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy1wsBS9Hl54GlRgm8FjXFiPeKMNlAi-Vz0o4oEKYkftpMXPr89CesVHDPbaOvBWC3K9_eiQi9NkzJ9MIQ8XWwWZEsQF_t_QdLbaNCILWk9ICYMtwGDLHx-gFCbzEzXKqOGMxx9fxVl7NLd_3aeKFeXtY3cpnRH6evJbC7rbYqX3bZ1dGvNruD0px23GhK2pkE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 无监督单目深度估计研究综述
{Author}: 蔡嘉诚;董方敏;孙水发;汤永恒
{Author Address}: 三峡大学计算机与信息学院;杭州师范大学信息科学与技术学院;三峡大学经济与管理学院;
{Journal}: 计算机科学
{Year}: 2024
{Volume}: 51
{Issue}: 02
{Pages}: 117-134
{Keywords}: 计算机视觉;深度学习;无监督学习;单目深度估计
{Abstract}: 深度估计作为三维重建、自动驾驶和视觉SLAM等领域中的关键环节，一直是计算机视觉领域研究的热点方向，其中无监督学习的单目深度估计技术由于具有方便部署、计算成本低等优点，受到了学术界和工业界的广泛关注。首先梳理了深度估计的基本知识及研究现状，简要介绍了基于参数学习、基于非参数学习、基于有监督学习、基于半监督学习和基于无监督学习的深度估计的优势与不足；其次全面总结了基于无监督学习的单目深度估计研究进展，按照结合可解释性掩膜、结合视觉里程计、结合先验辅助信息、结合生成式对抗网络和实时轻量级网络这五大类对无监督学习的单目深度估计进行归纳和总结，对典型的框架模型进行了介绍和分析；然后，介绍了基于无监督学习的单目深度估计在医学、自动驾驶、农业、军事等领域的应用；最后，简单介绍了用于无监督深度估计的常用数据集，提出了基于无监督学习的单目深度估计未来研究方向，并对这个快速发展领域中的各方向研究进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20231009.1704.059
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO v7-tiny的甜椒畸形果识别算法
{Author}: 王昱;姚兴智;李斌;徐赛;易振峰;赵俊宏
{Author Address}: 华南农业大学工程学院;岭南现代农业科学与技术广东省实验室;广东省农业科学院设施农业研究所;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 11
{Pages}: 236-246
{Keywords}: 甜椒畸形果;YOLO v7-tiny;目标检测;机器视觉
{Abstract}: 甜椒在生长发育过程中容易产生畸形果，机器代替人工对甜椒畸形果识别和摘除一方面可提高甜椒品质和产量，另一方面可解决当前人工成本过高、效率低下等问题。为实现机器人对甜椒果实的识别，提出了一种基于改进YOLO v7-tiny目标检测模型，用于区分正常生长和畸形生长的甜椒果实。将无参数注意力机制(Parameter-free attention module, SimAM)融合到骨干特征提取网络中，增强模型的特征提取和特征整合能力；用Focal-EIOU(Focal and efficient intersection over union)损失替换原损失函数CIOU(Complete intersection over union),加快模型收敛并降低损失值；使用SiLU激活函数代替原网络中的Leaky ReLU,增强模型的非线性特征提取能力。试验结果表明，改进后的模型整体识别精确度、召回率、平均精度均值(Mean average precision, mAP)mAP0.5、mAP0.5-0.95分别为99.1%、97.8%、98.9%、94.5%,与改进前相比，分别提升5.4、4.7、2.4、10.7个百分点，模型内存占用量为10.6 MB,单幅图像检测时间为4.2 ms。与YOLO v7、Scaled-YOLO v4、YOLOR-CSP等目标检测模型相比，模型在F1值上与YOLO v7相同，相比Scaled-YOLO v4、YOLOR-CSP分别提升0.7、0.2个百分点，在mAP0.5-0.95上分别提升0.6、1.2、0.2个百分点，而内存占用量仅为上述模型的14.2%、10.0%、10.0%。本文所提出的模型实现了小体量而高精度，便于在移动端进行部署，为后续机械化采摘和品质分级提供技术支持。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230926.1554.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的农作物病虫害检测算法综述
{Author}: 慕君林;马博;王云飞;任卓;刘双喜;王金星
{Author Address}: 山东农业大学机械与电子工程学院;山东省农业装备智能化工程实验室;山东省园艺机械与装备重点实验室;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: S2
{Pages}: 301-313
{Keywords}: 农作物病虫害;数字图像处理;深度学习;病虫害检测算法
{Abstract}: 农作物病虫害对农业产量和品质影响巨大。数字图像处理技术在农作物病虫害识别中发挥重要作用。深度学习在该领域取得显著突破，效果优于传统方法。深度学习方法的特征提取能力更强，能准确捕捉细微特征，提高检测精度和可靠性。深度学习为农业提供了有力支持。本研究综述了基于深度学习的农作物病虫害检测研究，从分类网络、检测网络和分割网络3方面进行了概述，并对每种方法的优缺点进行了总结，同时比较了现有研究的性能。在此基础上，进一步探讨了基于深度学习的农作物病虫害检测算法在实际应用中面临的难题，并提出了相应的解决方案和研究思路。最后，对基于深度学习的农作物病虫害检测技术的未来趋势进行了分析和展望。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230924.1753.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在工业机器人中的应用研究
{Author}: 谭春林
{Author Address}: 新疆昌吉职业技术学院;
{Journal}: 中国设备工程
{Year}: 2023
{Volume}: 
{Issue}: 18
{Pages}: 46-48
{Keywords}: 机器视觉;工业机器人;应用分析
{Abstract}: 智能制造是我国迈向制造强国的重要途径，加快我国工业发展步伐，有利于我国工业高质量发展。机器视觉是一种通过使用光学设备和无接触式传感器来实现对目标图像信息自动接收与处理，从而获取所需要的信息或实现对机器人移动控制。另外，机器视觉通过模拟人类眼睛来进行测量和判断信息，以高精度、高效率和可持续工作能力，在结构化场景量化方面有着突出的作用。随着工业结构的调整与转型，机器视觉技术已被广泛地应用于汽车、印刷、包装、农业、医药、纺织等各个行业。所以，如何推进机器视觉技术的发展，对于智能产业有重要的意义。
{ISBN/ISSN}: 1671-0711
{Notes}: 11-4623/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzxd9vPrEW8Vh5FLwicYdGnZggP9DAHIeNJctNMKQlzEr7hRFdvlT24nGr_c8CFkcH4dy5W3SlIUEHoLEuvw8HUb2i1twNSqxBX4ZmLHMZNmSBS4TZZ-osBUolfJJ9WvpF8tBMzM20s8DNdpgGpHsrjjiu7fq_2IG6i3-0oyuYlmzeRPHERcGas0oNhjcLJ9wE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV+MediaPipe实现运动姿态AI检测在体育训练中的应用
{Author}: 谢鹏
{Author Address}: 宁夏工商职业技术学院;
{Journal}: 无线互联科技
{Year}: 2023
{Volume}: 20
{Issue}: 18
{Pages}: 100-104
{Keywords}: OpenCV;MediaPipe;人体姿态估计;体育训练
{Abstract}: 文章基于OpenCV在计算机视觉和MediaPipe在机器学习中人体姿态估计中的应用，开发了体育运动AI训练系统V1.0,实现自定义示范动作，用以达到辅助体育训练的目的；实现方法为，通过采集MediaPipe检测追踪和捕获在人体运动时姿态各个关节角度数据，作为示范动作的数据集，将训练者动作数据集与示范动作数据集对比，判断动作是否标准；系统经运动员测试使用，动作识别率较高，训练效果良好；运动姿态AI检测在体育训练方面应用有效可行。
{ISBN/ISSN}: 1672-6944
{Notes}: 32-1675/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyV4ySIwjxivn7P5aZirnMRmWJf2u2SnlHj2mBEwVJhIiORHzQIKeF-P4fAuS4Cnabv14wqYeoaxDmyUDCTXMfBN9nA-tQoYZjMchYz1o3IdjYBgYbzspyJtjkeWSxBcA6LVYqewJ_Q3Z5lH4N4lbmm6sFqoQ8S0Anr_5NprQ2m2OhCdmui2eGzAfYW9_E985c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向图像分类的CNN特征鲁棒性研究
{Author}: 叶翔
{Tertiary Author}: 李永
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 图像分类;特征鲁棒性增强算法;旋转变换鲁棒性;背景变化鲁棒性;高斯噪声鲁棒性
{Abstract}: 图像分类是计算机视觉领域的基础任务之一,其目标是预测图像中物体的类别。图像分类任务的性能对于多种计算机视觉任务都具有重要影响,如目标检测和图像分割等。近年来,卷积神经网络(convolutional neural networks,CNNs)在图像分类任务上取得了突破性的成就。然而,由于图像采集过程中广泛存在的视角变化、场景变化和高斯噪声等因素会影响卷积神经网络提取特征的鲁棒性,导致分类性能下降。因此,研究如何增强神经网络所提取特征的鲁棒性具有重要意义。本文针对卷积神经网络存在的对图像旋转变换鲁棒性不足、图像背景变化鲁棒性不足以及缺乏适用于多种图像变换的鲁棒性增强模型等三个问题进行了研究。为提高特征对旋转变换的鲁棒性,本文首先提出了方向自适应卷积神经网络,设计了可提取多方向信息的方向自适应卷积核和方向自适应最大池化层。其次,为提高特征对背景变化的鲁棒性,本文提出了注意力权重模块,设计了逐卷积核独立抑制背景信息的注意力权重卷积层。最后,为缓解现有鲁棒性增强算法缺乏适用于多种图像变换的数学模型的问题,本文建立了特征鲁棒性增强正则模型并提出了鲁棒性增强正则项,从正则化的角度对不同的特征鲁棒性增强问题进行数学建模。本文的研究内容与主要贡献如下:针对卷积神经网络对图像旋转变换鲁棒性不足的问题,目前的解决方案主要依赖数据增广。然而,使用数据增广训练得到的特征仅对数据增广中包含的角度变换具有鲁棒性,对其它角度变换不鲁棒。此外,数据增广使得训练集中的样本数量成倍增加,导致算力和时间成倍消耗。为缓解这一问题,本文将图像旋转变换的先验知识融入到卷积神经网络的结构设计中,设计了方向自适应卷积核和方向自适应最大池化层,并提出了方向自适应卷积神经网络(OACNN)。该网络能够在不依赖数据增广的情况下提取对图像旋转变换鲁棒的特征表示,从而能够更加准确地分类具有旋转变换的测试图像。具体地,方向自适应卷积核能够根据输入特征图的方向自适应地旋转卷积核的角度,从多个方向提取与目标相关的语义信息,输出能够表征多方向信息的矢量特征。方向自适应最大池化层根据特征图的方向信息对其进行空间划分,保证了同一轮廓在不同方向特征图上具有相同的池化区域,提高了卷积神经网络对旋转鲁棒特征的提取能力。实验结果表明,相较于现有算法,OACNN提取到的特征对图像旋转变换更加鲁棒且参数量更小。特别地,在旋转图像分类任务中,OACNN在CIFAR10数据集上的准确率比ORN高出了 5.97%。针对卷积神经网络对图像背景变化鲁棒性不足的问题,现有注意力机制通过对特征图的空间或通道维度赋予不同的注意力系数来提高其对背景变化的鲁棒性。这种机制默认了下一个卷积层中的每个卷积核需要抑制的背景信息是相同的。然而,由于每个卷积核提取的特征不同,它们关注的前景信息是不同的,需要被抑制的背景信息也是不同的。因此,现有注意力机制难以根据每个卷积核提取的特征精细地抑制其不关注的背景信息。为缓解这一问题,本文提出了注意力权重模块(AWB)来建模每个卷积核与图像内容之间的依赖关系。AWB中的卷积核权重在测试阶段能够根据输入图像的内容自动进行调整,以自适应地抑制特征图中与所关注内容无关的背景信息。本文将AWB应用于卷积层和批归一化层,并在各种数据集上对其进行了评估。实验结果表明,AWB提升了各种目标检测算法和语义分割算法对背景信息的抗干扰能力,进而提高了各算法对前景信息的分类和定位能力。此外,在图像分类任务中,AWB的性能一致优于现有的注意力机制方法。在参数量和时间耗费相近的情况下,AWB在CIFAR-100和Tiny-ImageNet数据集上的准确率分别比高效通道注意力机制(ECA)高出了 1.0%和1.1%。针对现有算法缺乏适用于多种图像变换的鲁棒性增强模型的问题,本文设计了鲁棒性增强正则项,并提出了鲁棒性增强正则模型,将不同图像变换的特征鲁棒性增强问题转化为鲁棒性增强正则项的最小化问题。本文首先定义了特征在任意样本点处的鲁棒性度量,并进一步设计特征分布区域内的鲁棒性增强正则项。然后,本文分别在旋转变换、背景变化和高斯噪声的鲁棒性增强任务上验证了该正则项的有效性。具体地,尽管方向自适应卷积核和注意力机制被提出的动机不同,本文证明了现有的方向自适应卷积核和注意力机制通过对卷积神经网络的正则化作用,隐式地优化了鲁棒性增强正则项,从而提高卷积神经网络对图像旋转变换和图像背景变化的鲁棒性。进一步地,本文将针对图像旋转变换、图像背景变化和高斯噪声的鲁棒性增强正则项显式地加入到损失函数中进行优化。实验结果表明,显示地优化鲁棒性增强正则项提高了图像特征对多种图像变换的鲁棒性,进而同时提高了模型对具有旋转变换、背景变化和高斯噪声图像的分类准确率。综上所述,本文探究了卷积神经网络在特征鲁棒性方面存在的三个问题:对图像旋转变换鲁棒性不足的问题、对图像背景变化鲁棒性不足的问题以及缺乏适用于多种图像变换的鲁棒性增强模型的问题。为了缓解这些问题并弥补现有算法的不足,本文提出了方向自适应卷积神经网络和注意力权重模块,以提高特征对图像旋转变换和背景变化的鲁棒性。此外,本文还建立了适用于多种图像变换的鲁棒性增强模型,即特征鲁棒性增强正则模型。特征鲁棒性增强正则模型不仅可以为特征鲁棒性增强算法的设计提供指导,还可以帮助研究人员更好地理解现有特征鲁棒性增强算法能够提取鲁棒特征的原理。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000399
{DOI}: 10.26969/d.cnki.gbydu.2023.000399
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Transformer驱动的图像分类研究进展
{Author}: 石争浩;李成建;周亮;张治军;仵晨伟;尤珍臻;任文琦
{Author Address}: 西安理工大学计算机科学与工程学院;中山大学网络空间安全学院;
{Journal}: 中国图象图形学报
{Year}: 2023
{Volume}: 28
{Issue}: 09
{Pages}: 2661-2692
{Keywords}: Transformer;自注意力机制;深度学习;图像分类;可扩展位置编码
{Abstract}: 图像分类是图像理解的基础，对计算机视觉在实际中的应用具有重要作用。然而由于图像目标形态、类型的多样性以及成像环境的复杂性，导致很多图像分类方法在实际应用中的分类结果总是差强人意，例如依然存在分类准确性低、假阳性高等问题，严重影响其在后续图像及计算机视觉相关任务中的应用。因此，如何通过后期算法提高图像分类的精度和准确性具有重要研究意义，受到越来越多的关注。随着深度学习技术的快速发展及其在图像处理中的广泛应用和优异表现，基于深度学习技术的图像分类方法研究取得了巨大进展。为了更加全面地对现有方法进行研究，紧跟最新研究进展，本文对Transformer驱动的深度学习图像分类方法和模型进行系统梳理和总结。与已有主题相似综述不同，本文重点对Transformer变体驱动的深度学习图像分类方法和模型进行归纳和总结，包括基于可扩展位置编码的Transformer图像分类方法、具有低复杂度和低计算代价的Transformer图像分类方法、局部信息与全局信息融合的Transformer图像分类方法以及基于深层ViT(visual Transformer)模型的图像分类方法等，从设计思路、结构特点和存在问题等多个维度、多个层面深度分析总结现有方法。为了更好地对不同方法进行比较分析，在ImageNet、CIFAR-10(Canadian Institute for Advanced Research)和CIFAR-100等公开图像分类数据集上，采用准确率、参数量、浮点运算数（floating point operations,FLOPs）、总体分类精度（overall accuracy,OA）、平均分类精度（average accuracy,AA）和Kappa（κ）系数等评价指标，对不同方法模型的分类性能进行了实验评估。最后，对未来研究方向进行了展望。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxHDans3iFGpSj3giI8TiMn50vfqqpL2NmoTB35EJcQZwkaoQQBexDB41au4lPgJ-BDGIGnjF4_djn9m1vRsz7MSE4P1OQblE_8nr8C7qbfYmfxliSbwhwltCp981hdeE8NC-rhz8RhaQfwptiY1iuIQut6ziqy16iCelDbmXj2zVCC6vPyA2YIUHVQet5xB6o=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向边缘特征的实时模板匹配方法
{Author}: 王世勇;乾国康;李迪;张舞杰
{Author Address}: 华南理工大学机械与汽车工程学院;
{Journal}: 华南理工大学学报(自然科学版)
{Year}: 2023
{Volume}: 51
{Issue}: 09
{Pages}: 1-10
{Keywords}: 机器视觉;模板匹配;边缘特征;图像金字塔;视觉点胶
{Abstract}: 模板匹配是机器视觉领域的一项共性关键技术，目前基于边缘特征的模板匹配方法存在搜索时间长、在复杂环境下匹配准确率低等问题。为了在保证鲁棒性的同时提升实时性，提出了一种面向边缘特征的实时模板匹配方法。首先，在模板创建阶段，提出了一种新型边缘稀疏方法，通过置信评分机制筛选出模板中不变性强的边缘点，在保留模板关键特征的同时降低模板信息冗余，进而保证稳定性并提升计算效率。其次，在基于金字塔搜索的图像匹配阶段，提出了一种顶层提前筛选方法，采用归一化曼哈顿距离作为限制条件在顶层搜索结果中排除错误目标位姿，以加快后续各层的搜索速度。构建了5种工况不同的数据集，对所提模板匹配方法进行了对比验证，并将其应用于面向自由平面位姿的快速视觉点胶工艺。实验结果表明，所提模板匹配方法在显著提升匹配速度的同时能够保证高准确率，并且能够有效克服光照、旋转、缺陷、多目标、遮挡等干扰因素，满足机器视觉场景中对图像匹配的鲁棒性和实时性要求。
{ISBN/ISSN}: 1000-565X
{Notes}: 44-1251/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwhu8jRq3syBMFlPqqCEw7MI2WQvQinXJhxsFonfEZjvlS2zJeAn86Dl9JoPhYq4Wtrv_d1u6ZG84OuP2sLGfEg8qVtKmYLE9O-uNocBqlLkFzEtN6HojjOdi4xPE9Oy-HLrm1nsnDNyGgYnqZH3gmFbjwhpgfD98ZGN9WqNptfho9k6FTQuv5iBwr_Q3BdE7Y=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Transformer在计算机视觉场景下的研究综述
{Author}: 陈洛轩;林成创;郑招良;莫泽枫;黄心怡;赵淦森
{Author Address}: 华南师范大学计算机学院;广州市云计算安全与测评技术重点实验室;广东省电信规划设计院有限公司;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 12
{Pages}: 130-147
{Keywords}: 视觉Transformer;计算机视觉;图像分类;目标检测;图像分割
{Abstract}: Transformer是一种基于注意力的编码器-解码器架构，其凭借长距离建模能力与并行计算能力在自然语言处理领域取得了重大突破，并逐步拓展应用至计算机视觉领域，成为了计算机视觉任务的重要研究方向。文中重点回顾与总结了Transformer在图像分类、目标检测与图像分割三大计算机视觉任务中的应用和改进。首先，以图像分类任务为切入点，从数据规模、结构特点、计算效率等方面深入分析了当前视觉Transformer存在的关键问题，并基于关键问题对解决方法和思路进行了分类。其次，全面梳理了视觉Transformer在目标检测与图像分割两大领域的研究进展，并根据结构特点、设计动机来组织这些方法，分析对比代表性方法的优点与不足。最后，对Transformer在计算机视觉任务中亟待解决的问题以及发展趋势进行了总结和探讨。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20230913.1226
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于孪生网络的目标跟踪算法综述
{Author}: 马玉民;钱育蓉;周伟航;公维军;帕力旦·吐尔逊
{Author Address}: 新疆大学软件学院;新疆维吾尔自治区信号检测处理重点实验室;新疆大学软件工程重点实验室;新疆师范大学;
{Journal}: 计算机工程与科学
{Year}: 2023
{Volume}: 45
{Issue}: 09
{Pages}: 1578-1592
{Keywords}: 孪生网络;人工智能;计算机视觉;视觉目标跟踪
{Abstract}: 孪生网络是由2个或多个人工神经网络建立的耦合框架，因其将回归问题转换为相似度匹配问题，备受计算机视觉领域的研究人员关注。随着深度学习理论的快速发展，目标跟踪技术在生活中得到了广泛的应用。基于孪生网络的目标跟踪算法以其相对优越的准确率和实时性逐渐代替了传统的目标跟踪算法，成为目标跟踪的主流算法。首先，介绍了目标跟踪任务面对的挑战和传统方法；然后，介绍了孪生网络的基础结构及其发展，汇总了近年来基于孪生网络的目标跟踪算法与相应设计原理；另外，介绍多个用于目标跟踪测试的主流数据集，并基于这些数据集对比了基于孪生网络的目标跟踪算法的性能；最后，提出基于孪生网络目标跟踪算法目前存在的问题及对未来的展望。
{ISBN/ISSN}: 1007-130X
{Notes}: 43-1258/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzNh4y-Lz1z7vfWyz8gescR8LE01bRvZZXoTS_ZgiS98H3QDQPi3I-iHVAhduZ_dxVHBeFpeAM7yC2RhVrCQf14uSeKW5LK0KO6wa2ctSTkp6IeXNfK-TUIRoF_rGHySCgJ5qyMWp46EyYmN70O9mag9uxnzp7ZUOStikwEXC3hTi0s7UJeFhxGwPdTn4mrNp4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度卷积神经网络语义分割综述
{Author}: 马文琪;石颉;吴宏杰
{Author Address}: 苏州科技大学电子与信息工程学院;江苏省建筑智慧节能重点实验室;
{Journal}: 微电子学与计算机
{Year}: 2023
{Volume}: 40
{Issue}: 09
{Pages}: 55-64
{Keywords}: 深度学习;语义分割;卷积神经网络;计算机视觉
{Abstract}: 得益于深度卷积神经网络在特征提取和语义理解的强大能力,基于深度神经网络的语义分割技术逐渐成为计算机视觉研究的热点课题.在无人驾驶、医学图像,甚至是虚拟交互、增强现实等领域都需要精确高效的语义分割技术.语义分割从图像像素级理解出发,为每个像素分配单独的类别标签.针对基于深度神经网络的语义分割技术,根据技术特性的差异,从编码-解码架构、多尺度目标融合、卷积优化、注意力机制、传统-深度结合、策略融合方面展开,对现有模型的优缺点进行梳理和分析,并当前主流语义分割方法在公共数据集实验结果进行对比,总结了该领域当前面临的挑战以及对未来研究方向的展望.
{ISBN/ISSN}: 1000-7180
{Notes}: 61-1123/TN
{URL}: https://link.cnki.net/doi/10.19304/J.ISSN1000-7180.2022.0825
{DOI}: 10.19304/J.ISSN1000-7180.2022.0825
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于卷积神经网络的图像分类模型综述
{Author}: 郭庆梅;于恒力;王中训;刘宁波
{Author Address}: 烟台大学物理与电子信息学院;海军航空大学信息融合研究所;
{Journal}: 电子技术应用
{Year}: 2023
{Volume}: 46
{Issue}: 09
{Pages}: 31-38
{Keywords}: 卷积神经网络;计算机视觉;特征提取;分类模型
{Abstract}: 卷积神经网络在计算机视觉等领域占有一席之地，利用局部连接、权值共享以及池化操作等特性，有效地提取图像的局部特征，降低网络复杂度，具有更少的参数量和更好的鲁棒性，因此，吸引了众多研究者的关注，使分类模型朝着更轻、更快、更高效的方向迅速发展。按照卷积神经网络发展的时间线，介绍了常用的典型网络模型，剖析了其创新点与优缺点，并对其未来的发展方向进行了展望。
{ISBN/ISSN}: 0258-7998
{Notes}: 11-2305/TN
{URL}: https://link.cnki.net/doi/10.16157/j.issn.0258-7998.233909
{DOI}: 10.16157/j.issn.0258-7998.233909
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的苹果自动采摘分拣系统研究
{Author}: 王志勃;孙慧然;孙静波
{Author Address}: 江苏电子信息职业学院;长春工业大学;
{Journal}: 机械设计与制造
{Year}: 2024
{Volume}: 
{Issue}: 08
{Pages}: 326-332
{Keywords}: 自动采摘;自动分拣;机器视觉;苹果;机器人
{Abstract}: 为提升苹果自动化采摘、分拣效率，设计了一种基于机器视觉的苹果自动采摘分拣系统。为设计该系统，首先基于对采摘机器人机械手和末端执行器结构、机械手避障的分析，提出采摘机器人的苹果采摘流程；然后，搭建了基于实时数据处理的苹果自动分拣平台，该平台由两类传送带、可编程逻辑控制器、个人计算机和带有机器视觉、称重传感器和控制面板单元的封闭舱等组成。为验证所构建苹果自动分拣系统的有效性，对来自3个不同苹果品种的183个苹果进行了试验。试验结果表明，所构建的苹果自动采摘分拣系统对苹果按照颜色、尺寸分拣的准确率分别达到96.17%和92.77%，按重量分拣时对苹果重量的估算误差只有5.44克，同时还可对结痂、污点、腐烂等缺陷区域进行100%准确检测。所设计的苹果自动采摘分拣系统具备较高采摘分拣效率，从而对促进苹果产业的发展具有一定实用价值。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20230905.010
{DOI}: 10.19356/j.cnki.1001-3997.20230905.010
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人脸表情域迁移学习与多目标识别方法研究
{Author}: 别梅
{Tertiary Author}: 车翔玖
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 人脸表情;域迁移学习;特征融合;特征增强;多目标识别
{Abstract}: 人脸表情识别在情感计算领域有着重要而广泛的应用前景,是计算机视觉众多研究中的热点问题之一。然而,在实践中又存在诸多的挑战性问题亟待解决,例如:由于人脸区域在整体视频和图片中所占的比例较小且清晰度较低,导致难以提取有效信息。此外,缺乏高质量的公共数据集,而自制数据集往往存在样本量偏小和不均衡的问题。鉴于这些情况,本文在分析现有的表情识别研究成果的基础上,提出了一些针对性的改进策略。首先,针对表情识别领域的小样本问题,构建了域迁移网络,通过利用源域中已知的标签及数据进行训练,并将学到的知识迁移到目标域,使模型在目标域上能够更有效地识别表情;同时,本文考虑到不同场景、不同光照条件和不同设备下采集到的数据的多样性,且不同表情的关键性区域存在着分布差异,本文提出了一种多层次、多维度信息融合的方法来提取关键性的特征;在课堂教学场景下,往往面临多目标、小人脸检测的困难,因此,本文采用特征增强的策略,并建立了FE-YOLOv5模型,以实现了更为准确的多目标检测与定位。本文的具体工作如下:针对表情识别任务中的小样本问题,本文提出了DA-FER(Domain Adaptive for Facial Expression Recognition)模型,采用迁移学习的策略,利用其它样本充足的公共数据集作为上游任务进行网络训练,与此同时,用小样本的目标域数据集接着做域自适应的训练,使网络模型更加适合这个下游任务。本文所提出的基于域自适应的表情识别,综合应用SSPP模块和Slice模块融合不同维度的表情特征,并针对性地保留五官的感兴趣区域,实现更具辨别性的特征提取,强化了网络的表情域迁移能力。同时,通过均值操作和自适应平均池化等策略的应用,将参数总量降低了一半左右,最终使得DA-FER在网络复杂性和目标域的准确率方面都达到了较好的效果。本文以自制的Selfie-Expression数据集为目标域,以公共数据集RAF-DB和Fer2013为源域时,表情识别的效果都有所提升,体现了本文设计的域迁移方法的有效性。针对表情特征的提取容易受到光照变化、人物姿态、遮挡的影响,以及重要信息位置分布多样化,提取有判别性的表情特征困难等问题,本文提出了基于多层次、多维度信息融合的表情识别方法(Multi-dimension and Multi-level Information Fusion,MMIF)。首先,将网络模型所提取到的浅层、中层和深层特征进行可视化分析。针对较深层的特征包含更丰富语义信息的特点,本文明确了从中层特征到深层特征的融合策略。本方法应用于CNN网络(MMIF-CNN),利用残差模式,将各个上采样卷积组进行平滑处理后,聚合了不同尺度特征。同时,利用GAM注意力机制,在三维通道、空间宽度和空间高度上实现跨维度交互,使模型可以关注到图像中不同尺度的特征以及关键性区域。本方法应用于Transformer网络(MMIF-Trans),采用数据维度变换的策略,使整个网络模型感知到更多的空间维度信息。为提升模型的泛化性,增加了Split模块;同时采用了组卷积、均值化的策略,提升模型性能的同时,控制参数量基本保持不变。两个模型在自然条件下的数据集(Fer2013)与实验室环境数据集(CK+)上都取得了较好的实验结果。本文从上述通用的表情识别问题出发,逐步深化到特定场景的多人脸表情识别。在第5章开展了人脸表情识别在课堂教学环境下的具体应用研究。目前的研究算法大多基于实验环境下的单人、正面图像的情况,而对真实课堂中同时处理多人图像的效果欠佳。针对该场景下人脸尺寸小、分辨率低造成的人脸检测定位不准确、表情特征提取困难等问题,本文提出了基于特征增强的课堂环境下多人脸表情识别(Feature Enhancement for Multi-Faces Expression Recognition,FEMFER)方法。首先,本文对YOLOv5进行了改进,采用了上采样模块(UPS module)和CBL模块(CBL module)进行特征增强。UPS module减少了网络局部的感受野,有助于丰富骨干网络对小目标细节信息的学习;CBL module加快模型收敛速度,同时增加特征的非线性。该网络能够高效地提取并融合特征,更适合教室环境下的小脸、多目标检测,改善原有网络对小目标识别不准确的问题。同时,通过融合数据增强和损失函数两个方法,在一定程度上解决了真实场景中样本不均衡的问题。由于目前缺乏应用较为广泛的课堂教学场景的数据集,本文建立三个基于教学环境的数据集:多人脸图片数据集用于目标检测训练;单人脸图片用于表情分类的训练;视频数据集用于应用测试。与原始的YOLOv5相比,本文的方法人脸定位更准确,m AP提升了7.18%;检测速度也更快,达到每秒传输帧数52.13,体现了该方法在实时人脸表情识别领域也有着较好的应用潜力。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.006925
{DOI}: 10.27162/d.cnki.gjlin.2023.006925
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的钢轨表面缺陷智能检测关键技术研究
{Author}: 杨宏飞
{Tertiary Author}: 王言章
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 轨道交通;钢轨缺陷检测;机器视觉;网络模型;深度学习
{Abstract}: 轨道交通是公共交通的重要组成形式,钢轨失效会引发严重的列车运行故障会危及乘客人身财产安全,因此应在失效发生早期进行及时干预。而对钢轨表面缺陷进行准确、可靠的实时检测并提早介入以抑制缺陷的发展,是预防铁路交通安全事故的有效手段。目前广泛采用的人工检测和轨道车巡检两种方式,现有的两类巡检方式普遍存在着夜间巡检条件差、巡检频率低、受复杂极端天气约束等问题。同时,现有缺陷检测系统依然存在覆盖范围有限、故障预警不及时、数据处理和分析复杂、缺陷识别过分依赖人工辅助等问题,具有较大的主观性,检测结果与检测人员的工作经验、专业技术水平、身体、心理状态和工作环境等都有较大的关系。为了克服上述问题,本文设计了基于机器视觉的钢轨表面缺陷智能检测系统并研究了其中的关键技术,实现了强噪声多工况条件下钢轨精确提取、缺陷钢轨分类、钢轨缺陷精确分割和识别预测功能,在此基础上,系统开展了实车测试,实验结果表明提出方法的实用性和有效性。本文主要工作如下:（1）针对复杂噪声背景下原始缺陷钢轨精确提取问题,提出一种基于机器视觉和神经网络相结合的钢轨精确提取方法。首先,利用形态学滤波与概率霍夫变换相结合的算法解决原始图像中因采集设备震动等因素影响而造成数据集含有噪声问题,实现对钢轨的快速、准确识别;其次,针对Canny算法在提取钢轨边缘时产生大量伪边缘的问题,引入了动态因子Is和c,提出了顺次利用阈值法和离散法,得到了钢轨的真正边缘;最后,设计了能兼顾召回率和查准率的改进交叉熵损失函数,基于卷积神经网络建立了高效的钢轨表面形态分类器（Track CNN）。实验结果显示,本文所提出的算法在检测效率、召回率、准确率和鲁棒性等综合方面都有较好的表现。（2）针对复杂工况、光照变化以及不同类型和尺度的钢轨缺陷实时精确分割问题,本文提出一种专门分割钢轨表面缺陷的像素级分割网络（RPLSN）。将特征在通道维度中拼接在一起以形成更丰富的特征,使更多的钢轨缺陷纹理的信息在高分辨率的层中进行传播;对卷积过程中学习到的弱相关关系进行Dropout,使卷积块可以共用一套权重,减少重复计算、降低模型复杂度。同时,进行了基于多模型、多数据集、多工况下的模型性能实验,验证了模型的适应性和优越性。（3）由于钢轨表面服役年限不同,不同表面缺陷具有分布范围分散、形式多样的特点,其识别效果也易受到天气、光照等环境因素影响。针对上述问题,本文提出面向钢轨缺陷风险等级评估的识别预测框架（RLRNM）。首先,提出了一种改进的残差网络的钢轨缺陷特征提取模型,并进行多次训练以提高稳定性和鲁棒性;其次,从精度（Accuracy）、损失值（Loss）和均方根误差（RMSE）等方面与当前流行的特征提取网络进行了比较;最后,进行了基于多模型、多数据集、多工况下的整体模型性能实验,证明提出方法的先进性。（4）针对轨道交通设备日常安全监测管理和保障要求,设计了钢轨表面缺陷智能检测系统,由钢轨表面缺陷检测部分、检测模型在线更新部分、列车组数据交互部分、钢轨缺陷定位部分、供电部分和异常处理部分构成。对该系统及相应设备进行了实地实车测试,针对系统的关键部件进行了详细说明,并对深度学习模型的软硬件实现进行了设计与说明。综上所述,针对多样本、多工况钢轨样本缺陷提取、分割、识别预测等问题,分别从视觉定位、顺序动态阈值、样本分类网络、精确分割网络和缺陷识别预测网络等方面开展研究,提出的方法通过了实验验证。所取得的成果为基于视觉缺陷检测研究方向提供了一定的参考价值。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.007024
{DOI}: 10.27162/d.cnki.gjlin.2023.007024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOV5改进的肺结节检测算法
{Author}: 胡鸿铭
{Tertiary Author}: 叶育鑫
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 肺结节;深度学习;目标检测;Transformer;轻量化;YOLOv5
{Abstract}: 电子计算机断层扫描影像为灰度图,使得影像中肺结节的表征信息有限,同时肺结节的形态多样,以不规则的类圆形为主,且大小不一,不利于检测网络的特征提取,从而导致肺结节检测网络模型出现误检率高、定位不精确等问题。针对此问题,本文利用YOLOv5目标检测网络及Vision Transformer模型,提出了YOLO-Transformer(YOLO-TF)目标检测网络,且在YOLO-TF网络的基础上,进一步精简参数设计了YOLO-Transformer Lite(YOLO-TFLite)网络。当前,在目标检测领域中,存在各种不同类型的网络结构。在进行网络创新优化前,为了挑选出适用于肺结节检测任务的网络,本文进行了基础算法的选型实验。通过对比目前双阶段检测网络及单阶段检测网络中性能最优的检测网络,对各网络的检测精度及检测速度进行综合对比分析,结合实际应用需求及各网络的测试数据,最终选择YOLOv5网络作为基线网络。为提高网络的检测精度,本文在YOLOv5网络中加入Vision Transformer模型,优化设计了YOLO-TF网络,提出了级联并行Transformer模块,用于对全局特征的提取,以及Deform卷积模块,用于对细节局部特征的提取。同时设计了双维度编解码特征提取网络,相比于原特征提取网络具有更丰富的特征信息,采用特征叠加层,将局部特征与全局特征进行合并,得到多维度特征信息的特征图;此外,进一步的设计了特征重组网络,以对特征提取网络的输出进行二次特征处理,通过对不同网络层次的特征图重组、再分组的操作,均衡了特征图的特征信息量。因此,YOLO-TF网络相比于YOLOv5,能够提取更加丰富的特征信息,并且特征重组网络可对特征进行二次提权,提升有效特征的权值,去除冗余的背景特征、综合各网络层次的特征信息,提升各尺度检测器的检测精度。为优化网络的参数设计,降低参数复杂度和计算复杂度,本文通过采用轻量化卷积结构、重参数化设计对YOLOv5进行轻量化设计。提出了YOLO-TFLite网络,进一步精简模块参数,设计了DGhost轻量化卷积模块,并对DGhost卷积模块进行重参数化;本文通过修改YOLO-TF特征重组网络的结构,在其聚合多维度特征与重组操作后,仅输出单尺度特征供检测网络使用;对于检测网络的轻量化采用Anchor Free机制,生成圆形检测框。在该环节中,取消了非极大值抑制(Non Maximum Suppression,NMS)计算,且通过中心点判断目标的区域也可降低检测框数量的冗余。YOLO-TFLite网络相比于YOLOv5及YOLO-TF网络,主要采用了超轻量化的网络模块进行搭建,并仅使用单个Anchor Free机制的检测器进行目标检测任务,上述优化操作均使得YOLO-TFLite的网络参数量远低于YOLOv5及YOLO-TF。在对YOLO-TF及YOLO-TFLite的性能评估实验中,本文采用了LUNA16数据集,共包含有肺部CT影像888张,按照8:2的比例,将所有图片随机分为训练集与测试集。文中进行了消融实验和对比实验,实验结果表明:YOLO-TF的平均检测精度均值达0.918,相比于YOLOv5提升了0.056;YOLO-TFLite的网络参数量为6.6MB,仅为YOLOv5的七分之一,并且YOLO-TFLite的平均检测精度均值相比于YOLOv5仅下降了0.011,仍保持有较优的检测精度。为了能更好的应用所设计的模型,文中依据YOLO-TF及YOLO-TFLite模型设计了肺结节检测系统,通过可视化交互界面提升两个模型的易用性,并增加了检测报告的生成、导出、模型更新等功能。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.007344
{DOI}: 10.27162/d.cnki.gjlin.2023.007344
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv8算法的常用手势识别
{Author}: 孟青云;戴佳蔚;查佳佳;熊亦可;司博宇
{Author Address}: 上海健康医学院医疗器械学院;上海穿戴式医疗技术与器械工程研究中心;上海理工大学健康科学与工程学院;
{Journal}: 现代仪器与医疗
{Year}: 2023
{Volume}: 29
{Issue}: 04
{Pages}: 12-20
{Keywords}: 手势识别;机器学习;人机交互;YOLOv8;Python
{Abstract}: 手势控制医疗设备是一种新型的人机交互方式，其通过非接触式手势识别技术，为医护人员提供更加便捷、高效、卫生的操作方式。本文首先介绍了基于计算机视觉手势识别的概念，讨论了手势识别的分类等关键技术。继而提出了基于计算机视觉的手势识别YOLO算法，旨在实现对医疗设备的便捷操作。实验验证了YOLOv8算法在手势识别方面的可行性，并与YOLOv5版本进行了比较。实验结果显示，尽管YOLOv8的检测速度稍慢，但在不同IOU阈值下的平均精度值更高。通过使用YOLOv8模型训练的常用控制手势识别模型在测试集中展现出出色的拟合性能，能够实现对图片、视频和摄像头的实时检测与识别。
{ISBN/ISSN}: 2095-5200
{Notes}: 10-1084/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw66os2a4powdqxZEjILOl70r-WG8wqesCP4BEi8czlj9NvIR17undMHcxoou3f5a8IdYGpcyUXT9PAzH2PVF56MqBEVQRbdEhB8JPkZLVGyRufjHT60v9ASGMefGZeitrClCa9wnQftpyWlKcRtswW3wB0LuaTNmHJa7mOK7xwBcQYU5Fsnj7E50SK0Ykb3kY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在采摘机器人识别与定位中的应用
{Author}: 焦迎雪;董海涛;武文革
{Author Address}: 山西铁道职业技术学院;山西机电职业技术学院;中北大学;
{Journal}: 机械设计与制造
{Year}: 2024
{Volume}: 
{Issue}: 02
{Pages}: 280-285
{Keywords}: 机械视觉;采摘机械人;识别与定位;独立成分分析;三点定圆法
{Abstract}: 针对采摘机器人的运行环境复杂，采摘效率无法满足实际生产需求。这里在采摘机器人体系结构的基础上，提出了一种基于机器视觉的夜间识别与定位方法。使用基于粒子群优化的独立成分分析方法来降低夜苹果图像中的噪声，然后使用PCNN分割方法对图像进行分割并通过边缘检测等提取目标轮廓，最后通过改进的三点定圆法对目标果实进行定位。通过仿真验证了该方法的可行性。结果表明，该方法在夜间遮挡小于50%时识别率为94.3%，遮挡大于50%时识别率为89.05%，可以有效提高识别和定位的准确性。为机器人识别和定位技术的发展提供了一定的参考。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20230824.016
{DOI}: 10.19356/j.cnki.1001-3997.20230824.016
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉引导的机械臂定位与跟踪算法研究
{Author}: 李冲
{Tertiary Author}: 孙涛
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像去噪;卷积神经网络;卡尔曼滤波;深度学习
{Abstract}: 随着科技的快速发展,机械臂在工业制造、医疗、军事等领域中得到广泛应用。然而,机械臂的定位和跟踪问题一直是制约其应用的瓶颈之一。为了提高机械臂的精度和稳定性,基于视觉引导的机械臂定位与跟踪算法成为了研究热点。本文针对非结构化的环境下,围绕基于视觉引导的机械臂定位与跟踪方法展开研究,主要内容如下:首先,分析了机械臂视觉系统,针对机械臂定位和跟踪过程中图像噪声大的问题,提出了一种基于改进的二维经验模态分解与维纳滤波相结合的图像去噪算法。通过采用改进的二维经验模态分解技术,可以有效地将噪声图像分解得到含噪本征模态函数分量,并结合维纳滤波技术,实现最大程度的降噪。实验结果表明,该算法能够有效地去除图像噪声,提高图像质量,并且本文提出的算法对高噪声图像的去噪能力优于其它对比算法。其次,针对传统的图像处理与特征提取过程复杂繁琐,且鲁棒性不高的问题,本文采用基于深度学习的目标跟踪检测方法,提出一种基于改进的YOLOv5s与Deep SORT的目标跟踪检测算法。将改进的YOLOv5s模型作为Deep SORT的检测器,通过提升目标的检测性能来提升跟踪性能,降低目标身份切换率,提升目标特征信息的准确度。通过对本文所提方法进行测试,结果表明,相比于原始YOLOv5s+Deep SORT,改进YOLOv5s+Deep SORT模型的MOTA提高了13.1%,MOTP提高了3.3%,且对于遮挡目标以及小尺度目标都具有较好的跟踪和检测性能,为后续机械臂的规划控制提供了有效的目标特征信息。最后,针对基于无标定的机械臂目标定位方法中,图像雅克比矩阵的估计问题,提出了一种基于RBF神经网络修正的最大相关熵卡尔曼滤波算法。本文将最大相关熵准则引入到卡尔曼滤波框架中来抑制机器人视觉伺服中非高斯噪声对滤波精度的影响,然后使用RBF神经网络校正由最大相关熵卡尔曼滤波算法产生的估计误差。通过仿真与实验验证,结果表明,通过提高雅可比矩阵估计值的准确性和稳定性,可以有效改善视觉伺服定位的精度和鲁棒性。在非高斯环境下的仿真实验中,所提算法能够将定位误差控制在1.9pixels以内,并且图像特征轨迹较为平稳,具有较强的抗噪声干扰能力。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000561
{DOI}: 10.27278/d.cnki.gsdqc.2023.000561
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像分割技术研究综述
{Author}: 唐璐;赵英
{Author Address}: 广州工商学院;南昌应用技术师范学院;
{Journal}: 电脑知识与技术
{Year}: 2023
{Volume}: 19
{Issue}: 23
{Pages}: 30-32
{Keywords}: 图像分割;计算机视觉;深度学习;数据集;评价指标
{Abstract}: 图像分割是计算机视觉中的一个重要研究方向，它将图像分为不同的区域或对象，是许多高级应用的基础。文章对图像分割技术进行了总结，包括传统的基于阈值、边缘、区域和聚类的方法，以及深度学习方法，常用的数据集和评价指标，最后对图像分割技术研究的方向和面临的挑战进行了总结及分析。
{ISBN/ISSN}: 1009-3044
{Notes}: 34-1205/TP
{URL}: https://link.cnki.net/doi/10.14004/j.cnki.ckt.2023.1172
{DOI}: 10.14004/j.cnki.ckt.2023.1172
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的汽车装配件缺陷检测研究进展
{Author}: 张瀚丹;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2023
{Volume}: 44
{Issue}: 08
{Pages}: 1-20
{Keywords}: 汽车装配件;缺陷检测;机器视觉;深度学习;性能评价指标
{Abstract}: 汽车装配件的缺陷检测是汽车制造流程中的重要环节，不仅可以提升产品质量，降低退货率，避免成本浪费，还可以为驾驶人员提供安全保障。最早的缺陷检测依靠专家经验，准确度低，人力成本大，而无损检测技术依靠介质，且效率不高。引入机器视觉不仅可以平衡检测精度和效率的问题，还能提高检测系统的鲁棒性，是最有发展潜力的缺陷检测技术之一。本文首先给出了视觉缺陷检测的定义和主要流程，简述了视觉缺陷检测系统中的图像采集硬件，然后从常用的缺陷分割方法、特征提取方法、卷积神经网络3个方面综述了近年来汽车装配件缺陷检测的研究进展，并对比分析了相关方法的优缺点。接着把汽车的装配件大致分为轮毂轮胎、车身漆面、零件、发动机等4类，总结了缺陷类型及其缺陷检测算法的研究现状。随后介绍了与汽车工业相关的10个数据集和缺陷检测性能评价指标。最后指出针对汽车装配件的缺陷检测目前面临着诸多方面的技术挑战，并对进一步的工作进行了展望。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2311695
{DOI}: 10.19650/j.cnki.cjsi.J2311695
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉下的旋转目标检测研究综述
{Author}: 王旭;吴艳霞;张雪;洪瑞泽;李广生
{Author Address}: 哈尔滨工程大学计算机科学与技术学院;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 08
{Pages}: 79-92
{Keywords}: 计算机视觉;深度学习;目标检测;旋转目标;性能比较
{Abstract}: 传统目标检测器通过水平边界框(Horizontal Bounding Box, HBB)定位目标，在检测方向角任意、分布密集、长宽比大、背景复杂的目标时，往往精度较低、泛化能力较差。在边界框中增加不同旋转角度的旋转目标框可有效解决上述问题，其被广泛应用在遥感图像、场景文本图像、货架商品图像等目标检测领域，具有重要研究价值。目前大多数工作旨在构建不同的旋转目标检测模型，对现有模型的归纳总结及深入分析的综述性工作较少。为此，对旋转目标检测现有研究成果进行了详细综述。首先根据当前流行的目标框表征方式，将目标框分为旋转矩形框(Oriented Bounding Box, OBB)、四边形边界框(Quadrilateral Bounding Box, QBB)和点集(Point set) 3种类型，并比较了不同旋转目标检测算法的优缺点、网络结构和性能；其次分析了目前常用的旋转目标检测数据集和性能评价指标；最后对目前研究中存在的问题进行简要总结和讨论，并对未来的发展趋势进行展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxO0shDyDLAoaCnX0TsPCMOhXiC9S3ruaLaCyIZTrX6UaPcubxkWyv6gghomSRVZWHFmi9qlyEq_t9im52am_v6Tamtg8I9NtEwUPNUaSaaBr5bfF4-gMu7kl0WSVRdDwPph6pUWeznNtGlyrtVxO_fbuLVjmrIeoCzx0TSadslXS8Y1wmsbU8APcks3BdrhXM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的车辆目标检测算法综述
{Author}: 邹伙宗;邓守城
{Author Address}: 三峡大学机械与动力学院;
{Journal}: 时代汽车
{Year}: 2023
{Volume}: 
{Issue}: 15
{Pages}: 16-18
{Keywords}: 深度学习;车辆目标检测;卷积神经网络;计算机视觉
{Abstract}: 近年来，随着人工智能技术的迅猛发展，许多车企和互联网企业都共同致力于研发智能化的自动驾驶系统。在自动驾驶技术中，车辆目标检测技术是至关重要的核心技术之一。目前，传统的目标检测算法无法满足实时检测的要求，因此在自动驾驶等实际应用场景中很难进行大规模应用。相比之下，基于深度学习的目标检测算法更适合此类场景，已经成为该领域的主流算法。本文首先回顾了传统目标检测算法，然后介绍了当前几种主流的两阶段车辆目标检测算法和单阶段车辆目标检测算法，分析了这几种算法的结构和优缺点，最后对未来车辆目标检测算法的研究方向进行了展望。
{ISBN/ISSN}: 1672-9668
{Notes}: 42-1738/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyDfogA1PGQKTzueAXjmqncKBzsBjEENP89PDiec9Qy0aY-jwcU3FunG6ZwROoCx-BZbYEwK05uI8mZM2pDImSaIKdqz70mV1O_N7lszjZ41S87h2WUBohOht2OjCT1Z_GLEFVZVnN7PR6nEm_BoTPnJ17mLi66VoW1Zg9m2hxbw74nb4ZlejeHkcdmx1LYDgs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的视觉同时定位与建图研究进展
{Author}: 张耀;吴一全;陈慧娴
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2023
{Volume}: 44
{Issue}: 07
{Pages}: 214-241
{Keywords}: 同时定位与建图;机器视觉;深度学习;视觉里程计;回环检测;数据集;评估指标
{Abstract}: 随着机器视觉的不断发展，视觉传感器其小巧轻便、价格低廉等优势，使得视觉同时定位与建图(VSLAM)越来越受人们关注，深度学习为处理VSLAM问题提供了新的方法与思路。本文综述了近年来基于深度学习的VSLAM方法。首先回顾了VSLAM的发展历程，系统阐释了VSLAM的基本原理与组成结构。然后从视觉里程计(VO)、回环检测与建图3个方面分析各类基于深度学习的方法，从特征提取与特征匹配、深度估计与位姿估计及关键帧选择等3个部分阐述了深度学习在VO中的应用；基于场景表达方式的不同，总结了几何建图、语义建图及广义建图中的深度学习方法。接着介绍了目前VSLAM常用的各种数据集以及性能评估指标。最后指出了目前VSLAM面临的难题与挑战，展望未来深度学习与VSLAM结合的研究趋势与发展方向。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2311081
{DOI}: 10.19650/j.cnki.cjsi.J2311081
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenMV视觉技术对物体识别与跟踪的实验研究
{Author}: 杨益宽;王俊伟;孙钰樟
{Author Address}: 河套学院机电工程系;
{Journal}: 化工自动化及仪表
{Year}: 2023
{Volume}: 50
{Issue}: 04
{Pages}: 569-572
{Keywords}: OpenMV;机器视觉;PID算法;舵机;识别;动态追踪
{Abstract}: 以OpenMV作为图像处理模块，搭配两个云台舵机设计了一个物体识别与跟踪实验系统。介绍了实验所采用的装置和具体实现过程，对舵机采用了增量式PID算法进行控制。该实验系统实现了对物体的识别与跟踪功能。
{ISBN/ISSN}: 1000-3932
{Notes}: 62-1037/TQ
{URL}: https://link.cnki.net/doi/10.20030/j.cnki.1000-3932.202304025
{DOI}: 10.20030/j.cnki.1000-3932.202304025
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业害虫智能视觉检测研究综述
{Author}: 王春桃;梁炜健;郭庆文;钟浩;甘雨;肖德琴
{Author Address}: 华南农业大学数学与信息学院;农业农村部华南热带智慧农业技术重点实验室;广东省农业人工智能重点实验室;广州市智慧农业重点实验室;
{Journal}: 中国农机化学报
{Year}: 2023
{Volume}: 44
{Issue}: 07
{Pages}: 207-213
{Keywords}: 虫情监测;计算机视觉;目标检测;机器学习;深度学习
{Abstract}: 农业害虫智能视觉检测是实现虫情自动实时监测的重要技术，首先介绍经典机器学习技术在国内外害虫智能视觉检测中的应用，然后整理以R-CNN、Fast R-CNN、Faster R-CNN、SSD和YOLO等深度学习技术为核心的新一代害虫智能视觉检测方法的研究进展。接着，剖析农业害虫智能视觉检测方法在研究及实际应用中存在的问题，其中基于经典机器学习的方法存在特征捕获能力和检测精度较低、资源消耗较大以及鲁棒性较弱等问题；基于深度学习的方法比基于经典机器学习的方法拥有更高检测性能，但存在数据分布不同和目标较小时识别效果较差、检测精度低和速度慢等问题。最后，针对基于深度学习的方法在农业昆虫数据库的制作、数据分布偏移的鲁棒性处理、深度特征学习、多场景应用4个方面对未来研究方向进行展望。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2023.07.028
{DOI}: 10.13733/j.jcam.issn.2095-5553.2023.07.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆形垫圈尺寸测量系统设计
{Author}: 张炳星;高军伟;王建冲;刘佳浩
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 工具技术
{Year}: 2023
{Volume}: 57
{Issue}: 07
{Pages}: 141-145
{Keywords}: 机器视觉;尺寸测量;边缘检测;亚像素边缘;最小二乘法
{Abstract}: 针对传统工业检测中人工测量工件尺寸存在效率低、精度差等问题，设计了基于机器视觉的圆形垫圈尺寸测量系统。在MATLAB软件中对CCD相机进行尺寸标定，对采集的图像进行灰度处理，使用改进后的Canny自适应迭代阈值算法对图像进行边缘检测，对边缘坐标进行双线性插值并提取亚像素边缘坐标，根据最小二乘法对亚像素边缘坐标进行圆拟合，得到工件内径与外径尺寸。实验结果表明，本系统的测量精度可达到±0.02mm,可应用于圆形工件的视觉测量。
{ISBN/ISSN}: 1000-7008
{Notes}: 51-1271/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzFCneVDv9hE-eR5AicUtARk7cfKpeoJMOSujGNomcazoCFDmICwGBrJW5cGrV1VSVfW4zauUcEqHgZsiJ7IVkUPFx5WBbHZM6uVHp93iUtv1EvxBiJk8efOFMleR27GXZH7MAEgG5Lkm10CwHROR2jXz4x8mHIjPOwS9ijhdijTxTQKrpD2qCiT0q7wgCm4ws=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的学生课堂行为识别研究与应用
{Author}: 李甜甜
{Tertiary Author}: 赵志瑛
{Publisher}: 太原师范学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 学生行为识别;H/W阈值判定;YOLOv5
{Abstract}: 学生课堂行为识别是当代计算机与教育领域共同研究的热点课题。随着人工智能与互联互通的数字化教育平台相结合,教育管理出现重大革新,标志着以人工智能技术为支撑的教育信息化建设,将会成为现代教育的必然选择和发展形态。本文重点关注教室内的学生行为识别任务,采用级联网络和目标检测网络两种研究思路对课堂中学生出现的举手、站立、使用手机等行为展开研究,主要研究内容如下:(1)构建了包含多种课堂场景的Stud＿Hard数据库。针对该研究领域无合适的数据集,在教育平台和视频网站上收集了大量的公开课视频,并使用监控设备采集了真实课堂的视频图像;针对数量较少的学生行为类别,使用手机拍摄图像,并使用搜索引擎获得图片。经过处理后,Stud＿Hard数据库中每张图片的目标样本个数在1～64之间,总共5570张图片。(2)提出基于H/W阈值判定的级联网络学生行为识别方法。该方法使用Nano Det-Plus轻量级目标检测算法对学生进行位置定位,针对存在误检框的问题,将骨干特征提取网络Shuffle Net V2替换为Mobile Net V2,增强模型的学习能力,减少了误检框的数量,改进后的AP50提升了0.88%。H/W阈值判定方法用于筛选图像边缘区域中具有残缺行为信息的图片,根据50535张图片的高宽比分布情况,将阈值范围设定为[0.45,2.6],并使用554个检测框验证了阈值的有效性。针对级联网络中的学生行为分类任务,对比四种轻量级网络Res Net18、Mobile Net V3-Small、Efficient Net-B0、Rep VGG-A0的效果,使用综合性能较好的Rep VGG-A0作为学生行为分类网络,该网络类别平均正确率可达到97.24%。(3)将EIo U和Varifocal Loss损失函数引入YOLOv5模型。使用YOLOv5可以兼顾视频检测任务,扩展学生行为识别的应用场景,并针对YOLOv5模型的损失函数进行改进,改进后的EVF＿YOLO加快了训练时损失值收敛的速度,并提高了学生课堂行为识别的准确度,m AP0.5已经达到96.3%。此外综合多种目标检测模型,验证EVF＿YOLO模型在学生课堂行为识别任务中的先进性。为了将深度学习技术应用在课堂中,将研究的算法部署在学生课堂行为识别平台上,实现计算机技术与课堂管理相结合,助力智慧化教育的发展。
{URL}: https://link.cnki.net/doi/10.27844/d.cnki.gtysf.2023.000026
{DOI}: 10.27844/d.cnki.gtysf.2023.000026
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像处理中注意力机制综述
{Author}: 祁宣豪;智敏
{Author Address}: 内蒙古师范大学计算机科学技术学院;
{Journal}: 计算机科学与探索
{Year}: 2024
{Volume}: 18
{Issue}: 02
{Pages}: 345-362
{Keywords}: 注意力机制;核心思想;关键结构;图像处理
{Abstract}: 图像处理中的注意力机制已成为深度学习领域中流行且重要的技术之一，因其具有优秀的即插即用便利性，被广泛应用于图像处理领域的各种深度学习模型中。注意力机制通过对输入特征进行加权处理，将模型的注意力集中于最重要的区域，以提升图像处理任务的准确性和性能。首先，将注意力机制的发展过程划分为四个阶段，并在此基础上对通道注意力、空间注意力、通道与空间混合注意力和自注意力四个方面的研究现状及进展进行了回顾与总结；其次，针对注意力机制的核心思想、关键结构和具体实现进行了详细的论述，并进一步总结和归纳所使用模型的优缺点；最后，通过对当前主流的注意力机制进行对比实验和结果分析，讨论了现阶段注意力机制在图像处理领域中存在的问题，并对图像处理领域中注意力机制的未来发展进行展望，为进一步研究提供参考。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20230629.1447.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果分级系统
{Author}: 刘佳浩;高军伟;张炳星;王建冲
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 食品与机械
{Year}: 2023
{Volume}: 39
{Issue}: 06
{Pages}: 112-118
{Keywords}: 机器视觉;水果分级;边缘检测;最小外接圆法;HSI颜色模型
{Abstract}: 目的:解决目前水果分级检测方法效率低、误检率高等问题。方法:以苹果为分拣对象，设计一个基于机器视觉的水果分级系统。对实时采集得到的苹果图像进行预处理，使用改进的Canny边缘检测算法进行边缘提取，通过最小外接圆法拟合边缘坐标得到苹果的横切面半径。将采集到的RGB图像转换为HSI图像，根据H分量范围计算红色区域比例，判断苹果的色泽度。统计区域像素点个数，分别求取苹果的面积和周长，计算出苹果的圆形度。结合苹果果径长度、色泽度和圆形度3个特征值对苹果进行综合分级。结果:50个苹果样本试验结果表明，水果分级系统和人工分拣测量的果径误差范围在±1.5 mm以内，样本颜色特征与苹果实际外观相符，圆度值的大小与实际形状优劣相符。结论:该系统满足实际生产中对于苹果分级的需求，有助于实现苹果品级的准确识别。
{ISBN/ISSN}: 1003-5788
{Notes}: 43-1183/TS
{URL}: https://link.cnki.net/doi/10.13652/j.spjx.1003.5788.2022.80967
{DOI}: 10.13652/j.spjx.1003.5788.2022.80967
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的目标检测算法研究与应用综述
{Author}: 张阳婷;黄德启;王东伟;贺佳佳
{Author Address}: 新疆大学电气工程学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 18
{Pages}: 1-13
{Keywords}: 目标检测;深度学习;计算机视觉;深度卷积神经网络
{Abstract}: 随着深度学习的不断发展，深度卷积神经网络在目标检测领域中的应用愈加广泛，现已被应用于农业、交通和医学等众多领域。与基于特征的传统手工方法相比，基于深度学习的目标检测方法可以学习低级和高级图像特征，有更好的检测精度和泛化能力。为了概括和总结目标检测领域的最新进展和技术，通过分析近年来基于深度学习的目标检测技术，对基于深度学习的目标检测算法与应用现状进行综述。归纳了两阶段与单阶段两种目标检测网络架构的发展及优缺点；从骨干网络、数据集和评价指标等方面进行叙述，对比了经典算法的检测精度，总结经典目标检测算法的改进策略；讨论了现阶段目标检测应用，并提出了目标检测领域今后的研究重点。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230620.1746.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 服务机器人的抓取物体识别与位姿估计
{Author}: 巩大康
{Tertiary Author}: 张自嘉
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 服务机器人;机械臂;深度相机;目标检测;位姿估计
{Abstract}: 随着人工智能的发展,服务机器人已经广泛进入日常生活中。传统的服务机器人往往采用离线编程或者示教的方式完成抓取任务。随着计算机视觉技术不断的发展与完善,引入视觉的机器人可以完成更加复杂多样化的任务,抓取物体识别与位姿估计是视觉抓取服务机器人研究的重要领域之一。但是2D图像只能识别物体位置,无法获得物体的深度信息,而传统的3D点云视觉检测算法复杂且运算时间较长。因此,本文深入研究了计算机视觉领域中的目标检测与位姿估计算法,采用2D彩色图与3D深度图结合的物体识别和位姿估计方法,设计了基于计算机视觉的机械臂抓取系统,完成复杂环境下对目标物体的识别与位姿估计,机械臂依据其位姿完成抓取任务,提高服务机器人的智能化程度。本文完成的主要内容如下:根据视觉抓取服务机器人的功能需求完成硬件选型与平台搭建,并完成视觉抓取服务机器人系统的整体设计。接着对视觉抓取系统进行标定,获得相机坐标系与机械臂末端坐标系之间的转换关系。针对目标检测算法,采用改进的YOLOv7-tiny算法在本文抓取物体数据集上的平均精度均值m AP达到94.74%,获得抓取目标物体的检测定位框,将彩色图与深度图配准初步确定目标物体的类型及位置。针对位姿估计算法,通过RANSAC、聚类等算法对场景点云分割处理得到各个目标物体,结合目标检测算法确定目标物体类型,采用PCA位姿估计算法得到每个抓取物体位姿,对箱体位姿估计采用改进的PCA算法,相比于传统的PCA位姿估计算法点云数量减少了8.9%,制定打分策略获得优先抓取位姿。在ROS操作系统中建立相机与机械臂之间的数据通信,机械臂依据位姿信息进行抓取,完成复杂场景下抓取任务,单目标抓取成功率达到了90.8%,多目标抓取成功率为75%,验证了本文系统方案的可行性。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2023.000478
{DOI}: 10.27248/d.cnki.gnjqc.2023.000478
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 注意力机制在提高YOLOv5目标检测精度的研究
{Author}: 俞奋孝
{Tertiary Author}: 朱辉
{Publisher}: 阜阳师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;YOLOv5;注意力机制
{Abstract}: 近年来,由深度学习引发的人工智能热潮席卷了各个领域。深度学习使用神经网络建模数据,利用深度网络学习复杂模式,已广泛地应用到计算机视觉、自然语言处理、语音识别等领域。目标检测是计算机视觉技术中的一个重要分支,其目的是从图像或视频中识别出感兴趣的物体,同时确定其位置,应用于自动驾驶汽车、无人机技术、安防监控等领域。YOLOv5是YOLO(You Only Look Once)系列目标检测算法的第五代产物,是目前最流行的目标检测算法之一,但依然存在特征提取能力不足的问题。本文针对YOLOv5缺少有效特征强化以及背景噪声抑制,设计了一种将注意力机制插入YOLOv5网络模型的主干网络之中进行融合的方案。以YOLOv5s为基础,选取了SE(Squeeze-and-Excitation)、CBAM(Convolutional Block Attention Module)、ECA(Efficient Channel Attention)和CA(Coordinate Attention)这四种典型注意力机制进行模块化设计,插入YOLOv5s网络模型之中对其进行改进。构建了单一位置插入注意力机制的网络模型用于研究插入位置对YOLOv5s整体网络模型的性能影响,而后进一步构建了融合注意力机制的YOLOv5s＿Attention网络模型,加强YOLOv5s的特征提取能力,抑制背景噪声,实现提升其目标检测精度的效果。本文使用微软大型公共数据集MS COCO对四种单一位置插入注意力机制的网络模型以及融合注意力机制的YOLOv5s＿Attention网络模型进行训练和验证,利用COCO评价指标对实验结果进行性能评估。经过全面测试与分析,融合注意力机制的YOLOv5s＿Attention网络模型的评价指标均优于YOLOv5s,改进之后参数量和计算量不变。融合CA注意力机制的YOLOv5s＿Attention网络模型与原始网络模型相比,其AP(Average Precision)提升了0.8个百分点、AP@0.50提升了1.2个百分点、AP@0.75提升了0.6个百分点。
{URL}: https://link.cnki.net/doi/10.27846/d.cnki.gfysf.2023.000275
{DOI}: 10.27846/d.cnki.gfysf.2023.000275
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的智能垃圾分类系统设计与实现
{Author}: 王文武
{Tertiary Author}: 张颖慧
{Publisher}: 内蒙古大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 垃圾分类;深度学习;YOLOX;卷积块注意力机制;坐标注意力机制;NVIDIA Jetson Xavier NX
{Abstract}: 世界发展日新月异,生产力呈指数型增长,与此同时垃圾产生数量也不容忽视,如何处理各种垃圾是非常棘手的问题。对垃圾进行合理的分类,有利于垃圾的处理以及资源的回收利用,改善环境质量。然而,当前的垃圾分类与处理工作主要依靠人工完成,存在成本高和效率低等弊端,且垃圾集中分类环境恶劣,不利于人体健康。因此,应从源头解决垃圾分类问题。针对现有问题,本文设计实现基于深度学习的垃圾分类系统和智能垃圾处理装置。
本文将YOLOX目标检测算法应用在垃圾检测领域,以华为公司发布的公开垃圾数据集为基础,扩充常见生活垃圾样本数量。同时,采用数据增强技术对原始数据集进行扩充,解决模型训练过程中因为数据集样本不均衡、图像数据量小导致的模型精度低及过拟合问题。利用新构建的垃圾数据集训练YOLOX垃圾分类模型,对比YOLOX不同版本的网络模型性能,选择检测速度和检测精度更为均衡的YOLOX-s模型作为后续研究的基础。通过对YOLOX-s模型进行改进,并与经典目标检测算法进行性能比较。实验表明,改进后的模型平均精确度达到95.05%,性能优于现存的大多数算法模型。
为了进一步优化YOLOX-s垃圾分类模型性能,本文提出利用卷积块注意力机制(Convolutional Block Attention Module,CBAM)和坐标注意力机制(Coordinate Attention,CA)改进YOLOX-s特征提取网络。首先,利用注意力机制优化主干网络的特征提取信息;然后,通过注意力机制优化特征金字塔(Feature Pyramid Networks,FPN)结构,使得网络的特征提取更加具有针对性,从而提高对小目标的检测能力。实验结果表明,优化后的YOLOX-s垃圾分类模型平均精度达到了98.38%,比优化之前的模型平均精度提升了3.33%。
最后,本文将优化后的垃圾分类网络模型部署,进行系统化设计和应用。首先,基于灵活、轻便的Web应用程序框架Flask设计实现垃圾分类与管理系统。然后,将垃圾分类模型部署在NVIDIA Jetson Xavier NX芯片中,基于该模块设计实现了智能垃圾分类装置,该装置可以实时获取用户投放的垃圾图像并判断垃圾类别,自动完成垃圾分类任务。最后,将智能垃圾分类装置与系统结合,实现管理人员对装置的远程监测功能。同时,对垃圾分类与管理系统及智能垃圾分类装置的功能进行了测试并验证了其稳定性。实验结果表明,提出的改进垃圾检测算法能有效提升检测性能,并且该系统与智能装置均满足实际使用需求、有较高的实用性。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2023.000666
{DOI}: 10.27224/d.cnki.gnmdu.2023.000666
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向表面缺陷检测的视觉特征表示方法研究
{Author}: 赵文义
{Tertiary Author}: 杨辉华
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 机器视觉;特征表示;缺陷检测;自监督学习;空间感知
{Abstract}: 近年来,人工智能技术的快速发展已经对传统制造业产生了深远的影响,世界各国也相继开展制造业的产业升级。我国是制造大国,制造业是国民经济发展的重要支柱,也是我国落实工业化和信息化深度融合、打造制造强国的战略部署。国务院于2015年印发的“中国制造2025”及2017年印发的“新一代人工智能发展规划”,旨在加快制造企业从传统劳动密集型向智能高精尖转型。大力发展智能制造产业不仅能推动我国创新创业的迅速升级,也能促进中国制造走向世界。基于视觉成像的表面缺陷分类和检测作为智能制造业中最大的应用点之一,已受到学术界和工业界的广泛关注。如何准确表示、精准分类和有效检出背景复杂的表面缺陷,实现多种场景中表面缺陷特征的高效处理,是机器视觉领域的前沿挑战难题与技术制高点。因此,研究高效且泛化的基于深度学习的表面缺陷分类和检测方法已成为当前制造业领域亟待解决的挑战性难题。基于机器视觉的表面缺陷分类和检测是指利用机器学习和深度学习技术,对采集到的图片判断并定位出表面缺陷的类别和位置,以辅助对产品质量进行把控。然而,基于机器视觉的表面缺陷检测面向的是各式各样的缺陷,这些缺陷的形成受原料质量、生产环境等因素的影响,在外形和尺寸上表现出较大的差异,这些问题给表面缺陷的检测带来了巨大的挑战。使用监督学习范式在处理缺陷样本较少和类别分布不均的分类任务时会出现明显的头部类别偏置现象,不能准确对缺陷样本进行分类。此外,使用监督学习和自监督学习得到的预训练模型空间感知能力不足,导致在缺陷检测任务中性能较差。针对以上问题,本文改进模型结构来缓解表面缺陷检测中存在的形状和尺寸适应性不强的问题。对于少样本和类别分布不均的缺陷分类问题,本文从数据和特征利用的角度出发,提出两种自监督学习方法以获得无特征偏置的模型,从而提升分类性能。对于缺陷检测任务中模型空间感知能力不足的问题,本文深度借鉴目标检测的原理机制,提出结合空间特征采样的单分支自监督学习框架以提升模型的特征泛化能力。本文的具体贡献如下:1)针对表面缺陷分类和检测任务中模型对多样化和差异化特征适应性不足的问题,本文阐明了卷积网络在深度和宽度方向的表征机制,提出了在一个卷积模块中融合不同深度和宽度的卷积操作,构建了形状和尺寸感知的骨干网络以提高模型的视觉特征表示能力。实验结果表明本文设计的方法能有效分类、检出外观差异较大的目标,优化了基于残差网络的特征表示能力,显著提升了表面缺陷分类和检测的性能。在ImageNet分类数据集和COCO目标检测数据集中,提出的方法比基线模型性能分别高1.5%和2.0%;同时在多种缺陷检测数据集中性能能稳定提升2%以上。2)针对表面缺陷分类任务中模型在处理类别失衡的小规模数据时出现的类别偏置和过拟合问题,本文揭示了数据和模型对特征提取器优化的表征机制,提出了基于拼接图像和混合任务优化的数据增强策略和特征挖掘方法,构建了基于孪生网络的高效自监督学习框架以获得无特征偏置的泛化模型。另外,通过提出空间和语义约束的采样策略进一步减少了模型的计算消耗,并显著提高了预训练模型的泛化性能。在仅消耗50%计算量的前提下,提出的方法在多种类别失衡的小规模分类数据集中的性能达到最优。在ImageNet分类数据集中,提出的两种方法分别比基线模型性能高2.4%和2.7%;同时在不同的缺陷分类数据集中性能均优于监督学习1.2%以上。3)针对现有预训练模型对缺陷样本空间特征感知能力不足的问题,本文深度借鉴目标检测的机理,提出了基于全局和局部的采样方法,构建了用于目标检测的高效自监督学习框架,将包含定位、聚类和对比任务的混合优化方法嵌入到统一的单分支结构中,实现了用于目标检测的自监督特征提取。与基于孪生网络的方法相比,本文设计的方法消耗较少计算量,并且在多种表面缺陷检测数据集上的性能达到最优。在COCO目标检测数据集中,提出的方法比监督学习预训练模型性能高1.7%;同时在不同的缺陷检测数据集中性能均优于监督学习1.6%以上。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000362
{DOI}: 10.26969/d.cnki.gbydu.2023.000362
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的水稻病虫害监测预警技术研究
{Author}: 郑果
{Tertiary Author}: 姜玉松;张致力
{Publisher}: 重庆三峡学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智慧农业;图像识别;卷积神经网络;多任务学习;迁移学习
{Abstract}: 水稻是我国最主要的粮食作物之一,对解决中国粮食安全问题发挥极其重要的作用。我国水稻生产具有种植面积大,种植地分布广,病虫害灾害爆发频发特点,给我国粮食生产造成巨大经济损失,水稻病虫害防治工作面临巨大挑战。以人工巡查判别为主的传统水稻病虫害识别方式存在准确率低、成本高且效率低下等问题。为了解决该问题,本文以水稻病虫害叶片图像为研究对象,以深度神经网络理论为基础,围绕实际场景下图像尺度变化、标注样本数量不足等因素导致水稻病虫害识别精度下降问题,开展基于多尺度特征融合的水稻叶片病害诊断方法、基于迁移学习的水稻害虫识别方法研究,并采用主流的Springboot框架,开发面向移动互联网的水稻病虫害识别的预警系统,为水稻病虫害自动识别提供应用示范。本文研究内容及创新之处如下:(1)针对实际应用场景下图像尺度变化导致水稻病害识别准确率下降问题,提出一种基于多尺度特征融合的水稻叶片病害诊断方法。由于拍摄距离变化,水稻叶片图像分辨率出现变化。传统基于深度卷积神经网络的水稻叶片病害识别方法仅适应单一图像尺度的特征学习,在网络后端将最后若干卷积层特征图进行串联融合,这种方式难以适应尺度变化较大的情况。本文采用多任务学习框架,将水稻叶片病害类型和病害程度判别两个关联任务同时进行特征学习,共享底层视觉特征,有效提升水稻叶片病害类型和病害程度判别的准确率;引入通道和空间注意力模型,对经典的Mobile Net V3网络模型进行改进,并构建基于特征金字塔的多任务深度卷积神经网络模型。此外,采用多种数据增强方法对数据集进行扩展,解决数据集中样本分布不均衡问题。试验结果表明,本文提出方法与传统方法相比,水稻病害识别平均准确率提升1%。(2)针对实际应用场景下水稻虫害图像标注样本不足导致水稻虫害图像识别准确率下降问题,提出一种基于迁移学习的水稻虫害识别方法。本文提出一种在少量标注样本前提下,利用语义特征一致性,将足量样本数据集下的特征表达向少量标注数据集迁移,从而在实际应用场景下仅需少量标注样本就能实现高精度的水稻叶片图像虫害类型识别;此外,本文构建一个具有挑战性的大规模水稻虫害数据集,并根据数据集特征进行数据增强,引入随机噪声、Mixup、Cutout等数据增强方法,使深度学习模型从更深的维度学习害虫判别力视觉特征;通过引入自注意力模型,对YOLOv7网络进行改进,并构建基于特征金字塔的多尺度神经网络模型,提升小个体害虫的识别精度。试验结果表明,本文提出方法比原模型识别精度提升1.6%。(3)针对传统卷积神经网络模型复杂度高难以部署在资源受限的移动计算环境问题,提出一种基于知识蒸馏的模型压缩方法。在实际应用场景下,传统的卷积神经网络需要消耗大量的计算和存储资源,而手机等移动计算环境下,计算、存储和电力资源均不能满足需求。本文提出利用模型压缩理论,将精度高的复杂神经网络模型向复杂度低的简单神经网络模型进行转化,从而使简单网络模型具备复杂模型的判别能力,但其消耗的资源大大降低。在此研究基础之上,建立一套面向移动计算环境的水稻病虫害预警系统,实现水稻病虫害远程自动诊断,对水稻病虫害早期预警和防治措施提供精准技术指导建议。综上所述,本文研究工作主要解决了实际应用场景下水稻病虫害灾害预警技术面临多尺度特征表达、知识迁移、模型精简等难题,实现水稻病虫害远程快速诊断,为农业领域病虫害早期防治提供技术参考,具有一定理论价值和较好的应用前景。
{URL}: https://link.cnki.net/doi/10.27883/d.cnki.gcqsx.2023.000336
{DOI}: 10.27883/d.cnki.gcqsx.2023.000336
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的行人检测算法研究
{Author}: 宋晓琳
{Tertiary Author}: 张洪刚
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 行人检测;深度学习;遮挡处理;端到端检测;无监督域自适应
{Abstract}: 行人检测是计算机视觉领域一个具有挑战性的任务,目标是准确识别待检测图像中的所有行人目标并给予精确定位,在智能监控、自动驾驶及机器人等领域都有着广泛的应用。随着深度学习技术的不断发展,近年来行人检测技术取得了突破性的进步。然而,考虑到实际应用的多样化需求,目前的行人检测技术仍然有着很大的提升空间。本文基于深度学习技术,研究了行人检测中的遮挡处理问题、抛弃启发式非极大值抑制(NMS)后处理的完全端到端检测问题,同时致力于实现算法精度、效率以及部署难度的平衡,主要创新贡献如下:(1)为了应对行人检测中的遮挡问题,本文提出了一个渐进式优化网络PRNet,采用渐进式的策略逐步检测出行人实例的全身边界框,包含了三个检测步骤:行人可见部分检测;对行人可见部分框进行初步校准以获取初始全身锚框;对初始全身锚框进一步修正以获取准确的行人全身框。另外,还提出了遮挡损失和感受野回传模块来辅助训练。为了进一步提升模型处理遮挡问题的综合能力,本文在PRNet的基础上提出了升级版算法PRNet++,采用双数据处理流结构,构造了一个简单分支和一个困难分支分别学习相互补充的鲁棒性特征,可以应对各种各样的遮挡情况。为了进一步探索跨域情况下的遮挡处理问题,本文引入了无监督域自适应遮挡行人检测任务。为了更好地处理陌生域数据中的遮挡情况,提出了动态迭代域自适应策略和多专家域自适应策略。本文进行了有监督库内评估实验、跨库测试实验以及无监督域自适应实验,充分验证了所提方法的有效性及优越性。(2)为了实现真正意义上的完全端到端行人检测,本文提出了基于最优候选区域学习的无NMS后处理端到端行人检测器。最优候选区域学习通过两个模块实现:由粗到细的学习策略通过渐进式的边界修正去探索最优的分类判定边界;完整候选区域建议网络为困难样本的召回提供额外的信息补偿。大量实验验证了提出的端到端行人检测器达到了先进水平。(3)为了应对实际应用中的任务扩展需求,本文建立了一个无NMS后处理的高性能端到端检测器,能出色处理行人检测任务的同时,也可以应对扩展的多类别检测需求。具体而言,本文提出了增强型正样本提取器,为每一个目标实例提取唯一一个正样本候选框,通过两个部件实现:双流特征增强模块为正样本选择提供丰富的信息线索;解耦最大池化过滤器增强潜在前景区域特征的可区分性。基于增强型正样本提取器的端到端检测器在行人检测和通用目标检测任务上都取得了优秀的性能。本文基于单阶段检测框架,针对遮挡处理问题和无NMS后处理的端到端检测问题提出了高性能的检测算法,推进了先进行人检测技术的发展,为实际应用中的行人检测技术部署提供了参考方案。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000251
{DOI}: 10.26969/d.cnki.gbydu.2023.000251
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度图超分辨率重建研究综述
{Author}: 赵利军;王可;张晋京;张加龙;王安红
{Author Address}: 太原科技大学电子信息工程学院;中北大学大数据学院;
{Journal}: 计算机应用研究
{Year}: 2023
{Volume}: 40
{Issue}: 06
{Pages}: 1621-1628+1640
{Keywords}: 超分辨率重建;深度学习;卷积神经网络;深度图
{Abstract}: 虽然高质量高分辨率的深度图能够显著地提高各种自然场景计算机视觉任务的性能，但是深度相机硬件的限制使得消费级深度相机拍摄到的深度图存在分辨率低、质量差和无效空洞等问题。深度图超分辨率重建(depth super-resolution reconstruction, DSR)是一种能有效提高深度图分辨率和质量的技术，并且DSR已经成为计算机视觉领域的研究热点。首先将介绍DSR的定义和近几年国内外DSR算法的研究进展，然后对深度学习DSR重建算法进行重点阐述与分析。接下来，将介绍深度图像质量评估准则。最后，对DSR的应用领域和未来所面对的挑战和机遇进行展望。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2022.10.0505
{DOI}: 10.19734/j.issn.1001-3695.2022.10.0505
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5s的手语识别算法研究
{Author}: 邢晋超
{Tertiary Author}: 潘广贞;岳鹏程
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手语识别;YOLOv5;K-means++;注意力机制;损失函数
{Abstract}: 手语是听障人士之间、听障人士与健全人士之间的主要沟通交流工具。在现实手语识别任务中,由于复杂的背景环境等因素的影响,导致检测难度增加,造成传统网络模型收敛不平稳,检测效率低等缺点。为解决健全人士与听障人士沟通交流困难的问题,同时为了弥补传统识别网络中存在的缺陷,本文提出了一种改进YOLOv5s网络模型的手语识别网络,对手语识别任务进行了相应研究,主要工作如下:(1)为解决当前手语识别任务对复杂背景目标特征提取不充分、准确率低下等问题,本文改进了CBAM(Convolution Block Attention Module)注意力机制的通道域,解决其因降维而造成的通道信息缺失问题,并通过实验证明将改进CBAM模块融合到YOLOv5s骨干网络中,可以最有效地增强检测对象的特征信息,使模型更加精准地定位和识别到关键的目标。(2)为解决手语手势定位偏差大和传统网络模型收敛不平稳的问题,本文首先应用K-means++算法提高了先验锚框的尺寸匹配度,确定了适合本文数据集的最优先验锚框尺寸,实现先验锚框与实际物体的精准匹配;其次,将Lovasz-Softmax Loss与YOLOv5s原本的损失函数Cross Entropy Loss加权结合使用,使得网络在模型训练过程中收敛的更加稳定,在准确率上也得到了一定的提升。(3)进行了基于改进YOLOv5s的手语识别实验。将注意力机制、锚框计算方法和损失函数这三部分的改进方法进行结合,实验结果表明,改进后网络模型的平均精度值(mean Average Precision,m AP)达到了97.67%,与原本的YOLOv5s模型相比,提升了3.17个百分点。其次,精准率(Precision,P)和召回率(Recall,R)也分别提升了3.44个百分点、1.89个百分点,有效地提高了手语识别网络的检测性能。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.001085
{DOI}: 10.27470/d.cnki.ghbgc.2023.001085
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的刨花板表面缺陷在线检测系统研究
{Author}: 赵子宇
{Tertiary Author}: 周玉成
{Publisher}: 山东建筑大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 刨花板;板材表面缺陷检测;刨花板缺陷辨识;机器视觉;生产线应用
{Abstract}: 刨花板作为绿色建筑可再生材料,是由天然木材、枝桠材或其他含木质纤维素的物质经过刨片、干燥、胶合、热压而成的人造板材。由于刨花板具有结构强度高、隔音效果好和耐冲击性强等特点,刨花板被广泛应用于建筑工业和建筑装饰装修等行业。随着绿色建筑、工业科技不断的发展,我国已成为世界上第一人造板生产及应用大国,年生产总量已达3.37亿m3,我国居家、办公场所90%以上都在使用人造板板式家具,并且需求量逐年增长。但因原料成分、配比和生产工艺等因素影响,导致刨花板表面出现缺陷,造成板材结构强度下降、后续贴面困难等,带有缺陷的刨花板无法应用到建筑工业中。截止到目前,刨花板生产已由半机械化转向大型自动化生产,58%以上都是由连续平压生产线生产,但国内外刨花板表面缺陷检测依然处于人工肉眼观察检测阶段,板材在检板线上高速连续运行,肉眼检测无法准确辨别缺陷尺寸,极易导致分等失误。同时,长时间观察检测,人工极易疲劳,导致漏检率极高。其次,由于个体检测人员对表面缺陷检测判定尺度的不一致性,无法保证统一的缺陷辨识标准,从而无法保证缺陷辨识的准确率,经常出现漏检和误检现象。综上,人工观察检测无法满足快速高效、产量巨大的生产线要求,寻求机器智能表面缺陷检测就成为人造板行业面临亟需要解决的问题。针对以上问题,本课题研发了一款高效、快速的刨花板表面缺陷检测设备,并在企业现场投入使用,实现刨花板产业的全自动化、智能化生产,缓解国内外刨花板缺陷检测领域的窘迫困境。本文充分阐述了研发的检测系统组成、缺陷检测算法的实现原理,实现缺陷快速实时高效检测、小目标缺陷区域快速定位及缺陷分割,旨在提高刨花板表面缺陷检测算法的准确性与实时性。本文研究内容和创新点如下:1、设计并开发刨花板表面缺陷检测设备并建立刨花板表面缺陷数据集本文设计并开发一款刨花板表面缺陷检测设备（Piercing Eye II）,设备具有占地面积小、辨识准确率高、检测速度快等特点,并依靠自主研发的缺陷检测算法,成功应用在江苏汇丰木业集团刨花板生产线的检板线上。同时,为了促进不同场景下刨花板表面缺陷识别研究,本研究建立首个刨花板表面缺陷数据集,该数据集具有规模较大、种类最全等特点,能够满足所有分类、目标检测和语义分割等算法的应用,依靠该数据集能够精确衡量刨花板表面缺陷检测算法的性能。2、提出刨花板轻量型辨识模型（PBoard LIDNet）为解决现有神经网络算法中检测小目标物体不精确、模型内存占用较大等问题,提出刨花板轻量型辨识模型（PBoard LIDNet）,应用于刨花板表面缺陷自动辨识。算法模型具有精度高、参数量小和低延时等特性,完全符合轻量化机器视觉设计需求。为提升模型精度,提出一种轻量、高效的ELAM注意机制模块,保留缺陷信息,抑制干扰信息,有效提升检测精度。同时,本文提出一种PDCM非对称卷积模块,该模块能够取代常规标准卷积模块,不会对模型训练带来任何负担,使模型取得显著增益效果,增强模型对表面缺陷的表征学习能力。此外,本文提出PBLI-Standard模块、浅层PBLIDissymmetric模块、深层PBLI-Dissymmetric模块和PBLI-Concise模块,4种模块满足轻量型深度神经网络设计,避免大量计算开销,并通过对浅层和深层网络的不同设计,使其能够捕获到更精准的缺陷信息,提升模型检测精度。经试验表明,PBoard LIDNet对刨花板表面缺陷的识别精度为98.36%,模型参数仅为1.57M,均优于现有卷积神经网络的检测精度及参数量。3、提出刨花板表面缺陷快速检测模型（PB-FRTD）为提升缺陷检测的实时性,本文提出刨花板表面缺陷快速检测模型（PB-FRTD）,该模型具有高效、轻量级、高实时性的特点,较现有目标检测模型相比,参数量、运算速度及计算成本降低,满足模型在检测设备上的部署,并符合刨花板表面缺陷检测高精度要求,同时保证高实时性的特点。为提升模型对缺陷特征的提取能力,本文提出PBLI-LV、AC-PBLI-LV轻量化系列架构、Li SPP模块,实现轻量化模块设计,通过由浅层到深层提取特征网络设计,采用多尺度特性融合方式,避免模型性能退化,提升模型检测精度,同时,节省模型运算成本。PB-FRTD对刨花板表面缺陷的识别精度为98.00%,辨识每张刨花板图像的测试时间仅需23ms。4、提出刨花板表面缺陷快速分割模型（PB-FRTD-Li Seg）针对检测小目标缺陷与长宽比差异较大缺陷精度降低问题,本文提出刨花板表面缺陷快速分割模型（PB-FRTD-Li Seg）,模型针对表面缺陷特点,捕捉更精确的缺陷信息,能够满足更精确、高效的检测要求。同时,为实现小目标表面缺陷检测,提出LKSCM轻量化架构、DSDD卷积和LWPooling检测架构,多尺度提取不同尺寸、形状的表面缺陷,提高模型训练性能、效率、精度。此外,提出一种FCIM融合模块,将浅层与深层特征结合,提升缺陷特征的表示能力,精准获取刨花板表面缺陷的细节特征,为检测小目标缺陷提供一种有效的检测方法。5、检测设备落地应用本研究开发的Piercing Eye II型刨花板表面缺陷检测系统已在江苏汇丰木业集团生产线上应用,实际现场应用结果表明,采用上述三种检测模型的算法辨识时间分别为42ms、27ms和36ms,板材检测准确率为97.14%、98.40%和98.86%,完全满足刨花板表面缺陷在线检测的高精度、高实时性需求。综上所述,本文研发的刨花板表面缺陷在线检测识别系统,具有高效、快速、操作方便等特点。通过构建刨花板表面缺陷检测的深度学习模型,能够有效实现刨花板表面缺陷目标的自动检测和识别,提高系统的实时性和可靠性,降低算法复杂度。系统提高生产线自动化运行效率,降低板面缺陷对企业造成的经济损失,本文研究结果为刨花板表面缺陷检测识别领域奠定理论基础,为推动国内外刨花板产业现代化发展、应用做出贡献。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2023.000002
{DOI}: 10.27273/d.cnki.gsajc.2023.000002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于单目视觉的三维目标检测技术研究
{Author}: 胡贺南
{Tertiary Author}: 朱明
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 单目视觉;深度估计;三维目标检测
{Abstract}: 三维目标检测技术是数字图像处理领域的关键问题,在军事、工业等领域有着广阔的应用前景。深度学习是一个复杂的机器学习算法,通过对样本数据的内在规律进行学习,获取样本的深层次特征,进而更好的完成对样本的解释。近几年来,得益于基于点云和双目视觉的三维检测算法的发展,三维目标检测结果的精度得到显著的提高。然而,点云需要昂贵的激光雷达设备获取,双目成像设备的架设场景要求较高,且在工业应用方面,成本较高。因此,如何利用图像信息挖掘的优势,将现有基于单目视觉的三维目标检测算法改进,使其性能上能够与基于激光雷达和双目的三维目标检测算法媲美具有重要的意义。所以,开展基于单目视觉的三维目标检测技术的研究具有很强的学术意义和实用价值。本论文在对基于单目视觉的三维目标检测关键技术进行分析的基础上,分别对单目深度估计算法,基于单目图像目标深度优化算法,伪点云三维目标检测算法以及全景单目三维目标检测算法等关键技术进行了研究。本论文主要完成了以下四个方面的工作:1.深入研究单目深度估计方法,针对像素级深度估计任务中卷积神经网络和视觉Transformer作为主干网络分别缺失对全局信息和局部纹理信息表征的问题,提出了一种联合卷积神经网络和视觉Transformer的深度回归方法。通过重新构建卷积层的构成并在卷积模块后添加Transformer模块来构建编码器,编码器负责提取多尺度的图像局部和全局特征。采用多尺度卷积神经网络作为解码器对融合特征进行稠密化像素级深度回归。本方法利用视觉Transformer建模多尺度卷积特征的全局相关性,提高了深度估计预测的精度。2.深入研究了基于单目视觉的三维目标检测方法,针对单目三维目标检测精度的限制主要来自深度估计中前景目标位置误差的问题,提出了一种联合实例分割与几何约束的目标深度优化方法。重新设计了基于中心点回归的视觉实例分割模型获取目标三维高度分布。采用基于相机成像原理的深度分布计算,联合深度估计方法优化不同距离位置的目标深度,采用不确定度学习的方式对待检测目标深度进行优化,提高了深度估计方法对于不同位置的目标深度估计的准确度。3.深入探究了通过激光雷达获取的点云和由图像生成的伪点云对基于点云算法的影响。针对伪点云分布的长尾问题,提出了一种基于目标伪点云分布优化的单目三维目标检测方法。首先编码器通过整合Point Net++的点集抽象模块和Transformer模块为特征增加全局一致性。接下来使用带有多尺度特征级监督的解码器对伪点云进行重分布调整,完成伪点云分布的优化。本方法进一步采用基于点云的三维目标检测方法于伪点云数据上进行三维目标检测。实验表明该方法大幅提高了单目三维目标检测的精度。4.深入研究了基于全景图像的单目三维目标检测算法。针对从二维图像生成俯视图特征不准确以及缺失时域关联的问题,提出了一种基于长短时域特征融合和运动特征蒸馏的全景单目三维目标检测方法。分别利用不同的特征分辨率提取长短程的时域特征,利用基于Transformer交叉互相关模块的编码器将运动特征和深度信息联合编码并整合到融合长短时域的俯视图特征中,后续使用带有运动特征蒸馏技术的解码器完成空间三维定位。该方法融合了不同时间步长的全景目标特征表达,辅以嵌入的运动特征和深度信息,提高全景单目三维目标检测的精度。实验表明该方法能够提高全景单目视觉三维目标检测精度。本论文针对现阶段基于单目视觉的三维目标检测关键技术中存在的不足,分别从提高单目深度估计的精度、通过实例分割和几何约束优化前景目标深度,伪点云分布优化,以及在全景图像中引入长短时域信息和运动特征等方面,提出了多种提高基于单目视觉三维目标检测任务性能的算法。同时,对每个提出的算法进行了大量的仿真实验验证。本论文的研究成果对提高现阶段基于单目视觉的三维目标检测的精确度和稳定性,拓宽单目视觉三维目标检测的应用领域具有重要的理论意义和参考价值。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2023.000017
{DOI}: 10.27522/d.cnki.gkcgs.2023.000017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自动驾驶场景下基于深度神经网络的三维目标检测方法研究
{Author}: 李晓伟
{Tertiary Author}: 孔德明
{Publisher}: 燕山大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 自动驾驶;环境感知;深度神经网络;三维目标检测;激光雷达点云
{Abstract}: 高精度的环境感知是自动驾驶汽车安全行驶的前提。作为环境感知中的关键任务,三维目标检测在近几年受到广泛关注,它从自动驾驶汽车上多种传感器获取的环境信息中感知周围目标的位置、尺寸和运动方向等信息,为行驶提供重要的决策依据。近几年三维传感技术不断发展,环境感知的主要媒介逐渐从二维图像数据扩展到以点云为代表的三维数据,为三维目标检测研究提供了数据基础。随着深度学习技术的蓬勃发展,基于卷积和Transformer结构的深度神经网络在学术界和工业界取得了广泛的成功,为三维目标检测研究提供了新的思路和方法。基于此,本论文以激光雷达点云和图像为主要输入数据,基于深度神经网络,对自动驾驶场景下的三维目标检测任务开展研究,具体研究工作如下。首先,对基于卷积神经网络的点云三维目标检测开展研究。针对该类网络中的关键点信息损失和原始点云信息浪费问题,设计局部特征增强模块,丰富关键点的局部几何信息,增强关键点的局部表征能力;此外,还设计了关键点权重增强模块,引入丰富的原始点云信息,增强关键点权重的学习过程。在此基础上,构建局部特征增强和关键点权重增强的点体素区域卷积神经网络。KITTI数据集上的实验结果表明,该网络提升了点云三维目标检测网络PV-RCNN的检测精度。其次,引入图像像素数据,对基于卷积神经网络的多模态三维目标检测开展研究。针对该类网络速度慢和多模态特征难以准确对齐的问题,设计一种多模态数据处理方法,提升处理速度,降低映射对齐难度。在此基础上,针对多模态信息利用不完全和特征融合粗糙的问题,提出多尺度和多模态特征提取和融合网络,全面提取多模态特征,并进行精细的特征融合;此外,还设计了一项学习任务,获取有效的目标识别信息。基于此,构建稀疏表征输入多尺度和多模态融合区域卷积神经网络。KITTI数据集上的实验表明,该网络平衡了多模态三维目标检测网络的精度和速度,优于同期的深度融合三维目标检测网络。再次,引入图像伪点云数据,继续对基于卷积神经网络的多模态三维目标检测开展研究。针对伪点云特征提取粗糙和感兴趣区域表征能力差的问题,提出细粒度注意力卷积,对伪点云进行精细的特征提取;此外,还提出自适应组稀疏卷积,将感兴趣区域的特征分组,并进行差异化学习,获得多尺度信息,增强感兴趣区域特征的表征能力。在此基础上,构建自适应区域卷积神经网络。KITTI数据集上的实验表明,该网络有效改善了同类网络的缺陷,在同期网络中取得了较先进的检测水平。最后,对基于Transformer神经网络的三维目标检测开展研究。针对Transformer应用于点云数据时感受野受限的问题,设计一种混合采样策略,获取和点云分布相适应的交叉体素集;以交叉体素集作为自注意力计算的基本单元,提出分散局部注意力计算方法,增大点云体素的感受野。在此基础上,构建交叉体素集—体素Transformer。KITTI数据集上的实验表明,将该神经网络结构整合进现有三维目标检测网络后,整合后的网络检测性能均有提升。
{URL}: https://link.cnki.net/doi/10.27440/d.cnki.gysdu.2023.000043
{DOI}: 10.27440/d.cnki.gysdu.2023.000043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像处理的棉花幼苗期杂草识别方法研究
{Author}: 彭明霞
{Tertiary Author}: 夏俊芳
{Publisher}: 华中农业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 变量喷药;棉田杂草识别;Faster R-CNN;YOLO;StyleGAN;Swin Transformer
{Abstract}: 棉花是我国重要的经济作物,而我国棉田杂草危害较重,在当前大量采用化学除草的情况下,形成了对土壤、地下水和大气的污染。出于对减少化学除草剂用量的考虑,一个主流的技术方向是使用变量喷药系统。完整的变量喷药系统由图像采集系统、人机交互系统、核心控制系统和喷药机构几个部分组成。利用图像处理技术定位杂草的种类与数量是整个变量喷药系统的首要条件,杂草识别的正确率将影响整个系统的实用性。本文针对幼苗期的棉田杂草识别算法展开研究,主要包括传统算法、基于卷积神经网络的目标检测算法、基于Swin Transformer的目标分割算法,并使用GAN网络解决目标检测与分割算法中的样本不均衡问题,最后开发了一个模拟喷药系统进行算法有效性的验证。主要研究如下:(1)对传统的棉田杂草识别算法进行了研究,从图像预处理、分割、特征提取和分类4个角度详细总结了目前基于图像处理技术进行杂草识别的研究进展。在图像预处理技术中,试验了中值滤波等成熟的算法。在图像分割技术中,首先用颜色和OTSU算法进行前后背景的分割,然后进行区域分割得到独立的植株区域。在区域分割算法中,首先建立了轮廓层级的概念,然后使用区域生长法从单个像素出发,通过像素点的逐步迭代合并最终形成所需要的分割区域。在特征提取技术中,使用Hu矩对叶片的形状特征进行了提取并用于分类识别。在分类识别技术中,使用K均值聚类分析算法对提取到的Hu矩特征进行分类。(2)在杂草识别中引入Faster R-CNN和YOLO两种典型的卷积神经网络,进行棉花和杂草的目标检测。他们分别代表了卷积神经网络中两阶段与单阶段的典型算法。最后通过试验调优确定了最适用于棉田杂草识别的模型参数,给出了试验结果并分析了得到此结果的原因。在Faster R-CNN算法中,待识别对象分为棉花和杂草两类,建立Res Net50网络模型从原始图像中提取棉花和杂草特征。该模型不依赖于图像预处理,通过学习自主提取棉花和杂草的特征表达更准确地反映出棉花与杂草图像的有效识别信息。在测试中平均目标识别准确率为95.5%。测试模型的结果表明,使用CPU识别一帧图像仅需1.51s,使用GPU识别一帧图像的平均耗时为0.09 s。在YOLO算法中,对杂草的类型进行了扩充,从简单的棉花和杂草两个类别扩展到棉花和8个杂草类别。对YOLO模型的网络结构进行了分析,对训练参数进行了优化,在测试中取得了98.8%的平均正确率。(3)为了得到更精确的棉花与杂草植株的位置信息,对图像分割的相关算法进行了分析。引入Swin Transformer算法,分析其特点并建立了一个用于杂草检测的网络模型。由于在实际的棉田杂草识别喷药系统中,喷药过程不但需要知道杂草的种类以及位置,精准喷药还需要知道杂草的密度以及大小,从而控制喷药量。在满足应用需求的前提下,本文使用Mask RCNN与Cascade RCNN这两种经典的目标检测头,并比较了这两种检测头在棉田杂草识别中的使用效果。在训练完成后,使用测试集对训练的模型进行测试。当Io U=0.5时,Mask RCNN的平均正确率为71.47%,cascade＿mask＿rcnn的平均正确率为73.5%。说明通过级联结构,Cascade RCNN避免了单个模块检测网络设置阈值时的矛盾,提高了目标检测的准确率。(4)针对目标检测与图像分割过程中杂草的识别率较低的问题,经过分析后发现杂草图像训练样本表现为长尾类分布,各类植株的样本分布不平衡。正是这种训练样本数量的类不平衡,使得训练后的模型容易偏向训练数据量大的棉花类,导致模型在数据量有限的杂草类上表现不佳。为此构建了StyleGAN网络进行样本的扩充以解决样本不均衡问题,并使用扩充后的样本库对Faster R-CNN网络及Swin Transformer网络进行训练并比较扩充前后的识别效果。使用StyleGAN生成的棉花与杂草图片,扩充模型的训练样本,将训练样本数由3 000扩充到5 000,验证集与测试集的样本数量不变。使用扩充后的图片集对Faster R-CNN网络进行训练,杂草检测的平均精度由93.5%提高到了97%,与棉花接近同一水平,平均精度提高了4%,棉花的平均召回率与平均准确率略有下降,由97.5%下降到了97.3%,平均正确率由95.5%上升到了97.1%,上升了1.7%。使用StyleGAN生成的棉花与杂草图片,扩充Swin Transformer模型的训练样本,使用Mask RCNN检测头时的平均正确率由71.47%上升到82.5%,使用cascade＿mask＿rcnn检测头时的平均正确率由73.5%上升为83.2%。(5)为了验证算法的实时性与有效性,模拟真实的变量喷药系统,开发了一套模拟变量喷药软件,构造了一个可以实时识别杂草并模拟喷药的试验环境,在试验田进行了棉田杂草识别的测试,经过20分钟15秒的测试,对视频中的1214帧图像进行了识别,平均每帧耗时420毫秒,喷头动作的正确率达到89.5%。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2023.000108
{DOI}: 10.27158/d.cnki.ghznu.2023.000108
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的目标检测技术研究
{Author}: 汪李超
{Tertiary Author}: 夏长权;王茂祥
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;YOLOv5;注意力机制;轻量化目标检测;树莓派
{Abstract}: 基于深度学习的目标检测技术已经被广泛应用于交通车辆检测领域。这项技术有助于构建智能化的交通实时监测系统。然而现有的目标检测模型存在计算量大、对小目标检测精度低等问题,限制了其在实际中的应用。为此,本文在现有的基于YOLOv5的目标检测模型基础上进行改进设计,增强其对小目标检测的准确性,并实现模型的轻量化,最后将改进的模型部署到边缘设备中进行硬件实验验证。主要研究内容如下:(1)以YOLOv5目标检测模型中的YOLOv5s为基础,针对部分小目标及不明显目标的检测精度不足的问题,在YOLOv5s模型的主干部分引入卷积注意力机制模块(Convolutional Block Attention Module,CBAM),并进一步改进模型的特征融合部分,引入加权双向特征金字塔网络(Bidirectional Feature Pyramid Network,BiFPN),使模型在训练时融合更多有意义的语义信息和位置信息。将改进后的模型与原有模型在相同的数据集进行训练对比,结果表明经过改进后的模型的相关评价指标优于原有模型,且在部分小目标识别上更加精确,模型的检测精度和泛化能力得到了提升。(2)针对现有目标检测模型计算成本高、计算量大的问题,将YOLOv5s模型中的主干网络替换为轻量化目标检测模型ShuffleNet-V2中的反向残差模块,并对融合后的网络进一步改进激活函数、引入压缩激励网络和修改Focus模块等,得到了新型的融合目标检测模型。在同等实验条件下对相关模型进行了对比研究,结果表明经过本文改进的模型在几乎不损失检测精度的同时可以有效的降低模型的计算量、减小模型的大小,实现了轻量化的高精度目标检测模型。(3)将本文改进后的轻量化模型部署至移动端,选取树莓派作为移动边缘设备,在树莓派中安装相关软件系统搭建了深度学习框架,并使用OpenVINO推理框架和NCS2英特尔二代神经计算棒辅助模型进行推理加速。经过测试,树莓派端的目标检测结果展现了较好的检测效果和实时性。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2023.001655
{DOI}: 10.27441/d.cnki.gyzdu.2023.001655
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的跌倒检测算法研究
{Author}: 马双双
{Tertiary Author}: 曹少中;王佳;王大亮
{Publisher}: 北京印刷学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 跌倒检测;YOLOv7;OpenPose;SVM;关键点补齐
{Abstract}: 现如今,跌倒事件在日常生活中频频发生,跌倒造成的伤害和安全隐患众多,跌倒检测成为一项具有重要意义的研究。如果在跌倒事件发生时能及时做出反应,就可以减少跌倒造成的伤害。因此,本文提出一种基于深度学习的跌倒检测算法,主要研究内容如下所述。(1)由于跌倒动作与躺下动作特征极为相似,而目前公开数据集中缺少躺下行为的数据。本研究建立了监控视角下的人体动作数据集,主要包含跌倒、躺下、蹲下、坐下,并建立肢体遮挡的图像数据。本文采用空间维度与时间维度相结合的跌倒判定策略。通过提取人体宽高比、人体倾斜角、头部中心点速度、质心速度等,提出多特征融合策略判定跌倒行为,空间维度的形状特征用于区分跌倒、蹲下以及坐下等日常行为,时间维度的运动特征用于区分跌倒和躺下。在自建数据集上进行了大量实验分析,证明本文提出的跌倒特征可以有效区分跌倒和日常行为。(2)针对运动过程中肢体存在遮挡的情况,对存在肢体遮挡的图像进行讨论,提出一种基于对称的人体关键点补齐方法。通过OpenPose输出的关键点位置信息,排查出缺失的人体关键点,以人体中心线为对称轴,利用对称关键点得出缺失关键点的位置信息并进行补齐。针对该算法提出一种评价指标ADV,利用真实关键点坐标与补齐关键点坐标的距离的方差来评价该算法(3)本文构建一种多特征参数的跌倒检测方法,首先对视频序列进行目标检测,对YOLOv7进行改进,将YOLOv7中主干提取网络的E-ELAN层改进加入SE模块,使用SIoU替代原边框回归损失函数,改进模型的mAP@0.5提升1.45个百分点,召回率Recall提升1.11个百分点;采用OpenPose对人体进行姿态估计,获取跌倒特征信息,使用分类器处理视频的序列信息,有效区分跌倒行为和日常行为。实验结果证明算法在自建数据集上准确率可达到94.8%,在公开数据集Le2i上准确率可以达到95.6%,可以满足跌倒检测的基本要求。
{URL}: https://link.cnki.net/doi/10.26968/d.cnki.gbjyc.2023.000103
{DOI}: 10.26968/d.cnki.gbjyc.2023.000103
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的智能建造中3D目标检测研究
{Author}: 王永归
{Tertiary Author}: 李健
{Publisher}: 陕西科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;智能建造;单目3D目标检测;Transformer模型;多尺度特征
{Abstract}: 目标检测技术在计算机视觉中扮演关键角色,能够识别图像中的目标位置和类别,并广泛应用于无人驾驶、智慧交通、智能建造和智能制造等领域。然而,目前智能建造中的目标检测技术仅限于2D目标检测,而无人施工、碰撞检测和施工人员安全检测等应用需要获取目标的三维位置信息。此外,现有的计算机视觉任务仅提供局部视觉理解,并且对计算机视觉检测结果缺乏统一管理,导致智能建造过程中缺乏全局视觉理解和智能施工应用,造成数据资源的浪费。为了解决以上问题,本文基于计算机视觉任务,通过深入分析建筑工程智能建造的需求,结合场景图任务、目标检测、图像分割和三维重建等计算机视觉任务,提出了构建面向施工场地的室外3D动态场景图的方法。重点研究单目3D目标检测算法,并将其应用于智能建造领域。具体研究内容包括以下几个方面:（1）面向智能建造的室外3D动态场景图及其构建。针对目前在智能建造中室外建筑工程下的3D场景理解模型十分匮乏的问题,本文遵循3D场景图范式,基于不同任务类别以及抽象层次的网络模型,构建了一种面向智能建造的室外可操作空间感知统一表示:室外3D动态场景图（ODSG）。ODSG将室外施工场地划分为不同层次与细粒度的统一表示,并对其空间关系建模,在对施工场地数据统一化管理的同时,能够适应不同类型的施工任务,并且本文通过仿真与实验结果验证了该模型的有效性。（2）基于多尺度金字塔特征融合网络的单目3D目标检测。目标尺度差异性大是单目3D目标检测面临的重要挑战,通常解决目标尺度差异性大的方法是多尺度特征融合。然而,目前大多数多尺度特征融合方法使用单一尺度上下采样的金字塔网络融合不同尺度特征,忽略了特征图中噪声影响与特征融合的不平滑现象,并未充分利用多尺度特征图中的特征信息。针对上述问题,本文设计了一种多尺度金字塔特征融合网络,该网络由改进的DLA34与多尺度金字塔网络构成,能够实现多尺度特征的平滑与充分融合,同时减少噪声对后续特征融合的影响。在KITTI开源数据集上的实验结果表明:与其他基于多尺度融合的方法相比,本文所提出的方法在简单、中等与困难检测级别下的3D检测与BEV检测平均精度均达到最优。（3）融合深度与显著信息的DETR3D目标检测方法研究。基于深度和显著信息的单目3D Transformer目标方法研究。现有的单目3D目标检测算法大多结合几何关系与卷积神经网络预测目标三维属性,缺乏深度特征信息与特征全局关系。针对这些问题,设计了一种融合深度和显著信息的DETR（Detection TRansformer）单目3D目标检测算法,构建轻量型的无监督深度模块提取目标深度特征信息,并引入Transformer模型获取特征全局关系。另外,针对算法中Transformer模型计算成本高的问题,设计了一种显著网络用于降低Transformer编码器的计算量。在KITTI官方数据集中的实验结果表明,与当前其他先进的检测算法相比,所提算法在检测精度上多个指标达到最优,并通过消融实验证明了该算法中各个模块的有效性。综上所述,本文通过施工场景数据集的仿真实验结果和KITTI开源数据集上的实验结果,验证了本文所提出的ODSG模型与两种单目3D目标检测方法的有效性。
{URL}: https://link.cnki.net/doi/10.27290/d.cnki.gxbqc.2023.000291
{DOI}: 10.27290/d.cnki.gxbqc.2023.000291
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的水果识别与分割技术研究
{Author}: 郑浩
{Tertiary Author}: 王国珲
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;Transformer;卷积神经网络;水果;识别与分割
{Abstract}: 随着我国水果种植的面积不断扩大,产量不断提升,水果生产过程所需劳动力日益增加。目前水果作业环节主要依靠人工完成,人工作业存在费时、费力、主观因素强、易出错等问题。近年来,基于深度学习的水果识别与分割技术进入了崭新的时代,在一定程度上解决了传统方法的不足,但依然存在识别效率低、鲁棒性差等问题,难以实现工程化应用。针对上述问题,本文对深度学习网络进行深度剖析,对水果识别与分割算法展开研究,改进了不同任务下的网络模型,以达到更佳的水果识别与分割性能。主要研究工作如下:(1)由于一些传统目标检测算法的模型参数量较大,导致模型训练时间开销大、检测速度较慢。同时,传统检测算法对小目标的果实检测精度不高,并在不同干扰条件下(如枝叶遮挡、果实重叠和光照强度变化等)欠缺鲁棒性。为此,本文选用YOLOX算法为基准网络,将其主干特征提取网络替换为Dense Net网络,以加强特征的重用并降低网络的计算量,再结合注意力机制策略来加强深度特征融合。对比实验表明所提出的YOLOXDense-CT方法能实现更高检测精度、更快的检测速度和更强的鲁棒性。(2)基于传统机器学习的水果分类算法主要提取单一特征,提取的特征输入到机器学习算法实现分类,但一般分类效率较低。此外,基于卷积神经网络的分类模型虽然取得了较好的分类性能,但是更高的准确率需要耗费大量训练时间开销,并且对全局信息的建模具有局限性。针对以上问题,本文对Vision Transformer和Swin Transformer网络展开研究,直接用预训练Transformer模型提取深度特征,再将特征输入到选用的分类器中进行识别。所提的基于Transformer网络和支持向量机、多层感知器的分类方法在较低时间开销下依然取得了更高精度。不同实验的结果表明所提出的方法在多个指标下都优于传统方法。(3)针对传统分割算法存在泛化能力差、分割效率低问题,本文以Mask R-CNN为水果分割任务的基准网络,选用Res Net-50网络为主干特征提取网络。本文将Res Net-50中的部分传统卷积替换为可变形卷积,以适应形态各异的水果目标,并修改特征提取网络的层数,以加强特征的提取。实验结果表明所改进的分割模型取得了更好的泛化能力和更高的分割精度。通过上述研究,不仅有效地解决了现有水果检测、分类和分割算法存在的不足,提高了水果识别与分割算法的整体性能。对开发具有识别与分割功能的水果作业机器人提供了理论参考,同时对推动水果产业智能化方向发展有着重要意义。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000332
{DOI}: 10.27391/d.cnki.gxagu.2023.000332
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态图像融合的目标识别算法研究
{Author}: 刘珂琪
{Tertiary Author}: 董绵绵
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多模态图像;行人目标识别;多阶段特征融合;光照感知权重融合模块
{Abstract}: 近年来,随着现代社会迅速发展,信息呈现出多样化、复杂化的特点,目标识别技术作为计算机视觉领域的一个重要研究方向受到越来越多的重视,在智能驾驶、视频监控、遥感等诸多领域得到极大发展和应用。其中,在智能驾驶方面,由于城市道路环境的复杂性,有效识别行人目标是保障智能驾驶安全性的重要一环。传统的行人目标识别方法仅利用可见光单模态图像特征完成,导致目标识别在全天候条件下目标识别性能低下。由于红外模态与可见光模态之间具有互补特性,目前提出了以多模态图像融合为思想的目标识别算法。但现有算法存在未考虑不同光照条件、不同模态之间的差异性等问题,因此,如何有效的结合这两种模态之间的特征信息,提高目标的识别准确率,已成为当前研究的热点与重点。本文主要针对可见光模态与红外模态两种不同模态进行基于多模态图像融合的目标识别算法研究,主要研究内容如下:针对单一模态下的行人目标识别算法在全天候场景下识别性能较差、现有的多模态图像融合方法仅在某一阶段进行融合导致其他阶段特征浪费的问题,提出了一种基于多模态多阶段图像融合的行人目标识别算法。该算法以SSD算法作为基本的检测识别框架,并将其扩展到双流,采用直接堆叠的融合策略对两种模态特征进行融合,比较与分析单阶段和多阶段两种不同特征融合方式。通过实验证明,多阶段特征融合方式为最佳的融合方式。另外,多模态行人目标识别性能与单模态条件下相比更具优势。针对现有基于多模态图像融合的目标识别未考虑到不同光照条件下不同模态对融合特征的生成所占比例不相同的问题,提出了一种基于光照感知权重融合的多模态行人目标识别算法。该算法先将可见光特征与红外特征经过ECA注意力机制模块,以增强特征表示;然后,在此基础上,将特征送入到所设计的基于小型神经网络的光照感知权重融合模块中,学习获取不同模态所对应的权重,解决了现有光照加权对不同模态的特征按照1:1的方式进行堆叠的问题;最后,将获取到的权重与其相应的特征进行加权融合,生成融合特征,并将这些特征送入行人检测识别网络,完成识别。通过实验证明,该融合策略能够在一定程度上提升行人目标的识别性能。针对现有多模态特征融合模块将生成的融合模块直接用于行人识别网络,存在不同模态之间差异性较大、交互性不够的问题,提出了一种基于多模态特征互指导的行人目标识别算法。首先,通过将生成的可见光特征与红外特征送入到差异特征感知融合模块中缩小两种不同模态之间的差异性,并生成融合特征;然后,将融合特征再返回到可见光与红外特征流中,使下一阶段生成的可见光与红外特征具有更丰富的信息;除此之外,还将融合特征作用于下一阶段的融合特征,增强融合特征的表征能力;最后,将最后一阶段的可见光特征、红外特征及融合特征均送入到识别网络中进行行人目标识别。通过实验证明,该算法进一步提升了目标的识别性能,并增强了模型的鲁棒性能。本文基于特征级融合方式研究可见光与红外两种模态融合下的目标识别算法,通过KAIST数据集对算法进行性能验证的同时,在LLVIP据集、M3FD数据集上也进行泛化性能验证,在一定程度上表明算法在实际场景的可行性,具有一定的理论研究意义。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000115
{DOI}: 10.27391/d.cnki.gxagu.2023.000115
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的机械臂工件自主抓取研究
{Author}: 孙万林
{Tertiary Author}: 陈立平
{Publisher}: 塔里木大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机械臂;单目视觉;位姿估计;HSV;RRT;目标抓取
{Abstract}: 近年来,我国陆续颁布了多项有关工业智能制造的政策,智能制造旨在将信息技术和工业制造相融合,这是我国制造业发展和变革的重要方向。机器视觉和机械臂抓取技术在工业自动化领域应用广泛,提高了制造业的生产效率和智能化水平。但是复杂的自动化生产环境、作业工件摆放位置的不确定性却很大程度上限制了自动化生产的效率。目前在工业生产制造过程中,工业机械臂是按照固定的代码指令和特定的抓取路径工作,同时作业工件也是在固定位置按照特定位姿进行放置。如果工作环境或者工件位姿改变,机械臂将无法成功实现抓取,导致生产任务中断甚至失败。机器视觉具有信息传递实时性好、观测范围广、检测精度高等优点,被广泛应用于智能制造过程中。机器视觉与机械臂结合,赋予机械臂更好的协调性与灵活性,使机械臂更加智能化。因此,本文将以单目视觉引导的目标姿态估计、机械臂路径规划、任意位姿工件抓取为切入点,设计一个多目标静态背景下,目标工件姿态估计与机械臂智能化自主抓取系统。本论文主要研究如下:(1)为获取作业目标的空间位置信息,将其三维坐标作为机械臂抓取策略的输入,本文分析了单目相机的模型与成像原理、坐标系之间的转换关系;并使用MATLAB的单目相机标定工具箱对相机进行标定,确定相机传感器的参数,为后续的目标定位做好准备;(2)为获取机械臂的DH参数,分析了机械臂的连杆关系;参照连杆关系并根据机械臂实体,建立了机械臂的DH模型,确定了机械臂的连杆参数,并在此基础上完成了机械臂的正逆运动学分析和工作空间的求取;(3)为实现机械臂对任意摆放的工件的抓取,提出了一种基于位姿角的末端机械手抓取策略方法。运用HSV色彩空间分割算法和图像处理算法,求取物体外接矩形中心点的像素坐标;求解工件最小外接矩形的长边与图像坐标系横坐标的夹角θ,结合目标的坐标信息,作为机械臂抓取策略的输入,完成机械臂的自主抓取;(4)为了保证关节运动的平稳性和提高机械臂的抓取效率,分别研究了三次、五次多项式插值、直线插补、圆弧插补和RRT算法对机械臂运动平稳性的影响,实验结果表明五次多项式插值和RRT算法下的机械臂角位移和角速度曲线是平滑的,满足机械臂运动稳定性的要求;本文使用MATLAB和Move It对机械臂进行仿真实验,观察机械臂各关节的运动情况。同时进行实体机械臂的抓取实验,并进行实验分析,结果表明本文算法有效地实现了机械臂自主抓取。
{URL}: https://link.cnki.net/doi/10.27708/d.cnki.gtlmd.2023.000075
{DOI}: 10.27708/d.cnki.gtlmd.2023.000075
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的吸烟场景目标检测算法研究
{Author}: 王超平
{Tertiary Author}: 刘海英
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;吸烟检测;YOLOv5
{Abstract}: 因吸烟会产生火灾隐患,给社会及个人造成不可估量的损失,所以在加油站、生产车间、林业防护区等特殊场所均已明令禁烟。随着科技水平的不断发展,自动化吸烟检测系统已经可以代替人工监测并控制吸烟行为。目前常用的自动化吸烟检测系统可分为基于烟雾的检测、基于吸烟手势识别的检测和基于烟支的检测。在室外或通风性良好的室内环境下,基于烟雾的吸烟检测系统精度较低。由于个体差异和姿态变化等因素,基于吸烟手势识别的检测对不同个体的检测能力较低。而基于烟支的检测又可分为基于传统方法与深度学习两种吸烟检测系统,其中基于传统方法的烟支检测有着精度差,难以应对复杂场景的问题。因此,为解决上述问题,本文采用基于深度学习的烟支检测方法,对YOLOv5算法进行改进,搭建了一个高效准确的吸烟检测系统,具体围绕以下几个方面进行研究。(1)为选定基准模型,对YOLOv5模型进行缩放,并对缩放后的5种模型在COCO数据集上进行训练和测试。最终根据检测精度、模型参数量及运行速度选择YOLOv5s作为基准模型进行改进。(2)在模型骨干网络部分,使用Contextual Transformer(COT)模块代替原来C3模块,充分利用输入按键之间的上下文信息来指导动态注意矩阵的学习,从而增强视觉表示能力,进而加强骨干网络对烟支的特征提取能力。在骨干网络与特征融合网络的连接处引入CBAM注意力机制,使模型提取到的特征可以充分利用特征图的空间信息及通道信息,在不大量堆叠参数量的前提下,使模型可以更有针对性的对目标特征进行提取。(3)通过网络检索及现实场景拍摄自建吸烟数据集,并使用Mosaic数据增强、图像随机仿射变换等算法对数据集进行扩充,增强数据集中小目标的数量,提高模型对现实场景中小目标烟支的检测能力,进而增强模型的泛化性。使用扩充后的数据集在改进后的模型上进行训练验证,并通过消融实验证明本文所提改进均真实有效。实验结果表明,本文所提出的改进模型有着更高的精度与召回率,改进后的模型相较于基准模型在m AP@0.5和m AP@0.5:0.95分别提升2.4%和1.5%,在Precision和Recall分别提升0.5%和1.0%。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000652
{DOI}: 10.27278/d.cnki.gsdqc.2023.000652
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的智慧农业管理平台的设计与实现
{Author}: 贡丹慧
{Tertiary Author}: 云挺
{Publisher}: 南京林业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智慧农业;四情监测;物联网;大数据;深度学习
{Abstract}: 随着信息技术和物联网技术的不断发展,中国农业进入了一个智能化的时代。通过物联网设备可以对数据进行采集,并形成大数据中心。然而,目前主要的问题在于如何利用这些数据为农业生产的管理和发展提供决策依据。因此,本文旨在基于计算机视觉技术对农业数据进行挖掘和分析,并以智慧农业管理平台为研究对象,研究以下几个方面:(1)针对土壤墒情监测中施肥决策模型中测量值缺失导致的密度聚类方法聚集现象,本研究提出了一种新的两阶段缺失特征密度峰值聚类算法DPC-INCOM。该算法首先对特征完整的数据使用密度峰值聚类算法,并使用标记核心点代表整个数据分布训练分类器。然后对不完全的数据点计算对称FWPD距离矩阵,并对不完全数据进行归值和分类。实验结果表明,使用DPC-INCOM算法分析的测土配方施肥与实际施肥误差不到0.25%,该方法在农作物墒情监测方面具有良好的性能。(2)针对现有的虫情监测中害虫识别方法复杂、分类精度相对较低的问题,本研究提出了一种全新的端到端Deep Pest Net模型,用于害虫的分类和识别。本研究通过在收集的农作物害虫图像上进行实验,发现Deep Pest Net模型具有良好的表现。总的准确率、精密度、召回率和F1＿score分别为97.98%、98.48%、98.21%和98.33%,说明该模型在害虫分类识别方面表现优异,明显优于最新的CTCSP、Trans FG、NSC等方法。(3)针对传统的人工目测病害诊断方法效率低、耗时长,以及管理成本高的问题,本研究提出了一种基于深度学习的多类农作物病害目标检测模型。通过对四种水稻病害(白叶枯病、稻瘟病、东格鲁病、褐斑病)进行实验,发现本文模型的Io U比原YOLOv4模型提高了13.5%,在检测速度和准确率上都得到了优化,该模型在农业病害诊断领域具有较好的应用前景。(4)针对不同区域农作物生长有差异、生长周期长,田间试验和收集农作物数据是一个既耗时也耗费财力的问题等难题,本研究提出了一种新的解决方案,即使用时间卷积网络域对抗神经网络体系结构,以在目标域训练数据较少的情况下准确预测植物生长曲线。通过对采集的玉米生长数据进行实验发现,基于TCN的方法优于基于LSTM的方法,RMSE的最小值为2.621,说明该方法在时间序列数据预测的准确性方面表现优异。(5)本研究搭建了一个基于视觉智慧农业管理平台,该平台包括以下子系统:大田四情监测子系统、视频监控与联动子系统、农产品溯源子系统以及专家指导子系统。平台采用Java语言进行编程实现,并通过展示典型功能的运行效果来展示平台的基础性和智能化管理的实现效果。
{URL}: https://link.cnki.net/doi/10.27242/d.cnki.gnjlu.2023.000946
{DOI}: 10.27242/d.cnki.gnjlu.2023.000946
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的物流分拣系统研究与应用
{Author}: 马祥祥
{Tertiary Author}: 王琨;马歆
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像处理;物流分拣系统;目标检测;匹配定位
{Abstract}: 随着电商、快递行业的突飞猛进,针对物流快递的分拣工作愈发繁重,传统人工分拣存在枯燥繁琐、效率低、人工成本逐年增长等问题,智能化物流作为未来物流的发展方向,将机器视觉引入分拣机器人,使分拣机器人拥有视觉感知的能力,视觉系统通过获得图像信息,实时、精确地分析出物流快递的种类和位置信息,从而灵活地使分拣机器人对物流快递进行分类和放置,极大地提高物流分拣的效率。本文设计了一个基于机器视觉的物流分拣系统平台,并对其关键技术进行研究。主要研究内容如下:(1)根据眼在手外的方案搭建了基于机器视觉的物流分拣系统平台,利用Open CV程序对RGB相机进行标定,获得相机的内外参数和畸变系数,标定后相机平均误差为0.041160。同时采用基于SVD的手眼标定方法求解相机坐标系与机器人坐标系的关系矩阵,实验结果为手眼标定的结果在x、y、z三个坐标轴上的误差都在2 mm之内。(2)针对物流分拣场景下,物流快递视觉识别检测准确率低、检测速度慢等问题,本文采用基于深度学习的目标检测识别算法对物流快递进行类别检测和粗定位,为了提高目标检测识别算法的性能,对SSD目标检测算法进行改进。本文通过将主干网络VGG16修改为Mobile Net V2、采用特征融合模块、引入注意力机制等方法,设计了基于Mobile Net V2的改进SSD目标检测算法。在PASCALVOC数据集上进行训练和验证,平均准确率为82.31%,检测帧率为40.95 frame/s;在自建的物流快递数据集上进行训练与验证,得到的平均准确率达到了97.34%,检测帧率为42.84 frame/s。实验结果表明,本文改进的SSD目标检测算法具有较高的检测准确率和检测速度,能够满足物流分拣场景对准确率和实时性的要求。(3)针对传统视觉算法对物流快递的识别检测准确率低、定位精度不高等问题,本文先使用目标检测算法对物流快递进行识别和粗定位,再使用匹配定位算法获得物流快递的精确定位信息。本文对基于边缘轮廓特征的图像定位、基于多角度的模板匹配定位和基于SIFT与FLANN的匹配定位三种精确定位方法进行研究,实验结表明,基于SIFT与FLANN的匹配定位方法精确定位方法综合检测效果最好,定位误差在3个像素以内,旋转角度误差在0.1°以内,能够满足物流分拣场景下对物流快递的定位精度要求。(4)针对实际物流分拣场景,本文设计了基于机器视觉的物流分拣系统的分拣流程,进行了物流分拣系统的相机、机器人和上位机的通信建立,设计了物流分拣的分拣策略和机器人运动的轨迹规划,使用py QT、Open CV和Pytorch等框架设计了基于机器视觉的物流分拣系统验证软件。根据所搭建的基于机器视觉的物流分拣系统实验平台,进行了物流分拣实验,实验结果为:平均单个快递的分拣时间为14.38 s,平均分拣成功率为98%。实验结果表明,本文设计的基于机器视觉的物流分拣对物流快递的识别准确度较高、分拣速度较快、分拣成功率较高,验证了本文设计的物流分拣系统的可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.001817
{DOI}: 10.27169/d.cnki.gwqgu.2023.001817
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv7的自然环境下柑橘果实识别与定位方法研究
{Author}: 王乙涵
{Tertiary Author}: 许丽佳
{Publisher}: 四川农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 柑橘采摘机器人;果实识别;双目立体视觉定位;YOLOv7;计算机视觉
{Abstract}: 水果是农产品的一大类。目前水果的采摘仍然以人工为主,人工采摘耗时耗力,效率低下。采摘机器人的视觉系统是其获取目标果实信息的关键,对完成采摘动作起着关键性作用。本文以柑橘为研究对象,研究了自然环境下成熟柑橘的识别与定位,以提高柑橘采摘机器人采摘作业的实时性与鲁棒性。本文主要研究内容与结论如下:(1)构建了成熟柑橘样本数据集。使用相机与手机两种设备分三次在果园实地拍摄不同时段、不同光照角度下的成熟柑橘图像。通过多种图像处理技术对所拍摄的柑橘图片数量进行扩增,并且针对柑橘识别存在的重叠、遮挡难题,从采集到的图片中挑选具有代表性的样本制作出轻度遮挡和重度遮挡测试集。人工标注图片中的柑橘目标,从而构建本文研究所需的柑橘样本数据集。(2)柑橘果实识别模型的构建与研究。针对模型在自然环境下识别柑橘目标时存在的识别精度低且速度较慢的问题,本文以YOLOv7模型为基础,提出了LTYOLOv7模型。首先使用轻量级特征提取网络Rep VGG作为骨干网络以加强复杂背景下柑橘特征提取能力;其次,在颈部网络中引入深度可分离卷积,有效降低网络参数量;接着,采用通道注意力机制ECA(Efficient Channel Attention)增强主干网络获取的重要多尺度特征权重,从而最大化地提高检测模型的性能;最后,应用soft DIo U＿NMS(soft DIo U Non-Maximum Suppression)算法优化预测框的筛选,进一步提高重叠果实的识别能力。(3)柑橘果实目标定位研究。研究了双目视觉系统的基本理论和相机参数标定方法,搭建了柑橘目标的双目立体视觉系统。采用张正友标定法对所选ZED双目相机进行标定,通过Matlab软件完成相机的标定实验,从而得到ZED相机内外参数及相关矩阵并分析标定结果误差。为实现柑橘果实的三维空间定位,提出基于双目立体视觉的柑橘果实空间定位方法。通过SGBM(Semi-Global Block Matching)立体匹配算法提取特征,匹配左右目拍摄所获得的目标图像对应像素点,推导出数学公式以计算视差值,并通过公式演算出柑橘果实的深度值。(4)对柑橘果实的识别方法与定位方法分别进行了实验验证。就柑橘目标的识别而言,对比Faster R-CNN和YOLO系列模型,验证了本文所提出的LT-YOLOv7轻量级网络模型识别效果最优,其AP(Average Precision,AP)值为98.14%,F1值为0.94,在GPU上对柑橘目标识别速度可达208帧/s,对于单张大小为640×640的图片推理速度达到4.8 ms,模型所占内存仅32 MB。基于双目立体视觉技术对柑橘目标中心点进行定位实验,采用控制变量法总共进行11次实验并记录相应实验结果。通过与激光测距仪实测数据进行比较,本文在正常光下、顺光下及背光情况下对于深度Z方向上的误差分别为-6～7 mm、-7～7 mm和-6～7 mm,相对误差都在1.3%以内。综上可知,本文所用的定位方法满足采摘机器人的采摘要求。
{URL}: https://link.cnki.net/doi/10.27345/d.cnki.gsnyu.2023.000320
{DOI}: 10.27345/d.cnki.gsnyu.2023.000320
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的复杂零件精密测量方法与应用
{Author}: 李现友
{Tertiary Author}: 徐科
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 机器视觉;精密测量;误差分析;边缘检测
{Abstract}: 高端制造业与智能装备的关键零部件质量是提升我国国防与经济建设的装备水平、推动高质量发展的重要基础。以重型汽车曲轴为代表的大尺寸零件测量和以抽油杆螺纹为代表的微米尺寸高精度测量方面,目前一般采用制造过程或出厂前的人工离线抽检方式,存在检测效率低、人工劳动强度大、检测结果无法溯源、容易造成漏检等问题。基于机器视觉的高精度测量技术是提高精密产品质量、提升生产效率、降低成本的重要途径。但是目前在线应用的机器视觉测量系统存在检测效率和结果精确性不足等问题,还无法完全替代人工检测。本文对单目视觉测量方法以及在机械零件精密测量中的应用进行深入研究,提出新的边缘检测算子,以实现复杂图像背景下特定方向直线边缘的快速提取,解决多边缘的抽油杆螺纹牙型快速测量难题;提出大尺寸件精密测量中的多视场协同,应用于重型卡车曲轴主轴径测量。本文的主要研究内容和成果如下:(1)通过理论推导得到测量误差关于相机参数和位姿状态等参数的数学表达式,对实际测量平面与系统标定平面不重合产生的测量误差进行定量分析。分别使用工业镜头和远心镜头,对测量平面绕Xw轴的旋转运动与Zw轴的平移运动进行测量实验。理论分析与实验结果表明:当相机光轴垂直于测量平面时,测量误差与相机光轴的主点坐标、测量平面内的平移分量以及绕相机光轴的旋转角度无关,与相机光轴方向上的平移分量以及被测工件的像素距离呈线性关系,与相机归一化焦距成反比关系;当相机光轴不垂直于测量平面时,测量误差是关于相机归一化焦距、像素尺寸和旋转角度等参数的非线性函数。当测量平面存在旋转以及平移位姿变换时,可以通过调整被测工件拍摄角度或者位置来减小测量误差。(2)针对传统边缘检测算子对图像边缘方向敏感性差的问题,提出了基于高斯函数定权的定向边缘检测算子G-DEDA,用于多段边缘图像中特定方向边缘提取。不同于传统Prewitt、Sobel算法只在特定的角度下存在对应的边缘检测卷积核,G-DEDA利用双边滤波中的双高斯函数,建立卷积核与给定检测角度的一般性函数关系。首先,根据检测角度得到边缘线方程及其法线方程;接着,分别计算卷积核中各点到边缘线及其法线的距离,得到双边距离,将双边距离代入双高斯函数计算得到卷积核中该点的权值;最后,根据卷积核中各点与边缘线的相对位置关系计算各点权值符号,生成卷积核模板。随着卷积核尺寸增大,矩阵稀疏程度加剧,可有效提升卷积核的生成速度,降低卷积核存储所需空间,并提升后续卷积运算速度。仿真图像和实际图像的边缘检测实验表明,G-DEDA具有适用性好、检测效率高和检测精度高的优点,弥补了传统边缘检测算子在边缘方向性表示上的不足。(3)针对螺纹图像中存在螺纹牙错位与灰尘噪声等问题,设计了连通域去噪、连通域排序、连通域合并算法,通过左右边缘匹配算法对螺纹牙进行精确定位,以实现螺纹牙型角、螺距、大径、中径和小径的高精度测量。使用本文方法测量抽油杆螺纹参数,结果表明:螺纹角度测量的最小和最大误差分别为0.011°和0.63°,总平均偏差小于0.08°。与万能工具显微镜(UTM)的测量结果进行比较,本文方法和UTM对于螺纹节距、大径、中径和小径尺寸的测量偏差均小于10μm。本文方法对于单个螺纹的完整参数测量时间不超过0.13s,可满足螺纹在线测量的实时性要求。(4)针对大尺度件精密测量中出现的测量范围和测量精度无法平衡的问题,提出了多视场协同的精密测量方法,并应用于曲轴轴径的测量。提出双视场协同的测量原理,搭建双视场协同测量系统。采用定制的高精度标定板提高双相机采集系统的标定精度,并通过二次插值的亚像素处理有效提升边缘直线的拟合精度。用本文方法和三坐标测量机(CMM)对标称直径为100mm的曲轴轴径进行测量实验,结果表明:CMM和本文方法得到的μ95最大值分别为±2.11μm和±1.82μm,并且两种方法的平均值和均方差值接近,说明本文方法达到与CMM近似的测量精度。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2023.000458
{DOI}: 10.26945/d.cnki.gbjku.2023.000458
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的苹果采摘机器人目标识别与定位研究
{Author}: 宋洋
{Tertiary Author}: 张静
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 苹果检测;YOLOv5;深度学习;定位;PyQt
{Abstract}: 近年来,随着机器人技术在农业采摘方面的应用越来越广泛,对采摘机器人的采摘效率也有了更高的要求。苹果采摘机器人能在降低工人劳动强度的基础上,提高苹果的采摘效率。从目前的技术研究进展分析,深度学习技术虽越来越多地应用在苹果采摘过程中,但基于深度学习的苹果识别模型依然存在识别准确度低、定位准确性差的问题,这些问题一直是苹果采摘机器人研究的重难点。本文针对这种情况,从视觉识别、目标定位和软件设计等方面进行研究,为苹果采摘机器人提供研究基础。本文的主要研究内容和结论如下:(1)在设置好网络模型的相关参数后,对几种经典网络模型SSD、YOLOv4和YOLOv5在相同条件下进行对比实验。结果表明YOLOv5网络模型在速度和准确率方面均表现良好,因此选择YOLOv5作为苹果识别检测的基础网络进行改进研究。本文基于YOLOv5提出一种改进的网络模型并命名为YOLOv5-CE,该模型在特征提取部分引入性能更出色的Conv Ne Xt网络,并在特征提取过程中增加了注意力机制,使YOLOv5-CE网络模型的m AP从92.02%提高到了93.72%。(2)对RGB-D相机Intel SR305进行标定获取坐标转换所需参数,在完成相机标定的基础上,设计出基于Intel SR305相机的苹果识别和定位实验。在此基础上通过Py Qt设计出人机交互界面,并命名为苹果目标检测系统,该系统可以完成苹果目标的识别并对苹果进行三维定位。对该检测系统进行调试和实验,验证系统的检测效果,结果表明所设计的苹果目标检测系统简单高效。本文选择对深度学习技术中的卷积神经网络算法进行改进,在一定程度上提高了苹果的识别准确率。并设计出苹果目标检测系统的可视化操作界面,有效地提高模型在实际中的可应用性,为苹果采摘机器人提供技术支持。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2023.001163
{DOI}: 10.27206/d.cnki.ggsgu.2023.001163
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于迁移学习和自监督学习的Vision Transformers对高维医学图像分类研究
{Author}: 盖路路
{Tertiary Author}: 谯旭
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 卷积神经网络;Vision Transformers;迁移学习;自检督学习;高维医学图像分类
{Abstract}: 自从2012年AlexNet被提出以来,卷积神经网络(Convolutional Neural Networks,CNNs)—直是计算机视觉领域的主流模型算法。然而,在2020年Vision Transformers(ViTs)被应用在图像分类任务上并且超越了 CNNs在ImageNet数据集上的分类结果。Transformer最初是为了处理序列化数据提出的,它在自然语言处理领域得到了广泛的应用。ViTs因为其独特的网络结构,因此在图像处理任务上与CNNs相比具有多种优势:首先,ViTs通过自我注意力机制可以提供输入数据之间的上下文特征;其次,ViTs的并行化的网络结构允许其在更大规模的数据集上训练并且大大缩短了训练时间;除此之外,ViTs具有更强的可解释性,其中内置的注意力显著图可以更直观地展现模型在做决策时所关注的图像部分,这对人工智能在医学辅助诊断领域的应用至关重要。因此,将ViTs应用在医学图像处理领域具有重要的意义。然而,ViTs在医学图像任务的应用中还有很多阻碍:(1)由于缺少归纳偏差导致ViTs需要大规模数据集预训练,而医学图像由于隐私等问题难以达到与自然图像数据集一样的规模;(2)ViTs需要多种数据增强技术,而医学图像一般是多通道的高维图像,技术应用有难点。因此,探究Transformer在医学图像分类任务上是否可以替代CNNs以及如何在有限的数据集上提升Transformer的分类效果是亟待解决的问题。为解决以上问题,本研究将ViT-S与EfficientNet、ResNet等3-D CNNs模型进行对比实验,主要包括以下几方面的工作:(1)为了克服数据量有限对ViTs分类的影响,本研究使用迁移学习来提高ViTs的分类能力。实验结果表明,迁移学习可以显著提高Transformer的分类结果,并且可以超越CNNs。(2)此外,本研究采用自监督学习来提高模型的分类效果。具体来说,本研究采用知识蒸馏的思想,将ViTs和CNNs模型首先在无标签的数据集上做预训练,然后在有金标准的分类数据集上微调。实验结果表明自监督学习对ViTs和CNNs模型的分类能力都有很大提升,在数据集达到一定规模的条件下ViTs对高维医学图像的分类效果可以超越CNNs。(3)为了研究ViTs和CNNs在高维医学图像分类任务的泛化性,本研究一共在四个高维医学图像数据集(MGMT、Lung-Cancer、COVIDCTset 和 MosMedData)对三种疾病进行分类判别。基于高维医学图像,本研究还探究了不同位置编码(无位置编码、一维位置编码和三维位置编码)对ViTs分类的影响。最后,本研究对ViTs中的自我注意力机制进行了可解释性说明。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.003166
{DOI}: 10.27272/d.cnki.gshdu.2023.003166
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的番茄采摘机器人关键技术研究
{Author}: 关照昕
{Tertiary Author}: 左治江
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 番茄采摘机器人;机器视觉;深度学习;末端执行器;ROS
{Abstract}: 番茄采摘的环境舒适度差且工作强度大,而机器人不当的采摘方式会造成果实外皮损伤等不良影响,降低收获果实的质量。针对此问题,以机器人采摘番茄为研究对象,对番茄检测识别及空间定位、末端执行器设计、机械臂应用和系统集成等关键技术进行系统性研究,研发了能自动识别定位并进行采摘的机器人,采摘的番茄果蒂完整、外皮无损伤。主要工作和研究内容如下:(1)采集不同光照强度的番茄数据集图片。于湖北省武汉市农业科学院番茄温棚进行调研并开垦实验田种植番茄,使用双目深度相机采集番茄果实图片,分析不同自然光照强度和补充光照情况下对番茄图像的变化,并对数据集进行数据增强,使用标注工具Labelme标注图片,依据不同光照强度构建数据集。(2)研究番茄目标检测识别与双目视觉定位技术。采用YOLO算法对不同光照强度下的图像进行训练,确定了基于YOLO v3-tiny检测识别番茄的视觉系统,解决果实簇中不同成熟度果实遮挡造成误识别问题。根据相机标定内外参得到图像坐标系和空间坐标系转换关系,提取图片像素点对应的深度数据。进行定位可行性分析试验,确定检测识别的合适距离。(3)设计了无接触式末端执行器,并对机械臂的运动轨迹进行仿真。根据番茄生长特点,确定单果采摘方式。对果梗受力分析,避免剪切时滑脱,增加主茎槽解决采摘短果梗番茄卡住的问题,并3D打印制造减轻负重。使用Arduino控制板集成通信功能,进行通信控制测试。通过MATLAB对机械臂D-H建模仿真,采用笛卡尔空间轨迹规划减小运动时的扫动覆盖面积,防止采摘中外皮受伤。(4)试研番茄采摘机器人样机并开展验证试验。番茄采摘机器人由视觉系统、机械臂、Arduino控制板、末端执行器和移动平台等五个部分组成,基于ROS机器人系统进行软件集成。验证基于视觉系统自主规划机械臂运动的采摘技术。番茄采摘机器人视觉系统在光照强度20000-30000Lux下的识别效果较好,准确度达到90.5%,误识别为0%,漏识别为9.5%,平均图像识别时间约为1.0s/帧。番茄采摘机器人能得到果蒂完整、外皮未受损的番茄,平均单果的采摘时间约为9.5s,采摘的成功率为83.3%。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2023.000152
{DOI}: 10.27800/d.cnki.gjhdx.2023.000152
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合YOLOv7和BYTE多目标跟踪的多类别海珍品计数方法
{Author}: 安志强;李智军;刘硕;赵永刚;陈启俊;左然涛;林远山
{Author Address}: 大连海洋大学信息工程学院;辽宁省海洋信息技术重点实验室;设施渔业教育部重点实验室,大连海洋大学;大连鑫玉龙海洋生物种业科技股份有限公司;大连海洋大学水产与生命学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 09
{Pages}: 183-189
{Keywords}: 机器视觉;深度学习;海珍品计数;水产养殖;多目标跟踪
{Abstract}: 针对目前养殖过程中海珍品计数方法成本高、效率低、计数精度难以保障等问题,该研究以真实底播养殖环境下的海珍品为研究对象,以水下拍摄的海珍品视频为数据源,提出一种基于视频多目标跟踪的多类别海珍品计数方法。首先,采用性能优异的YOLOv7算法实现海珍品目标检测器,为多目标跟踪提供输入;然后,结合真实养殖环境下同类别海珍品外观相似性高、不清晰等特点,借鉴BYTE算法的多目标跟踪思想,设计多类别轨迹生成策略和基于轨迹ID号的计数策略,提出一种多类别海珍品跟踪与计数方法。并提出一套更适用于基于轨迹ID号计数方法的评估指标。试验结果表明,改进平均计数精度、改进平均绝对误差、改进均方根误差及帧率分别为91.62%、5.75、6.38和32帧/s,各项指标多优于YOLOv5+DeepSORT、YOLOv7+DeepSORT、YOLOv5+BYTE、YOLOv7+BYTE等算法,尤其改进平均计数精度、帧率指标比YOLOv5+DeepSORT高了29.51个百分点和8帧/s,且在改进平均绝对误差、改进均方根误差指标上分别降低19.50和12.08。该研究方法可有效帮助水产养殖企业掌握水下海珍品数量,为现代化渔业的测产研究提供技术参考,为水产养殖的智慧管理提供科学决策依据。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20230526.1003.028
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的移动目标在线检测与机械臂动态抓取研究
{Author}: 王宪渊
{Tertiary Author}: 费胜巍;黄荣和
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;YOLOv5;移动目标定位;动态抓取;ROS系统
{Abstract}: 相对于传统型机械臂,协作型机械臂在移动感知、路径规划、抓取效率等方面做出了全面改进,正被越来越广泛的运用在各种工业生产线领域。目前协作型机械臂抓取技术的主要制约因素是智能化水平有待提高,这也是近年来研究学者的研究重点。本文引入机器视觉作为机械臂的“眼睛”,进行机械臂的动态抓取技术研究,引入传送带上的水果模型分拣作为研究案例,主要应用于机械臂抓取教学领域。首先,对视觉系统和机械臂系统的硬件进行选型和设计,对深度相机进行标定获得内参和外参并且消除镜头畸变,利用Aruco码进行手眼标定,完成从相机坐标系到机械臂基坐标系的转换,使得标定的误差在1cm以内,为后续抓取做准备。其次,传统目标检测算法特征较单一、适用于静态场景,对于动态场景的检测准确率下降,本文提出以YOLOv5为基础的深度学习目标检测模型,将CSPDarket53作为特征提取网络结合Head层输出预测结果。实验显示YOLOv5预测结果的m AP值为95%,能够准确预测出图像中的水果模型种类。然后采用TOF时间飞行技术获得相机视野内的深度图,将深度图和彩色图对齐,根据测量的深度值和前面标定的结果得到目标坐标。再次,设计移动目标实时监测算法,利用编码器监测传送带的瞬时速度,基于时间和速度实时获取移动目标位置;设计基于S型加减速算法的机械臂控制和动态跟踪路径规划策略,有效减少机械臂关节运动中的震动,放置目标的过程中采用门字型运动轨迹规划,有效避障的同时保证稳定性。最后,搭建视觉系统和ROS机械臂抓取系统的硬件和软件平台,并构建人机界面进行数据交互,最终经实验验证得出移动目标的平均定位精度在毫米级,机械臂的抓取效率在92%以上,能够稳定的对水果模型进行分拣,满足课题的设计要求。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.000828
{DOI}: 10.27012/d.cnki.gdhuu.2023.000828
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CNN与Transformer融合的目标检测改进方法及其应用研究
{Author}: 郭文昌
{Tertiary Author}: 韩爱丽
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像处理;视觉计算;目标检测;CNN与Transformer融合
{Abstract}: 目标检测是计算机视觉领域的重要任务之一。目前经典的目标检测方法可以分为基于卷积神经网络(CNN)的目标检测、基于Transformer的目标检测、基于CNN与Transformer融合的目标检测等。基于CNN的目标检测模型较难捕捉全局特征,而基于Transformer的目标检测模型可能破坏局部细节。本文探讨基于CNN与Transformer融合的目标检测改进方法及其应用,所做工作在目标识别、场景理解、自动驾驶和智能交通等领域具有重要的理论和实践意义。(1)通过变换主干特征提取网络来改进基于CNN和Transformer融合的目标检测方法。轻量级网络主要通过减少模型的参数量来降低计算量,本文选择MobileViT和MobileNet轻量级网络作为改进模型的主干特征提取网络以提升模型的计算效率并扩展其应用领域。具体地,使用MobileViT代替CSPDarknet作为基于YOLO v5的改进模型的特征提取模块,将贯穿MobileViT的MobileNetV2模块使用的ReLU6激活函数替换为h-swish以消除由于sigmoid的不同实现而带来的潜在数值精度损失;使用MobileNet代替ResNet作为基于DETR的改进模型的特征提取模块,将MobileNet的初始Benck结构中的SE模块使用的ReLU激活函数替换为ReLU6以减少输出值的变化范围并提高网络提取特征的稳定性。(2)通过改进数据增强方法及特征融合网络来改进基于MobileViT与YOLO v5融合的目标检测方法。具体地,采用Mosaic数据增强与Mix-up数据增强相结合的方式进行数据增强以进一步增加数据样本的多样性,使不同类别的决策边界过渡更平滑,减少样本误差并提高模型精度;引入双向加权特征金字塔网络BiFPN,传统的BiFPN网络结构认为如果一个节点只有一条输入边则其对网络的贡献较小,本文将BiFPN第3层和第7层的特征融合节点删除以缩减特征融合网络的层数并增强特征融合效果,从而提升目标检测模型的性能、减少模型的计算量。(3)通过改进回归损失函数来改进基于MobileNet和DETR融合的目标检测方法。具体地,选择Wise-IoU作为改进模型的损失函数来替换原模型中的GIoU以削弱训练数据的几何度量对低质量图像的惩罚,提高模型的泛化能力。Wise-IoU损失函数是在IoU损失函数的基础上引入了一个权重因子,可以更好地处理类别不平衡的问题,使得目标检测模型在训练过程中更加稳定,提升融合模型的性能。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006400
{DOI}: 10.27272/d.cnki.gshdu.2023.006400
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5s的名优绿茶品质检测
{Author}: 尹川;苏议辉;潘勉;段金松
{Author Address}: 杭州电子科技大学电子信息学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 08
{Pages}: 179-187
{Keywords}: 机器视觉;图像识别;茶叶品质检测;YOLOv5s;感受野;swin transformer;注意力机制;SimOTA
{Abstract}: 针对实际检测过程中茶叶数量多、体积小、茶叶之间颜色和纹理相似等特点，该研究提出了一种基于YOLOv5s的名优绿茶品质检测算法。首先，该算法在骨干网络层引入膨胀卷积网络，通过增大感受野的方式增强茶叶微小特征的提取。其次，改进特征融合进程，基于通道注意力和空间注意力抑制无关信息的干扰，构建CBAM注意力机制优化检测器。接着根据swin transformer网络结构在多个维度对小尺度茶叶的特征进行交互和融合。最后，配合SimOTA匹配算法动态分配茶叶正样本，提高不同品质茶叶的识别能力。结果表明，改进后的算法精准度、召回率、平均精度均值、模型体积、检测速度分别为97.4%、89.7%、91.9%、7.11MB和51帧/s，相较于基础的YOLOv5s平均精度均值提高了3.8个百分点，检测速度提高了7帧/s。利用相同数据集在不同目标检测模型上进行对比试验，与Faster-RCNN、SSD、YOLOv3、YOLOv4等模型相比，平均精度均值分别提升10.8、22.9、18.6、8.4个百分点，进一步验证了该研究方法的有效性和可靠性。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.s.20230515.1849.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在农作物种子检测中的研究进展
{Author}: 王昊;祝玉华;李智慧;甄彤
{Author Address}: 粮食信息处理与控制教育部重点实验室(河南工业大学);河南工业大学信息科学与工程学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 22
{Pages}: 69-83
{Keywords}: 种子检测;机器视觉;不完善粒;图像处理
{Abstract}: 农作物种子是农业生产的基础。种子检测作为一种重要的手段，在种子生产、贸易和利用的各个环节都扮演着不可或缺的角色。然而传统的农作物种子识别方法效率低，需要人力以及专业检测设备的支持。相比之下，机器视觉技术能够通过模拟人的视觉功能来实现对目标的无损检测，效率高、准确度高，有助于实现农作物种子的品种识别、分级、分类的自动化、智能化。首先简单叙述了机器视觉技术中图像采集、预处理的方法，并以玉米种子为例给出了目前主流的处理流程，然后具体叙述了机器视觉技术中传统机器学习和深度学习两种检测方式在农作物种子检测中的应用，最后针对玉米不完善粒的研究，在分为以上两种检测方式进行具体叙述的同时，指出了目前存在的问题以及玉米不完善粒检测未来的研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20230512.1451.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Transformer的目标检测研究综述
{Author}: 刘宇晶
{Author Address}: 山西农业大学信息科学与工程学院;
{Journal}: 计算机时代
{Year}: 2023
{Volume}: 
{Issue}: 05
{Pages}: 6-10
{Keywords}: 目标检测;Transformer;计算机视觉;深度学习
{Abstract}: 基于Transformer的目标检测方法因其突出的性能引起了众多研究者的关注。文章从作为Neck的Transformer和作为Backbone的Transformer两类框架在目标检测领域的研究状况、几种常见模型的基本原理以及在COCO 2017 ValSet上的对比实验三个方面做出了综述。
{ISBN/ISSN}: 1006-8228
{Notes}: 33-1094/TP
{URL}: https://link.cnki.net/doi/10.16644/j.cnki.cn33-1094/tp.2023.05.002
{DOI}: 10.16644/j.cnki.cn33-1094/tp.2023.05.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 雨雾天气下的车辆目标检测关键技术研究
{Author}: 孙再鸣
{Tertiary Author}: 柳长安
{Publisher}: 华北电力大学(北京)
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 视觉Transformer;车辆检测;图像去雾;图像去雨;特征融合
{Abstract}: 随着人工智能领域的飞速发展和深度学习理论的进步,车辆检测技术已广泛应用于城市智能交通和自动驾驶领域,协助车辆在复杂的驾驶环境中实现安全驾驶,同时帮助监管部门监控车辆行为,改善交通流量,提高交通安全性。在良好的天气情况和视觉质量条件下,车辆检测技术已经达到较高水平,但是在具有挑战性的典型恶劣天气条件(雨天或雾天)和大范围的小目标影响下,图像质量退化造成检测效果不佳。因此,研究如何克服恶劣天气条件对图像数据质量的影响,确保各种天气条件下检测系统的准确性,对提高自动驾驶安全性和智能交通系统的可靠性具有重要意义。本文针对可见光相机采集的图像数据,对其在雾天和雨天典型恶劣天气条件下出现的图像质量差、车辆检测准确率低等一系列问题展开研究,重点关注图像质量增强、图像去雨雾和车辆检测算法。本文的工作和创新点主要为以下四个方面:(1)提出了一种面向小目标车辆检测的改进生成对抗网络图像超分辨率重建方法。针对复杂交通场景中远距离小目标占有像素点少,导致车辆检测精度大幅下降的问题,本文基于Transformer设计了一种图像超分辨率目标检测算法。首先依据生成对抗网络的结构改进Transformer的线性嵌入模块以补充小目标的线性嵌入信息,同时引入边缘增强网络对目标边缘进行增强,提高了图像中远距离、道路两侧密集停车区域以及遮挡情况下目标的分辨率。然后对获取的高分辨率图像进行层级构建,类似卷积神经网络中的特征金字塔,每层只对局部关系进行建模,并利用移位窗口机制扩大感受野,代替卷积层提取出更强有力的小目标车辆特征,实现精确的检测。通过对比实验证明,本文提出的算法提高了车辆在小尺度以及存在严重遮挡情况下的检测性能,同时为后续恶劣天气下车辆检测算法的研究提供了基础。(2)提出了一种基于改进U型网络的雾天条件下车辆检测算法。一方面,针对受空气中颗粒介质影响的雾天图像会出现质量低下、目标模糊、细节特征丢失严重等情况,进而导致特征提取困难的问题,参考U-Net的网络结构,引入Transformer设计了一个端到端的去雾网络。通过引入交叉注意力跳跃连接机制融合多尺度特征提高网络学习能力,以恢复去雾后具有干净特征的图像。另一方面,针对雾天图像车辆检测困难的问题,结合去雾和检测构建了面向雾天条件下的车辆检测模型。在合成以及真实雾天图像数据集上的实验表明,该算法在雾天场景下可以获得清晰的去雾图像并有效提高车辆检测的精度。(3)提出了一种多分支特征融合的雨天条件下车辆检测算法。针对雨天车辆检测精度低的问题,设计了一种基于Transformer的多分支结构去雨模型,通过提取不同层次,不同种类的特征,提高模型对复杂雨纹的表征能力,以有效去除雨纹并恢复退化图像丢失的信息。检测模型通过结合Transformer和卷积神经网络的优点,设计了局部感知增强Transformer骨干网络,增强了算法的局部感知能力,同时针对雨天图像资源少的问题,本文创建了交通场景雨天数据集,并通过实验证明该算法能够在增强雨天退化图像质量的同时提升相应场景下车辆检测性能。(4)提出了一种多层次特征融合的雨雾条件下车辆检测算法。针对现实场景中雾天和雨天两种恶劣天气经常同时出现的特点,首先设计了一种无需在单个模型和训练数据之间进行切换即可同时去除雨雾两种恶劣天气的模型。该模型通过一种具有层次结构的编码器获取退化图像的分层特征,即不同分辨率的多尺度特征,以更好地捕获对图像去雨雾有益的信息,恢复退化图像的细节。同时引入一种可学习天气类型查询的解码器,这种天气类型的嵌入与网络一同学习,以适应与输入图像相同的天气类型。最后,结合图像去雨雾模型,提出局部感知增强的车辆目标检测模型总体框架,分别使用混合天气条件和单一天气条件数据集对模型进行测试。实验结果表明,该算法在雨雾混合天气下图像恢复效果好,检测精度高,满足实际应用需求。
{URL}: https://link.cnki.net/doi/10.27140/d.cnki.ghbbu.2023.000203
{DOI}: 10.27140/d.cnki.ghbbu.2023.000203
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的孪生网络目标跟踪算法研究
{Author}: 戴加海
{Tertiary Author}: 常玉春
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 注意力机制;孪生网络;Transformer;特征融合;目标跟踪
{Abstract}: 视觉目标跟踪作为计算机视觉的研究热点之一,旨在定义了目标的初始位置和大小等状态信息之后,预测目标在视频后续帧中的状态信息。近年来,受益于深度学习技术和计算机硬件设备的发展,涌现出许多优秀的跟踪算法。然而在现实场景中,跟踪算法仍需面临遮挡、相似物干扰和目标尺度变化等复杂多变的因素影响。因此,设计一种精度高、实时性好的跟踪算法依旧是一个具有挑战性的问题。本文主要针对开放场景的单目标跟踪问题开展研究工作,并探索了相似背景干扰、目标尺度变化和线性相关语义信息丢失等导致的跟踪精度下降的问题。基于孪生网络跟踪模型,结合注意力机制原理,立足于构建有效、丰富的外观特征表达,开展了对准确、鲁棒的跟踪模型的研究工作。本文主要工作如下:(1)提出一种基于协同注意力孪生网络的视觉跟踪算法(CGS),解决搜索图像中存在背景干扰,导致跟踪精度下降的问题。在Siam RPN跟踪算法的基础上,引入协同注意力模块,学习搜索特征与模板特征之间的交互关系,并用于增强模板和搜索区域的判别性特征,减少了相似背景语义信息的干扰,从而抑制了错误相关结果的生成。同时,在模板分支引入门机制,从通道维度强化目标外观的特征表达,进而提高算法的跟踪精度。(2)提出一种基于分层特征融合Transformer的孪生网络视觉跟踪算法(Siam HFFT),解决跟踪过程中目标发生尺度变化,尤其对小目标物体跟踪效果欠佳的问题。在孪生网络跟踪架构的基础上,通过骨干网络提取不同尺度和语义信息的分层特征,将详细的结构信息纳入视觉表征。设计了一个新颖的特征融合Transformer将底层的空间信息和高层次的语义信息融合,整合和优化多层次多尺度特征,在跟踪过程中强化语义信息和空间细节,有效提高了跟踪算法的精度;同时为避免特征提取过程中计算量过大,影响算法跟踪速度的问题,利用轻量型骨干网络,降低计算量,提高了算法的跟踪速度。(3)提出了一种基于多头交叉注意力机制的Transformer视觉跟踪算法(MCTT),解决传统跟踪模型采用的线性相关匹配操作,导致语义信息的丢失或陷入局部最优解的问题。利用多头交叉注意力机制学习不同子空间的相关信息,自适应的关注关键特征,从而更深层次的挖掘模板和搜索区域之间的全局信息交互。同时设计了一个简易的辅助掩码预测头网络,将现有的主干网络特征和Transformer编码器-解码器特征以耦合的方式结合在一起,获得高分辨率像素特征并生成掩码,从而得到更准确和有效的跟踪结果。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.000711
{DOI}: 10.27162/d.cnki.gjlin.2023.000711
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的安全帽佩戴检测算法
{Author}: 陈家亮
{Tertiary Author}: 李文辉
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: YOLOv5;安全帽佩戴检测;注意力机制;空洞卷积;递归门控卷积
{Abstract}: 随着各生产领域的不断发展和进步,安全生产问题越来越受到重视。安全帽作为重要的安全防护装备,能应用在工业生产、建筑工地等行业中。在现代化的工作场所中,为确保员工的工作安全,检查安全帽的佩戴是必要的。传统的安全帽佩戴检查方式大多通过人工监管进行,存在成本高、效率低等问题。因此,利用目标检测技术,研究有效的安全帽佩戴检测算法对于保障员工的人身安全具有重要意义。本文提出了一种基于改进YOLOv5的安全帽佩戴检测算法。YOLOv5具有高效性和实时性等优点,能有效应用在安全帽佩戴检测中。但在实际应用中,安全帽佩戴检测技术会面临人员复杂、检测环境差、目标被遮挡、检测目标小等问题,导致检测精度不足,目标漏检或误检等情况的发生。因此,本文针对以上的问题及YOLOv5模型提出了改进方法,展开了如下工作的研究:(1)针对安全帽佩戴检测在小目标检测、复杂环境检测和模糊背景检测等场景中存在检测精度不足,容易出现误检、漏检的问题,本文提出了基于注意力机制改进的YOLOv5网络。该网络融合了本文提出的基于SENet改进的多尺度注意力机制MSENet模块。该模块能够弥补通道间的信息,然后整合各通道的信息,并为各通道间的特征分配权重,使得模型将注意力集中在目标检测任务上。MSENet网络采用了结合图片分块、残差连接和逐点卷积的多尺度特征输入模块,接着通过两个并行的池化层和全连接层,根据得到的通道权重与原特征相乘,形成了一种新的多尺度注意力机制。分别在本文自制数据集及SHWD数据集上进行实验,改进后的网络检测精度m AP相比于基准网络分别提升了1.1%及0.7%,并改善了小目标、复杂环境和模糊背景等场景的检测效果。(2)针对MSENet模块融合在YOLOv5的检测头前导致其对于特征提取的影响不大,其检测精度仍有进步空间的问题,以及原YOLOv5的SPPF模块信息丢失的问题,本文提出了基于多尺度空洞卷积模块NDC融合的改进YOLOv5网络。其能在保持特征图分辨率不变的情况下提高感受野,有助于捕捉不同尺度的目标,进一步加强各场景的检测效果。在本文自制数据集中进行实验,改进后的网络检测精度m Ap@0.5相比于基准网络提升了1.2%,在SHWD数据集上其m Ap@.5:.95值提升了1.1%。(3)针对安全帽佩戴检测中存在遮挡目标难以检测的问题,以及精度仍可以继续提升的问题,本文提出了一种基于递归门控卷积的改进模块GPANet。其可以获取到图像中相邻像素之间的高阶空间相互作用,以捕捉复杂的空间依赖关系。在本文自制数据集中进行实验,改进后的网络的检测精度m Ap@0.5相比于基准网络提升了2.2%,在SHWD数据集上其m Ap@.5:.95值提升了2.1%,并改善了遮挡目标检测等场景的检测效果。经实验验证,融合了本文提出的各模块的改进YOLOv5网络在自制数据集中的检测精度m Ap@0.5相比于基准网络提升了3.3%,在SHWD数据集中的检测精度m Ap@.5:.95相比于基准网络提升了2.4%,安全帽佩戴检测中的多场景检测问题也得到了改善,检测效果良好。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.005031
{DOI}: 10.27162/d.cnki.gjlin.2023.005031
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的手势识别算法研究
{Author}: 吴文
{Tertiary Author}: 李春晓;孙健
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;手势识别;特征提取;YOLOv5s;LSTM
{Abstract}: 随着计算机和人工智能等技术的飞速发展,手势识别技术在计算机视觉、人机交互等领域已经占据非常重要的地位。目前,基于计算机视觉的手势识别技术在车载智慧功能、手语翻译、交通指示等多方面已经有了相当广泛的应用。但是,由于手势识别的应用场景相对多元化,手势背景的复杂度、手势自身条件和对应动作形态均存在差异性,再加上使用者对识别技术的效果要求日益严格。因此,继续加强对手势识别技术的研究存在必要性。本文将分别以静态、动态手势为研究对象,从基于几何图形分割法和深度学习算法两方面分别进行探索。论文的主要工作与创新点如下:（1）针对传统的基于几何特征的手势识别算法的局限性,提出一种基于深度数据的静态手势识别算法:首先,对深度相机采集的数据进行预处理,提取前景信息,滤除背景;其次,利用提出的N-Iterate、C-Loop等判定算法检测手掌位置;然后,计算分析手形所有轮廓点到掌心距离的直方图及其波峰索引,并结合角度提取指尖个数,有效解决了手掌定位不准确的问题;最后,将得到的手势的最大掌、掌心位置、指尖个数该3类关键特征作为改进支持向量机（Support Vector Machine,SVM）的输入,并映射到高维空间,进行手势0-5的分类识别。实验结果表明,所提出的算法在复杂背景和手部自干扰等影响下仍具有较高的识别准确率和实时性,在自制数据集中进行验证,结果显示,平均准确率提高至98.57%,识别耗时降低至37.923ms,较大程度提高了识别效率。（2）为了进一步提高基于深度学习的静态手势识别算法准确率,提出一种基于改进YOLOv5s的静态手势识别算法:首先,改进了 YOLOv5s中的特征金字塔（Feature Pyramid Networks,FPN）结构,通过裁剪网络节点,增加残差跳跃连接等方法简化FPN结构,实现相对高效的双向跨尺度连接以及多尺度融合;然后,引入卷积注意力模块（Convolutional Block Attention Module,CBAM）,将通道注意力模块和空间注意力模块串联结合;最后,将ReLu激活函数替换成平滑的ACON-C函数,通过自适应激活,节省了大量运算,从而加快了分类、检测过程。实验结果表明,在公开的数据集handposexgesturev1中,14类静态手势识别的平均准确率达到95.80%,与原YOLOv5s网络结构和双向特征金字塔网络（Bidirectional Feature Pyramid Network,BiFPN）对比,证明了提出的基于改进YOLOv5s的静态手势识别算法优于YOLOv5s。（3）针对动态手势识别效率低、精度低等问题,提出一种基于长短期记忆网络（Long Short-Term Memory,LSTM）的动态手势识别算法:首先,通过使用Mediapipe框架和ResNet18网络,分别提取视频单帧中手部的21个关键点的三维归一化坐标,以及图像卷积特征,并结合相邻帧间矢量特征进行融合拼接,实现多特征融合;其次,在三层堆叠长短期记忆网络中引入注意力机制,增加网络深度,分析动态手势时间序列的特性,对手势进行分类识别。实验表明,该算法在公开数据集ChalearnIsoGD中单手识别准确率达到90.71%,可以更高效地识别动态手势,提高识别的可靠性,具有高鲁棒性和高识别精度。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2023.000405
{DOI}: 10.27441/d.cnki.gyzdu.2023.000405
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Mediapipe单人运动姿态评测系统的研究与开发
{Author}: 曹晓瑜
{Tertiary Author}: 夏端峰;梁少波
{Publisher}: 湖北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人体姿态识别;Mediapipe;Blaze-pose;SVM;运动评测
{Abstract}: 为了促进全民运动智能化,同时降低运动所需要花费的空间、时间和经济成本,预防运动姿势错误造成运动效果不好和出现肌肉损伤,设计并实现了单人运动姿态评测系统。系统主要采用计算机视觉技术来实时识别一个人的姿势和手势,并做出简单的效果评测。整个系统是基于Mediapipe框架以及改进的SVM分类算法实现运动检测、运动计数、运动分析等功能。系统使用Mediapipe这一对移动设备友好的框架,框架分为人体(Blaze-Pose)的姿势识别两部分,它们是系统实现的基础,主要用于对人体的姿态检测和对应关键点信息的提取,SVM分类算法主要被用于将系统新获取的关键点数据信息与系统预置的标准动作关键点数据信息进行比对、进行动作分类,判断动作是否达标。其中动作准确度的判定还加入了角度阈值配合SVM分类算法一起对动作进行是否标准的判定。与现有的运动应用相比,系统具有一些优势,包括了实时运动检测和计数,以及间隔的屏幕外非接触手势控制。系统可以用于加强无氧健身训练,包括动作标准程度、动作合理运动安排、动作注意事项等,这些都是运动监测的几个重要方面。论文主要分析了计算机视觉技术在人体姿态识别方面的国内外研究发展现状,包括非机器学习方法和机器学习方法,并且按模型提出时间顺序进行了简单介绍。接着对Medidapipe框架进行了简单介绍,描述了Blaze-Pose和Blaze-Hands两个分支框架的关键点分类以及解决方案的工作流程,包括轻量化的检测方法以及对视频流图像帧目标定位的新方法。还介绍了基础的SVM分类算法的基本原理和思路以及对增加的角度阈值方法以手臂动作为例进行了算法介绍,并且对对比试验的KNN、VGG16两种分类模型的检测原理和思路也进行了简单介绍。同时也对目前深度学习中所常被用到的人体姿态数据集FLIC,LSP,MPII和MSCOCO、JHMDB进行了介绍。接着对本系统所提出的人体姿态和预测动作类型的体系结构进行了详细介绍,并对分类算法在自己准备的数据集上进行了动作分类准确率的对比,并对实验结果进行了分析。最后详细展示了本系统的实现过程并总结了工作内容,及后期针对人体姿态识别模型进一步改进的思路。本系统的提出与实现将深度学习模型应用到实际生活的健身运动中,脱离人的主观指导,节省人力、空间资源、经济消耗,并且能够提供较好的动作监督与指导功能,减少在独自运动时因动作不标准出现的肌肉拉伤、关节损伤、运动效果不好等风险问题。
{URL}: https://link.cnki.net/doi/10.27796/d.cnki.ghbsf.2023.000310
{DOI}: 10.27796/d.cnki.ghbsf.2023.000310
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能技术辅助下的图像生成艺术创作研究
{Author}: 孙文倩
{Tertiary Author}: 陈金明
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人工智能技术;图像生成;生成艺术;创作研究
{Abstract}: 随着网络、大数据和人工智能技术的不断不断进步,给传统艺术设计带来了深远的影响和潜在的机遇,同时也不断塑造着其内容和形式。面对人工智能时代所引起的新浪潮,图像生成艺术创作迎来了前所未有的机遇和挑战,并逐渐成为一个备受关注的研究领域。人工智能技术在图像生成艺术中的运用,使得我们可以以一种全新的方式来探索科技在艺术创作中的应用潜力。人工智能时代之下,如何在图像生成艺术和人工智能技术中找到二者的平衡点并厘清如何借力人工智能技术克服人类自身局限性,推动图像生成艺术创作的创新发展,实现协同创作成为了当前研究的重要课题。因此,本研究旨在探讨如何利用人工智能技术辅助图像生成艺术创作,推动基于人工智能技术的艺术创作新模式的发展。本研究首先对图像生成艺术的发展历程和现状梳理分析,接着从人工智能技术的基础概念与演进历程出发,深入探讨了人工智能技术的优势特征与图像生成艺术创作的智能化需求两者之间的契合之处。可以发现,人工智能技术正在深刻地影响着图像生成艺术的创作方式和风格。同时,图像生成艺术也反向启发着人工智能技术的发展方向。文本智能生成图像技术的出现,为人工智能技术在艺术创作领域的应用提供了新的思路和方法。通过对现阶段文本智能生成图像技术在艺术创作中的应用现状分析,提出了相关的创作策略和技巧。基于此,研究从创作实践探索智能化的图像生成艺术创作。通过创作实践,进一步提出了智能化的图像生成艺术的创作新模式,为人工智能技术在艺术学科的学术研究提供更具实践性的参考和启示。最后,本研究对人工智能技术辅助下的视觉艺术创作的应用前景和发展趋势进行了总结和展望,期望人工智能技术的发展将为艺术设计领域提供更多的创作可能性。人工智能技术在图像生成艺术中的应用为艺术创作注入了新的能量,同时也带来了新的挑战。未来,需要更多的跨学科合作和深入研究,以更好地发掘人工智能技术在艺术创作中的潜力,推动艺术创作迈向更加智能化、多元化的未来。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.003587
{DOI}: 10.27149/d.cnki.ghdsu.2023.003587
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的镍基高温合金表面缺陷检测系统开发
{Author}: 郭慧文;刘晓鸣;陈浩天;葛良辰
{Author Address}: 南京航空航天大学机电学院;
{Journal}: 制造业自动化
{Year}: 2023
{Volume}: 45
{Issue}: 04
{Pages}: 81-87
{Keywords}: 镍基高温合金;表面缺陷;机器视觉;检测系统
{Abstract}: 在镍基高温合金棒料表面缺陷检测中，为避免人工目检方法的缺点、提高检测的效率和准确度，设计了一套基于机器视觉的镍基高温合金棒料表面缺陷检测系统。首先，采用工业相机采集棒料表面图像并采用高斯滤波方法进行图像降噪；其次，采用自适应二值化及形态学方法（如膨胀和腐蚀）对图像进行预处理，有效提取缺陷区域；然后，采用Canny边缘检测、轮廓查找等方法，对缺陷区域的边缘轮廓进行精准识别，并得到相应坐标；最后，系统通过与STM32的串口通讯，实现对相机移动和棒料旋转的节拍控制及相机位置和棒料转角的获取，并通过其与缺陷在视场中坐标的整合，最终得到棒料中所有缺陷相对于棒料原点的坐标信息。实验证明，的系统能较为准确地检测得到棒料表面的缺陷坐标信息。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzGjlJv679rRWcRkeQswcGmZG_Y0b8MpmzNGn3RZ6-DsT76G1QOkrotj_0WmVnrm5OItr81eRQjX-KZVmoyUGOZfjHWoY_btC4tYf034j7QmDQ1OVn6XSTS4xXSsecyi6laNsCSf1UU9A6n2ySw4Mkz-chvrVKcJ2qZqYlU7IfbSBqPgUKgnwW0ujEA6YZyAvI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属表面缺陷检测系统研究
{Author}: 胡皓
{Tertiary Author}: 刘爽
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 缺陷检测;现场可编程门阵列;特征提取;深度学习
{Abstract}: 随着科技的进步,当前工业界的发展趋向现代化和智能化,金属加工领域也不例外。金属表面缺陷检测在金属制造加工中扮演着重要的角色,直接影响生产的质量和效率。金属制造厂商之前通常采用人工抽检方式,此方法效率低、效果差,随着生产规模的扩大已无法满足实际需要。目前,基于机器视觉的深度学习方法逐渐成为缺陷检测领域的主流,并因其良好的通用性和灵活性被广泛运用。在深度学习方法在金属表面缺陷检测领域的实际落地中,发现仍存在如下问题:金属板材表面存在反射,不同环境光条件下对系统形成一定干扰,影响了图像采集的质量;金属板材存在小目标缺陷、大尺度缺陷、易混淆缺陷等检测难度较高的缺陷,对算法特征提取能力提出了更高要求;复杂模型巨大的参数量和计算量对运算设备提出了较高要求。为解决上述问题,本文提出了一种集成高速图像采集硬件和深度学习检测算法的金属表面缺陷检测系统设计方法。本文研究内容整体分为四个部分:(1)以FPGA为核心的图像采集硬件设计,包括环形LED光源应用、OV5640图像传感器逻辑设计、DDR3高速存储器控制以及千兆以太网传输实现,最终完成支持多种模式切换的高质量图像数据采集功能。(2)基于YOLOv5l的高性能检测模型实现,包括K-means++自适应锚框算法引入、Mish激活函数替换、ASPPFCSPCG特征提取模块引入、SGD优化器及余弦退火学习率策略调整等模型结构和训练方法的优化,最终模型的精确率达到93.27%,召回率达到90.56%,帧率达到44.2fps,缺陷检测效果良好,能够有效检测小尺度和超大尺度的缺陷。(3)基于YOLOv5s的轻量化模型设计,包括轻量化Ghost Net主干网络替换、轻量级特征提取模块RFB引入以及CA注意力机制引入,大幅降低了模型参数和计算量,改善了模型对缺陷和背景的划分能力,最终模型的精确率达到89.78%,召回率达到87.20%,帧率达到238.1fps,整体计算代价大幅降低且体积极小,为其在移动端部署提供了可能同时扩展了应用前景。(4)可视化界面的设计以及系统的稳定性测试和实际测试,结果证明本系统使用便捷,在真实场景下表现良好,具备较好的研究和实用价值。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001192
{DOI}: 10.27005/d.cnki.gdzku.2023.001192
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的单阶段目标检测算法综述
{Author}: 朱豪;周顺勇;刘学;曾雅兰;李思诚
{Author Address}: 四川轻化工大学自动化与信息工程学院;人工智能四川省重点实验室;
{Journal}: 工业控制计算机
{Year}: 2023
{Volume}: 36
{Issue}: 04
{Pages}: 101-103
{Keywords}: 目标检测;计算机视觉;深度学习;单阶段
{Abstract}: 目标检测技术是计算机视觉技术的一个热点研究方向，该技术广泛应用于车辆导航、航空及其他重要领域，发展前景广阔。将深度学习应用到图像目标检测中能够学习到图像的高级特征，弥补传统算法的不足。首先，重点介绍了基于深度学习的单阶段目标检测算法；分析了多种算法的结构和优缺点，然后对各算法做了归纳总结；最后，结合目标检测算法提出未来发展的方向与趋势。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyssVbncUZryQ66VjxrTJr3pbCklcfMez3TFtj9UNR4Tj_n2kbYqmCuxln8vm7GMikcMQQHxWJXpfe5avsNfsgfQ05wvL4Ou7YDOf6xX1yg5QRqvmoRLnjJ_x56yeGaRSqYbLqC8sSZHyU-kCx5PKTGGvqsm7YFfocEEB5B44GsSD70J5yNea0LuQXcfMZYs_c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLO v7-ECA模型的苹果幼果检测
{Author}: 宋怀波;马宝玲;尚钰莹;温毓晨;张姝瑾
{Author Address}: 西北农林科技大学机械与电子工程学院;农业农村部农业物联网重点实验室;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 06
{Pages}: 233-242
{Keywords}: 苹果幼果;检测;YOLO v7;高效通道注意力机制;机器视觉
{Abstract}: 为实现自然环境下苹果幼果的快速准确检测，针对幼果期苹果果色与叶片颜色高度相似、体积微小、分布密集，识别难度大的问题，提出了一种融合高效通道注意力(Efficient channel attention, ECA)机制的改进YOLO v7模型(YOLO v7-ECA)。在模型的3条重参数化路径中插入ECA机制，可在不降低通道维数的前提下实现相邻通道局部跨通道交互，有效强调苹果幼果重要信息、抑制冗余无用特征，提高模型效率。采集自然环境下苹果幼果图像2 557幅作为训练样本、547幅作为验证样本、550幅作为测试样本，输入模型进行训练测试。结果表明，YOLO v7-ECA网络模型准确率为97.2%、召回率为93.6%、平均精度均值(Mean average precision, mAP)为98.2%、F1值为95.37%。与Faster R-CNN、SSD、Scaled-YOLO v4、YOLO v5、YOLO v6、YOLO v7网络模型相比，其mAP分别提高15.5、4.6、1.6、1.8、3.0、1.8个百分点，准确率分别提高49.7、0.9、18.5、1.2、0.9、1.0个百分点，F1值分别提高33.53、2.81、9.16、1.26、2.38、1.43个百分点，召回率相较于Faster R-CNN、SSD、YOLO v5、YOLO v6、YOLO v7网络模型分别提高5.0、4.5、1.3、3.7、1.8个百分点；单幅图像检测时间为28.9 ms,可实现苹果幼果的高效检测。针对幼果目标模糊、存在阴影和严重遮挡的情况，本研究采用550幅测试图像进行模型鲁棒性检验。在加噪模糊情况下，YOLO v7-ECA的mAP为91.1%,F1值为89.8%,与Faster R-CNN、SSD、Scaled-YOLO v4、YOLO v5、YOLO v6、YOLO v7网络模型相比其mAP分别提高26.3、21.0、5.4、8.0、11.5、8.9个百分点，F1值分别提高27.19、7.08、8.50、4.20、3.94、4.67个百分点；在阴影情况下，YOLO v7-ECA的mAP为97.5%,F1值为95.36%,与Faster R-CNN、SSD、Scaled-YOLO v4、YOLO v5、YOLO v6、YOLO v7网络模型相比其mAP分别提高14.8、8.8、2.1、2.4、5.4、2.5个百分点，F1值分别提...
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230423.1404.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 浅谈机器视觉技术在汽车制造业中的应用
{Author}: 刘菁茹;李悦;李磊;刘久月;马丙臣
{Author Address}: 一汽模具制造有限公司;
{Journal}: 汽车工艺与材料
{Year}: 2023
{Volume}: 
{Issue}: 04
{Pages}: 7-11
{Keywords}: 机器视觉;数字化转型;引导;检测;测量
{Abstract}: 在数字化转型快速发展的时代背景下，机器视觉被广泛应用于各行各业。介绍了视觉采集方法与处理方法，在此基础上通过具体车间说明机器视觉与传统人工视觉相比的优点。在视觉引导上件、视觉引导装配、视觉检测和视觉在线测量等方面论证该方法从根本上解决了人工成本问题，使汽车制造更高质量、低成本、柔性化。
{ISBN/ISSN}: 1003-8817
{Notes}: 22-1187/U
{URL}: https://link.cnki.net/doi/10.19710/J.cnki.1003-8817.20220252
{DOI}: 10.19710/J.cnki.1003-8817.20220252
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人分拣系统设计
{Author}: 王洋洋;李国利;张曌
{Author Address}: 盐城工学院机械工程学院;金陵科技学院机电工程学院;
{Journal}: 电子设计工程
{Year}: 2023
{Volume}: 31
{Issue}: 08
{Pages}: 138-142
{Keywords}: 机器视觉;工业机器人;Socket通信;二维码;分拣
{Abstract}: 针对使用传统离线或示教编程方式工业机器人无法开展复杂分拣环境作业任务的问题，以ABB工业机器人、OMRON机器视觉、西门子S7-1200PLC等为硬件基础，搭建了基于机器视觉的工业机器人分拣系统平台。视觉系统通过识别二维码实现对物块的分类，以工业机器人控制器作为服务端、视觉控制器为客户端，采用TCP/IP协议建立Socket通信，将分类信息传递给工业机器人控制系统，从而引导机器人完成物块的抓取和分类搬运。实验结果表明，基于机器视觉搭建的工业机器人分拣系统定位精度和准确度高，可满足工业自动化生产的需求。
{ISBN/ISSN}: 1674-6236
{Notes}: 61-1477/TN
{URL}: https://link.cnki.net/doi/10.14022/j.issn1674-6236.2023.08.029
{DOI}: 10.14022/j.issn1674-6236.2023.08.029
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的表面缺陷检测方法研究进展
{Author}: 杨泽青;张明轩;陈英姝;平恩旭;方勇;吕雅丽;高岩
{Author Address}: 河北工业大学机械工程学院;河北省跨尺度智能装备技术重点实验室;天津爱思达航天科技有限公司;
{Journal}: 现代制造工程
{Year}: 2023
{Volume}: 
{Issue}: 04
{Pages}: 143-156
{Keywords}: 表面缺陷检测;机器视觉;深度学习;无监督学习
{Abstract}: 基于机器视觉的表面缺陷检测以无接触、无损伤、自动化程度高及安全可靠等突出优点被广泛应用于各种工业场景中，尤其随着深度学习技术的快速发展，视觉缺陷检测有助于提高产品及装备的智能化水平。综述分析了表面缺陷检测的常用方法、通用数据集、检测结果评价指标和现阶段面临的关键问题。首先，将缺陷检测方法分为传统基于图像处理的缺陷检测、基于传统机器学习模型的缺陷检测及基于深度学习的缺陷检测，并对各种方法进一步细分归类和对比分析，总结了每种方法的优缺点和适用场景；然后，对目前常用的缺陷检测结果评价方法做出了描述，进一步探讨了表面缺陷检测应用在实际工业产品检测过程中关键问题——小样本问题，重点剖析了小样本问题的解决方法和无监督学习在解决这类问题上的优势；最后，从提高缺陷检测方法的工业适用性角度展望了下一步研究方向。
{ISBN/ISSN}: 1671-3133
{Notes}: 11-4659/TH
{URL}: https://link.cnki.net/doi/10.16731/j.cnki.1671-3133.2023.04.020
{DOI}: 10.16731/j.cnki.1671-3133.2023.04.020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv7的小目标检测算法研究
{Author}: 陈熠名
{Tertiary Author}: 李垣江
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;YOLOv7;计算机视觉;目标检测;特征金字塔网络
{Abstract}: 近年来,小目标检测在监控、遥感和物体跟踪等领域具有广泛的应用,在计算机视觉领域也逐渐成为一个重要的研究课题。然而,由于小目标存在特征较少、分辨率低以及遮挡等问题,小目标检测仍然是一项具有巨大挑战的任务。在本文中,优化了YOLOv7的网络结构让它变成适用于小目标检测的高效方法,提出了更适合小目标检测的CTFPN特征金字塔网络,本文主要研究内容如下:
(1)针对YOLOv7在小目标检测方面的局限性,采取以下策略来改进模型的表现:首先,在网络中引入注意力模块(ECA-Net),以强化对小尺寸目标和较少特征图信息的处理能力;其次,通过调整数据增强训练策略,提升模型的适应能力,以解决YOLOv7泛化性能不足的问题;接着,针对YOLOv7激活函数收敛速度缓慢的问题,采用了表现更佳的EvoNorm来替换特征金字塔网络中的BN层,从而加速模型的收敛速度。最终在Vsidrone数据集上,AP50达到了57.5%的精确度,在VOC数据集上,m AP达到了90.7%的精确度。
(2)针对YOLOv7的特征金字塔特征提取能力有限的问题,提出了能够自适应的融合特征的特征金字塔网络CTFPN,将CNN和Transformer结合作为CTFPN的基础模块,它利用卷积运算和自注意力机制来增强表示学习。同时设计了新的特征链接模块(FLM),以消除CNN和Transformer之间的错位问题。设计了Fusion模块,为每个输入增加一个额外的自适应权重,并让网络自适应学习每个输入特性重要性。得益于CNN和Transformer的结合,局部特征和全局表示得以最大限度地保留,从而有效提高了模型整体的检测精度,同时CTFPN也能很好的替换主流的检测模型中的特征金字塔。最终在Visdrone数据集上AP达到了38.2%,AP50达到了59.3%。在COCO数据集上,AP达到了52.5%,AP50达到70.6%。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2023.001416
{DOI}: 10.27171/d.cnki.ghdcc.2023.001416
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度神经网络的多模态生成模型研究
{Author}: 周星然
{Tertiary Author}: 张仲非
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 对应关系学习;生成对抗网络;神经辐射场;生成模型;多模态模型
{Abstract}: 多模态生成模型是计算机视觉领域中一个重要的研究课题,涉及从多种输入数据生成多种输出数据。它模拟了人类对多种感官输入的整合和联想过程,被视为一种模拟人类创造过程的方法。研究多模态生成模型可以理解人类大脑对信息的处理方式,并作为探索人类创造力和想象力的工具。在这个领域中,有许多算法和解决方案,旨在提高模型的生成质量、增强多模态信息的表达和融合、优化模型的训练和推理等方面,从而推动多模态生成模型的发展和应用。本文研究的是如何从多种数据源生成高质量、逼真的图像和视频。为此,需要将来自不同数据源的信息合理地融合,在不同数据源之间建立联系,并对生成过程进行精细控制,以最终实现生成的结果符合人们的预期。多模态生成模型是一种涉及多种数据领域的模型,因此在设计中需要考虑如何合理表达和融合这些不同领域的数据,并建立起它们之间的联系。另外,作为一种生成模型,它也需要考虑如何控制生成过程,以期望的方式影响生成结果,并生成高质量、逼真的图像。因此,在多模态生成模型的研究中,不仅需要关注数据的表达和融合,还需要注重生成过程的控制和结果的优化。本文总结了多模态生成模型中的三个关键因素:多模态特征表达、跨模态融合和建立跨领域对应关系(correspondences)。在理解这三个关键因素的基础上,提出了三个研究问题:如何从文本描述中捕捉外观属性信息并对图像进行编辑;如何建立跨领域全分辨率的密集对应关系;以及如何对动态人脸进行建模并通过音频驱动生成人物讲话视频。至此,本文提出了一个多模态生成模型的研究和分析框架,该框架围绕着“三个关键因素–三个研究问题”进行开展。本文的研究根据数据不同的模态、促进跨模态间融合并建立联系、条件控制生成的三个不同角度进行讨论,分别提出了以下三个方法:基于文本指导的人物图像生成方法、图像迁移中的全分辨率对应关系学习方法、基于神经辐射场(Ne RF)的人物讲话生成方法。本论文的主要贡献如下:1.为了从文本描述中捕捉属性信息并对图像进行编辑,本文提出了基于文本指导的人物图像生成方法。本文关注通过文本编辑和生成人物图像,考虑了人物的外观属性和复杂的人体姿态几何关系,并提出了一个全新的问题设定和相应的解决方案。本文挖掘自然语言文本中的信息,建立图像和文本之间的映射关系,实现了基于文本指导的自动编辑人物图像的功能。针对该任务,本文还提出了新的感知评分作为评估指标。2.为了高效地建立起跨领域的全分辨率对应关系,本文提出了图像迁移中的全分辨率对应关系学习方法。本文提出了一种用于高效建立跨领域全分辨率对应关系的图像迁移学习方法。该方法采用分层级策略,并改进了Patch Match算法,通过迭代搜索局部最优解来逼近全局最优解。同时,引入卷积门控循环单元(Conv GRU)模块优化匹配结果,该模块考虑更大的上下文范围并将历史估计信息纳入匹配过程中。本文提出的方法可进行端到端训练,并且可扩展到更大的分辨率场景。该方法能够有效地解决学习全分辨率对应关系的难题,从而实现更好的图像迁移效果。3.为了对动态人脸建模并通过音频驱动生成,本文提出了基于神经辐射场的人物讲话生成方法。本文提出的方法利用隐式神经场景表示网络对动态人物讲话头像进行建模,可以通过音频驱动,并利用立体渲染技术生成高品质的人物讲话视频。为提高生成结果的真实感,本文采用了神经场景表示和相机校准的联合学习,以及由粗略到精细的位置编码策略。该方法支持来自不同身份的音频输入,并可进行人脸视角的编辑,具有良好的泛化性和鲁棒性。本文提出的方法拓展了神经辐射场在人脸生成与重现领域的应用。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.000495
{DOI}: 10.27461/d.cnki.gzjdx.2023.000495
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5和DeepSORT的目标检测与跟踪算法研究
{Author}: 李奇武
{Tertiary Author}: 杨小军
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多目标跟踪;YOLOv5;DeepSORT;卡尔曼滤波;匈牙利算法
{Abstract}: 多目标跟踪在计算机视觉领域中是重要的研究方向之一。深度学习技术的不断进步和社会需求对技术的驱动,多目标跟踪在智能交通、安防、无人机巡检和自动驾驶等领域发挥着极为关键的作用。在近十年,多目标跟踪算法的性能不断在提高,但在现实的复杂场景中准确检测和定位目标同时保证跟踪的鲁棒性仍然是一个值得研究的课题。本文以基于检测的行人小目标跟踪为研究主线,在已有目标检测和跟踪算法的基础上,进行针对性的改进,以提高算法的鲁棒性和准确率,本文主要研究内容如下:(1)针对复杂场景中的小尺寸目标在图像中分辨率低、难以提取到具有鉴别力的特征同时易受环境因素影响,而且现有目标检测算法大都面向常规尺寸目标设计,对小尺寸目标检测效果较差的问题,本文以YOLOv5m作为基线模型,在此基础上对网络进行针对性的设计,首先加入小尺寸目标检测层提高浅层与深层特征信息的融合,加强网络对小尺寸目标的特征的提取能力;其次通过融合CA注意力模块帮助网络定位感兴趣的目标;最后在基线模型的基础上将原来分类和定位任务耦合的检测头改进为解耦头,加快网络的收敛,提高检测精度。通过在Vis Drone2019数据集上实验可知,本文改进后的模型在Precision、Recall和m AP上都有了显著的提升,同时与目前主流的检测算法进行横向对比,充分证明了本文改进策略的有效性。(2)针对Deep SORT算法中存在的卡尔曼滤波器对所有检测目标采取统一的噪声测量尺度,没有考虑到检测质量对轨迹预测的影响,而且Deep SORT算法中数据关联策略缺少对低置信度检测框的合理利用的问题,本文首先以改进后的YOLOv5m作为多目标跟踪方法的检测器,对原Deep SORT算法的目标运动建模部分进行改进,采用噪声尺度自适应的卡尔曼滤波算法(NSA-KF)来获得更精确的运动状态;其次,采用全尺度特征提取模型OSNet替换Deep SORT中的简单的特征提取网络,来提取更具区分度的特征,缓解目标因遮挡导致的ID跳变的问题,提高跟踪的鲁棒性;最后对数据关联部分改进,提高低置信度检测框的利用,降低了漏检,提高了轨迹的连贯性。通过在Vis Drone-MOT数据集上对比实验可知,本文基于改进YOLOv5m和Deep SORT的行人小目标跟踪算法在跟踪准确度和鲁棒性上都得到了提升,体现了本文算法的有效性。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.000224
{DOI}: 10.26976/d.cnki.gchau.2023.000224
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLO v5-Lite的自然环境木瓜成熟度检测方法
{Author}: 熊俊涛;韩咏林;王潇;李泽星;陈浩然;黄启寅
{Author Address}: 华南农业大学数学与信息学院;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 06
{Pages}: 243-252
{Keywords}: 木瓜;水果成熟度检测;机器视觉;深度学习;深度卷积神经网络
{Abstract}: 利用深度学习实现视觉检测技术对自然环境下树上木瓜成熟度的识别，从而监测木瓜生长期成熟度有重要意义。针对目前木瓜的成熟度主要以人工判断为主，缺乏对木瓜成熟度快速、准确的自动检测方法问题，本研究基于轻量化YOLO v5-Lite模型，对自然环境下木瓜成熟度检测方法进行研究，通过采集的1 386幅木瓜图像，训练得到最优权值模型。实验结果表明，该模型对木瓜检测mAP为92.4%,与目前主流的轻量化目标检测算法YOLO v5s、YOLO v4-tiny以及两阶段检测算法Faster R-CNN相比，其mAP分别提高1.1、5.1、4.7个百分点；此外，在保证检测精度的前提下，检测时间为7 ms,且模型内存占用量仅为11.3 MB。同时，该模型对不同拍摄距离、不同遮挡情况、不同光照情况下的果实均能实现准确识别，能够快速有效地识别出复杂背景下木瓜果实的成熟度，具有较强的鲁棒性，可以为木瓜果园的产量估计和采摘机器的定位检测提供技术支持。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20230410.1639.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智能垃圾分类系统的设计与实现
{Author}: 邵丰宇;赵春明;姚伟健
{Author Address}: 西安电子科技大学通信工程学院;中国铁路济南局集团有限公司计量所;
{Journal}: 物联网技术
{Year}: 2023
{Volume}: 13
{Issue}: 04
{Pages}: 116-119+122
{Keywords}: 物联网;传感器;机器视觉;智能化;垃圾分类;BP神经网络
{Abstract}: 随着科技水平的不断进步,越来越多的智能化设施走进人们的生活。但在智能化垃圾分类研究方面仍然存在诸多问题,并不能满足人们对垃圾分类处理智能化的实际需要。为此,本文设计了一款以STM32L476RGT6微控制器为系统控制核心,结合数据采集模块、设备控制模块、垃圾识别模块和无线通信模块,集余量检测、智能识别、自动分类和远程通信功能于一体的智能垃圾分类系统。本系统在此基础上采用BP神经网络模型以较高准确率完成了垃圾的智能化识别,合理设计各模块使其协调有序工作,保证了垃圾分类处理操作流程的全自动化,还可以实时检测桶余量和环境易燃有害气体浓度,并将数据及时上报给用户,方便处理。通过垃圾投放测试证明了该系统在垃圾识别分类中的可靠性和有效性,具有推广应用的价值。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2023.04.033
{DOI}: 10.16667/j.issn.2095-1302.2023.04.033
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的视频人体动作识别综述
{Author}: 毕春艳;刘越
{Author Address}: 北京市混合现实与新型显示工程技术研究中心;北京理工大学光电学院;
{Journal}: 图学学报
{Year}: 2023
{Volume}: 44
{Issue}: 04
{Pages}: 625-639
{Keywords}: 动作识别;视频理解;深度学习;卷积神经网络;计算机视觉
{Abstract}: 随着网络多媒体技术的快速发展和视频采集设备的不断完善，越来越多的视频被共享到网络平台，视频逐渐占据了人类生活，因此视频理解已成为计算机视觉研究的热点之一。作为视频理解的首要任务，对动作识别的研究具有重要的意义。目前基于深度学习的二维图像识别分类方法已经取得了较大的进展，但是视频动作识别仍面临着巨大挑战。其原因在于视频和二维图像相差一个时间维度，对视频中行走、跑步、跳高和跳远等动作的理解不仅需要二维图像所具有的空间语义信息，还需要时序信息。因此，如何利用视频的时序信息对动作识别非常重要。首先介绍了动作识别的研究背景以及发展过程，分析了当前视频动作识别所面临的挑战，然后详细介绍了时序建模及参数优化的方法，分析了常用的动作识别数据集和度量参数，最后对未来的研究方向进行了展望。
{ISBN/ISSN}: 2095-302X
{Notes}: 10-1034/T
{URL}: https://link.cnki.net/urlid/10.1034.T.20230407.0944.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的手势识别系统设计与实现
{Author}: 于恒成
{Tertiary Author}: 陈正宇
{Publisher}: 盐城工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;手势识别;YOLOv5＿MediaPipe;嵌入式平台
{Abstract}: 随着信息技术的快速发展和智能终端设备的广泛使用,手势识别与手势交互因其自然直观的特性广泛应用于多种交互情景。相关研究主要集中于手势识别的可用性理论方法以及手势交互的技术应用上,而对于自然手势识别系统性的设计也同样具有重要研究价值。通过机器视觉进行手势信息的识别可以降低人工成本,对实现智能化生活具有重要意义。本文基于YOLOv5和Media Pipe Hands模型设计了一种手势识别算法,实现了手势在自然无约束状态下实时、准确检测,并在Jetson Xavier NX嵌入式平台完成系统的构建。主要工作如下:(1)为解决深度学习模型体积大、在嵌入式设备检测实时性不佳的问题。首先使用轻量化模型Shuffle Netv2替换YOLOv5中主干网络以减少模型参数量;然后在主干网络添加注意力机制以提升检测精度;最后引入CIOU损失函数提高模型训练过程的收敛速度。改进后的模型在参数量上压缩为原来的55.41%,浮点计算量压缩为原来的49.71%,在保证检测精度的同时检测速度提升了10.1FPS。(2)结合Media Pipe Hands提出了一种YOLOv5＿Media Pipe手势识别方法。该方法以上述改进的YOLOv5检测模型为基础,先将手势区域目标确定后,再通过Media Pipe Hands进行手部关键点的检测与分析,根据计算手指关键点向量角度,从而确定手指弯曲情况,进而得出手势信息。有效解决了手势在自然无约束环境下的旋转遮挡、光照背景不同时现有方法存在识别率低、泛化性差等问题。同时,制作了与所提方法相关联的12000张手势数据集,包含自建手势6000张图片和公开数据集6000张图片,并充分考虑了不同角度、不同拍摄距离、不同遮挡程度和不同光照背景等因素,极大增强了模型识别的鲁棒性。最后在自制数据集和公开数据集上进行实验验证,证实了所提方法的有效性。(3)针对当前新冠疫情、甲型流感反复不确定形势,为避免使用公共设施引发交叉感染的风险。基于Jetson Xavier NX嵌入式平台设计了一个电梯内无接触式手势控制系统。该系统通过摄像头读取视频流,将视频流解码后输入所提的YOLOv5＿Media Pipe模型进行推理,系统采用多线程的方式实现,可将读取视频流和模型推理同时进行。并使用Tensor RT优化系统检测性能,其通过降低计算精度和精简模型结构的方式,大幅提升了模型在嵌入式平台的检测速度,以达到实时性检测的目的。经测试,本文设计的系统在Jetson Xavier NX嵌入式平台上的检测速度达到30.2FPS,检测精度均值m AP@0.5为98.3%,实现了电梯内手势识别场景的准确、实时检测,具有极大的实际应用价值。
{URL}: https://link.cnki.net/doi/10.44381/d.cnki.gycit.2023.000179
{DOI}: 10.44381/d.cnki.gycit.2023.000179
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉与工业机器人的废旧塑料瓶分拣系统设计
{Author}: 王洋洋
{Tertiary Author}: 李国利
{Publisher}: 盐城工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 废旧塑料瓶;机器视觉;分拣系统;工业机器人;末端执行器
{Abstract}: 随着国民经济的日益增长,我国每年消费的塑料瓶数量逐渐增加,大多数的塑料瓶是通过掩埋的方式自然降解,这会对环境造成较大的污染。不同颜色的塑料瓶经过回收处理可以取代石油来生产不同颜色的聚酯化纤产品,而目前工厂对塑料瓶回收还是采用的人工方式,该方式分拣效率低下,在恶劣的环境下也会对人体造成极大的伤害。为提高塑料瓶回收的分拣效率,本文设计了基于视觉与工业机器人的废旧塑料瓶分拣系统。本文围绕图像预处理、塑料瓶形状特征、颜色识别以及目标定位进行研究,并设计新型末端执行器,利用PLC作为系统控制核心,工业机器人作为分拣机构完成系统的设计。本文的研究工作内容如下:(1)实际情况中塑料瓶通过料斗进入传送带可能会出现重叠现象,塑料瓶重叠会对图像识别造成干扰。本文提出了一种基于轮廓边界像素点集的形状特征描述子,利用Sobel边缘检测算子以及Moore追踪算法对塑料瓶轮廓边界的像素点进行提取,像素点集经过等间隔采样将其坐标转换到极坐标系下,并对其归一化处理,使得提取到的形状特征在旋转、缩放和平移的情况下保持不变。将单独塑料瓶与重叠塑料瓶的形状特征描述子建立样本库对传送带上的塑料瓶进行形状匹配,完成对重叠塑料瓶的筛选,避免重叠塑料瓶对颜色识别的干扰。(2)为了降低瓶身液体残留以及瓶身表面凹凸不平造成的反光影响,本文采用K-means聚类算法对经过滤波降噪处理的图像进行颜色聚类,颜色量化成绿色、蓝色和透明3种颜色,得出每种颜色在调色板中的标准值,利用塑料瓶身每种颜色像素点的数量占比来描述塑料瓶颜色。(3)由于塑料瓶的形状和大小各异,不同尺度的塑料瓶特征根本不同,导致对小型塑料瓶的定位精度较低。本文采用YOLOv3目标定位算法对图像中的塑料瓶进行定位,采用两种尺度由浅到深对塑料瓶进行特征提取,浅层特征用来定位小型塑料瓶,深层特征用来定位大型塑料瓶,得出预测框后,使用非极大值抑制算法去除图中多余预测框,得到塑料瓶位置。(4)为了使分拣装置成功将塑料瓶抓取,本文设计了一种“L”型手指与吸盘相结合的末端执行器,先利用吸盘接触塑料瓶表面,待塑料瓶被吸附起后,“L”型手指闭合夹持塑料瓶。本文利用Solid Works画出末端执行器的模型,并将其导入ADMAS中建立虚拟样机,验证末端执行器的可行性。(5)搭建试验平台,对形状匹配与颜色识别进行实验。试验表面,塑料瓶形状匹配的准确率达到95.37%,总体颜色识别的准确率达到了97.42%,满足工厂实际需求。
{URL}: https://link.cnki.net/doi/10.44381/d.cnki.gycit.2023.000209
{DOI}: 10.44381/d.cnki.gycit.2023.000209
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv4的轻量化菠萝苗心检测算法
{Author}: 张日红;区建爽;李小敏;凌轩;朱政;侯炳法
{Author Address}: 仲恺农业工程学院机电工程学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 04
{Pages}: 135-143
{Keywords}: 机器视觉;图像处理;菠萝催花;目标检测;深度可分离卷积;GhostNet;YOLOv4
{Abstract}: 当前菠萝催花作业以人工喷洒为主，生产效率低、劳动强度大。菠萝苗心位置的精准识别和定位是实现机械化、智能化菠萝催花的核心问题。该研究在YOLOv4目标识别算法的基础上，选择GhostNet作为主干特征提取网络，构建了一种混合网络模型，并在颈部网络中融合深度可分离卷积与轻量级的注意力模块。改进后的模型相较于YOLOv4模型的总参数量减少70%。与YOLOv4、Faster R-CNN和CenterNet 3个模型进行检测对比试验，结果可得：改进模型在菠萝植株种植密集与稀疏的条件下识别精度分别为94.7%和95.5%，实时识别速度可达27帧/s，每张图像平均检测时间为72 ms，相比常规YOLOv4模型用时缩短23%。总体性能表现均优于对比组的目标检测模型。总的来说，改进模型YOLOv4-GHDW在一定程度上实现了检测速度、识别精度和模型体量三者之间平衡，能够在实际种植环境下对菠萝苗心有较好的识别效果。研究结果可为智能化菠萝精准催花设备研发提供视觉技术支持。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.s.20230320.1757.038
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与Faster-RCNN的Delta机器人工件识别检测
{Author}: 张宇廷;王宗彦;李梦龙;赵鹏宇
{Author Address}: 中北大学机械工程学院;山西省起重机数字化设计工程技术研究中心;
{Journal}: 机床与液压
{Year}: 2023
{Volume}: 51
{Issue}: 05
{Pages}: 35-40
{Keywords}: 并联机器人;深度学习;Faster R-CNN;图像处理
{Abstract}: 针对传统并联机器人在工作环境中存在抓取不精确、定位与分类识别效率低下的问题，提出一种基于机器视觉与Faster-RCNN神经网络的工件识别检测技术。采用Delta机器人实验平台采集图像，进行图像的预处理操作并将其添加至网络训练集。通过Python3.7-torch1.7搭建深度学习中的Faster R-CNN卷积神经网络，作为基本框架训练工件图像数据集。最后将训练后的卷积神经网络得到的工件检测结果与原实验工件识别系统对比。结果表明：改进后的识别平均精确度比原有识别系统有所提高，反应时间缩短，并且能识别不同类型的工件。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzqwMN904F3n6kT_rCjszCkIH18icm_OWT3m68pLPgB55L-u08gr9jEbd1OIesWuoJkVtnzlyj4qAegzv9gS_Rs445WpE5aZurSRWGah6UQ_WZ1q11dowgofjuaMX8ddGCCNfeHBKMgG9rr08hmQOvEX0E8O5SXVCgnjnv4QLOf9p7R9vckPWvMAW4qyQ9KWKk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的石榴品质自动分级方法
{Author}: 罗山;侯俊涛;郑彬
{Author Address}: 攀枝花学院电气信息工程学院;攀枝花学院智能制造学院;
{Journal}: 中国农机化学报
{Year}: 2023
{Volume}: 44
{Issue}: 03
{Pages}: 117-122
{Keywords}: 机器视觉;石榴;品质分级;表面缺陷;色差分量
{Abstract}: 采用人工检测的石榴外观品质等级分级方法存在准确率和效率低的问题，提出一种基于机器视觉的石榴品质分级方法。首先，采用机器视觉系统采集石榴样本图像，进行去噪处理与获取掩模图像；其次，提取去噪图像的红、绿、蓝分量，用蓝色分量减去红、绿色分量得到色差图像，并对色差图像进行阈值分割；然后，对分割图像采用数学形态学处理获得连通的疑似缺陷区域的边界，提取纹理特征并根据缺陷与非缺陷区域纹理特征的不同来标记缺陷区域；最后，将缺陷面积与总面积之比和缺陷数目作为划分等级的依据，对石榴品质等级进行划分。试验结果表明：本方法总体分级准确率达到92.9%，能够高效、准确地识别石榴表面缺陷并进行品质分级，为实现自动分级的产业化提供思路。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2023.03.017
{DOI}: 10.13733/j.jcam.issn.2095-5553.2023.03.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进的YOLOv5的户外垃圾检测识别
{Author}: 陈胜选;王爱民
{Author Address}: 东南大学仪器科学与工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 22
{Pages}: 78-85
{Keywords}: 机器视觉;图像处理;目标检测;垃圾识别;神经网络训练;热力图
{Abstract}: 随着垃圾污染问题日益严重，垃圾自动检测识别具有越来越重要的应用价值。改进了YOLOv5算法，提升了对户外复杂背景下垃圾的检测性能，收集了6个类别的户外常见垃圾的图片，建立了一个背景复杂的垃圾图片数据集，提出了一种简单、高效的方法用于生成图片中垃圾目标物的简易真值热力图。基于YOLOv5网络，以真值热力图为量化标准，设计并实验得出一种用于生成垃圾目标物预测热力图的分支结构。随后，将预测热力图送回YOLOv5的backbone结构，增加目标检测网络前向传播过程中特征图的空间注意力权重，以提高整个目标检测网络的性能，改进后的网络仅增加了少量参数，生成了效果可观的预测热力图，垃圾检测的性能得到较大提升。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230309.1738.072
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多尺度融合卷积神经网络的鱼群计数系统设计与实现
{Author}: 张宇轩
{Tertiary Author}: 吴俊峰;沈鹏
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 鱼群计数;卷积神经网络;非对称卷积;空洞卷积;多尺度
{Abstract}: 我国水域面积广阔,具有丰富的渔业资源,其中鱼类资源占主要地位,具有巨大的开发利用价值,在生活中水产品类食材可以改善和丰富国民的膳食结构,提高国民的健康水平和生活质量。近年来渔业经济高速发展,已经成为我国国民经济不可或缺的重要组成部分。但是,在传统水产养殖过程中,人们很难精准的探知水域中鱼类资源的数量和密度分布,这给生态资源保护、饵料投放以及鱼苗放养带来了很大的困难,无法做到精细化的管理。因此,通过准确的获取水下鱼群的分布和数量可以有效帮助相关渔业企业快速了解当前环境下鱼类的生长情况,进一步制定可持续的捕捞计划;也可以指导企业进行科学的饵料投放,节约经济成本,减少环境污染。随着科技的快速发展,计算机视觉技术已经应用在渔业生产的许多环节之中。但是,高密度鱼群计数方面依然存在很多问题。为了解决高密度鱼群计数准确率低,本文提出了基于分列式卷积组的鱼群计数算法和基于多尺度特征提取网络的鱼群计数算法,并且设计了鱼群计数系统进行实际应用。本文主要的研究内容如下:1.在实际的鱼群计数过程中存在鱼群数量多,尺度变化大的问题。为了解决这一问题,本文提出了基于分列式卷积组的鱼群计数算法,通过滑动裁剪处理图像,减少尺度变化,同时做到保留更完整的特征信息。使用非对称卷积核代替传统卷积核,提高网络深度且大幅降低网络参数数量。在主干网络中使用卷积组增强特征提取能力。在网络后端使用空间金字塔结构获取鱼群的不同尺度特征,提高算法对鱼群的识别能力。该算法通过更精准的识别能力提高计数的精准度。2.在鱼群计数的进一步研究中,发现了高密度鱼群个体之间的遮挡,导致个体特征识别困难,同时随着卷积神经网络层数不断增加,鱼群图像分辨率不断下降,网络因此丢失鱼体的细节特征,最终共同导致网络的识别能力下降,进而影响计数精准度。因此本文提出了基于多尺度特征提取网络的鱼群计数算法。该算法可以还原图像的原始分辨率生成高质量的密度图,主干网络使用不同尺度的网络层以获取多尺度的特征信息。针对细节特征存在噪声信息的问题,利用高维特征引导模块对细节特征信息进行有效提取,剔除噪声干扰。该算法可以保留更多的细节特征,提高对遮挡鱼群的识别能力,生成的高分辨率密度图可以有效提高计数的准确率。3.为了验证提出算法的实际应用效果,设计的鱼群计数系统搭载本文提出的算法,可以对鱼群图像中鱼群数量进行计数。该系统基于python框架开发,通过引入Gradio库函数进行前端设计。该系统轻量化、可迁移,可以针对不同鱼类进行针对性的学习和计数,具有广阔的应用前景。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2023.000088
{DOI}: 10.27821/d.cnki.gdlhy.2023.000088
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的行人检测方法研究进展
{Author}: 娄翔飞;吕文涛;叶冬;郭庆;鲁竞;陈影柔
{Author Address}: 浙江理工大学信息科学与工程学院;浙江移动信息系统集成有限公司;浙江省技术创新服务中心;浙江理工大学浙江省智能织物与柔性互联重点实验室;
{Journal}: 浙江理工大学学报(自然科学)
{Year}: 2023
{Volume}: 49
{Issue}: 03
{Pages}: 318-330
{Keywords}: 计算机视觉;行人检测;图像分割;特征提取;机器学习;分类与定位
{Abstract}: 基于计算机视觉的行人检测方法可有效提高行人检测效率，已广泛应用于智慧城市、辅助驾驶等场景。文章对行人检测涉及的图像分割、特征提取、机器学习和分类与定位等方法进行了归纳，综述了各种方法的主要思想、适用性和局限性；同时介绍了行人检测算法的评价指标，对算法性能进行了分析；最后总结了行人检测方法的研究进展，并对未来的发展方向进行了展望。计算机视觉作为目标检测中的一项重要技术，在行人检测领域仍有待发展，算法结构改进、分类器优化、复杂场景下的行人检测等是未来的研究重点。
{ISBN/ISSN}: 1673-3851
{Notes}: 33-1338/TS
{URL}: https://link.cnki.net/urlid/33.1338.TS.20230331.0921.005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 红外与可见光图像特征提取及融合方法研究
{Author}: 李俊武
{Tertiary Author}: 李彬华
{Publisher}: 昆明理工大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 计算机视觉;红外光;可见光;图像融合;特征提取;目标检测
{Abstract}: 红外与可见光图像融合旨在将同一成像场景的红外模态场景表达和可见光模态场景表达相融合,以生成一幅信息量丰富且能全面表达红外与可见光模态场景的融合图像。它被广泛应用于军事侦察、遥感测量、安防监控、农业病虫检测和目标追踪等领域。传统的红外与可见光图像融合方法,通过手动设计的活动水平测量和提取特征来设计相应融合规则以适应复杂场景。虽然融合效果良好,但仍存在着信息丢失的问题。基于深度学习的红外与可见光图像融合方法,利用神经网络强大的特征表现力对源图像进行特征提取、特征融合和图像重建,并在训练中通过损失函数来约束融合图像所获取的源图像重要信息。虽然基于深度学习的融合方法实现了较理想的结果,但在训练数据集生成、模型构建和损失函数设计这三个方面仍然有较大提升空间。基于上述讨论,本文重点对红外与可见光图像进行了图像特征提取及融合方法的探索。主要研究内容概述如下:(1)针对传统小波变换存在的图像失真、边缘模糊及吉布斯(Gibbs)现象和非下采样剪切波变换存在的图像细微特征丢失问题,结合红外与可见光图像特点,本文提出了一种基于提升稳态小波变换(LSWT)与非下采样剪切波变换(NSST)二级多尺度特征分解的红外与可见光图像融合方法。首先,该方法采用LSWT和NSST算法对红外图像与可见光图像分别进行了高频和低频信息的一级和二级多尺度特征分解。其次,兼顾红外与可见光图像的自身特性和高、低频子带的特征表达,分别设计不同的融合规则。在低频部分,引入离散余弦变换(DCT)和局部空间频率(LSF)并设计DCT域的LSF自适应加权融合规则。在高频部分,结合人眼视觉特征,提出了一种改进的区域对比度融合策略。最后,进行消融实验以验证所提方法的合理性和高效性。在公共数据集上,通过与主流红外与可见光图像融合方法进行主观和客观实验比较,验证了LSWT-NSST方法融合的图像边缘清晰、目标突出、视觉感知效果良好和整体最优。(2)先前基于深度学习的图像融合方法在提取图像特征时大都采用单感受野、基于GAN的方法通常采用单判别器且其他主流融合方法未能区分多模态图像的差异信息会造成信息的丢失,本文提出了一种基于多感受野特征转移和深层注意力机制特征融合的生成对抗网络用于红外与可见光图像融合。首先,该方法在级联的源图像上采用三种经典的卷积核以提取多源图像的多尺度和多感受野的深层特征。其次,设计了一种多尺度的深层注意力融合机制,从空间和通道注意力两个方向上描述了多级感受野提取特征的重要表示,并按照层级的关注程度融合在一起。然后,该方法将编码器中的多感受野特征与解码器中的深层特征做了交互操作,在加强特征转移的同时更好地实现了特征重用。最后,采用双判别器的网络结构,迫使生成图像同时保留红外图像的强度和可见光图像的细节信息。通过模型的消融实验验证了深层注意力机制和多级卷积核特征提取的必要性和有效性。在三个公共数据集上进行定性和定量实验,表明所提出的模型与其他主流融合方法相比,在主观视觉和客观指标度量上均具有可比的融合性能。(3)先前基于深度学习的图像融合方法,大多都采用单卷积核来提取深层特征且双判别器的输入缺乏互补源图像,在特征传递和对抗过程中势必会造成信息损失,且目前大多数的红外与可见光图像融合都是基于灰度图的。基于此,本文提出了一种基于多尺度特征传递和双判别器的生成对抗网络用于红外与彩色可见光的图像融合。首先,该方法采用多个感受野在三个特征通道上提取多模态图像的多尺度和多级的深层特征。其次,将特征交互模块引入到编码器中,实以现特征在通道间的信息交互和预先融合。然后,引入新的梯度惩罚项加强Lipschitz约束,以提升模型的训练性能和稳定性。最后,采用双判别器的生成对抗网络以更好地在一个生成器和两个判别器之间实现对抗博弈。通过模型的消融实验验证了多感受野特征传递模块与主、辅助内容损失的必要性和有效性。通过在两个灰度和一个红外与彩色可见光图像公共数据集上的定性和定量分析,表明该方法的融合结果具有较好的主观和客观性能,并优于其他主流的图像融合方法。(4)通常大多数主流的图像融合方法只做主观和客观验证实验。为了验证图像融合对于后续目标检测任务的促进作用,本文设计了一个面向目标检测的实验。即,以LLVIP红外与可见光图像检测数据集为基础,设计了针对本文提出的三种融合方法及当前本领域四种主流融合方法的行人和汽车目标检测的比较实验。通过定性和定量的实验检测分析,验证了本文提出的三种融合方法可以有效地提高行人和汽车检测的精度并促进后续的计算机高级视觉任务,分析了三种融合方法的适应性。
{URL}: https://link.cnki.net/doi/10.27200/d.cnki.gkmlu.2023.000049
{DOI}: 10.27200/d.cnki.gkmlu.2023.000049
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的聚合物粒料杂质检测研究
{Author}: 赵向前
{Tertiary Author}: 杨双华;曹毅
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 杂质检测;图像异常检测;弱小目标检测;图像处理;机器视觉
{Abstract}: 机器视觉技术在化学品检测领域的应用因其自动化程度高和可重复性好的优势而快速增长。基于RGB图像的检测技术兼具空间和光谱分辨能力,可以实现特定场景下的化学品定性、定量检测。通用塑料等聚合物通常具有规律性的光谱特征,而杂质则表现出异常的光谱特征,采用光学技术测量特征的差异就能检测杂质。机器视觉技术在检测聚合物中的杂质方面需要解决两类问题,即可见光图像中的杂质信号信噪比低和检测方法对杂质信号的选择性差。本文主要研究基于通道加权的目标增强方法和基于背景统计建模的异常检测方法,并综合目标增强和异常检测方法设计杂质检测方法,实现聚合物图像中杂质信号的准确快速分析。
为解决杂质信号信噪比低的问题,本文提出了 一种结合信息量的通道加权方法,将空间分布信息与RGB图像的色彩偏差概率融合,显著增强了杂质信号与背景信号之间的对比度。通道加权实质是对原始图像作线性变换,得到原图中目标信号显著的图像成分,色彩偏差信息的引入加强了图像变换的非线性,使变换后的平均信噪比增益超过3dB。与传统图像增强方法相比,本文目标增强方法对杂质信号的选择性较高,在抑制噪声放大水平的前提下,显著提高弱小杂质目标的信噪比。
为提升检测方法对杂质信号的选择性,本文基于对杂质信号色彩偏差特征的分析,在原始图像中增加对数差分通道,构造检测算法的输入数据,提高杂质信号特征在异常统计量中的贡献比例,并解决检测方法在采样通道较少情况下的性能退化问题。杂质信号的实质是像素沿空间和通道分布的差值,因此信号强度与背景信号强度存在数量级差距,杂质特征在异常显著性计算中的贡献较小。通过构造检测算法的输入数据,检测方法在低误报率水平下取得较高的杂质查全率。误报率水平维持在0.01%时,增加差分通道可以使查全率提高20%以上,显著改善了异常检测算法对杂质信号的选择性。
针对树脂粒料生产中的检测场景,本文比较了统计异常检测方法和深度学习图像分割方法在离线数据集上的杂质检测性能。根据现场条件和图像处理速度,本文选择目标增强和异常检测方法的组合作为核心的杂质分类器,结合树脂粒料的先验知识规则设计集成分类器作为杂质检测方法,并增加目标区域提取算法以改善结果重复性和量化杂质含量。结果表明,杂质检测方法对照明条件和反光等干扰不敏感,粒料杂质的查全率和误报率达到预期精度指标。
本文展示了利用机器视觉系统对聚合物粒料中的杂质进行检测的可重复性,补充了图像异常检测方法在特定场景中分类小目标的研究。在杂质检测场景中,本文结合杂质信号的图像特征,改进了基于背景建模的异常检测方法,提高了统计异常检测方法在特定样本不平衡场景下的分类性能。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.000020
{DOI}: 10.27461/d.cnki.gzjdx.2023.000020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5的水下群体目标检测研究与实现
{Author}: 李海清
{Tertiary Author}: 于红;刘圣聪
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 水产养殖;深度学习;计算机视觉;目标检测;YOLOv5
{Abstract}: 精准的水下群体目标检测对准确获取养殖品生长状态、疾病预警以及实现精准投喂具有重要意义。真实养殖环境中,目标模糊、遮挡等问题导致水下群体检测准确率和召回率不高,影响信息获取能力。为解决上述问题,本文开展了融合先验知识、提升模糊图像特征提取能力和自适应阈值的水下群体目标检测等研究。具体研究内容及创新点如下:
1.基于改进YOLOv5和可变形卷积的水下群体目标检测模型(DCM-ATM-YOLOv5)。为解决目标受模糊背景影响的问题,提出可变形卷积模块,学习采样点的偏移,使采样点更注重对前景目标的采集,减少背景对检测的干扰,提高检测准确率。针对高密度群体互相遮挡导致的目标漏检问题,提出了自适应阈值模块,通过预测自适应的阈值,减少因固定阈值导致的漏检,以提高召回率。在真实养殖鱼群数据集上进行消融实验、不同水下目标检测模型的性能对比实验。实验结果表明,检测准确率和召回率分别为97.53%和98.09%,与先进水下目标检测模型比较,准确率和召回率均有所提升。
2.融合知识与改进YOLOv5的水下群体目标检测(KAYOLO)。为解决目标模糊带来的特征丢失问题,借鉴人类识别模糊目标时利用先验知识进行推理的做法,采用先验知识强化水下目标的特征,提高检测的准确率;针对高密度群体互相遮挡导致的目标漏检问题,提出了预测框聚合方法,聚合同一目标的预测框,减少不同目标间的影响,以提高召回率。为验证所提出方法的有效性,分别设计了消融实验、模型性能实验、模型鲁棒性实验。实验结果表明,KAYOLO的准确率和召回率分别达到了94.92%和92.21%;与YOLOv5相比,分别提高了1.29%和1.35%。结果表明,KAYOLO提升了水下群体目标的检测效果,该模型在不同数据集中都具有较强的鲁棒性。
3.鱼群检测与计数系统的设计与实现。本文设计了一套鱼群检测与计数系统,能检测并识别出多种输入数据中的鱼类目标,对结果进行展示,并统计目标数量。为满足用户在不同场景下的使用需求,添加了模型选择模块,能针对不同的需求选择不同的模型权重,提高了系统的泛用性。单一的检测算法无法快速地设置参数。因此,设计了参数设置模块,能根据给定参数对模型进行设置,简化了用户操作,提高了使用效率。添加了输入选择模块,对不同的数据设计不同的处理方式,提高系统的泛用性。结果展示模块将预测结果与原始输入一同展示,以突出检测结果,并引入了计数功能,对预测结果中的目标个数进行统计,方便后续的统计等操作。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2023.000146
{DOI}: 10.27821/d.cnki.gdlhy.2023.000146
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度迁移学习的脉冲涡流热成像裂纹缺陷检测
{Author}: 郝柏桥;范玉刚;宋执环
{Author Address}: 昆明理工大学信息工程与自动化学院;昆明理工大学云南省人工智能重点实验室;浙江大学控制科学与工程学院;
{Journal}: 光学学报
{Year}: 2023
{Volume}: 43
{Issue}: 04
{Pages}: 146-154
{Keywords}: 机器视觉;无损检测;脉冲涡流热成像;迁移学习;非负矩阵分解;YOLO v5
{Abstract}: 提出一种迁移学习与深度学习相结合的钢板裂纹缺陷检测方法。首先，通过非负矩阵分解（NMF）建立红外缺陷数据集的目标域特征空间，以余弦相似度为衡量指标选取可见光缺陷数据集的源域样本，对深度学习模型进行预训练，并将模型权重参数迁移至目标域，实现相似领域的知识迁移；然后，在YOLO v5算法基础上引入自适应空间特征融合（ASFF）模块，提高缺陷检测精度。实验结果表明：所提方法对钢板脉冲涡流热成像裂纹缺陷的检测精度达到98.6%，可实现不同长度裂纹的准确识别与定位。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyFAlGOxvrx6ptHrNy1CxiTEMHUuTOg6gMMdsmGPlTMGALzdp9cRIDjyim7feEgNz_4GeDm7vwtieACPFZH3vqLTUHw3x58fhG_DWoD9FrL5xNBW-P5beC1DIlgN0XHiOKKq17rZ3y4dxiLUBxJPF542uthFU-bA2ZIGTNmDi2br0fpf--c9RceMSaeErRy2sY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 金属棒材表面缺陷的机器视觉检测方法研究
{Author}: 马晓雄;熊晓燕;兰媛;乔葳
{Author Address}: 太原理工大学机械与运载工程学院;新型传感器与智能控制教育部(山西省)重点实验室;
{Journal}: 机械设计与制造
{Year}: 2023
{Volume}: 
{Issue}: 04
{Pages}: 196-200+205
{Keywords}: 金属棒材;缺陷检测;机器视觉;非下采样剪切波变换
{Abstract}: 针对传统金属棒材表面缺陷人工检测方法速度慢、效率低，工作环境差，且工人长时间工作导致的视觉疲劳会造成漏检，错检的问题，提出一种计算量小且稳定性高的检测算法。首先，采用同态滤波与CLAHE对使用检测系统采集的原始图像进行预处理；然后，利用保持平移不变性的非下采样剪切波变换（NSST）对预处理后的图像进行分解，对分解得到的高频成分采用各向异性扩散与改进的自适应gamma校正进行滤波与图像增强；同时，将低频成分与二维高斯函数作卷积运算，从而达到均匀背景的目的；最后通过NSST重构可得到质量较高的原始图像，结合形态学运算及Sobel算法实现划痕缺陷数量、尺寸及位置的检测。实验表明，算法的缺陷检测准确率为93.8%，平均检测时间为0.673s，可满足工业要求。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20230222.011
{DOI}: 10.19356/j.cnki.1001-3997.20230222.011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Harris与SURF特征点检测的手术器械机器视觉识别方法
{Author}: 陈贤儿;梁丹;傅云龙;梁冬泰;刘涛
{Author Address}: 宁波大学机械工程与力学学院;
{Journal}: 传感器与微系统
{Year}: 2023
{Volume}: 42
{Issue}: 02
{Pages}: 118-121
{Keywords}: 机器视觉;手术器械;Harris角点检测;目标识别
{Abstract}: 针对手术器械快速识别与定位需求，提出一种基于改进Harris与SURF特征点检测的手术器械机器视觉检测方法。通过MASK匀光算法消除金属表面不均匀光泽反射，并设计改进的Harris角点检测算法实现无堆叠手术器械的快速检测。利用SURF算法提取图像特征信息，采用KD-Tree搜索相似特征矢量，以实现堆叠手术器械的准确识别与定位。实验结果表明：本文方法的识别准确率和识别时间分别为92.4%和3.15 s,可有效实现典型手术器械的视觉识别与定位。
{ISBN/ISSN}: 2096-2436
{Notes}: 23-1537/TN
{URL}: https://link.cnki.net/doi/10.13873/J.1000-9787(2023)02-0118-04
{DOI}: 10.13873/J.1000-9787(2023)02-0118-04
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉与深度学习在猪只识别中的研究进展
{Author}: 刘峰;吴文杰;刘小磊;王欣然;方亚平;李国亮;杜小勇
{Author Address}: 华中农业大学信息学院/农业农村部智慧养殖技术重点实验室/农业智能技术教育部工程研究中心/湖北省农业大数据工程技术研究中心;华中农业大学深圳营养与健康研究院;中国农业科学院深圳农业基因组研究所/岭南现代农业科学与技术广东省实验室深圳分中心;农业动物遗传育种与繁殖教育部重点实验室;
{Journal}: 华中农业大学学报
{Year}: 2023
{Volume}: 42
{Issue}: 03
{Pages}: 47-56
{Keywords}: 身份识别;行为识别;深度学习;计算机视觉;智慧养殖;猪脸识别;自动监测
{Abstract}: 探索人工智能领域新技术与生猪养殖相结合，是当前智慧养殖领域的一个重要研究方向。其中，如何自动地识别猪只个体身份与行为，是当前生猪养殖行业要解决的一个关键问题。为推动计算机视觉和深度学习技术在猪只健康状态智能化监测方面的应用，本文先分析了基于计算机视觉与深度神经网络的人的身份及行为识别模型的研究进展，然后对利用计算机视觉与深度神经网络识别猪只个体身份及行为的方法进行了归纳总结，并指出已有方法中存在的问题，最后提出了下一步的重点研究方向：（1）在猪只运动不可控及关键特征部位受到污染的情况下，准确提取其身份及行为特征的方法研究；（2）针对猪只身份及行为特征的基于计算机视觉的原创性深度学习模型的研究；（3）能够同时检测猪只身份及行为的多任务神经网络的研究；（4）适用于多场景的基于基础姿态及动作的通用型猪只行为识别方法的研究；（5）基于边缘计算的猪只个体身份及行为识别的部署方法研究。
{ISBN/ISSN}: 1000-2421
{Notes}: 42-1181/S
{URL}: https://link.cnki.net/doi/10.13300/j.cnki.hnlkxb.2023.03.006
{DOI}: 10.13300/j.cnki.hnlkxb.2023.03.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习的目标检测算法改进综述
{Author}: 杨锋;丁之桐;邢蒙蒙;丁波
{Author Address}: 山东中医药大学附属医院资产设备处;山东中医药大学中医学院;中国康复研究中心医工科;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 11
{Pages}: 1-15
{Keywords}: 目标检测;深度学习;计算机视觉;注意力机制;多尺度检测
{Abstract}: 目标检测是当下计算机视觉领域的研究热点，随着深度学习的发展，基于深度学习的目标检测算法的应用越来越多，性能也不断被提升，通过总结目标检测过程中遇到的常见难题以及相应的改进方法，梳理了基于深度学习的目标检测方法的最新研究进展，重点针对基于深度学习目标检测算法的两大类型进行综述。此外还从注意力机制、轻量型网络、多尺度检测等方面对目标检测算法的最新改进思路进行总结梳理。针对当前目标检测领域存在的问题，对其未来的发展趋势进行展望，并提出可行的解决方案，以期为该领域后续的研究工作提供可借鉴的思路和方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20230214.1459.040
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的工业机器人离线编程系统的设计
{Author}: 张良安;张成鑫;谢胜龙
{Author Address}: 安徽工业大学机械工程学院;中国计量大学机电工程学院;
{Journal}: 机床与液压
{Year}: 2023
{Volume}: 51
{Issue}: 03
{Pages}: 28-34
{Keywords}: 机器视觉;工业机器人;离线编程系统;轨迹规划;机器人运动学
{Abstract}: 针对传统离线编程系统通用性差、可靠性低和二次开发难度大等问题，开发一套基于机器视觉的工业机器人离线编程系统。基于模块化思想，将该系统划分为机器视觉模块、虚拟环境模块、运动学模块、轨迹规划模块、离线程序模块和外部通信模块。借助机器视觉模块解构视觉系统与机器人末端位姿的坐标映射关系，得到规划机器人运动所需的位姿数据；基于虚拟现实建模语言构建机器人虚拟仿真环境，基于运动学模块与轨迹规划模块将位姿数据转化为机器人的作业指令；基于离线程序模块与外部通信模块实现控制器指令与虚拟仿真环境的无缝衔接。最后，以一种六轴工业机器人为测试对象验证了该离线编程系统的基本功能。实验结果表明：该系统定位误差最大为0.4 mm,精度高，可满足工业应用需求。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyUrXt0ythJl1lMVs4hL2-NFPAhrGl8P6545NTUc5vuXUeaJyk7clDuo3kzaGLh33eY3ZpURSBB9v1SdjJKt9lT5llk_8kUlTP7YAUkTCebvcuRrlDYIaZm1DAKmKaGl5ewyXcrmwNH4g3JW2RidmMr3lBuOSwPXW9Z-ZFNKJjKd1psfo-kufPj-I866R0yI7Y=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的土木基础设施裂缝检测综述
{Author}: 邓露;褚鸿鹄;龙砺芝;王维;孔烜;曹然
{Author Address}: 湖南大学工程结构损伤诊断湖南省重点实验室;湖南大学土木工程学院;
{Journal}: 中国公路学报
{Year}: 2023
{Volume}: 36
{Issue}: 02
{Pages}: 1-21
{Keywords}: 桥梁工程;基础设施裂缝检测;综述;深度学习;计算机视觉
{Abstract}: 基于深度学习的裂缝检测对于降低基础设施运营风险、节约运维成本并推进中国土木工程行业智能化转型具有重要意义。算法、数据集和评价指标是构建深度学习裂缝检测模型的关键要素；裂缝检测模型集成于机器人平台，从而实现对土木基础设施的全自动裂缝检测。为此，从以上4个方面对当前研究进行了系统梳理。首先，回顾了深度学习的发展历程，重点介绍了深度卷积神经网络在计算机视觉领域的应用及其在图像处理方面较传统算法所具有的显著优势。接着，详细介绍了3类基于深度学习的裂缝检测主流算法，包括分类算法、目标检测算法和语义分割算法。然后，对现有裂缝图像数据集以及模型性能评价指标进行了归纳。最后，总结了土木基础设施的各类裂缝检测机器人平台。综合分析表明：基于卷积神经网络主干结构的深度学习算法已被广泛用于土木基础设施表面裂缝的精准定位与分类，而裂缝的尺寸信息仍需依靠传统图像处理技术进行提取；由于像素级标注的成本和专业性高，大型的裂缝语义分割数据集相对缺乏，致使当前基于语义分割算法的裂缝检测模型鲁棒性较差；目前多数研究人员采用个人建立的裂缝数据集进行模型训练且采用不同的指标进行模型性能评价，缺乏统一的基准测试数据集和评价指标体系，无法对不同模型的性能进行平行比较；目前针对不同基础设施已相应开发了一些裂缝检测机器人，提高裂缝检测机器人的多场景适应性，并降低其应用成本是未来的发展方向。
{ISBN/ISSN}: 1001-7372
{Notes}: 61-1313/U
{URL}: https://link.cnki.net/doi/10.19721/j.cnki.1001-7372.2023.02.001
{DOI}: 10.19721/j.cnki.1001-7372.2023.02.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向计算机视觉系统的对抗样本攻击综述
{Author}: 王志波;王雪;马菁菁;秦湛;任炬;任奎
{Author Address}: 武汉大学国家网络安全学院空天信息安全与可信计算教育部重点实验室;浙江大学网络空间安全学院;清华大学计算机科学与技术系;
{Journal}: 计算机学报
{Year}: 2023
{Volume}: 46
{Issue}: 02
{Pages}: 436-468
{Keywords}: 对抗样本;计算机视觉;图像分类;目标检测;人脸识别;语义分割
{Abstract}: 对抗样本攻击是近年来计算机视觉领域的热点研究方向,通过对图像添加细微的噪声,对抗样本使计算机视觉系统做出错误判断.对抗样本攻击的研究起初重点关注于图像分类任务,随着研究的深入逐步拓展到目标检测、人脸识别等更加复杂的计算机视觉任务中.然而,现有的对抗样本综述缺乏对新兴图像分类攻击方案的梳理总结以及针对目标检测、人脸识别等复杂任务攻击的分析总结.本论文聚焦于计算机视觉系统中的对抗样本攻击,对其理论与前沿技术进行了系统性的综述研究.首先,本论文介绍了对抗样本的关键概念与敌手模型.其次,分类总结和对比分析了对抗样本存在原因的三大类相关假设.再次,根据数字域与物理域两大应用场景,分类概述和对比分析图像分类系统中的对抗样本攻击技术.根据不同的敌手模型,我们进一步地将图像分类任务数字域的攻击方案划分为白盒和黑盒两种场景,并重点总结梳理了新兴的攻击类别.同时,在目标检测、人脸识别、语义分割、图像检索、视觉跟踪五类复杂计算机视觉任务上,根据适用场景分类总结各类任务中的对抗样本攻击方案.进一步地,从攻击场景、攻击目标、攻击效果等方面对于不同攻击方案进行详细地对比分析.最后,基于现有对抗样本攻击方法的总结,我们分析与展望了计算机视觉系统中对抗样本的未来研究方向.
{ISBN/ISSN}: 0254-4164
{Notes}: 11-1826/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwS95m1fEnfrhx0mYRNlTkVib5VyNmOP9waePY3xyltdszOitypmclCKPQpSW01fg0SgigVppX3fDy6gViM1MuT_l4VDcM6OsCxyGdxOrnxj5q76yLfO2mMbVssM_sy_trF1Fr7h3pC0PsxOxsl-WM7w6qjww-TRqEvQW-J6TJ0Qk2iq5FBuX6GXQPtnWCd57A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉技术和深度学习的隧道掌子面岩体裂隙自动识别方法研究
{Author}: 罗虎;Miller Mark;张睿;方勇
{Author Address}: 西南交通大学土木工程学院;四川川交路桥有限责任公司;
{Journal}: 现代隧道技术
{Year}: 2023
{Volume}: 60
{Issue}: 01
{Pages}: 56-65
{Keywords}: 掌子面图像;岩体裂隙;卷积神经网络;计算机视觉技术
{Abstract}: 对掌子面图像的裂隙识别和特征提取进行研究，首先根据隧道中光照不足和光线不均匀的特点，对掌子面图像集进行包含多种光照处理措施在内的数据增强；通过Unet网络识别掌子面轮廓，其平均交并比和平均相似度为91%和93%；利用形态学操作使掌子面轮廓边缘平滑，消除噪点。然后利用拆分-拼接策略处理高分辨率掌子面图像，通过DeepCrack网络模型迁移学习识别岩体裂隙，其平均交并比和平均相似度为61%和75%。利用Zhang-Suen算法和8邻域标记算法进一步对识别结果进行细化、骨架化和连通域分析。最后，通过控制点标记和腐蚀标记法计算每条裂隙的像素级长度和倾角。
{ISBN/ISSN}: 1009-6582
{Notes}: 51-1600/U
{URL}: https://link.cnki.net/doi/10.13807/j.cnki.mtt.2023.01.006
{DOI}: 10.13807/j.cnki.mtt.2023.01.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合注意力机制的金属锅圆柱表面缺陷检测
{Author}: 乔健;陈能达;伍雁雄;吴阳;杨景卫
{Author Address}: 佛山科学技术学院机电工程与自动化学院;季华实验室;佛山科学技术学院物理与光电工程学院;
{Journal}: 光学精密工程
{Year}: 2023
{Volume}: 31
{Issue}: 03
{Pages}: 404-416
{Keywords}: 机器视觉;特征金字塔;注意力机制;金属表面缺陷
{Abstract}: 为实现高亮反射金属圆柱形锅的自动快速检测及分拣，破解目前金属锅表面缺陷检测速度慢、效率低的技术难题，在YOLOX网络基础上引入双向特征融合网络，提出基于注意力机制的轻量化特征融合网络模型，实现计算模型的轻量化设计；同时，通过注意力机制模块对特征信息进行通道与空间的学习，有效缓解多尺度特征的语义鸿沟问题，提高了模型的检测精度；考虑网络对难易分类样本学习权重分配不平衡，设计基于衰减因子的分类损失函数；利用金属锅圆柱表面缺陷数据集完成了特征融合网络对比实验、分类损失函数对比实验和注意力机制模块位置消融实验。实验结果表明，融合注意力机制模型可有效识别6种不同形态的缺陷，测试集的平均检测精度mAP0.5达到90.92%，检测帧率达到30.84 frame/s，实现了金属锅圆柱表面缺陷的高精度快速识别与定位。
{ISBN/ISSN}: 1004-924X
{Notes}: 22-1198/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzAhx7a4UNHZQXJB3Jt7x9WmCNFRFrlSVegBjCIAkeLwUN-kvPVerr_Q60DpnVjQZNkwwvaSIxNOZcMK7SboKyLIPp7rUPYYr0vbzeSR4lr5cOL4VXWU-vDEx4U6TK-28uKsTNTmkHjg7q8WvEPlyvUycm6U-fIE-3T2QhUCWNO0J89xEidp2r7zVc-YVaBMJU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的夜间户外环境情绪感知特征研究
{Author}: 陈崇贤;李海薇;林晓玲;陈婉静;夏宇
{Author Address}: 华南农业大学林学与风景园林学院;
{Journal}: 中国园林
{Year}: 2023
{Volume}: 39
{Issue}: 02
{Pages}: 20-25
{Keywords}: 风景园林;计算机视觉;夜间;情绪感知;空间统计
{Abstract}: 现代生活方式的转变使居民夜间户外活动不断丰富，建设高质量城市夜间户外环境已成为居民生活的重要需求。户外环境已被证实与人的情绪感知存在关联，但已有研究主要关注日间环境而较少聚焦夜间环境。基于计算机视觉技术，通过采集夜间户外环境的图像数据，结合公众的情绪感知评价，并利用空间自相关与空间回归分析方法探究情绪感知在夜间户外环境的空间分布特征及其影响因素。结果表明：1）夜间低维护的蓝绿空间能使人具有更强烈的恐惧感但焦虑感较弱，而高品质的绿色空间使人产生的恐惧感和焦虑感均较弱；高密度建筑区的户外环境往往令人感到不舒畅，低密度建筑区的户外环境则能使人感到较不恐惧、舒畅和放松；2）夜间户外环境要素如绿视率、天空可视率、拥挤度、围合度及视觉可步行性在不同类型户外环境中与情绪感知的相关性存在差异。本研究为如何快速、精准地测度夜间户外环境对情绪感知的影响提供了参考，有助于建设城市夜间户外环境，以提升居民生活质量和健康福祉。
{ISBN/ISSN}: 1000-6664
{Notes}: 11-2165/TU
{URL}: https://link.cnki.net/doi/10.19775/j.cla.2023.02.0020
{DOI}: 10.19775/j.cla.2023.02.0020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾自动分拣装置
{Author}: 付丽;梁华林;冯若愚;秦瑞;李语桐
{Author Address}: 重庆大学光电技术及系统教育部重点实验室;重庆大学大数据与软件学院;重庆大学重庆大学-辛辛那提联合学院;
{Journal}: 实验技术与管理
{Year}: 2023
{Volume}: 40
{Issue}: 01
{Pages}: 123-127+159
{Keywords}: 卷积神经网络;传感器;垃圾分类;YOLOv3;ResNet
{Abstract}: 为了提高垃圾智能分拣的效率和准确度，该文设计了基于机器视觉的垃圾自动分拣装置。装置首先利用金属传感器识别金属类垃圾，然后采用YOLOv3算法对其余垃圾进行目标检测，并使用ResNet101卷积神经网络模型进行分类，训练得到的目标检测模型及图像分类模型部署在Intel i3 8145 UE平台。装置采用两个步进电机分别控制托盘和隔板，提高垃圾的投放效率。垃圾分类测试结果表明，该装置实现了垃圾的自动分类和投放，对4类垃圾的平均识别准确率为98.3%，平均投放时间为3.1 s，具有一定的推广应用价值。
{ISBN/ISSN}: 1002-4956
{Notes}: 11-2034/T
{URL}: https://link.cnki.net/doi/10.16791/j.cnki.sjg.2023.01.019
{DOI}: 10.16791/j.cnki.sjg.2023.01.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 嵌入SENet的卷积神经网络的零件缺陷检测方法
{Author}: 张雪明;茅健
{Author Address}: 上海工程技术大学机械与汽车工程学院;
{Journal}: 农业装备与车辆工程
{Year}: 2023
{Volume}: 61
{Issue}: 01
{Pages}: 94-98
{Keywords}: 缺陷检测;特征压缩激活;Unet;损失函数;机器视觉
{Abstract}: 针对回转体零件的表面倒偏角、拉伤、线形纹等缺陷检测识别效率低、误检、漏检等问题，提出一种在编码器中嵌入特征压缩激活模块的Unet网络的零件缺陷检测方法。通过建立Unet网络架构模型并嵌入SE模块实现缺陷分割，完成缺陷图像的细节特征提取。采用BCEloss和Diceloss的混合损失函数进行训练，缓解缺陷图像分类不平衡的问题。该算法与Seg Net、FCN、Unet模型对比表明，Unet-SE在准确率、召回率和F1分数3个指标中表现最优，分别为0.929 8,0.892 9,0.911 0，且测试集中具有更好的分割效果。
{ISBN/ISSN}: 1673-3142
{Notes}: 37-1433/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyzIosQTNzF3N9LrdZpMPD4jXs9YeUI77FyQqCMqJtom4jUkUjc96_SH_YZpPAKC9-hdBWXmIVz6n9bAxk80cc-aJonThTtHbjx3aBIBI249Y4MMkTusJFpB59ASfXD5lDSUAw7XfvbZ53RuL_rD9BzoT46MEbroJ_E8ecxPes82WrGXp19MwOCN2apB5aMnwE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉和人工智能的现代化发展分析
{Author}: 陈之射;尹芳晔
{Author Address}: 武昌首义学院信息科学与工程学院;
{Journal}: 中国新通信
{Year}: 2023
{Volume}: 25
{Issue}: 02
{Pages}: 36-38
{Keywords}: 机器视觉;人工智能;现代化发展;技术细节
{Abstract}: 随着数字化科技的快速发展，越来越多的人工智能技术正在向传统领域进一步渗透，手机、电脑等电子化产品已经在人们生活中屡见不鲜，同时越来越多数字化产品，也即将改变人们的生产、生活方式，并发挥着越来越重要的作用。机器视觉是人工智能领域中的重要组成部分，不仅能够代替人工视觉，完成一些不可能完成的任务，而且也可以通过图像的采集分析以及处理整合，实现工业化的集成化发展目的。本文针对机器视觉和人工智能的概念以及内容进行分析，结合细化技术发展现状，探讨其在人类社会发展以及未来工业应用中的场景及展望。
{ISBN/ISSN}: 1673-4866
{Notes}: 11-5402/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxP48pjhRM_JH0cGsaljuDkqkfiqv5mSOShrYrclJMBaaM-wvtEUMs_wewR9Hk6G6R7xHHCOH86qwFv6CIqC3uI4mvqv8cbx0gXgRQVNlTCh_yp0mDcJR29uB4Lox0zVFuSrSXCLW6yHwAhT0SdcVXzbwEp0UjUcG_CLnS8xyzp4JMOjrnkF0BxyHB45RSf5nw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的施工现场钢结构焊缝坡口识别
{Author}: 成佳明;靳慧;郑子健;蒋朗坤;罗琴丽;董凯;周军红;陈小飞
{Author Address}: 东南大学土木工程学院;东南大学江苏省工程力学分析重点实验室;中建科工集团江苏公司;中建钢构江苏有限公司;
{Journal}: 东南大学学报(自然科学版)
{Year}: 2023
{Volume}: 53
{Issue}: 01
{Pages}: 86-93
{Keywords}: 智能建造;机器视觉;图像处理;焊缝识别;误差分析
{Abstract}: 基于线结构光视觉传感技术建立了一种适用于施工现场钢结构焊缝坡口识别方法.以南京某超高层建筑钢结构为工程背景，首先设计开发了适用于施工现场的图像采集装置，通过识别算法从采集图像中截取结构光线条感兴趣区域图像；其次，提出了基于分组教学优化算法-大津法(GTO-Otsu)的图像局部阈值分割方法，实现了结构光线条与背景的有效分割；然后，构建了线性结构元素用于修复结构光线条断裂区域；最后，通过比较相邻像素点的灰度和与一阶差分值的方法提取了结构光线条中心线及特征点坐标，并建立了像素转化方法，完成特征点像素坐标的转换，实现坡口几何尺寸测量.3组施工现场钢结构焊缝坡口图像处理和识别结果表明了该方法的准确性与适用性.
{ISBN/ISSN}: 1001-0505
{Notes}: 32-1178/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw53FZ3hHWVdyOl0Imu4gl1hKSKHpgkk_lYBvI26R-3atkH32dFAr-HwlId6yR3YJffca-gHVz5kBoVD0FzI28ds3mvE8SynQafgRIdzp7Q6Vha1N9eFS8zlPIh1LiwbRg3NxD1NlejAG3f2uYIF18lXXz39KruhOV9w0lJGSvbCLKJRQl4T0F5u7I_o6szZ4s=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于内容的图像检索技术研究综述
{Author}: 杨慧;施水才
{Author Address}: 北京信息科技大学计算机学院;
{Journal}: 软件导刊
{Year}: 2023
{Volume}: 22
{Issue}: 04
{Pages}: 229-244
{Keywords}: 图像检索;CBIR;深度学习;特征提取;卷积神经网络
{Abstract}: 随着互联网、计算机和存储技术飞速发展，数字图像信息日产量呈爆炸式增长。图像检索是计算机视觉领域的热点研究方向，旨在从大规模图像数据库中检索、查询数据视觉或文本相关内容，因此如何从海量数字信息库中快速、准确地检索用户所需内容是图像检索领域亟待解决的问题。图像传统的低层与深度特征是有效描述图像的特征表示，近年来提取图像深度特征受到广泛关注，已在计算机视觉领域图像检索技术中快速发展。为此，通过结合TBIR与CBIR方法的利弊，对近年CBIR技术相关研究进行综述。首先，介绍CBIR任务及评价方法，总结当前应用于图像检索任务的各类经典数据集。然后，根据图像特征提取方法，分别从传统、深度特征方面介绍相关算法，包含了图像的全局、局部特征提取及基于深度网络模型特征提取方法。接下来，归纳跨模态、类别级、实例级等8个类型的检索技术。最后，总结目前图像检索技术中亟待解决的问题，并在此基础上分析该技术未来的研究方向。
{ISBN/ISSN}: 1672-7800
{Notes}: 42-1671/TP
{URL}: https://link.cnki.net/urlid/42.1671.TP.20230118.1313.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业生产中机器视觉技术应用现状研究综述
{Author}: 张雷
{Author Address}: 辽宁省农业机械化发展中心;
{Journal}: 农业经济
{Year}: 2023
{Volume}: 
{Issue}: 01
{Pages}: 36-37
{Keywords}: 农业生产;机器视觉;嫁接机器人
{Abstract}: 本文通过农业生产中对蔬菜嫁接机器人嫁接幼苗接缝进行自动识别、检测技术的研究，为装配机器视觉系统的全自动嫁接机器人的研制与开发提供理论基础和技术支持。
{ISBN/ISSN}: 1001-6139
{Notes}: 21-1016/F
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzwDxH1wCYfXJ8jltGE_C4AegGhJWTedA8fxW6J_9tDyMjEusQJQN3bqHyoHyreRYhasKWfdkoW3e-Sk4A145KtIF-Z_eAHOeMKcSy0N_JarMhFOj0IZe1O9TauLESTCWzLCG6wZBE8zOWDjR3_u5mwc9geonmKQQSJpHueRA3ogTs7a0HkK4PEys4ZIB1-gaM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的织物疵点检测研究进展
{Author}: 王斌;李敏;雷承霖;何儒汉
{Author Address}: 武汉纺织大学湖北省服装信息化工程技术研究中心;武汉纺织大学计算机与人工智能学院;武汉纺织大学纺织服装智能化湖北省工程研究中心;
{Journal}: 纺织学报
{Year}: 2023
{Volume}: 44
{Issue}: 01
{Pages}: 219-227
{Keywords}: 深度学习;疵点检测;纺织品;神经网络;图像分割;机器视觉
{Abstract}: 为提高疵点检测的准确性和通用性，实现使用简洁而有效的形式对织物图像的特点和疵点的本质特征进行综合表达，首先，介绍了深度学习技术，对引入了深度学习的疵点检测方法进行综述，同时对深度学习与疵点检测的内在关系进行阐述；然后，分析总结了深度学习的概念及代表性的计算模型，并对引入深度学习的疵点检测方法进行归纳、总结和分类；最后，对典型的方法进行了分析，讨论了各种方法的优缺点，并对未来的研究趋势进行了展望。指出：随着深度学习的发展，探索更加通用的检测方法是推进深度学习在织物疵点检测领域应用的努力方向。
{ISBN/ISSN}: 0253-9721
{Notes}: 11-5167/TS
{URL}: https://link.cnki.net/doi/10.13475/j.fzxb.20211105509
{DOI}: 10.13475/j.fzxb.20211105509
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像语义分割综述
{Author}: 何雨岩
{Author Address}: 三峡大学计算机与信息学院;
{Journal}: 长江信息通信
{Year}: 2023
{Volume}: 36
{Issue}: 01
{Pages}: 77-79
{Keywords}: 语义分割;计算机视觉;深度学习
{Abstract}: 图像语义分割是计算机视觉种最热门的研究方向之一，随着深度学习技术的成熟，语义分割和深度学习相融合，取得了重大的技术突破。在自动驾驶，医疗影像分割，遥感影像检测，智能机器人的领域中有着广泛的应用。首先对语义分割的网络模型进行阐述，之后是语义分割应用领域的介绍，最后对语义分割未来的研究重点进行展望。
{ISBN/ISSN}: 2096-9759
{Notes}: 42-1914/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy4SGnSqz1sygAoPqz0LlEJR0Y24aLcIeo8T2_b_T6Ud3DRx3lhL10r-BKjbQsBIIiaOPynxqKHCjsaYB4Ii6nNdSP1DFOAr8RAwGILPTdgL7Z66domy9Vn0y2oHeqJEk6nV_HrX1nOIKIpU6_EMT0rH7lm2WPTK7AQw9646EFoSTFIBOhkhKkunl84r3P5zSI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的多模态AIGC动画探究
{Author}: 欧阳春雪
{Author Address}: 四川美术学院;
{Journal}: 现代电影技术
{Year}: 2023
{Volume}: 
{Issue}: 01
{Pages}: 41-47
{Keywords}: 深度学习;多模态;AIGC;AI动画;计算机视觉
{Abstract}: 深度学习是使得人工智能具备人类学习能力的重要技术,随着数字时代的进步,人工智能生成内容(AIGC)取得巨大突破,多模态AIGC引起了艺术从业者的关注。本文主要研究基于深度学习的文本、图像、视频等多模态的转换与融合技术应用于AIGC对动画生产方式的影响。本文运用计算机视觉、自然语言处理等跨学科思维将AIGC引入动画创作分析,归纳多模态AIGC的技术模型,分析多模态AIGC动画生成的模式类型,以模型模拟结果总结归纳其存在的局限性,并对多模态AIGC用于动画内容生产的技术、内容、市场、伦理各层面的发展方向进行了探索。
{ISBN/ISSN}: 1673-3215
{Notes}: 11-5336/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzt8dzCcbtcvkYtNENufOhnIKTc4wcQtYh20ch4KzPUR7n5bbBKUkRysiOOmidTtzeyy7Bep9qHuYVKefo4V_Lw16MPmWZR3-EPS87AeKjZgMJn4xzmoHJsGqvV0-bjYRPUzKpzbr_ngrZE6ftem0Fj0t9usSS_Gp6yWK2VuHFLsPJ0uRK1nZ6ax3cy2ctjxs8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在景观与健康关系研究中的应用进展
{Author}: 陈崇贤;李海薇;侯咏淇;刘京一
{Author Address}: 华南农业大学林学与风景园林学院;
{Journal}: 风景园林
{Year}: 2023
{Volume}: 30
{Issue}: 01
{Pages}: 30-37
{Keywords}: 风景园林;计算机视觉;公共健康;深度学习;图像数据
{Abstract}: 【目的】计算机视觉技术的发展为基于图像的景观自动化判别与分析提供了新的认知视角，非常有必要系统性认识计算机视觉技术在景观与健康关系研究中的应用。【方法】基于文献检索和筛选，系统梳理分析了中国知网数据库和Web of Science核心合集数据库中发表的20篇中文文献和90篇英文文献，并总结当前的研究趋势、主要应用方向及优劣势。【结果】结果显示：1）语义分割和图像分类在景观与健康关系领域研究中的应用最为广泛；2）生理健康威胁、体力活动、心理健康效益和环境感知评估是目前主要的研究应用方向；3）已有研究存在算法局限、计算精度不足、数据获取时间滞后及缺乏动态性等问题。【结论】计算机视觉技术的应用能促进快速、精准、大规模地进行景观与健康关系评价研究，但还需要在优化目标检测算法、融入设计和后评估过程、拓展景观与社会健康关系研究及构建时序数据集等方面进一步发展。
{ISBN/ISSN}: 1673-1530
{Notes}: 11-5366/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzt8dzCcbtcvkYtNENufOhnIKTc4wcQtYg0DzTEmhRX21tg4UT-KsBio1rTnc7p3dLnrhzcFkOagvDcqeG7jX83MBuWrLcyX40ZRt1ZZYuXaOdS-Whjifs76RQFGD96MOaRb6Slr8HitPORBb5wNH1EY3AIUWf3fwWDdxXSIkRizp4hdUZEzvPOmRuuCgRbxQE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于麻雀搜索算法优化支持向量机的瓶盖装配检测研究
{Author}: 张冬至;韩栋星;毛瑞源;郗广帅
{Author Address}: 中国石油大学(华东)控制科学与工程学院;
{Journal}: 河南师范大学学报(自然科学版)
{Year}: 2023
{Volume}: 51
{Issue}: 01
{Pages}: 29-38+171
{Keywords}: 瓶盖装配检测;机器视觉;图像处理;支持向量机(SVM);麻雀搜索算法(SSA)
{Abstract}: 针对基于支持向量机的瓶盖装配检测算法准确度不高、调参难度大的问题，提出通过麻雀搜索算法(Sparrow Search Algorithm, SSA)对支持向量机(Support Vector Machines, SVM)的关键参数寻找最优解.采集瓶盖部位图像，包括标准、歪斜、铝塑分离、胶塞缺失、高盖5种类型.提取6个典型特征构建数据集，采用二分类支持向量机分类，分别通过遗传算法、粒子群算法和麻雀搜索算法对支持向量机参数进行调节.训练结果表明，麻雀搜索算法优化后的支持向量机模型测试准确率达到98.33%,高于其他几种算法.基于SSA-SVM的瓶盖装配检测模型识别精度高，调参速度快，泛化能力强.
{ISBN/ISSN}: 1000-2367
{Notes}: 41-1109/N
{URL}: https://link.cnki.net/doi/10.16366/j.cnki.1000-2367.2023.01.004
{DOI}: 10.16366/j.cnki.1000-2367.2023.01.004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于时空混合Transformer的视频超分辨率研究
{Author}: 陆晨燕
{Tertiary Author}: 丁勇
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视频超分辨率;轨迹注意力;Transformer;计算机视觉;深度学习
{Abstract}: 视频超分辨率旨在将模糊的低分辨率视频重建为高分辨率视频,在视频监控和电影游戏等领域都有重要的应用价值。基于深度学习的视频超分方法的核心在于如何有效提取时间和空间特征信息,但是目前的视频超分模型在有效利用整个视频序列的时空依赖性等方面仍然存在巨大挑战,缺乏对长视频序列时空信息的有效建模、无法解决遮挡和边界问题,阻碍着视频超分性能进一步提升。针对这些问题,本文基于时空混合Transformer开展高性能视频超分辨率研究,提出了两种视频超分方法:
(1)基于可变形互注意力的轨迹Transformer视频超分方法。针对现有方法无法充分利用长视频序列的时空信息进行有效建模以及视频超分中存在的遮挡和边界问题。本文针对性地提出了一种基于可变形互注意力的轨迹Transformer视频超分方法。首先,通过时间轨迹沿着预先确定的运动路径聚集同一区域在不同时刻的信息,使模型能够利用远距离帧中的信息来恢复重建图像所需的纹理细节。其次,利用可变形互注意力隐式对齐前后帧,补充当前帧图像重建所需的信息,能够有效缓解视频中出现的物体遮挡和边界问题。实验定量结果PSNR相较于目前性能最佳的Transformer模型提升了近0.6d B,通过可视化图像定性结果证明本方法能够恢复锐利的边缘和清晰的细节。
(2)基于向量块选的轨迹Transformer视频超分方法。全局的注意力计算中不可避免地会引入部分不利于视频恢复的信息,这会直接导致特征在传播过程中不断累积误差并会扩大噪声的干扰。因此,本文提出了一种基于向量块选的轨迹Transformer视频超分方法。在空间特征提取过程中引入向量块选的策略来筛选出对视频帧重建有效的区域,将不利区域对恢复图像质量的影响最小化。同样在时间建模上,利用选择策略自适应地保留轨迹上的vision-token,提高模型的鲁棒性。实验证明,本方法在各大主流数据集上的性能表现均超过了现有的方法,PSNR结果相较于目前性能最佳的Transformer模型提升了0.94d B。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.000188
{DOI}: 10.27461/d.cnki.gzjdx.2023.000188
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的视觉多目标跟踪研究综述
{Author}: 伍瀚;聂佳浩;张照娓;何志伟;高明煜
{Author Address}: 杭州电子科技大学电子信息学院;浙江省装备电子重点实验室;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 04
{Pages}: 77-87
{Keywords}: 多目标跟踪;计算机视觉;目标检测;特征提取;数据关联
{Abstract}: 多目标跟踪(MOT)旨在从给定视频序列中输出所有目标的运动轨迹并维持各目标的身份。近年来，由于其在学术研究和实际应用中具有巨大潜力，因此受到越来越多的关注并成为计算机视觉的热点研究方向。当前主流的跟踪方法将MOT任务拆分为目标检测、特征提取以及数据关联3个子任务，这种思路已经得到了良好的发展。然而，由于实际跟踪过程中存在遮挡和相似物体干扰等挑战，保持鲁棒跟踪仍是当前的研究难点。为了满足在复杂场景下对多个目标准确、鲁棒、实时跟踪的要求，需要对MOT算法作进一步研究与改进。目前已有关于MOT算法的综述，但仍存在总结不够全面及缺少最新研究成果等问题。因此，首先介绍了MOT的原理及挑战；其次，通过总结最新的研究成果对MOT算法进行了归纳和分析，根据各类算法为完成3个子任务所采用的跟踪范式将其分为三大类，即分离检测与特征提取、联合检测与特征提取及联合检测和跟踪，并且详细说明了各类跟踪算法的主要特征；然后，将所提算法与当前主流算法在常用数据集上进行了对比分析，讨论了当前算法的优缺点及发展趋势，展望了未来的研究方向。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20221228.1145.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人工智能的计算机视觉研究领域发展现状研究——基于多种可视化工具的比较分析
{Author}: 肖文芳;黄稚霆;欧俊宏;刘浩鹏;黄诗琪
{Author Address}: 广东医科大学生物医学工程学院;
{Journal}: 科技创新与应用
{Year}: 2022
{Volume}: 12
{Issue}: 36
{Pages}: 27-30
{Keywords}: 人工智能;计算机视觉;CiteSpace;VOSviewer;SPSS
{Abstract}: 通过CiteSpace、VOSviewer、SPSS等可视化分析工具，对1996—2021年CNKI全文数据库中有关人工智能的计算机视觉研究领域的文献进行可视化分析。以作者、机构、关键词为分析对象，再通过对高产作者、高频关键词等的研究，分析基于人工智能的计算机视觉研究领域的发展现状，并通过阶段性分析，梳理本领域发展脉络，同时对该领域研究热点进行分析，以期为今后本领域的研究发展提供借鉴。
{ISBN/ISSN}: 2095-2945
{Notes}: 23-1581/G3
{URL}: https://link.cnki.net/doi/10.19981/j.CN23-1581/G3.2022.36.005
{DOI}: 10.19981/j.CN23-1581/G3.2022.36.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于高斯混合模型的水果分类识别方法研究
{Author}: 郑如新;孙青云;马素慧;徐鹏;程冬
{Author Address}: 南京林业大学机械电子工程学院;河北科技师范学院机电工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 12
{Pages}: 16-19
{Keywords}: 机器视觉;HALCON;分割;识别;高斯混合模型
{Abstract}: 对于水果的识别分类，目前大部分还是使用人工去完成分类，但是由于长期的重复劳动会使人工受到劳动强度和视觉疲劳的影响，容易造成错误，难以适应产业的发展。因此，为了提高水果识别分类的效率，使得水果分类能够更加的智能化、自动化，在此应用机器视觉技术针对水果识别分类展开研究。通过搭建水果图像采集平台系统，使用HALCON图像处理软件对水果进行了阈值分割和特征提取等操作，成功实现了水果与背景的分割，最后使用gmm（高斯混合模型）算法分类器对水果进行训练。实验表明：该方法能够准确有效的识别并区分出水果，在检验训练完成的分类器结果准确率为100%,100%,100%,90%,83%，验证了将高斯混合模型应用在水果分类识别方面的有效性。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyfcKAdX_hpNi1_yyhjIUglxle56_PmIw1vu9Bp7bXtAzfRxYvKL6Nx9m2oLsid-ruO4P06xOda_Gjdmt6CFfgMZ9z6ASYNtQzU1afAxR0yKTR4T4XB0Z6BAamuCH5tnlz73Ul-bpnMgZvOWcFQ9SAjpucn0WgtB-ysLYKfdVV2RyRPHhpjJPcDcbC08GzJlGc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和深度学习的建筑垃圾智能识别研究
{Author}: 许文稼;蒋庆斌;刘钢洋
{Author Address}: 常州机电职业技术学院电器工程学院;中国矿业大学化工学院;
{Journal}: 电子器件
{Year}: 2022
{Volume}: 45
{Issue}: 06
{Pages}: 1489-1496
{Keywords}: 建筑垃圾;机器视觉;目标检测;深度学习;图像识别
{Abstract}: 针对当前建筑垃圾分选中存在的分选效率不高、自动化程度较低等问题，提出了一种基于机器视觉和深度学习的建筑垃圾智能分选系统并对检测识别过程进行了详细研究。该系统采用背景建模法对建筑垃圾进行检测定位，可以有效避免运输皮带抖动、磨损和光照变化等情况，提高检测精度和定位速度。此外该系统基于ResNet卷积神经网络模型对建筑垃圾进行分类识别，并通过迁移学习方法对建筑垃圾分类模型的训练效率进行了优化，将模型的分类准确率提高到了99.47%,有助于更好地实现建筑垃圾的智能化分选。
{ISBN/ISSN}: 1005-9490
{Notes}: 32-1416/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxA0Y4RfGM_zY3N2DKG0N31XYrj-zeBNCPGn7qytRHxWp_koiSCzUmNlkObW9zGAV1CuX2M9li5OB5yxbZv89gYk5gjN2611EEPNohXdPmBkt3LnIOTrHjqh1lTjQpFBPTYS8QEh8oin3nFiXPnJikyruXdE7ZGTTfbcziQvINJ57RiWhu5ACfJyRlE_3BbGUM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在智能制造中的应用
{Author}: 刘允浩
{Author Address}: 长江大学;
{Journal}: 电子技术与软件工程
{Year}: 2022
{Volume}: 
{Issue}: 24
{Pages}: 186-190
{Keywords}: 机器视觉;智能制造;图像识别
{Abstract}: 本文通过对机器视觉技术和智能制造技术的概述，分析了机器视觉在智能制造中的具体应用。目前，科学技术水平不断发展，随之提高了工业机器人研究与使用水平，且自身特性也加速了制造行业的发展。尤其在产业制造技术精准度要求越发严格情况下，将智能机器人视觉技术植入到工业机器人当中，极大促进制造设备智能化，提高整体生产效率，及其国内经济发展水平产生积极影响。
{ISBN/ISSN}: 2095-5650
{Notes}: 10-1108/TP
{URL}: https://link.cnki.net/doi/10.20109/j.cnki.etse.2022.24.039
{DOI}: 10.20109/j.cnki.etse.2022.24.039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属表面缺陷检测方法综述
{Author}: 王慧菁;杨长辉;吕庆
{Author Address}: 重庆理工大学机械工程学院;
{Journal}: 微纳电子与智能制造
{Year}: 2022
{Volume}: 4
{Issue}: 04
{Pages}: 71-81
{Keywords}: 图像处理;缺陷检测;深度学习;金属表面
{Abstract}: 金属材料广泛应用于装备制造、机械电子等支柱性产业中,金属表面缺陷检测对工业生产中产品质量的控制至关重要,机器视觉作为自动检测技术在该方面应用甚广。本文首先对金属表面缺陷检测技术的现状进行讨论。其次,针对金属表面缺陷检测中的机器视觉方法,从传统算法和深度学习两个方面进行阐述,针对传统机器视觉方法主要讨论阈值分割、边缘检测、聚类等,并对各种方法进行对比;深度学习方法主要聚焦在缺陷检测和缺陷分割两个方面,对金属表面缺陷检测的一些主流算法和网络模型进行总结。最后,分析了机器视觉在金属表面缺陷检测中存在的困难和挑战,对未来的发展做出了展望。
{ISBN/ISSN}: 2096-658X
{Notes}: 10-1594/TN
{URL}: https://link.cnki.net/doi/10.19816/j.cnki.10-1594/tn.2022.04.071
{DOI}: 10.19816/j.cnki.10-1594/tn.2022.04.071
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 人脸微表情分析方法综述
{Author}: 于明;钟元想;王岩
{Author Address}: 河北工业大学人工智能与数据科学学院;天津商业大学信息工程学院;
{Journal}: 计算机工程
{Year}: 2023
{Volume}: 49
{Issue}: 02
{Pages}: 1-14
{Keywords}: 微表情分析;计算机视觉;微表情检测;微表情识别;深度学习
{Abstract}: 微表情分析在医学、公共安全、商业谈判等领域得到广泛应用并备受关注。微表情运动幅度小、变化快，导致人工分析难度较大，开发一个可靠的自动化微表情分析系统非常有必要。随着计算机视觉技术的发展，研究人员能够结合相关算法捕捉微表情运动变化特征以用于微表情分析。阐述微表情分析的发展历程和现状，从多个角度对微表情分析的两大分支，即微表情检测方法和微表情识别方法进行总结。整理现有微表情数据集以及微表情分析流程中常用的面部图像预处理方法。根据特征提取方式的不同，从基于时间特征、基于特征变化和基于深度特征这3个方面对微表情检测方法进行阐述。将微表情识别方法归纳为基于纹理特征和基于光流特征的传统机器学习方法以及深度学习方法，其中，基于深度学习的微表情识别包括基于运动单元、基于关键帧和基于迁移学习的方法。通过不同实验指标对以上方法进行分析和比较，在此基础上，探讨当前微表情分析中存在的问题和挑战并展望该领域未来的发展方向。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0065790
{DOI}: 10.19678/j.issn.1000-3428.0065790
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 水果采摘机器人视觉系统与机械手研究进展
{Author}: 苟园旻;闫建伟;张富贵;孙成宇;徐勇
{Author Address}: 贵州大学机械工程学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 09
{Pages}: 13-26
{Keywords}: 采摘机器人;水果收获;机器视觉;神经网络;机械手
{Abstract}: 水果采摘机器人对实现水果装备自动化智能化具有重要意义。对近年国内外水果采摘机器人领域关键技术研究工作进行总结，根据水果采摘机器人的重要组成结构与关键技术，对水果采摘机器人视觉系统的关键技术：传统基于水果特征的图像分割方法如阈值法、边缘检测法、基于颜色特征的聚类算法与基于区域的图像分割算法，基于深度学习的目标识别算法以及目标果实的定位等进行分析和对比；总结了水果采摘机器人机械臂与末端执行器的技术发展现状，指出水果采摘机器人存在的问题；对未来水果采摘机器人的发展趋势及方向进行了展望，可为水果采摘机器人相关研究提供参考。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20221213.1230.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 实例分割方法研究综述
{Author}: 黄涛;李华;周桂;李少波;王阳
{Author Address}: 贵州大学省部共建公共大数据国家重点实验室;贵州大学机械工程学院;
{Journal}: 计算机科学与探索
{Year}: 2023
{Volume}: 17
{Issue}: 04
{Pages}: 810-825
{Keywords}: 实例分割;深度学习;计算机视觉;图像分割
{Abstract}: 近年来，随着计算水平的不断提高，基于深度学习的实例分割方法的研究取得了巨大的突破。图像实例分割可以区分图像中同一类的不同实例，是计算机视觉领域的重要研究方向，具有十分广阔的研究前景，在场景理解、医学图像分析、机器视觉、增强现实、图像压缩和视频监控等方面取得了巨大的实际应用价值。近年来，实例分割方法的更新频率越来越高，但目前很少有文献全面系统地分析实例分割相关研究背景。对基于深度学习的图像实例分割方法进行了全面系统的分析与总结，首先，介绍目前实例分割中常用的公共数据集与评价指标，并对现有数据集面临的挑战进行了分析；其次，分别从两阶段分割方法与单阶段分割方法的特性上对实例分割算法进行梳理与总结，阐述其核心思想与设计思路，并对这两类方法的优势与不足进行总结；然后，在公共数据集上评估这些模型的分割精度和速度；最后，总结目前实例分割面临的困难与挑战，以及面对挑战的解决思路，并对未来的研究方向进行展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20221209.1401.002
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于深度学习的人脸表情识别研究综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2022年第二十六届网络新技术与应用年会论文集
{Author}: 钟源;李鸿天;袁家政;刘宏哲;徐成
{Author Address}: 北京联合大学北京市信息服务工程重点实验室;北京联合大学脑与认知智能北京实验室;北京开放大学科学技术学院;
{Secondary Title}: 中国计算机用户协会网络应用分会2022年第二十六届网络新技术与应用年会
{Place Published}: 中国北京
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2022
{Pages}: 4
{Keywords}: 计算机视觉;人工智能;人脸表情识别;卷积神经网络;多网络融合;多通道级联
{Abstract}: 图像、声音、文字和手势都可以用来表达人类的情感。面部表情是一种非语言交流,它揭示了一个人的内心感受和情感。随着计算机视觉和人工智能技术的发展,人脸表情识别已逐渐成为图像分类领域的研究热点。文中主要列举了几种基于深度学习的表情识别方法,包括卷积神经网络微调、多网络融合、多通道级联等,并详细阐述和比较了各种方法涉及的具体技术。最后,简要总结了人脸表情识别的研究现状,提出了人脸表情识别研究的难点和痛点,也对未来人脸表情识别领域进行了一些展望。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2022.049239
{DOI}: 10.26914/c.cnkihy.2022.049239
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 苹果外部缺陷全表面在线检测分选装置研发
{Author}: 彭彦昆;孙晨;刘乐;李阳
{Author Address}: 中国农业大学工学院;国家农产品加工技术装备研发分中心;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 23
{Pages}: 266-275
{Keywords}: 机器视觉;农产品;无损检测;苹果外部品质;在线式装置
{Abstract}: 中国是水果消费大国，但在水果产后检测装备方面相对滞后。针对目前在线检测装置无法采集苹果全表面图像信息且无法精确计算缺陷面积的问题，该研究以表面缺陷面积的快速检测为主要目标，提出苹果全表面图像合成算法，设计了一套苹果外部品质在线检测及分级装置。该研究以苹果为例，基于球模型提出苹果全表面图像合成算法、缺陷面积校正算法精确计算苹果的表面缺陷面积。通过试验验证，对苹果表面图像进行分割合成后，整体的图像的漏检率为0。提出缺陷面积校正算法，可以计算图像中位于任意位置的苹果缺陷真实面积，选取了120个样本进行验证，其中擦伤样本、碰伤样本、痘斑病样本、表面腐败样本各30个。4种表面损伤面积的预测值和真实值的决定系数R2均在0.97以上，均方根误差（Root Mean Squared Error, RMSE）在4 mm2以下。在偏角试验中，4种表面损伤面积的预测值和真实值的决定系数R2均在0.974 2以上，RMSE在6.304 4 mm2以下。装置检测苹果的速度为2个/s，评级准确率为95%。研究结果表明，检测与苹果评级精度较高，工作较为稳定，实现了苹果外部缺陷的检测与分级评价，可为苹果的外部品质检测提供技术支撑。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx81sp-sxoemFyujpx-_2c6JeeCW9U8mdByzI85ykUToLEA0MUk1AzURVwpUTlEqWKZ5HZNFYB60bPVoESCU7NOtfdK4kLBVZytVAH_mgWvAiCfp5X0_h2Ni7f2w80TkIPCiNDqCK5v5dF-x9-_QoK6eceUywvquNjS5k-zXA82yusi_IfhvcDrK4pqEoFB0RI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机械臂双目测距系统研究
{Author}: 汪凌阳;朱璠婷;蒋文萍
{Author Address}: 上海应用技术大学电气与电子工程学院;
{Journal}: 应用技术学报
{Year}: 2022
{Volume}: 22
{Issue}: 04
{Pages}: 383-387
{Keywords}: 工业机器人;机器视觉;测距;双目标定;立体匹配
{Abstract}: 针对工业机器人在非接触式的工作环境下获取目标三维信息的潜在问题，设计出了一套基于机器视觉的机械臂双目测距系统。该系统采用Matlab和OpenCV对CMOS双目工业相机进行双目标定，并根据标定得到的相机内外参数进行立体校正，然后结合双目视觉的SGBM立体匹配算法计算出相应环境下的深度信息，最后利用二维图像和深度信息辅助机械臂控制中心获取目标工件的三维信息并作出相应命令操作。根据实验分析，该测距系统测量时间短、鲁棒性好、测量精度高。
{ISBN/ISSN}: 2096-3424
{Notes}: 31-2133/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzEq24fwoheGR6VZ-cej1f56fs14cM2y4fJ4KWq4yjWY34IT7tqceneNI4dHK9jsn2I8_FSoZym5cRZFGpCXmj70MngK8rGWPXRL3pzwu5douo-wJewxodE70FttsjhYAuPNZstWVhGzaNEuT6Fb_DqpwwVFVU_ah0dhVUubdFEACbzTimhIqsyQt32XIUaKpo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的红外小目标检测关键算法研究
{Author}: 倪浩鹏
{Tertiary Author}: 钱唯
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 小目标检测;非局部模型;共生滤波;纹理分割
{Abstract}: 红外小目标检测任务的核心思路是在一组红外图像序列中定位到目标所在的位置,从而实现后续的目标跟踪任务。在以往的研究中,以Faster R-CNN和YOLO为代表的深度学习神经网络模型得到了快速发展。与此同时,一些基于局部滤波的算法也已经被证明在提高目标检测过程中的可区分度方面非常成功。但是,这些算法通过遍历局部图像来构建补丁,而忽略了不同图像区域之间的相关性,导致目标的某些纹理信息被忽略,最终会使得算法无法准确识别任意形式的目标。非局部检测算法以全局图像信息进行处理及训练,可以有效提升检测模型的鲁棒性,但该类算法存在计算量大、速度慢的缺点。为了提高在不同场景下的红外小目标检测算法的泛化性,本文提出两种改进方案,主要研究成果如下:(1)针对传统的局部红外小目标检测算法忽略不同图像区域之间相关性的问题,本文提出了基于金字塔共生特征架构的新型目标检测方法。新提出的检测框架可将红外小目标检测问题进行分解:首先通过金字塔特征架构,对输入的红外图像进行分层并提取相应的共生矩阵,再将这些共生矩阵进行融合,以更好地概括非局部空间稀疏限制。另一方面,共生矩阵保留了目标和周围区域的语义上下文信息,从而避免了低秩矩阵的偏离近似值。最后,通过结合自适应的菱形结构元素进行形态学操作,输出最终的红外小目标检测结果。(2)对于现有的深度学习显著性目标检测架构,虽然模型能够捕获更丰富的图像局部和全局信息,但是通常需要非常庞大的多样化训练数据集来训练更准确和稳健的模型。对于红外图像而言,虽然背景包含多种场景,但都会受到噪声影响,并在视觉上呈现黑灰感,总体的类别区分度并不明显。针对这一问题,我们提出基于共生图割神经网络的深度学习目标检测模型。将共生滤波作为一种可训练的卷积层,然后结合残差思想设计为共生残差块,结合进深度学习图像分割模型中,以提高训练过程中红外图像的可识别度。另一方面,在模型中引入反向注意力机制,生成相对粗略的掩膜图,然后在侧输入特征中去除当前预测的显著性区域,从而引导模型能够补充相应细节,最终融合每层的输出映射,得到最终的红外小目标检测结果。为了探讨本文提出的红外小目标检测算法性能,本文基于真实采集的红外序列图像数据集进行对比实验,包括13种红外小目标算法。通过对检测结果的主观评价和客观评估指标分析,本文所提出的红外小目标检测算法在各种复杂红外图像中能展现出良好的性能,同时保证泛化性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001462
{DOI}: 10.27251/d.cnki.gnjdc.2022.001462
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度卷积神经网络的面部表情识别研究
{Author}: 邹翔翔
{Tertiary Author}: 张昀
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 面部表情识别;深度学习;深度可分离卷积;注意力机制;Mish激活函数;AM-Softmax
{Abstract}: 面部表情是人们表达情感的重要途径,近年来随着计算机领域的发展,面部表情识别成为了当前的研究热点并取得了显著的进展,可应用于人机交互、情感计算等计算机视觉领域,人工智能和深度学习的发展则更好地促进了面部表情识别的研究。基于机器学习的传统面部表情识别算法采用人工的方式进行特征提取,所提取的面部表情特征存在人为因素的干扰,以至于训练完成的分类器不能有效地解释表情信息,最终导致模型泛化能力不足,识别准确率较低。深度学习算法中的卷积神经网络在面部表情识别任务中的优异性能表现吸引了众多研究学者的目光。但是现实场景中的基于深度学习的面部表情识别仍然受到人体姿势、面部不同程度的遮挡、背景环境与光线干扰等因素的影响,识别的准确率仍需进一步提高,因此本文提出一种改进的基于深度卷积神经网络的面部表情识别模型,用来提高面部表情识别的精度。具体工作和创新点如下:(1)针对传统面部表情识别模型准确率较低的问题,本文提出了两个改进的卷积神经网络模型用于对比选择。第一个模型是针对面部表情识别任务进行优化改进的VGG12网络,VGG12网络结构基于VGGNet,改变了其系统结构并添加了Dropout避免过拟合;第二个模型是基于深度可分离卷积的深度卷积神经网络(DCNN),DCNN的结构参考了VGG12中卷积块的叠加,但将其核心的卷积层替换成了深度可分离卷积层,同时搭配卷积残差块的使用,使网络能够有效减少参数的情况下,能够提取多尺度上的特征信息,从而有效的保留了细节特征。通过实验发现DCNN不仅拥有更少的参数数量,而且准确率也略高于VGG12,因此,本文选择基于深度可分离卷积的DCNN作为基础特征提取网络。(2)卷积神经网络的输入数据中缺乏多样性和易于分辨的特征信息可能会影响网络的性能,导致面部表情特征提取不足,为了解决以上问题,可以在网络中引入注意力机制使其忽略图片中无关特征而专注于有效特征。因此,在DCNN模型的基础上添加了卷积块注意力模块构成了新的DCNN-CBAM网络,使网络可以依次沿着通道和空间两个维度对给定的输入特征映射计算注意力图,然后再将输入的特征映射与其注意力图相结合以完成特征的精细化从而提高网络模型的特征表达能力。在不同数据集上的实验结果表明,在DCNN网络中引入注意力机制,可以有效地提高网络的性能和识别的准确率。(3)针对Re LU激活函数会在网络训练过程中产生负值神经元坏死,以及传统的Softmax损失函数无法解决在面部表情中训练数据存在同类表情差异较大,不同类别的表情差异较小的情况,在DCNN-CBAM网络中引入了Mish激活函数和AM-Softmax损失函数。Mish激活函数可以避免神经元坏死的情况,而AM-Softmax损失函数则可以最大化类间差异,实验证明,引入Mish激活函数和AM-Softmax损失函数可以改善DCNN-CBAM的训练情况,使其具有更好的特征表达能力。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001265
{DOI}: 10.27251/d.cnki.gnjdc.2022.001265
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的deeplab v3+语义分割算法研究
{Author}: 欧晓焱
{Tertiary Author}: 葛琦
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 语义分割;自注意力;卷积神经网络;通道注意力
{Abstract}: 在人类的日常生活中,图像语义信息在非言语信息传递上,扮演着日益关键的角色。伴随卷积神经网络(CNN)以及深度学习的高速发展,语义分割(Semantic Segmentation)的研究在计算机视觉、医学图像分割和自动驾驶领域获得了丰硕的成果。但是随着卷积神经网络结构的加深,图像分割过程中的局部信息与全局信息、边缘信息和上下文信息的依赖关系不断衰减,语义分割精度结果并不理想,因此,提高语义分割信息间长期依赖关系的研究具有重要的意义。随着计算机视觉技术的不断进步,在自然语言处理(Natural Language Processing)中起着十分重要作用的注意力机制模型也被广泛运用到了语义分割当中。自注意力(Self-Attention)和通道注意力通过两种不同的方法找到语义信息之间的关联性,突出被分割物体的重要特征,以此加强深度网络结构下语义信息的长期依赖性。本文针对上述问题,基于注意力机制分别设计了自注意力模型和多层级通道注意力模型的语义分割方法。两个语义分割模型都采用编码-解码结构,在编码器中对通过深度卷积网络的高层语义特征进行空洞空间金字塔池化后进行上采样,之后再与解码器中的低层语义特征拼接,最终上采样输出。对于自注意力模型的语义分割方法,我们在高层语义特征后引入三个键值Query、Key、Value,通过对Query和Key计算权重系数,再根据权重系数对Value进行加权求和让分割模型更加关注重要信息。对于多层级通道注意力模型,我们在解码器中引入通道注意力网络,通过最大池化和全局平均池化对特征图进行重标定,以此获取跨通道的空间尺度信息。为了验证基于自注意力模型的语义分割方法和基于多层级通道注意力模型的语义分割方法的性能,本文基于Cityspaces、PASCAL VOC 2012数据集进行了实验。实验结果表明,本文设计的基于自注意力和多层级通道注意力模型的语义分割方法在Cityspaces数据集上分别达到了72.21%和73.78%的平均交并比(m Io U),提升效果明显。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001466
{DOI}: 10.27251/d.cnki.gnjdc.2022.001466
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进Openpose网络的多特征跌倒识别系统
{Author}: 徐思成
{Tertiary Author}: 李晓飞
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;跌倒检测;Openpose;深度可分离卷积;多特征融合
{Abstract}: 进入21世纪之后,中国人口老龄化在不断加剧,养老机构资源逐渐稀缺,居家养老将成为一种重要的养老方法。据相关资料显示,突发性疾病导致的异常跌倒是居家独处老人死亡的几个重要原因之一。在居家养老领域,独居老人无感跌倒检测已成为当前研究热点之一。本文基于改进的Openpose网络,设计了一种多特征融合居家老人跌倒检测算法及系统,重点研究居家养老服务的场景中,独居老人无感异常跌倒行为监测系统,一旦系统确认发生了异常,即刻将老人的位置信息和异常跌倒信息同时发送给监护人和社区医护人员,及时进行必要的救治工作,减少老人因跌倒引发的伤害。由于家庭场景环境复杂,未来居家老人数目庞大,这就要求系统具有很高的识别精度,尽量避免发生误报现象。本文在分析传统卷积神经网络和原始Openpose人体骨架信息识别网络的基础上,通过对Openpose的网络架构的改进,设计了多特征跌倒判别规则,具体内容如下:(1)阐述了跌倒检测的研究背景、意义与国内外研究现状。对深度学习的相关知识做了系统的分析,介绍了当前经典的几个卷积神经网络,指出了原始Openpose的骨架识别方法在跌倒识别上的不足,并提出了网络结构的改进方法。(2)在Openpose人体骨架信息识别网络的基础上,提出将其原主干网络VGG-19替换为深度可分离卷积神经网络类型,选用Mobile Net,同时,针对其识别精度问题在Mobile Net的基础上增加了残差结构,并改进了激活函数。(3)提出了改进跌倒检测网络,设计了一种多特征融合算法,通过归一化坐标集合到基准点的欧氏距离、人体外接矩阵长宽比、特定部位夹角大小、人体关键点下降速度等四种评判特征的融合,提升了系统跌倒判别的识别精度,实验表明系统设计达到预期要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001363
{DOI}: 10.27251/d.cnki.gnjdc.2022.001363
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv3的目标检测模型研究与应用
{Author}: 过铭涛
{Tertiary Author}: 徐鹤
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;空间金字塔池化;注意力机制;半精度加速;模型剪枝
{Abstract}: 基于深度学习的卷积神经网络是当前目标检测利用的最为流行的方法之一。目标检测作为计算机视觉领域的一个重要分支,被广泛应用于自动驾驶、工业检测等生产活动中,通过目标检测算法可显著节约人力、物力成本,提高生产效率。并且目标检测是实例、全景分割等高层次计算机视觉任务的前置条件。YOLOv3作为目标检测技术中最为流行的算法之一,具有强的泛化能力。然而,当前自动驾驶领域涉及的算法存在精度差、部署难等问题,因此本文将从提高检测精度、压缩模型参数两个方面对目标检测算法进行研究,以YOLOv3为基础进行改进。本文主要工作如下:(1)在提高模型检测精度方面,本文首先采用空间金字塔池化来对图像中的局部特征和全局特征进行融合,从而更好地丰富特征图的表达能力,对于图像中大小差异较大的目标能够更加有效地检测;其次,在特征图中加入注意力机制对每个通道进行加权操作,增强关键特征,去除冗余特征,从而提高特征网络对目标物体和背景的辨别能力;最后,根据K-means聚类算法和GIoU损失函数得出的anchor box来拟合得出最终的预测框,完成对目标车辆和行人的定位与识别。实验结果表明,所提方法在KITTI数据集上达到了91.4%的m AP(精度均值),83.2%的F1分数,速度达到了45.3FPS(每秒帧数),检测性能在精度和速度上都优于传统的YOLOv3。(2)在模型压缩方面,本文首先采用Depth-Wise卷积组合而成的G-Module构建整个模型的主干网络,并在主干网络中加入注意力机制对每个通道进行加权操作,增强关键特征,去除冗余特征,从而提高特征网络对目标物体和背景的辨别能力;其次,利用Batch Normalization层中缩放因子gamma的大小将通道进行删减,达到压缩模型大小并提升运算速度的效果;最后,基于NVIDIA的Tensor RT框架进行了模型转化和半精度加速,将加速后的模型成功部署到嵌入式平台Jeston Nano上。实验结果表明,在KITTI数据集上,本章所提方法的推理速度约为原模型的5倍,参数体积缩小为十分之一。(3)设计并实现了基于改进YOLOv3模型的车辆行人目标检测原型系统。对该目标检测原型系统,分析了其使用的软硬件条件,将本文提出的改进YOLOv3模型进行实现与部署,给出了在相关数据集下该系统的识别性能测试,验证了算法的可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.000085
{DOI}: 10.27251/d.cnki.gnjdc.2022.000085
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于骨架信息的人体跌倒检测系统设计与实现
{Author}: 陈柯
{Tertiary Author}: 陈正宇;孙科学
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 骨架序列;跌倒检测;图卷积网络;姿态估计;Flask
{Abstract}: 跌倒是日常生活中常见且危险的行为,为减轻跌倒带来的危害,跌倒行为的识别检测成为智能视频监控领域中的一项重要研究课题。随着摄像头监控设备的普及和人工智能技术的发展,基于计算机视觉的跌倒检测是目前研究的热点方向,其中基于骨架信息的检测模型具有数据量小、不易受复杂背景干扰等优点,在人体行为检测方面表现出较好的鲁棒性。然而,在将该检测模型应用于跌倒检测时,在面向多人体目标的骨架序列提取,以及充分利用人体跌倒行为特征以提升检测准确率等方面仍需要进一步研究。因此本文在分析跌倒行为特征的基础上,提出了一种基于骨架信息的人体跌倒检测算法,该算法包括骨架序列数据采集和跌倒行为检测两个部分,并使用Flask技术将该方法部署于云端服务器,实现了一种BS架构的跌倒检测系统。本文的主要工作内容如下:(1)提出了一种面向多人体目标的骨架序列提取方法,该方法对实际场景中的所有人体进行检测和追踪,并分离出每个人体的骨架序列数据。首先使用目标检测算法VFNet识别并定位人体,然后使用多目标追踪算法Deep SORT对人体进行持续追踪,在追踪期间使用多人姿态估计算法HRNet提取人体骨架,最后经持续性追踪可采集到人体骨架序列数据。对于骨架序列提取过程中各阶段算法的选取,分别采用不同网络模型进行对比实验,实验结果表明VFNet、HRNet和Deep SORT是各自阶段最优的算法模型。(2)提出了一种基于改进骨架分区策略的子图加权自适应图卷积网络SI-AGCN(Subgraph＿Importance-Adaptive Graph Convolution Networks,SI-AGCN),该网络以骨架序列数据为输入进行跌倒行为判决。为降低跌倒和日常行为的混淆度而改进了骨架图的划分策略,提出三分区空间配置策略,并使用子图加权自适应图卷积替换原时空图卷积ST-GCN中的空间图卷积部分,构成本文的SI-AGCN网络。最后,以三种公开跌倒行为数据集为基础,使用姿态估计算法提取并构建跌倒骨架序列数据集Fall-skeleton Dataset,并在该数据集上进行训练和有效性验证实验,实验结果表明,相比于时空图卷积网络ST-GCN,SI-AGCN网络的跌倒检测准确率提升了6.9%,达到了96.4%。(3)采用Flask技术将本文人体跌倒检测算法部署于云端服务器,实现了一种BS架构的跌倒检测系统,该跌倒检测系统分为图像采集终端、云服务器端和Web浏览器三个部分。首先采用阿里云ECS服务器,然后通过Nginx、u WSGI和Flask技术完成跌倒检测算法部署,最后,在实际场景下测试部署后的跌倒检测系统,测试环境为三种光照情况下的单人和多人活动场景,测试结果表明本文人体跌倒检测系统均能满足跌倒检测要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.000093
{DOI}: 10.27251/d.cnki.gnjdc.2022.000093
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的苹果分拣系统研究
{Author}: 刘奇
{Tertiary Author}: 王建锋;李军
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 苹果分拣;苹果分类;迁移学习;ResNet模型;机器视觉
{Abstract}: 我国拥有非常庞大的苹果市场,近些年苹果的种植面积、苹果产量等指标都呈现出高速增长态势。但是苹果分拣技术的落后大大限制了苹果产业的发展。因此,研究基于机器视觉的苹果尺寸大小、病害分类识别方法,研究自动化的苹果分拣系统具有非常重要的现实意义。论文设计了一种基于机器视觉的苹果分拣系统。研究分拣系统的图像采集、图像处理、大小分级和病害苹果分选方法,提出苹果图像的预处理方法,实现了苹果的边缘轮廓提取,提出了基于改进霍夫变换的苹果径面检测和尺寸检测方法,实现了苹果的尺寸检测。提出基于改进Res Net101(residual network)结合迁移学习识别苹果病害识别方法。建立了苹果病害识别初始数据集,通过数据增强方法最终得到具有不同病害的6000张图像的病害数据集,在苹果数据集上对比分析了Res Net50、Res Net101、IRes Net50、IRes Net101(Improve Residual Network)模型作为改进Res Net主题网络并结合迁移学习识别苹果识别结果,最终选取了IRes Net101模型作为最终主体网络,并进行批大小、学习率等参数的优化处理。开发了具有图像存储与实时显示、图像分类处理、作业信息显示、通信等子功能模块的上位机图像处理软件与控制系统软件开发。通过试验验证了整机的工作性能,并且以精准率作为评价指标。试验结果表明IRes Net101模型相较于其他模型具有更高的识别准确率,在上料速度达到10颗/秒时,该装置分拣准确率能够达到97%,在上料速度继续增加时,准确率会产生大幅下降,这主要是由于分级执行机构存在惯性滞缓,装置可靠性下降,导致无法及时清理出缺损苹果。本文的主要研究成果可以为苹果智能化分拣技术更深入的研究提供一定的参考,为全面推广苹果智能化分拣技术提供一定的参考。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2022.000063
{DOI}: 10.27831/d.cnki.gxjxy.2022.000063
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在植物病害识别上的研究进展
{Author}: 孙亮;柯宇航;刘辉;胡义钰;冯成天;刘文波;王真辉;张宇;郑服从
{Author Address}: 中国热带农业科学院橡胶研究所/农业农村部橡胶树生物学与遗传资源利用重点实验室/省部共建国家重点实验室培育基地—海南省热带作物栽培生理学重点实验室/农业农村部儋州热带作物科学观测实验站;海南大学植物保护学院;
{Journal}: 热带生物学报
{Year}: 2022
{Volume}: 13
{Issue}: 06
{Pages}: 651-658
{Keywords}: 植物病害;计算机视觉技术;图像处理技术;深度学习
{Abstract}: 随着农业和现代化信息技术的交互、联结和碰撞，农业逐渐趋于现代化、智能化和数字化，近年来运用计算机视觉技术对植物病害进行诊断得到广泛应用，比传统方法更加迅捷、精确。分别从图像采集、图像预处理、图像分割、图像特征提取、病害识别和分类5个方面进行阐述，总结了植物病害图像识别技术的要点及存在问题，并对其未来发展进行了展望，为计算机视觉技术在植物病害识别上的应用和研究提供依据。
{ISBN/ISSN}: 1674-7054
{Notes}: 46-1078/S
{URL}: https://link.cnki.net/doi/10.15886/j.cnki.rdswxb.2022.06.016
{DOI}: 10.15886/j.cnki.rdswxb.2022.06.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的车道线检测技术研究进展
{Author}: 江漫;徐艳;吕义付;张乾
{Author Address}: 贵州民族大学数据科学与信息工程学院;贵州省模式识别与智能系统重点实验室;贵州民族大学教务处;
{Journal}: 信息技术与信息化
{Year}: 2022
{Volume}: 
{Issue}: 11
{Pages}: 21-24
{Keywords}: 车道线检测;特征提取;深度学习;计算机视觉
{Abstract}: 车道线检测是智能辅助驾驶的一项关键任务，准确且高速地检测出车道线具有重要的现实意义。文章对近年来基于计算机视觉的车道线检测方法进行了综述。首先介绍车道线检测流程，可概括为图像获取、图像预处理、车道线特征提取、车道线检测，并详细介绍了各个步骤的实现方法；其次，介绍了两种车道线特征提取方法，即传统方法和深度学习方法；接着分析和比较了四种车道检测方法，即基于分类、基于目标检测、基于图像分割、基于建模的检测方法；最后总结基于计算机视觉的车道线检测技术目前面临的机遇与挑战。
{ISBN/ISSN}: 1672-9528
{Notes}: 37-1423/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzwH1g7n81ipdSvG5tHuQArASFUWvNL0CTe6Jdi4xNY6737W0uZ-BS468HxTfhsDJoZU95YPpKufFn_lgsd3ZZ7qCJZ044kh5GJ9LGiGHR4KFyOXhkYKWQQcG07_wM5gGDJR2NkJse3lVoN0k1gUodehF33GbG7hpDmagrPEc32y8fEtpAQJ0zPQWDscEMxqjQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉中的Transformer发展综述
{Author}: 李清格;杨小冈;卢瑞涛;王思宇;谢学立;张涛
{Author Address}: 火箭军工程大学导弹工程学院;
{Journal}: 小型微型计算机系统
{Year}: 2023
{Volume}: 44
{Issue}: 04
{Pages}: 850-861
{Keywords}: Transformer;计算机视觉;自注意力机制;图像分类;目标检测
{Abstract}: Transformer是基于自注意力机制的编码器-解码器架构模型，擅长建立远距离依赖关系，已经成为自然语言处理领域的主流模型.受Transformer在自然语言处理领域中取得巨大成功的启发，近两年一些开创性的工作开始研究如何将Transformer应用于计算机视觉领域，并取得了显著的成果，目前视觉Transformer依然是研究的热点.本文对近年来Transformer在多个视觉任务上的应用与发展进行梳理、分析与总结.首先阐述了视觉Transformer基本结构与实现原理，分析了模型结构的特点与优势，梳理了视觉Transformer的研究进展.其次，介绍了Transformer在高层视觉任务、底层视觉任务和多模态任务上的典型应用模型，并详细对比了在图像分类、检测和分割领域典型视觉Transformer模型的性能指标.最后总结了当前视觉Transformer各类模型存在的问题与难点，并指出未来的发展方向.
{ISBN/ISSN}: 1000-1220
{Notes}: 21-1106/TP
{URL}: https://link.cnki.net/doi/10.20009/j.cnki.21-1106/TP.2022-0504
{DOI}: 10.20009/j.cnki.21-1106/TP.2022-0504
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 改进YOLOv5s的交通标志识别算法
{Author}: 乔欢欢;权恒友;邱文利;闫润禾
{Author Address}: 长安大学信息工程学院;河北雄安京德高速公路有限公司;
{Journal}: 计算机系统应用
{Year}: 2022
{Volume}: 31
{Issue}: 12
{Pages}: 273-279
{Keywords}: 交通标志;计算机视觉;YOLOv5s;注意力机制;Ghost
{Abstract}: 为了准确且实时地检测到交通标志指示牌,减少交通事故的发生和推动智慧交通的发展,针对现有的道路交通标志检测模型存在的精度不足、权重文件大、检测速度慢的问题,设计了一种基于计算机视觉技术的改进YOLOv5s检测算法YOLOv5s-GC.首先,使用copy-paste进行数据增强后再送入网络进行训练,加强对小目标的检测能力;然后,引入Ghost来构建网络,削减原网络的参数和计算量,实现轻量化模型;最后,将坐标注意力机制(coordinate attention)融合到骨干网络里,增强对待测目标的表示和定位能力,提高识别精度.实验结果表明,YOLOv5s-GC模型相比于原YOLOv5s模型,参数数目减少了12%,检测速度提高了22%,平均精度达到了94.2%,易于部署且能满足实际自动驾驶场景中对识别交通标志的速度和准确度要求.
{ISBN/ISSN}: 1003-3254
{Notes}: 11-2854/TP
{URL}: https://link.cnki.net/doi/10.15888/j.cnki.csa.008859
{DOI}: 10.15888/j.cnki.csa.008859
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器学习中成员推理攻击和防御研究综述
{Author}: 牛俊;马骁骥;陈颖;张歌;何志鹏;侯哲贤;朱笑岩;伍高飞;陈恺;张玉清
{Author Address}: 西安电子科技大学计算机科学与技术学院;国家计算机网络入侵防范中心中国科学院大学;海南大学网络空间安全学院;西安电子科技大学广州研究院;西安邮电大学网络空间安全学院;西安电子科技大学网络与信息安全学院;西安电子科技大学通信工程学院;中国科学院信息工程研究所信息安全国家重点实验室;中国科学院大学网络空间安全学院;
{Journal}: 信息安全学报
{Year}: 2022
{Volume}: 7
{Issue}: 06
{Pages}: 1-30
{Keywords}: 机器学习;成员推理攻击;隐私安全;防御措施
{Abstract}: 机器学习被广泛应用于各个领域,已成为推动各行业革命的强大动力,极大促进了人工智能的繁荣与发展。同时,机器学习模型的训练和预测均需要大量数据,而这些数据可能包含隐私信息,导致其隐私安全面临严峻挑战。成员推理攻击主要通过推测一个数据样本是否被用于训练目标模型来破坏数据隐私,其不仅可以破坏多种机器学习模型(如,分类模型和生成模型)的数据隐私,而且其隐私泄露也渗透到图像分类、语音识别、自然语言处理、计算机视觉等领域,这对机器学习的长远发展产生了极大的安全威胁。因此,为了提高机器学习模型对成员推理攻击的安全性,本文从机器学习隐私安全攻防角度,全面系统性分析和总结了成员推理攻击和防御的基本原理和特点。首先,介绍了成员推理攻击的定义、威胁模型,并从攻击原理、攻击场景、背景知识、攻击的目标模型、攻击领域、攻击数据集大小六个方面对成员推理攻击进行分类,比较不同攻击的优缺点;然后,从目标模型的训练数据、模型类型以及模型的过拟合程度三个角度分析成员推理攻击存在原因,并从差分隐私、正则化、数据增强、模型堆叠、早停、信任分数掩蔽和知识蒸馏七个层面对比分析不同防御措施;接着,归纳总结了成员推理攻击和防御常用的评估指标和数据集,以及其在其他方面的应用。最后,通过对比分析已有成员推理攻击和防御的优缺点,对其面临的挑战和未来研究方向进行了展望。
{ISBN/ISSN}: 2096-1146
{Notes}: 10-1380/TN
{URL}: https://link.cnki.net/doi/10.19363/J.cnki.cn10-1380/tn.2022.11.01
{DOI}: 10.19363/J.cnki.cn10-1380/tn.2022.11.01
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv3与改进VGGNet的车辆多标签实时识别算法
{Author}: 顾曦龙;宫宁生;胡乾生
{Author Address}: 南京工业大学计算机科学与技术学院;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: S2
{Pages}: 542-548
{Keywords}: 计算机视觉;车辆识别;多标签识别;目标检测;深度学习
{Abstract}: 为了能快速、有效地识别视频中的车辆信息，文中结合YOLOv3算法和CNN算法的优点，设计了一种能实时识别车辆多标签信息的算法。首先，利用具有较高识别速度和准确率的YOLOv3实现对视频流中车辆的实时监测和定位。在获得车辆的位置信息后，再将车辆信息传入经过简化与优化的类VGGNet多标签分类网络中，对车辆进行多标签标识。最后将标签信息输出至视频流，得到对视频中车辆的实时多标签识别。文中训练与测试数据集来源为KITTI数据集和通过Bing Image Search API获取的多标签数据集。实验结果证明，所提方法在KITTI数据集上的mAP达到了91.27，多标签平均准确率达到80%以上，视频帧率达到35fps，在保证实时性的基础上取得了较好的车辆识别和多标签分类效果。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyD2cF0CYazmr3ubyT7xeouINRp09UsvqyB_CTpaFLeDprJKIv8miL2KqFUjMXVnHvE77DsRv0TZDHzK7KYwaHojOCKsmFIYPNi1vYz1EP8l1p_Q-emha-NVk_T2kQOShIV5TiVv88pjcMVBsRwcAH7XH2kHKtj7bfKppyicEl6uFoyDrbPlYQwKRkmjO1uxjs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在军事领域的应用现状及发展趋势
{Author}: 陈静;宫黎明
{Author Address}: 中国人民解放军93160部队;
{Journal}: 遥测遥控
{Year}: 2022
{Volume}: 43
{Issue}: 06
{Pages}: 124-135
{Keywords}: 机器视觉;军事装备;目标识别;缺陷检测
{Abstract}: 机器视觉技术凭借其非接触测量、实时性好、可持续工作等优点，在军事领域中有着广阔的应用前景。在对机器视觉光学照明系统、成像系统、视觉信息处理系统等关键技术进行概述的基础上，详细分析了机器视觉技术在军事领域进行典型目标物识别、人员识别、装备缺陷检测等典型场景以及典型军事装备上的应用现状。在此基础上，指出了机器视觉在军事领域的应用，仍然存在视觉传感器硬件系统难以适应极端环境、复杂的军事目标适应性不足、目标识别的实时性难以保证、多传感器融合获取军事目标信息能力缺乏等问题。同时，对机器视觉技术在军事领域应用的未来发展趋势进行了展望，研究分析结果可为机器视觉在军事领域的进一步实用化提供参考。
{ISBN/ISSN}: 2095-1000
{Notes}: 11-1780/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyD2cF0CYazmr3ubyT7xeouINRp09Usvqw3MZcvn5o5Niuu-E8S-H5h1a4-KqjIvH_JSahCBYDXwwiH2XWD3HvKfcqoPfYoJtXcCSKVY07oG19RQEo7sEcj0Bhp64GbauvkXaQirAxJk_Bxq8mJpRimfN56DxZYj1YeJi8HFj5aASYo4T0futKuX1MAgbYYknE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的指针式压力表智能检定系统研究
{Author}: 伍开宇;朱海清;沈晓东;沈伟;方明
{Author Address}: 江南大学机械工程学院;嘉兴市计量检定测试院;
{Journal}: 计量学报
{Year}: 2022
{Volume}: 43
{Issue}: 11
{Pages}: 1450-1455
{Keywords}: 计量学;指针式压力表;检定系统;机器视觉;智能化;追溯复核法
{Abstract}: 针对传统的指针式压力表检定装置工作效率低、数据无法保存追溯等问题，设计了一种基于机器视觉技术的指针式压力表智能化检定系统。首先介绍了系统的硬件架构与软件设计，然后对其图像解析的技术原理与解决方案进行了阐述，同时提出了系统的智能控制流程与检定数据的追溯复核方法，实现了2～10块相同检定点的压力表同时进行计量检定的技术方案。实测结果表明，系统图像解析平均速度为467 ms/帧，检定效率较人工检定可提升2倍以上；对于量程2.5 MPa的0.4级精密压力表和1.6级一般压力表，系统读数相对误差分别为0.08%、0.2%。
{ISBN/ISSN}: 1000-1158
{Notes}: 11-1864/TB
{URL}: https://link.cnki.net/urlid/11.1864.TB.20221111.1659.036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 表面缺陷检测的机器视觉技术研究进展
{Author}: 程锦锋;方贵盛;高惠芳
{Author Address}: 杭州电子科技大学电子信息学院;浙江水利水电学院机械与汽车工程学院;
{Journal}: 计算机应用研究
{Year}: 2023
{Volume}: 40
{Issue}: 04
{Pages}: 967-977
{Keywords}: 缺陷检测;机器视觉;深度学习;表面缺陷;Transformer
{Abstract}: 物体表面缺陷检测技术是工业质检领域的一项重大课题，对工业生产有着重要的意义。针对近些年基于机器视觉的表面缺陷检测技术进行梳理总结。首先，列举了几种缺陷检测在工业领域的应用场景；其次从特征提取和分类算法的角度简要阐述了传统的机器视觉方法；重点探讨了缺陷检测中常用的经典神经网络结构和缺陷检测算法的最新发展，并介绍了两种常用的缺陷检测算法优化方式；最后，分析了缺陷检测领域面临的三大挑战：实时性问题、小样本问题和小目标问题，目的是为工业表面缺陷检测的研究提供有益的参考和脉络梳理。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2022.08.0426
{DOI}: 10.19734/j.issn.1001-3695.2022.08.0426
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于可见光和热成像的风机叶片全周期无损检测综述*
{Author}: 何赟泽;李响;王洪金;侯岳骏;张帆;牟欣颖;刘浩;程豪;李时华;李杰
{Author Address}: 湖南大学电气与信息工程学院;中国电建集团中南勘测设计研究院有限公司;
{Journal}: 机械工程学报
{Year}: 2023
{Volume}: 59
{Issue}: 06
{Pages}: 32-45
{Keywords}: 风机叶片;热成像;无损检测;机器视觉;深度学习
{Abstract}: 风机叶片在制造、服役和维修阶段的无损检测非常重要。叶片长期在高强度的风力载荷下工作，制造过程产生的任何微小缺陷将在服役中扩大，进一步威胁到风机的正常运行。因而，风机叶片的无损检测一直是工业界与学术界探索的难题。根据叶片视觉检测方法结合无人机技术应用、相关数据包括图像处理方法以及缺陷评判方法的智能程度等方面对前人以及作者所在课题组的前期工作进行综述、总结、分析与对比。目前，可见光视觉检测与红外热成像检测等以视觉为基础的检测手段满足了风机叶片在役运维时非接触、高效、低成本、安全等需求。视觉检测与无人机巡检技术相结合能最大程度的保证人员安全，同时克服了望远镜检测视野受限的难题。然而该检测手段在风机叶片巡检中目前尚存在缺陷定量难、内部缺陷识别率低等方面的不足。通过分析对比可见光检测与热成像检测技术，认为结合智能算法的无人机搭载双光融合检测手段未来有望于解决风机叶片检测中存在的不足。
{ISBN/ISSN}: 0577-6686
{Notes}: 11-2187/TH
{URL}: https://link.cnki.net/urlid/11.2187.th.20221104.1505.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 虚拟人形象合成技术综述
{Author}: 邓钇敏;张旭龙;司世景;王健宗;肖京
{Author Address}: 平安科技(深圳)有限公司;中国科学技术大学;上海外国语大学国际金融贸易学院;
{Journal}: 大数据
{Year}: 2023
{Volume}: 9
{Issue}: 03
{Pages}: 114-139
{Keywords}: 元宇宙;虚拟人;三维人体重建;计算机视觉;深度学习;人脸合成
{Abstract}: 随着元宇宙兴起，针对虚拟人形象化高效建模的需求日益迫切。从人类图像数据集中构建人类模型一直是计算机视觉的热门话题，其中3D虚拟人合成可以视作三维重建的子模块，重点在于对复杂的人体结构和表面细节的还原。对近年来虚拟人形象构建相关文献进行了全面调研，研究范围覆盖了全身形象、头部形象以及衣物建模等领域。分析归纳构建工作的基本原理，从各自技术路线层面出发将虚拟人合成方法分为基于网格、基于图像、基于体素、基于隐式表示、混合表示5类。首先介绍各类方法的基本原理，然后结合现有工作讨论具体技术，并指出各类方法的优缺点。此外还介绍了部分常见的模型质量评估的数据集和评价指标，简要介绍了虚拟人的常见应用。最后对虚拟人合成技术未来发展方向进行了展望，以合成高质量、高保真度、低延迟的虚拟人形象。
{ISBN/ISSN}: 2096-0271
{Notes}: 10-1321/G2
{URL}: https://link.cnki.net/urlid/10.1321.G2.20221108.1339.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 相机标定方法及进展研究综述
{Author}: 黄文文;彭小红;李丽圆;李潇雁
{Author Address}: 国科大杭州高等研究院;中国科学院上海光学精密机械研究所;中国科学院上海技术物理研究所红外物理国家重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 16
{Pages}: 9-19
{Keywords}: 相机标定;摄影测量;计算机视觉;智能标定;神经网络
{Abstract}: 相机标定是摄影测量学和计算机视觉的重要基础之一。首先介绍了相机标定的应用及分类；然后，概述了标定理论基础，包括空间坐标系转换、几何成像模型、内外参数解算方法，并从传统和智能化两大方面对相机标定方法进行阐述，传统标定方面介绍了基于参照物、主动视觉及自标定方法，并对3种方法优缺点进行了详细对比分析，智能化标定方面介绍了误差反向传播、多层感知器及卷积神经网络在标定过程的应用；接着，总结了相机标定方法的常用评价指标；最后，进行了归纳总结，并给出了相机标定技术的发展方向，可为相机标定相关领域研究者提供参考。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20221031.1625.096
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的钢结构表面损伤识别与健康监测综述
{Author}: 逯鹏;赵天淞;王剑;赵磊;常好诵;郑云
{Author Address}: 中冶检测认证有限公司;中冶建筑研究总院有限公司;天津城建大学;96854部队;
{Journal}: 工业建筑
{Year}: 2022
{Volume}: 52
{Issue}: 10
{Pages}: 22-27
{Keywords}: 钢结构损伤;损伤识别;计算机视觉;健康监测;搭载平台
{Abstract}: 由于钢结构材料特性及日常管理不足等原因，其表面损伤情况时有发生。随着数字信息技术的发展，计算机视觉技术已经成为钢结构损伤识别与健康监测的重要手段。本文介绍了计算机视觉技术在钢结构损伤与健康监测方面的相关研究进展，围绕钢结构表面锈蚀损伤、焊缝损伤、螺栓连接损伤的识别技术及钢结构健康监测技术展开讨论，并展望了基于计算机视觉的钢结构损伤识别与健康监测技术的发展方向。
{ISBN/ISSN}: 1000-8993
{Notes}: 11-2068/TU
{URL}: https://link.cnki.net/doi/10.13204/j.gyjzg22071401
{DOI}: 10.13204/j.gyjzg22071401
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在家畜智慧养殖中研究应用进展
{Author}: 郭阳阳;杜书增;乔永亮;梁栋
{Author Address}: 安徽大学互联网学院;南阳农业职业学院;悉尼大学工学院;
{Journal}: 智慧农业(中英文)
{Year}: 2023
{Volume}: 5
{Issue}: 01
{Pages}: 52-65
{Keywords}: 智慧畜牧;精准养殖;个体识别;信息感知;行为识别;深度学习
{Abstract}: 准确高效地监测动物信息，及时分析动物的生理与身体健康状况，并结合智能化技术进行自动饲喂和养殖管理，对于家畜规模化养殖意义重大。深度学习技术由于具有自动特征提取和强大图像表示能力，更适用于复杂的畜牧养殖环境中动物信息监测。为进一步分析人工智能技术在当下智慧畜牧业中研究应用，本文针对牛、羊和猪三种家畜，介绍了深度学习技术在目标检测识别、体况评价与体重估计以及行为识别与量化分析的研究现状。其中，目标检测识别有利于构建动物个体电子档案，在此基础上可以关联动物的体况体重信息、行为信息以及健康情况等，这也是智慧畜牧业发展的趋势。智慧畜牧养殖技术当前面临着应用场景存在多视角、多尺度、多场景和少样本等挑战以及智能技术泛化应用的问题，本文结合畜牧业实际饲养和管理需求，对智慧畜牧业发展进行展望并提出了：结合半监督或者少样本学习来提高深度学习模型的泛化能力；人、装备和养殖动物这三者的统一协作及和谐发展；大数据、深度学习技术与畜牧养殖的深度融合等发展建议，以期进一步推动畜牧养殖智能化发展。
{ISBN/ISSN}: 2096-8094
{Notes}: 10-1681/S
{URL}: https://link.cnki.net/urlid/10.1681.S.20221029.1150.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的四足机器人目标识别与跟随系统设计
{Author}: 陈瑾龙;徐哲壮;黄平;江灏;吴读桑;周泓宇
{Author Address}: 福州大学电气工程与自动化学院;
{Journal}: 实验技术与管理
{Year}: 2022
{Volume}: 39
{Issue}: 10
{Pages}: 135-139+167
{Keywords}: 四足机器人;机器视觉;目标识别;目标跟随
{Abstract}: 根据四足机器人竞赛项目要求，设计了一种基于机器视觉的四足机器人目标识别与跟随系统。该系统首先运用不同骨干网络的YOLOv3算法对目标图像数据集进行特征学习，生成目标识别模型，进而将模型部署至四足机器人的视觉感知主机，完成目标识别功能。再基于机器视觉获得的目标坐标信息，使用PID控制算法计算得到四足机器人的行进速度，实现对目标的实时跟随。最终测试结果表明，四足机器人能够成功完成竞赛项目要求的目标识别与跟随任务，具有较高的精度与实时性。
{ISBN/ISSN}: 1002-4956
{Notes}: 11-2034/T
{URL}: https://link.cnki.net/doi/10.16791/j.cnki.sjg.2022.10.023
{DOI}: 10.16791/j.cnki.sjg.2022.10.023
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进的Canny算子的图像边缘检测方法
{Author}: 张久超;徐晓光;叶炯
{Author Address}: 安徽工程大学高端装备先进感知与智能控制教育部重点实验室;安徽工程大学电气工程学院;
{Journal}: 海南热带海洋学院学报
{Year}: 2022
{Volume}: 29
{Issue}: 05
{Pages}: 79-84
{Keywords}: 机器视觉;边缘检测;小波变换;双边滤波
{Abstract}: 目前，结合机器视觉的智能制造业加工生产方式，需要机器视觉精确测出待处理工件图像边缘信息，并对噪声和无关信息进行过滤，保留有用的关键信息，由此提出一种改进的Canny算法实现边缘检测。该算法利用小波变换和双边滤波代替高斯滤波实现图像的预处理，不仅可以对工作环境中图像的高低频信号去噪，还可以更好地保留边缘细节信息。最后在Sobel算子基础上增加更多图像梯度幅度值及其方向计算，解决随机角度工件摆放问题。
{ISBN/ISSN}: 2096-3122
{Notes}: 46-1085/G4
{URL}: https://link.cnki.net/doi/10.13307/j.issn.2096-3122.2022.05.10
{DOI}: 10.13307/j.issn.2096-3122.2022.05.10
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向空间应用的视觉位姿估计技术综述
{Author}: 周芮;刘延芳;齐乃明;佘佳宇
{Author Address}: 哈尔滨工业大学航天学院;
{Journal}: 光学精密工程
{Year}: 2022
{Volume}: 30
{Issue}: 20
{Pages}: 2538-2553
{Keywords}: 计算机视觉;图像处理;位姿估计;深度学习;空间任务
{Abstract}: 随着人工智能的发展，基于计算机视觉的目标识别、位姿估计技术受到了广泛关注。目前，在交会对接等空间任务中，基于计算机视觉的合作目标位姿估计技术已取得广泛应用。但在非合作目标的视觉位姿估计问题上，由于空间中存在杂散光背景、表面包覆层反射、光照强度变化剧烈等因素，导致特征提取困难、位姿估计易发散、存在累计误差等难题，这些也是亟待解决的热点问题。本文首先总结了空间任务中计算机视觉技术的发展及应用；然后，对视觉位姿估计技术进行概述，以深度学习算法作为切入点，系统地归纳了目标识别及位姿估计算法；最后，综述了深度学习在空间任务中的研究进展，并在任务需求和研究现状分析的基础上，针对空间任务的特殊性，讨论了一些未来的发展趋势。
{ISBN/ISSN}: 1004-924X
{Notes}: 22-1198/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz8fPy6OtPr1ZwYz-3XWzOMf258ZF6uIG61XaYxpuetBIDnopkqrmHZmhSSAofx8D7iaSJBofo1qwiL98qIg_XEWw4CwHInKHPyn5Im5EqE0qLnlml8uuqkF6iMEUKuHx49mTNSlS9LZKn1zGYPquvmYAupObXzrTEM4HJbjnKM1up8aAnbn3lrxOEZMVvNOjk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的畜禽体质量评估研究进展
{Author}: 谢秋菊;周红;包军;李庆达
{Author Address}: 东北农业大学电气与信息学院;农业农村部生猪养殖设施工程重点实验室;黑龙江八一农垦大学工程学院;东北农业大学动物科学技术学院;教育部北方寒区猪智能化繁育与养殖工程研究中心;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: 10
{Pages}: 1-15
{Keywords}: 畜禽;机器视觉;体尺;体质量评估;机器学习;深度学习
{Abstract}: 体质量(体重)是反映畜禽身体健康与生长状况、繁殖与生产性能的重要指标。对畜禽体质量精准快速地评估和监测是提升养殖生产管理水平、实现精准畜牧生产的重要手段。传统的直接称量方式耗时费力，易造成动物的应激反应。基于机器视觉技术的体质量评估，能够利用视觉检测技术获取体型特征建立其与体质量之间的智能评估模型，是目前畜禽养殖智能化技术研究的热点。首先对体质量的评估方法进行分类阐述；然后，详细分析了机器视觉体尺图像获取的传感器类型、畜禽体尺提取与处理方法及应用现状；重点开展基于机器学习方法的体尺、体征与体质量评估模型相关研究的分析，对比了各类机器学习算法在体质量评估方面的应用效果和最新研究成果，特别探讨和分析了深度学习算法在全自动畜禽体质量评估领域的发展潜力；最后，指出畜禽体质量评估研究面临的问题和未来研究的发展趋势。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxsnxGUSHQNtRD4AW2-gI0F1KJ39-cCeGHC_dcS-GLK04BQM0YX58UcwY8NJEgd13Hr3WVGUmracfoPDJVKYM-fcKOx3eSiVf6aqG-n9uv7iQY2fN1L-F2Z82yhd_wQoG_UXOZfAzDbTwYM1MckwULBcLKlxGhbtS5Iq5gYcYmGNlvhS_afDOxGmP6M2oam_Bg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算传播研究中的计算机视觉分析：基于B站政务视频的研究案例与讨论
{Author}: 周葆华;王风范
{Author Address}: 复旦大学信息与传播研究中心;复旦大学新闻学院;复旦大学全球传播全媒体研究院、国家发展与智能治理综合实验室;
{Journal}: 青年记者
{Year}: 2022
{Volume}: 
{Issue}: 20
{Pages}: 25-28
{Keywords}: 计算传播;计算机视觉;B站;政务视频;视觉框架
{Abstract}: 本文基于视觉框架理论，运用计算机视觉分析方法，基于B站政务视频数据，探索风格层次的视觉框架(包括人脸呈现、感知亮度、图像熵等元素)分布特征与层级差异，及其对于视频传播效果的影响。本研究在此基础上对如何更好地开展基于计算机视觉的计算传播研究进行了讨论。
{ISBN/ISSN}: 1002-2759
{Notes}: 37-1003/G2
{URL}: https://link.cnki.net/doi/10.15997/j.cnki.qnjz.2022.20.045
{DOI}: 10.15997/j.cnki.qnjz.2022.20.045
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在电力安全监控中的应用综述
{Author}: 王刘旺
{Author Address}: 国网浙江省电力有限公司电力科学研究院;
{Journal}: 浙江电力
{Year}: 2022
{Volume}: 41
{Issue}: 10
{Pages}: 16-26
{Keywords}: 机器视觉;目标检测;目标分割;目标跟踪;安全监控
{Abstract}: 视频监控对保障电网安全稳定运行起着不可忽视的作用。随着人工智能技术的发展，机器视觉在电力安全监控中表现出巨大的应用潜力。首先概述了机器视觉领域主要关注的目标检测、目标分割、目标跟踪三大任务；然后从设备状态、人员状态、环境状态三个角度出发，总结分析了机器视觉技术在输变电设备状态检测、人员状态判别、重要区域环境状态监测三大典型应用场景的应用及研究进展；最后就机器视觉技术在电力安全监控领域落地应用存在的问题进行分析并提出了相关建议。
{ISBN/ISSN}: 1007-1881
{Notes}: 33-1080/TM
{URL}: https://link.cnki.net/doi/10.19585/j.zjdl.202210003
{DOI}: 10.19585/j.zjdl.202210003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的刚体位姿估计方法综述
{Author}: 郭楠;李婧源;任曦
{Author Address}: 东北大学计算机科学与工程学院;
{Journal}: 计算机科学
{Year}: 2023
{Volume}: 50
{Issue}: 02
{Pages}: 178-189
{Keywords}: 计算机视觉;刚体目标;位姿估计;位姿优化;深度学习
{Abstract}: 刚体位姿估计旨在获取刚体在相机坐标系下的3D平移信息和3D旋转信息，在自动驾驶、机器人、增强现实等快速发展的领域起着重要作用。现对2017-2021年间的基于深度学习的刚体位姿估计方向具有代表性的研究进行汇总与分析。将刚体位姿估计的方法分为基于坐标、基于关键点和基于模板的方法。将刚体位姿估计任务划分为图像预处理、空间映射或特征匹配、位姿恢复和位姿优化4项子任务，详细介绍每一类方法的子任务实现及其优势和存在的问题。分析刚体位姿估计任务面临的挑战，总结现有解决方案及其优缺点。介绍刚体位姿估计常用的数据集和性能评价指标，并对比分析现有方法在常用数据集上的表现。最后从位姿跟踪、类别级位姿估计等多个角度对未来研究方向进行了展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20221019.1803.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的车铣刀具磨损检测方法
{Author}: 邓晓鹏;胡小锋
{Author Address}: 上海交通大学机械与动力工程学院;
{Journal}: 组合机床与自动化加工技术
{Year}: 2022
{Volume}: 
{Issue}: 10
{Pages}: 105-108+114
{Keywords}: 车铣刀具;机器视觉;傅里叶变换;区域生长算法;一致性分析
{Abstract}: 针对加工过程中人工检测刀具磨损效率较低、难以获取刀具磨损全局信息等问题，提出一种基于机器视觉的车铣刀具磨损检测方法。首先通过傅里叶变换将刀具图像映射到频域空间，去除刀体条纹对应的频率分量，消除刀具图像中的条纹干扰。通过自适应区域生长算法分割图像背景区域，并以分割结果为模板，实现图像对比度自适应增强与刀体非磨损区域分割。合并两次分割结果，得到磨损区域二值图像，实现刀具磨损量的自动测量。最后，通过磨损数据的一致性分析验证算法的有效性。结果表明：所提方法测量结果与人工测量结果具有较强的一致性；相较于已有的视觉检测算法，该方法抗干扰能力强，可从低质量图像中准确提取刀具磨损信息，从而实现刀具磨损状态的有效检测。
{ISBN/ISSN}: 1001-2265
{Notes}: 21-1132/TG
{URL}: https://link.cnki.net/doi/10.13462/j.cnki.mmtamt.2022.10.023
{DOI}: 10.13462/j.cnki.mmtamt.2022.10.023
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的SAR图像舰船检测及识别技术研究
{Author}: 张天文
{Tertiary Author}: 张晓玲
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 合成孔径雷达;深度学习;舰船检测;舰船识别
{Abstract}: 合成孔径雷达(Synthetic Aperture Radar,SAR)图像舰船检测及识别在交通监视、渔业管理、海难救援、国防保护等领域具有重要作用。近年来,随着人工智能兴起,深度学习为SAR舰船高性能检测及识别提供了新途径。然而,目前仍有一些挑战性问题亟待解决。对于SAR舰船检测而言,多尺度以及复杂场景影响了检测精度,大规模网络牺牲了检测速度,小场景数据束缚了检测模型大场景应用,框等级检测限制了舰船像素级表征。对于SAR舰船识别而言,过度依赖网络抽象特征降低了识别模型可信度,缺少利用雷达极化信息阻碍了识别精度的进一步提升。因此,为解决上述问题,本文开展了相关研究,主要研究内容如下:(1)针对多尺度舰船检测精度低的问题,研究了基于特征金字塔网络(Feature Pyramid Network,FPN)的多尺度SAR舰船检测。具体地,提出了一种基于变形卷积(Deformable Convolution,Deform-Conv)的特征金字塔网络Deform-FPN,实现了多尺度舰船自适应几何建模。此外,还提出了一种四元级联特征金字塔网络QuadFPN,实现了多尺度舰船特征的渐近式尺度信息增强交互。最终,在公开的多尺度边界框SAR舰船检测数据集(Bounding Box SAR Ship Detection Dataset,BBox-SSDD)上的实验结果表明,Deform-FPN和Quad-FPN改善了多尺度SAR舰船检测精度。(2)针对复杂场景下舰船检测精度低的问题,研究了基于平衡学习(Balance Learning,BL)的复杂场景SAR舰船检测。具体地,提出了一种平衡场景学习机制(Balance Scene Learning Mechanism,BSLM),实现了靠岸复杂场景的训练样本自动扩增和复杂场景样本重点学习。此外,还提出了一种综合平衡学习网络(BL Network,BL-Net),实现了模型在数据级、采样级、特征级和任务级的多等级平衡。最终,在公开的复杂场景高分辨率SAR图像数据集(High-Resolution SAR Images Dataset,HRSID)上的实验结果表明,BSLM和BL-Net提高了复杂场景SAR舰船检测精度。(3)针对大规模网络牺牲舰船检测速度的问题,研究了基于轻量级模型的快速SAR舰船检测。具体地,提出了一种基于深度可分离卷积的网络模型(Depthwise Separable Convolution Neural Network,DS-CNN),减少了网络参数和模型计算成本。此外,还提出了一种基于结构优化和特征增强的超轻量型网络(Hyper Lightweight Network,Hyper Li-Net),实现了检测精度与检测速度的联合优化。最终,在公开的早期SAR舰船检测数据集(SAR Ship Detection Dataset,SSDD)上的实验结果表明,DS-CNN和Hyper Li-Net能在保证良好检测精度的前提下提高SAR舰船检测速度。(4)针对小场景数据束缚检测模型大场景应用的问题,研究了基于Sentinel-1的大场景SAR舰船检测。具体地,构建了基于Sentinel-1的大场景小目标SAR舰船检测数据集LS-SSDD-v1.0,分析了该数据集在大场景海洋监视中的优势和潜在价值。此外,还提出了一种基于纯背景混合训练(Pure Background Hybrid Training,PBHT)的虚警抑制方法,减少了大场景舰船检测的陆地虚警。最终,实验结果表明LS-SSDD-v1.0和PBHT有助于检测模型大场景的迁移应用。(5)针对框等级检测限制舰船像素级表征的问题,研究了基于实例分割的像素级SAR舰船检测。具体地,提出了一种全等级(Full-Level,FL)上下文(Context)压缩激励型(Squeeze-and-Excitation,SE)感兴趣区域提取器(Regions Of Interest Extractor,ROIE)和掩模增强预测(Mask Enhancement Prediction,MEP)的网络FL-CSE-ROIEMEP-Net,实现了精细化舰船像素预测。此外,还提出了一种掩模注意型交互(Mask Attention Interaction,MAI)和多尺度增强(Multi-Scale Enhancement,MSE)网络MAIMSE-Net,实现了更精确的多尺度舰船像素预测。最终,在公开的像素级多边形分割SAR舰船检测数据集(Polygon Segmentation SSDD,PSeg-SSDD)上的实验结果表明,FL-CSE-ROIE-MEP-Net和MAI-MSE-Net实现了优越的SAR舰船像素级表征。(6)针对过度依赖网络抽象特征而降低识别模型可信度的问题,研究了基于传统手工特征融合的SAR舰船识别。具体地,提出了一种基于方向梯度直方图(Histogram of Oriented Gradient,HOG)特征融合的识别网络HOG-Ship CLS-Net,实现了网络抽象特征与传统手工特征的有机结合。此外,还提出了一种其他通用化传统特征融合方法,将该项网络特征与传统手工特征相融合的技术进行通用化应用推广。最终,在公开的Sentinel-1 Open SARShip-3三分类数据集和Gao Fen-3 FUSARShip-7七分类数据集上的实验结果表明,HOG-Ship CLS-Net和其他通用化传统特征应用推广方法可以改善SAR舰船识别精度,可潜在地增强识别模型的可信度。(7)针对缺少利用雷达极化信息可能阻碍识别精度进一步提升的问题,研究了基于雷达极化信息融合的SAR舰船识别。具体地,提出了一种SE型极化多通道注意和拉普拉斯金字塔网络(Laplacian Pyramid Network,LPN)多分辨分析的双极化特征融合(Dual-Polarization Feature Fusion,DPFF)网络SE-LPN-DPFF,实现了由粗到细的极化特征精炼提取。此外,还提出了一种多等级极化融合和几何特征自适应嵌入的网络PFGFE-Net,实现了数据级、特征级和决策级的多等级极化融合几何特征的自适应联合决策。最终,在公开的双极化复数格式Sentinel-1 Open SARShip-3-Complex三分类数据集和Open SARShip-6-Complex六分类数据集上的实验结果表明,SE-LPN-DPFF和PFGFE-Net进一步提升了SAR舰船识别精度。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.005360
{DOI}: 10.27005/d.cnki.gdzku.2022.005360
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 视觉目标检测关键技术研究
{Author}: 邱荷茜
{Tertiary Author}: 李宏亮
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉目标检测;目标特征提取;对象表示;回归优化;多模态目标检测
{Abstract}: 目标检测是计算机视觉领域的共性基础问题,在公共安全、智能制造、智能交通等诸多领域,具有重要的理论意义和应用价值。然而,实际应用场景通常包含目标种类数目繁多、尺度变化大、背景噪声干扰以及模态数据差异等复杂分布特性,导致目标检测面临目标漏检、类别混淆、定位困难等关键问题。研究有效的目标检测模型成为计算机视觉领域和多媒体应用的迫切需求。因此,本文围绕上述问题开展视觉目标检测关键技术研究,以构建高效的目标检测模型为总体目标,从目标特征提取、检测网络结构和网络学习优化三方面进行了研究。同时,对不同场景下的图像与自然语言结合的多模态目标检测问题进行了探讨。具体研究内容和主要创新点可概括为以下几个方面:(1)针对目标区域内背景噪声干扰而导致的语义类别混淆问题,开展了基于多级上下文特征的目标检测研究。该方法首先提出了分割动态编解码网络,为每个目标提供精细的像素级分割信息。然后收集了局部对象区域、非局部对象区域以及周围环境等多种距离范围的上下文信息,并建立不同信息之间的语义依赖关系。最后利用这些多级上下文信息,有效地挖掘分割中辅助特征,抑制目标区域内的噪声干扰,从而提升多类别对象的目标检测性能。(2)针对目标大小、宽高比差异大所带来的目标漏检与误检难题,开展了基于多尺度门融合特征的目标检测研究。该方法首先构建了门融合模块,通过计算相邻尺度通道的语义重要性,自适应控制不同尺度特征的信息流,从而为每个目标对象分配适宜的尺度特征。同时,基于当前对象的宽高比,灵活地选择与其相关的形状区域特征,从而避免固定区域池化导致的目标特征扭曲问题。该方法能够有效地提升关于不同大小和宽高比对象的目标检测性能。(3)针对视觉目标检测难以适应目标外观变化的问题,开展了基于十字线对象表示的目标检测网络结构设计研究。该方法首先设计了一组灵活且可学习的十字线对象表示,用于有效感知目标水平和竖直方向的特征变化。然后,构建了轴查询的十字线生长模块,沿轴方向查询与当前十字线语义相关的周围邻域像素。同时,结合边界框标注的直接监督,灵活判断十字线的生长方向,以应对视觉场景中目标的外观变化。最后,提出了语义引导的标签分配与解耦回归优化机制,通过选择语义丰富度较高的十字线优化目标,进一步提升了目标检测网络的灵活性与准确性。(4)针对目标边界框位置回归优化困难的问题,开展了基于偏移区间概率的目标检测网络优化准则研究。该方法通过分析现有边界框回归优化问题,巧妙将连续的位置偏移值量化为多个离散偏移区间。然后采用了距离感知的偏移区间分类器,以预测当前样本位置偏移相应的单标签或距离标签分布。此外,提出了期望估计的偏移生成方法,将离散的偏移区间转换为精确的位置偏移值。同时设计了分层聚焦的偏移生成方法,通过逐步细化离散的偏移区间范围,从而提升目标检测输出边界框的定位质量。(5)针对多模态目标检测任务中难以精准关联对象外观细节的问题,开展了基于渐进式可变形对象关联的多模态目标检测方法研究。该方法首先提出了语言感知的可变形对象模型,通过自适应在图像中采样与当前语言相关的对象关键点,以准确映射文本描述的对象细节信息。然后建立了语言与视觉特征之间的双向交互,进一步增强跨模态特征间的语义关联。最后,从局部单词到全局句子,逐级将语言中包含的对象以及对象关系映射到图像中,准确地在图像中定位出语言所描述的目标区域。(6)针对复杂密集场景下跨模态映射的实际需求,首次探索了多模态密集场景的目标检测方向研究。该方法首先构建了更具挑战性的密集场景多模态目标检测数据集(Ref Crowd),其中包含丰富多样的密集场景图像和属性细节信息的文本描述。为应对这一挑战,同时提出了细粒度的多模态属性对比学习模型的解决方案,通过建立属性感知的多模态分解模块,将复杂笼统的图像与语言特征分解为显式的多模态属性特征。最后,设计了细粒度属性对比模块,以有效地区分相似人群间的细微差异,从而实现密集场景中语言与视觉间的细粒度映射,进一步推动目标检测领域的研究发展。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004874
{DOI}: 10.27005/d.cnki.gdzku.2022.004874
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于动态范围压缩增强和NSST的红外与可见光图像融合算法
{Author}: 王满利;王晓龙;张长森
{Author Address}: 河南理工大学物理与电子信息学院;
{Journal}: 光子学报
{Year}: 2022
{Volume}: 51
{Issue}: 09
{Pages}: 277-291
{Keywords}: 图像处理;图像融合;机器视觉;动态范围压缩增强;非下采样剪切波变换;阈值收缩;视觉显著图
{Abstract}: 为实现红外与可见光图像的优势互补，提高机器视觉的环境适应性，提出一种基于动态范围压缩增强和非下采样剪切波变换的红外与可见光图像融合算法。首先，用动态范围压缩增强方法增强弱可见光图像。其次，利用非下采样剪切波变换提取红外与可见光图像的低频和高频系数。接着，对高频系数实施硬阈值收缩，抑制高频中的噪声。然后，分别采用视觉显著图加权的“平均”融合方法和绝对值取大融合方法对低频和高频系数进行融合。最后，通过非下采样剪切波变换逆变换得到最终融合图像。实验表明，该算法可以有效保留原图像的边缘特征和纹理细节，显著提高融合图像的清晰度和对比度。
{ISBN/ISSN}: 1004-4213
{Notes}: 61-1235/O4
{URL}: https://link.cnki.net/urlid/61.1235.O4.20221014.1728.014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉显著性的复杂场景目标检测方法研究
{Author}: 黄周
{Tertiary Author}: 陈怀新
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 显著目标检测;复杂场景;稀疏表示;深度学习;特征融合
{Abstract}: 精准、快速地从复杂场景中提取关键内容和感兴趣目标在军事侦察、城市安全监视和国家安防监控等应用中具有重要意义。然而,海量视觉信息的快速分析与智能理解对算法性能提出了更高的要求,尤其是面对包含杂乱背景、低对比度、多种类别和多尺度目标的复杂场景时,常规的算法或机器学习模型难以发挥有效作用。作为计算机视觉的主流方向和基于视觉内容分析的基础研究,视觉显著性检测旨在模拟人类视觉注意力的场景感知能力和主动选择机制,以实现场景中重要内容和关键信息的快速筛选与提取。基于此,本文以视觉显著性检测为方法基础,以光学遥感、自然图像、多模态和低对比度场景图像为研究对象,从模型结构设计、监督策略优化、深度特征集成以及弱监督学习角度出发,开展了一系列基于视觉显著性的复杂场景目标检测方法研究。本文研究内容及创新总结如下:1.针对复杂场景下杂乱背景干扰与区分的问题,提出了一种基于对比度加权字典学习的光学遥感显著目标检测方法。将样本对比度引入字典学习过程中,实现了一种在线判别字典学习;基于判别字典,结合稀疏表示系数和重构误差设计了一种新颖的显著性度量准则,以提高对遥感影像中显著目标的判别能力。本方法解决了基于稀疏表示的显著目标检测算法受限于错误的背景区域采样对非高斯噪声敏感问题。在构建的遥感数据集和公开的自然图像数据集上的实验表明,所提方法能更好的抑制背景干扰,突出显著目标的完整性。2.针对高分辨率遥感影像显著性检测存在目标定位不准确和边界粗糙的问题,提出了一种基于语义引导和注意力细化的光学遥感影像显著目标检测方法。设计的语义引导解码器通过聚合高级特征来实现粗略但准确的目标定位,集成的语义信息通过自顶向下的方式来引导低层次特征的融合并逐步细化目标边缘;构建的检测模型以端到端的方式进行监督学习并输出高质量的预测显著图。与主流的14种先进方法的实验结果表明,提出方法在主要性能评价指标上均取得了最佳结果。遥感目标检测的实验示例进一步证实了方法具有在对地智能监视的应用潜力。3.为增强光照变化或云雾干扰情况下场景显著目标检测能力,提出了一种多层次交互学习的多模态场景显著目标检测方法。设计的跨模态细化模块集成多模态(深度影像图、红外影像图)特征;采用多级别融合模块以自低向上逐级特征层集成与反馈特征修正的方式实现特征细化和复用;以金字塔检测方式将不同层次的跨模态特征融合输出最终预测。本方法构建了RGB-D和RGB-T数据场景的统一显著目标检测架构,取得了与主流的14种方法相比的主要指标性能优势。同时,在利用RGB-D的开放水域船舶检测和RGB-T的场景玻璃区域检测的实验示例进一步展现了所提模型的泛化能力。4.分析显著目标检测和伪装分析任务的内在联系,提出了一种用于伪装分析的视觉Transformer显著目标检测方法。采用视觉Transformer对伪装物的全局上下文进行编码与建模;通过非局部操作和图卷积构造非局部token增强模块,以增强Transformer的局部表示;在解码器中通过逐层收缩的金字塔结构聚集成对的token,以挖掘和累积有效的细节和语义特征。本方法解决了基于Transformer方法的局部建模效率较低和解码器中特征聚合的局限性问题。实验表明,所提方法在典型的伪装分析数据集上实现了超过23种先进方法的卓越性能。在遥感和自然图像显著目标检测数据集上的实验表明所提方法具备良好的模型泛化能力。5.为了从稀疏标注中实现光学遥感影像的显著目标检测,提出了一种基于涂鸦注释的弱监督光学遥感目标检测方法。通过带类激活映射的分类网络生成可靠的边界(伪)标签;设计从浅层特征和输入图像中提取目标边界信息的边界感知模块;将边界信息与密集聚合策略生成的初始显著图相结合,以引导解码器网络中的显著性预测。为解决数据集的缺失,构建了涂鸦标注的遥感影像显著目标检测数据集,并实验验证了在主要性能评价指标上取得了领先现有算法。本方法首次采用基于涂鸦标注的弱监督方法来解决目标边界预测模糊问题,突破了通常采用全监督进行遥感的显著性检测方式。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004843
{DOI}: 10.27005/d.cnki.gdzku.2022.004843
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 数据受限条件下的多模态处理技术综述
{Author}: 王佩瑾;闫志远;容雪娥;李俊希;路晓男;胡会扬;严启炜;孙显
{Author Address}: 中国科学院空天信息创新研究院;中国科学院大学电子电气与通信工程学院;中国科学院空天信息创新研究院网络信息体系技术科技创新重点实验室;
{Journal}: 中国图象图形学报
{Year}: 2022
{Volume}: 27
{Issue}: 10
{Pages}: 2803-2834
{Keywords}: 多模态数据;数据受限;深度学习;融合算法;计算机视觉
{Abstract}: 随着多媒体技术的发展,可获取的媒体数据在种类和量级上大幅提升。受人类感知方式的启发,多种媒体数据互相融合处理,促进了人工智能在计算机视觉领域的研究发展,在遥感图像解译、生物医学和深度估计等方面有广泛的应用。尽管多模态数据在描述事物特征时具有明显优势,但仍面临着较大的挑战。1)受到不同成像设备和传感器的限制,难以收集到大规模、高质量的多模态数据集;2)多模态数据需要匹配成对用于研究,任一模态的缺失都会造成可用数据的减少;3)图像、视频数据在处理和标注上需要耗费较多的时间和人力成本,这些问题使得目前本领域的技术尚待攻关。本文立足于数据受限条件下的多模态学习方法,根据样本数量、标注信息和样本质量等不同的维度,将计算机视觉领域中的多模态数据受限方法分为小样本学习、缺乏强监督标注信息、主动学习、数据去噪和数据增强5个方向,详细阐述了各类方法的样本特点和模型方法的最新进展。并介绍了数据受限前提下的多模态学习方法使用的数据集及其应用方向(包括人体姿态估计、行人重识别等),对比分析了现有算法的优缺点以及未来的发展方向,对该领域的发展具有积极的意义。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwfr2tlbhHf70vKynlkscTxNtqrmk23JRxiqoJ1Mbj0lnNKk4WNRmeegqVs2xxSxv1jL1FznhDZeY6TTcQ_MEYI_dT54fQqgFeXt02VxpgEKHk8LN5lNWIM-T2_1sN6_wPThFf6aZxZhcbo-vL0iP2I32eFqTzegygbpv9oZmZRH9PZ1PG8OBmuhKOJ97NbGQI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Halcon的单目相机标定方法与测量实验
{Author}: 李晓晓;吴昊荣;孙付春;杨涛
{Author Address}: 成都大学机械工程学院;成都大学电子信息与电气工程学院;成都农业科技职业学院机电信息学院;
{Journal}: 山东工业技术
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 8-12
{Keywords}: 机器视觉;单目相机;Halcon;标定;测量
{Abstract}: 机器视觉已经在现代工业自动化生产中得到了广泛应用，尤其是在三维测量领域。物体三维空间与二维图像间的关系求解离不开相机标定，尤其是相机标定结果的优劣直接决定了机器视觉的测量精度。通过搭建单目相机视觉系统实验平台，先分析了相机标定的工作原理，再利用Halcon软件的标定助手功能对型号为GB050-2-7×7的圆点标定板进行相机标定，获得了相机的内参和外参。在进一步测量实验中验证了单个特征圆点测量偏差为0.03862 mm、多个特征圆点测量平均偏差为0.05655 mm，二者测量精度都高于0.1 mm，说明了利用机器视觉进行测量能够满足常用精度需求。
{ISBN/ISSN}: 1006-7523
{Notes}: 37-1222/T
{URL}: https://link.cnki.net/doi/10.16640/j.cnki.37-1222/t.2022.05.002
{DOI}: 10.16640/j.cnki.37-1222/t.2022.05.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与无人机的结构动位移测量方法
{Author}: 韩怡天;冯东明;吴刚
{Author Address}: 东南大学混凝土及预应力混凝土结构教育部重点实验室;东南大学智慧建造与运维国家地方联合工程研究中心;
{Journal}: 振动与冲击
{Year}: 2022
{Volume}: 41
{Issue}: 19
{Pages}: 1-7
{Keywords}: 位移测量;模态参数识别;无人机(UVA);机器视觉;相机运动修正
{Abstract}: 针对基于视觉的结构位移测量方法中相机分辨率不足或测量基站位置选取困难等局限，提出一种结合机器视觉与无人机的结构动位移测量方法。以静止激光灯投射在结构表面的激光光斑为参考，设计算法自动检测目标测点和激光光斑位置，逐帧计算并更新比例因子，估计并消除无人机自身的运动，从而计算目标测点的绝对位移；为验证该方法的准确性，设计一个小型框架模型试验，随后又将此方法应用于大型地震模拟振动台试验。结果表明，利用无人机进行视觉测量得到的位移响应与激光位移计和加速度计测得的参考数据具有良好的一致性，在结构动位移测量和模态参数识别上均能较好地应用。
{ISBN/ISSN}: 1000-3835
{Notes}: 31-1316/TU
{URL}: https://link.cnki.net/doi/10.13465/j.cnki.jvs.2022.19.001
{DOI}: 10.13465/j.cnki.jvs.2022.19.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的SOP芯片引脚缺陷检测系统
{Author}: 王建冲;高军伟;张炳星;刘佳浩
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 工业仪表与自动化装置
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 32-37
{Keywords}: 机器视觉;改进的边缘检测;连通域标记;灰度投影;缺陷检测
{Abstract}: 针对传统工业中SOP芯片引脚缺陷检测速度慢、精度低等问题，设计了一个基于机器视觉的SOP芯片引脚缺陷检测系统，通过MATLAB软件调用CCD相机采集芯片图像，采用改进的Canny边缘检测等算法实现引脚边缘的连接，采用连通域标记和灰度投影算法对得到的二值芯片引脚图像进行缺陷检测并完成GUI界面的设计。由实验数据可知，系统对芯片引脚缺陷检测的正确率为99.6%,测量误差在±0.03 mm之内，满足了工业生产中SOP芯片引脚缺陷检测实时性和准确性的需求。
{ISBN/ISSN}: 1000-0682
{Notes}: 61-1121/TH
{URL}: https://link.cnki.net/doi/10.19950/j.cnki.cn61-1121/th.2022.05.006
{DOI}: 10.19950/j.cnki.cn61-1121/th.2022.05.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术应用研究综述
{Author}: 王锦凯;宋锡瑾
{Author Address}: 阿里巴巴(杭州);浙江大学;
{Journal}: 计算机时代
{Year}: 2022
{Volume}: 
{Issue}: 10
{Pages}: 1-4+8
{Keywords}: 计算机视觉;应用场景;视频分析;安防监控;遥感影像
{Abstract}: 为了快速高效地处理图片，视频等信息。文章结合近年来国内外的一些参考文献和资料，选择了视频分析，安防监控和遥感影像等几个常见的应用场景，对当前的视觉技术应用情况进行详细的阐明，并对该领域今后的研究方向提出一些见解。希望此文所做的工作可以为读者带来一些收益和思考。
{ISBN/ISSN}: 1006-8228
{Notes}: 33-1094/TP
{URL}: https://link.cnki.net/doi/10.16644/j.cnki.cn33-1094/tp.2022.10.001
{DOI}: 10.16644/j.cnki.cn33-1094/tp.2022.10.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的喷涂机器人轨迹规划与涂装质量检测研究综述
{Author}: 訾斌;徐锋;唐锴;王宜藩;沙炜鹏
{Author Address}: 合肥工业大学机械工程学院;合肥工业大学安徽省智能互联系统实验室;
{Journal}: 控制与决策
{Year}: 2023
{Volume}: 38
{Issue}: 01
{Pages}: 1-21
{Keywords}: 机器视觉;喷涂机器人;轨迹规划;质量检测;深度学习
{Abstract}: 随着智能喷涂技术的快速发展,机器视觉在喷涂机器人系统中的研究和应用引起广泛关注,合理的喷涂轨迹能保障油漆厚度均匀、减少漆膜缺陷产生,并且融合涂装质量检测技术形成闭环的喷涂系统.鉴于此,针对机器视觉在喷涂机器人轨迹规划与涂装质量检测中的研究进行综述.首先,对喷涂系统在现代产品制造中的快速发展所面临的机遇、挑战和机器视觉技术进行介绍;然后,综述基于机器视觉技术的喷涂机器人轨迹规划和涂装质量检测的研究成果,对基于机器视觉的喷涂机器人轨迹规划方法,包括待喷涂工件的三维重建、基于点云数据的喷涂轨迹自动规划和基于视觉伺服的喷涂轨迹补偿进行分析和讨论,并重点介绍机器视觉在涂装质量检测中的应用与研究现状,从数据增强和模型选择两个方面,对不同任务中基于深度学习的涂装质量检测算法性能的改善提供潜在解决方案;最后,总结与展望机器视觉技术在喷涂机器人轨迹规划与涂装质量检测中的研究方法和思路,为喷涂系统朝着智能化、柔性化的方向发展提供参考.
{ISBN/ISSN}: 1001-0920
{Notes}: 21-1124/TP
{URL}: https://link.cnki.net/doi/10.13195/j.kzyjc.2022.1438
{DOI}: 10.13195/j.kzyjc.2022.1438
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Transformer在计算机视觉领域的研究综述
{Author}: 李翔;张涛;张哲;魏宏杨;钱育蓉
{Author Address}: 新疆大学软件学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 01
{Pages}: 1-14
{Keywords}: Transformer;卷积神经网络(CNN);混合结构;计算机视觉;深度学习
{Abstract}: Transformer是一种基于自注意力机制的深度神经网络。近几年，基于Transformer的模型已成为计算机视觉领域的热门研究方向，其结构也在不断改进和扩展，比如局部注意力机制、金字塔结构等。通过对基于Transformer结构改进的视觉模型，分别从性能优化和结构改进两个方面进行综述和总结；也对比分析了Transformer和CNN各自结构的优缺点，并介绍了一种新型的CNN+Transformer的混合结构；最后，对Transformer在计算机视觉上的发展进行总结和展望。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20221009.1217.003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 三维点云深度学习分析的关键技术研究
{Author}: 李潞洋
{Tertiary Author}: 韩燮;何黎刚
{Publisher}: 中北大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 点云;三维计算机视觉;深度学习;分类;语义分割;目标检测
{Abstract}: 随着激光传感技术的发展,三维数据的获取变得更加便捷。三维点云数据的分析和理解成为三维计算机视觉领域的一个重要研究方向。如何高效、准确地对三维点云数据的特征进行学习和表征,是实现点云深度学习分析亟需解决的关键问题。近年来,深度学习技术在计算机视觉领域的多种任务中取得重大突破,其中卷积神经网络作为特征编码的核心起到了关键的作用。然而,由于点云的无序性、稀疏性和非规整性,在点云上利用深度学习技术进行分析还存在着诸多挑战:1)分层深度学习模型必须对点云进行数据结构组织以构建特征编码网络所需的局部分组与逐层采样。然而,传统的方法忽略了点自身空间特征的影响,无法根据空间特征自适应组织点云数据,同时计算资源利用率较低,降低了模型的训练和推理速度。2)点云是一种非欧几里得数据结构,图像上的规整深度卷积网络难以直接扩展并应用在三维点云的分析与理解任务中,需要针对点云设计特定的空间卷积滤波器生成方法。针对这些问题,本文对点云深度学习进行了深入探究,旨在解决深度学习在点云分析中存在的共性问题。本文的主要研究与创新工作如下:(1)基于空间特征的点云分层快速数据结构化。由于点云的无序性,采样和局部分组是点云分层深度学习架构中必要的数据结构化步骤。现有的点云分层深度学习多采用了迭代最远点查询进行采样,并在采样点周边查找邻域点进行分组。此过程依赖于大量的欧几里得距离计算,且其中多数的距离计算在点的查找过程中是重复的。此外,采样点的查找过程难以被并行化,造成了模型的推理速度降低。针对这些问题,本文提出了一种基于空间特征变换的数据结构化方法,从点自身的空间特征出发对点云进行分层数据结构化,将具有相似空间特征的点划归为同一分组,并从中选举特征代表点作为采样点。由于这些特性,提出的方法的数据结构化结果稳定,且易于并行化。此外,能够以即插即用的方式取代主流点云深度学习模型中的数据结构方法。实验结果表明,所提方法在保持模型精度的前提下,显著提高了训练速度和推理速度。(2)基于框架点注意力的三维点云卷积。由于点云的无序、稀疏和非规整的性质,直接在点云局部上下文上定义传统规整卷积是困难的。已有的工作尝试利用点的局部位置信息生成对应的卷积滤波器,在滤波权重的计算过程依赖于一些先验知识,如基于距离的线性插值等。然而先验知识限制了滤波器生成的自由度,不利于滤波特征模板的多样性,使得局部特征的提取不够全面。针对这些问题,本文提出了一种基于框架点注意力的空间卷积,通过邻域点与预定义的框架点之间的空间注意力关系对邻域点对应的卷积权重进行非线性插值,降低了滤波器生成的先验约束,使得能够生成更加多样化的特征模板。此外,论文对提出的卷积进行了内存开销优化,减少了训练过程中的内部维度,从而降低了内存消耗,并显著提高了训练速度。基于该卷积方法,论文构建了三种公共点云任务网络,并在广泛使用的数据集上进行了实验。实验结果表明,该方法在点云任务上能够与目前最先进的方法相竞争。(3)基于框架点的局部多重形状感知卷积。通过降低卷积权重学习策略的先验知识约束能够有效提升滤波器的多样性,但是造成卷积权重生成方法的复杂化。基于形状感知的卷积从点云局部形状特征中学习滤波器权重,使得滤波器与局部形状更加相关。过去的方法基于单一中心构建星型拓扑对局部形状进行感知,然而这种策略的形状感知较为粗糙,使得滤波器的学习过程无法与局部形状精确关联,从而降低了卷积的有效性。针对这个问题,本文提出了一种新的卷积策略,称为框架点多重关系卷积:一个局部形状的多个中心点被用来产生对局部形状特征与局部点之间关系的多重感知,多重感知有助于产生对局部形状的更准确的感知。这些感知被用来学习卷积算子的特征转换函数,这反过来又允许卷积自适应地学习各种局部形状,并为点云获得更合适的卷积滤波器。论文构建了基于提出卷积的分层深度网络,并将其应用于三种常见的点云任务。实验结果表明了该方法的有效性。此外,本文还进行了实验和综合分析,以证明和理解该方法的基本原理。(4)基于环形体素随机采样的三维目标检测网络。目标检测任务是三维计算机视觉的重要应用之一,常见于汽车的自动驾驶和机器人工程。基于点表示的模型具有更好的三维特征编码能力。然而,由于点云场景数据的规模巨大,基于点的表示处理速度较慢,对目标检测任务的实时性产生了不良影响。本文提出一种基于环形体素网格的随机采样方法,能够快速对场景点云进行均匀下采样,提升了点云的预处理速度。此外,结合本文提出的数据结构化方法和特征抽象算子,提出了一种目标检测的特征提取骨干网络,并在自动驾驶数据集上进行了实验验证。实验结果表明,本文提出的方法在提升了目标检测的准确率的同时显著降低了推理时间。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.001332
{DOI}: 10.27470/d.cnki.ghbgc.2022.001332
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于U型Swin Transformer自编码器的色织物缺陷检测
{Author}: 黄媛媛;熊文博;张宏伟;张伟伟
{Author Address}: 西安工程大学电子信息学院;浙江大学工业控制技术国家重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 12
{Pages}: 303-310
{Keywords}: 机器视觉;图像处理;色织物;缺陷检测;无监督学习;Swin Transformer
{Abstract}: 针对传统卷积神经网络对色织物花型缺陷检测效果不佳的问题，提出一种基于U型Swin Transformer重构模型和残差分析的缺陷检测方法。该方法使用Transformer模型，可更好地实现对图像全局特征的提取以及更准确的重构，同时解决了实际生产过程中缺陷样本数量少且种类不平衡的问题。首先，针对某种花型，采用叠加噪声后的无缺陷样本完成重构模型的训练过程；然后，将待测图像输入模型中获得重构图像；接着，计算待测图像和重构图像的残差图像；最后，通过阈值分割和数学形态学处理，即可实现对缺陷区域的检测和定位。实验结果表明，该方法在不需要对缺陷样本标记的情况下，能够有效地检测和定位多个色织物花型上的缺陷区域。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.tn.20220927.1957.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的课堂行为识别方法综述
{Author}: 贾轶钧;杨辉跃
{Author Address}: 陆军勤务学院;
{Journal}: 自动化与仪器仪表
{Year}: 2022
{Volume}: 
{Issue}: 09
{Pages}: 1-6
{Keywords}: 课堂行为识别;目标检测;特征提取;行为分类
{Abstract}: 计算机视觉技术发展为智能化教学提供了有力支撑。针对课堂行为自动识别问题，在分析学生课堂行为、识别流程和应用现状基础上，重点从目标检测、特征提取、行为分类三个方面综述了课堂行为识别方法，对比分析各方法优缺点，探讨了课堂行为识别在标准数据集构建、多目标检测、行为识别准确性等方面存在的问题与发展趋势。
{ISBN/ISSN}: 1001-9227
{Notes}: 50-1066/TP
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.1001-9227.2022.09.001
{DOI}: 10.14016/j.cnki.1001-9227.2022.09.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Transformer的小目标车辆精确检测算法
{Author}: 谢光达;李洋;曲洪权;孙再鸣
{Author Address}: 北方工业大学电气与控制工程学院;北方工业大学信息学院;华北电力大学控制与计算机工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 18
{Pages}: 364-371
{Keywords}: 机器视觉;车辆检测;小目标;图像增强;视觉Transformer
{Abstract}: 智能交通系统的建立离不开车辆检测技术。目前的主流方案是使用卷积神经网络（CNN）架构进行车辆检测，然而在复杂交通场景中，远距离小目标像素点少，CNN的下采样机制导致提取的特征缺乏充足的上下文信息，因而小目标检测面临极大挑战。针对这个问题，提出了一种基于视觉Transformer的小目标车辆检测算法。所提算法通过改进Transformer的线性嵌入模块，补充小目标的线性嵌入信息；对图像进行层级构建，每层仅对局部进行关系建模，同时扩大感受野，代替CNN提取出更强有力的小目标车辆特征，实现端到端的精确检测。在UA-DETRAC车辆数据集上进行验证，实验结果表明，改进后的车辆检测算法提高了对远距离及严重遮挡情况下小目标的检测性能，检测精度达到99.0%。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy7PbwsjxVy1m6O6HiD09xEwerbA8QZ6pL7oiRc9OtMK_3CAcQEEiS3WBgpDE9YUxM5LrpqEj5MAyYiTRTrWGvbnACv_6vZe5jokfm52Ccx1SXgWdCI_dHsBH3dq56C9wx3HNpmK-QNjfHU7sY25roWZ9DqtKJ8ka1M3f-vanIkf27L8KX96z7gK37dLtKD7zA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的计算机视觉中图像检索算法研究
{Author}: 黄界生
{Author Address}: 闽南理工学院信息管理学院;
{Journal}: 信息技术与信息化
{Year}: 2022
{Volume}: 
{Issue}: 09
{Pages}: 181-184
{Keywords}: 计算机视觉;图像检索;深度学习;特征提取
{Abstract}: 随着计算机技术的发展，计算机视觉中图像信息分析方法对计算机视觉的研究尤为重要。图像数据集能极大地推动深度学习和计算机视觉的发展。基于此，采用CNN来进行图像特征的提取，将图像输入网络，通过全连接层的输出将特征映射到一维数组。利用汉明距离来循环计算图像的相似度，把图像按照相似度排序并返回给前端。该方法获得较高的查全率，系统查询获得较高的图像检索质量。
{ISBN/ISSN}: 1672-9528
{Notes}: 37-1423/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvztW5aZjjFX-MMD8I-mUPyA_SXTatuWzOLPe0OYYzfhFbgRqJhFDFBL2I75BydZUSYLoLuFQ_-qcSdk5Q8NGoGBbeUuegpo_-5ts_HpWvmb03zylFkiFVDgNzkspCI0gEFUBDwKWuH6i28s4q_Chr5HK4IZQXawoEA1Gq7kXy0ClRxQnNXEwNjIcN_fd9LsTns=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 快速精准识别棚内草莓的改进YOLOv4-Tiny模型
{Author}: 孙俊;陈义德;周鑫;沈继锋;武小红
{Author Address}: 江苏大学电气信息工程学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 18
{Pages}: 195-203
{Keywords}: 机器视觉;图像处理;果实识别;YOLOv4-Tiny;注意力机制;小目标
{Abstract}: 为了实现棚内草莓果实的快速精准识别，该研究提出一种基于改进YOLOv4-Tiny的草莓检测模型。首先，为了大幅度减少模型计算量，采用轻量型网络GhostNet作为特征提取网络，并在GhostBottleneck结构中嵌入卷积注意力模块以加强网络的特征提取能力；其次，在颈部网络中添加空间金字塔池化模块和特征金字塔网络结构，融合多尺度特征提升小目标草莓的检测效果；最后，采用高效交并比损失作为边界框回归损失函数，加速网络收敛并提高模型的检测准确率。结果表明，改进YOLOv4-Tiny模型权重大小仅为4.68 MB，平均每幅图片的检测时间为5.63 ms，在测试集上的平均精度均值达到92.62%，相较于原YOLOv4-Tiny模型提升了5.77个百分点。与主流的目标检测模型SSD、CenterNet、YOLOv3、YOLOv4和YOLOv5s相比，改进YOLOv4-Tiny模型平均精度均值分别高出9.11、4.80、2.26、1.22、1.91个百分点，并且模型权重大小和检测速度方面均具有绝对优势，该研究可为后续果实智能化采摘提供技术支撑。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyG9oBH33FGLWNPYN_8kn9I1UEf8cAdcTdyn6kaieS-UPK2dkNZzbPZ8q47RYiFHIQJLLDToOQUQE3CSgek_anHQn2OPI3c-EjnnfxQObzt0GAK9790AwvkwrovlnOn9uHY0cQg8xEo7Iq-ZkCoGw8XOBRxoTtrbnBbkP5Tdi-8RfiOCvY-ZZ9jzxO8AuLbfl4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于半监督SPM-YOLOv5的套袋柑橘检测算法
{Author}: 吕佳;李帅军;曾梦瑶;董保森
{Author Address}: 重庆师范大学计算机与信息科学学院;重庆市数字农业服务工程技术研究中心;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 18
{Pages}: 204-211
{Keywords}: 机器视觉;图像识别;目标检测;套袋柑橘;YOLOv5;条带注意力;教师学生模型
{Abstract}: 为解决柑橘经过套袋后其形状从圆形变为条状导致当前目标检测算法对套袋柑橘检测难度增大，同时目标检测算法性能依赖于有标记样本数量的问题。该研究设计了一种基于教师学生模型的SPM(Strip Pooling Module)-YOLOv5算法，在YOLOv5的骨干网络中加入条带注意力模块使模型更加关注条状的套袋柑橘与树枝，同时教师学生模型为半监督方法，使目标检测算法可利用无标记样本提升模型的性能，降低对有标记样本的依赖。试验结果表明，该算法在套袋柑橘与树枝检测的平均精度均值分别为77.4%与53.6%，相比YOLOv5分别提升了7.5个百分点与7.6个百分点，套袋柑橘检测的精度与召回率达到94.0%与76.2%。因此，基于教师学生模型的SPM-YOLOv5算法精度高、速度快，能有效用于套袋柑橘检测。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzv0qIUlsHOhFLAifOh_Cg2cRoyAMIUKujsyp4cpYecIIDhZdElL-iyrV-tFw_HeQqpzoX_362T8gaAX19TjQyrIa11t1Zh7_Krr4sAd5QKRwLmNUFvopcbfnU-bcE7XS8vMKKxKG_pvsyCcTlzVRdbiXOChd_2sjvwuPwcYczemEJGy7MDi0JmIA5x3M7HV3I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向计算机视觉的生成对抗网络研究与应用
{Author}: 刘明辉
{Tertiary Author}: 刘明
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 生成对抗网络;训练动态不稳定;模式崩溃;多鉴别器集成;隐层表征;特征均衡;半监督学习;强化学习
{Abstract}: 随着人工智能和深度学习的快速发展,面向计算机视觉的生成模型研究获得了广泛的应用。其中,生成对抗网络具有最深远的影响。相较于其他传统的生成模型,生成对抗网络中生成器与鉴别器的对抗训练可以在显著提升生成样本生成质量的同时避免传统生成模型近似或者变分的推导过程。另一方面,由于生成器不直接参与数据分布的学习,这使得生成对抗网络对与数据分布相关的先验知识并不敏感,从而可以更好地生成与数据分布相似但又不完全相同的新样本。尽管生成对抗网络具有多个优点且已经在不同的任务中都取得了成功,但其依然存在两个固有缺陷:训练动态不稳定和模式崩溃。本文对生成对抗网络的相关研究和发展现状进行了梳理,根据流形理论和最优传输理论分析了这两种固有缺陷出现的原因,并从不同的角度提出了两种解决方案。在此基础上,进一步扩展了生成对抗网络在半监督学习和强化学习中的应用,为生成对抗网络在医学领域中的应用提供了新的思路。在该过程中,利用理论分析和大规模实验充分验证了提出的方法与应用的有效性。本文工作的具体概述如下:(1)针对生成对抗网络的两种固有缺陷,本文提出了一种基于具有不同损失函数的多鉴别器集成的生成对抗网络框架CES-GAN。通过同时对多个具有不同损失函数的鉴别器进行集成训练,利用不同损失函数偏好不同数据模式的特点尽可能捕获数据空间中可被观察的数据模式并稳定生成对抗网络的训练动态。同时,针对不同性能鉴别器集成可能出现木桶效应的问题,本文还提出了一种梯度选择机制,只使用能够有效降低生成分布和数据分布之间距离的梯度来更新生成器的权重,从而避免性能较低的鉴别器带来的负面影响。最后,本文提供了理论分析以证明方法的可靠性,并在不同规模的多个数据集上验证了该方法的有效性。(2)针对生成对抗网络训练动态不稳定的问题,本文提出了一种基于隐层表征的生成对抗网络快速构建方法。通过解耦生成对抗网络的生成过程将其分为两个独立的生成过程以分别生成经验隐层表征和最终结果,从而稳定生成对抗网络的训练动态并捕获更多的数据模式。在第二个阶段中,使用经验隐层表征替换白噪声作为生成器的输入。考虑到隐层表征是数据分布在神经网络隐空间中的低维映射,具有数据分布的先验知识,这意味着二者的映射函数将更加连续和平滑。因此,该方法可以有效稳定生成对抗网络的训练动态。最后,本文通过理论分析证明了该方法可以稳定生成对抗网络的训练动态并降低对抗训练的难度。多个数据集上的大规模实验证明了该方法的有效性。(3)针对监督学习中深度学习分类网络一般性特征和特异性特征不平衡导致的过拟合问题,本文提出了一种基于特征均衡的半监督训练方法。将分类网络顶端的卷积层视为生成器并将其输出作为伪样本,真实样本经过矩阵变换得到的投影作为真样本,引入一个无监督鉴别器基于对抗损失来尝试区分这两种样本,进而约束模型更多的学习一般性特征而非特异性特征。理论分析和大规模实验证明了该方法的可靠性和有效性。(4)针对新冠肺炎与其他肺炎放射学特征过于相似的问题,本文提出了一种基于生成对抗网络的半监督学习检测模型以识别不同类型肺炎医学影像之间的细微差别。同时,针对放射学特征和临床指标不平衡导致的归纳偏置问题,本文提出了一种基于生成对抗网络的强化学习预测框架,以结合放射学特征和临床指标预测新冠肺炎患者病情进展。本文还构造了一个包含超过十万张CT影像的新冠肺炎胸部扫描图像数据集,并基于此进行了大规模的验证。除此之外,外部验证集的结果证明了提出方法的有效性和泛化能力。本文提出的方法可以显著稳定生成对抗网络的训练动态并捕获更多的数据模式。同时,在半监督学习和强化学习上的应用结果表明生成对抗网络具有很高的潜在应用价值。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004820
{DOI}: 10.27005/d.cnki.gdzku.2022.004820
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 自动驾驶3D目标检测研究综述
{Author}: 任柯燕;谷美颖;袁正谦;袁帅
{Author Address}: 北京工业大学信息学部;
{Journal}: 控制与决策
{Year}: 2023
{Volume}: 38
{Issue}: 04
{Pages}: 865-889
{Keywords}: 机器视觉;深度学习;目标检测;3D目标检测;自动驾驶
{Abstract}: 精确实时地进行目标检测是自动驾驶车辆能够准确感知周围复杂环境的重要功能之一,如何对周围物体的尺寸、距离、位置、姿态等3D信息进行精准判断是自动驾驶3D目标检测的经典难题.服务于自动驾驶的3D目标检测已成为近年来炙手可热的研究领域,鉴于此,对该领域主要研究进展进行综述.首先,介绍自动驾驶感知周围环境各相关传感器的特点;其次,介绍3D目标检测算法并按照传感器获取数据类型将其分为:基于单目/立体图像的算法、基于点云的算法以及图像与点云融合的算法;然后,对每类3D目标检测的经典算法以及改进算法进行详细综述、分析、比较,梳理了当前主流自动驾驶数据集及其3D目标检测算法的评估标准,并对现有文献广泛采用的KITTI和NuScenes数据集实验结果进行对比及分析,归纳了现有算法存在的难点和问题;最后,提出自动驾驶3D目标检测在数据处理、特征提取策略、多传感器融合和数据集分布问题方面可能遇到的机遇及挑战,并对全文进行总结及展望.
{ISBN/ISSN}: 1001-0920
{Notes}: 21-1124/TP
{URL}: https://link.cnki.net/doi/10.13195/j.kzyjc.2022.0618
{DOI}: 10.13195/j.kzyjc.2022.0618
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的葡萄品质无损检测方法研究进展
{Author}: 刘云玲;张天雨;姜明;李勃;宋坚利
{Author Address}: 中国农业大学信息与电气工程学院;中国农业大学烟台研究院;山东省葡萄研究院;中国农业大学理学院;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: S1
{Pages}: 299-308
{Keywords}: 田间葡萄;深度学习;无损检测;机器视觉
{Abstract}: 我国葡萄产量逐年上升，田间葡萄品质检测有益于提高葡萄收获后流入市场的经济效益。传统田间葡萄品质检测主要依靠人工进行破坏性检测，存在经验差异导致的误差。随着深度学习、图像检测技术的发展，基于机器视觉的田间葡萄品质检测克服了传统人工检测的局限性，以快速精准、实时无损检测的优势得到了大量应用。葡萄品种不同，衡量其内、外在品质评级的指标也不同。本文根据葡萄品种与品质评价指标，从品种的机器视觉检测方法、品质的机器视觉检测方法展开，对国内外基于机器视觉技术的田间葡萄品质无损检测相关研究进行系统性分析与总结。总结了不同机器视觉检测方法对葡萄品质指标检测的优缺点，并对田间葡萄品质无损检测研究面临的问题进行了讨论，指出了今后的发展趋势与研究方向。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.s.20220915.1313.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的单帧图像超分辨率重建综述
{Author}: 吴靖;叶晓晶;黄峰;陈丽琼;王志锋;刘文犀
{Author Address}: 福州大学机械工程及自动化学院;福州大学先进技术创新研究院;福州大学计算机与大数据学院;
{Journal}: 电子学报
{Year}: 2022
{Volume}: 50
{Issue}: 09
{Pages}: 2265-2294
{Keywords}: 超分辨率重建;深度学习;单帧图像;卷积神经网络;生成对抗网络;Transformer;挑战赛
{Abstract}: 图像超分辨率重建是计算机视觉中的基本图像处理技术之一，不仅可以提高图像分辨率改善图像质量，还可以辅助其他计算机视觉任务.近年来，随着人工智能浪潮的兴起，基于深度学习的图像超分辨率重建也取得了显著进展.本文在简述图像超分辨率重建方法的基础上，全面综述了基于深度学习的单帧图像超分辨率重建的技术架构及研究历程，包括数据集构建方式、网络模型基本框架以及用于图像质量评估的主、客观评价指标，重点介绍了根据网络结构及图像重建效果划分的基于卷积神经网络的方法、基于生成对抗网络的方法以及基于Transformer的方法，并对相关网络模型加以评述和对比，最后依据网络模型和超分辨率重建挑战赛相关内容，展望了图像超分辨率重建未来的发展趋势.
{ISBN/ISSN}: 0372-2112
{Notes}: 11-2087/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwuqWsSVVKFOwVtgdWbpcY4laWr1dpzW5gC4cP6sr9hxXBkuU8oJHrtrfY8b2o9t3aNgIXKKXCjcKEa_fgTVo86e_C5QJfrPrpe-OKyxb2XtEa_mMM2xVO6y_4nZ3Kx5ok9Sd4GTy82okDSEjJr4UWywWNt0IRVTKPXm4-uZcZPSb6KqhR9QbuRISi86pIqnH4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进VGG16卷积神经网络的烟丝类型识别
{Author}: 牛群峰;袁强;靳毅;王莉;刘江鹏
{Author Address}: 河南工业大学电气工程学院;河南中烟工业有限责任公司安阳卷烟厂;
{Journal}: 国外电子测量技术
{Year}: 2022
{Volume}: 41
{Issue}: 09
{Pages}: 149-154
{Keywords}: 烟丝识别;机器视觉;深度学习;VGG16;残差模块
{Abstract}: 为改善人工分拣烟丝效率低下，分类效果差导致香烟品质难以得到保证的现象，提出一种将机器视觉和深度学习相结合的烟丝类型识别方法。实验采集了4种烟丝图像并经过预处理以后送入以VGG16为基础改进的Light-VGG网络模型中进行分类，改进包括减少VGG16中卷积核个数以优化网络结构；增加残差模块以提升模型学习能力；使用全局池化代替全连接层，大幅减少网络参数量，应对网络过拟合。Light-VGG相比VGG16参数量减少96.5%,预测时间减少20.3%,在自建烟丝数据集中准确率达到95.5%,也明显高于其他神经网络(AlexNet、VGG13、GoogLeNet),实现了快速、准确识别烟丝类型的目标。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2203982
{DOI}: 10.19652/j.cnki.femt.2203982
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的鱼类视频跟踪技术应用研究进展
{Author}: 裴凯洋;张胜茂;樊伟;王斐;邹国华;郑汉丰
{Author Address}: 中国水产科学研究院东海水产研究所农业农村部渔业遥感重点实验室;上海海洋大学信息学院;上海峻鼎渔业科技有限公司;
{Journal}: 海洋渔业
{Year}: 2022
{Volume}: 44
{Issue}: 05
{Pages}: 640-647
{Keywords}: 计算机视觉;鱼类视频;图像清晰化;鱼类跟踪
{Abstract}: 通过将基于计算机视觉的鱼类视频跟踪技术应用于海洋环境、水产养殖监控等领域，可低成本、高效率的了解鱼类的生态环境、健康和生长情况。其中，图像清晰化和水下目标跟踪是鱼类视频跟踪技术中的重要环节。重点从这两方面对基于计算机视觉的鱼类视频跟踪技术应用研究进展进行了概述。图像清晰化技术可用来消除光线衰减和散射导致的图像模糊、偏色和能见度低等问题，实现方法主要分为图像增强、图像复原和深度学习；由于鱼类在水下的运动状态不确定，需采用水下目标跟踪技术感知鱼类运动规律，实现方法主要分为生成式方法和判别式方法。最后对该领域研究进行了小结与展望，计算机视觉技术为生态系统监控提供了新的观测途径，但仍存在一定局限性，需进一步研究发展。
{ISBN/ISSN}: 1004-2490
{Notes}: 31-1341/S
{URL}: https://link.cnki.net/doi/10.13233/j.cnki.mar.fish.2022.05.006
{DOI}: 10.13233/j.cnki.mar.fish.2022.05.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智慧植保及其发展建议
{Author}: 王海光
{Author Address}: 中国农业大学植物保护学院;
{Journal}: 中国农业大学学报
{Year}: 2022
{Volume}: 27
{Issue}: 10
{Pages}: 1-21
{Keywords}: 智慧植保;智慧农业;植物保护;交叉学科;发展建议
{Abstract}: 现代科学技术促进了智慧农业和相关学科的发展。物联网、移动互联、云计算、大数据、人工智能等现代信息技术推进了植保信息化，提高了植物保护的智能化水平，推动着传统植保向智慧植保发展。智慧植保是现代植保的重要发展方向和重要体现，具有智能化、高精确性、高效率、可持续性、高安全性的特点。为了促进对智慧植保的认识，本文基于农业、科技和学科的发展，分析了智慧植保产生的必然性和必要性，分别从概念、理论框架、应用场所、关键技术等方面对智慧植保进行了阐述，提出智慧植保主要具有智能监测、智能预测预警、智能决策、智能溯源、智能管理、智能服务等功能，简要介绍了智慧植保的研究进展和相关技术的应用，并从重视智慧植保的发展潜力、智慧植保体系建设、学科建设、人才培养、产学研协同合作、技术研发、标准化建设、学术交流、技术培训、农村基础设施和示范园区建设等方面提出了发展智慧植保的建议，可为智慧植保的良性发展提供一些参考。
{ISBN/ISSN}: 1007-4333
{Notes}: 11-3837/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzoJu46CqpSrJ96JIiWaMFxrUt2pRdBHMOd6qCxpNP4zkTTzOSjz4dQSmiqvEbQbcyyI-UqdsyBBOROVLMZj2Eql3Y7aow17Uvgo8XWYsGFw4lSWO0G0SntJ4Fqb6I4oNLwrFLNy9DqEQbabNgOfKT1iSv3PBehDCXOlhNSvso7C8lgIU7a9qMcK4eC3gFgB4U=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 移动机器人视觉SLAM回环检测现状研究
{Author}: 赵燕成;房桐;杜保帅;赵景波
{Author Address}: 青岛理工大学信息与控制工程学院;
{Journal}: 无线电工程
{Year}: 2023
{Volume}: 53
{Issue}: 01
{Pages}: 129-139
{Keywords}: 同步定位与建图;回环检测;词袋模型;深度学习;性能评估
{Abstract}: 同步定位与建图(Simultaneous Localization and Mapping, SLAM)是移动机器人实现自主定位与导航的关键技术，已成为该领域研究的热点。视觉SLAM是指相机作为仅有的外部传感器，进行同步定位与建图的技术，随着计算机视觉的迅速发展，视觉SLAM因为信息量大、成本低廉、适用范围广和可提取语义信息等优点受到广泛关注，而回环检测(Loop Closure Detection, LCD)作为其重要的一个环节，受到学者的广泛研究。对视觉SLAM系统进行简单概述，对LCD的原理、传统的LCD算法分类和主流的LCD算法进行总结归纳，介绍了LCD的性能评估标准，对LCD当前面临的挑战及未来前景进行展望。
{ISBN/ISSN}: 1003-3106
{Notes}: 13-1097/TN
{URL}: https://link.cnki.net/urlid/13.1097.TN.20220907.1411.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的条件式视觉内容生成研究及应用
{Author}: 张江宁
{Tertiary Author}: 刘勇
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 计算机视觉;深度学习;条件式视觉内容生成;图像上色;图像超分辨率;人脸换脸;人脸驱动;图像动态化
{Abstract}: 随着深度学习的快速发展和计算能力的不断提高,条件式视觉内容生成技术蓬勃发展并取得了许多瞩目的科研成果,在火热的泛娱乐、元宇宙和虚拟人等领域具有极大的应用价值。然而,受限于当前技术与高标准应用需求之间的差距,生成模型在效率和易用性等方面有待进一步提高,且如何通过给定的条件输入(如图像,音频,运动信息等)生成高质量且合理的视觉内容仍是当前面对的棘手问题。本文聚焦基于深度学习的条件式视觉内容生成技术,按照对信息理解程度逐渐升高的原则,由浅及深地对不同层次的问题进行分类总结并展开具体研究。一方面,低层次的图像像素级任务核心关注局部结构感知及分布预测问题,面临的最大挑战是如何生成合理且高质量的图像,以及设计高效的模型来支持各种终端应用。另一方面,高层次的图像语义级生成任务不仅需要理解图像中的语义信息,同时对高分辨率、高精度生成模型研究及训练优化提出了极大挑战。尤其过渡到视频生成任务中这些难点愈发凸显,且需要额外地对时序合理性及生成多样性进行建模。针对上述挑战,本文研究典型的图像上色和超分辨率任务,以期从低层次的感知中生成更高质量的视觉内容;以及语义层面的人脸换脸、人脸驱动和图像动态化任务,以期从高层次的理解中可控地生成更丰富的图像和视频。本文的研究内容与主要创新点如下:1.从局部结构感知的图像增强出发,本文针对图像上色和超分辨率问题展开研究,提出了一种高效的联合图像上色和超分辨率端到端框架,设计了金字塔阀控交叉注意力模块以支持自动和参考两种上色模式,不仅能更好地理解并聚合参考图像的颜色信息,同时具有较强的解释性。此外,本文针对任意倍率图像放大应用需求提出了连续像素映射模块,使用更少计算量的同时提升了模型的预测精度。2.从多条件受限的图像纹理语义迁移出发,本文针对人脸换脸问题展开研究,提出了一种基于区域注意力感知的换脸方法以对人脸进行更精细的建模,其包含新颖的面部区域感知的局部分支和源特征适应的全局分支:前者通过引入全局注意力机制来有效地建模不重合的多尺度面部语义交互,而后者补充全局身份相关的线索来进一步保证生成图像的身份一致性。此外,本研究提出了一种无监督人脸软掩膜预测模块,进一步提升了模型的准确性与实用性。3.从多条件受限的图像几何语义编辑出发,本文针对人脸驱动问题展开研究,提出了一种基于人脸几何和纹理信息解耦思想设计的多人脸驱动模型,其包含一个精心设计的人脸关键点转换器分支以在几何空间上进行不同身份的面部运动迁移,以及一个几何感知生成器分支生成人脸驱动图像,在保证图像生成质量的基础上实现了多人脸驱动任务目标。同时本文将该框架扩展到了音频多人脸驱动任务,设计了音频特征融合器和几何控制器模块分别进行音频特征提取及高效注入,并提出了一个高质量的Ann VI数据集以支持高分辨率的音频人脸驱动研究。4.从运动约束下的图像序列生成出发,本文针对图像动态化问题展开研究,基于运动和纹理解耦的思想设计了端到端的动态视频生成框架,其包含光流编码器模块和双分支动态视频生成器:前者将表示视频运动的光流信息编码为归一化向量,同时可通过随机运动向量采样的推理方式实现多样化的视频生成;后者在运动向量的控制下基于单帧输入图像生成合理的目标动态视频。此外,针对当前延时视频数据集质量较差的问题,本研究提出了大规模的高分辨率QST数据集来支持该任务的持续研究。针对以上研究内容和成果,本文在多个主流数据集上进行了大量的实验评估,证明了所提方法的有效性和优越性,在基于深度学习的条件式视觉内容生成领域取得了出色的研究成果,同时提出的部分算法模型已用于商业产品中,具有较大的应用价值。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001806
{DOI}: 10.27461/d.cnki.gzjdx.2022.001806
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的PCB缺陷检测算法研究现状及展望
{Author}: 吴一全;赵朗月;苑玉彬;杨洁
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2022
{Volume}: 43
{Issue}: 08
{Pages}: 1-17
{Keywords}: 印刷电路板;缺陷检测;机器视觉;深度学习;数据集;性能分析
{Abstract}: 印刷电路板(PCB)是电子零件的基板，需求量极大，承载着电路元件和导线的布局，其优良与否对电子产品的质量有着重要影响。由于电子产品的制作逐渐趋于轻薄、精小，基于机器视觉的PCB缺陷检测已成为一个具有挑战性的问题。为了加深研究人员对PCB缺陷检测的理解，本文从传统图像处理方式、传统机器学习及深度学习3大维度全面回顾了近10年基于机器视觉的PCB缺陷检测算法，并分析其优缺点；介绍了9个PCB数据集，给出了评价PCB缺陷检测算法的性能指标，且在PCB数据集及流行的小目标数据集上分别对典型的算法进行了对比分析；最后指出了PCB缺陷检测算法目前存在的问题，展望了未来可能的研究趋势。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2209701
{DOI}: 10.19650/j.cnki.cjsi.J2209701
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向计算机视觉任务的深度卷积神经网络鲁棒性研究
{Author}: 姚杰
{Tertiary Author}: 邢薇薇
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 卷积神经网络;模型鲁棒性;参数自适应;空洞卷积;主动学习;对比学习
{Abstract}: 近年来,深度学习技术快速发展,已经成为人工智能领域的研究热点和主流发展方向。尽管某些基于深度学习的视觉应用已经开始向产品化方向发展并取得一定成绩,但深度学习技术全面、深入地向产业界进行转化仍存在诸多限制,其中,深度模型鲁棒性是关键因素之一。深度模型鲁棒性要求模型在常规训练集上具有显著的性能、在噪声数据集上具有良好的稳定性同时在分布发生偏移的测试数据上具有较好的泛化性能。为了全面提高模型在不同视觉测试场景下的鲁棒性,本文首先对模型鲁棒性问题进行建模分析,并将建模结果作为本文评价模型鲁棒性的统一依据。然后本文以计算机视觉任务为主要应用场景,结合深度模型鲁棒性的限制因素,对深度模型进行模块化分析。根据分析结果,本文以增强模型的特征提取和鉴别能力为核心切入点,从增强卷积神经网络的特征提取能力、模型的特征鉴别能力和特征在模型中的一致性响应三个方面进行深入研究,论文的主要创新性工作包括:(1)提出了基于在线推理策略的自适应空洞卷积神经网络,实现模型在训练过程中自适应地调整卷积核的感受野,增强卷积神经网络的特征提取能力。空洞卷积通过引入空洞值这一参数使相同尺寸的卷积核获得了更大的感受野,而错误的空洞值选择会降低空洞卷积的效率,给模型训练造成影响。针对这一问题,本文提出了空洞值在线推理策略,并通过引入Gumbel-Softmax函数来近似拟合空洞值采样过程。同时设计了马尔科夫聚合模式等多种层间信息聚合模式对隐藏单元的信息更新方式进行建模。实验结果表明,本文提出的自适应空洞卷积神经网络可以灵活嵌入卷积模型进行训练,并对模型在典型视觉任务上的鲁棒性带来稳定的提升。(2)提出了基于主动学习的Active Dropblock方法,实现Dropblock中掩码的在线优化,增强模型对数据中所包含有效特征的鉴别能力。Dropblock通过使用结构化掩码对特征进行扰动,克服了传统Dropout在卷积神经网络效率低中的问题,然而掩码的生成缺乏合理的指导,给模型训练效率造成一定负担。针对这一问题,本文首先基于主动学习思想对模型的更新过程进行优化,然后通过构建参数选择器实现掩码的在线优化。实验结果表明,本文提出的Active Dropblock可以有效提高模型对对抗样本的抵抗能力,同时,该方法提升了模型对数据的利用效率以及特征在模型中的激活响应。(3)提出了基于对比学习的鲁棒性学习模式,提升模型在未知测试数据上的泛化能力,增强特征在模型中的一致性响应。数据增强技术通过将增强后的图像数据添加到训练集,扩大了训练集的数据分布程度,一定程度上提高了模型在未知测试数据上的泛化能力,然而有限的数据增强操作无法应对复杂的现实测试环境。针对这一问题,本文首先通过引入不同的数据增强方法构建干净样本的增强变体,并使用这些图像样本构建基于类别敏感的正负样本对,然后将这些样本同时输入模型进行训练,在特征提取和样本预测阶段,本文分别提出了基于对比学习的特征一致性和预测分布一致性约束策略,对特征及预测分布的一致性表达进行约束。实验结果表明,该方法可以有效增强模型同类样本的特征在模型中的一致性响应以及数据的利用效率。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000192
{DOI}: 10.26944/d.cnki.gbfju.2022.000192
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 光场相机建模与畸变校正改进方法
{Author}: 杨守瑞;段婉莹;艾文宇;陈胜勇
{Author Address}: 天津理工大学计算机科学与工程学院教育部视觉与系统重点实验室;
{Journal}: 红外与激光工程
{Year}: 2023
{Volume}: 52
{Issue}: 01
{Pages}: 239-247
{Keywords}: 机器视觉;光场相机;重投影误差;相机标定;镜头畸变
{Abstract}: 光场相机作为一种新型的成像系统，可以直接从一次曝光的图像中得到三维信息。为了能够更充分有效地利用光场数据包含的角度和位置信息，完成更加精准的场景深度计算，从而提升光场相机的三维重建的精度，需要实现精确的几何建模，并精确标定其模型参数。该方法从薄透镜模型和小孔成像模型出发，将主透镜建模为薄透镜模型，将微透镜建模为小孔成像模型，结合光场相机双平面模型，将每个提取到的特征点与其在三维空间中的射线建立联系，详细解释了内参矩阵中每个参数的物理意义，以及标定过程中初值确定的过程，并在镜头径向畸变模型的基础上进一步应用了相机镜头的切向畸变模型以及基于射线重投影误差的非线性优化方法，改进了光场相机的标定方法。实验显示，该方法的RMS射线重投影误差为0.332 mm，与经典的Dansereau标定方法相比，进行非线性优化后得到的射线重投影误差精度提升了8%。该方法详细分析的场景点与特定像素索引的推导过程对光场相机的标定具有重要的研究意义，为光场相机光学模型的建立与初始化标定奠定了基础。
{ISBN/ISSN}: 1007-2276
{Notes}: 12-1261/TN
{URL}: https://link.cnki.net/urlid/12.1261.TN.20220829.1430.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在图像分类中的应用综述
{Author}: 金玮;孟晓曼;武益超
{Author Address}: 华北水利水电大学;
{Journal}: 现代信息科技
{Year}: 2022
{Volume}: 6
{Issue}: 16
{Pages}: 29-31+35
{Keywords}: 深度学习;卷积神经网络;图像分类;计算机视觉;过拟合
{Abstract}: 近年来，深度学习在计算机视觉领域得到了广泛的应用，卷积神经网络也是这个领域中较为重要的研究方向之一。卷积神经网络在图像分类、目标检测等领域的应用前景非常可观。然而，卷积神经网络依然存在着过拟合、梯度消失等问题。鉴于此，文章首先介绍了卷积神经网络的发展历程以及经典的网络模型。其次具体分析了各种卷积神经网络的结构和优缺点，并针对以上问题给出了相应的解决方法。最后分析了卷积神经网络在图像分类领域的不足并展望了未来的发展方向。
{ISBN/ISSN}: 2096-4706
{Notes}: 44-1736/TN
{URL}: https://link.cnki.net/doi/10.19850/j.cnki.2096-4706.2022.16.008
{DOI}: 10.19850/j.cnki.2096-4706.2022.16.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的人体姿态识别研究
{Author}: 盛洋;王健庆
{Author Address}: 浙江中医药大学医学技术与信息工程学院;
{Journal}: 现代信息科技
{Year}: 2022
{Volume}: 6
{Issue}: 16
{Pages}: 87-91+95
{Keywords}: 人体姿态识别;姿态检测;Openpose;神经网络;可视化
{Abstract}: 人工智能交互领域的不断发展，使计算机视觉技术的研究更加深入且多样化。人体姿态识别是计算机视觉中的一个重要的基础问题。文章基于计算机视觉开展人体姿态识别研究，通过VGGNet模型实现神经网络预测，采用Openpose算法获取18个人体关键点位置和置信度，根据PAF和二分图算法实现关节拼接。实验基于MS COCO 2017数据集建立优化模型，在测试集上达到了96.31%的准确率。最后，文章实现了能够识别出人体骨骼姿态的系统。
{ISBN/ISSN}: 2096-4706
{Notes}: 44-1736/TN
{URL}: https://link.cnki.net/doi/10.19850/j.cnki.2096-4706.2022.16.023
{DOI}: 10.19850/j.cnki.2096-4706.2022.16.023
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工业机器人目标识别和定位研究
{Author}: 颉永鹏
{Tertiary Author}: 朱玉华
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;目标识别;塑料膜片;工业机器人
{Abstract}: 随着我国工业自动化和智能化的发展,机器视觉技术和工业机器人成为人们研究的热点。机器视觉技术有非接触、高敏感性和高适应性的优点,它可以满足不同工业环境下的生产需要。其中单目视觉具有成本低、稳定性好、操作简单和功耗低等优势,因此在缺陷检测、目标识别、视觉引导、机械装配等方面广泛使用。本论文以塑料膜片注塑项目中机器人通过视觉定位将塑料膜片嵌入模具为研究背景,使用单目视觉技术和图像处理算法来实现工业机器人的目标识别和定位。主要的研究内容如下:首先,进行了系统整体结构设计。根据项目中机器人目标识别和定位部分的设计概况,对论文的总体方案进行设计。根据实际的项目需要,对机器人、相机、镜头、光源等硬件进行选型,并对图像处理、数据通讯、计算机编程等软件部分进行了介绍。其次,对图像处理、目标识别和定位算法进行研究。对相机标定和手眼系统标定原理进行了研究,使用Python调用Open CV开源库中的张正友标定法对相机进行标定,获得相机的内外参数和畸变系数;根据项目要求,对机器人的手眼系统进行选择和标定,并进行了精度验证,实验结果表明标定精度误差在0.1mm内。针对环境中光照和噪声对图像的影响,进行了图像处理算法的研究。结合灰度校正、图像滤波等提出了改进的Canny边缘检测算法,与传统Canny算法相比,在滤除噪声的基础上很好的保留了图像的边缘信息。使用模板匹配方法进行目标识别,根据harris角点检测算法在特征提取方法的优势,对SIFT算法进行改进,提高了匹配的正确率和稳定性。为了让机器人将塑料膜片准确的嵌入模具中,使用形态学处理和边缘检测算法获得图像的轮廓,根据轮廓的最小外接矩形获得目标物体的质心坐标和偏转角度。最后,总体方案实现和系统实验。实现了对人机界面设计、编程控制机器人抓取和放置、数据通讯和程序封装等工作。根据系统实验结果表明,目标识别可以达到99.7%,机器人放置塑料薄片的误差始终保持在0.1mm以内,满足工业生产的需要。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000353
{DOI}: 10.27322/d.cnki.gsgyu.2022.000353
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 苹果品质动态无损感知及分级机器手系统
{Author}: 彭彦昆;孙晨;赵苗
{Author Address}: 中国农业大学工学院;国家农产品加工技术装备研发分中心;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 16
{Pages}: 293-303
{Keywords}: 机器视觉;可见/近红外光谱;苹果;无损感知;分级;机器手系统
{Abstract}: 为了实现灵活高效的苹果多品质指标检测分级，基于机器视觉技术及可见/近红外光谱技术，开发了用于苹果内外部品质无损感知及分级的机器手系统。机器手系统采用六轴机械臂搭载自行研发的末端执行器，末端执行器上装载有光学传感器与抓取结构，可以抓取流水线上的苹果并同时采集苹果的光谱进行糖度检测。使用CMOS相机采集苹果图像，训练并使用PP-YOLO深度学习目标检测模型处理采集的苹果图像，计算苹果的坐标位置实现苹果的动态定位，并获取苹果的果径大小、着色度信息实现外部品质检测。采集苹果样本光谱，结合不同的光谱预处理方式，利用偏最小二乘（Partial Least-Square,PLS）方法进行建模分析。试验结果表明，使用PP-YOLO目标检测算法处理图像和计算苹果位置，其识别速度为38帧/s，极大地提高了检测速度。使用归一化光谱比值法（Normalized Spectral Ratio,NSR）作为预处理算法的糖度建模结果较佳。采用NSR+CARS(Competitive Adaptive Reweighted Sampling，竞争性自适应重加权算法)作为机器手的动态光谱模型效果较佳，该动态光谱模型相关系数Rv为0.958 9，验证均方根误差RMSEV(Root Mean Squared Error of Validation)为0.462 7%，与静态下建立的模型相比，机器手在动态状态下采集光谱对所建立的预测模型的预测效果影响较小。对整体机器手系统进行了试验验证，机器手在工作时能够无损伤地抓取苹果，给出果径大小、着色度、糖度3个检测指标并依据指标自动划分等级，然后依据等级信息分级。随后测定了3个指标的实测值与预测值进行分析，果径大小的预测相关系数为0.977 2，均方根误差为1.631 5 mm；着色度的预测相关系数为0.967 4，均方根误差为5.973 4%；糖度的预测相关系数为0.964 3，均方根误差为0.504 8%，预测结果与真实值均具有较强的线性关系和较低的预测误差，机器手系统分级正确率为95%，完成一颗苹果的定位、抓取、检测、分级和放置的时间约为5.2 s，具有较好的工作可靠性，研究结果可为苹果多品质指标的高效检测提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxthsNJDazPDtqk7rux7KoVNpONjRy5Rf-sf4MoTcPNkJJ-hOMpNOg3npho9tOwgXvHtCIL7jLRzEA3K1xBmG7LADAfEDY0ABH2gwDLIjDUpw-fPD5dw5rQBOz_cPZJOFeggu9Jpp_FzGmEuFCGc2_4cy4eokzXRkcegAkvQOflqbY_SP95-6jPOhf7j_Ps97s=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于颜色特征和连通域标记的目标检测算法
{Author}: 杨志林;杨彦锋
{Author Address}: 郑州工业应用技术学院;
{Journal}: 机电工程技术
{Year}: 2022
{Volume}: 51
{Issue}: 08
{Pages}: 57-60
{Keywords}: 机器视觉;颜色特征;连通域;边缘检测
{Abstract}: 为了实现机器视觉图像中目标的准确检测与识别，提出了一种基于YUV颜色空间的颜色特征提取以及具有连通性的目标区域标记的目标检测算法。首先根据目标的颜色特征，人工标定其颜色阈值，通过颜色特征学习，搜索并提取符合目标颜色特征的目标区域；进而对符合目标颜色特征的多个颜色区域，采用四连通的区域标记算法进行区域标识，并结合Warshall算法完成具有相同颜色特征的连通区域的分割，实现同一颜色的多个目标的识别；为消除具有同一颜色特征的噪声点，依次对各个有效颜色区域进行标记、统计以及面积测量，然后依据目标所占屏幕像素面积与目标距离的关系，通过检测距离设定动态面积阈值，过滤噪声，实现准确识别目标区域。实验结果验证了方法的可行性和有效性。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxthsNJDazPDtqk7rux7KoVNpONjRy5Rf8uGkbOT2Hb0hEtm8_fKzffkbu4weXufzvwY01TH4R26ct5apTy2_5PEPaPS7vRg7pxEk4nhV4oE-Y4DsTSmdjrWd6zpL-l6NWQbcjYVXHUNCkDKzJTNO_8zPHt8_EfPmAyOCzOXW_od11kIvQzmJgZgYEwsGBAMok=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 非接触式三维重建技术综述
{Author}: 刘志海;代振锐;田绍鲁;刘飞熠
{Author Address}: 山东科技大学交通学院;山东科技大学机械电子工程学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 23
{Pages}: 9897-9908
{Keywords}: 三维重建;计算机视觉;适用性;非接触式;基本理论
{Abstract}: 三维重建技术是获取研究对象三维信息的主要途径，是计算机视觉和计算机图形学的研究热点，广泛应用于机器人视觉导航、工业制造、医学等领域，具有较高的研究价值。目前，三维重建技术的方法众多，而且研究对象的外界环境、使用设备和物体的几何形状等因素都会对三维重建效果的准确性、稳定性产生影响。为了解三维重建技术各种方法的适用性，对非接触式三维重建技术进行了介绍，包括飞行时间法、基于三角测距的结构光三维重建、光栅重建、单目视觉、双目视觉、多目视觉和基于深度学习的三维重建。分析了各种方法的基本理论，总结了其使用场景并对今后的研究进行了展望。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxAenDqCArhKqDEltOOtfaHWX-4_givD6yO5a2-UhQM3SCMB1owOvBN8xVIkHCN8hOutFsCa7zuO7Q1wI07g-qBTsOJUrZx9z6t98NnyFryF-oSfHSU9sXWpM8FnCcal03l1IVnin5uJv6cidejnSMaQy0bdHgAo3v9RvF0cZBMSO2uL3mqBc7cZmTjsNydi7k=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业采摘机器人视觉感知关键技术研究
{Author}: 周浩;唐昀超;邹湘军;王红军;陈增兴;龙亚宁;艾璞晔
{Author Address}: 华南农业大学工程学院;仲恺农业工程学院城乡建设学院;
{Journal}: 农机化研究
{Year}: 2023
{Volume}: 45
{Issue}: 06
{Pages}: 68-75
{Keywords}: 采摘机器人;机器视觉;深度学习;果实定位
{Abstract}: 为了提高农业机器人在复杂野外环境下采摘油茶果的速度和准确性，针对机器人视觉感知的关键技术，设计了一种农业机器人果实检测、定位和采摘系统。首先，使用双目相机采集油茶果的左右图像；然后，应用先进的目标检测网络YOLOv4-tiny检测出左右图像中的油茶果；再次，不同于传统的双目相机图像的立体匹配技术，根据YOLOv4-tiny网络生成的预测框提取出油茶果图像的感兴趣区域，并根据预测框的生成机制自适应地进行立体匹配以求解出视差，为后续使用三角测量原理求出油茶果采摘点提供参考；最后，使用基于Eye-in-Hand手眼标定的农业机器人进行采摘试验，验证了本研究的可行性和准确性。试验结果表明：YOLOv4-tiny网络能够精确和实时地检测油茶果，提出的定位方法满足采摘机器人的应用需求，验证了本研究的可行性和准确性。研究可为果园环境中作业的农业采摘机器人视觉感知关键技术提供参考。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2023.06.013
{DOI}: 10.13427/j.cnki.njyi.2023.06.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的家庭智能分类垃圾桶设计
{Author}: 宋涛
{Author Address}: 辽宁经济职业技术学院;
{Journal}: 电脑知识与技术
{Year}: 2022
{Volume}: 18
{Issue}: 23
{Pages}: 74-75+78
{Keywords}: 机器视觉;垃圾分类;家庭智能垃圾桶
{Abstract}: 随着社会经济的不断发展，人们的生活水平也有显著提高，伴随着产生的生活垃圾也逐渐增多，对生活垃圾进行分类处理，可以减少垃圾对环境的污染，也可以提高垃圾可回收利用率，但是由于在垃圾分类过程中，人们对垃圾分类概念不了解，还有对垃圾分类意识不强等问题，这些都影响了垃圾分类的效果。基于这些问题提出了利用人工智能中的机器视觉，实现对家庭中的生活垃圾进行自动分类，提高垃圾分类的准确性和处理效率。
{ISBN/ISSN}: 1009-3044
{Notes}: 34-1205/TP
{URL}: https://link.cnki.net/doi/10.14004/j.cnki.ckt.2022.1576
{DOI}: 10.14004/j.cnki.ckt.2022.1576
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 人类动作识别的特征提取方法综述
{Author}: 彭月;甘臣权;张祖凡
{Author Address}: 重庆邮电大学通信与信息工程学院;
{Journal}: 计算机应用与软件
{Year}: 2022
{Volume}: 39
{Issue}: 08
{Pages}: 1-14+68
{Keywords}: 计算机视觉;人类动作识别;特征提取;卷积神经网络;深度学习
{Abstract}: 人类动作识别是计算机视觉领域中一个重要的研究方向，特征提取作为人类动作识别任务的最关键步骤一直备受关注。面向视频中的人类动作识别任务所涉及的特征提取方法，从全局特征提取和局部特征提取这两个方面概括了传统的手工特征提取方法，并详细介绍了基于深度学习的特征提取方法中常用的特征学习模型，主要分为双流卷积网络、多流卷积网络、三维卷积网络与长短时期记忆网络四个方面。总结了动作识别领域中所面临的机遇和挑战并展望了未来可能的研究方向。
{ISBN/ISSN}: 1000-386X
{Notes}: 31-1260/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwlH_FrJktPMZg0TcSEHVEiNH37r7PNN73MLhMwrBdwWH7h2dJDQgHWJXSStdAEnrY0YulYHBEz9ojTx7XP93ONHqaJmPh_l4LIvJ0fLi88O5wohggmycxs0ofVDU7XC6qWNjAbA2HMxf5Pb8rBX88-OiutOwirSgRX5eU6WcTtt_c_5IiM-ytfCpYnxKiuli0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术对智能交通系统发展的促进作用
{Author}: 黄凯宁
{Author Address}: 蚌埠学院计算机与信息工程学院;
{Journal}: 黄河科技学院学报
{Year}: 2022
{Volume}: 24
{Issue}: 08
{Pages}: 59-63
{Keywords}: 计算机视觉技术;智能交通;促进作用
{Abstract}: 为适应科技迅速发展的现代社会，交通系统引进了许多现代化信息技术，特别是近年来快速发展的智能交通系统，大幅降低了交通事故、交通拥堵、违规停车等事件的发生频率。智能交通系统是在计算机技术、人工智能、传感器技术等基础上构建的交通系统，应用计算机视觉技术设计的智能交通系统主要通过现代信息技术、智能技术和自动控制技术等设计相应的实时交通数据收集系统、交通数据信息传输系统、车辆导航系统、交通监控和指挥系统等，便于相关部门掌握交通实时数据，进行有效的监管和指挥，提高现代交通安全性、有序性，促进交通事业快速发展。
{ISBN/ISSN}: 2096-790X
{Notes}: 41-1279/N
{URL}: https://link.cnki.net/doi/10.19576/j.issn.2096-790X.2022.08.011
{DOI}: 10.19576/j.issn.2096-790X.2022.08.011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的奶牛跛行识别技术研究进展
{Author}: 李前;初梦苑;康熙;刘刚
{Author Address}: 中国农业大学智慧农业系统集成研究教育部重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 15
{Pages}: 159-169
{Keywords}: 计算机视觉;图像处理;深度学习;奶牛跛行识别;可见光相机;深度相机;热红外相机
{Abstract}: 奶牛跛行严重降低奶牛福利及潜在产奶量，影响养殖场经济效益。准确高效识别奶牛跛行，有助于奶牛肢蹄病的及早发现与治疗，促进奶业的健康和可持续发展。人工观察法识别奶牛跛行存在识别效率低、成本高、主观性强等问题。计算机视觉技术可以通过无应激、无接触地采集奶牛行走视频数据，准确高效识别奶牛跛行。该研究从可见光相机、深度相机以及热红外相机3种视频采集手段出发，概述了当前奶牛跛行自动识别的主要研究方法、关键技术以及未来发展方向等，对比分析了各研究方法的优势和不足，指出个体差异性、跛行特征的优选以及早期跛行识别等需要重点关注的技术问题。同时，该研究从数据获取、技术研发和试验验证等方面，分析了奶牛跛行识别技术研究领域存在的主要问题及挑战，展望了未来奶牛跛行识别技术的研究重点和发展方向，为奶牛跛行的精准高效识别提供相关理论依据和技术参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzB9m9msC1Z-nXkGmz5zzDGxCbE_nOTesWUbatcdX71AU8jAS8g729PwPHK5zwDYVbZyQnw5QKgCiDhMIA2x0SdcJZPEmB8RfsveYPpXORBqVdykxiHXGFzjpy4jF_LHzn1QZBZVEYuv5wA4s9etAVlXfU6gnDFXj3BM2DVUioPE573CkTbW4BXMKGZ8lF0z60=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的车辆目标检测算法综述
{Author}: 苏山杰;陈俊豪;张之云
{Author Address}: 重庆交通大学机电与车辆工程学院;
{Journal}: 汽车文摘
{Year}: 2022
{Volume}: 
{Issue}: 08
{Pages}: 14-23
{Keywords}: Deep learning;Vehicle object detection;Convolutional Neural Network(CNN);Lightweight network
{Abstract}: 近20年来，随着以物联网技术，计算机视觉技术为代表的核心技术蓬勃发展，基于深度学习的目标检测算法在各个领域都受到了较高的重视，而车辆目标检测是基于深度学习的目标检测中的一个重要研究领域，也是应用在智能驾驶、智能交通系统中非常重要的一部分。针对车辆目标检测任务，首先对深度学习的车辆目标检测进一步探讨，提出检测任务的重点、难点及发展现状，以时间线对卷积神经网络下车辆目标检测算法进行概括，并对目前2种主流的基于候选框和基于回归的车辆目标检测算法进行总结。伴随着目标检测算法的更加轻量化，检测性能更加优越，将在嵌入式设备得到应用，以提高检测任务的效率。在未来自动驾驶，智能交通系统领域对于安全性，实时性的要求会更高，使得车辆目标检测算法有较好的发展前景。
{ISBN/ISSN}: 1671-6329
{Notes}: 22-1112/U
{URL}: https://link.cnki.net/doi/10.19822/j.cnki.1671-6329.20220011
{DOI}: 10.19822/j.cnki.1671-6329.20220011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Harris角点检测算法的应用研究
{Author}: 姚依妮;王玮
{Author Address}: 洛阳科技职业学院智能制造与汽车工程学院;
{Journal}: 智能计算机与应用
{Year}: 2022
{Volume}: 12
{Issue}: 08
{Pages}: 148-151
{Keywords}: 机器视觉;图像处理;特征点;Harris角点
{Abstract}: 角点是机器视觉和图像处理技术中常用的特征点，在降低信息数据量的同时有效保留了图像的重要特征，现已广泛应用于各个领域，用来实现图像处理的特定要求。本文先对Harris角点检测算法原理进行阐述；再详细介绍改进的Harris角点检测算法的应用领域及效果；最后，对Harris角点检测的研究趋势做出总结和展望，为Harris角点检测的研究和应用提供参考。
{ISBN/ISSN}: 2095-2163
{Notes}: 23-1573/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwNDzNThRZFAscBSqKY69nvmwpibh01EiY7zKTthTD8n0yOgDL1AljNxotkRU1IwNC8l0tGiCcEQLUFA0pRKfKmqhX3RJ5vORDYcDmzfo_sLcG5ofO6iP6bxdULm2XbftNhGNfHnZDQWw6NfGnrdg6foQ2ut2Ef7t1A_MMkQufmwyKwz60minK70UMFmPcJ-kg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向复杂场景的行人重识别综述
{Author}: 张敏;余增;韩云星;李天瑞
{Author Address}: 西南交通大学计算机与人工智能学院;综合交通大数据应用技术国家工程实验室;西南交通大学唐山研究生院;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: 10
{Pages}: 138-150
{Keywords}: 行人重识别;深度学习;特征提取;度量学习;计算机视觉
{Abstract}: 行人重识别(Person Re-Identification,简称Re-ID)旨在研究多个不相交摄像头间特定行人的匹配问题。文中首次以复杂场景中需要克服的挑战为行人重识别论文的分类依据，将2010-2021年期间发表的研究成果分为7类，即姿势问题、遮挡问题、照明问题、视角问题、背景问题、分辨率问题以及开放性问题，该分类方式有利于研究人员从实际需求出发，根据要解决的问题找到相应的解决方案。首先回顾行人重识别的研究背景、意义及研究现状，总结当前主流的行人重识别框架，统计了2013年以来发表在三大计算机视觉顶级会议CVPR,ICCV以及ECCV的论文情况和国家基金项目中Re-ID的相关项目情况；其次就复杂场景中面临的七大挑战，分别从问题成因和解决方案两方面对现有文献展开分析，归纳总结出处理各类挑战的主流方法；然后给出了行人重识别研究中泛化性较高的方法，并列举了当前行人重识别研究的难点；最后讨论了行人重识别未来的发展趋势。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.TP.20220722.1808.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 依据批归一化卷积神经网络算法的木材类别机器视觉识别方法
{Author}: 袁科文;张贯宇;刘送永;杨建华;卢硕辰;刘后广
{Author Address}: 中国矿业大学;
{Journal}: 东北林业大学学报
{Year}: 2022
{Volume}: 50
{Issue}: 07
{Pages}: 94-98
{Keywords}: 木材分类;批归一化;卷积神经网络;机器视觉
{Abstract}: 以巴西植物区系的树种为研究对象，提出一种依据批归一化的卷积神经网络算法的木材类别机器视觉识别方法。以VGG-16模型为基础，通过批归一化对输入数据进行处理调整卷积神经网络的中间输出参数，以2个全连接层替换VGG-16模型原全连接层，使用5标签的SoftMax分类器替换原SoftMax分类器，构建一个依据优化后的全连接层和SoftMax分类层相结合的新型木材种类识别模型(模型包括卷积层、批归一化层、激活层、池化层、全连接层、SoftMax分类层)。以桃花心木(Swietenia macrophylla)、苏里南维罗蔻木(Virola surinamensis)、轴状独蕊木(Erisma uncinatum)、酸枝木(Dalbergia cochinchinensis)、黄金檀木(Cordia elaeagnoides)5种木材纹理图片为训练样本(原始样本455张、增强样本2 730张),输入模型进行训练并测试，检验模型对木材类别的识别准确率。结果表明：依据批归一化卷积神经网络算法对木材类别的识别准确率，比AlexNet、VGG-16、GoogLeNet模型更好；经批归一化和数据增强处理后，构建的卷积神经网络模型可以加快模型的收敛速度，提高模型的泛化能力，木材类别识别准确率达到99.46%。
{ISBN/ISSN}: 1000-5382
{Notes}: 23-1268/S
{URL}: https://link.cnki.net/doi/10.13759/j.cnki.dlxb.2022.07.010
{DOI}: 10.13759/j.cnki.dlxb.2022.07.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: “机器视觉技术及应用”专题前言
{Author}: 于起峰;卢荣胜;刘晓利;王程;李璋
{Author Address}: 中国科学院;国防科技大学空天科学学院;国防科技大学科技委;合肥工业大学;无锡维度机器视觉产业技术研究院;安徽省计量测试学会;深圳大学;仪器仪表图形图像学会;厦门大学;福建省智慧城市感知与计算重点实验室;国际摄影测量与遥感学会(ISPRS)多传感器集成与融合工作组;中国计算机学会;中国图像图形学会;国防科技大学图像测量与视觉导航实验室;湖南省力学学会;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 4+3
{Abstract}: <正>机器视觉是研究如何让机器看见和理解目标场景，并快速作出决定的一种科学与技术。一个典型的机器视觉系统一般包含图像获取、数据传输、处理分析、决策及执行4个部分，具有“感-传-知-用”的系统特征。在成像技术、处理算法、算力平台和行业应用4个核心要素的驱动下，机器视觉目前已广泛应用于工业视觉、图像解释、物体识别、虚拟现实、生命科学、智能安防、自动驾驶、人机交互等领域。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxGH78Sn6QVSrVRPd93O8Lh3jpNjBu2qgqU2V5_HxMSf7pIlfO1j7XYzcZO4YVscbf-2xbB7MZVb_Vnqt9HH6L_6EcZZ9L-l08rHoTg9BYyXyv9QiK3BLb3XiQ1z7-BXkwGIi6fRz1a6eJgQyyjH-QQu3YePU9oDzIwvkax7i6of0MgOzF8mwmlieWM5KQiu9w=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于特征组合与SVM的小粒种咖啡缺陷生豆检测
{Author}: 赵玉清;杨慧丽;张悦;杨颜凯;杨毅;赛敏
{Author Address}: 云南农业大学机电工程学院;昆明理工大学交通工程学院;云南省作物生产与智慧农业重点实验室;云南农业大学大数据学院;云南普洱市长木咖啡有限公司;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 14
{Pages}: 295-302
{Keywords}: 机器视觉;识别;特征组合;SVM;缺陷生咖啡豆;检测模型
{Abstract}: 缺陷生咖啡豆显著影响商品咖啡豆品质及定价，其分选剔除是咖啡豆烘焙前的重要工作环节。目前缺陷豆的检测、分选及剔除主要由人工操作完成，耗时、费力且主观性大。该研究采用机器视觉技术提取咖啡豆轮廓、颜色和纹理3类特征，使用单一类别特征和不同类别特征进行组合，运用网格搜索确定支持向量机（Support Vector Machine,SVM）分类模型参数，通过k折交叉验证试验对比SVM模型性能，运用皮尔逊相关系数进行特征筛选，找到检测缺陷生咖啡豆的较优特征组合。为说明SVM检测模型的有效性，选用随机森林（Random Forests,RF）、极端随机树（Extremely Randomized Trees,ERT）、逻辑回归（LogisticRegression,LR）、LightGBM、XGBoost和CatBoost算法进行较优特征组合的对比试验。结果表明：包括轮廓、颜色和纹理3类14个特征的组合是较优特征组合，其SVM检测模型的平均准确率、平均精度、平均召回率、平均F1值分别为84.9%、85.8%、82.3%、84.0%，效果均明显优于2类特征组合和单一类别特征的检测模型，SVM检测模型的准确率和F1值相比随机森林、极端随机树、逻辑回归、LightGBM、XGBoost和CatBoost分别提高4.7和4.8,3.4和4.0,5.6和7.2,3.0和3.0,3.5和4.2,2.6和2.6个百分点。较优特征组合的SVM缺陷生咖啡豆检测模型检测缺陷类型较全面，识别准确率高，可实际应用于小粒种生咖啡豆智能化分选装备。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzeoLE9jLA7yX8cm2WGuTVd8aybpd6XIzcthwiW1Glwzgbej_YOKubx6vXNk9ymC95HvgjGfTx0E7IuvaVhAAPyr2VM7AzM0rEmVxx-xjoi-4xSnhzrBkQK7uaippMAR13H9JkWh7cAFDmLmHo5oQNMQuzjiq6u5FuP2L9-HHlDywaFhNf1gvdR5qclPGHpkPM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像边缘检测方法性能比较
{Author}: 齐艳丽;汪代俊
{Author Address}: 安徽省质量和标准化研究院;
{Journal}: 中国标准化
{Year}: 2022
{Volume}: 
{Issue}: 14
{Pages}: 141-144
{Keywords}: 边缘特征;边缘检测;图像处理;Canny边缘检测
{Abstract}: 边缘特征是图像的关键特征之一，因此准确地进行边缘检测对于图像识别、计算机视觉、视频监控等领域应用具有十分重要的意义。本文选择Canny、Roberts、Sobel、Prewitt等四种常见的图像边缘检测方法进行了研究，并基于美国加州大学伯克利分校计算机视觉组提供的BSDS500数据集进行了性能比较和分析。实验结果表明，采用默认参数条件下Canny方法具有较好的识别效果，而Roberts方法边缘检测算法相对较差。
{ISBN/ISSN}: 1002-5944
{Notes}: 11-2345/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyIocVBW9J9Ko91MB8JnD3S7hds9lTfMYXx7Y0PMIjZkwFZDUmpfJXtZ7iMhys_y2wlUW1lZLvXhdI5-8O7BYUr1994EFtoQjC7-kxnsYs84NVNIu4JLzEtCww8-ZSarBflG-0o6u7DIWLxCz2C9U7XGjLjyABpv-HlDnU5Zniv-nuaOD40ZPXwTMN3DABUDo0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的焊缝识别研究现状与发展趋势
{Author}: 张帆;泮佳俊;刘腾;张浩;李佩齐
{Author Address}: 南通大学张謇学院;
{Journal}: 电焊机
{Year}: 2022
{Volume}: 52
{Issue}: 07
{Pages}: 24-33+61
{Keywords}: 机器视觉;焊缝识别;视觉传感器;图像处理
{Abstract}: 机器视觉技术以其高精度、高自动化等特点被广泛用于工业测量、工业检测和识别等领域。概括了几种焊缝识别传感技术，并对传感方式的基本原理和特点进行了分析。详细阐述了基于机器视觉的焊缝识别的具体实现步骤，重点归纳总结了针对不同的噪声和干扰采用相应的滤波和消除方法、焊缝的特征提取与中心线拟合方法等。在国内外焊缝识别研究的基础上，提出了几个有价值的研究方向，包括基于新型测距法及其传感器的焊缝定位、基于卷积神经网络的焊缝类型识别、针对焊后质量检测的三维信息重构和多种干扰因素并存情况下的焊缝识别等。
{ISBN/ISSN}: 1001-2303
{Notes}: 51-1278/TM
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwToEO7Y5a8emvK7HeFZOqIeb_SpYIcxPTLdtid4nEGf2Zm92z1CdIsaLMzVhRuN9mMUqoVNpcbKuVhUIV4_3UdMc9tYSJI0hMao58XNOBfiro8UcMHz3TH_ZwHOBktSOoOk_w-Nno6C7W4U6RpbpqGnf7uFFWawOAhS1jzuDDPj35OvRjLYbVdQ2JWP33fizE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 齿轮视觉检测仪器与技术研究进展
{Author}: 石照耀;方一鸣;王笑一
{Author Address}: 北京工业大学北京市精密测控技术与仪器工程技术研究中心;河南科技大学河南省机械设计及传动系统重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 74-86
{Keywords}: 机器视觉;齿轮测量;齿轮视觉检测仪器;齿轮精度测量;齿轮缺陷检测
{Abstract}: 相对于接触式测量，机器视觉检测这种非接触式测量具有效率高、信息全、稳定性好、可识别缺陷等优点，在齿轮检测领域得到越来越广泛的应用。近十年来出现了影像仪、闪测仪、CVGM仪器、在线检测设备等多种基于机器视觉技术的齿轮检测仪器，它们既可以实现齿轮综合式测量，又可以实现齿轮分析式测量。回顾了齿轮视觉检测仪器的发展历程和特点，分析了齿轮视觉检测中边缘检测、亚像素定位、特征提取和模式识别等算法的研究和应用进展，总结了机器视觉在齿轮精度测量和齿轮缺陷检测两个方面的技术发展，并指明了齿轮视觉检测仪器与技术的发展前景。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.tn.20220714.1314.367
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的亚像素精度法兰盘尺寸测量方法
{Author}: 焦博;刘国宁;赵孟轩;马光岩
{Author Address}: 郑州大学机械与动力工程学院;
{Journal}: 现代制造工程
{Year}: 2022
{Volume}: 
{Issue}: 07
{Pages}: 121-126
{Keywords}: 机器视觉;亚像素;法兰盘;尺寸检测
{Abstract}: 针对空调压缩机法兰盘尺寸人工测量方式存在效率低、精度难以保证等问题，提出一种基于机器视觉的法兰盘尺寸亚像素级别测量方法，并构建视觉测量系统。对法兰盘图像，先使用转灰度、中值滤波和二值化分割进行预处理，抑制图像噪声，同时提取目标法兰盘区域；再使用Canny算子获取法兰盘边缘像素坐标；然后根据Zernike算法对旋转、尺度等不敏感的特点，使用改进的Zernike矩亚像素边缘检测算法重新定位法兰盘边缘，获取法兰盘边缘的亚像素级别坐标；最后使用最小二乘拟合算法得到法兰盘外圆直径与内孔直径尺寸。实验证明，该检测方法与人工测量方式相比效率高、精度高，能够满足对法兰盘关键尺寸的在线测量需求。
{ISBN/ISSN}: 1671-3133
{Notes}: 11-4659/TH
{URL}: https://link.cnki.net/doi/10.16731/j.cnki.1671-3133.2022.07.019
{DOI}: 10.16731/j.cnki.1671-3133.2022.07.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 动态场景下基于光流和实例分割的视觉SLAM方法
{Author}: 徐陈;周怡君;罗晨
{Author Address}: 东南大学机械工程学院;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 14
{Pages}: 147-159
{Keywords}: 机器视觉;视觉里程计;动态场景;光流;运动物体检测;实例分割
{Abstract}: 为提升动态场景中视觉SLAM(Simultaneous Localization and Mapping)系统的定位精度和鲁棒性，提出一种基于光流和实例分割的视觉SLAM方法。针对动态物体和静态背景光流方向的不一致性，提出一种高实时性动态区域掩模检测算法，从而在ORB-SLAM2原有跟踪线程中实时地剔除处于动态区域掩模中的特征点。利用已有深度图和跟踪线程位姿估计的信息去除相机运动相关光流，然后聚类动态物体自身运动产生的光流幅值，从而实现高精度的动态区域掩模检测，并结合对极几何约束剔除局部建图线程中的动态路标点。在TUM和KITTI数据集上的测试结果表明，在高动态场景下，本文算法相较ORB-SLAM2、Detect-SLAM、DS-SLAM，定位精度平均提升97%、64%和44%。相较DynaSLAM，本文算法在一半的高动态场景中定位精度平均提升20%，这验证了本文算法在高动态场景中提升了系统定位精度和鲁棒性。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://link.cnki.net/urlid/31.1252.O4.20220714.1319.060
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 单相机三维视觉成像技术研究进展
{Author}: 刘兴盛;李安虎;邓兆军;陈昊
{Author Address}: 同济大学机械与能源工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 87-105
{Keywords}: 机器视觉;三维成像;立体视觉;相机运动;光学元件;参数标定
{Abstract}: 机器视觉应用场景复杂化和功能需求多元化给三维成像技术带来巨大挑战。针对复杂环境及受限空间的目标重建和场景感知问题，结构简单且性能可靠的单相机三维视觉成像技术能够提供重要的解决途径。在阐明单相机三维立体视觉成像理论模型的基础上，根据相机运动情况以及采用的反射、折射或衍射等附加光学元件的情况，分类介绍了单相机三维视觉成像系统组成、基本原理和实现方法。从视场范围、空间分辨率、视角灵活性、动态响应性、环境适应性等角度，分析了现有单相机三维视觉成像方法的优越性和局限性。围绕三维重建精度及成像质量提升问题，回顾了相机与附加光学元件未对准参数的主要标定方法。结合单相机三维视觉成像的技术挑战和应用前景，展望了其在实现大视场高分辨率、高动态高实时性、复杂环境适应性等方面的发展方向。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220714.1207.128
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的划痕检测技术综述
{Author}: 杨乐淼;周富强
{Author Address}: 北京航空航天大学仪器科学与光电工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 118-125
{Keywords}: 机器视觉;划痕检测;数字图像处理;深度学习
{Abstract}: 在现阶段的智能制造过程中，精密产品及仪器表面的零划痕质量要求不断提高，基于机器视觉的划痕检测方法因其无损高精度的特点具有重要的研究意义。综述了基于机器视觉的划痕检测技术的发展现状，将目前主流的划痕检测方法分为手工设计特征方法和深度学习方法。基于手工设计特征的划痕检测方法包括灰度分布统计法、变换域法和高低维空间映射法，基于深度学习的划痕检测方法包括有监督学习方法和无监督学习方法，总结了每种方法的优缺点和适用场景，阐述了基于机器视觉的划痕检测技术的发展趋势。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220714.1209.142
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的双目立体匹配方法综述
{Author}: 尹晨阳;职恒辉;李慧斌
{Author Address}: 西安交通大学数学与统计学院;
{Journal}: 计算机工程
{Year}: 2022
{Volume}: 48
{Issue}: 10
{Pages}: 1-12
{Keywords}: 计算机视觉;深度学习;双目图像;立体匹配方法;图像深度
{Abstract}: 双目立体匹配是计算机视觉领域的经典问题，在自动驾驶、遥感、机器人感知等诸多任务中得到广泛应用。双目立体匹配的主要目标是寻找双目图像对中同名点的对应关系，并利用三角测量原理恢复图像深度信息。近年来，基于深度学习的立体匹配方法在匹配精度和匹配效率上均取得了远超传统方法的性能表现。将现有基于深度学习的立体匹配方法分为非端到端方法和端到端方法。基于深度学习的非端到端方法利用深度神经网络取代传统立体匹配方法中的某一步骤，根据被取代步骤的不同，该类方法被分为基于代价计算网络、基于代价聚合网络和基于视差优化网络的3类方法。基于深度学习的端到端方法根据代价体维度的不同可分为基于3D代价体和基于4D代价体的方法。从匹配精度、时间复杂度、应用场景等多个角度对非端到端和端到端方法中的代表性成果进行分析，并归纳各类方法的优点以及存在的局限性。在此基础上，总结基于深度学习的立体匹配方法当前面临的主要挑战并展望该领域未来的研究方向。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0064294
{DOI}: 10.19678/j.issn.1000-3428.0064294
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进CenterNet的水下目标检测算法
{Author}: 王蓉蓉;蒋中云
{Author Address}: 上海海洋大学信息学院;上海建桥学院信息技术学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 02
{Pages}: 239-248
{Keywords}: 机器视觉;水下目标检测;CenterNet;高分辨率网络;注意力机制;特征融合
{Abstract}: 针对常规目标检测器检测水下目标时存在特征提取困难、目标漏检等问题，提出一种改进CenterNet的水下目标检测算法。首先，使用高分辨率人体姿态估计网络HRNet代替CenterNet模型中的Hourglass-104骨干网络，降低模型参数量，提升网络推理速度；其次，引入瓶颈注意力模块，在空间维度及通道维度进行特征增强，使网络关注重要目标特征信息，提高检测精度；最后，构建特征融合模块，融合网络内部丰富的语义信息和空间位置信息，并利用感受野模块增强融合后的特征，提高网络多尺度目标检测能力。在URPU水下目标检测数据集上进行实验，与CenterNet相比，所提算法的检测精度可达77.4%，提升1.5个百分点，检测速度为7 frame/s，提升35.6%，参数量为30.4 MB，压缩84.1%，同时与其他主流目标检测算法相比具有更高的检测精度，在水下目标检测任务上更具优势。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220713.1233.102
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于半监督学习和生成对抗网络的医学图像融合算法
{Author}: 尹海涛;岳勇赢
{Author Address}: 南京邮电大学自动化学院人工智能学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 22
{Pages}: 245-254
{Keywords}: 机器视觉;生成对抗网络;半监督学习;医学图像融合;注意力机制
{Abstract}: 为了有效利用少量的医学图像标签数据和大量的无标签数据，提出了一种基于半监督学习和生成对抗网络的医学图像融合算法。所提生成对抗网络融合架构包含1个生成器网络和2个判别器网络。采用半监督学习策略对所提网络进行训练，主要包括监督训练、无监督训练、参数微调等3个阶段。此外，生成器由面向融合任务的U-Net和squeeze and excitation通道注意力模块组成，而判别器含有3层卷积层、1层全连接层及sigmoid激活输出层。在各种不同模态医学图像上的实验结果表明，与现有的6种基于深度学习的算法相比，所提算法的主观视觉效果和客观性能指标都有一定竞争力。相关消融实验也验证了半监督学习策略能强化生成网络的性能，提高融合图像的质量。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220713.1218.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉和人工智能技术的图书馆图书盘点系统的探索与应用
{Author}: 王晓刚;钱思文;张继;郭俊俊;潘操
{Author Address}: 常州市武进区图书馆;常州大学机器人产业学院;常州大学计算机与人工智能学院;常州大学微电子与控制工程学院;
{Journal}: 图书馆杂志
{Year}: 2022
{Volume}: 41
{Issue}: 07
{Pages}: 96-100
{Keywords}: 图书盘点;计算机视觉;书脊分割;文字识别
{Abstract}: 针对现代图书馆对图书自动盘点的需求，基于计算机视觉和人工智能技术设计了图书馆图书盘点系统。使用Mask R-CNN深度学习网络对书脊图像进行实例分割，再对分割后的书脊图像提取书架号和书名位置并进行文字识别，最终对书架号和书名两步验证确认书籍是否乱架。通过实地采集图像并测试表明，本文方法对于不同类型的书脊图像能够实现较好的分割和识别效果，能够准确地检测出乱架书籍，适合搭载在图书馆自动盘点机器人上，可以有效提高图书盘点的工作效率。
{ISBN/ISSN}: 1000-4254
{Notes}: 31-1108/G2
{URL}: https://link.cnki.net/doi/10.13663/j.cnki.lj.2022.07.013
{DOI}: 10.13663/j.cnki.lj.2022.07.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度神经网络图像目标检测算法综述
{Author}: 付苗苗;邓淼磊;张德贤
{Author Address}: 河南工业大学信息科学与工程学院;河南省粮食信息处理国际联合实验室;
{Journal}: 计算机系统应用
{Year}: 2022
{Volume}: 31
{Issue}: 07
{Pages}: 35-45
{Keywords}: 卷积神经网络;特征提取;深度学习;目标检测;计算机视觉
{Abstract}: 随着深度卷积神经网络优异的特征提取能力被发掘,目标检测的进程开始以一种势不可挡的姿态向前推进,同时,和深度学习结合的目标检测技术取得了显著的成果,在自动驾驶、智能化交通系统、无人机场景、军事目标检测和医学导航等现实场景中得到了广泛的应用.本文回顾了传统目标检测算法的缺点,介绍了常用的检测数据集以及性能评估指标,综述了基于深度学习的目标检测经典算法,阐述了当前目标检测的以及存在的困难与挑战,对目标检测的未来可行的研究方向进行了展望.
{ISBN/ISSN}: 1003-3254
{Notes}: 11-2854/TP
{URL}: https://link.cnki.net/doi/10.15888/j.cnki.csa.008595
{DOI}: 10.15888/j.cnki.csa.008595
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉识别技术在机械传动领域的发展与应用
{Author}: 吴鲁纪;秦佳音;李安虎;杨林杰
{Author Address}: 郑州机械研究所有限公司;同济大学机械与能源工程学院;
{Journal}: 机械传动
{Year}: 2022
{Volume}: 46
{Issue}: 07
{Pages}: 167-176
{Keywords}: 机器视觉;图像识别;传动零部件;发展趋势
{Abstract}: 阐述了基于机器视觉的图像采集方法及其在多个领域中的应用；介绍了图像处理技术，以齿轮齿面为例，给出了各个方法的处理结果示意图；对多种分类识别技术的特点和应用现状进行综述，并给出了基于卷积神经网络的轴承表面损伤识别案例；最后，对机器视觉识别技术在机械传动领域，如齿轮齿面损伤识别方向的应用及发展趋势做出了展望。
{ISBN/ISSN}: 1004-2539
{Notes}: 41-1129/TH
{URL}: https://link.cnki.net/doi/10.16578/j.issn.1004.2539.2022.07.025
{DOI}: 10.16578/j.issn.1004.2539.2022.07.025
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Swin Transformer的森林火灾检测算法
{Author}: 叶铭亮;周慧英;李建军
{Author Address}: 中南林业科技大学计算机与信息工程学院;
{Journal}: 中南林业科技大学学报
{Year}: 2022
{Volume}: 42
{Issue}: 08
{Pages}: 101-110
{Keywords}: 森林火灾;深度神经网络;Swin Transformer;目标检测
{Abstract}: 【目的】森林火灾常常会对人类的财产和生态多样性造成巨大损害，传统的森林火灾检测技术存在可靠性低、造价过高等不足。目前基于卷积神经网络的深度学习算法在处理图像型数据上具有准确性高、成本低、速度快等优势，但是其处理视觉要素和物体之间关系的能力不如Transformer。因此，本研究提出一种改进Swin Transformer网络的方法应用于森林火灾检测。【方法】Transformer是一种基于自注意机制的深度神经网络，其强大的表现能力使得其能够在计算机视觉领域大放异彩。Swin Transformer提出将Transformer应用于计算机视觉任务,构建了一种名为Swin Transformer Blocks的骨干网络，并且提出了一种滑动窗口多头自注意力机制。本文结合Transformer与深度学习算法并应用于森林火灾检测领域，在Swin Transformer网络结构中对窗口自注意力机制进行改进，采用了knn自注意力提高对小块噪声的识别，使用Augmentation数据增强方法增加模型的泛化能力。【结果】数据集为自建的森林火灾图像数据集，通过旋转、裁剪、模糊以及色彩调节等数据增广的方法将300张不同环境下的森林火灾图像数据扩充到1 900张图像，最后对Swin Transformer以及改进后的模型进行对比实验，改进后的算法准确率可达98.1%,bbox＿mAP、bbox＿mAP＿50和bbox＿mAP＿75分别达到了66.7%、96.4%和81.3%。【结论】本文提出一种改进Swin Transformer应用于森林火灾检测的方法。研究结果表明，改进的Swin Transformer模型能够有效检测不同环境下的森林火灾。
{ISBN/ISSN}: 1673-923X
{Notes}: 43-1470/S
{URL}: https://link.cnki.net/doi/10.14067/j.cnki.1673-923x.2022.08.010
{DOI}: 10.14067/j.cnki.1673-923x.2022.08.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像去雾技术研究综述
{Author}: 李博文;刘进锋
{Author Address}: 宁夏大学信息工程学院;
{Journal}: 现代计算机
{Year}: 2022
{Volume}: 28
{Issue}: 13
{Pages}: 57-61
{Keywords}: 深度学习;图像去雾;图像增强;计算机视觉
{Abstract}: 图像去雾是计算机视觉领域一个重要的研究方向，旨在从有雾图像中获取原有场景的细节和纹理特征等信息，进而得到清晰无雾的图像。作为一项基础的图像处理任务，图像去雾技术有着广泛的应用。为了探究图像去雾算法的发展历程与研究现状，现将去雾算法按照所使用图像数量的不同分为多幅图像去雾算法和单幅图像去雾算法两大类。首先梳理了图像去雾算法的发展历程与研究现状，然后对比总结了各类算法的异同点，最后讨论了图像去雾算法的研究所面临的潜在问题，并对未来的研究方向做出了全新的展望。
{ISBN/ISSN}: 1007-1423
{Notes}: 44-1415/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz81lMcBTDYTr-cg_xKIXsQobmilOIW_KWHxHsA8VfTZ-8VWs-QkrY0BUSL0IgGvmQi5EQ9gs1oulIuptRSgn0MizIntlKMzdie4IvBCffg5XZimPn0qoW5TNGcKnLDGJ0jET7yQtBePY_VMLMba019fFqCoywMI0aMuUBeZTXlIgQJxUEAwhOaaoc3N-LZBIo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 家畜体尺自动测量技术研究进展
{Author}: 初梦苑;司永胜;李前;刘刚
{Author Address}: 中国农业大学智慧农业系统集成研究教育部重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;河北农业大学信息科学与技术学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 13
{Pages}: 228-240
{Keywords}: 机器视觉;图像处理;家畜养殖;体尺测量;目标分割;无损监测
{Abstract}: 家畜体尺参数是评价家畜生产性能的关键指标之一，可为选取优良品种提供重要参考依据。人工测量家畜体尺费时费力、主观性强、有损动物福利。随着计算机技术的应用普及，家畜体尺自动测量技术发展较快，取得了较好的研究成果。该研究从家畜数据采集与预处理、家畜直线体尺测量、家畜围度体尺测量3个方面，阐述了家畜体尺自动测量技术的一般流程、常见技术、研究现状及方法优劣。首先，数据采集与预处理是家畜体尺自动测量的重要步骤，包括家畜图像数据的采集、分析与处理，输出便于体尺测点定位的数据，为家畜直线与围度体尺测量奠定基础；其次，家畜直线体尺测量技术基于数字图像处理和计算机视觉等方法，提取直线体尺测点并计算体尺测量值，是目前家畜体尺自动测量领域的主要研究内容；最后，因家畜围度体尺测量难度较大，其测量方法也是近年来相关领域研究的难点，胸围、腹围等体尺参数是家畜体质量和肉产量的重要参考指标，围度体尺测量主要包括体尺测点定位、围度体尺曲线拟合与尺寸计算。该研究还探讨了目前家畜体尺自动测量领域存在的成本高、自动化程度低、实时性与普适性差等问题，展望了未来该领域发展趋势，以期为开展家畜体尺自动测量技术与方法研究提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxKmjThrvjquyGWh7Pkg5OhP7rbon37ggdNQq7JCDGd5RzzNwHt4KGcyFo2SfCyUbE6_zDdPTozJxEUhYBCk2D2SNrhcBO1uweQFkHhWTz82rcGEPoxz1oXuZkhSVY9Jwf1GGB5O6-t7fZnXvAnzSmszHdRb9xqq4mv9wwzEP87ysFJwBJ3u2X-LvsVOxSHqsk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于轮廓角点检测的螺纹关键参数视觉测量方法
{Author}: 江涛;李媛;贺晨龙
{Author Address}: 陕西科技大学电气与控制工程学院;
{Journal}: 电子测量与仪器学报
{Year}: 2022
{Volume}: 36
{Issue}: 07
{Pages}: 54-61
{Keywords}: 螺纹测量;机器视觉;Canny算子;分段拟合;CTAR算法;角点检测
{Abstract}: 为解决现有螺纹关键参数视觉测量方法中易存在螺纹角点误检和漏检导致测量精度降低的问题，本文提出一种基于轮廓角点检测的视觉测量方法。首先，使用双边滤波和迭代阈值法改进Canny算子，提高边缘检测的精度；其次，使用双阈值DP算法和Hough变换对轮廓进行分段拟合，在保护边缘的前提下平滑轮廓，并在此基础上使用CTAR算法提取螺纹牙顶、牙底的角点；最后，根据角点的位置信息实现螺纹大径、小径的测量。实验结果表明，相对于现有使用Canny算子和Harris角点检测的视觉测量方法，该方法能准确可靠地检测螺纹的边缘和角点，实现螺纹参数的高精度测量，螺纹大径、小径的平均测量精度分别达到0.003 3 mm和0.002 6 mm。
{ISBN/ISSN}: 1000-7105
{Notes}: 11-2488/TN
{URL}: https://link.cnki.net/doi/10.13382/j.jemi.B2205246
{DOI}: 10.13382/j.jemi.B2205246
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉成熟度检测的苹果色选分拣机设计
{Author}: 王丽娟;陈浩然;季石军;刘志刚
{Author Address}: 南通科技职业学院机电与交通工程学院;
{Journal}: 农业与技术
{Year}: 2022
{Volume}: 42
{Issue}: 12
{Pages}: 36-40
{Keywords}: 成熟度;机器视觉;颜色信息;无损检测;分拣机
{Abstract}: 我国是世界上水果第一生产国与消费国，所以如何对水果进行快速以及准确的分拣至关重要。设计了基于机器视觉成熟度检测的苹果色选分拣机，该装置主要由装置主体和传输装置、分拣设备及机器视觉检测系统组成，用于辅助水果经营企业、水果后处理企业进行自动化传输、水果成熟度检测与水果分拣，旨在降低工人的劳作强度，提高成熟度检测正确率与效率和实现流水线生产需求。该装置操作简单、价格低廉、结构新颖、实用性强，适用于多种类水果的成熟度检测。基于此，对该装置的使用背景、研究现状、整体设计介绍、部件设计介绍、使用效果分析等进行了详细说明，以全面展示该装置及其使用方法。
{ISBN/ISSN}: 1671-962X
{Notes}: 22-1159/S
{URL}: https://link.cnki.net/doi/10.19754/j.nyyjs.20220630009
{DOI}: 10.19754/j.nyyjs.20220630009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 生成对抗网络及其文本图像合成综述
{Author}: 王威;李玉洁;郭富林;刘岩;何俊霖
{Author Address}: 桂林电子科技大学人工智能学院;郑州轻工业大学计算机与通信工程学院;
{Journal}: 计算机工程与应用
{Year}: 2022
{Volume}: 58
{Issue}: 19
{Pages}: 14-36
{Keywords}: 文本图像合成;生成对抗网络;文本编码;深度学习
{Abstract}: 随着深度学习的快速发展，基于生成对抗网络的文本图像合成领域成为了当下计算机视觉研究的热点。生成对抗网络同时包含生成器和鉴别器，通过两者的博弈来实现逼真数据的生成。受生成对抗网络的启发，近几年提出了一系列的文本图像合成模型，从图像质量、多样性、语义一致性方面不断取得突破。为推动文本图像合成领域的研究发展，对现有文本图像合成技术进行了全面概述。从文本编码、文本直接合成图像、文本引导图像合成方面对文本图像合成模型进行了分类整理，并详细探讨了各类基于生成对抗网络的代表性模型的模型框架和关键性贡献。分析了现有的评估指标和常用的数据集，提出了现有方法在复杂场景和文本、多模态、轻量化模型、模型评价方法等方面的不足和未来的发展趋势。总结了目前生成对抗网络在各领域的发展，重点关注了在文本图像合成领域的应用，可以作为一个研究人员进行图像合成研究时选择深度学习相关方法的权衡和参考。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20220627.1413.018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5的红外相机野生动物图像识别
{Author}: 杨铭伦;张旭;郭颖;于新文;侯亚男;高家军
{Author Address}: 中国林业科学研究院资源信息研究所;国家林业和草原局林业遥感与信息技术重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 12
{Pages}: 382-390
{Keywords}: 机器视觉;野生动物;目标检测;YOLOv5;图像识别;深度学习
{Abstract}: 为在红外相机等资源受限平台上实时、准确地实现海量野生动物图像自动识别，改善野生动物监测过程中数据传输负载重、时效性低等问题，基于YOLOv5模型，利用5类物种的红外相机图像构建数据集，对YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x四种网络结构进行训练。通过对比不同网络结构的精度、检测速度、体积，明确最优网络结构；同时分析模型在复杂背景信息干扰下的识别效果，评价YOLOv5在真实野外场景的适用性；并通过与其他同类算法的比较，明确YOLOv5用于野生动物识别的优势。实验结果表明：四种网络结构的识别精度均较高，F1-score和平均精度（mAP）均在90%以上，其中YOLOv5m的综合性能最好；YOLOv5在多种复杂背景信息干扰下识别效果仍较好，能够很好地适应真实野外场景；与其他算法相比，YOLOv5同时具有精度高、鲁棒性强、资源占用低等优势。YOLOv5是一种轻量化的模型且性能优越，为在资源受限的平台上进行野生动物实时识别提供了新的契机。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyQjJ_eejBw8eDb3b6Z2-n5Ot0wi4972VqG331WQzLTl4jgxCBDBj77v6hN9Y3JA03uoYnBJp2YQbPQmZnHAAUuOLiR3hBUC-4IKjtrrBH4rH6UQEEhXHCFIVxNFUhoKB3YA6EcitYQ5KZ1FhVMTKRrVCzlTgTl8WfgshQmluj-nQzUcuDVjtt5sEnshQAWYB0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOV5s网络的奶牛多尺度行为识别方法
{Author}: 白强;高荣华;赵春江;李奇峰;王荣;李书琴
{Author Address}: 西北农林科技大学信息工程学院;北京市农林科学院信息技术研究中心;国家农业信息化工程技术研究中心;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 12
{Pages}: 163-172
{Keywords}: 机器视觉;图像识别;奶牛行为识别;YOLOV5s;Transformer;多尺度;注意力机制
{Abstract}: 奶牛站立、喝水、行走、躺卧等日常行为与其生理健康密切相关，高效准确识别奶牛行为对及时掌握奶牛健康状况，提高养殖场经济效益具有重要意义。针对群体养殖环境下奶牛行为数据中，场景复杂、目标尺度变化大、奶牛行为多样等对行为识别造成的干扰，该研究提出一种改进YOLOV5s奶牛多尺度行为识别方法。该方法在骨干网络顶层引入基于通道的Transformer注意力机制使模型关注奶牛目标区域，同时增加路径聚合结构的支路与检测器获取奶牛行为图像的底层细节特征，并引入SE(Squeeze-and-Excitation Networks)注意力机制优化检测器，构建SEPH(SE Prediction Head)识别重要特征，提高奶牛多尺度行为识别能力。试验验证改进后的奶牛行为识别模型在无权重激增的同时，多尺度目标识别结果的平均精度均值较YOLOV5s提高1.2个百分点，尤其是对奶牛行走识别结果的平均精度4.9个百分点，研究结果为群体养殖环境下，全天实时监测奶牛行为提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwslld1E_CE7cSGiAOUeLVclU9GoyBwrIPcz-rMrrM0WBiqCxaOF79MZ4kjk-lvElhjRV9kp3K-URSWlP47z3ThXNcuc4g3Zoc3ecZ2eovoXSKnEvmYnloBd5X48vri2inBoCO5th_v3VROeAlkcWqgrLNuz2sfIVI4B_2Me3_h0RN1udd0z77UWTGOVqN4aks=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv4模型的橙果识别与定位方法
{Author}: 刘洁;李燕;肖黎明;李炜琪;李浩
{Author Address}: 华中农业大学工学院;农业农村部长江中下游农业装备重点实验室;农业农村部柑橘全程机械化科研基地;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 12
{Pages}: 173-182
{Keywords}: 机器视觉;识别;定位;橙;YOLOv4;深度学习;RealSense
{Abstract}: 为提高橙果采摘定位精度和作业速度，提出一种便于迁移至移动终端的改进YOLOv4模型，可从RealSense深度相机所成彩色图像中获取果实质心二维坐标，经配准提取对应深度图中质心点深度值，实现果实的三维空间定位。改进YOLOv4模型以Mobile Net v2为主干网络，在颈部结构中使用深度可分离卷积替换普通卷积，实现模型轻量化并提高检测速度。训练后的改进模型对513张独立橙果测试集数据的识别平均精度达97.24%，与原始YOLOv4模型相比，平均检测时间减少11.39 ms，模型大小减少197.5 M。与经典Faster RCNN、SSD模型相比，检测平均精度分别提高了2.69和3.11个百分点，模型大小分别减少了474.5和44.1 M。与轻量化模型YOLOv4-tiny相比，召回率提升了4.22个百分点，较Ghostnet-YOLOv4，平均检测时间减少了7.15 ms。为验证该改进算法实用性，应用改进模型获取果园中78个橙果的位置信息，结果表明：果实二维识别成功率达98.72%，水平方向及垂直方向的平均绝对百分比误差均在1%以内。果实三维定位成功率达96.15%，深度信息平均绝对百分比误差为2.72%，满足采摘机械手精准定位需求。该方法为复杂场景下采摘作业实现提供了鲁棒性强、实时性好、精准度高的目标定位途径。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyAnJNkdAl7Fj3ata_oF6iOIRevsnmI0SU5q-AC5gW7fCTKr_0ei-M-G-KkhtGHFD_SMkrmdrlFyqzVMA0bn63Gs82tLZxP_3echLyY9R0ksGsbfPaPliiyLvvWgc8chFLD8Q6z0IYsgQeYW96c5tOYaIHeDYRvVGdDfN809WoQc8gpO9bqW3wOSe705NsEkDc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于均值滤波和小波变换的单幅图像去雾算法
{Author}: 崔建伟;王冬青;刘金燕
{Author Address}: 青岛大学自动化学院;
{Journal}: 计算机与数字工程
{Year}: 2022
{Volume}: 50
{Issue}: 06
{Pages}: 1339-1342
{Keywords}: 图像去雾;Haar小波变换;均值滤波;环境光;HSV颜色空间
{Abstract}: 雾霾天气造成图像质量下降,进而影响计算机视觉系统的特征提取。论文提出一种改进的单幅图像去雾算法。先通过正交Haar小波变换进行处理得到图像的低频分量和高频分量,然后基于大气物理模型将低频分量利用均值滤波对环境光和大气光进行估计,得到低频去雾图像。然后将低频去雾图像与小波分解后的高频图像进行重构。最后将重构后的RGB图像转换到HSV颜色空间增强图像亮度。实验结果表明,论文算法简单有效,改善了图像质量,增强了去雾图像的边缘特征,利于计算机视觉进行特征提取。
{ISBN/ISSN}: 1672-9722
{Notes}: 42-1372/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz3RV6G6qbBzDdLfFcuC7cCvTWM2vIXrMrd4ht0oTm9rdATFO9m8yJH3is1PBHsoHgFENfFridexKGaL9gNDX21kED7n3_Kne2bRkT8qTbx1lL0vesB9N0U9Vlx9-wSA8Nwv2F-EURoVEfaA3JKBVyh2p9eZxYTliQ1UlaTpcURt7rG8sEEHtSpNF6iu4s46HY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像修复方法研究综述
{Author}: 罗海银;郑钰辉
{Author Address}: 南京信息工程大学计算机学院软件学院网络空间安全学院;南京信息工程大学数字取证教育部工程研究中心;
{Journal}: 计算机科学与探索
{Year}: 2022
{Volume}: 16
{Issue}: 10
{Pages}: 2193-2218
{Keywords}: 计算机视觉;图像修复;深度学习;单元图像修复;多元图像修复
{Abstract}: 图像修复是指恢复图像中受损区域像素，使其尽可能地与原始图像保持一致。图像修复不仅在计算机视觉任务中至关重要，同时也是其他图像处理任务研究的重要基石。然而现存图像修复相关总结研究较少，为了更好地学习和推进图像修复任务研究，对近十年的经典图像修复算法和极具代表性的深度学习图像修复方法进行了回顾和分析。首先，简单概述了经典的传统图像修复方法，并将其分为基于偏微分方程和基于样本的图像修复方法，同时进一步分析了传统图像方法局限性；着重分类且阐述了现有基于深度学习的图像修复方法，根据模型输出图像数量的不同，将其划分为单元图像修复和多元图像修复，结合方法应用图像、损失函数、类型、优势以及局限性对不同方法进行分析总结。之后，详述了图像修复方法常用数据集和定量评价指标，并给出图像修复方法在不同图像数据集上修复不同面积损坏区域的定量数据，根据定量数据对比分析了基于深度学习的图像修复方法性能。最后，归纳分析了现有图像修复方法的局限性，并对未来重点研究方向提出了新的思路和展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.tp.20220616.2027.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 工业缺陷检测深度学习方法综述
{Author}: 罗东亮;蔡雨萱;杨子豪;章哲彦;周瑜;白翔
{Author Address}: 华中科技大学电子信息与通信学院;华中科技大学人工智能与自动化学院;
{Journal}: 中国科学:信息科学
{Year}: 2022
{Volume}: 52
{Issue}: 06
{Pages}: 1002-1039
{Keywords}: 缺陷检测;异常检测;计算机视觉;工业视觉;深度学习
{Abstract}: 基于深度学习的工业缺陷检测方法可以降低传统人工质检的成本,提升检测的准确性与效率,因而在智能制造中扮演重要角色,并逐渐成为计算机视觉领域新兴的研究热点之一.其被广泛地应用于无人质检、智能巡检、质量控制等各种生产与运维场景中.本综述旨在对工业缺陷检测的任务定义、难点、挑战、主流方法、公共数据集及评价指标等进行全面归纳,以帮助研究人员快速了解该领域.具体而言,本文首先介绍工业缺陷检测的背景与特点.接着,按照实际数据标注情况,划分出缺陷模式已知、缺陷模式未知与少量缺陷标注3种研究任务设置,并根据方法类型作进一步归纳与分析,探讨了各方法的性能优劣与适用场景,阐明了方法与实际应用需求的关联性.此外,本文还归纳了方法部署中的关键辅助技术,总结了现有方法在实际产业落地中存在的局限性.最后,本文对该领域未来的发展趋势和潜在研究方向进行了展望.
{ISBN/ISSN}: 1674-7267
{Notes}: 11-5846/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx9JXGfpdjx2Y5ScL3YSxE_B20aWb9-iNyG_m52VSPgKdNkhh9XDJoq9zfubQ-8vm3RrnjkK9UfHg9v7R5c50RbEdFt3O6T2oxCKD22fpSt8uibimqhZXZaSDKk8vMFQmlrr5W2YgXCdet4CJBvEgAsr3MD7YGsInMYg0J3wW98smvat5JUnNU6E08jrEsvJE0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与深度学习的飞机防护栅裂纹检测系统
{Author}: 张良安;陈洋;谢胜龙;刘同鑫
{Author Address}: 安徽工业大学机械工程学院;安徽省工业互联网智能应用与安全工程实验室;中国计量大学机电工程学院;
{Journal}: 兵工学报
{Year}: 2023
{Volume}: 44
{Issue}: 02
{Pages}: 507-516
{Keywords}: 飞机防护栅;裂纹检测;机器视觉;深度学习;卷积神经网络
{Abstract}: 针对传统飞机防护栅裂纹检测中存在的效率低、可靠性差等问题，基于机器视觉技术设计一种飞机防护栅裂纹检测装置，并结合图像处理技术与深度学习原理提出一种飞机防护栅裂纹检测算法。设计飞机防护栅裂纹检测系统，研究防护栅裂纹图像识别算法。采集并整理飞机防护栅裂缝图像，研究并制作飞机防护栅裂纹检测数据集；分别以ZF-Net、VGG-16和ResNet-101卷积神经网络作为Faster-RCNN特征提取网络，开展飞机防护栅表面裂纹和缺陷裂纹检测研究。实验结果表明：3种模型均达到了良好的检测精度，其检测精度分别为92.79%、95.12%和97.54%,其中ResNet-101网络检测效果最好，相比于现有的防护栅裂纹机器视觉检测方法，漏检率和虚警率分别下降了22.54%和89.28%,检出率提高了22.54%;ResNet-101网络在不同光照条件下仍有较高的检测精度，检测装置和检测算法有效，可为飞机防护栅的检测提供了新方法。
{ISBN/ISSN}: 1000-1093
{Notes}: 11-2176/TJ
{URL}: https://link.cnki.net/urlid/11.2176.TJ.20220614.1659.003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的机动车典型交通安全违法行为识别研究
{Author}: 宋路浩
{Tertiary Author}: 韩凤春
{Publisher}: 中国人民公安大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 交通安全违法行为识别;机动车检测;机动车跟踪;YOLOv5;OpenCV
{Abstract}: 我国公安机关交通管理部门针对道路上出现的机动车交通安全违法行为还应用传统的人工监管手段,耗时耗力还易出现监管疏漏的问题亟需解决。目前,智能交通系统被广泛应用,基于人工智能、机器视觉等领域的智能交通系统正逐步替代繁琐的人工操作,本文在分析国内外目标检测与跟踪技术的基础上,提出基于深度学习的机动车检测与跟踪算法,并创新性地提出基于深度学习的机动车典型交通安全违法行为识别模型,极大降低了违法行为识别成本,为交通管理部门执法提供依据,主要研究内容如下:首先,分析研究背景及意义,评析目标检测、目标跟踪与违法行为识别技术的研究现状,确定论文研究内容与组织结构,进行相关理论概述。其次,基于改进YOLOv5设计机动车检测算法,利用Ghost Net对YOLOv5主干网络进行轻量化改进,添加SE、CBAM注意力机制模块提升检测准确度,利用预处理的KITTI、UA-DETRAC数据集进行检测训练,构建YOLOv5-Ghost机动车检测算法。再次,基于DeepSort设计机动车跟踪算法,将原算法中的目标检测器替换为YOLOv5-Ghost算法,构建YOLOv5-DeepSort机动车检测与跟踪算法,并利用预处理的Veri-776数据集进行跟踪训练,实现机动车检测与多目标持续跟踪。最后,基于OpenCV设计机动车典型交通安全违法行为识别算法,级联YOLOv5-DeepSort机动车检测与跟踪算法,构建机动车典型交通安全违法行为识别模型,该模型可通过实时路段监控视频或无人机拍摄视频自动识别机动车交通安全违法行为并抽取关键帧进行后台保存,同步录像取证。构建后的YOLOv5-Ghost机动车检测算法m AP为99.8%,Fps为58 f/s,模型大小为48.4MB,与同类型YOLOv5算法相比,提高检测精度的同时也减少了模型比重。调研获取城市道路监控视频以及无人机拍摄视频对该模型识别效果进行验证,实验结果表明,机动车压实线变道违法行为识别率达98.2%;机动车压导流线行驶违法行为识别率达98.7%;机动车违规掉头违法行为识别率达97.9%。该模型能够快速准确地进行机动车检测与典型交通安全违法行为识别工作,有效缓解了视频取证易疏漏、人工成本高等问题,弥补了交通管理领域非现场执法证据不充分的短板,为公安机关交通管理部门监管机动车交通安全违法行为提供了切实可行的管理办法。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2022.000231
{DOI}: 10.27634/d.cnki.gzrgu.2022.000231
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于轻量化神经网络的目标检测算法研究与应用
{Author}: 倪一华
{Tertiary Author}: 闫胜业
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;轻量化;多特征融合;知识蒸馏
{Abstract}: 目标检测已然成为计算机视觉的基础任务,为许多下游任务的发展带来了巨大的动力,因此受到广泛的关注。随着深度学习技术的发展,基于深度神经网络的目标检测算法更倾向于复杂的框架和更深的神经网络,这在提升网络性能上非常必要。然而,复杂的框架、高昂的计算成本也限制了很多优秀算法的应用。本文旨在简洁的目标检测框架上思考合理的神经网络轻量化方法,并针对其展开探索和研究。本文研究的前半部分聚焦于通过轻量化模块设计结合多特征融合的方式对基于关键点的目标检测算法进行轻量化改进,提出了一种基于多特征融合的轻量化目标检测算法。该方法利用本文提出的基于中心点的自适应高斯热图编码策略对输入进行编码,实现对目标的自适应编码。在特征提取网络中引入本文提出的混合反残差模块以达到轻量化和特征融合的作用。另外,还引入了一种带有注意力机制的空间金字塔池化模块,对多尺度局部区域特征进行池化、级联和筛选,使网络能够学到更加全面有效的特征。实验表明,该方法在通用检测数据集PASCAL VOC上将m AP从72.56%提升到了73.71%,同时参数量与计算量均有明显降低。本文研究的后半部分聚焦于通过知识蒸馏结合多范式网络设计的方式对基于关键点的目标检测算法进一步轻量化,并将其迁移到实际的应用中,提出了一种基于热图知识蒸馏的轻量化目标检测算法。该方法首先构建了基于热图的知识蒸馏框架,通过挖掘教师网络热图中的潜在知识引导学生网络学到更具泛化性的特征。其次,结合了Transformer设计范式和卷积神经网络设计范式构建了在局部特征以及全局建模均更有优势的教师网络。最后,设计了热图知识蒸馏损失,通过平衡教师网络与真值的贡献,动态调整学生网络学习的走向。实验表明,该方法保持轻量化的同时在通用检测数据集PASCAL VOC上将m AP从73.71%进一步提升到了74.23%,并且在车辆与行人检测数据集L-KITTI上实现了73.5%的m AP。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.001096
{DOI}: 10.27248/d.cnki.gnjqc.2022.001096
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的单目深度估计方法综述
{Author}: 江俊君;李震宇;刘贤明
{Author Address}: 哈尔滨工业大学计算学部;
{Journal}: 计算机学报
{Year}: 2022
{Volume}: 45
{Issue}: 06
{Pages}: 1276-1307
{Keywords}: 单目深度估计;深度学习;计算机视觉;场景理解
{Abstract}: 深度估计是一种从单张或者多张图像预测场景深度信息的技术,是计算机视觉领域非常热门的研究方向,在三维重建、场景理解、环境感知等任务中起到了关键作用.当前深度估计技术可以分为多目深度估计和单目深度估计.因为单目摄像头具有成本低、设备较普及、图像获取方便等优点,与多目深度估计技术相比,从单目图像估计深度信息是当前更为热门和更具挑战的技术.近年来,随着深度学习的迅速发展,基于深度学习的单目深度估计方法被广泛研究.本文对基于深度估计的单目深度估计方法进行综述,首先给出单目深度估计问题的定义、介绍常用于训练的数据集与模型评价指标,然后根据不同的训练方式对国内外相关技术进行分析总结,将现有方法分为基于监督学习、无监督学习和半监督学习三大类,对每种类型方法的产生思路、优缺点进行详细分析,最后梳理、总结该技术的发展趋势与关键技术.
{ISBN/ISSN}: 0254-4164
{Notes}: 11-1826/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz1YLYwCiDoG2TiClvlh8WV0qMojKTI0LgqCG8aKnet9t5mHg4Vr4QLJVsru_pl3OqeeHzuA1J9U7xFEgfjxziq2f5PeD4j0sgBcV-OBxVehfRgzgaE60wjHZrxSwcb_IDo05mT4DO4l_wMKDCetaijmgmnxXeKtoD1mCJS0xVQRe7DMTXkWKTaGQh7yXzKAc8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉下的果实目标检测算法综述
{Author}: 李伟强;王东;宁政通;卢明亮;覃鹏飞
{Author Address}: 佛山科学技术学院机电工程与自动化学院;佛山科学技术学院粤台人工智能学院;
{Journal}: 计算机与现代化
{Year}: 2022
{Volume}: 
{Issue}: 06
{Pages}: 87-95
{Keywords}: 计算机视觉;深度学习;果实检测;目标检测
{Abstract}: 基于计算机视觉的果实目标检测识别是目标检测、计算机视觉、农业机器人等多学科的重要交叉研究课题，在智慧农业、农业现代化、自动采摘机器人等领域，具有重要的理论研究意义和实际应用价值。随着深度学习在图像处理领域中广泛应用并取得良好效果，计算机视觉技术结合深度学习方法的果实目标检测识别算法逐渐成为主流。本文介绍基于计算机视觉的果实目标检测识别的任务、难点和发展现状，以及2类基于深度学习方法的果实目标检测识别算法，最后介绍用于算法模型训练学习的公开数据集与评价模型性能的评价指标，且对当前果实目标检测识别存在的问题和未来可能的发展方向进行讨论。
{ISBN/ISSN}: 1006-2475
{Notes}: 36-1137/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx9rLUOfJ7CYXf4nvhtt-RhEgUZCXsGwczDEx-YfsEUWxpYCsBzEoc4CQqA_CY-4ZWDU1JmLDzgz8GFmZDWEwVXU69mFMEYVW4uxFZl9G5Uo9P86R-pEIl3hcRijgu7eSW6JAC5dDlOZUBDxDBU3TQa-FYmTq8XoJYqVduI5shMVU0cXFFEOV1vc5Zl98zIGyY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机器人物料分拣系统的设计
{Author}: 朱名强;韦娟;老盛林;黄志彬
{Author Address}: 广西电力职业技术学院;
{Journal}: 电子制作
{Year}: 2022
{Volume}: 30
{Issue}: 12
{Pages}: 38-40+53
{Keywords}: 机器视觉;机器人;物料分拣;智能化
{Abstract}: 随着生产技术发展和产业转型升级，机器人代替人工劳动是大势所趋，而视觉是机器人的“眼睛”。分拣是工业生产过程的关键环节，但传统分拣工作多以人工分拣为主，这降低了生产效率，且难以保证产品质量。运用基于机器视觉的机器人物料分拣系统，能对不同颜色的物料进行准确识别和精准定位。本文阐述了机器视觉应用的意义、基于机器视觉的机器人物料分拣系统组成，设计了基于机器视觉的机器人物料分拣系统软件，分析了系统的应用优势。通过实践，实现了基于机器视觉的机器人物料分拣系统功能，提高分拣安全性、可靠性和工作效率，从而提高工业生产的智能化，适应产业发展需要。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2022.12.027
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2022.12.027
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 复杂背景下基于LBP纹理特征的运动目标快速检测算法
{Author}: 裘莉娅;陈玮琳;李范鸣;刘士建;李争;谭畅
{Author Address}: 中国科学院上海技术物理研究所;中国科学院大学;中国科学院红外探测与成像技术重点实验室;
{Journal}: 红外与毫米波学报
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 639-651
{Keywords}: 机器视觉;背景建模;LBP纹理特征;运动目标检测;复杂背景
{Abstract}: 在雨雪天气、树叶晃动、水面闪烁等有复杂背景的可见光与红外场景中，快速准确地提取完整目标一直是运动目标检测中的首要难题。为了满足实时性，并针对现有视频的前景提取算法依赖先验信息、召回率低、缺乏纹理和噪声较大等问题，提出了一种基于直方图统计和改进的局部二值模式（Local Binary Pattern,LBP）纹理特征相结合的背景建模方法。首先，使用各像素直方图的众数作为参考背景，无需先验知识，节省了大量存储空间，再采用邻域补偿策略提出了一种改进的S＿MBLBP纹理直方图与参考背景进行背景建模，消除了大部分动态背景和光照变化影响，实现目标的精确提取。实验表明，所提的算法在红外和可见光的多种复杂场景下，能快速提取前景目标的同时，提高了准确率和召回率。
{ISBN/ISSN}: 1001-9014
{Notes}: 31-1577/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwbJTLApVgFYRFVLnTSGLHEKVHHVJAYuZyPJl2Q-Z5mv5zcue4hH1ONTdJP3NsDi1hSv7Uq76t2GQWHVGQqNmBOXkS0UE4mHSj5m5puMEaiAHDCwP-Kj6pkSZ9Rb7e5Daa1au8ozviTBfo85_kUpgExIyjhBmfxoDPsm0WLgjOQI6Sc_Ks--6NfkjISDRr0z84=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 文档智能：数据集、模型和应用
{Author}: 崔磊;徐毅恒;吕腾超;韦福如
{Author Address}: 微软亚洲研究院自然语言计算组;
{Journal}: 中文信息学报
{Year}: 2022
{Volume}: 36
{Issue}: 06
{Pages}: 1-19
{Keywords}: 文档智能;深度学习;多模态自然语言处理
{Abstract}: 文档智能是指通过计算机进行自动阅读、理解以及分析商业文档的过程，是自然语言处理和计算机视觉交叉领域的一个重要研究方向。近年来，深度学习技术的普及极大地推动了文档智能领域的发展，以文档版面分析、文档信息抽取、文档视觉问答以及文档图像分类等为代表的文档智能任务均有显著的性能提升。该文对于早期基于启发式规则的文档分析技术、基于统计机器学习的算法以及近年来基于深度学习和预训练的方法进行简要介绍，并展望了文档智能技术的未来发展方向。
{ISBN/ISSN}: 1003-0077
{Notes}: 11-2325/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwL3LEvfLCwC66hlOBzN7g_vmQ-F0UX9O-mmuQvo14Et3A7bK9DXQa_yVyz5MqtHdghfsjUlRjnekjl8zGC405iM9zVL2rQhhM9bsDzTpU4BW2rDiebODsvsV_WR1YpD-WYFHkYbIRsXxkWQ701LGWNt4lzrF0nsgyHj8YP63DzF1tVKEyCRMU5kmWTuHoBp2c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习的目标检测典型算法及其应用现状分析
{Author}: 侯学良;单腾飞;薛靖国
{Author Address}: 华北电力大学经济与与管理学院;
{Journal}: 国外电子测量技术
{Year}: 2022
{Volume}: 41
{Issue}: 06
{Pages}: 165-174
{Keywords}: 目标检测;深度学习;检测模型;计算机视觉
{Abstract}: 目标检测是利用图像处理技术对输入图像中的兴趣目标进行分类和定位。深度学习凭借强大的表征和建模能力，使得目标检测的效率大大提升。首先回顾了传统目标检测方法的检测过程以及存在的问题；然后，分别从两阶段和单阶段两大方面，对基于深度学习的典型目标检测算法进行了比较，介绍了目标检测算法常用的性能评价指标和数据集。在此基础上，总结了当前目标检测算法的应用领域，分析了目标检测研究中需要进一步深入探究的问题，并对未来目标检测的发展趋势给出了相关建议。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2103503
{DOI}: 10.19652/j.cnki.femt.2103503
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉自动检测纸张表面缺陷质量分析研究
{Author}: 隋胄君;肖靖毅
{Author Address}: 新疆工业职业技术学院;新疆建设职业技术学院;
{Journal}: 造纸科学与技术
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 76-79
{Keywords}: 机器视觉;纸张表面缺陷;图像处理;缺陷检测
{Abstract}: 针对传统的纸张表面缺陷检测算法容易受复杂背景干扰的问题，提出一种机器视觉自动检测纸张间相对均匀的表面缺陷检测方法。主要分析了纸张表面各个环节中可能会出现的缺陷识别分类与缺陷类型等算法。根据目前的机器视觉自动检测技术，对已有的表面识别算法进行了分析。将通道注意力信息与空间注意力机制进行融合，设计出新的注意力机制模型，对纸张表面缺陷进行分类，此方法提升了模型算法的缺陷识别准确率，在纸张表面缺陷检测上，用过分析和总结机器视觉自动检测在纸张表面缺陷的应用，提高了纸张检测的准确率和效率，所述方法具有较强工程可行性和推广价值。
{ISBN/ISSN}: 1671-4571
{Notes}: 44-1532/TS
{URL}: https://link.cnki.net/doi/10.19696/j.issn1671-4571.2022.3.019
{DOI}: 10.19696/j.issn1671-4571.2022.3.019
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和深度学习的钢板表面缺陷检测研究综述
{Author}: 李雪露;杨永辉;储茂祥
{Author Address}: 辽宁科技大学电子与信息工程学院;
{Journal}: 辽宁科技大学学报
{Year}: 2022
{Volume}: 45
{Issue}: 03
{Pages}: 193-202
{Keywords}: 缺陷检测;机器视觉;缺陷分类;目标检测;缺陷分割;深度学习
{Abstract}: 钢板作为制造业发展的基础，表面缺陷检测具有重要的研究意义和应用价值。本文总结了基于传统机器视觉的钢板表面缺陷检测算法的优缺点及应用，分别从缺陷分类、目标检测和缺陷分割三个方面介绍深度学习技术在钢板表面缺陷检测领域的应用，总结目前钢板表面缺陷检测存在的短板与不足，并对未来的研究趋势进行展望。
{ISBN/ISSN}: 1674-1048
{Notes}: 21-1555/TF
{URL}: https://link.cnki.net/doi/10.13988/j.ustl.2022.03.006
{DOI}: 10.13988/j.ustl.2022.03.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去模糊方法研究与应用
{Author}: 侯坤
{Tertiary Author}: 郭业才
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像去模糊;卷积神经网络;深度学习;图像复原
{Abstract}: 由成像设备获取的图像,因相机抖动、失焦或物体运动等因素而导致图像模糊,严重影响了人们对清晰图像的高质量需求。因此,图像去模糊问题一直是图像复原技术中的研究重点。传统的基于模糊核估计的反卷积图像去模糊方法适用范围受限且易受未知噪声影响,且复原图像仍然存在振铃效应,去模糊效果较差。而基于深度学习的图像去模糊方法却存在复原图像的细节丢失问题。基于此背景,本文进一步研究了三种基于深度学习的图像去模糊方法。主要工作和创新点如下:(1)针对传统图像去模糊方法中复原图像存在振铃效应的问题,提出一种基于生成对抗网络的端到端图像去模糊方法。该方法在特征金字塔网络中加入特征增强模块进行改进,将得到改进的特征金字塔网络作为生成器生成复原图像,并通过判别器进行对抗训练从而获得最终的去模糊图像。实验表明,该方法能有效去除图像模糊,减轻图像复原中的振铃效应,去模糊性能优于传统图像去模糊方法。(2)针对现有深度学习图像去模糊方法中复原图像细节丢失的问题,以多尺度卷积神经网络为基础,构建了基于多尺度卷积神经网络图像块的图像去模糊方法。该方法使用多尺度卷积神经网络来对图像进行从细到粗的优化,聚合多个图像块特征并在编码网络中加入通道增强注意力模块,从而提高去模糊效果。实验表明,与现有的深度学习图像去模糊方法相比,该方法能显著减轻图像复原中的振铃效应并恢复图像细节。(3)针对一般的深度学习网络模型无法准确建立图像模糊形成过程并且依赖训练数据的问题,从图像先验信息出发,提出一种联合深度先验图像去模糊方法。该方法利用自编码-自解码网络和全连接网络,分别对清晰潜像和模糊核深度先验进行建模,并通过联合优化得到最终的清晰图像,同时在去模糊模型中加入TV正则化和冲击滤波进行改进,从而提高方法的抗噪性能,增强复原图像细节。实验表明,该方法可以在不依赖大量训练数据的情况下有效提取模糊图像的先验信息、复原图像细节,振铃效应不明显、自适应性更高。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.000239
{DOI}: 10.27248/d.cnki.gnjqc.2022.000239
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于FPGA的实时目标跟踪设计与实现
{Author}: 夏金锋
{Tertiary Author}: 严飞
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: FPGA;目标跟踪;Mean Shift算法;图像处理;硬件加速
{Abstract}: 目标跟踪技术目前在安防监控、赛事直播等领域具有较好的前景。但在实际的跟踪应用场景中面临着实时性要求高、跟踪场景较复杂等情况,加上受成本和嵌入式处理平台本身的限制,其处理效果往往很难满足现实需求。因此,目标跟踪等图像处理技术的落地实现是当前研究的热点内容。FPGA具备的硬件逻辑资源可灵活编程与并行处理等的特点,使其在图像处理领域拥有很好的应用前景,通过合理的算法优化,可使FPGA成为理想的视频图像处理算法的加速平台。本文首先搭建了基于FPGA的软硬件平台,然后在充分利用FPGA并行和流水线处理等特点的基础上,针对性地设计了运动目标检测与跟踪算法,实现了高清视频图像场景下的实时目标跟踪。实验结果表明,该系统结构更轻量化,且能在1920×1080分辨率下跟踪目标,跟踪速率达到60FPS,测试的平均跟踪重叠率在85%以上,在较复杂场景下也能具备一定的抗干扰能力。具体的算法实现包含三个部分。(1)采用DDR3缓存视频图像实现帧间差分算法,对视频中的运动目标进行实时检测,获取进入区域的目标信息,并用于下一步目标跟踪的执行。(2)针对FPGA平台优化实现了基于Mean Shift的目标跟踪算法。先通过检测结果获取目标特征,之后每帧都会经过Mean Shift计算将跟踪窗口指向目标特征分布最密集处。通过不断迭代,窗口中心将始终收敛于目标位置,达到跟踪效果。(3)抗干扰的算法实现。为了解决遮挡、相似物体干扰等问题,在跟踪算法中引入了卡尔曼滤波预测机制,进一步地提升了跟踪算法的准确性。同时,系统具备更新目标特征模型的功能,以针对目标在跟踪过程中的形态变化。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.000884
{DOI}: 10.27248/d.cnki.gnjqc.2022.000884
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉技术的烟条包装检测系统研究与应用
{Author}: 鲁鑫
{Tertiary Author}: 郭业才
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;产品包装检测;图像处理;缺陷检测
{Abstract}: 现代的烟草生产工业中基本部署了各种自动化机械设备,为了增加产能,生产过程中广泛使用自动化的流水线,产线的运行速度逐步加快。在这种快速生产过程中,容易产生诸如褶皱、印刷错误、翻卷、脱胶、标签歪斜、纸箱破损等外包装的瑕疵缺陷。为解决烟条在包装机流水生产的过程中所产生的缺陷瑕疵,自主研究开发了一款基于机器视觉的烟条外包装检测系统,当识别出外包装缺陷的条烟时,检测系统发出信号至剔除装置,剔除装置通过一定时间的延时等待烟条到位后,将其剔除。本文系统地讨论了检测系统的总体设计、硬件选型、用户交互软件设计以及检测算法设计,主要如下几方面工作:1.对烟草外包装检测系统的研究现状和应用背景进行了深入研究,分析并初步设计了烟草外包装检测系统的整体方案,主要包括设计系统的组成和机械结构,确定了光源和CCD相机的安装方案。2.对视觉检测系统需要进行了硬件选型,主要包括光源、CCD相机、镜头等,通过对硬件特性的理论分析确定了类型和型号。3.基于生产检测系统的需要及实际生产工作的业务需求,提出了注重用户交互软件的设计方案,包括业务逻辑框架设计、模块设计。尤其是开发了一款基于C#的图形引擎,其功能除了正常显示采集图像外,加入了不同类型的算子框编辑工具。4.针对烟条外包装缺陷类型的特征,设计编写了基于图像处理技术的检测算法。对图像采用新的预处理方式,运用图像特征统计、边缘检测、模板匹配、Hough变换等方法对烟条的褶皱、端面折线、拉线、拉耳等缺陷进行检测。对现有的图像处理程序进行改进,提高了算法的工作效率。5.对系统进行的模块化和整体性的实验测试。表明系统的设计合理性和算法的检测可行性。最后,总结本文所完成的工作,对存在的问题进行改进分析并做出思考。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.000358
{DOI}: 10.27248/d.cnki.gnjqc.2022.000358
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的分拣机器人设计与研究
{Author}: 韦志文
{Tertiary Author}: 王成军
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;分拣机器人;驱控一体化关节;铸件分拣;TRIZ理论
{Abstract}: 机器人分拣技术广泛应用于农场、工业生产和物流仓储等领域,执行分拣的主要是工业机器人。传统工业机器人体积大、柔性低且工作在结构化环境中,一旦工作任务改变或者环境发生变化,则需要重新编译。因此,采用轻量化分拣机器人结合机器视觉代替传统工业机器人执行分拣任务意义重大。本文针对传统工业机器人分拣系统存在的问题,设计了一种轻量化的分拣机器人,搭建了基于机器视觉的分拣机器人实验平台并完成了小型铸件的分拣。主要研究内容如下:(1)为解决传统工业机器人分拣系统存在的柔性低、可移植性差及智能化程度低等问题,提出了一种基于机器视觉的分拣机器人设计方案。运用TRIZ理论中的创新工具分析了传统工业机器人分拣系统存在的问题,获得了基于驱控一体化关节的分拣机器人本体的设计方案,为基于机器视觉的分拣机器人的设计方案提供了依据。(2)为完善基于机器视觉的分拣机器人的总体方案,对分拣机器人的本体进行了设计。首先对机器人机构进行拓扑分析,完成了机器人结构设计;其次运用ADAMS仿真软件获得实际负载情况下关节负载最大扭矩,完成伺服电机和谐波减速机的选型;然后运用ANSYS Workbench软件对外壳及法兰盘等部件进行强度校核,验证了结构设计的合理性;最后完成了分拣机器人的制作。(3)为研究分拣机器人本体的运动特性,对其进行了运动学分析与动力学仿真。首先运用标准和改进的D-H方法对分拣机器人本体进行运动学建模分析,完成机器人在连杆坐标系下的正逆求解;然后分别在关节空间和笛卡尔空间对分拣机器人本体进行轨迹规划;最后对分拣机器人本体进行动力学仿真,验证了设计和选型的合理性。(4)为完成分拣实验平台的搭建,对分拣机器人的总体方案进行了设计。首先对分拣机器人的系统组成进行完善,提出了设计的理念;其次对分拣机器人的末端执行器、传送系统、气动系统和电气系统进行了设计,并基于分拣机器人设计了一种柔性控制系统;然后分别对视觉系统和机器人参数进行了标定;最后搭建了基于机器视觉的分拣机器人实验平台。(5)为验证分拣实验平台的有效性,进行了仿真与识别抓取实验。首先基于Robot Operating System(ROS)机器人操作系统搭建了仿真平台;其次完成了分拣机器人控制系统和整体控制系统软件设计;然后对目标物体进行了图像处理,并使用基于Darknet的深度学习算法和基于Linemod的模板匹配算法分别对目标物体进行了识别和位姿估计,通过对比分析选取合适的算法完成小型铸件的抓取和分拣;最后对实验结果进行了分析总结。最后对全文的研究内容和创新点进行总结,指出研究的不足之处,给出未来研究工作的若干建议。图[107]表[17]参[147]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2022.000275
{DOI}: 10.26918/d.cnki.ghngc.2022.000275
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的目标检测研究综述
{Author}: 谷永立;宗欣欣
{Author Address}: 安徽理工大学计算机科学与工程学院;
{Journal}: 现代信息科技
{Year}: 2022
{Volume}: 6
{Issue}: 11
{Pages}: 76-81
{Keywords}: 深度学习;目标检测;卷积神经网络;计算机视觉
{Abstract}: 目标检测是计算机视觉领域内的热点研究课题，在医疗、监控及航空等领域都有广泛应用。先对目标检测技术的背景进行了介绍，然后从基于锚框的两阶段目标检测算法、基于锚框的单阶段目标检测算法、基于Anchor Free的目标检测算法三个阶段分别进行介绍，同时还介绍了主流的数据集以及主要的性能评价指标。最后叙述了当前目标检测领域存在的挑战，展望了目标检测技术在未来的发展方向。
{ISBN/ISSN}: 2096-4706
{Notes}: 44-1736/TN
{URL}: https://link.cnki.net/doi/10.19850/j.cnki.2096-4706.2022.011.020
{DOI}: 10.19850/j.cnki.2096-4706.2022.011.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的登海605玉米品种真伪鉴别方法研究
{Author}: 王佳;马睿;马德新
{Author Address}: 青岛农业大学;
{Journal}: 中国粮油学报
{Year}: 2023
{Volume}: 38
{Issue}: 03
{Pages}: 151-157
{Keywords}: 玉米;深度学习;机器视觉;品种鉴别
{Abstract}: 玉米是我国重要的谷类作物，玉米种子的纯度是影响种子质量的关键指标，不同品种玉米的种子活力、物理指标和发芽率都是不同的，因此需要对玉米品种的真伪进行鉴别分选。传统模式识别的方法需要人工定义各类特征，存在主观判断、费时费力等问题，实用性较差。针对上述问题，本研究拟建立一种基于RGB图像结合深度学习的低成本、高效、无损的单粒玉米种子真伪检测方法，选用不同产地登海605玉米种子440粒，其他品种480粒，采集玉米种子胚面和胚乳面制作数据集，通过图像处理技术对图像进行预处理，并按照7∶2∶1的比例将数据集分为训练集、验证集和测试集，分别使用GoogLeNet、MobileNet、Inception-ResNet、ResNet、DenseNet共5种网络模型利用迁移学习对3类数据集进行分类测试，结果表明，5种网络模型在双面数据集的平均识别准确率最高，测试识别准确率为99.05%,ResNet网络在3类数据集中的分类效果最佳，在双面测试集上为99.91%。本研究提供了一种无损、高效、相对可靠的方法来鉴别登海605玉米品种的真伪。
{ISBN/ISSN}: 1003-0174
{Notes}: 11-2864/TS
{URL}: https://link.cnki.net/doi/10.20048/j.cnki.issn.1003-0174.000265
{DOI}: 10.20048/j.cnki.issn.1003-0174.000265
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的光纤环绕制缺陷检测算法研究
{Author}: 陈晓乐
{Tertiary Author}: 杨瑞峰
{Publisher}: 中北大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 光纤环;机器视觉;缺陷检测;图像分割;特征提取;深度学习
{Abstract}: 由圆环形多匝光纤线圈绕制而成的光纤环是干涉型光纤陀螺中传播两相向光波来产生SAGNAC相位差的核心部件,其绕制品质的好坏直接影响光纤陀螺的测量精度,因此对光纤环绕制缺陷进行实时监测,无论在理论上还是在工程上都有很大的实际应用价值。传统依靠人工目视进行光纤环绕制质量的监测已不能适应现代化生产高精度和高效率的要求。机器视觉作为一种非接触性测量方式,具有检测精度高、速度快、成本低、安全性高等优点,已广泛应用于实际工业生产和检验中。因此,本文基于机器视觉技术围绕光纤环绕制缺陷检测这一实际问题,采用图像分析和模型构建等手段,开展以下研究工作:(1)通过对缺陷特征进行分析,提出一种基于小波变换的快速光纤环缺陷检测方法。首先利用形态学方法进行图像预处理得到利于后续分析的理想区域。之后利用投影变换和离散小波变换对信号局部化时频分析的能力,实现缺陷的定位。实验证明该方法在光纤环缺陷检测上取得较高的准确率。针对光纤环图像的周期性复杂纹理特征,提出一种基于纹理特征和低秩矩阵表示模型的缺陷分割方法。首先根据多种特征描述子构建纹理特征库来编码光纤环图像的纹理信息。在此基础上,通过将矩阵分解为代表高度冗余信息的低秩矩阵和与显著缺陷部分相对应的稀疏矩阵,进而分离出缺陷信息和缺陷位置,在缺陷分割方面取得了很好的效果。(2)为了识别缺陷类型,构建结合支持向量机和自适应遗传算法的分类模型。提出交叉概率和变异概率的自适应调整方案,以进行分类器参数寻优,通过实验验证了该方法对光纤环绕制缺陷具有较高的识别率。(3)为克服传统检测方法缺陷检测和类型识别分阶段进行的局限性,依据当前深度学习取得的先进成果,探索如何把深度学习应用到光纤环质量监测中以得到更好的缺陷检测效果,提出一种基于深度学习的端到端缺陷检测及分类一体化方法。通过模型结构的优化改善了模型对于小尺寸目标检测能力弱的问题,提高了缺陷检测的精度。为了增强网络模型的鲁棒性,采用数据扩充及网络微调的策略防止过拟合现象。针对实际工业应用中轻量化的需求,采用稀疏训练和通道剪枝策略使模型进一步简化,速度更快,满足实时性要求,为光纤环实际生产过程中自动检测提供了有效的算法和参考。综上所述,本文以光纤环绕制过程中质量视觉检测的实际需求和问题为导向,搭建缺陷视觉检测系统,提出可用于光纤环图像的缺陷检测方法,并进行大量测试。实验证明,本文提出的方法在解决光纤环绕制缺陷检测问题上的有效性,对于提高我国光纤环生产的自动化水平具有重要的理论意义和工程价值。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.000017
{DOI}: 10.27470/d.cnki.ghbgc.2022.000017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的人群计数方法研究
{Author}: 何宇强
{Tertiary Author}: 殷保群
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 计算机视觉;人群计数;注意力机制;特征融合;轻量化网络设计;模型压缩
{Abstract}: 随着城市化进程的稳步推进与人口规模的日益扩大,人群聚集的情况越来越普遍,大量密集场景存在着诸多安全隐患。为了预防突发事件,保障人民安全,智能监控系统引起了社会的重点关注。人群计数作为该系统的重要组成部分,旨在准确估计图像中的行人数目与密度分布,在城市规划、交通管控等领域有着广泛的应用。特别是最近两年,新冠肺炎席卷全球,监测和分析高密度人群可以提供有效的疏散计划,是控制疫情大面积蔓延的必要手段。随着深度学习技术在计算机视觉领域逐渐成熟,基于卷积神经网络的人群密度图估计算法凭借着优秀的计数性能与泛化能力,逐步得到了研究学者的认可。然而,在实际应用场景中,现有的计数模型仍然面临着诸多严峻挑战,比如行人尺度变化,特征信息空间偏移和语义失衡,模型参数冗余和结构臃肿。针对上述问题,本文展开深入研究并提出解决方案,进一步提升计数模型的性能与鲁棒性。本文的主要研究工作和创新点归纳如下:1.针对复杂场景中人群尺度剧烈变化问题,提出了一种基于联合注意力机制的多尺度人群计数算法。首先,构建了多阶尺度注意力模块以获取高阶统计信息,辅助骨干网络捕获对尺度变换敏感的判别性特征;其次,为了研究人群全局分布情况,设计了多重池化关系注意力模块,紧凑表征全局结构关系并学习任意通道节点之间的相互依赖性;然后,采用分布式组合损失函数来实现对网络中间层的分布式监控,逐层增强信息反向传播能力,避免梯度消失问题。最后,在ShanghaiTech、UCF-QNRF、JHU-CROWD++、NWPU-Crowd 数据集上进行多轮实验,以验证算法的有效性。2.针对多路径融合架构引发的特征图空间错位和语义失衡问题,提出了一种基于多元优化融合的人群计数算法。该算法由跨维优化模块、混合语义优化模块以及一个强大的基线网络构成。其中跨维优化模块利用三重注意力机制学习跨维度依存关系,并结合上采样特征与相邻特征之间的像素变换偏移,共同修复特征空间错位;混合语义优化模块负责捕获不同层次特征之间的语义依赖关系,以缓解粗糙的特征融合操作引起的语义失衡问题并且增强语义表征能力。随后,将上述两个模块集成到基于自顶向下金字塔架构的基线网络中。多个数据集上的实验结果表明该算法可以显著改善多路径特征融合的有效性,并且能够提升计数网络的泛化能力。3.针对计数模型参数冗余和结构臃肿与实际部署的矛盾,分别从轻量级网络结构设计和大规模网络剪枝两个角度来提出解决方案。(1)提出了一种基于幻影注意力的轻量人群计数算法。首先,设计了幻影编码器网络作为精简骨干网络来提取基础特征信息,以较小的性能下降为代价大幅降低浮点运算量。其次,提出了参数共享的跨阶幻影注意力模块来捕获判别性语义信息,并保证运算高效性。然后,利用基于权重共享机制的掩码密度生成模块来生成多尺度密度图和前景背景掩码,以消除复杂的背景干扰。(2)针对本文提出的两个大规模人群计数网络,同时引入了一种通道级剪枝算法进行网络瘦身,并结合稀疏化训练方式来获得紧凑的计数模型并加快推理速度。(3)在多个数据集上进行大量实验,分别验证了两种方法的有效性。同时从多个角度对比两种方法,详细阐述各自的优缺点与应用场景。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.000578
{DOI}: 10.27517/d.cnki.gzkju.2022.000578
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的苹果采摘机器人识别与定位研究
{Author}: 李昌璐
{Tertiary Author}: 张静;蒲小陆
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;SSD;机械臂;手眼标定;PyQt
{Abstract}: 采摘机器人是一种典型的智能农业设备,被广泛应用于种种复杂的采摘环境中实施作业,采摘机器人作为现代智能设备的代表,集机器人、传感器、控制器等先进技术于一体。近五年来,人工智能技术受到了广大科研人员的持续追捧,其中智能农业技术的发展也不例外。同时,制约采摘机器人机器性能提高的技术瓶颈主要在于视觉识别、图像处理、路径规划等方面。本文在研究过程中为提高智能采摘机器人的采摘效率,需要在特定目标生长情况下对实际应用提供参考,将以智能苹果采摘机器人作为研究对象,围绕视觉识别、目标定位、机械臂结构设计、软件设计等方面展开研究。本文的研究内容和取得的结论概括如下:首先,对自然光下苹果果实及其生长情况进行图像采集。针对苹果的实际生长特点和采摘作业需求,提出了基于改进的SSD神经网络的自然环境下苹果采摘模型。通过添加注意力机制与特征融合的方式提高苹果采摘机器人对于小目标及复杂环境下的苹果识别能力。并且提出了两种不同的改进方式:SSD-F及SSD-FC,经过实验与原始的SSD神经网络进行训练比较。实验结果表明,改进的模型中SSD-FC的方法不仅对于小目标及复杂环境区域的目标检测效果最优,而且由于模型复杂度的增加对识别稳定性并未产生较大影响,达到了预期效果。其次,搭建了苹果采摘机器人的目标定位系统,完成世界坐标系与像素坐标系转换关系的计算分析,深度相机的选用及标定试验。因为末端执行器获得的采摘目标坐标信息需要通过相机标定结果转换得出,所以将进行机械臂设计,机械臂D-H模型构建以及正运动学分析。选用Eye-in-hand的方式搭建视觉采摘系统及进行手眼标定仿真试验,并运用Tsai标定法获取手眼坐标的位置关系结果。最终对苹果采摘机器人视觉识别与定位系统进行试验验证。采用Intel Real Sense相机对苹果目标进行识别及三维定位,并将三维坐标信息实时地呈现在识别结果框内,实现系统可视化。通过试验验证了改进算法以及手眼标定转换结果的合理性。并设计出基于PyQt工具包的苹果智能识别软件。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2022.000718
{DOI}: 10.27206/d.cnki.ggsgu.2022.000718
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像识别的无监督域适应方法研究
{Author}: 张燚鑫
{Tertiary Author}: 王子磊
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 无监督域适应;图像分类;图像语义分割;图像目标检测
{Abstract}: 深度神经网络(Deep Neural Network,DNN)在各种机器学习任务中获得了巨大的成功。然而其效果在很大程度上依赖于大量标记好的训练数据。在实际问题中,手动标注充足的训练数据通常会耗费大量时间和费用。同时,传统深度学习的另一个缺点是由于域差异问题,而无法泛化到新数据集。域适应(Domain Adaptation,DA)通过利用标签丰富的源域知识来帮助相关但标签稀缺的目标域来解决这个问题,例如对于语义分割这种需要细粒度标注的任务,可以借助于游戏引擎来方便快捷地生成大量带标注的图像,从而辅助真实场景中的语义分割任务。本文主要关注无监督域适应问题,即给定一个源域和一个目标域,源域具有充足的图像和标注信息,而目标域只有图像没有标注,希望获得在目标域上有良好性能的模型。本文考虑了图像分类、图像语义分割和图像目标检测三个基本的计算机视觉任务,根据实际应用场景和任务的不同,分析了存在的挑战性问题,提出了具有针对性的域适应学习方法。本文的主要研究工作和贡献可概括如下:·围绕语义分割任务中的域适应问题,提出了融合低层领域判别器和高层领域判别器的联合对抗学习方法。对于语义分割这样具有结构化输出的任务,通常使用概率空间的领域对抗学习。本文首先提出了一种联合对抗学习方法,通过从低层特征对应的领域判别器引入到高层特征来提升输出空间中的领域对抗学习,然后提出了一个权重迁移模块来减轻解码器对源域的过拟合。具体来说,权重转移模块将原始解码器更改为新的解码器,该解码器仅在对抗损失的监督下学习,因此主要侧重于减少域差异。在两个标准的迁移设置下进行的实验表明,本文方法可以在不同的基线方法上带来明显的性能提升,证明了本文方法在输出空间领域对抗学习的有效性。·围绕目标检测任务中的域适应问题,提出了针对RPN网络的基于类别原型的跨域对齐方法。当前,大多数现有的目标检测域适应方法主要在骨干网络或实例分类器上采用特征对齐来增加检测模型的可迁移性。不同于此,本文首先指出RPN中存在领域差异问题,基于此,提出在RPN阶段进行特征对齐,以便可以有效地区分目标域中的前景和背景候选框。具体来说,首先构建一组可学习的RPN类别原型,然后强制RPN特征与源域和目标域的原型保持一致。其次,采用Grad CAM来找到前景建议中的判别区域,并在RPN特征和原型对齐时,以空间加权的方式增加RPN特征的判别性。本文在多个跨域检测场景进行了实验,结果表明本文所提方法相对于当前最先进方法的有效性。·围绕图像分类任务的域适应问题,提出了基于目标域低置信度样本的实例区分的对比学习方法。当前探索目标域分布的域适应学习方法大部分依赖于高置信度的样本来构建可靠的伪标签、类别原型或者聚类中心,以这种方式表示目标数据结构会忽略大量的低置信度样本,导致次优的可迁移性,因为高置信度样本一般更偏向于源域。为了克服这个问题,本文提出了一种针对低置信度样本的对比学习方法来利用目标数据的完整结构。首先,提出使用低置信度样本构建正负样本对可以更好地避免语义冲突问题,然后用分类器权重重新表示原始特征,这样可以缓解学习到的特征分布和任务判别能力的不一致性。其次,将跨域Mixup与提出的对比损失相结合,以进一步减小跨域差距。最后,在标准的无监督和半监督域适应任务设置上的结果表明,本文的方法是有效的并且达到了当前最好的性能。总结起来,本文针对不同视觉任务中的域适应问题,进行了深入探索和研究,结合实际问题的具体特性,从输出空间的领域对抗学习、RPN网络的类别特征跨域对齐和目标域特征分布的学习等角度入手,提出了具有创新性的解决方案。本文涉及到了从虚拟到真实、不同天气以及不同城市场景等多样化的迁移学习场景,实验结果表明,本文方法在提高CNN模型在不同视觉任务的域适应能力上取得了很好的效果,相较于已有的各类算法取得了明显进步,进一步减少CNN模型对于标注信息的依赖,提高了模型在真实场景下的泛化能力,展示了在自动驾驶、工业4.0和智慧城市等实际应用中的价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.000408
{DOI}: 10.27517/d.cnki.gzkju.2022.000408
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的COVID-19图像分类方法研究
{Author}: 陈万坤
{Tertiary Author}: 顾海明
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;卷积神经网络;激活函数;注意力机制;迁移学习
{Abstract}: 新型冠状病毒2019(COVID-19)会对人类健康造成巨大危害,并在2020年初迅速蔓延到世界各地,感染数亿人并造成大量患者死亡。遏制COVID-19传播的关键一步是对可能感染的患者进行检测、隔离并治疗,但是逆转录聚合酶链反应(RTPCR)检测以及病毒抗体检测会消耗大量时间,因此对肺部医学图像进行COVID-19医学图像自动诊断在临床上具有重要的意义。本课题基于深度学习对新冠肺炎肺部医学图像进行识别研究,课题的主要研究内容如下:1.提出基于注意力机制的新冠肺炎端到端自动识别算法,称为AFANet。首先,引入一种全新的自动通道注意力融合网络(AFANet)提取通道注意力,采用自动注意力融合操作来更好的提取通道间的注意力权重。其次,将AFANet与多个经过预训练的深度学习模型结合并进行迁移学习,通过迁移学习来缓解训练数据部分缺乏的问题并加快模型的收敛速度。最后,通过Grad-cam算法对模型的权重进行可视化,使模型的决策过程更加清晰,并可在一定程度上辅助医生进行患者诊断。通过在多分类数据集上使用四个指标进行性能比较,发现AFANet在二分类、三分类以及四分类任务中取得了较好的性能,同时也优于常见的先进算法。为了验证AFANet的有效性,我们分析了模型中不同模块的作用,进一步明确各模块对模型性能的提升作用。最终结果表明,AFANet结合到卷积神经网络中并进行迁移学习,不仅可以降低数据不足的影响,而且可以进一步加快模型收敛速度,并具有较高的分类性能。2.提出基于多尺度特征金字塔的新冠肺炎自动识别算法,称为MSFPNet。首先通过多尺寸并行卷积操作在多尺度层面构建特征金字塔,通过构建多尺度特征图来获取更加丰富的特征表示,其中高分辨率特征对应图像的细节特征信息,低分辨率特征对应图像的高维结构信息。其次,采用多通路特征融合模块对所提取多尺度特征信息进行融合以更好的突出重要信息,同时促进特征的传播。最后,将融合后的特征输入到编解码特征加权模块中进行特征尺寸的统一,促进高权重特征的提取,并对加权后的特征进行最终的分类。此方法在新冠患者图像识别任务中取得了较好的结果。最终结果表明,基于特征金字塔的卷积神经网络图像识别模型,不仅可以快速的进行训练,而且可以准确的识别新冠肺炎患者。更重要的是,该模型可以应用于小样本的数据集,能更好的应对疫情。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2022.000429
{DOI}: 10.27264/d.cnki.gqdhc.2022.000429
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像质量评价与提升算法及应用研究
{Author}: 王璠
{Tertiary Author}: 张卫冬
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像质量评价;图像质量提升;图像超分;图像去噪;散景渲染
{Abstract}: 图像是人类获取信息的重要来源,是人们分享生活、表达情感的方式之一,同时也是计算机视觉任务的重要数据类型。但是由于拍摄设备、图像传输等问题,图像质量参差不齐,低质量的图像严重影响人们的视觉需求和后续高级视觉任务的准确性。客观准确的图像质量评价方法可以为图像质量提升算法挑选低质量的图像,也可以提供反馈和优化。但是,目前图像质量评价仍然存在数据量少、参考图像难以获得等问题,图像超分、图像去噪作为非单一解的图像质量提升任务仍然存在较大提升空间。因此本文围绕图像质量评价和图像质量提升在算法与应用两个层面展开了深入研究。在算法层面,主要针对图像质量评价,图像质量提升中的图像超分、图像去噪问题的难点展开研究;在应用层面,将图像质量评价应用在相机镜头局部解析力失效检测中,将图像去噪算法应用于水面反光图像去噪点,最后围绕图像美学质量提升提出了自然散景效果渲染的方法。本文的研究内容和主要贡献如下:(1)在图像质量评价研究中,针对参考图像难以获得和图像数据量少的问题,本文提出了一个基于生物视觉启发的图像质量评价模型,具有图像输入多尺度、网络结构多尺度、输出特征多尺度且完全不需要参考图像的特点。受生物视觉启发,设计了模拟人眼视神经对不同距离图像的多尺度轮廓响应模块,使模型更加关注图像边缘轮廓清晰度而非图像色彩特征;受视网膜神经节细胞感受野机制启发,构造了中心注意周边抑制模块,同时结合亮度信息,对图像不同区域的图像块采用不同的质量权重。模型采用两阶段方法解决了数据量少的问题,并对模型添加分类任务分支后,成功的应用在了图像失真类型分类及质量评价的多任务研究中。(2)针对大倍率的图像超分问题,提出了基于图像局部特征关联的图像超分模型。目前的许多超分模型大多应用在4倍以下的图像超分中,为了应对大倍率图像超分的问题,引入局部特征关联模块为不同区域的图像块建立关联度,使特征相近的图像块在进行超分时可以互相借鉴;通过预训练的跳跃连接式生成网络生成高倍图像,然后通过多分辨率逐级提升模块,让不同分辨率的图像进行融合,充分融合不同分辨率图像的特征,进一步优化高倍分辨率图像的纹理、轮廓、颜色等特征细节。(3)针对真实噪声-干净图像对获取困难的问题,提出了基于噪声空间特征表征的图像去噪模型。当前有监督的深度学习去噪模型,大多采用人工添加高斯噪声的方式来获取噪声图像进行模型的训练,由于人工合成的噪声与真实噪声的分布差异,导致模型在真实噪声图像的处理上表现不佳。针对上述问题,本文借鉴自监督对比学习的方法,通过“图像平移”和“噪声自相似搜索”两种正样本生成的方式,在没有噪声标签的情况下学习噪声特征。同时本文将去噪模型应用在游泳馆危险行为检测的任务中,成功的解决了水面图像反光噪点影响后续检测误检的问题,充分说明了图像去噪等图像质量提升任务作为后续视觉任务预处理功能的重要性。(4)针对相机镜头解析力检测对检测位置的局限性,借鉴图像质量评价的思路提出了相机镜头局部解析力失效检测的方法。目前大多数相机镜头生产厂家采用的镜头解析力检测方法,仅仅对左上、左下、右上、右下及中间区域进行检测。为了能够对镜头的任意位置进行解析力失效检测,本文根据图像质量检测的原理,通过拍摄的图像间接反映镜头解析力,并提出了基于亮度和梯度的计算方法作为衡量镜头解析力的指标。通过相关性对比实验和可视化分析,说明了提出方法的可行性,为相机镜头局部解析力检测提供了一种新的思路。(5)为了进一步提高图像的美学质量,根据自然散景效果的特点,提出基于深度估计的可选焦平面的重对焦图像生成方法。通过深度估计模块获得图像中物体深度信息;通过背景分区模块选择不同的焦平面,获得不同的模糊半径,使散景渲染效果更多样,且不会过度分割物体;通过调整渲染参数,改变渲染程度。可视化结果表明,该方法满足“焦平面的物体清晰,焦外物体模糊且距离焦平面越远物体越模糊”的散景效果特点。本文针对图像质量评价和提升算法的部分难点展开研究,并将图像质量评价和提升算法应用在了相机镜头解析力检测、图像预处理、图像美学提升领域,充分说明了本文研究的意义及重要性。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2022.000167
{DOI}: 10.26945/d.cnki.gbjku.2022.000167
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于DeepSORT的行人多目标跟踪算法研究与应用
{Author}: 裴云成
{Tertiary Author}: 刘海英
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;DeepSORT;深度学习;卡尔曼滤波;匈牙利算法
{Abstract}: 行人多目标跟踪技术在人工智能、无人驾驶、虚拟现实等领域占有重要地位,基于检测的行人多目标跟踪算法DeepSORT在工业上得到广泛地使用,该算法主要是对多个行人目标连续跟踪,并保持其ID不变。本文主要针对DeepSORT算法对行人外观特征提取能力的不足,提出改进措施,提高跟踪模型的鲁棒性,并提出基于DeepSORT跟踪算法的行人撞线计数法。文章主要从两个方面进行展开,首先对DeepSORT算法进行完善提高跟踪的准确性,其次根据完善的DeepSORT算法展开对行人撞线计数算法介绍。本文的主要贡献如下:DeepSORT算法在行人跟踪过程中对行人表观特征信息描述不够充分,无法适应实际复杂场景的需要。为了提高DeepSORT算法的适用性和跟踪准确性,使其更具鲁棒性,通过改进DeepSORT算法中特征提取网络模块,提取多层金字塔特征,增加网络的残差层数,提高对特征提取的广度和深度,并在公共数据集MOT-16上进行验证,本文提出的基于多特征融合的特征提取网络,使DeepSORT算法的跟踪准确度提升4.1%。在使用IOU(Intersection over Union)距离度量时,当检测框和预测框无重叠时,IOU值恒为0,不能有效判断该检测框和预测轨迹框之间的权重值,同时当检测框和预测框之间重叠时,会出现具有相同的IOU距离值时,检测框和预测框具有不同的重叠方式,为了解决此问题,使用GIOU(Generalized Intersection over Union)距离度量代替DeepSORT算法中IOU距离度量,提高跟踪过程中精度,使MOTP达到81.9。为了解决人流密度统计问题,本文提出基于DeepSORT算法的行人撞线计数法,此方法首先利用检测算法,检测出行人目标的位置信息,然后结合DeepSORT算法,通过卡尔曼滤波算法对轨迹信息做出预测,完成对行人目标的跟踪,并保持ID(Identity)信息不变,根据目标的轨迹和ID信息,判断该目标通过计数线的方向和数量,此方法可以有效地计算从不同的方向通过计数线的行人数量。间接统计进入某一场所或通过某一路口的人数,达到跟踪计数的目的。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2022.000282
{DOI}: 10.27278/d.cnki.gsdqc.2022.000282
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的联轴器尺寸测量及表面缺陷检测研究
{Author}: 王亭亭
{Tertiary Author}: 郭忠峰
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;联轴器;尺寸测量;缺陷检测
{Abstract}: 针对某联轴器生产厂家对弹性膜片联轴器的实际生产检测需求,为了改善产品出厂前人工检测效率低、稳定性差的问题,计划将现有的人工产品检测改进为机器视觉检测。本课题将利用机器视觉技术完成对联轴器中心孔的尺寸测量以及边缘凹坑缺陷检测工作,主要研究内容如下:首先,根据产品检测需求确定机器视觉检测系统的整体方案,将整个系统分为照明系统、图像采集系统以及计算机视觉系统三个模块。通过对光源特性及照明方式进行对比,结合尺寸测量及缺陷检测系统的需求特征,制定了不同的照明方案。根据检测系统的需求特点,完成尺寸测量与缺陷检测系统图像采集设备的选型工作,并搭建两组检测试验平台。其次,通过分析世界坐标系、相机坐标系、图像坐标系以及像素坐标系之间的转换关系,在图像采集前对检测系统进行相机标定,获取到相机的内、外参数,进而得到图像像素尺寸与真实物理尺寸之间的比例关系,为后续尺寸测量工作做铺垫。然后,针对联轴器的中心孔尺寸测量需求,先对中心孔的不规则形状进行边缘轮廓提取,并利用二维计量模型理论中的最小二乘拟合法,实现中心孔标准圆形轮廓的高精度拟合。再通过创建中心孔的模板图像,使用模板匹配与仿射变换方法,对新采集的图像进行轮廓匹配,成功实现任意位置的自适应尺寸测量功能。最后,为了实现联轴器的定向区域缺陷检测功能,先对采集到的图像进行二值化和滤波降噪处理,再结合联轴器的缺陷特征,提出闭合性区域填充优化方案,通过对法兰端面上的孔洞进行区域填充,有效排除定向区域外的干扰因素,进而实现法兰边缘轮廓的定向提取,并使用形态学原理对联轴器边缘轮廓进行标准圆拟合,利用轮廓求差法实现定向区域的凹坑缺陷检测。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000470
{DOI}: 10.27322/d.cnki.gsgyu.2022.000470
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向工业场景的表观缺陷视觉检测方方法研究
{Author}: 王建柱
{Tertiary Author}: 李清勇
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 计算机视觉;工业缺陷检测;结构化相似;实体稀疏追踪;监督对比学习
{Abstract}: 经过几十年的快速发展,我国制造业规模已跃居世界第一位,逐步建立起技术领先的制造体系,成为支撑我国经济社会发展的重要基石。在产品生产与使用的过程中,工业制品不可避免地会出现各式各样的表观缺陷。这些缺陷不仅影响产品的美观和舒适度,而且也会对其使用性能带来不良影响,严重情况下还可能导致重大的安全事故。因此,表观缺陷检测技术在工业场景中得到了广泛的关注与重视。随着人工智能的不断发展,基于计算机视觉的缺陷检测在理论研究和实际应用中均取得了一定的进展。但由于待检图像质量不均、缺陷样本稀疏失衡、特征表示学习困难等原因,导致现有的一些视觉检测方法仍面临着虚警率高和鲁棒性弱等性能瓶颈。针对这些问题,本论文面向工业场景中表观缺陷检测任务的不同粒度,分别从样本分布特性、缺陷先验信息和类别特征学习的角度展开了深入研究。本文的主要贡献概述如下:(1)提出了一种基于结构相似深度卷积自编码的缺陷图像判定模型在工业视觉检测场景中,缺陷图像判定是检测系统的首要任务。考虑到缺陷图像相对稀缺、标注困难的问题,提出了一种基于结构相似深度卷积自编码的缺陷图像判定模型。模型整体遵循编解码架构,训练过程无需缺陷样本,避免了传统监督学习模型对大规模高质量标注数据的依赖问题。在处理具有复杂纹理的缺陷图像时,模型灵活地引入了特征直连结构,能够提高对图像复杂纹理背景的重构能力。为了拉大缺陷图像较正常图像的重构误差,模型在训练与测试过程中均采用了结构化相似指标从亮度、对比度和结构度三个方面综合度量原始图像和重构图像的差异程度。在3个真实工业表观缺陷数据集上的实验结果表明,结构化相似指标较传统像素级度量指标能显著提升模型对缺陷图像的判定能力,且与其它无监督缺陷图像判定方法相比也表现出了明显的性能优势。(2)提出了一种基于实体稀疏追踪的缺陷目标分割模型缺陷目标分割是指从输入图像中准确地确定缺陷的轮廓和位置,它是工业检测中对缺陷进行定量分析的基础。传统的检测方法大多只针对特定场景有效,模型的泛化能力较弱,且缺乏一个相对普适的理论框架。基于待检图像表面纹理在原始灰度空间或者特征空间中能形成一种低秩结构,而表观缺陷会对这种低秩性造成破坏的事实,提出了一种基于实体稀疏追踪的缺陷目标分割模型。在特征层面,考虑到大多数工业图像为灰度图,可用特征较少,基于局部二值模式的思想设计了一种新型特征,其对于图像背景和缺陷目标有着更好的判别能力,在此基础上,融合灰度特征和纹元特征组成了特征提取模块;在模型设计上,舍弃了传统低秩稀疏框架下常用的正则化约束,转而挖掘缺陷图像固有的实体稀疏性和局部显著性先验知识,并以此来指导特征矩阵低秩稀疏分解的过程。在多个表观缺陷检测数据集上的实验结果表明,所提出的模型在缺陷目标分割任务中具有较低的漏检率和误检率,展现出了较好的泛化能力。(3)提出了一种基于监督对比学习的缺陷类型识别模型缺陷类型识别是指从缺陷的形态、成因或者危害程度等角度对缺陷的定性分析,一般可形式化为一个多分类问题。在真实的工业视觉检测场景中,缺陷目标形态各异、尺寸不一、位置多变,且收集标注的缺陷样本难以覆盖同类缺陷所有可能的表观。与此同时,还存在着样本表观类内多变、类间相似的情形,这进一步加深了紧致化特征表示学习的难度。为了解决这些问题,提出了一种基于监督对比学习的缺陷类型识别模型,将监督对比学习与缺陷类型识别融合在统一的框架之下,对属于不同类型的缺陷样本建立了紧致化的特征描述。在对比学习分支的作用下,主干特征提取网络能够学习到更为紧致的特征空间,这反过来又提升了分类网络的识别性能。除此之外,实现了有效的特征生成策略,提高了模型对类内多变、类间相似缺陷样本的识别能力。在热轧钢带表面缺陷分类数据集和轨道异常扣件分类数据集上的实验结果证明了所提出方法的有效性。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000229
{DOI}: 10.26944/d.cnki.gbfju.2022.000229
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度学习框架下的生成式目标跟踪方法研究
{Author}: 孙兴龙
{Tertiary Author}: 郭立红;韩广良
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标跟踪;深度学习;孪生网络;注意力机制;残差学习;少样本学习;特征融合
{Abstract}: 作为信息处理与计算机视觉领域的研究热点之一,目标跟踪技术在安防监控、智能交通、视觉导航以及军事侦察等应用领域中扮演着十分重要的角色。以初始时刻感兴趣目标的位置状态为参考,目标跟踪致力于在后续任意时刻准确预测该目标的状态参数。尽管该技术在近年来已经取得了长足的进步,但仍存在许多难以解决的问题。在复杂多变的实际场景中,背景杂乱、光照变化、运动模糊以及遮挡等干扰因素使实现高质量的视觉跟踪成为了一个具有挑战性的课题。为此,探索精确可靠的目标跟踪方法具有重要的理论意义和应用价值。随着人工智能理论的迅速崛起,深度学习模型逐渐被应用到目标跟踪领域,使该技术领域得到了突破性的发展。深度学习框架下的目标跟踪方法已经取得了非常优异的跟踪表现,尤其是生成式的孪生网络跟踪方法。为此,论文在深入分析深度学习和目标跟踪的基本理论的基础上,在深度学习框架下对生成式目标跟踪方法开展研究,主要研究内容和创新性成果如下:1、目前,深度生成式跟踪方法在跟踪过程中通常难以兼顾精确性和鲁棒性,且对目标表观变化缺乏适应能力。针对这些问题,论文提出一种分层感知框架下基于注意力选择的深度跟踪方法。在离线训练阶段,该方法同时采用了空间感知训练机制与表观感知训练机制。前者在训练浅层网络模块时引入了大量的空间变换,这有利于提取位置感知特征;后者在优化深层模块时采用了丰富的表观变换,这有助于捕获表观感知特征。结合这两种训练机制可以有效提升模型跟踪的精确性和鲁棒性。此外,基于通道注意力机制与空间注意力机制设计了一个高效的特征选择模块,其能够使跟踪器快速鲁棒地适应目标的表观变化。实验结果表明了所提出方法的先进性和有效性,其可以实现精确鲁棒的目标跟踪。2、传统的融合算法难以自适应地结合多层卷积特征,所以不能够有效提升孪生网络模型的跟踪能力。针对此问题,论文基于残差学习理论为孪生网络设计一种新的特征融合模块。该模块将孪生网络深层部分输出的高阶特征作为直连分量,利用抽象语义信息整体性地识别目标;同时将来自浅层部分的特征输入到残差通道,利用局部细节信息精调目标的空间位置参数。此外,提出一种多损失集成训练机制。该机制采用不同的损失函数分别优化孪生网络模块与残差融合模块,抑制了网络优化的失衡现象。实验结果表明,提出的残差融合机制可以显著提升孪生跟踪器的跟踪能力。3、由于缺少有效的在线更新机制,典型的孪生网络模型难以在复杂场景下持续稳定地跟踪目标。针对该问题,论文首先通过分析孪生网络中的少样本学习机制提出一个两阶段少样本学习器,其可以结合不同阶段的目标样本预测主分类器的参数权重。此后,基于该学习器设计一个可更新的孪生网络模型。具体地,一个额外的输入分支被用于在后续阶段捕获目标的表观特征。接下来,利用一个特征更新模块结合不同阶段的模板特征,生成一个信息更丰富的融合模板。该模板可以帮助跟踪器更有效地在搜索区域内检测目标。实验结果表明了所提出方法的有效性,其在复杂场景下可以实现稳定鲁棒的跟踪。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000099
{DOI}: 10.27522/d.cnki.gkcgs.2022.000099
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的单目深度估计算法研究
{Author}: 杨依凡
{Tertiary Author}: 朱明
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 单目深度估计;空洞卷积;编解码器结构;图像分割;变换器结构
{Abstract}: 单目深度估计是指通过单幅RGB图像对图像对应场景里的每个像素点到相机的距离信息进行估计。作为三维空间视觉的底层任务,为机器人避障、自动驾驶、虚拟现实等研究提供最基本的深度信息。当前的深度探测设备主要包括激光雷达系统、毫米波雷达系统、飞行时间相机系统、双目相机系统、多目相机系统和结构光相机系统等,单一的深度探测设备存在或造价昂贵、或精度易受外界环境影响、或测距短、或算法计算量大等缺点,使用多个深度探测设备进行测距又很难兼顾成本与有效距离。单目深度估计仅需要一个RGB相机,通过算法进行像素级的深度估计。由于单目深度估计具有极低的硬件成本,因此其具有良好的发展和工程前景。当前在自动驾驶和机器人避障等领域,深度精度仍然是首要考虑的要素,且有监督的方法精度要高于无监督方法。鉴于此,本论文基于深度学习方法,针对有监督的单目深度估计算法展开一系列研究。围绕提高网络模型的估计精度以及轻量化模型等技术难点,开展了理论分析、方法研究、技术实现、实验验证等工作,主要研究内容如下:(1)基于多尺度U型网络的单目深度估计网络研究针对如何更好的融合局部深度信息与全局深度信息,更好的利用全局与局部的诸如形状、颜色、纹理等特征帮助网络进行深度估计,提出了一个基于密集空洞金字塔的混合尺度Unet网络框架。将用于图像分割领域的Unet++网络结构引入单目深度估计领域,在Unet++网络框架下重新设置了网络的卷积层数,并将解码器部分进行密集连接。通过选择合适的空洞半径大小,在编码器与解码器中间的过渡器部分构成了一个基于不同特征层的密集空洞金字塔,以更好地连接网络深层和浅层中的特征。在KITTI数据集和NYU Depth V2数据集上进行测试,所提方法优于大部分同类型方法,且在平方相对误差、均方根误差指标中表现突出,可以较全面的融合全局和局部信息,提高网络预测精度。(2)基于边缘约束的单目深度估计损失函数研究针对稀疏的深度真值图导致预测深度图模糊的难点,提出了一种强边缘约束损失函数。强边缘约束损失函数由加权的尺度不变性损失函数、点对排序损失函数和鲁棒有序深度损失函数构成。在点对排序损失函数中,提出了一种跨边缘点对采样方法,使用Sobel算子对图像边缘进行提取,通过边缘线中像素点的灰度梯度,与图像的任意坐标轴方向将该像素点附近区域分为四部分,通过在四个部分区域中随机选取任一像素点,构成三组点对,其中点对连线保证穿过边缘轮廓线。设置轮廓线中的像素点个数,得到对应的点对集合。在权威数据集上,对不同网络模型进行测试,证明了所提损失函数的先进性。并将使用强边缘约束损失函数训练的网络模型在自采数据上进行评估,取得了较好的效果。(3)基于语义信息的变换器型单目深度估计网络研究针对如何在不影响检测精度下轻量化模型的难题,提出了一种基于分割引导的类Unet-Swin Transformer深度估计网络模型。考虑到Transformer具有通用的建模能力,基于Swin-Unet框架,在跳跃连接部分嵌入了卷积残差模块,在不影响网络退化的前提下增加网络的深度,令网络更好的学习映射关系。在网络解码器部分,提出了一种最近邻引导模块对补丁进行上采样。最近邻引导模块通过输入RGB图像对应的语义过滤图像,得到前景和背景的掩模图,以此对特征图进行引导滤波,再送入卷积层进行卷积,最终使用最近邻函数进行上采样。在KITTI数据集和NYU Depth V2数据集上的大量实验表明,所提网络先进、有效,在缩减计算量和网络存储体积的前提下,仍然提高了网络的估计精度。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000009
{DOI}: 10.27522/d.cnki.gkcgs.2022.000009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成式对抗网络的图像去雾算法研究
{Author}: 姜鑫
{Tertiary Author}: 朱明
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像去雾;生成式对抗网络;密集连接网络;U-Net型网络;注意力机制;Transformer
{Abstract}: 近年来,环境污染问题日趋严重,雾霾天气出现的越来越频繁,严重地影响了我们日常的生产与生活。在雾霾天气下,光学设备无法获取有效的场景信息,色彩失真严重,图像对比度较低,成像质量较差,对视频监控、自动驾驶、卫星遥感等领域造成了较大的影响和干扰。因此,如何在不丢失图像细节或引入额外干扰信息的前提下,有效地去除图像中的雾霾,最大程度上恢复出图像的细节和纹理信息,提高图像清晰度和饱和度,具有重要的研究意义和应用价值。图像去雾是一个极具挑战性的研究课题,引起了学术界和工业界的广泛关注。但大多数图像去雾方法都严重依赖于大气散射模型,通过估算有雾图像的场景深度图和大气环境光来线性拟合出无雾图像。但在现实自然环境中,雾霾的成因错综复杂,难以通过一个简单的线性公式来进行拟合,同时场景深度图和大气环境光等参数的不准确估计也进一步影响了图像去雾效果,造成复原图像出现颜色失真、伪影以及去雾不明显等现象。此外,很多基于神经网络的去雾方法在推理计算的过程中,对不同空间像素、不同特征通道施以同样的权重值,但雾气在一幅图像中往往是非均匀分布的,不同特征通道提取的特征信息也是不同的,因此需要对图像中不同空间像素和不同特征通道施以不同的注意力或权重值,以提高神经网络的特征表达能力。同时,很多基于神经网络的去雾方法都需要同一场景下成对的有雾图像与无雾图像作为训练数据,但这些数据在实际应用中难以获得,这也严重限制了去雾网络的发展和应用。同样值得指出的是,大部分基于神经网络的去雾方法均利用了卷积操作来提取图像特征,但是,具有参数共享特性的卷积操作在应用时有两点弊端,一是卷积操作更加关注于局部特征信息的提取,不能对超出感受野范围的特征进行建模,因此无法很好地感知图像全局特征信息;二是卷积核与图像之间的交互并不能根据图像内容而自适应地调整,使用相同的卷积核来复原不同区域的图像可能并不是最好的选择。针对上述问题,论文对图像去雾问题展开了研究。围绕生成式对抗网络,结合密集连接网络、U-Net型网络、Transformer、残差网络、注意力机制等关键技术,开展了问题分析、网络设计、理论研究、仿真实验等一系列工作。论文主要研究内容如下:·针对大气散射模型和神经网络注意力问题,提出了一种基于空间和通道残差注意力网络的图像去雾方法,该去雾方法不需要估计任何大气散射模型参数,可以直接根据输入的有雾图像恢复出清晰无雾图像。具体来说,提出了一个空间和通道残差注意力模块,该模块通过分析不同空间像素、不同特征通道之间的相互关系,自适应地为不同空间像素和不同特征通道分配权重值,使得神经网络更着重于分析和处理价值量更大的像素点和特征通道,进而提升神经网络的特征表达能力。同时,提出了对比损失函数和配准损失函数来对去雾网络进行训练,以更好地保留图像中的细节和纹理信息,并减少伪影的生成。实验结果表明,该方法在公开的合成图像数据集和真实有雾图像中均取得了良好的去雾效果,复原出的图像细节更加清晰,色彩也更加丰富。·针对成对图像数据集问题,基于循环式生成对抗网络,设计了一个雾气关联特征注意力去雾网络。具体来说,考虑到有雾区域与无雾区域在多方面物理特性的差异,首先计算得到有雾图像的亮度、饱和度、对比度、颜色衰减和暗通道特征图,之后分别将这些特征图输入到雾气关联特征注意力网络中,得到相对应的雾气注意力图。由于雾气在图像中通常都是非均匀分布的,雾气注意力图可以提供有雾图像中每个像素点的雾气浓度信息,进而对后续去雾网络进行指导并提供参考,以实现更好的去雾效果。同时,提出了颜色损失函数来对去雾网络进行训练,以减少生成图像的色彩失真。该网络的训练不依赖于成对的有雾图像与无雾图像,只需要随机选取一个有雾图像数据集和一个无雾图像数据集,即可完成对网络的训练。经实验验证,该去雾方法可以高效地去除有雾图像中的雾气,并复原出高质量无雾图像。·为了克服卷积操作无法对超出感受野范围的特征进行建模的问题,提出了全局和局部特征融合去雾网络。具体来说,该网络分别利用Transformer和卷积操作提取图像全局和局部特征信息,并将两者融合后输出,充分发挥了Transformer建模长距离依赖关系和卷积操作局部感知特性的优势,实现了特征的高效表达。在最终输出复原图像前,设计了包含多尺度图像块的增强模块,利用Transformer进一步聚合全局特征信息,丰富复原图像细节。同时,提出了一个全局位置编码生成器,可自适应地根据全局图像内容信息生成位置编码,进而实现对像素点间依赖关系的二维空间位置建模。实验结果表明,所提出的去雾网络在合成图像数据集和真实有雾图像中均展现出了较好的去雾性能,复原图像更加真实和清晰,细节还原度高。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000007
{DOI}: 10.27522/d.cnki.gkcgs.2022.000007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉反馈的自动对准系统关键技术研究
{Author}: 李勤文
{Tertiary Author}: 王志乾
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自动对准;位姿测量;机器视觉;路径规划;避障
{Abstract}: 近年来,随着高速数据处理器的发展,对准系统已越来越广泛的用于大型物体的吊装和搬运工作,如集装箱的吊装,物料的装载及弹药的运送等。通过对目标空间位置的测量,自动调整移动部件进行对准,克服了传统的利用人工观察并指挥操纵的半自动对准方式效率低下的缺点,使得系统即使在与对准目标非常接近,工作空间狭小及周围有其他设备遮挡的情况下也能较好的完成对准任务。为了提高对准系统的自动化和智能化水平,本文针对导弹吊装对准系统中相关的测量及路径规划等关键技术进行了研究,论文的主要研究工作及成果如下:首先,阐述了本文基于视觉反馈的自动对准系统的相关流程及框架,介绍了视觉测量相关的数学表示方法及测量模型,以及机械臂运动学的D-H参数表示方法和基于齐次坐标变换矩阵的机械臂正、逆运动学模型。其次,针对对准测量系统中由于两测量相机分别对应一个合作目标点而导致的没有公共目标的问题,建立了视觉测量整体方案。提出了在不改变系统结构情况下的测量系统在线装调标定方案,包括光学测量装置光轴垂直度的装调,测量相机焦距的标定,激光测距数据的标定,两相机位姿关系的标定以及测量系统手眼关系的标定。重点解决了测量系统中两个非公共目标相机位姿关系的标定问题,基于DLT-LM算法提出了双相机在线标定方法。实验结果表明基于DLT-LM算法的双目相机标定方法求出的目标点距离均方差优于0.2mm。然后,介绍了非公共目标双目相机位姿测量方法。分析了只有两个合作目标点情况下的部件水平对准偏差测量问题,通过建立测量系统坐标系,利用坐标系间的转换关系构建两合作目标点成像方程之间的联系,结合双轴倾角仪及已标定的测量系统参数求得上下两部件间的水平对准偏差。建立了基于蒙特卡罗方法的测量系统误差分析模型,通过仿真和实验验证了对准系统上下两部件间的水平对准测量均方差优于1mm,满足导弹吊装对准系统的实际应用需求。最后,研究了基于动态运动原语的机器人运动路径规划和避障方法。在基于位置信息的视觉反馈系统中,动态运动原语方法能够根据位置反馈信息重新规划执行路径,即使在对准目标物体位置发生改变的情况下也能够完成对准任务。为了使机械臂能够自动避开对准过程中可能出现的移动障碍物,利用卡尔曼滤波和模型预测控制算法预估未来时刻机械臂末端与障碍物的相对状态,使系统达到更优的避障效果。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000096
{DOI}: 10.27522/d.cnki.gkcgs.2022.000096
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 高真实感人脸表情动态三维重建及迁移方法研究
{Author}: 叶于平
{Tertiary Author}: 宋展
{Publisher}: 中国科学院大学(中国科学院深圳先进技术研究院)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 三维重建;结构光;表情动画;表情迁移;4D成像
{Abstract}: 随着数字人技术的发展,人脸表情动画生成技术得到了研究者们的广泛研究。其中基于运动捕捉的方法具有更高的精度,更好的真实感,所以在电影、游戏行业得到广泛的应用。在本研究中我们在人脸建模精度以及模型驱动的流畅性与精细度两个方面入手提出了一系列相关的算法来实现高真实感的人脸表情动态重建以及迁移。围绕着实现高真实感的人脸表情重建以及迁移,本研究的主要内容可以分为四个方面:(1)本文基于近红外高频二值结构光技术重建技术提出了一种用于动态物体实时的三维重建系统。该红外结构光系统通过采用格雷码加线移作为编码策略,该编码策略可以做到亚像素的定位从而得到高精度三维测量结果。为了进一步提高系统重建精度,本文提出了一个基于3D优化的标定方法来对得到结构光系统标定参数进行优化。为了使结构光系统系统能够以硬件的最大帧率进行工作,本文将解码算法在GPU设备上进行并行化。该研究奠定了后续人脸动态重建技术的相关基础。(2)本研究利用提出的GPU的高精度结构光重建技术搭建了一个3D面部采集系统,通过该设备,本文采集了两个高精度且高分辨率的3D人脸表情数据库。相较于现有的3D人脸数据库,本文采集人脸3D数据库具有元数据丰富、表情丰富、数据库样本大等优点。(3)人脸动画的生成一般与采集设备的性能息息相关,得益于上述近红外结构光技术的研究成果,本文基于红外结构光传感技术提出了一种高保真3D实时人脸面部动画生成的系统与相关算法(基于GPU的非刚性配准方法、基于光流的模型跟踪算法,以及纹理融合算法等算法),可以同时实现系统易于部署且得到高精度高保真度的人脸动画表情。该系统可以实时捕捉高精度和稠密的人脸面部表情运动。(4)针对现有的人脸表情稠密迁移算法只能处理光顺的人脸序列模型,本研究中提出了一种基于关键点形变的非刚性配准算法该算法可以将输入的非光顺的非规整的表情输入序列处理成统一拓扑的三角形网,接着对该输出利用提出的带约束的人脸表情迁移算法可以准确鲁棒的得到表情迁移的结果。最后针对每一部分的研究,本文都进行了许多的实验来验证相关的算法的性能,其一般都比现有的算法具有更好的性能表现。本研究针对人脸表情动态重建以及迁移算法提出的一系列相关的设备、算法、数据,这些工作可以为游戏、电影行业提供一个新的解决方案。
{URL}: https://link.cnki.net/doi/10.27822/d.cnki.gszxj.2022.000018
{DOI}: 10.27822/d.cnki.gszxj.2022.000018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视频多目标跟踪算法研究
{Author}: 羊洁明
{Tertiary Author}: 葛洪伟
{Publisher}: 江南大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 多目标跟踪;深度学习;神经网络;运动模型;外观模型
{Abstract}: 对视频中的多个被关注对象进行维持固定身份标识的追踪,也就是多目标跟踪(Multi-Object Tracking,MOT),一直是众多研究者们所感兴趣的问题。其在应用于安防、工业、交通和军事领域等众多更复杂的计算机视觉系统中都能发挥独特的效果。离线跟踪能够利用整段的视频提供完整的时空信息来支撑跟踪,而在线跟踪仅能利用当前帧和历史帧等已知信息来构建目标轨迹。基于在线跟踪的特性,其能够满足诸如视频监控、自动驾驶等场景中所需要的实时性要求。因此,能够进行实时跟踪的在线跟踪算法以及其实现过程中碰到的相关问题是本文的首要关注点。传统的多目标跟踪算法,采用人工手段来设定被跟踪对象。而基于检测的跟踪范式则是从给定的视频每一帧的检测结果中获取当前场景中所有物体的位置和类别,再决定算法所关注的对象并加以跟踪。随着深度学习技术被应用到目标检测领域并带来巨大的性能提升,研究者们都将注意力集中到了基于检测的跟踪范式上,并设计出了一系列具有优异跟踪性能的视频多目标跟踪器。然而,当前的检测算法无法在一些目标遮挡严重以及目标数量较多的视频场景中完全准确地识别和定位感兴趣的目标,得到的检测结果中存在着大量的漏检和误检。因此,如何克服检测结果中噪声带来的不利影响并对目标的完整路径进行准确还原,是基于检测的多目标跟踪范式所面临的主要挑战。本文通过深入研究和分析基于检测的跟踪范式在视频在线多目标跟踪技术上的应用,探求了如何解决运动位置预测、边界框精细化、外观特征建模、跟踪管理、跟踪模块兼容性以及其对跟踪任务本身适应性等问题的方案。本文的主要工作概括如下:(1)基于预测细化和遮挡分类的在线多目标跟踪算法。深入研究了严重遮挡时不同遮挡类型目标的分类处理,旨在解决不准确的检测和预测带来的关联错误、目标重合导致的身份转换问题以及严重遮挡导致的漏警问题。具体而言,该方法首先采用了结合卡尔曼滤波器与增强相关系数法(Enhanced Correlation Coefficient,ECC)的运动模型来提升位置预测的准确性,其次采用了边界框回归网络来对运动预测后的目标位置来进行具有检测属性的细化,从而提高定位准确性,然后对被严重遮挡的目标进行分类以及差异化处理,并采用简单的贪心匹配算法就能够准确地将被跟踪的目标与检测响应进行关联,最后利用行人重识别环节对重新进入场景中的丢失目标进行身份的还原,从而提升了算法进行在线多目标跟踪的性能。(2)基于多功能聚合和跟踪模拟训练的多目标跟踪算法。为了使多目标框架中各个模块之间更加兼容,该算法将边界框细化和目标外观特征提取功能整合到一个网络模型之中并利用后续的不同分支来实现对应功能。该算法还采用了卡尔曼滤波器聚合增强相关系数法ECC的运动模型来提高预测准确度。为了提升各个网络模块对于跟踪任务本身的适配性,该算法还提出了一种跟踪模拟训练法来训练网络模型。在训练时模拟在线多目标跟踪过程,利用运动预测的位置来扩充训练数据,并结合了一种能够利用目标历史外观特征的指标损失来训练外观特征提取模块,使得网络模型能以一种端对端的方式来优化权重。(3)基于二源运动预测的多目标跟踪算法。在存在大量转弯、加减速等非线性运动的复杂视频场景中,简单的线性运动模型往往表现乏力。因此,该算法提出采用在文本翻译、语音识别等领域中展现出卓越的序列数据处理能力的Transformer结构构建运动模型,实现对目标位置变化规律的感知以及在后续帧的位置预测。目标的历史位置差被用来提取目标本身运动带来的非刚体位置变化信息,并用增强相关系数法ECC提取连续视频帧之间的仿射向量来提供刚体位置变化信息。这两类信息分别被两个全连接层扩充信息尺度后,输入到网络模型中予以预测目标当前的位置,从而提升了预测准确度。同时,该运动模型也能够简易地部署到其它跟踪框架中来提升跟踪性能。本文将提出的视频多目标跟踪算法在多个被研究者们认可且广泛应用的公开实验数据集上进行了评估并与其它优异的跟踪算法进行了定量的比较。通过分析实验结果,可以发现提出的方法是十分有效的,它们能够有效地缓解上述几个关键性问题,并提升基于深度学习的视频多目标跟踪算法的整体性能。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000024
{DOI}: 10.27169/d.cnki.gwqgu.2022.000024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轻合金车轮表面缺陷检测系统研究
{Author}: 刘杨
{Tertiary Author}: 苑玮琦
{Publisher}: 沈阳工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 轻合金车轮;自动成像;缺陷检测;互信息;深度学习
{Abstract}: 在“碳达峰、碳中和”的时代驱动下,我国为了积极推动能源绿色低碳转型,在新能源车辆领域正努力探索新材料与新技术。目前,轻合金材质以其轻量、耐久、环保等优势已经代替钢制材料广泛应用于车轮产品中。出于安全角度的考量,生产厂家对轻合金车轮表面质量的检测非常严格,避免细微缺陷对产品安全性的潜在危害。然而轻合金车轮生产的多重工序都可能会面临机器或人工损伤,使轻合金车轮表面缺陷特征复杂,给表面质量检测带来一定的挑战。目前对于轻合金车轮表面的质检仍依靠人工的方式,重复的工作疲劳以及专家知识的差异性都可能对检测效率产生影响。另一方面,基于机器视觉的检测技术已经凭借其自身优势在工业自动化中占有一席之地,并占据视觉引导、表面质量检测的主力地位。在机器视觉检测技术中,硬件和软件技术可分别用于解决不同的图像缺陷检测问题。例如,操作平台、相机、光源等硬件的协调配合可以将三维空间中的检测对象转换成二维空间中的数字图像,以突出图像中的目标区域;检测算法可以将二维数字图像中的目标信息进行选择性特征表达,实现图像缺陷区域的精准识别。本文致力于利用机器视觉技术在车轮生产线末端实现轻合金车轮表面缺陷的自动检测,设计目标涵盖车轮部件的自适应全覆盖成像,同时,重点研究了轻合金车轮表面缺陷检测系统存在的若干关键问题。考虑到车轮制造工艺对轻合金表面的影响,研究内容分为三个主要部分:轻合金车轮自动成像系统、加工面缺陷检测方法、铸造面缺陷检测方法。论文的主要研究内容如下:(1)设计了轻合金车轮加工面与铸造面两种自动成像系统。首先,设计了线阵相机和光源扫描自转车轮的加工面自动成像系统,基于几何光学原理从微观加工纹理分析拓展到宏观表面轮廓分析,通过成像机构空间位姿自动寻优过程实现了加工面纹理显著性成像目标。其次,设计了以机械臂控制的面阵相机移动触发采集的铸造面自动成像系统,通过对差异性成像部位的自动识别完成成像机构空间位姿的自适应调整,实现了铸造面全覆盖成像目标。两种成像系统解决了由轻合金车轮多样性结构与表面导致的固定成像位姿不能实现的全覆盖问题。通过成像系统试验,结果表明实际采集图像符合设计目标,并建立了轻合金车轮加工面与铸造面图库。(2)提出了一种基于最大互信息与二维直方图的加工面缺陷检测算法。针对加工面存在的具有非显著性类间差异的浅坑缺陷漏检问题,首先建立了灰度-局部空间灰度差直方图并改变了传统的多阈值分割模式,在突出浅坑缺陷分布特征的同时,增强了与背景之间的类间差异,解决了浅坑缺陷与背景之间的灰度差异与分布间距无法直接作为二值化判据的问题。其次,分析了浅坑缺陷与背景的特征交叉区间,并基于互信息表示浅坑缺陷与背景之间的最大依赖程度,解决了特征交叉区间中目标缺陷检测困难的问题。实验表明本文方法在轻合金车轮加工面浅坑类缺陷检测中获得了较好的性能。(3)提出了一种基于临级编码特征融合的铸造面缺陷检测算法。在U-net网络编码-解码结构的基础上,首先加入了残差模块用于实现各层级输入输出之间的快速链接,其次利用空间软注意力机制剔除了冗余信息,最后提出了临级编码特征融合的方式加强对空间信息的恢复,临级特征关联最大化的表示方式解决了深度学习方法提取的各层级特征对铸造面多类型缺陷的表示问题,进而实现了轻合金车轮铸造面中类内差异与类间相似缺陷区域的分割与分类。实验表明本文方法在轻合金车轮铸造面多类型缺陷检测中取得了较好的分割结果与分类性能。基于机器视觉技术的轻合金车轮表面缺陷检测系统可以降低车轮表面质检的漏检率和误检率,减少表面缺陷对车辆行驶安全性的隐患,提高实际生产线的质检效率和自动化水平,为新能源转型发展提供技术支持。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.001017
{DOI}: 10.27322/d.cnki.gsgyu.2022.001017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的图像超分辨率重建算法研究
{Author}: 程国安
{Tertiary Author}: 詹曙
{Publisher}: 合肥工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像超分辨率重建;注意力机制;编解码结构;神经网络搜索;对比学习
{Abstract}: 图像超分辨率重建是指利用给定的低分辨率图像恢复出高分辨率图像的过程,是一类关键的计算机视觉或图像处理技术。该技术不仅是单独的低级视觉任务,它还可以作为其他计算机视觉任务的预处理过程,在公众安全、遥感卫星图像、医学图像、视频显示等大量图像相关领域广泛应用。一般来说,图像超分辨率(Super-Resolution,SR)重建任务非常具有挑战性并且本质上是病态的。因为如果确定降质模型后,从高分辨率(High-Resolution,HR)图像到低分辨率(Low-Resolution,LR)图像的过程是唯一的,但是从LR图像恢复HR图像时,这个映射并不是唯一的,每一个LR图像都有着对应的大量HR图像。近期基于深度学习的图像超分辨率重建算法取得了长足的发展,这主要得益于图形处理器(Graphics Processing Unit,GPU)等硬件计算能力的提升。本文在前人工作的基础之上,从注意力机制、编解码结构、神经网络搜索和对比学习等方面研究了基于卷积神经网络的图像超分辨率重建,设计了多种基于卷积神经网络的图像超分辨率重建算法,论文的核心研究工作主要包括以下四个部分:(1)针对同期卷积网络结构无法充分提取低分辨率图像所具有的层次特征,提出了增强的双路径注意力网络。该算法结合了残差网络的特征复用优点以及密集连接网络的特征探索优点,并采用了通道注意力机制。该算法利用双路径网络模块来融合残差和密集连接网络模块的优点,并通过特征早期分离的方式进一步增强了双路径网络的表征能力。该网络通过堆叠这样的增强型双路径模块,并将注意力机制引入到增强型双路径模块中,从而自适应地细化提取的特征。实验结果表明,该算法具有更强的表征能力,可以重建出视觉效果更好的结果。(2)针对未知退化过程的图像超分辨率重建困难的问题,研究提出了一种鲁棒且有效的现实世界图像超分辨率重建算法。该算法设计了一种逐步降噪并恢复丢失信息的编解码器残差网络结构。该算法通过采用编解码器结构来获取大范围像素之间的关系,从而进一步将原始图像编码为具有更多上下文信息的特征。对于编码后的特征,由于特征的空间尺度不同,该算法在网络中引入由粗到细的思想,逐步恢复出高质量的图像。该算法提出的结构可以通过残差学习来对每个尺度丢失的信息和需要去除的噪声进行建模。此外,该算法通过实验证明仅将批量归一化应用于下采样和上采样卷积层可以带来性能增益。最后定性和定量的实验表明,该算法的鲁棒性很好,可以适用于未知退化过程的图像超分辨率重建任务。(3)针对手动设计神经网络硬件成本太高的问题,提出了一种即插即用的基于神经网络搜索的单图像超分辨率重建算法。该算法仅使用单个RTX 2080TI GPU就可以搜索出很好的网络结构。该算法不仅搜索每个节点的操作算子,还搜索每个节点的激活函数、来源节点和跳连接节点,从而以更少的搜索代价探索更多样化的网络结构。这种搜索空间一方面隐式的优化了cell中的中间节点数目,另一方面直接避免了其他神经网络搜索算法出现的跳连接富集现象。此外,为了消除训练和测试阶段目标函数不一致的影响,该算法在训练过程中对架构参数引入随机变量来作为正则化。搜索出的网络结构表明,本文的算法可以探索出较为多样化的网络结构。定性和定量实验表明,该算法可以搜索出有效且鲁棒的网络结构。(4)针对当前图像超分辨率重建算法忽略输入特征空间位置差异的问题,提出了一种基于Involution的轻量化对比学习网络。该算法首次将Involution应用于图像超分辨率重建来引入空间特定的特性。然而,原始Involution提取的特征是空间特定的,但却通道共享的。因此,该算法针对原始Involution存在的问题,进一步对模型的结构进行了改进。同时,该算法通过将L1损失与自监督对比损失混合来优化整个网络。实验结果表明,该算法取得了最先进的定性和定量结果,证实了该算法的有效性。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000059
{DOI}: 10.27101/d.cnki.ghfgu.2022.000059
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人脸检测方法
{Author}: 屈诺希
{Tertiary Author}: 郭昕刚
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人脸检测;卷积神经网络;肤色检测;多层特征融合
{Abstract}: 人脸检测是人脸识别技术中的关键一步,在计算机视觉领域中有着许多研究与应用。在大多数研究工作中,实际场景环境会影响人脸图像采集,如光线、遮挡等,还有自身的姿势、站位、拍照方式都对人脸检测的准确率存在一定影响。大多数人脸检测模型对这些问题进行了研究但表现未到最优。本文通过对人脸检测技术进行研究,构建基于深度学习的人脸检测模型,对图像进行自动特征提取,提取出更加有利于对人脸进行检测的特征,从而解决外部环境和自身因素对人脸检测的影响。本文首先介绍了人脸检测流程,包括候选区域选择、特征提取、分类器分类等步骤。按照该过程进行研究工作,从图像上更准确地选取出可能存在人脸的候选框;然后利用深度学习技术对候选框中的图像提取特征,提取出更加具有人脸代表性的特征;最后使用分类器来对提取出的特征进行分类,判断该图像中是否存在人脸。论文的主要内容如下:(1)针对外部环境对人脸检测算法的干扰问题,本文提出基于肤色区分的卷积神经网络人脸检测算法。首先使用仿射变换进行人脸对齐,然后使用参考白算法对图像进行光线补偿;利用基于YCr Cb空间的肤色检测提取人脸特征,最后利用卷积神经网络结合Adaboost算法训练生成分类器。在遮挡、多姿态情况下,本章算法能够保持较高的准确性,并具有较强的鲁棒性,检测准确率达到98.6%。(2)由于传统的基于图像金字塔机制的人脸检测算法,提取出的高层次语义特征往往丢失了人脸细节信息,而低层次特征具有人脸的细节信息。为进一步提高人脸检测算法提取出的特征对人脸的表达能力,并解决人脸复杂性对人脸检测算法性能造成的影响。本文提出了基于改进注意力机制的多层融合算法,从而获得具有更多低层次细节以及高层次抽象的高级特征向量,以此来提高特征向量的丰富性以及代表性,避免人脸复杂性与外部环境对人脸检测算法的干扰。该算法将深度学习理论与基于部分模型的思想相结合实现人脸检测。(3)采用Tensor Flow深度学习框架来搭建人脸检测平台,在此平台上部署本文所提出的人脸检测模型,以此来进一步验证本文所提算法模型的有效性以及实用性。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000008
{DOI}: 10.27805/d.cnki.gccgy.2022.000008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像特征提取及其应用
{Author}: 袁琳
{Tertiary Author}: 赵宏伟
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 特征提取;遥感图像检索;深度度量学习;卷积神经网络;裂缝图像检测
{Abstract}: 信息技术和硬件设施的不断发展进步,使得数字图像中包含的数据量不断增加,图像处理及应用开始受到人们重视。尤其是在遥感图像检索、农作物种子分类及检测、路面裂缝检测、医学图像分割等应用领域,图像中所包含的信息的精确分析将对使用者提供很大的帮助。而随着计算机领域的快速发展,人们开始尝试将“如何看见并看懂图像”这一人类感知世界的重要方式赋予给计算机,随之出现了计算机视觉这个概念。而计算机视觉任务在对图像进行理解和分析的过程中,对于图像的特征提取是非常关键的一步。本文从两个计算机视觉中遥感图像检索和路面裂缝检测两个应用领域入手,在当前已有方法的基础上进行算法改进,旨在挖掘卷积神经网络的特征描述能力,进而提高检索、检测等计算机视觉任务的效率和精准度。本文研究内容:1.为了解决特征提取过程中类内样本相似度差异大的问题,提出了一种基于相似性保持损失(Similarity Retention Loss,SRL)的深度度量学习方法。从样本挖掘、网络模型结构、度量损失函数等方面对现有的度量学习方法进行了改进。在样本挖掘方面,重新定义了困难样本和简单样本,并根据样本集合大小和数据集类的空间分布分别挖掘了合适的正样本和负样本。同时,在度量损失函数方面提出了相似性保持损失的概念。根据类别中难易样本的数量情况为挑出来的难样本分配不同的学习系数,通过这种方式学习相同类别样本的空间结构特征。而负样本则根据空间中同一范围内样本的空间分布给予不同系数,以此来保持相似性空间结构特征。最后使用针对遥感图像数据特征进行修改后的微调网络对两个遥感数据集进行了大量综合实验。2.对于特征提取过程中类间差异小导致样本区分困难的问题,结合深度度量学习两种损失函数设计思路(即结构损失和基于结果的损失),提出了全局感知排序损失(Global-aware Ranking Loss,GRL)模型,这是一个基于特征空间和检索候选列表的全局优化模型。并且提出对于每个数据集中的每个类别来说,类内样本之间的相似度是不同的,因此需要学习的样本和样本数也应该是不同的。提出类内空间样本挖掘(Intra-class Space Sample Mining,ISSM),即根据样本的分布情况选择错位样本,而不是像通常那样人为设置样本挖掘的边界阈值。3.针对更加困难的计算机视觉任务,即从复杂背景中自动提取并区分裂缝,提出一种结合Residual注意力机制的Octave U-Net网络模型,解决特征提取过程中前景和背景不平衡的问题。通过结合Octave卷积和Octave转置卷积,并根据网络特点选择Residual注意力模块辅助模型捕获不同类型的图像特征,同时防止U-Net网络随着网络深度的增加丢失底层语义信息。并且提出改进的加权交叉熵损失,该损失既稳定而且解决了类别失衡问题。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.003268
{DOI}: 10.27162/d.cnki.gjlin.2022.003268
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络优化的细粒度图像识别研究
{Author}: 倪天宇
{Tertiary Author}: 李鹏松
{Publisher}: 东北电力大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;细粒度图像识别;双线性网络;特征融合;小样本学习
{Abstract}: 随着互联网的不断进步,各类图像已成为互联网时代的主要数据媒介和信息载体,如何快速高效地提取图像的关键信息并对图像进行准确识别是当前的主要问题。细粒度图像识别和传统的图像识别有所区别,是指对某大类物体对象中区分出不同子类。由于细粒度图像具有子类间差别小和子类内差别大的特点,所以在计算机视觉领域中,细粒度图像识别成为一项具有挑战的研究任务。双线性卷积神经网络可以在只有图像标签的情形下实现端到端训练,从而成为了目前细粒度图像识别的主流模型。本文将围绕细粒度图像识别模型展开研究,提出基于卷积神经网络优化的细粒度图像识别模型。该模型解决了两个问题,一是如何有效获取网络的浅层特征,并将浅层表面特征与深层抽象特征进行融合识别。二是如何借助现有较少的标注样本信息,或借助只有图像标签标注的数据样本信息训练出具有良好性能的模型。为保证通过细粒度图像识别模型可以获取有用的浅层特征并将深层特征与其加以融合,本文提出基于特征融合的细粒度图像识别模型。鉴于网络的深层特征与浅层特征对图像识别的作用不同,本文将双线性卷积神经网络进行了改进,利用高分辨网络构造双线性网络,可以便于网络实现多次的特征融合,从而提升网络的识别准确率。本文将所构造的网络在CUB-200-2011鸟类数据集以及汽车数据集Stanford Cars上进行测试,并与Lin所提出的双线性卷积神经网络以及3种常见的细粒度图像识别模型进行对比试验,验证了该方法的有效性。为保证细粒度图像识别模型可以在较少训练样本的情况下也有较强的学习能力,本文提出基于小样本训练的细粒度图像识别模型。该模型考虑到目前的可标注数据样本较少,提出利用原型网络对小样本的细粒度图像进行训练。本文使用Mobile Net网络和Res Net-18网络构造的双线性网络作为原型网络的嵌入函数,将测试集的标注样本映射至嵌入空间并取均值,得到类别原型,最后计算验证集的特征向量与类别原型之间的欧氏距离并对其进行分类。利用此方法能够迅速地从少量样本中学习特征,进而将图像样本进行准确分类。本文将所构造的网络在CUB-200-2011鸟类数据集以及汽车数据集Stanford Cars的抽样子集上进行测试,并与3种常见的小样本学习模型进行对比,得到的识别精度均高于其他网络,验证了该模型具有识别准确率高、泛化能力强的特点。
{URL}: https://link.cnki.net/doi/10.27008/d.cnki.gdbdc.2022.000316
{DOI}: 10.27008/d.cnki.gdbdc.2022.000316
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉与深度学习的油茶果目标检测方法研究
{Author}: 吕帅朝
{Tertiary Author}: 宋怀波
{Publisher}: 西北农林科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 油茶果;深度学习;低照度图像增强;目标检测;GUI程序设计;PyQt5
{Abstract}: 油茶果在中国的栽种历史超过两千年,被誉为“东方橄榄油”,具有极高的营养价值和经济价值。在油茶果生产作业中,人力成本占整个采收成本的20～30%,由于我国正在进行产业升级,大量人员涌入第二、第三产业,目前从事农业相关的人员数量越来越少,劳动力短缺问题日益严重。而使用机械化设备对油茶果进行自动化采收则可以大大降低人工作业成本,有望缓解劳动力不足的问题,其中油茶果果实的准确定位是油茶果采摘设备正确工作的关键。本研究基于深度学习技术,开发了非结构化场景下的油茶果目标检测系统,主要包括油茶果图像增强子系统和油茶果果实目标检测子系统,其主要的研究内容及结论如下:（1）针对现有低照度增强算法难以对自然场景下的油茶果图像进行符合语义增强的问题,提出了一种油茶果低照度增强算法（A-UNet）。A-UNet是U-Net卷积神经网络（CNN）的基础上,融合通道注意力机制的低照度图像增强算法。试验结果表明,A-UNet对图像增强后的峰值信噪比（PSNR）、结构相似度（SSIM）、相对亮度顺序（LOE）、特征相似度（FSIM）分别为31.76、0.98、37.49、0.98;使用经A-UNet增强后的油茶果数据集训练YOLOv4模型,在测试集下的准确率（P）为93.85%,召回率（R）为89.63%,全类平均正确率（m AP）为93.85%,综合评价指标（F1）值为0.92,分别比对照组模型的P、R、m AP、F1提高了6.33%、9.25%、7.93%和7.89%,表明将A-UNet应用于低照度油茶果图像的增强是可行的、有效的。（2）针对常见目标检测算法在果实重叠时识别精度较低的问题,提出了一种Soft-YOLO油茶果重叠果实识别算法。传统的目标检测算法剔除重叠部分的相邻预测框时,多采用贪心NMS算法,直接将重叠区域得分较低的框剔除掉,容易导致重叠果实的误检和漏检,而Soft-YOLO在进行重复框的筛选时,将NMS的硬置零策略修改为设置衰减函数,从而允许网络在果实重叠区域精准识别对应的果实,增加网络对重叠果实目标的检出率。试验结果表明,该算法可对处于不同重叠程度下的油茶果果实图像进行高精度识别,本算法检测精度为94.74%,优于原始YOLOv4网络的93.43%,可以满足油茶果采收机器人对果实定位精度的需求。（3）针对夜间环境下油茶果果实图像识别精度较低的问题,提出了一种夜间油茶果识别算法YOLON。YOLON在目标检测网络YOLOv3的基础上,引入照度自适应调整模块（LA）,可以自适应地对夜间油茶果果实图像进行照度调整,使得特征图中轮廓和细节的表达更加清晰。此外,本研究提出了夜间先验知识模块（NPK）,对网络的误差进行数据建模,以辅助因子的形式对网络特征图的预测结果进行精细化调整,从而提高网络的识别精度。试验结果表明,本研究所提出的YOLON模型在夜间油茶果图像的测试m AP为94.37%,优于原始YOLOv3模型的92.23%,可以满足油茶果采收机器人对定位精度的要求。（4）利用PyQt5进行油茶果目标检测软件系统的设计。结合所提出的油茶果目标检测方法,设计了非结构化环境下的油茶果综合图像处理系统,通过对自然场景下采集到的油茶果果实图像进行照度调整,并针对不同场景下的油茶果果实图像进行目标检测。实验结果结果表明,该系统可以准确、实时地对于油茶果图像进行照度增强、目标检测。
{URL}: https://link.cnki.net/doi/10.27409/d.cnki.gxbnu.2022.000964
{DOI}: 10.27409/d.cnki.gxbnu.2022.000964
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的农业图像分类方法研究
{Author}: 杨承林
{Tertiary Author}: 王贵参
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视觉Transformer;杂草叶片数目分类;迁移学习;集成学习;害虫分类
{Abstract}: 近年来,深度学习技术得到快速发展,计算机视觉与农业领域结合引起学者们的广泛关注。神经网络在复杂场景下对农业图像的识别成为一个热门研究课题。如今在农业的发展中,杂草和害虫对农作物的产量和质量影响依旧巨大,致使农业发展缓慢。因此,快速且准确识别杂草叶片数目和害虫更有利于解决上述问题,对农业领域其他相关研究有着良好的应用价值。本文分析了深度学习技术及其在农业领域应用的研究现状,结合不同的农业领域图像,以神经网络理论为基础,主要的工作内容如下:(1)缓解数据集分布不均衡和数量较少的问题。本文使用的Leaf-Counting数据集具有类别不均衡问题,为了使数据集分布更均衡合理,采用过采样的方法对数量少的类别进行样本扩充,同时创建Leaf-Counting-B数据集进行额外的补充。并为复杂场景下害虫分类创建Pests-D数据集。对本文实验使用的数据集进行数据处理,包括图像裁剪和图像归一化,并选用了旋转、翻折、添加噪声等数据增强方式进行进一步的样本扩充,有效避免数据量过少带来的过拟合问题。(2)提出一种改进的Vision Transformer杂草叶片数目分类模型。由于对图像直接硬性分块容易造成图像信息丢失,使得模型对整体图像信息不敏感,从而导致模型准确率较低等问题。针对以上问题,本文结合卷积神经网络模型的层次化结构,提出了CNN-Stem模块,并基于Vision Transformer模型构建一种新的网络模型,命名为C＿Vi T。通过消融实验验证模型改进的有效性,并通过参数搜索实验为模型寻找合适的网络超参数。经实验验证,改进的网络模型在Leaf-Counting数据集的准确率提升到74.05%,比Vision Transformer模型提升1.20%,相较于Inception-V3模型提升3.98%。(3)提出基于集成学习的害虫分类模型。由于单一模型在害虫分类过程中存在因特征提取不充分或特征丢失造成害虫误检等问题。针对以上问题,为弥补单一模型学习能力的不足,通过排列组合的方式对Goog Le Net、Res Net、Vi T、Pi T这四个网络模型中的两个或两个以上进行集成学习,并用于害虫分类任务。将各模型保留特征提取部分,接入新的分类结构模块,使用迁移学习方法对网络模型进行再训练,最终使用集成学习方法对不同模型进行集成。经实验验证,通过集成学习后的模型分类准确率普遍要高于各单一模型,并且模型鲁棒性更强。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000506
{DOI}: 10.27805/d.cnki.gccgy.2022.000506
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的户外智能车车道线检测与交通标志识别研究
{Author}: 杨学祺
{Tertiary Author}: 邱东;杨伽利
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 户外智能车;改进层次分析法;车道线检测;改进模板匹配法;交通标志检测与识别
{Abstract}: 随着科学技术的快速发展,智能车在工业生产中扮演重要角色,户外智能车产品也逐渐升级改造,带动社会发展。本文主要针对密闭和半封闭的公共空间环境,研究以智能车为载体的车道线检测和交通标志的识别,使其能够在特定的环境下完成工作,主要研究工作如下:(1)基于改进的层次分析法和三标度法建立了多因素层次结构模型,引入最优传递矩阵优化了整个方法的计算过程。通过定量的评价研究,分析了户外智能车的性能权重,为后续智能车道路信息采集与分析提供了研究依据。(2)基于户外智能车复杂的工作环境,开展了道路图像预处理工作,对采集到的图像进行感兴趣区域提取、灰度变换、图像滤波和图像增强等处理;通过实验对比分析,选择了既能降低噪声,又能保存图像边缘信息的双边滤波法。以Canny算子边缘检测算法为基础,给出了一种改进双阈值的Canny算子对车道线进行边缘检测。针对有干扰标志、阴影、夜间和光照强度不高的直线车道,采用累计概率霍夫变换算法和分段霍夫变换的算法分别对直线车道模型和曲线车道模型进行车道线检测。最后采用最小二乘法对检测的线段进行拟合。实验表明累计概率霍夫变换算法相比传统霍夫变换算法具有更高的准确率和更好的实时性,在曲线车道线检测方面,分段霍夫变换算法也能够很好地完成曲线车道检测。(3)针对基于颜色模型的交通标志检测算法进行了实验研究,在HSV颜色空间分割法的基础上给出了基于HSV颜色空间的改进阈值分割法。经过颜色空间转换将待测图像的RGB颜色空间转化为HSV颜色空间,然后通过对H、S、V三个分量进行自适应阈值分割来完成交通标志检,该方法不仅有效实现了交通标志的分割,而且去除更多的干扰噪声。最后将基于HSV颜色空间的改进阈值分割法与RGB颜色空间模型分割法和HSI颜色空间模型分割法进行实验对比分析,实验结果表明该方法可有效去除背景干扰,同时大大提高了检测速度与准确率。(4)在传统模板匹配识别算法的基础上,给出中心不变矩模板匹配法和相关性系数与HU不变矩法的两种改进型模板匹配法。中心矩不变模板匹配法是通过计算模板图像的中心矩特征向量和测试图像的特征向量,并采用相似系数函数来对两个特征向量进行相似度对比。通过计算相对简单的模板图像特征向量克服了传统模板匹配法为了减少计算量而只能降低识别精度的弊病。相关性系数与HU不变矩的交通标志识别法是根据不变矩的原理将三阶规格化中心矩的非线性组合构成7个具有平移不变性、旋转不变性和放缩不变性的不变矩。针对这种方法存在因为车载摄像机拍摄的图像会发生旋转或者放缩变化而导致识别率降低的问题,利用不变矩之间的比值约掉比例因子的方法使不变矩公式不受图像旋转和放缩变化的影响。基于这种思想,拓展出10个不变矩,通过这10个不变矩之间的比值消除比例因子来保持不变矩的不变性,从而提高了识别的准确率。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000193
{DOI}: 10.27805/d.cnki.gccgy.2022.000193
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自动驾驶场景下的三维目标检测技术研究
{Author}: 李瑞龙
{Tertiary Author}: 吴川
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;目标检测;点云;体素;深度估计
{Abstract}: 感知功能是自动驾驶的关键环节,是行车智能性和安全性的保障。“感”是指硬件部分,负责收集周围环境信息,“知”是指算法对硬件收集信息的理解。三维目标检测是指从传感器数据中检测物理对象,预测估计目标的类别、边界框和空间位置等物理信息,是感知系统和场景理解的核心,也是路径规划、运动预测和紧急避险等决策控制环节的基础。近年来,深度学习在目标检测和深度估计等方面取得了突破性进展,基于深度学习的检测、识别、分割、深度估计算法性能突出,为感知系统的研究提供了新的思路和方法;并且随着传感器技术的发展,例如激光雷达的等效线数提升、成本大幅降低和广泛使用,可以通过相机、激光雷达等多种传感器为感知系统提供更丰富的车辆周围信息。使用单传感器可以避免多传感器融合带来的时间同步和视角不一致等技术难题,目前基于深度学习的单传感器下的目标检测性能已经超越多传感器融合的技术路线。基于此,论文分别采用激光雷达点云数据和单目相机图像数据,结合深度学习方法,围绕激光雷达点云和单目图像分别进行三维目标检测任务,并进行了理论分析、方法验证、结果分析等工作,主要研究内容如下:(1)对国内外经典的三维目标检测算法及研究现状进行调研。首先对基于深度学习的三维目标检测算法发展历程和原理进行调研,分析其性能提升的原因,对目前经典的三维目标检测算法进行了具体分析。针对自动驾驶使用的主流传感器(相机和激光雷达)的工作原理和类型分类进行了研究,针对使用数据类型及数据的表示和处理方式上对主流的算法进行分类比较,分析各种方法在自动驾驶领域中的优缺点,以及三维目标检测算法未来发展方向。(2)激光雷达稀疏点云体素化场景下的三维目标检测技术研究。针对激光雷达点云数据在目标场景中具有稀疏性、数据量大的特点,本文改进一种点云体素化场景下的三维目标检测算法。算法将目标空间划分为体素网格,然后使用基于稀疏卷积的三维主干网络将体素格快速转化为立柱体素形式的二维数据,提升算法的训练和检测速度。然后使用二维主干网络处理立柱体素形式的二维信息,同时将三维主干网络中不同尺度的体素特征与二维主干网络提取的特征输入到多尺度体素特征聚合模块,充分的学习点云的空间信息,最后将得到的结果通过损失函数进一步细化检测框,预测目标的位置和类别等信息。通过在数据集上实验验证,算法实现了速度与准确率的平衡,对大目标识别效果较好。(3)基于深度估计的单目图像三维目标检测。针对自动驾驶中过度依赖单一传感器(激光雷达)造成感知系统鲁棒性差的问题,提出了一种基于相机图像数据的三维目标检测算法。算法通过深度估计为单目相机图像像素预测深度,可以得到伪点云形式的数据。再转化为体素网格形式,利用基于体素的三维目标检测算法进行目标检测。最终结果显示,基于单目图像的三维目标检测性能仍具有优势,可以作为基于激光雷达点云三维目标检测的有效补充。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2022.000158
{DOI}: 10.27522/d.cnki.gkcgs.2022.000158
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Python的海生物图像识别研究
{Author}: 隽志龙
{Tertiary Author}: 于复生
{Publisher}: 山东建筑大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 海生物捕捞;机器视觉;种类识别;平行结构光;尺度测量;深度测量
{Abstract}: 海参、海胆等底栖生物的收获主要靠人工进行。而这些海生物的生长环境复杂,收获时海底巨大的水压会严重损害捕捞者的身体健康。目前尽管已经有越来越多的自动化捕捞设备开始涉足该领域,但海生物的检测与定位问题一直是自动化捕捞的技术瓶颈。本文针对海参、海胆等海生物的实时水下图像采集、目标检测和尺度测量进行了深入的研究。本文以实地采集和网络搜索等途径获取的海参、海胆、海星和扇贝图像为研究对象。首先搭建了水下海生物的实时图像采集系统。该系统在结构上具备轻量化、拓展性强等特点,在实时采集中能在人工光源的辅助下完成水下高清视频的拍摄。其次,利用数字图像处理及深度学习技术开展了海生物目标检测算法研究。建立了海生物图像数据库,采用线下数据扩充方法对已有图像进行了数据增广处理。针对传统目标检测算法在复杂水下环境中识别率低并且容易漏检等问题,将改进Faster-RCNN算法用于海生物目标检测中,这种算法采用残差结构将输入映射到输出层,通过残差学习的方式避免了网络层数增加带来的梯度消失或网络退化问题,通过特征融合增强了模型的特征提取能力,提高了目标检测精度。并将该算法与Res Net-SSD算法进行了对比实验,对比实验表明,在满足实时性图像处理要求的基础上,该算法的识别准确率比Res Net-SSD算法高18.4%。再次,本文提出了基于平行结构光的海生物尺度测量与深度计算方法。该方法利用平行线型激光器在水底生成主动结构信息,利用像素距离与空间距离的映射关系,实现了海生物尺度及深度的快速实时计算,实现了单一CCD在采集海生物单幅图像的基础上进行的种类识别以及尺度与深度测量。最后,本文搭建了基于CCD与平行结构光的海生物实时测量系统,利用Tensor Flow框架将该软件嵌入到轻量化计算机设备中,并进行了水池实验。实验表明:在42ms的采样时间内,实现了识别准确度达89.7%的海生物种类识别;采用平行结构光进行的海生物尺度识别误差在±7%内。本文的研究为海生物自动化捕捞提供了种类识别、尺度与深度的测量方法及测量装置基础,可有效应用于海参、海胆、海星及扇贝的自动化捕捞设备中。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2022.000384
{DOI}: 10.27273/d.cnki.gsajc.2022.000384
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 无人驾驶视觉环境感知目标检测与分割技术研究
{Author}: 黄篷迟
{Tertiary Author}: 朱勇建;秦国锋
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 无人驾驶;深度学习;目标检测;语义分割;多任务
{Abstract}: 随着汽车行业的发展,无人驾驶汽车成为新的研究热点之一。无人驾驶汽车具有辅助驾驶或自主驾驶功能,不仅能给消费者提供更好的驾驶体验,还能提高行车安全性,缓解交通拥堵问题。无人驾驶汽车由环境感知系统、决策系统、控制系统组成,环境感知系统负责收集车辆周围的道路环境信息,因此环境感知系统的性能对于行车安全至关重要。其中视觉环境感知系统是无人驾驶环境感知系统的重要组成部分,因此研究无人驾驶视觉环境感知算法具有重要意义。本文基于深度学习方法,对无人驾驶视觉任务中的目标检测和语义分割算法进行了改进研究,并在此研究的基础上,提出一种多任务网络AMTNet,能同时完成目标检测、可行驶区域分割和车道线检测任务。具体研究内容可概括成以下几个方面:首先,对现有的无人驾驶的目标检测算法进行了一定的研究,并在YOLOv5的基础上,搭建了本文的无人驾驶目标检测网络。对网络中的CSP模块做出了改进,取消其中的一个卷积模块,使用CBS模块替换另一个卷积模块,并调整输出层的顺序,减少了计算量。使用BDD100K数据集对网络进行训练和验证,改进后的网络在13类交通目标的平均检测精度上有所提升。其次,对现有的无人驾驶语义分割算法进行研究和对比,并依据DeepLabv3+的结构设计了本文的无人驾驶语义分割算法。将主干网络替换成更轻量化的MobileNetv2,并加入了辅助损失分支用于优化网络训练。使用Cityscapes数据集对网络进行了训练和验证,实验表明,所改进网络在保证精度的基础上,对检测实时性有较大的提升,因此在精度和实时性上取得了较好的平衡。最后,在前面所研究内容的基础上,提出了一种适用于无人驾驶视觉环境感知的多任务网络AMTNet。使用编码器和解码器结构搭建网络,同时完成目标检测、可行驶区域分割和车道线检测任务,并使用BDD100K数据集对AMTNet网络进行了端到端的训练和验证。由于多任务网络共享几种任务之间的共性,因此网络在三种任务上的性能都有所提升,并提高了网络的实时性。实验表明,AMTNet在性能和实时性上都取得了优异的表现。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.001337
{DOI}: 10.27036/d.cnki.ggxsu.2022.001337
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的室内目标检测与测距系统研究
{Author}: 郭海洲
{Tertiary Author}: 李自立
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目视觉;立体匹配;目标检测;测距
{Abstract}: 获取工作场景周围物体的详细信息是室内服务机器人进行运动规划和完成具体工作的基础,是实现室内服务机器人智能化的关键。对工作环境中物体的类别、位置和距离信息的获取可以让室内服务机器人针对得到的目标信息做出合适的反应。为了使室内服务机器人实现同时获取特定目标的类别、位置和距离信息的功能,本文对双目立体视觉技术与目标检测技术进行深入研究,结合室内服务机器人的工作场景和实际的应用需求,设计并实现了可在嵌入式系统上运行的基于双目视觉的室内目标检测与测距系统。本文的主要工作如下:1.基于摄像头的成像和双目立体视觉测距的原理,结合双目立体视觉测距的需求,选择合适的摄像头标定方法对双目摄像头进行标定,并使用标定得到的双目摄像头参数对双目图像进行立体校正以满足立体匹配算法的使用要求。2.对双目立体匹配算法的应用场景适用性进行研究,分析不同立体匹配算法的优缺点。为了提升立体匹配算法的抗噪声能力,保证在具体应用场景下算法的适用性和测距的准确性,对基于Census变换的立体匹配测距算法进行了有针对性的改进。主要改进在于:优化Census变换计算方法,采用设置阈值的方式选择Census变换的参考值,提升算法的抗噪声能力;在初始匹配代价中融入图像梯度信息,提升立体匹配效果;减少代价聚合路径提升运行效率;优化测距视差的选取,提升测距的可靠性。3.对目标检测算法进行研究,针对室内服务机器人实时检测和测距需求,综合考虑整个目标检测与测距系统的实现难易度和运行效率,本文采取了合适的轻量目标检测算法。从开源的MS COCO数据集中筛选常见室内目标种类制作新的数据集,训练目标检测模型并对模型进行评估。4.整合系统实现获取目标位置和类别的同时获取距离信息,完成嵌入式部署并进行实验分析。通过Open CV调用模型实现目标检测功能,减少在嵌入式设备部署时的环境依赖。模拟室内服务机器人的工作场景,对系统的目标检测效果与测距准确性进行实验验证,并测试系统在嵌入式设备上的运行效率。实验表明,本文设计的系统实现了预定的设计目标,使用制作的数据集训练得到模型m AP为53.8%,在5米内的测距误差小于6%,在嵌入式设备的平均运行速度可达27FPS,满足室内服务机器人在室内场景应用的需求。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.001014
{DOI}: 10.27036/d.cnki.ggxsu.2022.001014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属复杂表面缺陷检测技术
{Author}: 常文娴
{Tertiary Author}: 郭全民;王彤
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像处理;缺陷检测;缺陷分区;纹理抑制;缺陷分类
{Abstract}: 金属复杂表面质量不仅决定金属工件的质量评估,还影响终端产品的性能,因此对金属复杂表面进行检测一直是相关部门的研究重点。目前的金属复杂表面检测方法大多以人工为主,局限性较大,为此需寻求能够代替人工并能在工厂内进行实时检测的新方法,而以图像处理技术为基础的机器视觉技术在工业中的大量应用为此提供了新途径。对此,本文在研究机器视觉技术的基础上提出了金属复杂表面缺陷检测方法,主要内容如下。1)针对金属复杂表面缺陷整体检测速度慢、效率低的问题,研究了基于PCC-CFSFDP聚类的缺陷分区算法。该方法首先利用背景差分和多约束降噪模型确定疑似缺陷的位置,其次通过基于潜在聚类中心的密度峰值聚类算法和区域获取算法合并或分离缺陷,将待处理图像自动分为多个缺陷小区域,最终实现分区的目的。实验表明本文提出的缺陷分区算法能够对图像进行自动分区,在提高速率的同时为进一步检测提供了基础。2)针对金属复杂表面缺陷检测中因背景纹理干扰导致缺陷目标提取准确度低的问题,研究了基于区域纹理抑制及分割的缺陷提取算法。该方法首先通过基于区域特征的纹理抑制算法弱化区域的背景纹理,然后利用缺陷分割及标注算法对抑制后的缺陷图像进行分割和标注,实现对缺陷目标的提取。实验结果表明该算法在弱化背景纹理的基础上有效地解决了传统阈值分割误差大的问题,从而能够准确提取出缺陷目标。3)针对缺陷多分类算法准确率低的问题,研究了一种基于决策树支持向量机的缺陷分类算法。该算法利用图像的几何特性和纹理特性实现对缺陷特征的提取,基于主成分分析法优化特征向量,并构造一种基于决策树的多分类器以完成缺陷的精确分类。实验结果表明,所选择的分类方法可以有效地区分缺陷的三种典型类别,且分类的精度较高,减少了误检和漏检。4)对缺陷检测方法进行实验验证。结合缺陷检测技术指标要求及检测内容,以不同表面的金属工件为样本,通过实验证明检测方法的有效性和普适性。实验结果表明该方法能够实现金属复杂表面缺陷的自动检测,检测准确率达到99.5%以上,达到了零漏检,误检率较低且检测速度较块,各项检测指标均满足实际工业检测的需求。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2022.000436
{DOI}: 10.27391/d.cnki.gxagu.2022.000436
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的目标检测算法与应用研究
{Author}: 张卫良
{Tertiary Author}: 陈秀宏;石小华
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;SSD;RetinaNet;PASCAL VOC;MS COCO
{Abstract}: 随着硬件和理论的快速发展,从传统的基于手工设计特征的方法到现在流行的基于深度学习的目标检测方法,目标检测已发展20多年。自2012年AlexNet提出以来,人们逐渐使用卷积神经网络(CNNs)来处理目标检测任务,基于深度学习的目标检测方法受到广泛关注。它可以分为两类,一是基于锚框(anchor-based)方法,二是无锚框(anchor-free)方法。其中anchor-based算法又可以分为两类,其一是两阶段(two-stage)目标检测算法,其二是一阶段(one-stage)目标检测算法。本文主要针对一阶段目标检测算法SSD和RetinaNet做了改进,具体如下:第一,针对SSD算法不同层特征图没有信息融合和模型感受野的不足,对SSD算法进行改进。从以下方面进行改进:详细阐述了基于SSD的目标检测算法,提出了跨层融合模块和感受野扩增模块,来改善原SSD检测算法在检测精度上的不足。首先,鉴于原SSD模型不同层缺乏信息的交互,以及利用FPN的思想,设计了一种跨层信息交互模块,在增强了不同层的语义信息能力的同时减少了不同层的信息差异。然后,为了提高模型的感受野和多尺度检测能力,设计了一种感受野扩增模块。最后,采用批处理归一化层减少训练时间,提高模型的收敛速度。为了评价提出的ESSD的有效性,在PASCAL VOC2007测试集、PASCAL VOC2012测试集和COCO testdev2017测试集上进行了实验。实验结果表明,在PASCAL VOC2007数据集上其mAP为82.1%且检测速度为15.7FPS,相比于原有的SSD512,其mAP提升了2.3%;在PASCAL VOC2012测试集上其mAP达到80.6%,也比SSD512高2.1%;在COCO test-dev2017测试集上其AP为30.9%,比SSD512高2.1%。实验证明了ESSD检测器在达到较高的检测精度情况下,仍然可以满足实时性。第二,针对原RetinaNet目标检测器没有利用更低层的特征图(如P2层)以及在大型物体上检测效果差的特点,提出了浅层融合模块和全局注意模块。通过使用浅层融合模块,增强了模型的细节信息,提高了RetinaNet模型在小目标上的检测精度。其次,通过在高层(如P5层)后添加全局注意模块,扩大了模型的感受野,也提高了RetinaNet模型在中大型目标上的检测准确度。最后,在公开数据集PASCAL VOC和MS COCO数据集上进行一系列的实验。从实验结果来看,在PASCAL VOC2007测试集上的mAP为82.6%,比原RetinaNet800高3.6%,而且速度只是略微下降(13.8FPS vs 16.8FPS);以ResNet-101为主干网络时,在MS COCO测试集上,改进后RetinaNet模型的AP达到41.7%,在原RetinaNet800基础上提高了2.0%。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000377
{DOI}: 10.27169/d.cnki.gwqgu.2022.000377
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的目标检测方法轻量化研究
{Author}: 杨锦辉
{Tertiary Author}: 刘琼
{Publisher}: 中国科学院大学(中国科学院光电技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;轻量化目标检测;特征融合;感受野
{Abstract}: 在过去的几年里,与传统的计算机视觉算法相比,深度学习在各种计算机视觉应用中已经显示出更优的效果,深度学习模型在准确性和处理时间方面都表现出色,因此基于深度学习的目标检测算法已渐渐超越传统的检测技术,并且随着海量标注图像测试数据集的出现,以及计算硬件的突破,如更强大的GPU(图形处理单元)、CPU(中央处理单元)和更好的计算程序(库和框架),基于深度学习的检测模型在复杂测试数据集上取得了越来越高的准确性。但这些检测模型为了追求高准确精度,网络结构越来越复杂,参数量和计算量过大,难以满足低功耗的嵌入式设备和移动设备的使用,如智能手机,视频实时监控设备等。为了解决该问题,本文从轻量化目标检测模型的网络结构、感受野增强、特征融合等方面展开深入研究,主要研究内容分为以下两个部分:(1)提出了一种感受野增强和卷积轻量化的检测算法(RFBG-YOLO)。针对YOLO系列最新的轻量化目标检测算法YOLOv5s的PANET特征融合中的Bottleneck结构感受野太小,特征提取不足,从而影响了检测精度的问题。本文提出了多分支空洞卷积结构RFB-Bottleneck,来替换PANET的Bottleneck结构,优化后的特征融合方式RFB-PANET,可以通过更少的参数量和计算量获得更大的感受野,这有利于提升轻量化检测模型的检测精度。针对优化后的特征融合方式RFB-PANET虽然提高了检测精度,但结构也变得更加复杂,因此引入了Ghost Conv替换常规卷积,通过减少常规卷积的冗余计算来弥补RFB-PANET推理速度变慢的缺点,提高了检测速度,降低了计算量。(2)RFBG-YOLO算法使用多分支空洞卷积结构RFB-Bottleneck提高了检测精度,但结构更加复杂影响了检测速度,因此本文又提出了一种浅网络和窄通道的多重双向融合轻量化目标检测算法(Multi-TF YOLO),在提升检测准确率的同时,保持较高的推理速度。针对目标检测网络YOLOv3参数量和计算量过大,难以满足低功耗的嵌入式设备和移动设备完成实时检测任务,本文对YOLOv3的网络部分做了压缩,以提升模型的推理速度,大幅减少参数量。针对YOLOv3采用的FPN特征融合获取到的深层特征图的分辨率小,位置信息不足,减弱了大物体的检测能力的问题,本文提出了Multi-TF多重双向特征融合方式,该融合方式增加了自下而上的融合路径,实现了浅层特征图利用深层特征图的位置信息,并且将此双向特征融合方式作为基本特征融合单元在Neck部分多次使用,显著提升了网络的检测精度,并且能够达到与YOLOv5s接近的推理速度。
{URL}: https://link.cnki.net/doi/10.27543/d.cnki.gkgdk.2022.000068
{DOI}: 10.27543/d.cnki.gkgdk.2022.000068
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向机械臂抓取应用的视觉识别与定位技术研究
{Author}: 董阳
{Tertiary Author}: 台立钢;张禹;李志海
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;机械臂;轮廓检测;图像处理
{Abstract}: 随着机器人视觉技术的蓬勃发展,机器人视觉的算法性能逐步提高,视觉硬件成本大幅降低,使得机器人视觉技术被大范围应用到各个行业领域中去了。传统机械臂的离线编程和在线示教方式,已经不能适应现代自动化行业的需要。把机器视觉技术应用到机械臂操作中,便可提高机械臂在工业生产中的自动化、智能化应用程度。本课题针对工业生产中工件形状不规则,难以定位的问题,开展面向机械臂抓取应用的视觉识别与定位技术研究。论文开展的研究工作如下:首先,查阅了大量相关的文献,系统地总结了机器人视觉技术研究现状。对机器人视觉抓取系统进行总体设计,搭建抓取实验平台。详细分析设计了论文的视觉系统标定机理和流程。采用了张正友标定算法对单目工业相机实现了相机内部参数的求解,并分析验证了相机内参标定结果的正确性。分析两种机器人手眼标定方法的原理,优选眼在手外(eye-to-hand)系统模型。推算出相机和机械臂基座之间的位姿变换关系,得到了手眼标定的转换矩阵,通过实验验证并分析标定结果的准确性。使用标准的D-H方法建立了机械臂连杆参数与连杆坐标系,并进行了六自由度协作机械臂的正逆运动学分析,方便后续编程控制机械臂运动。其次,使用中值滤波滤除图像噪点,利用最大类间方差算法自动计算图像阈值,完成图像的二值化分割。论文改进了Canny边缘检测算法,检测后的目标图像边缘杂点较少,能够去除一些伪边缘,并且目标图像边缘也更加连续。改进后的边缘检测算法提高了边缘检测的准确度。检测到目标工件轮廓后,利用Hough投影法寻找目标轮廓的主轴,建立目标工件的最小外接矩形,实现对目标工件的识别,并确定目标图像位置。最后,将目标工件的图像坐标变换为实际机械臂运动的位置坐标。把抓取信息传输到ROS(机器人操作系统)中,在Move It平台下通过程序控制机械臂到达指定抓取位置,完成工件的抓取操作。从抓取实验数据的误差中可知,抓取的位置误差结果不超过2mm,工件的偏转角度误差不超过2°。所以本课题图像处理算法的误差较小,能够完成对不规则形状的工件定位,具有实际工程的应用价值。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000884
{DOI}: 10.27322/d.cnki.gsgyu.2022.000884
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: AGV导航系统中视觉SLAM定位与建图方法的设计与实现
{Author}: 韩玉虎
{Tertiary Author}: 郑飂默;李伦兴
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: SLAM;计算机视觉;定位与建图;特征匹配;AGV
{Abstract}: 当前正是中国由制造业大国向制造业强国转向的关键时期,需要不断的提高制造业的智能化水平,AGV是智能制造的重要工具,可以极大的提高生产和生活效率,降低工业成本,具有非常重要的研究价值。在很多产品的工业生产过程中,需要频繁地进行物料运输,相比于使用人工运输的方式,使用AGV可以提高物料运输的效率并降低成本。AGV经过多年的发展,在各个行业也得到了广泛的应用,其导航系统也由最传统的固定轨道导航演变为电磁导航和激光导航,但考虑到灵活性以及成本等因素,电磁导航和激光导航依然不是最佳的导航方法。近几年随着深度学习的出现,学术界对于计算机视觉技术研究火热,同时带动了视觉SLAM技术的快速发展,也出现了许多经典的视觉SLAM方案。为了更好的发挥AGV的灵活性和自主性,本文基于经典的SLAM的技术方案开展用于AGV导航系统的视觉SLAM定位和建图方法的设计和实现工作,提出了一种基于特征点法和光流法融合的定位方案。该方案可以有效的避免特征点的误匹配,为后续的位姿估计、后端优化以及稠密建图奠定了良好的数据基础。此外,鉴于AGV导航对于稠密地图的需求,本文提出了一种基于极线匹配的稠密建图方案,首先利用双目相机进行极线匹配构建初始局部地图,然后利用前后多帧进行深度滤波以使得地图点的位置收敛于可接受的状态值,最后通过点云滤波进行点云的下采样和外点的去除并通过相对位姿变换关系实现局部稠密地图到全局地图的融合工作。针对提出的SLAM定位和建图方案,本文采用模块化的方法对其进行实现,通过在KITTI数据集和本地进行实验,证明了本文所提出的用于AGV导航系统的视觉SLAM定位和建图方法的可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000038
{DOI}: 10.27587/d.cnki.gksjs.2022.000038
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进的U-Net模型的医学图像语义分割方法研究
{Author}: 邵硕
{Tertiary Author}: 葛洪伟;秦如清
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;编解码结构;注意力机制;医学图像分割;聚合连接
{Abstract}: 图像分割是计算机视觉领域的重要研究分支,随着人们对健康水平的愈加关注,医学影像分割成为了图像分割的热门研究方向。面对多样的医学成像技术,传统的专家人工诊断的方式耗费大量的人力物力但效果有限,开发出计算机辅助诊断系统帮助临床预防、诊断、分割潜在病灶显得尤为重要。传统的图像分割方法大多基于先验规则,例如形状、纹理、边界等,其应用在复杂的医学图像分割任务时得到的结果难以令人满意。随着深度学习的不断发展,诸多深度学习方法被提出用来执行医学图像分割任务。对比传统的分割方法,深度学习方法在应对医学图像目标模糊、尺度变化等问题时,取得了令人满意的效果。为了更好地解决医学图像语义分割面临的多尺度变化、噪声干扰、结果粗糙等问题,本文立足于经典的编解码网络结构,提出了可行的模型改进方案,取得了更好的分割性能和鲁棒性。本文主要工作归纳如下:1)为了解决医学图像分割面临的预测结果粗糙、特征表示能力差的问题,本文研究了一种结合编解码网络与注意力机制的分割结构。首先,引入U-Net网络结构,既利用编码器阶段下采样操作提取目标高级语义特征,又在解码器阶段通过上采样和跳跃连接恢复高分辨率分割细节。其次,引入了卷积块注意力模块,相应从通道与空间维度使用注意力机制,重点关注对分割结果贡献度大的通道和特征密集的空间区域,过滤掉分割背景和噪声干扰。最后,提出一种结合编解码网络和注意力机制的分割模型,从通道和空间维度优化中间特征图,获得更准确细致的分割结果。在四个医学图像数据集上的实验结果显示,本模型相较于基准模型U-Net及其衍生网络获得了更准确的分割效果,具有更强大的特征表示能力。2)为了解决医学图像分割面临的多尺度变换问题和空间信息不充分利用问题,本文提出了结合聚合连接和注意力机制的多尺度分割模型。首先,采用聚合连接策略,虽然编解码结构使用跳跃连接帮助恢复高分辨率细节,但编解码器对应阶段的图像可能存在语义鸿沟。聚合连接可以弥合语义鸿沟,融合不同尺度和深度的特征信息,利于恢复预测细节。其次,使用多通道卷积模块,将带有残差连接的串联卷积结构拓展为多通道并联结构,多通道间互为补充,提供不同空间信息,帮助模型在多目标或者多尺度情况下保持分割准确性。最后,在编解码结构中融合聚合连接、多通道模块和注意力机制,提出改进模型。在四个医学图像数据集上与多个前沿分割网络进行对比试验,实验结果表明应对多尺度变化和噪声干扰等问题,提出的分割模型具有更好的分割性能和稳定性。3)为了解决CNN模型有限感受野导致的固有局限性问题,克服CNN模型建立长距离依赖能力差的缺点,本文提出一种结合Transformer和CNN的编解码分割模型。首先,使用CNN-Transformer混合的编码器结构,既利用CNN提取语义特征和恢复高分辨率细节的能力,又利用Transformer自注意力机制方便建立长距离依赖的优势。其次,引入了卷积块注意力模块,从通道和空间两个维度优化中间特征映射。最后,提出结合Transformer和CNN的分割模型,模型遵循编解码结构设计,使用CNN-Transformer混合编码器,融合卷积块注意力模块帮助分割。在Synapse多器官分割数据集上做出的对比实验证明了提出模型的有效性,结合Transformer和CNN的编解码模型能够获得准确的医学图像分割结果。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000359
{DOI}: 10.27169/d.cnki.gwqgu.2022.000359
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的大尺寸工件圆孔测量系统的研究与设计
{Author}: 黄南海
{Tertiary Author}: 汪志成;丁香乾
{Publisher}: 东华理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;大尺寸工件;尺寸测量;图像处理
{Abstract}: 现代制造业中,大尺寸工件由于幅面广、尺寸长、表面结构复杂,导致对大尺寸工件加工表面缺陷、尺寸等的自动检测面临困难,难以满足生产线全自动化的要求,尤其是对大尺寸工件上存在的圆、弧几何特征的尺寸高精度自动测量问题尚未有好的解决手段。本文以3C产品外壳工件为研究对象,搭建了一种基于机器视觉的大尺寸工件图像采集硬件平台,提出了两种大尺寸3C外壳工件上螺纹圆孔的在线尺寸测量方法,实现了大尺寸3C产品外壳工件的螺纹圆孔位置尺寸和孔径尺寸测量。论文主要工作包括:(1)提出了基于改进Canny边缘检测的Zernike矩亚像素边缘检测方法,建立对于大尺寸工件表面几何特征的尺寸测量的参考坐标系,实现对工件轮廓的准确定位,在改进Canny检测的粗边缘定位基础上可以避免Zernike矩全局积分导致的宏大计算量,提升检测速度的同时实现0.1-0.3pixel的边缘检测精度;(2)针对3C产品外壳工件采用角点定位的螺纹圆孔加工的特点,以及线阵相机采集子图像的连续性,提出一种基于直线特征和圆特征定位的螺纹圆孔位置尺寸测量方法,通过改进的Hough圆检测方法进行圆孔特征定位,实现螺纹圆孔的圆心坐标提取及直径尺寸测量,基于图像的连续性,采用子图像逐一检测,相邻子图像起始像素累加的方式,实现大尺寸工件图像螺纹圆孔尺寸全局检测。该方法最终实现大尺寸3C外壳工件螺纹圆孔的位置尺寸测量精度为±0.2220mm和孔径大小测量精度±0.0904mm,且单工件检测效率为33.737s;(3)基于研究(2)提出一种基于圆孔先验位置关系定位的工件螺孔尺寸测量方法,该方法基于图纸尺寸预先定位螺纹圆孔的位置,将工件全景图像分解为感兴趣区域进行尺寸信息检测。该方法解决了高精度圆检测法需要对高分辨率图像边缘信息全局检索映射导致系统内存泄漏、处理速度缓慢的问题,实现了3C产品外壳工件的螺纹圆孔位置尺寸测量精度为±0.1472mm,螺纹圆孔直径尺寸精度为±0.0690mm,且单工件检测效率为77.628s。
{URL}: https://link.cnki.net/doi/10.27145/d.cnki.ghddc.2022.000164
{DOI}: 10.27145/d.cnki.ghddc.2022.000164
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的目标检测与6D位姿估计算法研究
{Author}: 王晨露
{Tertiary Author}: 陈立家
{Publisher}: 河南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;YOLOv5算法;目标检测;6D位姿估计;点云模型
{Abstract}: 随着经济的快速发展,我国对工业化、自动化以及智能制造的技术水平提出了更高要求。智能制造旨在将工业化和自动化技术相互融合,这也是未来智能制造业发展与变革的重要方向。机器视觉是移动机器人平台十分关键的技术,代表着机器人智能化、自动化及先进性的判定标准。检测物体及其6D位姿(3D位置和方向)是许多机器人应用系统中的重要任务,包括物体的拾取操作,工厂零件装配等。在复杂环境中,机器视觉一般包括两个阶段:第一阶段是目标检测,在RGB图片中使用目标检测算法或者分割网络获取目标类别;第二阶段是6D位姿估计,对检测出来的物体进行6D位姿估计。本文首先介绍了目标检测与6D位姿估计的研究现状,并着重对YOLOv5目标检测算法进行详细的阐述,然后以目标检测、6D位姿估计这两方面为切入点,设计了一个基于YOLOv5算法的目标检测与6D位姿估计的动态检测系统,本文的主要贡献如下:针对YOLOv5算法对目标物体及局部特征定位不准确的问题,提出了一个基于YOLOv5的YOLOv5-CBE目标检测网络。首先为了得到准确的定位信息,本文将卷积注意力机制(Convolutional Block Attention Module)中的空间注意力机制(Spatial Attention)与坐标注意力机制(Coordinate Attention Module)相结合,提出了一个融合空间特征信息与坐标信息的空间-坐标注意力机制(Spatial and Coordinate Attention Module),在YOLOv5的Backbone网络中加入空间-坐标注意力模块,在Neck检测层引入加权双向特征金字塔网络(Bidirectional Feature Pyramid Network),并对锚框参数进行优化,提高了网络对样本模型及局部特征的检测精度及定位能力,分别用改进前后的算法对自定义数据集和PASCAL VOC 2012数据集进行训练,实验结果表明,改进后的算法性能要优于YOLOv5算法,在识别精度没有降低的前提下,对目标物体的定位更加准确,鲁棒性更好。针对目前6D位姿估计算法中对遮挡物体的6D位姿估计精确度不高的问题,提出了一个局部特征表征的端到端6D位姿估计算法。选择3D Harris关键点提取算法提取点云模型中具有显著特征的关键点,然后根据这些关键点对样本模型的对应位置的特征进行标注并编码,使点云模型的关键点与特征的中心点对应,再用YOLOv5算法以及改进后的YOLOv5-CBE算法分别对局部特征数据集训练,实验结果表明,局部特征中心点坐标误差较改进前最高提升了25%。然后用奇异值分解法(Singular Value Decomposition)计算出样本模型相对点云模型的旋转矩阵R和平移矩阵T,也就是样本模型的6D位姿。本文提出的算法实现了在复杂背景下对单目标物体、多目标物体准确的6D位姿估计,并且在最高遮挡70%的情况下,仍然可以保证二维重投影精度(2D reprojection Accuracy)和ADD度量精度(ADD Accuracy)在95%以上,具有较强的鲁棒性。另外该算法在RTX3050显卡上帧率达到35FPS,实时性很好。
{URL}: https://link.cnki.net/doi/10.27114/d.cnki.ghnau.2022.001039
{DOI}: 10.27114/d.cnki.ghnau.2022.001039
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属表面缺陷检测的设计与研究
{Author}: 邵先鑫
{Tertiary Author}: 夏筱筠
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像增强;YOLOv3;K-Means++;空间金字塔池化
{Abstract}: 随着人工智能相关产业进入发展的快车道,金属制造业仍采用着人工眼检的目标缺陷检测方式进行金属刚材的缺陷检测。这种传统目标缺陷检测方式存在着生产成本高、劳动强度大、误检率高和准确性差等弊端。为解决上述企业生产过程中的产品表面缺陷检测问题、降低人力成本,同时提高检测精度。论文提出通过改进YOLOv3算法模型的方法,来提高金属表面缺陷检测准确率,算法模型以YOLOv3算法模型中的Dark Net-53网络结构作为算法模型的骨干网络结构,通过在神经网络中增加特征图层的方式,提高算法模型对图像中目标的特征提取力度,并且在神经网络中引入空间金字塔池化模块结构来替换特征金字塔网络结构规范化各类缺陷的尺寸大小,减少模型训练的时间和提高对图像中小目标和堆叠小目标的检测精度。同时采用K-Means++聚类算法来等方式来提高神经网络的收敛速度。使用开源数据集训练模型,在经过YOLOv2、SSD、YOLOv3等常见算法模型训练结果对比之后,证明改进后的算法模型在检测准确率上有一定的提升,同时不会大幅度影响算法模型的检测速度,其m AP为模型效果75.76%,检测速度为每秒检测31张。最后,设计并利用现用车间硬件设备搭建起金属表面检测系统的自动化检测装置,并且在实际生产线中测试,希望帮助工厂职员减轻工作压力,同时降低生产成本。本文的主要研究内容如下:(1)首先,考虑到工厂车间内部环境复杂,空气中粉尘颗粒和照明环境差等因素导致图像的成像效果不佳,对缺陷检测的准确率产生不良影响。为解决这一问题,论文中采用在密闭灯箱内进行拍照,降低环境因素的图像成像的影响,然后进行图像处理,尝试使用灰度变换和邻域去噪等方式进行实验,来对减少图像中的噪声。(2)其次,考虑到图像中可能存在着更小目标物体,在这种实际的场景下,论文选择在YOLOv3算法模型的输出层上,增加网络结构中的特征尺度的方式,以此提升算法模型对于目标特征的特征提取能力。(3)最后,为了解决图像中出现小目标物体被遮挡的问题,算法模型采用了空间金字塔池化模块,对图像进行浅层特征和深层特征的提取,提高模型对于图像中产生的堆叠目标的特征提取能力,达到提升算法模型对于目标的检测精度。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000018
{DOI}: 10.27587/d.cnki.gksjs.2022.000018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉算法的武汉湖泊公园景观意象特征及感知偏好研究
{Author}: 马薛骑
{Tertiary Author}: 裘鸿菲
{Publisher}: 华中农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 湖泊公园;社交媒体图片;计算机视觉算法;景观意象;感知偏好;武汉市
{Abstract}: 湖泊公园作为城市典型的蓝绿空间,提供着重要的生态调节服务与景观游憩服务,具有多种环境及社会效益,对改善城市游憩环境、提高人类福祉和公共健康大有裨益。然而在城市水资源危机和快速城市化的背景下,湖泊的生态环境遭到破坏,影响了城市人居环境的健康可持续发展,因此保护和改善城市湖泊资源,促进湖泊公园景观质量提升,已经成为城市建设亟待解决的课题。从公众感知偏好视角挖掘景观特质,揭示景观视觉要素对游人潜在情感倾向的影响机制,有助于创造真正“以人为本”的景观,满足人们对高品质人居环境的需求。本研究以武汉市中心城区的已建成的20处湖泊公园为研究对象,利用多种计算机视觉算法对来自社交媒体的35631张景观图片进行参数化分析,提取和量化图片中的景观特征,包括图像分类与内容识别、图像语义分割与图像色彩量化三大板块:(1)利用Google Cloud Vision算法,通过数据准备、图像标签分析、人工标签添加、模型训练、模型效度评估和批量预测这六个模块,构建景观要素分类、空间尺度分类和景观元素识别Auto ML模型,分析湖泊公园的景观类型、空间尺度与景观元素。(2)通过DeepLab v3+算法分割图像内容,得到绿视率、天空可见度和建筑可见度三项指标。(3)利用OpenCV和K-means聚类算法提取图像的主色彩及其HSV特征值,实现图像的色彩聚类与量化。基于图像参数化处理提取的景观特征归纳景观意象的三大维度:景观构成、景观占比和景观色彩,构建基于公众感知的多维度景观意象量化测度框架。通过多种数理统计方法和空间分析法定量化分析景观意象的感知共性与感知特性,探讨公众的偏好取向以及影响感知偏好差异的原因,揭示湖泊公园景观意象的时空变化规律。本研究得到的主要结论如下:(1)景观构成维度:在景观类型层面,湖泊公园中自然景观的感知显著高于人文景观,其中水体景观、林木景观和历史文化是湖泊公园的核心景观类型;在空间尺度层面,公众对不同尺度(宏中微)的景观不存在显著的偏好差异,且人们更偏好于大尺度空间广阔深远的自然景观和小尺度精细化设计的人文景观;在景观元素层面,常绿树、湖泊、草地、背景建筑群和倒影是湖泊公园的代表景观元素,且公众对不同公园景观的感知偏好差异较大,其中代表公园特色的特异性景观更容易得到人们的高度感知,表明了景观特质挖掘与差异化景观建设的重要性。除此之外,人们在不同季节中对各景观类型和景观元素的的偏好也存在一定的差异。(2)景观占比维度:湖泊公园的平均绿视率(GVI)、天空可见度(SVI)和建筑可见度(BVI)分别为0.3597、0.1863和0.0741,整体来看公众更偏好于中等绿视率(0.3<GVI<0.5)、中等空间开敞度(0.10<SVI<0.25)和较低建筑可见度(0.01<BVI<0.1)的景观,除此之外,人们对不同景观类型和空间尺度的景观占比具有不同的偏好特征。(3)景观色彩维度:人文景观的色彩相较于自然景观更加多样化,组内差异更大。整体来看,湖泊公园景观的主导色相为蓝绿色,并呈现低饱和度、中亮度的色彩特征,从色彩心理学的角度看,在湖泊公园中人们更偏好于色彩柔和的、低视觉刺激的、能够让人心情平静、舒缓放松的景观。总体来看,人们偏好的湖泊公园景观意象呈现出自然性与历史性相结合、同质性与异质性相共存、视觉元素配比合理、时空变化规律显著、色彩视觉效果多样的特征。根据以上研究结果,本研究从保持自然本真性、重视历史底蕴、增加景观旷奥变化、挖掘景观特质、优化景观视觉元素和合理设计景观色彩方面为湖泊公园的景观视觉质量提升提出了建议。本研究丰富了景观偏好的分析方法与内容框架,为以大数据图片实现感知偏好分析的相关研究提供了新的方法思路与技术支持,对指导湖泊公园和城市景观的建设具有理论与实践应用价值。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2022.000323
{DOI}: 10.27158/d.cnki.ghznu.2022.000323
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的驾驶员疲劳监测系统设计
{Author}: 刘钰发
{Tertiary Author}: 郭显久
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 疲劳监测;YOLOv5;Res2Net;网络轻量化;Jetson Nano
{Abstract}: 汽车作为现代交通运输工具的重要组成部分,在方便人们日常出行的同时,也带来了交通事故。其中,每年由于疲劳驾驶造成的事故大约占车祸数量的21%,因此,设计一种对驾驶员的疲劳驾驶状态进行预警的监测系统是很有社会意义的。本文通过分析驾驶员的驾驶行为特征来设计驾驶员疲劳监测系统,该系统是基于改进的深度学习下的YOLOv5目标检测算法,本文使用Res2Net结构替换YOLOv5原网络结构中的残差组件,使模型主干网络具备更强的目标特征提取能力,以提高检测的准确度;分析数据集的样本基本为小尺度目标,故对YOLOv5原结构的预测头部分进行剪枝操作,剔除大目标和中目标,使网络轻量化,以提高系统在边缘计算设备部署时的实时检测速度。同时,本文以NVIDIA Jetson Nano为开发平台,开发了一款驾驶员疲劳监测系统,该系统通过Intel Real Sense D435i摄像头捕获驾驶人员脸部图像,在系统判定驾驶员具有疲劳驾驶行为时,系统通过可视化界面直观地显示监测系统的相关信息,并通过蜂鸣器进行预警,为驾驶员安全驾驶提供帮助。本文设计的检测模型在公开数据集NTHU-DDD和自建数据集进行了对比测试,利用精确度、准确率和召回率作为测试评估指标。经过对比实验,改进后的检测框架表现出了很好性能,相比于改进前的网络结构,精确度提升了1.2%,准确率提升了1%,召回率提升了1.1%,并且m AP@0.5由97.9%提升到了98.3%,模型的计算量降低了25%,参数量减少了14%。利用该算法开发的驾驶员疲劳监测系统进行车载实验验证,当驾驶员出现闭眼频率增加、打哈欠次数增加的疲劳驾驶行为时,系统能够及时的检测到并对驾驶员做出预警,同时监测信息也能同步显示在系统的可视化界面。通过实验表明,本文所设计和开发的系统运行平稳,具有较高的准确性、鲁棒性和实时性。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2022.000213
{DOI}: 10.27821/d.cnki.gdlhy.2022.000213
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 无人驾驶汽车视觉导航方法的研究
{Author}: 王子豪
{Tertiary Author}: 李向军
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 无人驾驶汽车;视觉导航;车道线检测;动态目标检测;DeepLabv3+;YOLOv5
{Abstract}: 无人驾驶汽车是如今世界汽车领域研究的热点和前沿,其将环境感知、路径规划、辅助驾驶等融为一体构造一个综合智能系统。无人驾驶汽车的出现,在一定程度上改善了交通效率、提高了行驶的安全性、解放人的双手。无人驾驶汽车应具有独立完成任务的能力,自主导航技术是其重中之重,而且环境感知是其最关键,最基本的问题。所谓环境感知即无人驾驶汽车利用雷达、激光、相机等传感器感知周围环境,其中利用相机进行环境感知完成自主导航即为无人驾驶汽车的视觉导航方法。本文利用计算机视觉技术和深度学习算法处理视觉感知的环境数据,展开无人驾驶汽车的视觉导航方法的研究,主要研究内容如下:(1)针对目前车道线检测算法的鲁棒性不强,容易受环境因素影响,提出一种基于改进DeepLabv3+的车道线检测算法,将车道线检测任务变成语义分割二分类任务,实现对车道线的检测。针对车道线细长且分布不均的特点,对DeepLabv3+模型进行优化,增加了特征金字塔网络,将ASPP模型进行通道拼接,有效的提升了模型对车道线边缘部分的检测效果,恢复DeepLabv3+采样时丢失的细节信息;最后引入注意力机制,使模型有针对性训练有效特征信息。改进后的DeepLabv3+模型在Tu Simple数据集的m IOU为77.02%,具有良好的准确性。(2)根据BDD100k数据集结合实际情况对无人驾驶汽车视觉导航场景的分析,提出了一种改进YOLOv5m的动态目标检测方法。首先,将其预测层由三个增加到五个,增强对不同尺寸的检测能力;其次,引入BiFPN结构,使特征信息融合更加丰富高效;最后,加入Soft-NMS非极大值抑制方法,解决场景复杂易出现遮挡而导致缺检漏检的情况。改进后的模型在BDD100k数据集上mAP指标由69.2%变为73.4%,虽然FPS降到67,但仍满足实时要求。(3)对改进DeepLabv3+输出的二值化图片进行形态学处理和车道线拟合操作,使其为车道偏离预警、车道保持提供基础,并建立一个多任务融合检测模型,同时检测车道线和动态目标。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2022.000076
{DOI}: 10.27821/d.cnki.gdlhy.2022.000076
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于网络摄像机的桥梁挠度非接触识别
{Author}: 朱前坤;崔德鹏;杜永峰
{Author Address}: 兰州理工大学防震减灾研究所;兰州理工大学甘肃省减震隔震国际合作研究基地;
{Journal}: 工程力学
{Year}: 2022
{Volume}: 39
{Issue}: 06
{Pages}: 146-155
{Keywords}: 计算机视觉;实时监测;桥梁挠度;非接触;HSV
{Abstract}: 针对传统的桥梁挠度识别系统可达性差、效率低、不能全天候实时监测，建立了一种基于网络摄像机的桥梁挠度非接触识别系统。系统采用LED光源作为标志物，以网络摄像机作为采集设备，通过无线传输图像信息，利用计算机搭载基于HSV的快速模板匹配和基于颜色追踪(cvCamShift)的几何匹配算法获取目标的挠度时程信息，进而实现对桥梁挠度的非接触识别。通过在人行桥模型上进行四种工况的振动试验以及现场实桥测试，以此验证系统的可行性。研究结果表明：在模型试验中，系统识别得到的时域和频域信息与激光位移传感器对比的误差都小于0.6%，在雾气干扰下识别的误差仍可小于0.7%；实桥测试下，系统的识别结果与桥梁挠度仪对比的误差小于1.9%。由此表明系统鲁棒性强且经济性好，具备广泛的应用前景。
{ISBN/ISSN}: 1000-4750
{Notes}: 11-2595/O3
{URL}: https://link.cnki.net/urlid/11.2595.O3.20220527.1700.026
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视觉目标跟踪算法研究
{Author}: 张大伟
{Tertiary Author}: 郑忠龙;张笑钦
{Publisher}: 浙江师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标跟踪;深度学习;孪生网络;视觉注意力;相似度匹配;不确定性估计;深度强化学习
{Abstract}: 视觉目标跟踪是计算机视觉领域中最为重要的研究课题之一,在视频监控、自动驾驶、智能交通、人机交互以及军事侦察等领域都有着非常广泛的应用价值。它要处理的问题是在视频序列中连续地估计出感兴趣物体的位置和尺度信息,从而服务于高层次的视频分析与理解。尽管目标跟踪已经取得了长足的进展,但是复杂多变的实际场景中存在着光照变化、遮挡、快速运动、形变、尺度变化以及背景杂波等一系列问题,这些动态不确定因素使得实现高精度且鲁棒的视觉跟踪仍然是一个巨大的挑战。近年来,随着深度学习的快速发展,其在目标跟踪领域也得到了很好的应用和发展。同时得益于海量的视频数据和计算机软硬件运算能力的不断提高,使得数据驱动的深度学习跟踪算法展现了显著的性能优势。因此,本论文在详细分析现有基于深度学习目标跟踪理论及方法的基础上,从有效的表征学习、鲁棒的相似度匹配、准确的目标框预测以及高效的运动估计四个角度进行深入研究,主要研究内容和创新如下:1)针对深度学习跟踪模型中浅层特征表示能力不足而深层特征计算开销大这一问题,提出了一种视觉注意力引导的残差学习目标跟踪算法(CSART)。该方法首先研究不同主干网络提取的视觉特征对于跟踪精度和效率的影响。其次使用自注意力模块分别在空间和通道维度捕获基特征的长距离语义依赖关系,从而获得两个富含上下文信息的注意力特征图。然后,利用残差学习的思想将其与原始特征进行自适应融合,以更有效地学习前景和背景的判别性表示。此外,还设计了一个多任务损失函数来端到端地联合优化整个表观模型,同时也缓解样本的不平衡问题。大量的实验结果表明,所提算法在基本没有降低跟踪速度的情况下,显著提高了原始模型的精准度和鲁棒性。2)基于孪生网络的跟踪算法一般采用简单的互相关操作来执行模板特征与搜索区域特征之间的相似度匹配,这种固定且线性的度量方法难以处理混乱的背景噪声问题,限制了模型的判别力。本文提出了一种基于孪生关系网络(Siamese Relation Networks)的鲁棒跟踪框架,利用关系网络建模了一种非线性可学习的相似性函数。它可以很好地集成到现有的孪生网络跟踪模型中,从而实现了由粗到细的两阶段匹配过程。推理期间,提出了一种基于双模板匹配的在线跟踪策略,保持初始帧模板,并利用高置信度跟踪结果的反馈来获取和更新动态模板,进一步提高了模型的鲁棒性和在线自适应性。实验结果表明,该跟踪算法能够很好地应对目标外观变化、背景噪声等难题。3)针对现有无锚框跟踪器分类与回归任务的不一致性以及预测框不够准确问题,提出了一种具有不确定性感知的孪生网络跟踪算法(UAST)。该方法主要探讨物体边界框的不确定性和模糊性表示,首先利用回归向量直接建模目标框四个偏移量的离散概率分布,并通过计算各个分布的积分以捕获更为灵活且信息丰富的边界框表示。其次基于预测值近邻的概率可以估计出每个边界的确定性分数,从而实现跟踪的不确定性估计。同时,考虑到不确定性与回归精度的高度相关性,构建了一个联合的分类-定位质量表示头,解决了分类与回归任务的不对齐问题,并开发动态标签分配实现了高质量的目标跟踪。在五个公开视频跟踪数据集上的测评结果表明,UAST算法优于所对比的多个先进的跟踪模型,并且该不确定性跟踪能够更可靠地用于实际视觉系统。4)考虑到目前基于分类的深度跟踪器搜索效率低下且网络参数在线更新耗时长等局限性,提出了一种基于分层深度强化学习的视觉目标跟踪模型。该工作重新定义了目标跟踪的问题建模,即研究如何教会机器模仿人类的行为范式(若干次动态迭代搜索)来执行跟踪任务。具体地,构建了特征观测网络,策略网络和演员评论家网络,以及用于建模物体运动时序信息的长短时记忆模块,并遵循马尔科夫决策过程通过深度强化学习算法学习有关跟踪模式和运动估计的层次化决策。为提高在线跟踪效率,还引入专家跟踪器来引导模型的更新和重新初始化过程。广泛的实验结果表明,提出的模型在多种挑战属性下获得了较好的跟踪结果,并且在鲁棒性与准确率方面表现良好。
{URL}: https://link.cnki.net/doi/10.27464/d.cnki.gzsfu.2022.000543
{DOI}: 10.27464/d.cnki.gzsfu.2022.000543
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度神经网络的医学图像特征学习与分析
{Author}: 梁爽
{Tertiary Author}: 张维存
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度神经网络;医学图像分析;计算机辅助诊断;计算机视觉
{Abstract}: 医学图像分析是综合医学影像、数学建模、人工智能等多技术的交叉研究领域,具有数字图像处理、特征分析、评估决策等关键过程,尤其是特征分析结果的优劣影响了分析方法的性能。传统的医学图像分析方法多依赖手工特征工程技术,需要专家针对特定医学任务,结合其先验知识,花费大量时间和精力手工设计特征,这种人工针对特定场景显式设计的特征往往通用性欠佳,而且其特征表示的充分性和精细性也在一定程度上受限。当前医学图像分析中的特征处理方法的主流研究方向开始从特征设计转向特征学习。由于以深度神经网络为代表的深度学习方法具备直接从医学图像中隐式的自动进行特征学习的优点,因此逐渐在多种医学图像分析任务中被应用,并取得了一定的成绩。本文针对医学图像复杂性且缺少简单线性特征的特点、医学图像标注数据获取困难和稀缺的特点、医学图像包含信息丰富但特征提取与学习困难的特点,运用以数据驱动方式为基础的深度神经网络方法,在医学图像的多元特征提取、少样本特征表达、多层级特征融合三个方面开展研究,提出多种基于深度学习的模型框架与对应的解决策略,所提出的方法在公开数据集与临床数据集上得到验证并在医学图像分析的典型应用中进行实践,均取得优异的性能与表现。本文的主要研究内容如下:(1)医学图像多元特征提取方法研究:医学图像包含人体器官组织的信息,其结构形状和分布常呈现出拓扑复杂性的特点,现有的基于深度神经网络的医学图像处理方法往往仅注重图像局部信息或全局信息的单一描述,导致在复杂场景下模型识别能力弱。为了增强特征学习方法准确、丰富的特征提取能力,本文提出了基于多尺度卷积神经网络与图卷积神经网络的复合网络框架用于医学图像多元特征的提取;在此基础上,设计了用于肌肉骨骼X射线图像异常检测的疾病辨识模型,并在公开的大规模肌肉骨骼X射线图像数据集(Musculoskeletal Radiographs,MURA)上进行了评估验证:所提出的模型的准确率为91.22%,F1分数和Kappa分数分别为0.909和0.836。结果表明所提出多元特征提取方法可以从复杂性较高的医学图像中获取更准确、精细和全面的特征,提高模型在疾病辨识上的综合性能。(2)少样本条件下的医学图像特征表达方法研究:实际的医学场景中,有良好标注的大规模医学图像数据通常较为稀缺,其数据具有“少样本”的特点,但目前用于医学图像处理与分析的深度学习网络模型多为监督学习方法模型,其训练过程往往过于依赖大规模、高质量的标注数据。针对实际医学场景中医学图像标注数据获取困难、稀缺的问题,为了提高运用深度学习网络框架在少样本条件下的特征表达能力,增强分析模型的综合表现,本文提出了一种基于注意力双分支网络结构的半监督学习框架,可依次从无标注数据中学习底层特征表达来完成框架权重预训练,从少量的有标注数据中充分学习高层特征表达来完成对医学图像的特征学习过程。所提出半监督学习方法和模型在两个公开的脑部核磁共振成像数据集(Kaggle Alzheimer Classification Dataset,KACD)和(RecognitionofAlzheimer Dataset,ROAD)上进行了验证:其分类准确率分别为0.9961和0.9871,不仅优于仅从少量有标注数据中进行学习的有监督学习方法,且相较另外两个先进半监督学习方法(ResNeXt WSL,SimCLR)分别高出2.50%和1.88%。结果表明所提出半监督学习方法用于基于深度神经网络的疾病辨识模型在解决“少样本”场景中的“低精度”问题上有良好的潜力。(3)基于多层级特征融合的医学图像分析方法研究:医学图像中包含底层像素、中层对象、以及高层语义等多种层级的信息,但现有的医学图像特征学习方法往往仅在像素或对象层次进行信息挖掘,却较少关注基于多层级特征融合的医学图像分析。为了提高特征学习方法在医学图像中的多层级特征表示能力,充分与客观的反映医学图像中所包含的丰富信息,本文提出了一种多层级、模块化的卷积神经网络框架,通过引入门控制模块,实现自底向上的多层级特征逐级学习,并在深层级网络中完成不同层级间的特征融合,从而加强框架的多层级特征表示能力。所提出方法和模型在用于COVID-19疾病检测的两个公开胸部X射线图像数据集(Covid-ChestXray Dataset,CCD;Rsna-pneumonia-detection-challenge,RSNA)、两个计算机断层扫描图像数据集(Lung Nodule Analysis 2016,LUNA16;Images of COVID-19 positive and negative pneumonia patients,ICNP)和北京佑安医院临床数据(95例病例)上进行了评估,结果表明所提出方法在COVID-19疾病辨识任务中取得了接近专家医生的评估表现:辨识模型的精确性为98.33%,敏感性为95.16%、特异性为99.33%;在此基础上,本文还构建了基于卷积神经网络的回归框架,表征了医学图像视觉特征与临床指标因子之间的映射关系,为医学图像的准确分析提供了基础,并为医学图像分析方法在临床医学应用中提供了因果推断的支撑。(4)计算机辅助诊断应用研究:计算机辅助诊断是医学图像分析方法的典型应用之一,其对模型精度和推理效率有较高要求。本文在前述研究的基础上,面向实际医学场景应用,基于胸部、腹部计算机断层扫描图像,提出多种复合深度学习网络框架,开展了 COVID-19疾病检测与肾脏癌症图像分割及疾病检测的应用研究。本文设计了一种新的数据重采样方法,结合所提出的复合深度神经网络框架,在COV19-CT-DB数据集上的新冠病毒疾病诊断任务中取得了 88.23%的F1分数,相较于基线方法提高了 18个百分点;基于双分支网络框架构建了多层级模块化的网络模型,采用深度卷积网络与深度自注意力变换网络对腹部计算机断层扫描图像同时进行时空特征提取,在(The 2019 Kidney and Kidney Tumor Segmentation Challenge,KiTs19)数据集上的肾脏癌症分级及肿瘤分割任务上取得了 97.56%的分级准确率和92.54%的分割Dice分数,其分级性能比其他两个先进模型(ResNeXt,ViT)分别高出6.25%和9.38%,其分割性能比其他两个先进模型(Hybrid V-Net,Unet3+)分别高出1.36%和1.80%。结果表明,本文所提出方法具有较强的性能表现和较大的应用潜力。本文所提出方法与网络结构可为智能医疗领域的医学图像分析提供理论支持和应用实践。研究结果具有正向的社会价值和潜在的商业价值,有助于推动深度学习方法在医学图像分析和临床实践中的快速发展和应用。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2022.000220
{DOI}: 10.26945/d.cnki.gbjku.2022.000220
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自动驾驶环境感知中的目标跟踪与轨迹预测研究
{Author}: 陈佳
{Tertiary Author}: 张卫冬
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标跟踪;轨迹预测;注意力机制;自动驾驶;环境感知
{Abstract}: 目标跟踪和轨迹预测作为计算机视觉领域的高级视觉任务,在自动驾驶环境感知中起着举足轻重的作用。目标跟踪按照被跟踪目标数量可分为单目标跟踪和多目标跟踪,而跟踪器设计的精准鲁棒程度直接关系到自动驾驶车辆的行驶安全。轨迹预测即对车辆未来(0～5秒不等)可能行驶轨迹的预测,是自动驾驶决策阶段的前提和基础。近年来,随着“十四五”规划全面推开,以人工智能、自动驾驶、车路协同为特征的交通科技革命持续发力,推动了交通发展由追求速度规模向更加注重质量效益转变。着眼交通科技革命实际需求,本文对自动驾驶环境感知阶段目标跟踪和轨迹预测展开深入研究论证,相关成果具有重要的理论意义和应用价值。本文的研究重点是实现对脆弱道路使用者(Vulnerable Road Users,VRU,多指老人和小孩)的单目标跟踪、多个交通道路参与者的多目标跟踪以及道路智能体轨迹预测三个方向的突破。针对单目标跟踪经常遇到的遮挡、形变和尺度变换等问题提出SiamSC算法和SiamMFC算法;对多目标跟踪过程中遇到的遮挡问题提出了在线多目标跟踪算法DM-Tracker;在智能体轨迹预测中针对视觉信息的缺失,提出了融合视觉信息的DA-LSTM轨迹预测算法,最终为实现自动驾驶环境感知智能系统的构建提供理论支撑。论文主要工作和研究成果如下:(1)针对脆弱道路使用者被跟踪过程中经常出现被遮挡的问题,提出了一种空间特征和通道特征相融合的孪生单目标跟踪算法SiamSC。该算法分为特征提取和区域建议分类回归两部分。在特征提取阶段,为了体现因物体被遮挡而造成的不同位置的重要性,引入空间注意力机制,重点关注未被遮挡部分位置的重要信息;在分类回归阶段,将分类网络中融合后的特征加入通道注意力机制,对不同的通道赋予不同的权重,使得网络可以更好的锁定被跟踪者的主要特征,进而快速精准的定位跟踪。所提出的算法在公共数据集VOT2017中进行验证,其综合评价指标期望平均重叠率(EAO)比基准算法SiamRPN高5.7%。(2)针对视觉单目标跟踪中经常出现的形变和尺度变换等问题,提出了一种基于流形特征的孪生分类回归单目标跟踪算法SiamMFC。常用的目标跟踪算法仅考虑了物体的语义信息而忽略了物体丰富的几何特征。针对上述问题,本算法在网络设计时增加流形模板分支来提取物体的几何信息。同时,在语义分支的特征提取阶段采用计算量少且无需考虑人为因素的锚点设计来提升网络的计算效率;在回归阶段有效融合流形分支中提取的流形特征,对物体位置进行准确的回归。本算法有效提升了物体在形变和尺度变换问题下的跟踪精度,在多个数据集上进行验证性能良好,其中在GOT-10K数据集上的评价指标SR0.75 比基准算法 SiamRPN++高 8.8%。(3)针对多目标跟踪中物体被频繁遮挡后经常出现ID跳变的问题,提出了一种具有可分辨力的在线多目标跟踪算法DM-Tracker。DM-Tracker本质上是一种基于检测的目标跟踪算法。在特征提取阶段,采用多特征融合的骨干网络有效提取被跟踪物体的检测特征,并采用参数量少且计算简单的无锚框检测器,有效提升了检测精度,为后续的精准跟踪提供了高精度的检测结果;在在线跟踪过程中,通过引入具有分辨力的模块,对经过遮挡和交互的目标重新分配不同权重的特征,并重点关注物体未被遮挡部分和此前物体是否为同一 ID,据此指导模型的精准输出。DM-Tracker在MOT公共基准数据集上的准确度(MOTA)和精度(MOTP)指标分别比离线算法TPM高5%和4%。(4)针对轨迹预测过程中交通参与者特别是行人在受到外界社会力因素影响后会发生轨迹改变的现实问题,提出了一种基于双重注意力模型的状态细化LSTM轨迹预测算法DA-LSTM。传统轨迹预测算法仅考虑了轨迹信息而忽略了图片中丰富的场景信息,本算法在设计过程中有效融合场景信息对道路智能体轨迹预测的影响。DA-LSTM首先将场景图像进行特征提取,再送入场景注意力机制模块中,同时历史轨迹信息经过状态细化模块的信息编码后输入到社会注意力模块中提取重要轨迹信息,二者在经过注意力模块后将信息进行有效融合,再将融合后的信息送入到状态细化模块中进行信息的解码以预测未来的轨迹。在实验分析阶段,本算法在滴滴数据集上进行验证,所得结果误差低于基准算法SR-LSTM。本文从不同的视觉感知任务出发,对不同研究对象的视觉跟踪和轨迹预测开展研究,分别提出了具有代表性的SiamSC算法、SiamMFC算法、DM-Tracker算法和DA-LSTM算法,实现了多重挑战性下视觉感知任务跟踪算法和轨迹预测算法性能的提升,为自动驾驶车辆环境感知研究提供了一定的理论与实践基础。同时,相关研究方法还可以在智能巡检、治安巡逻和无人机等领域进行推广应用。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2022.000276
{DOI}: 10.26945/d.cnki.gbjku.2022.000276
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轴承表面缺陷检测系统研究
{Author}: 赵明
{Tertiary Author}: 于大国;肖江剑
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 轴承;机器视觉;图像处理;缺陷检测
{Abstract}: 轴承作为一种机械设备中大量使用的基础零部件,其质量好坏将严重影响设备运行的稳定性。近年来,随着我国制造业的大力发展,各行业对轴承产品的需求量不断增加,同时对轴承外观质量的要求也日益提高,尤其是在轴承进出口贸易中。尽管我国的机械加工技术已经达到较高的水平,但在轴承批量生产中难免产生一定的损伤。目前,企业对于缺陷轴承的分拣工作仍采用人眼检测、手动分拣的方式进行,这种方式不仅存在工作量大、效率低的问题,而且由于工人的分拣标准不同和视觉疲劳,导致分拣结果存在较高的漏检率和误检率。针对上述问题,本文基于机器视觉技术设计了一套轴承表面缺陷检测系统,代替人工目测分拣,实现轴承表面缺陷的自动化检测。论文的主要研究内容和成果如下:(1)为实现轴承表面缺陷的全检,根据轴承表面的缺陷类型和分布位置,设计了一种多工位组合式光源照明方案以完成图像采集工作,并对每个检测工位进行工业相机、光学镜头、视觉光源的选型和照明方式的设计等。(2)根据系统检测需求设计并搭建一套自动化分拣系统,该套硬件系统主要由上料装置、拨料装置、图像采集装置、翻转装置、分拣装置和码料装置组成,整体由PLC负责控制运行。(3)分别对不同的检测工位设计相应的检测算法,包括基于传统图像处理算法的边缘检测、EDCircles圆检测、EDLines直线检测、区域分割提取、Blob分析等方法。此外,本文提出一种基于SFCS-YOLO v3的轴承防尘盖表面的凹坑缺陷检测算法,该算法实现了97.50%的检测准确率,以及提出一种基于两阶段神经网络(Attenitve GAN和AE-WGAN)的轴承图像去油滴算法,该算法可降低93%的轴承表面油滴误检率。(4)本文基于Qt Creator平台开发了一套轴承表面缺陷检测软件,该软件集成了图像采集、图像处理、结果可视化、数据统计和参数配置等功能。最后经测试,本文设计的轴承表面检测系统的检测准确率为95.80%,单个轴承检测时间约为2.14s。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.000316
{DOI}: 10.27470/d.cnki.ghbgc.2022.000316
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的水位检测算法
{Author}: 孙维亚;王达;许帅;汪京晔;马占宇
{Author Address}: 南水北调中线干线工程建设管理局;北京邮电大学人工智能学院;
{Journal}: 应用科学学报
{Year}: 2022
{Volume}: 40
{Issue}: 03
{Pages}: 434-447
{Keywords}: 水尺读数;计算机视觉;边缘特征;关键字处理
{Abstract}: 鉴于传统的水位读数方法误差大，成本高，需要一种精确、实时、鲁棒的智能水位检测算法来高效读取水位，为此提出了一种基于计算机视觉的水位检测算法以满足实际需求。首先对拍摄到的图像进行预处理和边缘检测以找出水尺位置，并通过仿射变换对水尺进行矫正。通过两种策略在水尺区域找到水尺关键字的位置，即关键字处理。然后对边缘特征进行投影并检测出水面位置。最后根据关键字处理结果和边缘特征计算得到水面高度。大量实验和实地测试的结果表明：所提算法在基于计算机视觉的水位检测、水尺读数等领域具有理论和应用的双重价值。
{ISBN/ISSN}: 0255-8297
{Notes}: 31-1404/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzoOuMe2NQhk8xN7tUYtXE156do0dEga98-xjUWJHfn_ZTBL2LjnSjElVI59YsyRernSsPomkhKiOOGyTVz610kJDnVT-QendFKi2vztm-cJ4Fm2R4AgAl0ftBZCDIKpA6Nc2kxU9Q1t3xfuAA-F7QJfulMh32N_bDWJgl0cuSDCiAON12peZ0YVn-P5SiVQm8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视频人体行为识别算法研究
{Author}: 武寒波
{Tertiary Author}: 马昕
{Publisher}: 山东大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 人体行为识别;深度学习;卷积神经网络;注意力机制;时空特征学习
{Abstract}: 视频人体行为识别是计算机视觉领域的研究热点之一,具有十分深远的理论研究意义和广阔的实际应用前景。由于存在人体行为多样性造成的行为类间变化丰富和类内差异明显等问题,以及实际场景中复杂背景环境、视角及光照变化等干扰因素造成的行为时空特征提取不够高效的问题,基于视频的人体行为识别是一个极具挑战性的研究课题。近年来,得益于计算机性能的不断提升和网络上视频数据的爆炸式增长,数据驱动的深度学习技术发展迅速,成为人体行为识别任务的主流实现手段。目前基于深度学习的人体行为识别已经开展了大量研究工作并取得了一定进展,但仍存在以下不足:(1)基于深度卷积网络的行为识别方法倾向于根据场景和目标的外观特征来预测行为,容易受到杂乱背景的影响,且无法主动聚焦视频行为的显著运动区域,从而导致识别性能受限;(2)视频行为识别高度依赖于有效的时空特征学习,而现有的2D深度卷积网络擅长提取视频中丰富的空间信息,缺乏直接建模视频时间结构的能力;(3)3D深度卷积神经网络具有同时学习时空特征的显著优势,但其包含的大量参数增加了模型的复杂性。此外,目前基于3D卷积网络的视频行为识别工作大多依赖于单一数据模态,限制了识别性能。本文针对上述问题展开深入的算法研究,主要研究工作包括:(1)基于层次动态深度投影差值图像表示与卷积神经网络的人体行为识别方法。针对基于2D卷积神经网络(Convolutional Neural Networks,CNN)的行为识别方法需要从视频中分别提取空间和时间特征且时空信息表达不够高效的问题,围绕深度视频行为识别,提出一种高效视频行为表示方法——层次动态深度投影差值图像(Hierarchical Dynamic Depth Projected Difference Images,HDDPDI)。该方法将深度视频序列投影在三个正交的笛卡尔平面内,利用排序池化技术对每个投影平面中行为的时空运动变化进行多时间尺度编码,生成的HDDPDI表示从不同视角及不同时间尺度同时捕获行为的时空信息,能够有效描述深度视频行为的三维运动模式。将三个投影视角的HDDPDI分别输入2D CNN进行时空特征学习,同时基于不同网络层设计了三种多视角信息融合方案来实现行为识别。在三个公共人体行为数据集上的实验结果表明,HDDPDI视频表示包含了丰富的时空运动信息,使CNN能够学习到更加全面的行为特征,且融合多视角信息能够显著提升深度视频行为识别的性能。(2)基于通道与时空兴趣点注意力卷积神经网络的人体行为识别方法。针对CNN缺乏建模视频长时依赖性的能力以及对视频中显著行为运动区域不敏感的问题,提出了通道与时空兴趣点注意力卷积神经网络,同时对行为视频提出了动态图像序列表示,通过时序建模局部短时时空结构来有效表达整个视频的长时时空动态变化。通道与时空兴趣点注意力模型包含通道注意力和时空兴趣点注意力两部分,通道注意力通过自动学习多通道卷积特征为不同通道分配不同的权值,以强化网络中具有辨识力的特征通道;时空兴趣点注意力将从动态图像中检测的时空兴趣点映射在特征图空间来生成空间注意力权值,以聚焦行为显著运动区域。该模型能够被灵活地嵌入到CNN中来增强网络的特征表达能力,长短时记忆网络(Long Short-Term Memory,LSTM)基于强化后的卷积特征建模时间依赖性并进行行为预测。实验结果表明,所提方法充分利用了卷积特征多通道、空间化的特点,能够提取具有辨识力的时空信息,显著提升视频行为识别的性能。(3)基于3D CNN时空多模态学习的人体行为识别方法。针对目前基于3D CNN的行为识别工作大多依赖于单一 RGB数据模态,从而限制了 3D网络性能的现状,提出了一个多模态双流3D网络行为识别框架,探索3D CNN对深度和姿态数据下时空特征的学习能力,并融合不同数据模态的互补信息来提高识别性能。该方法构建了深度残差动态图像序列(Depth Residual Dynamic Image Sequence,DRDIS)和姿态估计图序列(Pose Estimation Map Sequence,PEMS)作为多模态视频行为表达,DRDIS通过一组动态帧来建模行为的显著时空运动模式,PEMS通过一组彩色编码的姿态图像来直观地描述身体姿势的时空演化过程。基于四个行为数据集的实验结果表明,3D CNN能有效学习深度和姿态数据中的时空信息,多模态融合有助于增强视频行为识别的性能。(4)基于多级通道注意力导向时空运动学习的人体行为识别方法。针对现有大多数行为识别方法基于卷积特征学习时空线索,而没有同时考虑特征通道差异性的问题,提出了一个多级通道注意力导向时空运动学习模块(Multi-level Channel Attention Guided Spatio-Temporal Motion Learning,MCA-STML),在通道注意力的引导下有效地捕捉人体行为的时空演化。该模块包含两个阶段:多级通道注意力激活(Multi-level Channel Attention Excitation,MCAE)和时空运动建模(Spatio-Temporal Motion Modeling,STMM)。MCAE基于视频卷积特征生成运动感知的帧级和视频级通道关系。STMM在MCAE的引导下,选择部分运动显著的特征通道沿时间维度捕获双向空间运动动态。MCA-STML模块能够有效且灵活地对时空结构进行建模,并且可以以非常有限的额外计算成本嵌入到许多流行的2D网络中,以增强其时空建模能力。实验结果表明,所提方法能够有效增强网络的时空运动学习能力,取得具有竞争力的行为识别结果。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.000361
{DOI}: 10.27272/d.cnki.gshdu.2022.000361
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向光学测量跨源点云的多尺度采样配准方法
{Author}: 汪千金;崔海华;张益华;权冬;刘贡平;宁莉
{Author Address}: 南京航空航天大学机电学院;中航西安飞机工业集团股份有限公司;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 10
{Pages}: 139-148
{Keywords}: 机器视觉;跨源点云;尺度滑移;点云降采样;点云配准;三维测量
{Abstract}: 为了实现具有不同测量尺度、分辨率与精度等特性的跨源点云的精确配准，提出了基于多尺度采样的测量点云数据配准方法。通过尺度滑移算法来滤除高频细节信息，保留轮廓数据，并结合体素网格邻域法来实现点云数据的降采样；对于宏观结构光视觉测量的低分辨率点云数据，通过基于深度学习的渐进式三维点云上采样算法可以精确还原结构光点云的轮廓细节，实现跨源点云在尺度与分辨率上的统一。最后，采用迭代最近点法对处理后尺度近似的数据进行配准，并将配准关系逆向用于原始跨源点云的配准。实验结果表明，多尺度采样方法对于跨源点云的配准精度有所提高，能有效用于发动机叶片等零部件的高性能检测。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxLDymYvoCqQ_GVyGlXNFYsz6m_5dNJA3KAawBKbqaggc5NbKt4-2e60YmN9tRt_k_TnVNq4BzT8wKRH_vp9hxHqyt4KzscNU7Rl2WcJka5U3EE0k6g2sltVpQDrz8XpZP0KrqXU1bV0wjm-L3AWCsuW6bIKa89X5mWVwp4CiZCWhQYy_E_2AwWsAxA1C_-oc0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv3的纹理瓷砖缺陷检测
{Author}: 李泽辉;陈新度;黄佳生;吴磊;练洋奇
{Author Address}: 广东工业大学广东省计算机集成制造重点实验室;广东工业大学省部共建精密电子制造技术与装备国家重点实验室;科达制造股份有限公司切割技术事业部;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 10
{Pages}: 294-302
{Keywords}: 机器视觉;图像处理;缺陷检测;YOLOv3;自编码器
{Abstract}: 针对目前瓷砖缺陷检测算法主要依赖人工设计特征和分类器，实际应用中存在调试困难、鲁棒性不足的问题，提出一种基于改进YOLOv3的纹理瓷砖缺陷检测算法。首先，在Darknet-53前加入卷积自编码器，将瓷砖的弱缺陷重构图像与原输入融合，得到更丰富的输入信息。然后，利用K-means聚类方法计算新的锚框，以获得更适合的锚框。最后，针对小样本问题，利用在公共数据集上预训练好的权重初始化网络，以提高模型收敛性能。实验结果表明，改进后的模型平均准确率提高了5个百分点，基本保持原模型的预测速度，可以有效检出纹理瓷砖的孔洞及划痕缺陷。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyBQnULCzDUfhXlV4MLQOeMQd_0x2SAtnhVC-L62H-5JOKv_6Wbc0csqPMCz9gfvZ4qZEpDkSH_yVQNwebdnuEQkp-SDtaD4QZ5NND0xP4cbBb2OVpk9TRqaWdNYyWNmNB775ZsWvMtYT_TQhZ9_5VM-xCS89SeCFl8jmo2EUIoyBlo6egfDZrtcLg60oMRVeY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 多尺度卷积神经网络的图像边缘检测
{Author}: 石昌友;孙强;卢建平;夏榕泽;刘锦锋
{Author Address}: 陆军工程大学通信士官学校;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 08
{Pages}: 121-128
{Keywords}: 计算机视觉;卷积神经网络;自注意力集中;多尺度技术
{Abstract}: 在受图像拍摄条件、图像内容自身复杂性、图像内容与背景接近程度等多种因素的影响，图像的边缘线检测容易发生漏检、误检。因模型自身设计缺陷或训练样本中边缘像素点与非边缘像素点的不平衡原因，多数算法的图像边缘检测结果普遍存在线条粗、质量较低的问题。提出一种多尺度卷积神经网络模型，由三个分别接受一幅图像的不同尺度输入的子网络结构组成，分别在不同尺度视觉下学习图像的边缘知识。然后按尺度从粗到细对各尺度提取的知识特征进行融合，实现边缘轮廓检测。模型充分利用多尺度技术在图像处理领域的优势，同时引入了自注意力机制以提升卷积特征内部关联性的捕获能力。本文提出了一个新的损失函数，由交叉熵损失函数和L1范数组成，避免训练样本非均衡性对训练模型的影响。使用指标ODS、OIS、AP度量图像边缘检测的质量。在BIPED数据集上测试，三个指标的得分分别为0.845,0.856,0.886。在BSDS500数据集上测试，算法在F-measure指标上得分为0.826。实验结果表明，与其它学习型的算法相比，算法输出图像边缘结果漏检率更低、且质量更高。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108738
{DOI}: 10.19651/j.cnki.emt.2108738
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像质量评价研究综述——从失真的角度
{Author}: 鄢杰斌;方玉明;刘学林
{Author Address}: 江西财经大学信息管理学院;
{Journal}: 中国图象图形学报
{Year}: 2022
{Volume}: 27
{Issue}: 05
{Pages}: 1430-1466
{Keywords}: 图像质量评价(IQA);图像处理;视觉感知;计算机视觉;机器学习;深度学习
{Abstract}: 随着多媒体技术的快速发展及广泛应用,图像质量评价因其在多媒体处理中的重要作用得到越来越多的关注,其作用包括图像数据筛选、算法参数选择与优化等。根据图像质量评价应用时是否需要参考信息,它可分为全参考图像质量评价、半参考图像质量评价和无参考图像质量评价,前两类分别需要全部参考信息和部分参考信息,而第3类不需要参考信息。无论是全参考、半参考还是无参考图像质量评价,图像失真对图像质量评价的影响均较大,主要体现在图像质量评价数据库构建和图像质量评价模型设计两方面。本文从图像失真的角度,主要概述2011—2021年国内外公开发表的图像质量评价模型,涵盖全参考、半参考和无参考模型。根据图像的失真类型,将图像质量评价模型分为针对合成失真的图像质量评价模型、针对真实失真的图像质量评价模型和针对算法相关失真的图像质量评价模型。其中,合成失真是指人工添加噪声,如高斯噪声和模糊失真,通常呈现均匀分布;真实失真是指在图像的获取中,由于环境、拍摄设备或拍摄操作不当等因素所引入的失真类型。相对合成失真,真实失真更为复杂,可能包括一种或多种失真,数据收集难度更大;算法相关失真是指图像处理算法或计算机视觉算法在处理图像时,由于算法本身的缺陷或性能不足等原因而出现在结果图像中的降质,相对合成失真和真实失真,算法相关失真的显著特点是该类型失真呈现非均匀分布。本文介绍现有的图像质量评价数据库,包括图像数据来源和数据库构建细节等;然后重点介绍图像质量评价模型的设计思想。最后总结了介绍的图像质量评价模型,并指出未来可能的发展方向。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyIFK3BwRzuD5O4Z_-F3325ZiOk_d_npn2ptHnSjcY-EesTstnygqcrktzzs7Mz2hMKmECxHQEIka_40pN-SXez1pViHEB6cxpnoxNMyg8TJDHAYPWDlT4gFl5KEGDuPklVpeXgH4lAsiYEisFPSh4NEEAuHOldGfTv20j7VDt7SHeg8GCsjgdj_Xdc7fSPrwU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 课程思政在高校专业课中的应用探索——以计算机视觉课程为例
{Author}: 李冠彬;毛明志;方艳梅
{Author Address}: 中山大学计算机学院;
{Journal}: 软件导刊
{Year}: 2022
{Volume}: 21
{Issue}: 05
{Pages}: 198-201
{Keywords}: 课程思政;计算机视觉;专业课程
{Abstract}: 课程思政是新时代积极贯彻中国共产党教育方针的重要方法。阐述课程思政的概念与内涵，论述课程思政融入专业课程的3种方法，并以计算机专业课程计算机视觉为例，对开展思政教育的具体方法进行探索。通过提升教师思政能力，在课程设计时找准切入点和在课堂上综合运用多种教学方法，成功帮助学生建立了科学严谨的思维方式，激发了其爱国情怀和文化自信。
{ISBN/ISSN}: 1672-7800
{Notes}: 42-1671/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx9zlp-XH8fYuSlpRTRs44i6Wv_XTFllewAoaaU4QrSnzbWZK_lCzbPl2G_3V-zDGihCXP9z3kHdyxdAx9ik4MXIGqcqVI3FDxradk7R2l5OFVxanSW2P4NPhCDGKlGIlqwWclQCJXusX2kp2BeCUN5fucO6V-46yfWnsmeGcaIdSdEVJg5mexyXcPsRaI3ZL0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习中的后门攻击综述
{Author}: 杜巍;刘功申
{Author Address}: 上海交通大学网络空间安全学院;
{Journal}: 信息安全学报
{Year}: 2022
{Volume}: 7
{Issue}: 03
{Pages}: 1-16
{Keywords}: 后门攻击;人工智能安全;深度学习
{Abstract}: 随着深度学习研究与应用的迅速发展,人工智能安全问题日益突出。近年来,深度学习模型的脆弱性和不鲁棒性被不断的揭示,针对深度学习模型的攻击方法层出不穷,而后门攻击就是其中一类新的攻击范式。与对抗样本和数据投毒不同,后门攻击者在模型的训练数据中添加触发器并改变对应的标签为目标类别。深度学习模型在中毒数据集上训练后就被植入了可由触发器激活的后门,使得模型对于正常输入仍可保持高精度的工作,而当输入具有触发器时,模型将按照攻击者所指定的目标类别输出。在这种新的攻击场景和设置下,深度学习模型表现出了极大的脆弱性,这对人工智能领域产生了极大的安全威胁,后门攻击也成为了一个热门研究方向。因此,为了更好的提高深度学习模型对于后门攻击的安全性,本文针对深度学习中的后门攻击方法进行了全面的分析。首先分析了后门攻击和其他攻击范式的区别,定义了基本的攻击方法和流程,然后对后门攻击的敌手模型、评估指标、攻击设置等方面进行了总结。接着,将现有的攻击方法从可见性、触发器类型、标签类型以及攻击场景等多个维度进行分类,包含了计算机视觉和自然语言处理在内的多个领域。此外,还总结了后门攻击研究中常用的任务、数据集与深度学习模型,并介绍了后门攻击在数据隐私、模型保护以及模型水印等方面的有益应用,最后对未来的关键研究方向进行了展望。
{ISBN/ISSN}: 2096-1146
{Notes}: 10-1380/TN
{URL}: https://link.cnki.net/doi/10.19363/J.cnki.cn10-1380/tn.2022.05.01
{DOI}: 10.19363/J.cnki.cn10-1380/tn.2022.05.01
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的接触网吊弦缺陷检测研究
{Author}: 刘杰;许建国;高春丽;刘裘航
{Author Address}: 中铁电气化局集团有限公司;大连维德集成电路有限公司;北京理工大学;
{Journal}: 铁道工程学报
{Year}: 2022
{Volume}: 39
{Issue}: 05
{Pages}: 91-97
{Keywords}: 接触网吊弦;智能视觉;图像采集;智能识别;机器视觉;维修
{Abstract}: 研究目的:为解决电气化铁路接触网人工巡检效率低和耗时长的问题，针对接触网吊弦存在的缺陷进行研究，创建一种应用高清图像采集技术和图像缺陷识别建模技术的高铁接触网吊弦缺陷检测系统。研究结论:(1)通过引入视觉智能技术，可建立接触网吊弦安装状态图像检测标准，创建吊弦缺陷图像数据库，对吊弦缺陷状态进行动态智能快速识别检测；(2)该系统使用Faster R-CNN神经网络模型对吊弦缺陷图片数据进行训练，对吊弦缺陷图片数据进行数据变换处理并加载于模型进行识别训练，训练结果中均值平均精度(mAP)可达81.36%;(3)创建的高铁接触网吊弦缺陷检测系统识别速率、准确率较高，提高了检测效率，减少了人为的漏检问题；(4)本研究成果可为传统接触网巡检方式变为智能化巡检提供新的途径，具有一定的参考价值。
{ISBN/ISSN}: 1006-2106
{Notes}: 11-3567/U
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwzr6W79VDlpKWiayA-UjaF3UP1SVYMj2GQxaHIPjmXFjIEY3oTNbcgbMvQZTmDhtMhDhGUpufCnu1QoKZBshAW37sNehibdb4vsbXa10nrV47Q5roZRRJZD4HAy1j98E7JWAucnQoQwWcVcfyerdh17KmKsBePGh_zmdDP5xa-rI3QqiobKmjKZ4eIMmj7B1U=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向机器视觉的不锈钢棒材表面螺纹缺陷检测
{Author}: 侯幸林;周培培;赵景波;高照;孙磊
{Author Address}: 常州工学院汽车工程学院;常州工学院电气信息工程学院;
{Journal}: 重庆理工大学学报(自然科学)
{Year}: 2022
{Volume}: 36
{Issue}: 05
{Pages}: 109-114
{Keywords}: 不锈钢棒材;螺纹缺陷;机器视觉;特征提取;数据集
{Abstract}: 不锈钢棒材表面的螺纹是棒材磨制过程产生的一种缺陷，严重影响棒材的验收与后续使用，目前针对该类缺陷多采用双目观察、手指感知等人工方式进行判断，漏检率较高。已有的方法多针对钢材表面的划痕、砂眼、凹坑等缺陷进行检测，鲜少对螺纹缺陷进行研究，据此，设计了一种基于机器视觉的螺纹缺陷检测方法，提出了一种快速有效的螺纹特征提取方法，建立了一个不锈钢棒材图像的螺纹缺陷数据集，通过对图像特征进行训练，得到分类器。实验结果表明：提出的算法有效提升了螺纹缺陷的检测正确率和检测速度。
{ISBN/ISSN}: 1674-8425
{Notes}: 50-1205/T
{URL}: https://link.cnki.net/urlid/50.1205.T.20220512.1012.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 改进U-Net芯片X线图像焊缝气泡缺陷检测方法
{Author}: 李可;吴忠卿;吉勇;宿磊
{Author Address}: 江南大学机械工程学院;江南大学江苏省食品先进制造装备技术重点实验室;中国电子科技集团第五十八研究所;
{Journal}: 华中科技大学学报(自然科学版)
{Year}: 2022
{Volume}: 50
{Issue}: 06
{Pages}: 104-110
{Keywords}: 缺陷检测;机器视觉;语义分割;空间注意力;密集条件随机场
{Abstract}: 针对传统图像处理算法的芯片缺陷检测方法难以实现缺陷的精确提取且泛化性较差的问题，提出了结合空间注意力机制(SAM)、空间金字塔池化(SPP)、移动端神经网络(Mobile-Net)和密集条件随机场(DCRF)改进经典UNet芯片X线图像焊缝气泡缺陷的检测方法(DSSMob-U-Net)．首先，针对经典U-Net网络特征提取能力不足、泛化性较差的问题，引入Mobile-Net作为U-Net的主干特征提取网络，提高网络获取缺陷形状和位置信息的能力，并减少网络的参数量，降低模型对训练样本量的要求；其次，在Mobile-Net的低维特征提取部分引入空间注意力机制，并在特征提取后引入空间金字塔池化，提升网络对图像高、低维特征的提取能力，解码后针对解码器上采样层导致的特征信息丢失问题，在分类完成后引入密集条件随机场，结合像素点的像素值和所属类别信息对像素的分类结果重新评估，进一步提高分割精度；最后，在芯片缺陷数据集上进行实验，验证了DSSMob-U-Net模型的有效性，并与其他常用的语义分割网络进行比较，结果表明该模型具有更好的检测性能．
{ISBN/ISSN}: 1671-4512
{Notes}: 42-1658/N
{URL}: https://link.cnki.net/doi/10.13245/j.hust.220613
{DOI}: 10.13245/j.hust.220613
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的吸烟行为检测系统研究
{Author}: 万里波
{Tertiary Author}: 曾勇
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人脸检测;烟支检测;FaceBoxes;YOLOv4
{Abstract}: 众所周知,吸烟危害吸烟者自身的健康,同时二手烟对周围人健康的危害性也不容忽略;此外,不适当的吸烟行为有时也会造成许多安全事故,例如火灾或爆炸等,给社会带来巨额财产损失。因此,加强对公共场所的禁烟监管力度成为社会各界越来越关注的问题。智能吸烟行为检测系统成为了当下非常迫切的需求,而研究该类系统的核心在于如何设计一种算法来快速而准确地检测吸烟行为。本文根据现有的吸烟行为检测研究现状,提出了一种结合人脸检测的吸烟行为检测方法。在自制的吸烟行为数据集上对本文的方法进行了测试,其准确率为94.78%,其检测速度为26.76FPS,基本满足吸烟行为检测的准确性和实时性的要求。本文的主要研究内容如下:(1)针对直接检测烟支可能会出现吸烟行为误判的情况,提出了将人脸检测与烟支检测相结合的吸烟行为检测方法,使用人脸检测模型与目标检测模型分别检测人脸和烟支,根据人脸检测框和烟支检测框的位置关系判断是否存在吸烟行为。(2)在现有的人脸检测模型FaceBoxes上进行了金字塔特征融合,增强了模型对多尺度人脸的检测能力,调整了快速消化卷积层的结构,使其保留了更多的人脸特征信息。(3)对几个性能强大的深度学习目标检测算法进行了研究,测试了其在自制的吸烟行为数据集上的性能,根据实验结果选择了性能优异的YOLOv4进行后续的改进,以适应对烟支这类目标的检测。(4)为了提高YOLOv4对图像中尺寸较小的烟支目标的检测能力,本文对YOLOv4的颈部进行了改进,提高了模型精度,并且使用PP-LCNet替换原来的主干网络CSPDarknet53,加快了推理速度。(5)根据现有的Web应用开发技术和本文的吸烟行为检测方法,设计了一个简易的在线吸烟行为检测系统,能实现用户与系统之间的可交互性,为更好地让吸烟行为检测算法应用到实际社会中提供了可能。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000930
{DOI}: 10.27005/d.cnki.gdzku.2022.000930
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于针孔成像原理的监控摄像机标定方法
{Author}: 谯帅
{Author Address}: 四川大学网络空间安全学院;
{Journal}: 现代计算机
{Year}: 2022
{Volume}: 28
{Issue}: 09
{Pages}: 91-95+104
{Keywords}: 视频监控;安防;摄像机标定;计算机视觉;针孔成像原理
{Abstract}: 为降低一般安防视频监控场景下摄像机标定的难度、提高方法的通用性，提出了基于针孔成像原理的监控摄像机标定方法。该方法通过分析针孔成像原理和一般安防视频监控场景特点，采用在图形界面中手工确认图像中已知世界坐标系中的目标点以获取像素坐标系位置的方法，通过矩阵变换快速实现摄像机标定。实验表明，该方法操作简明易懂，精度可满足一般安防视频监控的需求，具有实际应用价值。
{ISBN/ISSN}: 1007-1423
{Notes}: 44-1415/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzfSq_nKWe4bLibkYiG62TaHDoXvkZPOq-1ERYXxCEVGS2qe8VgIUocnugHV_6GmCeBIJSmIyp_DHbFi8CXGgnk16tj8fhRkleUbb9IeEEJ50ezaaP-0gvw22vxYwxJvwD7vZtt2Oxdl6cDjgeqMCEsJLa7tkHpQbWXVW22fjbfG0L297Rx0Ma9EFr2q7IKZWM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5s的深度学习在自然场景苹果花朵检测中的应用
{Author}: 尚钰莹;张倩如;宋怀波
{Author Address}: 西北农林科技大学机械与电子工程学院;农业农村部农业物联网重点实验室;陕西省农业信息感知与智能服务重点实验室;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 09
{Pages}: 222-229
{Keywords}: 机器视觉;苹果花朵;检测;YOLOv5s;自然场景
{Abstract}: 疏花是苹果栽培的重要管理措施，机械疏花是目前最具有发展潜力的疏花方式，花朵的高效检测是疏花机器人高效作业的重要保障。该研究基于机器视觉与深度学习技术，提出了一种基于YOLOv5s深度学习的苹果花朵检测方法，在对田间拍摄得到的苹果花朵图像标注后，将其送入微调的YOLOv5s目标检测网络进行苹果花朵的检测。经测试，模型的精确率为87.70%，召回率为0.94，均值平均精度(mean Average Precision, mAP)为97.20%，模型大小为14.09 MB，检测速度为60.17帧/s，与YOLOv4、SSD和Faster-RCNN模型相比，召回率分别提高了0.07、0.15、0.07,m AP分别提高了8.15、9.75和9.68个百分点，模型大小减小了94.23%、84.54%、86.97%，检测速度提升了126.71%、32.30%、311.28%。同时，该研究对不同天气、颜色和光照情况下的苹果花朵进行检测，结果表明，该模型对晴天、多云、阴天、小雨天气下苹果花朵的检测精确率分别为86.20%、87.00%、87.90%、86.80%，召回率分别为0.93、0.94、0.94、0.94,m AP分别为97.50%、97.30%、96.80%、97.60%。该模型检测白色、粉色、玫红色和红色花朵的精确率分别为84.70%、91.70%、89.40%、86.90%，召回率分别为0.93、0.94、0.93、0.93,m AP分别为96.40%、97.70%、96.50%、97.90%。该模型检测顺光和逆光条件下苹果花朵的精确率分别为88.20%、86.40%，召回率分别为0.94、0.93,m AP分别为97.40%、97.10%。结果表明YOLOv5s可以准确快速地实现苹果花朵的检测，模型具有较高的鲁棒性，且模型较小，更有利于模型的迁移应用，可为疏花器械的发展提供一定的技术支持。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw_tDs8ckXs50eMFfpQmI0zSPWz3OgH2l3NvQTgb4vaLctuOAYVLBZNtmflLjar8QKsSEGP2JjiTSse263CZfsgJ3afEB4r39OlxTZ9Huuewgkh2x1N2WYl_xpPVIXRt-jK9WI5Yjtt7DEu-ygV7Q-F3hF4t-7Uh-wesLotgMZKmScIMcCN2K0Oh-fuKxK9ZXA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于棋盘格和圆标定物的双目相机标定方法研究
{Author}: 高磊
{Tertiary Author}: 郑媛
{Publisher}: 内蒙古大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目相机标定;棋盘格标定物;圆标定物;本质矩阵分解;圆心识别;圆心排序
{Abstract}: 随着人类文明和科学技术的迅速发展,研究者们逐步使用双目相机模拟人类双眼。双目相机标定技术是解决双目视觉领域问题的先决条件。目前为止,虽然现有的双目相机标定方法众多,可应用于大多数标定场景,但是对于一些工业检测、半导体应用等高精领域,标定精度以及场景需求仍不能满足当前所需。标定方法的实用性以及准确性会直接影响到双目视觉后续任务的研究。本文探讨了当前两类主流标定物:棋盘格标定物与圆标定物的双目标定问题,针对双目相机的标定方法进行了深入研究,并通过标定实验验证了本文方法的实用性以及准确性。本文的主要工作如下:1.针对基于棋盘格标定物的双目相机标定,首先运用经典单目标定方法张正友标定法求得左右相机内参数,然后分别利用八点法、随机采样一致法、最小中值法三种不同方法求得精确的基本矩阵。利用基本矩阵与左右相机内参几何约束关系可求得本质矩阵,最终通过多个约束条件对本质矩阵进行奇异值分解,求得双目相机相对位姿即外参数。实验通过三角化长度重建棋盘格对角线以及格间距验证其标定精度,分析结果表明该标定方法在保证标定精度的前提下,降低了求解过程中参数的耦合性。2.针对基于圆标定物的双目相机标定,其中圆心检测是求解初始参数的关键,本文提出了圆心识别及圆心排序算法,大体分为三个步骤。其一检测圆标定板中的五边形内框;其二检测标定板内框区域的所有特征点圆心;其三基于“内框最近特征点”法对圆标定板所有特征点进行排序。然后运用张氏标定法原理求得左右相机内参数,利用双目相机位姿与左右相机参数的几何约束关系求得双目相机外参初始解,进而对左右相机参数减半优化,获得双目相机外参近似解,最终基于圆对角线长度为约束条件对全局参数二次估计,获得优化解。实验通过三角化长度重建圆对角线以及圆心距验证其标定精度,分析结果表明该标定方法具有良好的鲁棒性和准确性。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2022.001068
{DOI}: 10.27224/d.cnki.gnmdu.2022.001068
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度强化学习的目标检测算法与应用研究
{Author}: 王光耀
{Tertiary Author}: 王生生
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标检测;深度强化学习;深度学习;强化学习;样本学习
{Abstract}: 近些年来,目标检测在深度学习技术的加持下已经成为了感知智能在计算机视觉领域中的发展重点,并广泛应用在诸多领域中,同时为学术界和工业界列为研究热门。目标检测的发展在人们的生活中有着重要的社会意义,以其作为核心基础所衍生出的智能应用对人们的生活模式产生了重要影响。作为感知智能中视觉的重要基石,它在研究和应用过程中的问题与挑战成为了学术界所研究的重点课题,同时也从学术界的验证性研究转向工业界的实践性应用。针对目标检测现有的研究工作进行整理总结可以发现,当前目标检测在训练样本标签分配、特殊场景目标识别和物体表达形式方面的相关研究较多。虽然目标检测作为感知智能视觉领域中的基础研究课题发展多年,但在工业界不断深入实用化的过程中仍然面临着诸多问题和挑战。本文在工作中分析了当前目标检测的若干关键问题,总结了目标检测发展的路径及其当前的研究现状;并在此基础上,针对训练样本划分、复杂样本学习、样本的形式表达这三个关键问题进行了分析研究并给出了对应解决方案。本文的主要工作包含以下三方面:1.提出基于深度强化学习的训练样本自适应目标检测算法RTSA(Reinforcement Training Sample Adaptation):对于目标检测方法中正负样本类别不平衡引发的问题,训练样本划分的策略作为一个研究方向对于目标检测模型的性能产生了重大的影响,训练样本的合理划分可以使得目标检测模型更加专注于图像中的目标实例本身从而提升模型性能。作为被检测目标实例的前景,相比于背景在图像中的所占空间比例较低,密集预测作为当前目标检测所用的主要方式生成了大量的负训练样本,导致了模型训练效果更偏向简单的负样本而无法检测到应该关注的目标实例,这种问题在诸如医疗图像背景复杂物体实例规模小的专业应用上更加严重。为了解决这个问题,本文提出了一种基于深度强化学习控制的训练样本划分策略RTSA。在这种策略的支持下,正负训练样本划分的阈值将根据生成锚框集合的统计属性动态生成确定,并且可以通过深度强化学习控制下的智能体对负训练样本锚框进行形变操作来优化提升正训练样本比例,从而针对性的化解正负样本不平衡带来的难题。该工作中所提出的方法在腹腔镜医疗数据集上进行了验证,并通过消融实验进一步验证了方法不同设置对于方法性能表现的有效性的影响。2.提出了基于深度强化学习的旋转目标检测算法RL-RPN(Reinforcement Learning Region Proposal Network):旋转目标检测在背景信息含量高的图像中面临着背景干扰过多的问题,因此复杂样本学习作为一个研究方向对目标检测模型的性能有着重大的影响。水平目标检测对于任意朝向的目标进行检测时存在着边界框内冗余信息过多的情况,这导致了模型的网络训练需要更多的训练数据和时间来提升对干扰信息的鲁棒性。为了解决这个问题,该工作提出了一种基于深度强化学习控制优化的目标检测方法ORL-RPN,将目标检测任务由通常的回归问题转换为控制一系列分解图像检测动作的序列决策任务,通过引入强化学习机制,智能体可以采用动态的策略来对旋转目标进行精准采样。为了验证样本复杂性对于目标检测模型的影响,我们采用了专用的旋转目标检测数据集,并在这些数据集上进行对比实验。通过实验,本文验证了由旋转目标带来的样本复杂性对于目标检测的影响,并证实了所提目标检测方法ORLRPN的有效性。3.提出了基于深度强化学习的关键点目标检测算法RLRep Points(Reinforcement Learning Rep Points):图像中物体实例的表达方式在目标检测任务中作为一个关键研究主题,一直为学术领域的人所关注。样本的表达,即物体实例的表达方式的定义,决定了目标检测方法在模型上的设计和实现,对目标检测有着重要影响。受目标检测传统方法的影响,边界框在样本表达上一直占据着统治地位。人们通过框作为参照物,利用回归方法对目标实例进行预测,以达到将物体包含在边界框内的目的。但随着目标检测领域的发展,这种边界框的样本表达方式成为了目标检测方法性能提升的瓶颈,边界框只能表达出框内物体的分类信息和粗略的位置信息,且边界框的表达方式因为受限对于物体形状的表达而提升了图像位置搜索难度。为了解决这个问题,当前学术界发展出了基于关键点的表达方式来替代原本基于边界框的表达方式。但表达目标实例的关键点在分布方式和数量上仍然面临着次优问题,为此该工作提出了一种基于深度强化学习控制关键点表达的目标检测模型RLRep Points。通过实验,本文验证了在深度强化学习算法的优化下,对于样本进行表达的点自适应到最优状态和增强目标检测模型的稳定性。样本学习作为目标检测方法的重要环节,对模型性能的表现起到了关键作用。本文的工作从训练样本划分、复杂样本、样本形式表达这三个方面来分析样本学习对目标检测模型产生的影响,同时在现有目标检测模型的基础上加入深度强化学习模块,最终通过实验验证强化学习机制在目标检测任务中的有效性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.000210
{DOI}: 10.27162/d.cnki.gjlin.2022.000210
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于细粒度特征融合的多模态行人重识别方法研究
{Author}: 谢更生
{Tertiary Author}: 温显斌
{Publisher}: 天津理工大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 行人重识别;细粒度;多模态;特征融合;颜色鲁棒
{Abstract}: 行人重识别(Person Re-Identification,re-id)是指利用计算机视觉技术在指定视频或图片序列中对特定行人进行识别的技术,通常被认为是图像分类或图像检索的子问题。作为跨摄像头行人轨迹跟踪、行人行为识别等机器视觉方案的核心构成,行人重识别技术在园区安防、公安刑侦、交通纠违与公共安全等领域展现出广阔的应用前景。在实际应用中,因受到前景遮挡、背景噪声、行人姿态的非刚性形变以及光照变化等诸多外在因素影响,当前行人重识别任务依然面临着巨大的挑战。现有行人重识别方法大多基于图像视觉信息进行分类,一方面缺乏对于语义信息的进一步挖掘与充分利用,另一方面忽略了不同模态的信息交互。本文围绕行人重识别研究领域的多项关键问题进行系统深入的研究,对关系特征潜力发掘、颜色特征过度依赖、遮挡算法缺乏通用性、注意力模型训练困难等问题展开探索,取得成果如下:1.提出一种基于局部-全局关联特征关系信息挖掘的行人重识别方法。区别于专注获取局部图像细节特征进行检索的方式,本文对不同语义分区特征间的隐藏关联展开推理,以挖掘对行人识别结果存在因果关联的关键关系信息,并针对其核心网络模块设计展开深入探讨。该方法利用全局特征的全局感受野特性将其与特定图像区域表征进行叠加,手动构建不同粒度下的成对的关联特征对,实现不同语义分区下多粒度特征关联。通过局部图像上下文感知及“局部-整体”特征对构建,驱动模型对不同粒度特征间关联信息展开推理,进一步挖掘对分类结果至关重要的深层次关系信息,以克服传统基于局部特征的re-id方法在关系表示构建方面的不足。全局图像区域覆盖加局部显著特征补充的做法,也在一定程度上缓解了由于姿态变化、遮挡、错误剪裁而导致的关键点不对齐问题。2.针对深度re-id模型过度依赖颜色表征问题,提出了一种颜色通道控制非局部注意力网络,用于加强多分支网络框架下基于关系感知的颜色鲁棒特征学习。该网络通过原始图像样本与通道调整图像样本的成对输入,人为加入颜色扰动信息,有效增强了非局部注意力模型获取对颜色鲁棒特征的能力。此外,该方法提供了一种一致性约束下的训练数据增强方法,通过对颜色通道的随机调整及通道调换进行数据集增扩。该方法可部分模拟行人在不同光照条件下表现以及不同摄像机之间的颜色偏好差异,增强模型最终表征对颜色的鲁棒性,有效提升了深度学习模型泛化能力。3.针对遮挡行人重识别场景,提出了一种人体姿态信息引导的局部特征融合模型,通过对原始图像表征与包含姿态估计信息表征在不同粒度进行融合以获得良好的最终特征表示。该模型通过融合姿态估计先验信息的特征与常规图像特征在不同粒度上的结合,协同考虑了不同网络分支在共享图像区域内所存在显性响应关联,通过引入外部监督信号完成独立分支先验标签差异化构建,以进一步基于人体可见区域图像表示进行关系推理与特征学习。实验表明该方法不仅在遮挡行人重识别数据集上取得了优异的性能,在常规的非遮挡行人行重识别数据集上同样达到了有竞争力的水平。4.提出一种姿态估计信息引导的半监督行人重识别网络模型。针对基于注意力的行人重识别模型缺乏结构化约束、训练困难的问题,该模型利用融合姿态估计信息的特征对输入样本高响应行人可见图像区域进行标注,通过教师-学生双网络监督模式,在统一深度学习框架下实现深层语义信息与注意力特征的协同学习与表达。通过外部监督信号驱动注意力聚类,模型根据已有语义特征分区推理出显著图像表征规律,有效增强了基于注意力的行人重识别模型在稀疏特征样本分布下获取高判别性特征的能力。
{URL}: https://link.cnki.net/doi/10.27360/d.cnki.gtlgy.2022.000701
{DOI}: 10.27360/d.cnki.gtlgy.2022.000701
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的复杂环境下表面缺陷检测技术研究
{Author}: 曹锦纲
{Tertiary Author}: 杨国田;杨锡运
{Publisher}: 华北电力大学(北京)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 机器视觉;复杂环境;表面缺陷检测;深度神经网络;鲁棒性主成分分析
{Abstract}: 基于机器视觉的表面缺陷检测是生产过程自动化、智能化发展的需要。表面缺陷检测作为工业生产中产品质量监控的重要环节,能够有效地提高产品质量和生产效率;表面缺陷检测还是进行日常设备维护的重要手段,及时发现表面缺陷能够有效延长设备的寿命。随着机器视觉和人工智能技术的发展,对于背景单一、缺陷明显等简单环境下的表面缺陷已经取得了较好地检测效果,具有较高的准确率。但是对于复杂环境下的表面缺陷,由于干扰因素多、涉及的领域广,大大增加了缺陷检测的难度,为实现智能检测和制造强国、质量强国发展战略,复杂环境下表面缺陷的高精度检测是一个亟待解决的问题。本文以表面缺陷为研究对象,基于机器视觉技术,针对复杂环境下的表面缺陷检测问题进行了深入研究,采用鲁棒性主成分分析和深度学习技术,提出了解决的方法。本文的创新和主要研究工作如下:(1)针对采集的图像中光照不均和检测结果中缺陷不连续的问题,提出了一种基于视觉显著性和鲁棒性主成分分析的表面缺陷检测方法。该方法将缺陷图像看成由低秩矩阵表示的非缺陷区域、稀疏矩阵表示的缺陷区域和噪声矩阵组成,通过对表面缺陷的人工特征提取,基于改进的鲁棒性主成分分析求得稀疏矩阵。为抑制非均匀光和检测出连续的缺陷区域,在鲁棒性主成分分析基础上,增加了F范数和拉普拉斯正则项。再根据稀疏矩阵,采用视觉显著性,实现对表面缺陷的检测。对提出的方法,在人工数据集和风机叶片数据集上与其他传统方法进行了比较,结果表明所提出方法能够有效抑制非均匀光和噪声,检测出连续的缺陷区域,提高缺陷检测的性能。(2)针对复杂环境下,传统的表面缺陷检测方法难以有效检测缺陷的问题,提出了一种基于注意力机制的深度神经网络表面缺陷检测模型。该模型基于编码器-解码器架构,编码器采用ResNet34提取各层特征,通过在编码器和解码器间增加基于注意力的更高层特征提取模块,以获取更高层的语义上下文信息,更好地定位缺陷区域。此外,在解码器各层引入基于注意力机制的解码模块,利用空间和通道注意力机制,提升对表面缺陷定位的准确性。对提出模型在两个公开路面缺陷数据集CFD和CRACK500上,与其他8种模型进行了性能对比,提出模型在评价指标F-measure和IoU上取得了最佳的检测结果。(3)针对低对比度、微小缺陷和缺陷种类形态多样以及非均匀光等给表面缺陷检测带来的巨大挑战,为提升复杂环境下表面缺陷检测方法的准确性和通用性,提出了一种基于深度神经网络的多层多级特征融合的表面缺陷检测模型。该模型首先利用ResNet50提取多层特征,然后利用多层特征聚合模块融合各层特征,具体过程为先采用横向连接和特征融合块自下而上融合特征,再利用跳跃连接与高层特征相加融合,从而使各层不仅包括丰富的局部信息,而且包含高层的语义上下文信息。接着再利用多级解码器进行特征深度融合,多级解码器包含多个解码分支,各分支结构相同,各级解码器利用横向连接传递各层特征。前一级解码分支的输出还通过反馈连接与各层特征融合后再传入后一级解码器。通过多层多级特征的深度融合,实现对表面缺陷的准确定位和分割。在三个不同类型的复杂表面缺陷数据集MT、RSDD和CFD上和多种模型进行了实验对比,结果表明提出模型能够有效提升表面缺陷检测的性能和通用性。(4)为进一步提升复杂环境下表面缺陷检测的性能,采用FCN构架,提出了一种基于两级注意力特征融合的表面缺陷检测模型。该模型首先利用ResNet50特取表面缺陷的各层特征,为更好地检测微小缺陷,增加了一个基于扩张卷积的多尺度特征提取模块。然后将各层特征送入两级注意力特征融合模块,该模块先通过基于注意力的相邻特征融合模块在各层进行相邻特征融合,再通过基于注意力的高层特征融合模块实现将各层与其高层特征融合,通过两级特征融合,各层能够包含更多的局部细节信息和全局语义信息。最后将各层特征拼接融合,经过边界求精模块和卷积模块,输出缺陷分割图。为验证提出模型的有效性,在三个不同类型的表面缺陷数据集SD900,MT和CFD上与其它模型进行了对比,结果表明提出的模型具有最优的检测性能和较强的通用性,IoU分别提高到89.90%,76.72%和 64.92%。
{URL}: https://link.cnki.net/doi/10.27140/d.cnki.ghbbu.2022.000105
{DOI}: 10.27140/d.cnki.ghbbu.2022.000105
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的水下图像增强算法研究
{Author}: 石慧
{Tertiary Author}: 王欣
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 水下图像增强;图像处理;计算机视觉;深度学习;机器学习
{Abstract}: 在水下环境中,悬浮的颗粒会对光造成散射和波长相关的衰减,使水下图像出现颜色失真、成像模糊以及对比度低等问题,影响对水下图像中有用信息的获取,不利于后续图像目标检测、图像分割等高级视觉任务的进行。针对上述问题,国内外研究人员提出了多种水下图像增强算法,但现有算法具有一定的局限性。传统的水下图像增强方法对失真严重的水下图像的增强效果较差,增强后的图像会引入噪声或者出现过度增强,无法获得理想的增强结果,而当前基于深度学习的方法因为缺少成对数据集,多利用对抗生成网络在生成合成数据集的同时实现水下图像增强,而实验表明合成数据集与真实数据集仍存在差异,使得现有方法在真实水下环境中应用效果不佳,而非基于对抗生成网络的算法无法提供能够处理水下图像多样性的单一解决方案,算法鲁棒性较差。本文在现有算法的基础上进一步探索了深度学习在水下图像增强领域的应用,提出2种基于深度学习的水下图像增强方法,分别为基于双重残差混合注意力机制的水下图像增强算法和基于残差Swin Transformer的水下图像增强算法。其中基于双重残差混合注意力机制的水下图像增强算法致力于以较小的模型参数量获得优秀的性能,该算法采用改进的双重残差块完成特征学习,并通过在双重残差块中引入混合注意力模块,沿通道和空间两个维度对特征进行注意力权重推断,以捕获显著特征;基于残差Swin Transformer的水下图像增强算法探索了深度学习模型Swin Transformer在水下图像增强任务中的应用,并致力于实现模型性能与模型规模之间的平衡,获得了最优的性能,该算法通过建立层次化结构充分发挥了传统卷积神经网络和Transformer的优点,并通过残差连接实现了多尺度特征的融合。为激励产生颜色自然、对比度高且具有更精细纹理的增强图像,本文设计了结合l1损失、结构相似性损失和内容感知损失的联合特征损失函数,对网络进行端到端训练。此外,本文应用水下图像形成模型（Image Formation Model,IFM）对水下图像基准数据集（Underwater Image Enhancement Benchmark dataset,UIEB）进行优化,获得了具有更高视觉质量的N-UIEB数据集,实验表明,相较于UIEB数据集,基于N-UIEB训练得到的增强图像具有更自然的颜色和更清晰的细节。本文将提出的方法基于双重残差混合注意力机制的水下图像增强算法和基于残差Swin Transformer的水下图像增强算法获得的增强结果与主流的方法进行比较和分析,结果表明,本文提出的方法有效提高了图像对比度并恢复了图像颜色,且在细节恢复方面表现优秀,而且在与水下图像增强算法的定量比较中获得了优秀的性能。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.002918
{DOI}: 10.27162/d.cnki.gjlin.2022.002918
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于嵌入式系统和人脸识别技术的门禁控制器设计
{Author}: 徐勉
{Tertiary Author}: 严辉
{Publisher}: 安徽建筑大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 嵌入式系统;人脸识别;门禁系统;Exynos4412
{Abstract}: 在科学技术不断发展的今天,人们在追求高水平生活的同时,安全防卫意识也在增强。门禁系统作为安防的基础,对其研究有着重要意义。传统的门禁系统都是基于密码或者证件的身份验证方式,由于安全性不强、操作复杂等缺点逐渐走向淘汰。伴随着生物识别技术的迅速发展,人脸识别因其非接触性、非干扰性、简易便捷等优势被广泛应用于图像处理、视频监控等行业。基于人脸识别的门禁系统具备较高的安全系数和可靠性,并且由于其自动化、智能化等特性受到大部分消费者的青睐。传统的人脸识别门禁系统都选择基于高性能的大型计算机,其具有海量的存储能力,在人员变动较大的大型场所表现出很好的识别效果。但由于体积大、成本高、便携性不够,在家庭、实验室等人员变动较小的小型场所反而没有很好的市场效益。随着嵌入式系统的发展,嵌入式处理器的性能得到了很大的提升。因此本文提出了基于嵌入式系统的中小型人脸识别门禁系统设计,主要从算法分析、硬件设计以及软件设计三个方面进行详细的阐述。在算法分析上,为了提升图像的质量,需要对图像进行预处理操作,包括图像格式转换、灰度化、直方图均衡化、中值滤波和大小归一化。人脸检测选择基于Haar特征的Adaboost算法,根据Haar特征确定人脸关键信息后,利用积分图方法计算特征值,送入由Adaboost算法训练得到的若干强分类器级联成的级联分类器中进行人脸检测。通过对PCA、LDA和LBPH三种人脸识别算法的分析,最终选择基于LBPH的算法进行人脸识别。在系统硬件设计上,本系统采用Exynos4412处理器作为主控模块,根据系统的功能需求,逐一设计系统的外围电路。为了满足系统各部分的供电需求,设计了5V、4V、3.3V和1.8V电源电路;为了解决处理器内存不足的问题,设计了SDRAM接口电路和e MMC接口电路;为了进行人机交互,设计了LCD显示屏、电容触摸屏和USB键盘接口电路;为了满足通讯要求,设计了UART、JTAG和以太网接口电路;为了进行图像的采集和门禁的控制,设计了摄像头接口电路和电磁锁控制接口电路。在系统软件设计上,选择在本目标平台搭建嵌入式Linux操作系统开发环境,并移植了图像用户界面Qt库和计算机视觉库Open CV。针对系统的各个功能需求,设计了系统主程序、图像采集程序、图像预处理程序、人脸检测程序、人脸识别程序、数据存储程序和电磁锁驱动程序。最后成功在嵌入式平台上实现了人脸识别的功能。通过对系统人脸检测和人脸识别功能进行测试,测试结果表明:在数据样本较小的情况下,系统具有较高的识别速度和精度,并且使用简便快捷。本系统相对PC机具有成本较低、扩展性较好等优点,在人员变动较小的中小型场所下运行效果实时、稳定、可靠,能够达到预期目标。图[48]表[6]参[56]
{URL}: https://link.cnki.net/doi/10.27784/d.cnki.gahjz.2022.000372
{DOI}: 10.27784/d.cnki.gahjz.2022.000372
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的X射线管道焊缝气孔缺陷检测技术研究
{Author}: 欧阳昌青
{Tertiary Author}: 方黎勇
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: X射线;缺陷检测;LSTM网络;YOLO网络
{Abstract}: 管道的安全性能与其焊缝质量密切相关,从家用燃气管道到战略能源管道,焊接缺陷可能会引发管道爆炸,造成严重经济损失甚至人员伤亡。因此,必须对焊缝缺陷进行严格的检查。X射线检测具有准确、直观、无损等特性,是目前应用最为广泛的焊缝无损检测方法之一。但X射线检测结果目前主要依赖于人工评片,人工评片具有操作繁琐、工作强度大、检测结果不一致等缺点。而现有的缺陷自动化检测算法则普遍存在精度低、速度慢等问题,且大量阈值参数依赖于手工选取,智能化程度相对较低。针对上述问题,为提高焊接缺陷检测质量与自动化水平,提出了基于深度学习的X射线焊接缺陷检测算法,主要工作如下:(1)提出了一种基于LSTM网络的焊缝区域定位方法,根据焊缝成像特点,构造Intensive曲线将二维问题降维成一维序列问题,通过LSTM网络从序列中学习焊缝边界特征,实现焊缝区域定位,进而将检测范围大幅缩小,提升了233%的计算速度。(2)提出了一种基于YOLO改进的缺陷目标检测算法,基于残差学习策略重新设计了前级特征提取网络以保证实时检测速度;优化了用于引导网络参数训练的损失函数,降低了计算复杂度并提升了缺陷检测精度。(3)设计并实现了焊缝缺陷自动化检测原型系统,使工作人员可以通过客户端图形界面,借助服务器的强大算力,通过云计算快速获得焊接缺陷检测结果并可视化显示,提高了X射线像片的评估效率。为验证检测效果,构建了一个包含1200张X射线检测图片的实验数据集,经实验,本文提出的算法缺陷召回率为99.3%,单张图像平均检测时间为32毫秒,能够满足精度和效率的检测要求。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000864
{DOI}: 10.27005/d.cnki.gdzku.2022.000864
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的驾驶员疲劳状态检测预警技术
{Author}: 王红君;白浩;赵辉;岳有军
{Author Address}: 天津理工大学电气电子工程学院;天津农学院工程技术学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 12
{Pages}: 4887-4894
{Keywords}: 计算机视觉;疲劳检测;perclos值;人脸检测
{Abstract}: 疲劳驾驶是造成交通事故的主要原因之一，为提高驾驶员疲劳驾驶状态的智能化检测水平，提出一种基于计算机视觉的面部多特征疲劳驾驶检测算法，采用多线程优化后的Dlib(图像处理开源库)实现对驾驶员面部的定位与追踪，利用Dlib开源库中的人脸关键点检测器对驾驶员面部关键特征点进行提取，实时计算驾驶员眼部的纵横比和嘴部长宽比，并以视频流数据集作为实验样本计算出相关阈值，有效提高了检测算法的普适性，在此基础上，计算出眨眼频率、闭眼次数、眼睛闭合时间百分比以及打哈欠频率这4个反映驾驶员疲劳状态的指标，并利用数学方法进行指标实时融合，根据融合指标的数值对驾驶员疲劳状态进行分级，最终通过实验验证该疲劳检测系统的准确性。结果表明：所提出的综合疲劳指标能够准确反映在不同环境和光照下驾驶员的疲劳状态和发展趋势，驾驶员疲劳判定的正确率达到97.5%以上。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyYBNQJSBBN9w3s4bGmevNrCE4hZs0_GTN9w0zX0sIk8UTfNIGSt_qCxrqFwIGoD83JW3zEsMp92WXveOAKwiYwroXRG-sFdqCcIOYIjwTL_4L_7ZWZ-AHle9F0tvkkXHECvsXz28sjgM5_Q1qOS-diMlx9Ag62f-2OzOMHidbOG3N2X336jVzzqkxdv2ozZ-g=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的图像特征提取方法研究
{Author}: 杨有帅
{Tertiary Author}: 刘珊
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: Transformer;特征提取;计算机视觉;轻量化
{Abstract}: 图像特征提取是当前计算机视觉领域的重要技术之一,很大程度上决定着许多视觉任务的精度与速度。随着大数据时代的发展,海量的图像数据与各种复杂的实际应用场景使得高效而精准地从图像中提取特征成为了挑战,学术界因此对图像特征提取方法进行了广泛的研究。近年来,基于Transformer提取图像特征的方法被广泛研究,但相关模型仍存在一些需要改进的地方。首先,Transformer的复杂度与输入的序列数量成二次关系,阻碍了基于Transformer设计的图像特征提取网络对高分辨率的图像建模,并且高昂的计算成本使其很难适用于边缘设备。其次,Transformer在建模视觉结构时缺乏归纳偏置,使其需要采用超大数据集进行预训练。最后,与卷积神经网络相比,Transformer模型可优化性较差,对于优化器的选择较为敏感,缺乏稳定性,收敛速度较慢。针对上述问题,本文主要工作如下:(1)提出了两种加速Transformer模型的方法,分别从模型内部和外部两个角度去解决当前Transformer模型计算成本高,模型的复杂度与输入的Token数量成二次关系的问题。首先是将自注意力机制本身的二次复杂度降低为线性,从内部提高模型的处理速度;然后又提出了一个无参数,可以根据不同输入图片自适应采样从而筛掉不重要Token的轻量化剪枝方法,从外部减少无意义的输入。最后将两种方法合并得到了一种新的高效注意力机制(E-Attention)。实验表明,两种方法各自可降低原Transformer模型30%-50%的计算量,而E-Attention可以减少原Transformer模型60%-70%的计算量。(2)在本文提出的E-Attention基础上,进一步结合深度卷积和空洞卷积,从平移不变性,局部性,尺度不变性三个角度引入Transformer模型缺乏的归纳偏置。然后再利用一个轻量化卷积模块改变传统Transformer模型对输入图片的处理方式,从而加快收敛速度,提升稳定性。最终得到了一个结合卷积的高效Transformer图像特征提取网络(CEFormer)。实验表明,CEFormer在性能和运算速度之间均取得了良好的结果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003530
{DOI}: 10.27005/d.cnki.gdzku.2022.003530
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像语义分割方法综述
{Author}: 王可;沈川贵;罗孟华
{Author Address}: 贵州财经大学信息学院;贵州财经大学大数据应用与经济学院(贵阳大数据金融学院)贵州贵阳;
{Journal}: 信息技术与信息化
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 23-30
{Keywords}: 图像语义分割;卷积神经网络;深度学习;计算机视觉;图像分割数据集
{Abstract}: 图像语义分割技术是计算机视觉领域的核心研究内容 之一，在生产生活中有着广泛的应用需求。随着计算机性能的提升和深度学习技术的不断发展，研究者们对图像语义分割的实际效果和性能有着越来越高的研究热情。文章通过对图像语义分割方法的研究整理，梳理出现阶段图像语义分割研究的主要问题，针对这些主要问题整理了研究者们提出的解决方法和思路，介绍了语义分割领域常用的公共数据集以及算法性能评价标准，最后对各个算法进行性能的比较和评价，并对图像语义分割领域下一步的研究热点方向进行了展望。
{ISBN/ISSN}: 1672-9528
{Notes}: 37-1423/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx0siycV01S8QnrlNFyARcInyS3iE7fQzqJz1TK4sYTZZTiz04Y784u8035d_-9lsudFrkSUWlbFDCPv7hVrnEpRnj_ITLmRFs81Blh1wQODVTqQFet7xxv7BlNK-YwUeJNWjZOPoxO4M2WxicfJ-_l6w_wd8zBap2427tuV3XBzXhzt4v8uDn45P-N_muQCYQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于方向性靶标和多约束优化的双目相机标定
{Author}: 杨霈;殷玉龙;卢荣胜;朱华炳
{Author Address}: 合肥工业大学机械工程学院;合肥工业大学仪器科学与光电工程学院;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 08
{Pages}: 195-206
{Keywords}: 机器视觉;双目相机标定;方向性平面靶标;平面靶标姿态;多约束优化
{Abstract}: 提出了一种基于方向性靶标和多约束优化的双目相机标定方法。新型方向性平面靶标能够判断靶标的旋转方向，并对每个标定角点进行编码，以保证双目相机在拍摄到局部靶标的情况下依然能够完成同名点匹配，进而完成双目相机标定。根据方向性靶标建立双目相机标定模型，引入用于描述平面靶标姿态的天顶角和方位角，通过天顶角和方位角筛选出在不同位置上的靶标姿态均具有明显差异的图像作为标定图像，这提高了双目标定结果的稳定性；结合靶标的三维几何信息，建立了多维度约束的双目参数优化模型，提高了双目标定结果的精度。实验结果表明，与传统的张氏标定方法相比，所提出的标定方法能够有效提高所获得的标定结果的稳定性和精度；通过对标准量块进行多次测量，进一步验证了所提方法的有效性。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz4-wfQr2GCVhG2_E-642Mnwv0LUGJF7pEozhpJbpzRwCrzyiL0vZT1ggOv3sXFlXjLDWnb-8c6dF_TbrQcBvxi0z01H2VxUoivkcjzkdeEzXY4gAHOvJnbcIlJRv6MwbxQ5BXHx44uYqFIyznHgqCj-2DkjSb0VRZrLhvYOTfa1VvHMBTKerQTdmH80lMqzv0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 大田甘蓝作物行识别与对行喷雾控制系统设计与试验
{Author}: 韩长杰;郑康;赵学观;郑申玉;付豪;翟长远
{Author Address}: 新疆农业大学机电工程学院;北京市农林科学院智能装备技术研究中心;国家农业智能装备工程技术研究中心;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: 06
{Pages}: 89-101
{Keywords}: 大田甘蓝;机器视觉;精准施药;作物行识别;轨迹追踪
{Abstract}: 对行喷雾技术可提高农药的利用率，有利于保护环境和减少农药残留。本文搭建基于机器视觉的大田甘蓝对行喷雾控制系统。通过改进的ExG算法提取颜色信息，采用最大类间方差法和形态学的开闭运算分割作物与背景。提出甘蓝作物行定位与多作物行自适应ROI提取方法，在条带分割的ROI内基于限定阈值垂直投影对特征点集进行采集，通过最小二乘法对特征点集进行线性拟合得到作物行中心线。利用中心线几何关系得到作物行偏移信息，根据对行机构的运动特性建立对行偏移补偿模型，并设计基于PID轨迹追踪算法的对行喷雾控制系统。试验结果表明，实验室作物行识别准确率为95.75%,算法平均耗时为77 ms。在田间试验中，识别算法在时间段09:00—11:00、14:00—16:00内测试效果最佳，识别偏差均值保持在2.32 cm以下。针对不同范围的杂草测试中，算法平均识别成功率为95.56%,说明算法具有较强的鲁棒性。在与其他识别算法对比测试中，本文算法平均耗时最短，识别成功率最高，能够为实时作业提供视觉引导。在对行喷雾控制系统田间试验中，对行准确率达到93.33%,对行控制算法可将对行偏差控制在1.54 cm,满足田间实际应用要求。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20220422.1345.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 采用双目视觉和自适应Kalman滤波的作物行识别与跟踪
{Author}: 翟志强;熊坤;王亮;杜岳峰;朱忠祥;毛恩荣
{Author Address}: 中国农业大学工学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 08
{Pages}: 143-151
{Keywords}: 导航;机器视觉;图像处理;大田作物;作物行识别;作物行跟踪;线性状态观测
{Abstract}: 针对传统作物行识别方法在相邻图像间的识别结果偏差较大，作物行的定位精度和稳定性低等问题，该研究提出一种基于双目视觉和自适应Kalman滤波技术的作物行识别与跟踪方法。对于作物行识别，首先建立图像预处理算法，基于改进的超绿-超红模型和最大类间方差法分割植被灰度特征；建立作物行特征提取算法，基于特征点检测技术和双目视差测距方法计算植被角点特征的三维坐标，根据三维阈值提取作物行特征点，进而建立作物行中心线检测算法，建立基于主成分分析的直线拟合模型，根据作物行特征点的频数统计规律检测作物行冠层中心线。对于作物行跟踪，建立跟踪目标规划模型，提取位于图像中央区域的作物行作为跟踪目标；建立目标状态方程，基于自适应Kalman滤波技术构建作物行中心线跟踪模型。以棉花图像开展试验研究，图像数据包括阴影、杂草、地头等田间场景。试验结果表明，该研究方法的作物行识别准确度、精度和速度均较高，识别正确率约为92.36%，平均航向偏差为0.31°、标准差为2.55°，平均识别速度约80.25 ms/帧；经目标跟踪后，航向角和横向位置估计的标准差分别为2.62°和0.043m、较无跟踪状态分别减小22.94%和10.42%，作物行中心线的方位估计精度进一步提高。研究成果可为导航系统提供连续、稳定的作物行导引参数。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxGgLoo0_RRQnljd_wUhQe9Kc8c9E9xqkZL9BsaGbNVYH0c-AL6wJ1uPrUMUnG5IHSFbG4jaTr0ebcBRvBxmub7HCUjEjuRYwG1p7grFrHKJLneSXfd2UyDkQLjl7xDFczx_9o5UzJFFBAj1azPIw6PaW40QO_NsJFmL0j1OLDTuLXzGPiuFJD1qGvrX2SR3P4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的人群计数算法综述
{Author}: 田月媛;邓淼磊;高辉;张德贤
{Author Address}: 河南工业大学信息科学与工程学院;河南省粮食信息处理国际联合实验室;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 07
{Pages}: 152-159
{Keywords}: 人群计数;卷积神经网络;深度学习;计算机视觉
{Abstract}: 人群计数在视频监控、公共安全、智能商业等许多领域都有广泛的应用，近年来，随着深度学习的不断发展，人群计数已经成为计算机视觉领域研究的热点之一。本文根据提取特征方式的不同，将人群计数分为两类一类是传统方法，另一类是基于深度学习的方法，对基于卷积神经网络的方法进行重点分析和介绍；进一步介绍了人群计数领域的基准数据集和其他代表性数据集，实验结果表明，在人群密集和尺度变化较大的场景，基于卷积神经网络的方法优于传统方法，在尺度变化较大、人群较复杂的场景中多列网络比单列网络计数更加准确，效果更好；最后讨论了算法的未来发展方向。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108231
{DOI}: 10.19651/j.cnki.emt.2108231
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CNN-Transformer的视觉缺陷柑橘分选方法
{Author}: 安小松;宋竹平;梁千月;杜璇;李善军
{Author Address}: 华中农业大学工学院;国家柑橘保鲜技术研发专业中心;农业农村部长江中下游农业装备重点实验室;
{Journal}: 华中农业大学学报
{Year}: 2022
{Volume}: 41
{Issue}: 04
{Pages}: 158-169
{Keywords}: 柑橘;缺陷检测;机器视觉;深度学习;卷积神经网络;在线柑橘分选;轨迹预测;Transformer
{Abstract}: 针对产线分拣缺陷柑橘费时费力等问题，以柑橘加工生产线输送机上随机旋转的柑橘果实为研究对象，开发了一种基于卷积神经网络（CNN）的检测算法Mobile-citrus，用于检测和暂时分类缺陷果实，并采用Tracker-citrus跟踪算法来记录其路径上的分类信息，通过跟踪的历史信息识别柑橘的真实类别。结果显示，跟踪精度达到98.4%，分类精度达到92.8%。同时还应用基于Transformer的轨迹预测算法对果实的未来路径进行了预测，平均轨迹预测误差达到最低2.98个像素，可用于指导机器人手臂分选缺陷柑橘。试验结果表明，所提出的基于CNN-Transformer的缺陷柑橘视觉分选系统，可直接应用在柑橘加工生产线上实现快速在线分选。
{ISBN/ISSN}: 1000-2421
{Notes}: 42-1181/S
{URL}: https://link.cnki.net/doi/10.13300/j.cnki.hnlkxb.2022.04.020
{DOI}: 10.13300/j.cnki.hnlkxb.2022.04.020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态语义理解的视觉问答研究
{Author}: 彭亮
{Tertiary Author}: 杨阳
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉问答;多模态语义理解;注意力机制;视觉关系;图网络
{Abstract}: 随着互联网和多媒体等高新技术的不断发展,融合视觉语言的多模态数据逐渐成为主流的信息传播媒体,与人们的现实生活息息相关。目前,针对单一模态的研究,如计算机视觉、自然语言处理等领域已取得了巨大的研究进展。如何更进一步,进行视觉和语言之间的跨模态语义理解和推理,减少模态之间的语义鸿沟,成为了一个热点问题。而视觉问答作为一个典型跨模态任务,自提出起便受到了广泛的关注。视觉问答旨在根据视觉媒体(图像/视频)以及与视觉内容相关的自然语言问题,预测问题的正确答案。这需要视觉问答系统1)对各个模态之中的语义信息进行有效的挖掘;2)建立各模态之间的准确关联和对齐;3)高效地融合模态信息和答案推理。针对这三个关键问题,本文从多模态语义理解的层面出发,首先提出了一种从单词到区域的注意力机制,用以获取视觉和文本模态之中与回答问题相关的语义信息。其次,设计了一种具有级联结构的问答模型,针对预测答案中潜在的语义信息进行有效挖掘和利用。之后,从跨模态关联的角度出发,深入研究问题文本和视觉目标之间的多模态关系信息。最后,充分考虑视频中多种不同层次的视觉语义信息以及文本语义信息,促进不同模态之间信息的有效融合。具体而言,本学位论文的主要研究成果包括以下几点:(1)本论文提出了一种从单词到区域的注意力网络,用以充分挖掘视觉图像与问题文中的语义信息。该方法使用更具表达能力和符合自然情况的目标区域特征作为图像表征,同时采用两种注意力网络关注问题中的关键单词和与之对应的图像目标区域,促进模型更好地理解问题文本与图像中的语义信息。实验结果表明所提方法能聚焦各模态之中重要的语义信息并取得了性能的提升。(2)本论文提出了一种级联的问答模型,将传统的单阶段视觉问答模型扩展为两阶段的结构,从而充分利用嵌入在问题答案中被现有模型忽略的语义信息。该方法首先利用一个带有协同注意力的问答模型生成问题的候选答案,然后利用另一个问答模型融合问题、答案和图像三者信息,从而预测问题的最终答案。在多个公开数据集上的实验表明所提级联问答模型能够生成高质量的候选答案并在整体性能上优于传统的单阶段模型。(3)本论文提出了一种多模态关系注意力网络,用以对问题文本和视觉目标之间的关系信息进行建模并进行有效的关联,在获取问题单词之间潜在的语义关系的同时也能精确提取视觉目标之间的空间语义关系信息。此外,该方法能够有效地结合视觉图像中的表观特征和关系特征,从而获取更好的视觉表征。在公开数据集上的实验表明所提多模态关系注意力网络能够更好地获取多种关系信息,并在整体性能上优于现有基于关系编码的方法。(4)本论文提出了一种递进的图注意力网络以回答针对视频内容所提出的问题。该方法旨在解决现有方法只能获取单一模态之间的关系,从而不能准确表示视频中复杂场景的缺点,其包含三个用于获取不同层次视觉关系的图网络,并用一种递进的方式进行连接,能够促进视频中多种视觉语义的获取以及与文本语义的融合。此外,本论文也首次发现,在一个经典的视频问答数据集TGIF-QA中存在严重的答案偏差,为解决该问题,本文在TGIF-QA的基础上重构了一个更为平衡的数据集。最后,本文简要总结了以上研究内容,对视觉问答的未来和可继续深入研究的方向进行展望,并为之后的研究者提供了新的思路。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000641
{DOI}: 10.27005/d.cnki.gdzku.2022.000641
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的三维目标检测方法研究综述
{Author}: 张冬冬;郭杰;陈阳
{Author Address}: 陆军工程大学野战工程学院;
{Journal}: 机电工程技术
{Year}: 2022
{Volume}: 51
{Issue}: 04
{Pages}: 5-11
{Keywords}: 机器视觉;三维目标检测;点云;深度学习
{Abstract}: 作为计算机视觉的基础算法，目标检测被广泛应用于自动驾驶、智能导航、视频监控、工业检测、航空航天等诸多领域，已成为深度学习的热门研究方向之一。随着深度传感器和三维激光扫描仪的普及运用，基于点云的三维目标检测得到广泛关注，其性能也随着深度学习的迅速发展而显著提升。首先从点云的稀疏性、离散性、无序性和旋转平移不变性等自身特性入手，分析了基于点云的目标检测难点，以及将深度学习应用于三维点云面临的挑战，然后总结了基于图像视锥、基于数据降维、基于原始点云3类三维目标检测方法，介绍了近几年提出的典型三维目标检测网络，比较了每类方法的优势劣势，提炼了每类方法的工作原理和主要创新点，最后对三维目标检测未来研究方向进行了展望。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx0a-M0m4uQ_FQzlcXhzec6ioyXmiCdpngLnqVjZ6sizpQ4O6tyQkuWE1Vzdbb3T0tSsWlJbPmHmejZo5ZHrE29aUDadCFUtyFi2jokM8tqEpWpRkyS2z9xD7JA0btHLU5fru7Z7BIz4qheszC3Tabn-5EM9faSCwaMiIeakECAoG7UOZLHb15jwmPkdK5ZyO0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术的发展及应用
{Author}: 王铁胜
{Author Address}: 闽江师范高等专科学校;
{Journal}: 信息系统工程
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 63-66
{Keywords}: 计算机技术;视觉技术;技术应用
{Abstract}: 随着时代的快速发展，计算机技术在人们日常生活中随处可见，更是给各行各业的发展提供了新的动力。而在计算机的发展过程中视觉技术是其中的一项核心技术，它集中数字技术、图像技术及人工智能等多个学科的知识于一体，使信息能够以更加直观的形式呈现给人类。自计算机技术融入到人们生活以来，人类从计算机中所接受的信息有80%以上是来自于图像信息，这便是计算机视觉技术所提供的内容，它已经成为目前人类最有效的信息获取和交流方式之一。而要想使计算机视觉技术更好的发展和应用，就必须要进行对其进行简单的研究使其能够更好地在计算机中服务于人类。
{ISBN/ISSN}: 1001-2362
{Notes}: 12-1158/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy0CWUUDgxmFwe7cZWzE67V2SpdDcTLWr4OGl60Iudu-1D0LXu5nIIEFc8UmoAva4_qLirkLglgYumSi9_3OWo7Z8cumCBLB5GgrSIhECODrw68kIK6DPA72zLlKL6m4tnvb2UFBFNFIAjKuj8OxbNGpxvW6f54IjSs8b0laWJuT29ZSEfTI3nqmb-3wN1rPAs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合自注意力机制的生成对抗网络跨视角步态识别
{Author}: 张红颖;包雯静
{Author Address}: 中国民航大学天津市智能信号与图像处理重点实验室;中国民航大学电子信息与自动化学院;
{Journal}: 中国图象图形学报
{Year}: 2022
{Volume}: 27
{Issue}: 04
{Pages}: 1097-1109
{Keywords}: 机器视觉;步态识别;跨视角;自注意力;生成对抗网络(GANs)
{Abstract}: 目的 针对目前基于生成式的步态识别方法采用特定视角的步态模板转换、识别率随视角跨度增大而不断下降的问题,本文提出融合自注意力机制的生成对抗网络的跨视角步态识别方法。方法 该方法的网络结构由生成器、视角判别器和身份保持器构成,建立可实现任意视角间步态转换的网络模型。生成网络采用编码器—解码器结构将输入的步态特征和视角指示器连接,进而实现不同视角域的转换,并通过对抗训练和像素级损失使生成的目标视角步态模板与真实的步态模板相似。在判别网络中,利用视角判别器来约束生成视角与目标视角相一致,并使用联合困难三元组损失的身份保持器以最大化保留输入模板的身份信息。同时,在生成网络和判别网络中加入自注意力机制,以捕捉特征的全局依赖关系,从而提高生成图像的质量,并引入谱规范化使网络稳定训练。结果 在CASIA-B(Chinese Academy of Sciences’ Institute of Automation gait database——dataset B)和OU-MVLP(OU-ISIR gait database-multi-view large population dataset)数据集上进行实验,当引入自注意力模块和身份保留损失训练网络时,在CASIA-B数据集上的识别率有显著提升,平均rank-1准确率比Gait GAN(gait generative adversarial network)方法高15%。所提方法在OU-MVLP大规模的跨视角步态数据库中仍具有较好的适用性,可以达到65.9%的平均识别精度。结论 本文方法提升了生成步态模板的质量,提取的视角不变特征更具判别力,识别精度较现有方法有一定提升,能较好地解决跨视角步态识别问题。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyUrhIj2fHPG5ob32x355nqWrCDbI1Krh03fIcaB1re_mP5CslY7UdpWTYNmoGZxTKlC0299JFGHgOBGozAhEvIVLb3alPWx_jK5qCUhwTtRV7nYMnGbo71mHdL9I3lZLu_o35HZGi9_s_gsGFh3Yr28_F82bkj30_NDEHzp_0nWuOZw6K_yOUEJoZAmK3EB_A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金银花图像识别处理算法研究
{Author}: 郑如新;孙青云;肖国栋
{Author Address}: 南京林业大学机械电子工程学院;天津微深科技有限公司;
{Journal}: 中国农机化学报
{Year}: 2022
{Volume}: 43
{Issue}: 04
{Pages}: 153-159
{Keywords}: 机器视觉;图像处理;金银花识别;Canny算法;边缘检测
{Abstract}: 运用机器视觉和图像处理的方法可实现金银花的自动化采摘，提高采摘效率。首先通过摄像机对金银花进行图像采集，将采集到的金银花图像进行中值滤波处理，有效消除图中的噪音；然后对金银花图像进行RGB和HSV颜色分割，找出金银花与背景区分最明显的分量B;再对分量B进行阈值分割处理，设定阈值，将金银花从背景中提取出来，运用形态学运算，使图像更加饱满；最后运用Canny算法，对金银花图像进行边缘检测研究，通过对Canny算法进行改进，使之达到更好的边缘检测效果。结果表明：通过阈值分割的金银花识别率为79.17%,传统Canny算法识别率为66.67%,改进的Canny算法识别率为93.75%,能够满足后续金银花采摘机器人的实时作业要求。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2022.04.022
{DOI}: 10.13733/j.jcam.issn.2095-5553.2022.04.022
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的带钢表面缺陷检测研究进展
{Author}: 米春风;卢琨;汪文艳;王兵
{Author Address}: 安徽工业大学电气与信息工程学院;安徽工业大学电力电子与运动控制安徽省重点实验室;
{Journal}: 安徽工业大学学报(自然科学版)
{Year}: 2022
{Volume}: 39
{Issue}: 02
{Pages}: 180-188
{Keywords}: 热轧带钢;表面缺陷;检测方法;机器视觉
{Abstract}: 热轧带钢是钢铁行业的主要原材料之一，其表面质量控制一直是生产过程智能检测的重点任务。针对带钢表面缺陷自动在线检测逐步取代人工检测的现状，概述带钢表面缺陷检测方法，着重阐述基于机器视觉的表面缺陷检测方法，比较分析传统机器视觉、深度学习方法在带钢表面缺陷检测的应用，探讨带钢表面缺陷检测中存在的关键技术问题，并对其未来发展趋势做展望。传统机器视觉的带钢缺陷检测方法检测速度较高，但精度较低；主流深度学习的缺陷检测方法检测精度高，但速度较慢。如何在保证检测实时性的前提下提高算法的准确性和鲁棒性，不仅是自动化和智能化检测的发展趋势，也是基于机器视觉部署在实际工业现场的关键所在。
{ISBN/ISSN}: 1671-7872
{Notes}: 34-1254/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvySkZJM0clpSUq9C9AqYCm4ldAZpUQ24PxT77T_Eli8D2BFLb8Ao8ot2yOCuIjeRMi4apTxmynZyYnaFQFMSizbT_cNwNbNRg6DTPslyx4g3xlIjbqnlfJVKJczzK8r9RO_JlkKoHE0l7d-Z1QMlakmHWsb7AxYLHd9DgeoSsuaFq-rLPigS6gQ6kzjwGQj50w=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Two-Stage的目标检测算法综述
{Author}: 王彦雅
{Author Address}: 河北经贸大学信息技术学院;
{Journal}: 河北省科学院学报
{Year}: 2022
{Volume}: 39
{Issue}: 02
{Pages}: 14-22
{Keywords}: R-CNN;计算机视觉;卷积神经网络;深度学习;Two-stage;目标检测
{Abstract}: 近年来，深度学习领域出现了许多优秀的算法，特别是Two-Stage（两阶段）目标检测模型R-CNN(Region-CNN)的产生，基本取代了传统目标检测算法，极大地提高了检测模型的综合性能。本文详细介绍了目前流行的Two-Stage算法，并对它们的流程、特点、效率以及优缺点等方面进行了综述，最后对目标检测领域存在的问题以及未来研究方向提出了建议。
{ISBN/ISSN}: 1001-9383
{Notes}: 13-1081/N
{URL}: https://link.cnki.net/doi/10.16191/j.cnki.hbkx.2022.02.003
{DOI}: 10.16191/j.cnki.hbkx.2022.02.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉Transformer研究的关键问题:现状及展望
{Author}: 田永林;王雨桐;王建功;王晓;王飞跃
{Author Address}: 中国科学技术大学自动化系;中国科学院自动化研究所复杂系统管理与控制国家重点实验室;青岛智能产业技术研究院;
{Journal}: 自动化学报
{Year}: 2022
{Volume}: 48
{Issue}: 04
{Pages}: 957-979
{Keywords}: 视觉Transformer;图像分类;目标检测;图像分割;计算机视觉
{Abstract}: Transformer所具备的长距离建模能力和并行计算能力使其在自然语言处理领域取得了巨大成功并逐步拓展至计算机视觉等领域.本文以分类任务为切入,介绍了典型视觉Transformer的基本原理和结构,并分析了Transformer与卷积神经网络在连接范围、权重动态性和位置表示能力三方面的区别与联系;同时围绕计算代价、性能提升、训练优化以及结构设计四个方面总结了视觉Transformer研究中的关键问题以及研究进展;并提出了视觉Transformer的一般性框架;然后针对检测和分割两个领域,介绍了视觉Transformer在特征学习、结果产生和真值分配等方面给上层视觉模型设计带来的启发和改变;并对视觉Transformer未来发展方向进行了展望.
{ISBN/ISSN}: 0254-4156
{Notes}: 11-2109/TP
{URL}: https://link.cnki.net/doi/10.16383/j.aas.c220027
{DOI}: 10.16383/j.aas.c220027
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于CNN与Transformer的无人机图像目标检测研究
{Author}: 祝星馗;蒋球伟
{Author Address}: 华北计算技术研究所系统七部;
{Journal}: 武汉理工大学学报(信息与管理工程版)
{Year}: 2022
{Volume}: 44
{Issue}: 02
{Pages}: 323-331
{Keywords}: 深度学习;无人机图像检测;卷积神经网络;目标检测算法;计算机视觉
{Abstract}: 针对无人机航拍图像中存在的密集目标、背景复杂、小目标检测困难、图像尺寸大等问题，提出了卷积神经网络(CNN)与Transformer相结合的无人机图像目标检测算法。该算法在YOLOv5网络的基础上结合了Transformer结构打破了CNN感受野的局限性，凭借自注意力机制捕获全局的依赖关系。同时采用了大尺度的特征图，使用加权双向特征金字塔网络(BiFPN)增强了特征的传播与重用，让网络对小目标的检测能力大大提高。最后使用数据降维与滑动窗口的方法减少网络的内存消耗与计算量。在VisDrone无人机数据集上的实验结果表明所提算法在满足实时性的基础上，平均精确率比YOLOv5网络提高约7%,达到了最先进的42.48%,展现了模型对无人机图像的优秀检测性能。
{ISBN/ISSN}: 2095-3852
{Notes}: 42-1825/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwYRFIHxOPUmBEGzAE-q1isLi37WaeFkAkE7roddejGgDa62iSNaGUhyI1E_ppS56_iWlMSiSVwzuDkowiQKE3l6EeSgI_nTWWlvXmtgdLKWYNRKqFwLXFtOOMZxdxT1HesPvAVEHf840Lq5pPoLDXq4pNYG1_jnGhe7iPLnN9qmadTv2RCQuafOvXeNlRX__Q=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLO的动物目标检测算法研究与实现
{Author}: 沈磊
{Tertiary Author}: 王玉文
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标实时检测;空洞卷积;动物目标检测;嵌入式平台
{Abstract}: 得益于深度学习技术的飞速发展,基于深度学习的目标检测算法研究成为近几年研究的热门方向。本文将目标检测算法与动物目标检测场景相结合,基于公司实际业务场景对算法模型做针对性优化,来满足实际生产需求。本文工作重心主要集中在两个方面,一个是如何提升算法性能来提高动物目标检测分类的准确性,另一个是如何将具有巨量权重参数的目标检测算法部署在硬件性能不佳的边缘设备中。首先本文通过融合混合空洞卷积的方式,来提升对于小目标和重叠目标的检测效果,之后通过采用一种基于K-means聚类算法的通道剪枝算法,对网络模型进行了压缩,然后对数据集进行预处理并采用非极大值抑制的方法减小定位误差,为了减小设备体积,降低硬件成本和部署难度,并且针对野外场景的小目标动物检测的效果,本文提出了一种基于YOLOv4的目标检测算法M-HDC-YOLO算法。最后将检测网络框架移植到基于K210芯片设计的嵌入式平台上,达到了实时检测的目的。本文主要工作如下:1.对于YOLOv4算法在小目标检测的性能上进行优化,提出了HDC-YOLOv4算法,采用混合空洞卷积替代原本卷积层,在较少参数量的情况下,通过获取更多的特征图来实现算法精度的提升。2.针对现有模型产生的权重文件过于庞大,计算量远超硬件平台的限制,本文通过压缩算法对模型进行瘦身,压缩率达到了80%,通过硬件平台模型转换最终被移植到边缘设备的模型大小只有4M左右,可以很好被硬件平台所支持。实验结果表明,本文所应用的动物目标检测算法,可对在野外场景下收集的10类动物进行正确的判断,在仅损失较少精度的情况下,保持较高的网络压缩率和识别速度。在RTX3090硬件平台上,模型经过压缩后,m AP可达到89.26%,FPS可达112;移植到K210硬件平台上,m AP为68.63%,FPS为14,可以达到实时检测的基本要求,完成了动物目标检测的嵌入式实现。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.001482
{DOI}: 10.27005/d.cnki.gdzku.2022.001482
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种机器视觉巡线避障小车的设计
{Author}: 欧寒芝;匡盈霏;丁慧玉;陈慧;龙慧
{Author Address}: 长沙师范学院信息科学与工程学院;
{Journal}: 电脑与信息技术
{Year}: 2022
{Volume}: 30
{Issue}: 02
{Pages}: 13-17
{Keywords}: 智能小车;图像二值化处理;超声波检测
{Abstract}: 提出了一种基于STM32f103rct6嵌入式微处理器的图像识别智能小车模型,可应用于勘测领域。通过摄像头进行信息采集和图像识别，配合小车液晶监控系统，能够实时接收搭载的OV7670摄像头传输的二值化处理后的视频和图像，对前方路径情况进行监控。同时，为避免小车行驶过程中发生碰撞，利用超声波技术测距避障。经过实际的调试和运行,结果表明小车系统能较好地执行完成视觉巡线和自动避障任务。
{ISBN/ISSN}: 1005-1228
{Notes}: 43-1202/TP
{URL}: https://link.cnki.net/doi/10.19414/j.cnki.1005-1228.2022.02.023
{DOI}: 10.19414/j.cnki.1005-1228.2022.02.023
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属表面缺陷检测方法研究与系统实现
{Author}: 叶鑫龙
{Tertiary Author}: 徐尚龙
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 缺陷检测;图像分类;目标检测;机器视觉
{Abstract}: 由于金属工业产品生产过程中各种因素的影响,金属工件表面可能会存在一些表面缺陷。这会降低材料强度,缩短工件寿命,并且增加安全风险。因此需要对金属产品表面进行质量检测,这也是保证工业生产质量的关键环节。与传统人工检测相比,基于机器视觉的表面缺陷检测方法具有速度快、精度高等优点。本文以金属插头表面缺陷识别为研究课题,针对金属表面缺陷图像质量低、缺陷复杂等问题,探索机器视觉中图像预处理、缺陷分类和缺陷目标检测等方面的有效方法,最后形成一套高速、高识别精度的金属表面缺陷检测系统。在图像预处理方面,在分析了图像噪声情况的基础上,对比了4种基于滤波器的去噪方法的处理效果。结果表明,中值滤波的方法对该类型图像的处理效果最好,去噪速度最快。接下来,采用边缘检测的方法分割出金属表面图像感兴趣区域(Region of Interest,ROI),完成预处理操作。在缺陷分类识别方法研究方面,首先,针对经过预处理的金属插头表面图像,提出了一种基于连通域分析的缺陷识别方法。结果表明在金属插头原始图像数据集上整体分类准确率为89.60%。然后,针对基于连通域分析方法适用范围较小和依赖于人工设置阈值的问题,提出了基于PSO-SVM(粒子群优化的支持向量机)模型与基于Ghost Net模型的表面缺陷分类方法。同时,引入NEU-CLS数据集用于对比不同方法的缺陷分类识别能力。结果表明基于Ghost Net模型的识别方法缺陷分类能力较好,分类准确率达到了99.43%。在缺陷目标检测方法研究方面,引入NEU-DET数据集。针对YOLOX-S模型在缺陷数据集上检测存在的问题,提出了改进损失函数与添加注意力机制模块的优化措施。结果表明,采用EIOU＿Loss损失函数的YOLOX-S模型在NEU-DET数据集上的目标检测性能指标最好,m AP(mean Average Precision)达到了79.17%,检测速度为71 fps。将研究的表面缺陷分类方法与目标检测方法应用于自制金属插头数据集上,分类准确率达到了99.44%,m AP达到了93.34%。最后,配合图像采集设备组成检测系统,满足多个层次的金属插头表面缺陷检测需求,该检测系统能够有效地识别出表面缺陷。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.002260
{DOI}: 10.27005/d.cnki.gdzku.2022.002260
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习与机器视觉的装配机器人关键技术研究
{Author}: 马兆昆
{Tertiary Author}: 陈东
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 装配机器人;零件识别定位;机器视觉;深度学习
{Abstract}: 装配作业决定着产品的质量水平、工作性能和后期维护难易程度等一系列属性,所以在制造业体系中占据着重要地位。对比人工操作的流水线装配作业,装配机器人具有作业稳定性高和生产效益高的巨大优势,目前装配机器人控制方式仍以示教或离线编程为主,系统的灵活性较差、示教工作量较大以及对不同零件尤其是堆叠遮挡零件的识别定位准确率较低。针对上述问题,本课题将深度学习、机器视觉与装配机器人结合使用,提高了装配系统对不同零件的识别定位准确率,对促进未来装配机器人高速化和智能化地发展具有重要理论研究价值。本文针对基于深度学习与机器视觉的装配机器人关键技术研究如下:(1)论述了工业机器人自动化装配作业中零件识别定位工作的重要性,选用五种常见工业零件作为识别定位的目标,通过分析待识别零件的两种来料情形以及结合实际生产效益,针对零件无堆叠遮挡的情形,选用基于模板匹配的方法进行研究,针对零件存在堆叠遮挡的情形,选用基于深度学习的方法进行研究。设计并搭建了基于单目视觉识别定位的装配机器人系统平台,完成了对机器人模块和视觉模块的设计和选型,使用张氏标定法获取单目视觉成像模型中的相机参数,并使用九点标定法建立本文所选直角坐标机器人与单目相机的坐标变换关系。(2)针对无堆叠遮挡情形下的零件识别与定位,选取螺母和两种定制垫圈作为研究对象,提出的改进Retinex增强算法解决了螺母边缘低对比度问题,使用改进双边滤波能够较好地平滑零件图像,对PIO算法进行改进并将其应用于快速求取阈值分割的最优阈值,为后续提取和匹配垫圈零件轮廓特征做准备。选用性能稳定的基于Hu矩轮廓匹配方法实现了对两种垫圈的准确识别,并根据两种垫圈的结构特性设计了相应的位姿确定方法,最终可求解得到不同垫圈对应的质心坐标和旋转角度。(3)针对存在堆叠遮挡情形下的零件识别与定位,采用深度学习目标检测中的YOLO算法进行处理,通过分析算法不同版本的改进和不足,最终基于最新的YOLOv5算法进行研究和改进。针对YOLOv5算法如何在保持检测精度不变情况下实现降低网络模型的参数量和运算量的问题,使用基于Ghost Net的网络模块对其进行轻量化改进;针对YOLOv5算法检测堆叠遮挡零件的性能仍存在欠缺的问题,引入混合域注意力机制CBAM和改用滤除准则更为友好的DIo U-NMS对其进行感受野和预测框方面的改进。通过在自制零件图像数据集上对改进前后的算法进行训练和测试,发现本文改进算法在轻量化网络模型的同时仍较原始算法在m AP上有1.2%的检测精度提升,最终能够在模拟的不同来料情形下实现准确的零件检测。(4)针对目前公开数据集中有关工业零件的图像数量较少的问题,通过网络收集了2243张常见工业零件的图像,然后自行制作了包含有螺母、螺栓、垫圈、齿轮和联轴器的零件图像数据集,为进一步提高零件图像的色彩丰富性和位姿丰富性,使用基于仿射变换和色彩变换的数据增强方法将自制零件数据集扩增到7200张。通过扩充数据集,本文提出的改进YOLOv5网络模型在训练时没有出现过拟合现象,并有效保证了训练得到的网络预测模型的检测精度。(5)使用C#Winform程序结合OpencvSharp视觉库对系统上位机软件进行界面设计和算法封装,完成了相机模块、标定模块和零件识别定位模块的开发,最终利用矩阵关系将零件图像处理结果变换为机器人坐标,对零件的定位精度可达0.25mm。使用改进YOLOv5算法对采集的包含不同零件的测试集进行检测,实验表明,检测模型对堆叠遮挡零件测试集的平均识别准确率能够达到83.8%。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2022.000185
{DOI}: 10.27264/d.cnki.gqdhc.2022.000185
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器人与机器视觉的垃圾分拣系统设计
{Author}: 梅志敏;陈艳;胡杭;张融
{Author Address}: 武昌工学院机械工程学院;绿色风机制造湖北省协同创新中心;武汉轻工大学机械工程学院;
{Journal}: 机械设计与制造
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 275-278
{Keywords}: 机器视觉;机器人;垃圾分类
{Abstract}: 随着人工智能和机器人在自动化生产线广泛应用，无人化、智能化为其提供了有力技术支撑。垃圾分类和再利用是当今亟待解决的社会问题，本研究结合机器视觉和机器人优势，基于Halcon的图像处理平台和IRB1410机器人的运控载体，对固体流通商品按国家分类标准进行分拣。重点研究机器人逆运动学算法、垃圾外包装条码实时采集、数字图像处理、数据传输及机器人分拣等内容。试验结果表明：（1）随机商品条码识别与数据库匹配平均时间0.002s;(2)可回收垃圾和有害垃圾分拣率100%、干垃圾分拣率达97.0%。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.2022.04.008
{DOI}: 10.19356/j.cnki.1001-3997.2022.04.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合注意力机制的个体猪脸识别
{Author}: 谢秋菊;吴梦茹;包军;尹辉;刘洪贵;李欣;郑萍;刘文洋;陈刚
{Author Address}: 东北农业大学电气与信息学院;农业农村部生猪养殖设施工程重点实验室;东北农业大学动物科技学院;朝阳市建平县畜牧技术推广总站;朝阳市凌源市种畜场;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 07
{Pages}: 180-188
{Keywords}: 机器视觉;图像处理;注意力机制;猪脸识别;DenseNet
{Abstract}: 随着机器视觉技术的发展，猪脸识别作为猪只个体识别方法之一受到广泛关注。为了探索非接触式的猪只个体精准识别，该研究通过深度学习模型DenseNet融合CBAM(ConvolutionalBlockAttentionModule)，建立改进的DenseNet-CBAM模型对猪脸进行识别。将DenseNet121模型进行精简，然后将CBAM注意力模块嵌入到精简的DenseNet121分类网络之前，以加强对关键特征的提取，实现猪脸图像的分类。以随机采集的1 195张猪脸图像作为数据集对本文模型进行测试。结果表明，DenseNet-CBAM模型对个体猪脸识别的准确率达到99.25%，模型参数量仅为DenseNet121的1/10；与ResNet50、GoogLeNet和MobileNet模型相比，DenseNet-CBAM的识别准确率分别提高了2.18、3.60和23.94个百分点。研究结果可为智能化养殖过程非接触式个体识别提供参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzK_JcR9iz6WITz02aIFuMWdWhJZBTobu8dNuSe_dhhKjsiJJ8Xrihsv-MVBQ_YG8YOHyrfU_ldYd4-t_JkpZGDmy-4Z0lTdF2ZuxR_PE6u6mcB88COpJ3kBlTvNsKVXVP8zPCLoK1ZqOPY-RZGL-pmHgG1pRQcTYjDzVtBgu1VKkIGPXGMwzoh8WCNru7sggs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工业机器人目标定位及检测系统研究
{Author}: 潘广耀
{Tertiary Author}: 于镭
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;工业机器人;图像处理;目标定位;目标检测
{Abstract}: 随着机器视觉技术的发展,机器人变得更加智能化。由于视觉传感器能够为工业机器人提供更加完整的环境信息,同时具备非接触测量等优势,因此为工业机器人配备视觉系统成为了相关领域的重点研究课题。在此背景下,本文针对角磨机圆形控制器外壳工件的定位与检测,设计了一套基于机器视觉的工业机器人目标定位与检测系统,对精确定位和非接触式检测工件的方法进行研究,并搭建了基于机器视觉的工业机器人实验平台。首先,设计系统整体方案,并完成了实验平台的硬件选型。研究相机成像模型与各坐标系转换关系,完成相机标定,并获取到相机的内外参数与畸变参数,最后通过实验完成了视觉系统的标定。其次,在对目标工件的定位与检测中,研究了Blob分析与模板匹配两种定位方法,选取定位精度较高的模板匹配法用于工件的粗定位。在此基础上,对比了基于最小二乘边缘拟合算法与卡尺边缘拟合算法对工件定位与测量的精度。最终提出一种模板匹配结合卡尺边缘拟合的方法,对目标工件实现精确定位与非接触式检测。经实验验证,定位精度可达毫米级。最后,采用多线程设计思路,使用HACLON联合C#编程,开发了机器视觉定位检测系统软件。基于相机SDK设计了图像采集模块,并调用HALCON导出的图像预处理、定位与检测算法实现对工件的位置获取、尺寸测量,再使用网络通讯结合自由协议与ABB机器人实现通讯,完成模拟抓取实验。实验结果表明:本文设计的基于机器视觉的工业机器人目标定位与检测系统,实现了对圆形目标工件的自动精准定位和内外径的非接触精确检测,并控制工业机器人进行下一步的模拟抓取动作,为工业生产提供了可靠的自动定位与检测方法,同时也为相似的工业应用场景提供了研究思路,具有一定的现实参考意义。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2022.000452
{DOI}: 10.27264/d.cnki.gqdhc.2022.000452
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 相机标定的精度影响实验分析
{Author}: 翟溢章;宿洁华;张士恒;吴恩启
{Author Address}: 上海理工大学机械工程学院;库柏电子科技(上海)有限公司;
{Journal}: 电子设计工程
{Year}: 2022
{Volume}: 30
{Issue}: 07
{Pages}: 82-86
{Keywords}: 机器视觉;相机标定;精度;误差;因素分析
{Abstract}: 相机标定是机器视觉中的必要步骤，标定效果直接影响后续的测量精度。在张正友标定方法的基础上，对棋盘格尺寸、标定图片数量、棋盘格打印方式3个方面进行实验分析，实验过程中通过控制变量法进行对比实验。实验结果表明，棋盘格尺寸选择10～15 mm时标定效果较好；当棋盘格角点数目相同时，棋盘格尺寸越大，标定所需的图片数量越多；当棋盘格尺寸相同时，角点数目越多，标定所需的图片数量就越少；彩印的标定棋盘格在有效焦距、主点坐标以及重投影误差方面都比普通打印的精度高，且与实际值的误差维持在5个像素内，波动较小。实验结论为提高相机标定精度提供了有效参考。
{ISBN/ISSN}: 1674-6236
{Notes}: 61-1477/TN
{URL}: https://link.cnki.net/doi/10.14022/j.issn1674-6236.2022.07.017
{DOI}: 10.14022/j.issn1674-6236.2022.07.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉技术的非接触测量精度优化研究
{Author}: 邓伟伦;于涛;詹洪陈;丁尧
{Author Address}: 南京大学金陵学院信息科学与工程学院;中国·福州物联网开放实验室;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 05
{Pages}: 118-123
{Keywords}: 图像处理;非接触测量;图像增强;机器视觉;超分辨重建
{Abstract}: 针对精密加工行业零件形位公差在线检测实时性不高并且无法同时检测多个零件的问题，采用机器视觉技术，改良了相机采集图像的图像预处理流程与测量方法，提出一种基于CNN的超分辨重建的非接触测量改良算法。相较于其他超分辨率重建算法该算法模型简单，精度较高，速度快，在资源受限的情况下可以兼顾测量精度和效率。为了验证所设计算法的可靠性，设计了一套机器视觉的非接触测量系统。实验结果表明，改良测量方法后测量精度较之前使用的测量方法至少可提高47.86%,平均提高49.67%;该超分辨率算法在分辨率一定的基础上，对原始采集图像的超分辨率重建提升图像分辨率后，测量精度较不使用超分辨率重建提高了60.38%,最后利用该算法实现对多个目标在线同步测量分析，并且精度不低于同分辨率下单一零件检测精度。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108489
{DOI}: 10.19651/j.cnki.emt.2108489
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的芯片字符识别系统
{Author}: 杨桂华;唐卫卫;戴志诚;卫嘉乐
{Author Address}: 桂林理工大学机械与控制工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 05
{Pages}: 105-110
{Keywords}: 机器视觉;HALCON;灰度值投影;字符分割;字符识别
{Abstract}: IC芯片表面的字符主要包括厂商名称和序列号，这些字符对于芯片的制造和应用具有重要现实意义，针对芯片表面印刷字符的检测，基于HALCON视觉软件开发平台研发了一套芯片字符识别系统。首先，采用灰度值投影法获得字符区域的行和列坐标分割点，进行字符分割。然后，利用形状匹配技术对欲检测芯片图像进行定位与校正，采用BP神经网络分类算法实现字符的识别。通过不同算法的对比实验分析，实验结果表明单张图片检测时间为42 ms,完整字符与缺陷字符的分割准确率均为100%,字符识别率达到99.5%。本系统能有效快速、准确的对IC芯片表面字符进行识别，检测精度满足要求。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108506
{DOI}: 10.19651/j.cnki.emt.2108506
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于嵌入式人工智能的人体姿态识别研究与实现
{Author}: 伏娜娜
{Tertiary Author}: 刘大铭
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人体目标检测;OpenPose;模型轻量化;嵌入式系统;人体姿态识别
{Abstract}: 人体姿态估计(Human Pose Estimation)作为计算机视觉领域的一个重要分支,在人机交互、体感游戏、运动预测以及医疗康复等领域得到广泛的应用。其目标是检测出图像中人体各部位的骨骼关键点并将这些点连接形成人体姿态骨架,是人体动作特征中很重要的一种表征,尤其是在视频数据中,可以通过将多帧的人体姿态串联在一起形成某种动作轨迹。因此,越来越多的研究人员会把时间和经历投入到该方面的研究中来。其中,基于OpenPose的人体姿态识别存在模型结构大、计算复杂度高,使得网络检测速度慢以及不易部署在边缘设备等问题。因此,为了能够在边缘设备上实时识别出人体动作姿态,本文主要从两个方面进行了研究:一方面,为了网络在运行时能够达到实时标准,在网络层面上利用轻量级网络对人体姿态估计网络进行改进,以减少模型的计算量。另一方面,为了减轻服务器端计算压力,在边缘设备Jetson Xavier NX上运行人体姿态识别模型。本文的最终目标是将基于嵌入式系统的人体姿态识别模型应用到现实场景中。具体工作主要包括以下几点:(1)为了解决OpenPose算法在无人区域存在误检出人体骨骼关键点的问题,本文提出了在人体姿态估计之前先进行人体目标检测的方法。即先检测出图像中目标人体的位置并将其框出,再将框出了人体的图像输入到人体姿态估计网络中进行人体关键点检测。(2)将摄像头实时捕获的数据输入到人体姿态估计网络中提取每一帧中人体的18个关键点的坐标信息,对坐标数据做归一化处理,并采用COCO数据集的格式对动作姿态类别进行标定,形成包含37列数据的csv文件数据集。该数据集一共有24276条数据,包含11类动作姿态,有站立、跑步和踢腿等,并用该数据集训练人体动作姿态识别模型。(3)针对OpenPose模型结构大、参数量多等特点,提出了一种轻量化的人体姿态估计算法。用轻量级MobileNet网络中的深度可分离卷积替换原OpenPose模型中的标准卷积,减少网络的参数量,提升检测速度。同时为了验证改进算法的有效性,做了基于OpenPose、改进OpenPose以及MediaPipe Pose的人体姿态识别实验,通过比较分析,基于轻量级OpenPose的人体姿态识别在识别准确率和实时性方面均表现良好。(4)为了减轻服务器端计算压力,在边缘设备上识别人体动作姿态。在Jetson Xavier NX平台上安装操作系统、搭建运行环境,将人体姿态识别模型移植到该平台上,通过实验测试验证了该模型在边缘设备上运行的效果,可基本满足检测实时性要求。并针对意外摔倒对老年人造成的伤害,本文也进行了摔倒检测实验,实验验证了人体姿态识别模型可以有效的识别出摔倒动作并进行报警。因此,能够将该模型应用到对独居老人摔倒检测的现实场景中。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2022.001592
{DOI}: 10.27257/d.cnki.gnxhc.2022.001592
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人体异常行为识别
{Author}: 谭金鸿
{Tertiary Author}: 陶冰洁
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人体异常行为;深度学习;行为识别;监控平台
{Abstract}: 随着人们安全意识的逐步提高,基于视频监控的人体异常行为识别技术研究得到了广泛关注。人体行为识别作为计算机视觉领域的研究热点之一,相关的研究成果不断增多。总体可以将这些人体行为检测算法划分为两大类,首先是传统的检测算法,此类算法依赖于手工方式提取特征,另一类则是近年来备受瞩目的基于深度学习方法的自动提取特征。由于传统的视频监控系统,需要大量的人力财力支撑,耗费大量时间去做异常筛选,已经不满足当下社会的迫切需求,所以需要开发一种拥有智能化行为识别的系统。本文针对复杂多变的环境下人体异常行为的识别,在深度学习算法模型进行优化,并开发了一套行为分析平台系统以弥补传统视频监控平台缺陷。具体工作如下:1.基于YOLOv5算法模型,提出了YOLO-Ghost Net-SE网络模型用于人体异常行为识别,并取得了显著效果。通过Ghost Bottleneck层替换原有的CSP Bottleneck with 3 convolutions网络层,同时新增了注意力机制SE(Squeeze-andExcitation)模块。实验得出此网络模型相比于官方YOLOv5s网络,其模型参数量减少36%。2.基于当下优秀的Transformer网络模型,借助于其强大的自注意力机制(Self-Attention),建立YOLO-Transformer模型。最后得到的网络模型平均精确度(m AP@0.5)有所提高,网络参数减少20%,网络层深度减小,计算速度进一步提高。3.由于当下许多开放数据集仅仅是对行为进行分类,并没有对行为进行异常的定义,因此本文自制了不同场景下的数据集,包括图像收集、筛选、数据标注、数据增强和数据集格式转换,最后得到两个数据集:smoke-mask数据集和打架数据集。4.设计开发了一套基于C/S的兼容性的人体行为分析系统。本系统可以通过图片、视频以及监控视频实现实时的识别效果,并具有高效的普适性,可以根据不同场景,训练不同的数据集得到权重文件,从而识别其定义的异常行为。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003927
{DOI}: 10.27005/d.cnki.gdzku.2022.003927
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的垃圾分类识别系统研究
{Author}: 蔡昊辰
{Tertiary Author}: 曹新莉;张军
{Publisher}: 武汉工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 垃圾分类;计算机视觉;特征融合;卷积神经网络;YOLO算法;注意力机制
{Abstract}: 目前,垃圾分类已成为社会热点话题。我国在推行垃圾分类的过程中,普遍存在不愿分、不会分、不能有效回收等问题,使得垃圾分类难以真正落地。北京、上海等多个城市已经严格执行垃圾分类制度并出台管理办法和条例,一场让垃圾分类成为新时尚的浪潮就此展开。随着人工智能的发展,借助计算机视觉对垃圾进行自动化分拣是一种有效的解决办法。因此,论文对个人投放垃圾和各种垃圾混杂分拣这两种应用场景,提出了基于计算机视觉的垃圾分类识别系统的研究。具体研究内容如下所述。首先,论文介绍了垃圾分类的研究背景和意义,从传统的垃圾分类方法和基于计算机视觉的垃圾分类这两方面对研究现状进行论述,并对论文所要研究的内容进行概括。其次,论文针对个人投放垃圾这种应用场景,建立了单目标垃圾数据集。依据垃圾“四分类”方法,将生活垃圾可分为有害垃圾、可回收垃圾、厨余垃圾和其他垃圾这四类。从这四类中选取具有典型代表的20个小类垃圾建立子类别,总共有8000多张垃圾图片,分别采用基于特征融合的分类识别算法和基于卷积神经网络的分类识别算法对数据集进行训练、测试。实验结果验证了卷积神经网络对垃圾图像有更好的识别效果。再次,针对各种垃圾混杂分拣这种应用场景,论文进一步研究了在同一张图像中对多种垃圾的检测识别,构建了以实地拍摄的垃圾照片为主的多目标垃圾图像数据集。采用YOLO算法对多目标垃圾图像识别检测,通过实验对比YOLO v3和YOLO v4在多目标垃圾图像数据集上的性能差异。同时引入注意力机制对YOLO v3进行改进,并与原始模型就训练和测试结果进行分析,验证了引入注意力机制对YOLO算法有增强效果。最后,利用PyQt5开发了垃圾分类检测系统,并对训练得到的YOLO算法的权重模型进行测试和应用。经过系统测试,表明系统功能都能正常运行,满足系统工作需求。
{URL}: https://link.cnki.net/doi/10.27727/d.cnki.gwhxc.2022.000009
{DOI}: 10.27727/d.cnki.gwhxc.2022.000009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进U-Net神经网络的图像去噪算法
{Author}: 姜旭;赵荣彩;刘勇杰;宋雯琦
{Author Address}: 河南省超级计算中心;郑州大学信息工程学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 09
{Pages}: 3629-3635
{Keywords}: 图像去噪;U-Net神经网络;多特征融合;跳跃连接;计算机视觉
{Abstract}: 针对目前常见的U-Net网络结构以及现有的图像去噪算法在去除图像噪声时，处理后得到的图像较为模糊且图像的边缘纹理过于光滑缺乏真实性的问题，提出了一种改进的U-Net网络结构去噪算法。它由去噪模块以及边缘信息提取模块组成，首先，利用U-Net++中的跳跃连接应用到原始的U型去噪子网中，密集连接的U型去噪网络可以减少编码器与解码器特征映射之间的语义差距，还原出更清晰的图像。其次，基于VGG-16网络结构的边缘信息提取模块对去噪网络处理后的图像进行特征提取，同时反向优化U型去噪模块，还原出更真实的图像。实验表明，在常见的Set5、Set12、Kodak24和CBSD68数据集测试所提出的算法，在图像的客观评价指标上均优于目前具有代表性的去噪算法，同时图像的边缘细节和纹理特征更清晰真实，视觉效果上更好。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxFLmFK_oy6HK4muh47J6TJSycpOBverDbTy-GMNo3khOU2FnDrltceE3A__6xglD0GRnZDut4ux3bH_DE37KlgOlGA0-jn-poGD9zw8jSbtTGdB5e-FMos2DVDxm_ukrNe6ZtPycP1wMOVLAS4t5byYBWRhm8fpDnJc189t5X21L-rhGU9C5VPJLZO7opBk68=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的车道线检测研究进展综述
{Author}: 赵强;王瑞;朱宝全;李哲煜
{Author Address}: 东北林业大学交通学院;
{Journal}: 计算技术与自动化
{Year}: 2022
{Volume}: 41
{Issue}: 01
{Pages}: 34-40
{Keywords}: 车道线检测;机器视觉;特征检测;模型检测;深度学习
{Abstract}: 针对车道线检测技术在车道偏离预警、自动泊车和车道变换等各种辅助驾驶系统中的重要作用，国内外专家学者对车道线检测技术做了较多的研究，但是近年来少见有关于车道线检测的综述，因此本文主要阐述了近几年国内外机器视觉的车道线检测研究进展。首先简单介绍了机器视觉的车道线检测的基本流程；其次重点阐述了基于特征、基于模型和基于深度学习三种典型方法的基本检测原理和研究现状，并对比三种典型研究方法；最后，提出了机器视觉的车道线检测方法主要存在的问题，并针对问题提出未来的发展方向。
{ISBN/ISSN}: 1003-6199
{Notes}: 43-1138/TP
{URL}: https://link.cnki.net/doi/10.16339/j.cnki.jsjsyzdh.202201007
{DOI}: 10.16339/j.cnki.jsjsyzdh.202201007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在包装行业研究进展与应用综述
{Author}: 王耀南;刘学兵;张辉;周显恩
{Author Address}: 湖南大学机器人视觉感知与控制技术国家工程研究中心;
{Journal}: 包装学报
{Year}: 2022
{Volume}: 14
{Issue}: 02
{Pages}: 1-14+107
{Keywords}: 机器视觉;包装技术;质量检测;工业应用
{Abstract}: 基于机器视觉的包装检测技术，通过视觉成像和计算机信息处理，完成包装的识别、检测和测量等任务，相比传统的人工检测方式，其具有执行速度快、精度高、重复性好等特点，可显著提高产品包装自动化程度，因而近年来广泛运用于食品饮料、医药、3C电子产品、物流和烟草等领域的包装检测。为进一步提高其在包装领域的实际应用效能，基于机器视觉的包装检测技术，亟待解决通用高质量视觉成像难、检测与识别算法开发效率低、人工智能应用推广慢、高复杂度任务应用难等突出问题。
{ISBN/ISSN}: 1674-7100
{Notes}: 43-1499/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyScdfNpWOCH_B45XIIobxjMexKpbzP4UkH3O3Yj7h3bo85ty77SLcjwPF5fL_BIGv019OtcHmJsIuphik5H9ywe4ug3iAEqSZTCH920oW5GTx84TLrM0QVWezR3oXgxjy_zg_rTv8LF1YTPKUxJqT7P14yX9LpIMArMYwjAs2GFxxCAcr596_Lj3i_ZeDJFbE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的草莓采摘机械手设计
{Author}: 宁彤;张燕;梁栋;吴超
{Author Address}: 海南大学机电工程学院;
{Journal}: 海南大学学报(自然科学版)
{Year}: 2022
{Volume}: 40
{Issue}: 03
{Pages}: 287-293
{Keywords}: 草莓;采摘;机械手;机器视觉;SOLIDWORKS
{Abstract}: 设计了一种智能草莓采摘机械手.首先通过SOLIDWORKS三维建模方法建立整机模型；其次对传动丝杠、采摘道具等关键部件进行设计与分析，并用SOLIDWORKS simulation软件进行有限元分析，得到其真性频率符合要求；最后通过运用机器视觉技术，对草莓果实成熟时期进行图像采集与特征提取，运用均值滤波法进行图像降噪处理，最终使采摘机械手能够自动识别和定位成熟草莓果实并进行采摘作业.
{ISBN/ISSN}: 1004-1729
{Notes}: 46-1013/N
{URL}: https://link.cnki.net/doi/10.15886/j.cnki.hdxbzkb.2022.0034
{DOI}: 10.15886/j.cnki.hdxbzkb.2022.0034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能导盲杖
{Author}: 左炳辉;范志文;邱宇
{Author Address}: 青岛理工大学信息与控制工程学院;
{Journal}: 自动化技术与应用
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 150-152+191
{Keywords}: 智能导盲杖;树莓派;OpenCV;障碍物检测;百度AI开放平台
{Abstract}: 为解决盲人出行难的问题，设计了基于机器视觉的智能导盲杖。本设计以机器视觉为研究重点，利用OpenCV技术，可按照使用者的需求，对障碍物进行识别。对于避障环节，使用超声波测距模块、红外光电传感器模块和蜂鸣器相搭配的方案，可提醒使用者附近是否有障碍物。导盲杖还搭载有GPS模块，能对使用者的当前位置进行精准定位。同时，配备有SIM800C模块，可在使用者发生紧急情况时，快速与家人取得联系。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxxVHGDQ79homjudnLbYUESkuhRW427EDyzqGFIFMt8rEWubEEUtGEMNBEeAN_eyHRZcLuASMsFA6NJK4xlpF9N4V1V2tNyOwzbV-K66Ekf4cYd6NcEHHP0BcCKHpRwxnkpywsGW7YeAaZhwCkjxtCgGZRm-VQuM3MTRL1bkpx_RVB4yVI_Nfu9N5lcV7i19tM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉引导的工业机器人无序抓取系统设计
{Author}: 王连庆;钱莉
{Author Address}: 上海工程技术大学机械与汽车工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 03
{Pages}: 86-89+196
{Keywords}: 机器视觉;图像处理;CCD相机;手眼标定;视觉定位技术
{Abstract}: 随着近些年“智能制造”理念的提出，自动化工厂对于无人数字化生产的需求越来越多。过去的技术早已不能满足如今工厂的要求。随着工业机器人与机器视觉行业迅速发展，大大降低了生产中的人工参与度，实现了真正意义上的无人化工厂，视觉行业的出现也扩大的工业机器人的应用领域，对整个自动化行业逐步走向智能化有着十分重要的作用。构建了一套针对无序来料的定位系统，该系统可以引导机械手对无序物料精确抓取，并进行有序摆放。整个系统由机械手、CCD相机、计算机，光源及软件算法构成。首先通过标定获取相机的内外参，机械手和相机之间的转化矩阵，其次通过光源配合CCD相机对物料，物料盒进行取像，利用图像处理算法，定位算法，对物料和物料盒进行定位。将定位结果通过通讯协议传输给机械手端，机械手完成对物料的无序抓取与有序摆放。最后我们通过雅马哈YK500-600XGL机械手，大华工业相机，研华工控机进行实验，实验结果符合预期期望。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw7B-UZVZg_OqMcKZED5NfCsRUdK-OJYAXOziF6eJcuds2RIDn7cpQ7BtC99iduQ5KnodQZo-tozlZAe7XLNkxFBXLIA2Y64Y_87I8nfoImKTmF2DEImr_i4i_w2qxu4fLPqy4XdSQwh2pePLCdIbyUN8hhJA95KfEAGdDXM37S9LCE19C05eTDs_WthUG_f-Q=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的目标检测算法综述
{Author}: 王树贤;翟远盛
{Author Address}: 江西理工大学电气工程与自动化学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 06
{Pages}: 67-69
{Keywords}: 目标检测;深度学习;卷积神经网络;计算机视觉
{Abstract}: 目标检测技术应用非常广泛，主要用于识别以及定位图像中的物体，是发展较快的一种技术。在广泛文献调研的基础上对大量检测算法进行了研究，对各种主流网络框架的结构、优缺点作出综述，从两阶段、一阶段两种范式对不同模型的原理、优点等进行了分析，对常用数据集进行了简单介绍，并对其未来发展趋势给出了合理的分析预测。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzhGPmiUKpEDK-O0l0LMKdPwy2v2oFMbfUAi170SBl8ngREqvICMaC0en9MYD39JNEIrhrVlMbWvKr1suj-SImwBN35iKxh-FF02KFvdh1yh70KTET6bixuMKzEOJ_OBVDm450c-gRZz0zHskMuuGRQNnLD41qkbYmg-bf1OEbXR7l9gaq6m9Z6OYgj-V6CEDo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 无监督领域自适应目标检测方法研究
{Author}: 张丹
{Tertiary Author}: 叶茂
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标检测;无监督领域自适应;注意力机制;对抗学习;知识蒸馏
{Abstract}: 目标检测是计算机视觉、人工智能等领域的重点研究方向之一。该方向的主要任务是对图像中多个感兴趣的目标进行定位和识别。目标检测技术的研究成果广泛应用于行人检测、人脸识别、遥感检测和车辆检测等领域。传统的目标检测方法总是假设训练数据和测试数据遵循相同的分布,但现实生活中很难满足这种假设,因为训练数据和测试数据通常是在不同的环境中进行收集的。为此,领域自适应目标检测方法被提出用来解决分布不一致场景下的目标检测问题。然而,另一个现实问题是,由于数据隐私性和数据传输等问题,很多情况下源域模型在完成训练后便无法访问源域数据。针对这两种情况,本文对无监督领域自适应目标检测的有源及无源两个问题进行研究。对有源问题而言,本文分别从源域数据是单源数据还是多源数据这两个角度展开研究工作。在单源的情况下,主要研究如何保证在特征空间自适应过程中语义的一致性及如何处理具有不同迁移性的图片及图片上的目标来避免“负迁移”。在多源的情况下,研究如何充分利用多个源域的知识及如何将多个知识进行融合来提高检测模型对目标域的检测准确度。对无源问题而言,本文主要研究如何在只有源域训练好的模型而无法访问源域数据的场景下利用模型内隐含的风格信息和知识蒸馏的框架进行领域自适应。本文的主要工作及贡献总结如下:(1)为解决单源领域自适应目标检测在域自适应过程中丢失语义信息的问题,本文提出了循环一致性域自适应目标检测方法。首先,将源域的特征转换到目标域,并对齐转换后的源域特征和目标域特征。同时目标域的特征也经过类似操作。然后,优化循环一致性损失来保证样式在转换过程中两个域之间的语义一致性。最后,使源域特征等价于源域生成器输出的源域重构特征,并对目标域特征也进行同样重构操作,来优化源域和目标域的生成器。实验表明,该方法通过对齐转换后的源域特征和目标域特征及源域特征和转换后的目标域特征,能够有效地保留在域自适应过程中的语义信息。(2)为解决单源领域自适应目标检测直接对齐源域和目标域的图片和目标造成的“负迁移”问题,本文提出了基于注意力机制的局部和全局的领域自适应目标检测方法。首先,提出全局的注意力机制来突出和加权可迁移的图片,用来缓解由于直接全局对齐不当造成的“负迁移”。然后,在包含像素,纹理等信息的浅层特征空间中实现两个域之间的强匹配,在未破坏语义信息的条件下缩小了跨域差异。最后,对于较大域差异的图像,利用注意力机制将更多的注意力集中在目标上同时忽略背景信息,来提高模型的性能。实验表明,该方法通过有区别地对待具有不同迁移性的图片和目标来改进域自适应过程,有效地缓解了领域自适应目标检测的“负迁移”问题。(3)为充分利用多源领域自适应目标检测中多个源域知识来提高目标检测模型对目标域的检测性能,本文提出了基于多个源域知识迁移的领域自适应目标检测方法。首先,通过学习浅层特征提取网络对多个域的浅层特征进行对齐,来缩小源域跟目标域的分布差异。然后,利用后续的多个分支网络对每一对源域和目标域的高层特征进行对齐,来度量每个源域到目标域的迁移性,并在测试时,基于这个迁移性来融合多个分支网络输出的目标样本特征。最后,利用图像级和实例级的注意力来促进“正向”跨域迁移和抑制“负迁移”。实验表明,多源域自适应不仅能提高模型的鲁棒性,还能充分利用多个源域知识来提升目标域模型的检测性能。(4)为解决在无源领域自适应目标检测中只有源域训练好的模型而没有源域数据的域自适应问题,本文提出了基于源域风格迁移蒸馏网络方法。首先,利用预训练源模型中的批归一化信息将目标域特征转换为类源风格特征。然后,利用Mean Teacher网络模型的一致性正则化进一步将知识从源域蒸馏到目标域。最后,通过添加与目标域分布相关的扰动,来增加领域特定信息的鲁棒性。实验表明,充分利用预训练源模型的批归一化信息,能够有效地将源域的知识迁移到目标域中。综上所述,本文通过对无监督领域自适应目标检测任务的多个问题面临的技术瓶颈进行深入分析,从解决不同问题的角度出发,分别在自适应过程中保留语义信息、自动和动态地加权可迁移性的图片和目标、提出了多源领域自适应知识迁移方法、基于批归一化的源域风格迁移等方法的研究,有利于无监督领域自适应目标检测领域的发展,具有一定的理论价值和应用价值。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000104
{DOI}: 10.27005/d.cnki.gdzku.2022.000104
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv4模型剪枝的番茄缺陷在线检测
{Author}: 梁晓婷;庞琦;杨一;文朝武;李友丽;黄文倩;张驰;赵春江
{Author Address}: 上海海洋大学信息学院;北京市农林科学院智能装备技术研究中心;北京市农林科学院信息技术研究中心;湖南省农业装备研究所;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 06
{Pages}: 283-292
{Keywords}: 机器视觉;模型;番茄缺陷;YOLOv4;模型剪枝
{Abstract}: 为解决番茄缺陷检测过程中的精确性和实时性问题，该研究提出一种基于模型剪枝的番茄表面缺陷实时检测方法。采用模型剪枝的方法在YOLOv4网络模型基础上进行模型优化，首先将3个连续检测工位采集的RGB图像拼接生成YOLOv4网络的输入图像，然后采用通道剪枝和层剪枝的方法压缩YOLOv4网络模型，从而减少模型参数，提高检测速度，最后提出一种基于L1范数的非极大值抑制方法，用于在模型微调后去除冗余预测框，从而精准定位图像中的缺陷位置，并将模型部署到分级系统上进行实时检测试验。结果表明，该研究提出的YOLOv4P网络与原YOLOv4网络相比，网络模型尺寸和推理时间分别减少了232.40 MB和10.11 ms，平均精度均值（Mean Average Precision,mAP）从92.45%提高到94.56%，能满足实际生产中针对缺陷番茄进行精准、实时检测的要求，为番茄分级系统提供了高效的实时检测方法。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxYJrRNRZvXiyDYEZzaHDPGuOYOS64_Q_27dpyrxUQX4n63UvWeZqemIscO8qZGDPtTecYYmqJ3sUsJtIVMftDBPU51n5fvJrKgK4mpHgqvyqQxl_596ivevSH2Nj9MTNMf3axEiSfWkP5trgCHSrLr9T7p98FoqQjy42laH3Azr8m1b-i5-Xmf1qeq1p7vMWQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆形零件尺寸参数测量
{Author}: 陈怡然;廖宁;刘超
{Author Address}: 重庆工程学院大数据与人工智能学院;贵州航天电器股份有限公司;
{Journal}: 工具技术
{Year}: 2022
{Volume}: 56
{Issue}: 03
{Pages}: 109-113
{Keywords}: 机器视觉;图像分割;数学形态学;最小二乘法
{Abstract}: 针对圆形零件尺寸传统测量方法存在测量效率低、一致性差及同心度参数不易测量的问题，设计一种基于机器视觉的圆形零件特征参数测量系统。采用阈值分割法对灰度图像进行阈值分割以提取特征目标，利用数学形态学方法对二值图像进行腐蚀、膨胀操作，避免纤细、重叠的噪声干扰；通过最小二乘法对内、外圆弧轮廓点进行拟合，得到圆心和半径参数，通过欧式距离计算出同心度参数。实验测试显示，系统精度达到0.01mm,与采用测量仪相比，视觉测量方法更适合大批量非接触式测量。
{ISBN/ISSN}: 1000-7008
{Notes}: 51-1271/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxTURCk_zsypZAnAGlP-y2XQKjPKc3Qxbn5FUuywNe-OCzz-lwEbzSATsRl1HZKcLJuRkbLX1shJX-B-HNfVCfRI3QuS0shWOadKHezwTbMAW2Jin_oApG1Qkl6rKf-HGwSy9JZ-ieaqLvzOFs6AF2zfpeyzpRYaqzm1RTdKJ9-UM0p98la0ooeIiBC_tJEEGE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 纹理表面缺陷机器视觉检测方法综述
{Author}: 朱贺;杨华;尹周平
{Author Address}: 华中科技大学机械科学与工程学院数字制造装备与技术国家重点实验室;
{Journal}: 机械科学与技术
{Year}: 2023
{Volume}: 42
{Issue}: 08
{Pages}: 1293-1315
{Keywords}: 纹理;缺陷检测;机器视觉;机器学习;深度学习
{Abstract}: 纹理表面缺陷检测在机器视觉领域具有意义和挑战性，其历史可以追溯到20世纪中后期，近年来随着深度学习技术的蓬勃发展，纹理表面缺陷检测技术大幅飞跃。直至今日，关于纹理表面缺陷检测的调研和综述仍然很少。在此背景下，本文回顾2017年-2021年间200余篇纹理表面缺陷机器视觉检测论文，对纹理表面缺陷机器视觉检测研究进展进行了及时、全面的调查；分析了纹理表面缺陷检测的发展历史和最新研究进展，原则上将纹理表面缺陷机器视觉检测方法分为传统方法与深度学习方法，并对二者进行了深层次研究分析，特别是深度学习方法；对近期出现的几种纹理表面缺陷机器视觉检测方法主题进行总结的同时，也对这些主题的研究进展进行了综述。最后，对未来的研究趋势进行了展望，以期为后续研究提供指导和启示。
{ISBN/ISSN}: 1003-8728
{Notes}: 61-1114/TH
{URL}: https://link.cnki.net/doi/10.13433/j.cnki.1003-8728.20220086
{DOI}: 10.13433/j.cnki.1003-8728.20220086
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的计算机视觉研究新进展
{Author}: 卢宏涛;罗沐昆
{Author Address}: 上海交通大学计算机科学与工程系;
{Journal}: 数据采集与处理
{Year}: 2022
{Volume}: 37
{Issue}: 02
{Pages}: 247-278
{Keywords}: 深度学习;目标检测;图像分割;超分辨率;计算机视觉
{Abstract}: 近年来，深度学习在计算机视觉各个领域中的应用成效显著，新的深度学习方法和深度神经网络模型不断涌现，算法性能被不断刷新。本文着眼于2016年以来的一些典型网络和模型，对基于深度学习的计算机视觉研究新进展进行综述。首先总结了针对图像分类的主流深度神经网络模型，包括标准模型及轻量化模型等；然后总结了针对不同计算机视觉领域的主流方法和模型，包括目标检测、图像分割和图像超分辨率等；最后总结了深度神经网络搜索方法。
{ISBN/ISSN}: 1004-9037
{Notes}: 32-1367/TN
{URL}: https://link.cnki.net/doi/10.16337/j.1004-9037.2022.02.001
{DOI}: 10.16337/j.1004-9037.2022.02.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属工件尺寸测量
{Author}: 李执;闫坤;傅琪;刘威
{Author Address}: 桂林电子科技大学信息与通信学院;
{Journal}: 仪表技术与传感器
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 92-97
{Keywords}: 机器视觉;卡尺工具;Ramer算法;Tukey算法;尺寸测量
{Abstract}: 针对多孔金属工件人工测量步骤繁杂、精度低问题，提出了基于机器视觉的金属工件尺寸精密测量方法。首先对目标进行灰度化、增强、滤波等预处理，再提取区域轮廓，针对轮廓定位分割问题，提出了基于Ramer算法逼近的两步轮廓分割方法，并引用全局轮廓分割参数S对轮廓进行分类。为提高直线和圆的边缘点定位准确性，提出了基于卡尺工具的边缘点检测方法，最后采用基于Tukey拟合算法对直线和圆形进行测量，计算得到亚像素精度尺寸。实验证明该方法可以提高测量精度且效率高。
{ISBN/ISSN}: 1002-1841
{Notes}: 21-1154/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwJGCrCzUD3ssgNALxcgA7bEc2Ed0504oU0dqVlF8EA1Petu9ahUo5Fap3HZ24ymt9SjMe6LDQhehKQJJLvPEElteO5X6jOIljaE6jEZRfFicJetaL6jHgqhilxB1nova1cP3YyCX2lYVhkR2a2CA_sZvNTW5FL5cPYKMLPAL4ynxBYds4_iju8YosuN7bfqgI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 局部–全局关系耦合的低照度图像增强
{Author}: 王克琪;钱宇华;梁吉业;刘畅;黄琴;陈路;贾洁茹
{Author Address}: 山西大学大数据科学与产业研究院;盘古深度智能信息技术有限公司;山西大学计算智能与中文信息处理教育部重点实验室;
{Journal}: 中国科学:信息科学
{Year}: 2022
{Volume}: 52
{Issue}: 03
{Pages}: 443-460
{Keywords}: 低照度图像增强;局部–全局关系;计算机视觉;卷积神经网络;深度学习
{Abstract}: 卷积神经网络目前在人工智能多个领域均取得了不同程度的进展.卷积计算是基于参数共享的滑窗机制,这导致卷积神经网络更多地关注特征信息的局部关系,对全局关系的建模能力有限.局部关系和全局关系对特征的表达均具有重要的作用.为此,本文聚焦于如何对特征信息的局部–全局关系进行构建并有效耦合,从而挖掘更加丰富的特征信息,提高特征的判别性.本文提出了局部–全局关系耦合模块,该模块是由特征提取、基于深度卷积(depth-wise convolution, DWConv)的局部关系构建分支、基于多头自注意力机制(mutli-head self-attention, MHSA)的全局关系构建分支和基于点向卷积(point-wise convolution, PWConv)的关系耦合4部分组成.基于此模块,本文构建了编解码结构的局部–全局关系耦合神经网络,该网络可以对特征信息的局部–全局关系进行建模,增强特征信息的表征能力,进而提升模型的性能.为验证所提算法的有效性,本文在低照度图像增强任务上,使用基准数据集与其他算法进行了实验对比.实验结果表明,本文所提出的方法取得了较好的图像增强结果,优于当前先进的图像增强方法.最后,本文通过消融实验和扩展实验从多个角度进一步验证了有效耦合局部–全局关系的重要性和可扩展性.
{ISBN/ISSN}: 1674-7267
{Notes}: 11-5846/TP
{URL}: https://link.cnki.net/urlid/11.5846.TP.20220308.1139.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的AlexNet网络煤矸石检测系统
{Author}: 何江;张科星
{Author Address}: 太原学院;
{Journal}: 煤炭技术
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 205-208
{Keywords}: 机器视觉;煤矸石;噪声抑制;AlexNet
{Abstract}: 针对传统的煤矸石检测方式成本较高、识别准确率较低、适用性较差等不足，经分析实际检测要求，设计了一种基于机器视觉和AlexNet网络的煤矸石检测系统。该系统通过工业相机来采集传送带上煤矸石图像，利用直方图均衡化和二阶微分线性算子来加强图像对比度与锐化效果，并使用高斯滤波来抑制图像噪声，进而获取更具辨识度的图像，最终运用AlexNet网络实现煤矸石的识别与定位。结果表明，该系统识别准确率达到了95.90%，准确率较高，且实现过程较为简单，适用性良好。
{ISBN/ISSN}: 1008-8725
{Notes}: 23-1393/TD
{URL}: https://link.cnki.net/doi/10.13301/j.cnki.ct.2022.03.049
{DOI}: 10.13301/j.cnki.ct.2022.03.049
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人工智能的计算机视觉技术研究
{Author}: 李徐梅
{Author Address}: 铜仁职业技术学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 05
{Pages}: 147-149
{Keywords}: 人工智能;计算机视觉;视觉测量
{Abstract}: 目前,计算机视觉技术进行视觉测量、目标检测时,存在准确度和运算效率低的问题。因此,本文提出人工智能的计算机视觉分析。选择互补金属氧化物半导体(Complementary Metal Oxide Semiconductor,CMOS)图像传感器与发光二极管(Light Emitting Diode,LED)光源共同采集图像;面对图像采集时出现的质量降低问题,引入欧式变换模型变化图像坐标、邻居平均滤波两种算法去除图像噪声,并在此基础上进行标准化图像处理;选择人工智能技术中的机器学习设计计算机视觉技术算法,实现基于人工智能的计算机视觉技术。实验结果:此次研究技术具有较高的视觉测量和目标检测准确率和效率。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzsu1uaWnNLGoEcVrfS3rAyd2-EjKIMl74lEG8id_0TRPCMcdptXld4adnHid1vnQEXwJBoNBj4TyImEhvAuTgYyxl0KyUt-NJIAK1MxLl4NFfrgsZrUeq0lR_K2P5ayJL1yvDKV_Qga0lljqXsY-w2ZmRvSTD7QBF2yLrhuyjarSiHlcgXzms6GhLNGhRnzv4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Dlib与OpenCV的人脸识别考勤平台
{Author}: 高燕飞;张晋芳
{Author Address}: 山西省财政税务专科学校;山西林业职业技术学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 05
{Pages}: 156-158
{Keywords}: Dlib;卷积神经网络;人脸识别;计算机视觉
{Abstract}: 随着深度学习的不断发展，计算机视觉也迎来了新的发展机遇，将机器学习、深度学习算法运用到实际问题上，成为当前的研究热点。笔者将以人脸识别为基础，利用Dlib、OpenCV、ResNet等相关技术在Python环境中实现对人脸的检测，最终通过计算实现了基于人脸识别的实验室考勤平台。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyGr3k6ikKqLh85Zicjy2pLcQTY3i0xhpSYhxmx_Xc3sDi-Lt2ECeDr1QwnkeY6lwsGfK3btUyt83QrF0gGatBesCvmoddMaIl24gjSk8vHfXiIh6eFx5Pd_f6-UcIrutZcjrQZHq97EXwMlXOOQjK8Z-ahyVK95fhRG7DveXuT3NUeOEKbDYHz70WLDfzlHLw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于中值点Hough变换玉米行检测的导航线提取方法
{Author}: 李霞;苏筠皓;岳振超;王思超;周海波
{Author Address}: 天津理工大学天津市先进机电系统设计与智能控制重点实验室;天津理工大学机电工程国家级实验教学示范中心;天津理工大学机械工程学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 05
{Pages}: 167-174
{Keywords}: 机器视觉;特征点提取;作物行检测;导航线提取;Hough变换;导航
{Abstract}: 为解决机器视觉对早期玉米苗带在多环境变量下导航线提取耗时长、准确率低的问题，该研究提出了一种基于中值点Hough变换作物行检测的导航线提取算法。首先，改进了传统的2G-R-B算法，再结合中值滤波、最大类间方差法和形态学操作实现土壤背景与玉米苗带的分割。其次，通过均值法提取玉米苗带特征点，然后采用中值点Hough变换拟合垄间两侧玉米苗列线，最后将检测出的双侧玉米苗列线为导航基准线，利用夹角正切公式提取导航线。试验结果表明：改进的灰度化算法能够正确分割玉米苗带与土壤，处理一幅640×480像素彩色图像平均耗时小于160ms，基于中值点Hough变换检测玉米苗列再提取导航线的最大误差为0.53°，相比于传统Hough变换时间上平均快62.9ms，比最小二乘法平均精确度提高了7.12°，在农田早期玉米苗带多环境变量影响因素下导航线提取准确率均达92%以上，具有较强的可靠性和准确性。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwJMhXBziXnmx7QHbHlFl26BI3q5mtWLDxwYl1OSghxE8ZIXSh24S2sJBC06kkijE4uLfgn_UoE9Mox4u66cfL5QHNSROmktJBbRfcUU1o5Px-MUJidB5SUQdyy2PjowUzZOBc34hx-HZ_0W3SMdMqH67dMmz4p_yC5OETsd7_faOmFxvL0xAt_VT95G0vaAcc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在智能化纺纱生产中的应用现状
{Author}: 徐伟锋;胡俊武;祝新军;叶佳佳
{Author Address}: 绍兴职业技术学院;振德医疗用品股份有限公司;
{Journal}: 棉纺织技术
{Year}: 2022
{Volume}: 50
{Issue}: 05
{Pages}: 71-74
{Keywords}: 机器视觉;棉纺织;智能化;在线检测;深度学习
{Abstract}: 探讨机器视觉在智能化纺纱生产中的应用情况与发展趋势。分析了棉纺智能化纺纱生产流程，从原棉异纤检测、梳理棉网在线检测、细纱加工检测和筒纱加工检测等重要方面，对机器视觉检测的应用原理、方法和产品进行了阐述与总结。指出：基于机器视觉的检测技术可将机器视觉感知数据与生产信息数据共享，通过数据驱动，提高纺纱质量和生产效率。认为：机器视觉在智能化纺纱生产中的应用可加速棉纺企业转型升级和智能化改造的进程。
{ISBN/ISSN}: 1000-7415
{Notes}: 61-1132/TS
{URL}: https://link.cnki.net/urlid/61.1132.TS.20220303.1854.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的病虫害检测综述
{Author}: 温艳兰;陈友鹏;王克强;刘展眉;林钦永;蔡肯;马佳佳;孔翰博
{Author Address}: 仲恺农业工程学院;广州南洋理工职业学院;
{Journal}: 中国粮油学报
{Year}: 2022
{Volume}: 37
{Issue}: 10
{Pages}: 271-279
{Keywords}: 机器视觉;图像分割;特征提取;深度学习;分类识别
{Abstract}: 作物病虫害直接影响作物的代谢过程，是降低作物的产量和品质的主要威胁之一，给农民造成了大量的经济损失。实现快速、准确的病虫害检测和分类识别，对农民及时采取有效的防治措施具有重要意义。目前，利用机器视觉技术实现农作物病虫害检测具有很好的前景，可以有效的克服人工识别速度慢、误判率高的不足，对于加快农业产业智能化，以及病虫害防治的智能化水平的提高都有很好的借鉴价值。结合近年来国内外学者研究进展情况，本文就病虫害检测方面的应用进展进行综述，并展望了未来的研究方向，以期为后续研究工作提供参考。
{ISBN/ISSN}: 1003-0174
{Notes}: 11-2864/TS
{URL}: https://link.cnki.net/doi/10.20048/j.cnki.issn.1003-0174.000330
{DOI}: 10.20048/j.cnki.issn.1003-0174.000330
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的类球形水果外部品质分级方法研究
{Author}: 饶剑;吕自玉
{Author Address}: 西南科技大学制造科学与工程学院;重庆交通大学经济与管理学院;
{Journal}: 科技与创新
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 63-65
{Keywords}: 机器视觉;类球形水果;特征检测;外部品质分级
{Abstract}: 针对传统方法在水果品质分级中存在的人工成本高、分级精度低等问题，开发了一种基于机器视觉的类球形水果外部品质分级方法。通过预处理获得采集目标的前景图像，采用最小外接矩阵表征果形指数，结合形态学区域填充分析果面缺陷，同时根据两特征参量大小实现对类球形水果的外部品质分级。利用设计的类球形水果外形尺寸检测系统对脐橙开展了在线检测和分级实验。结果表明，对5个抽样脐橙进行横径检测中，检测值与实际测量值的最大相对误差低于0.8%，对100个脐橙进行品质分级中，总体平均识别率高达94.4%，验证了该方法可应用于类球形水果的外部品质分级。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2022.05.020
{DOI}: 10.15913/j.cnki.kjycx.2022.05.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向自动驾驶农机的农田地头边界线检测系统
{Author}: 乔榆杰;杨鹏树;孟志军;王侨;刘卉
{Author Address}: 首都师范大学信息工程学院;国家农业智能装备技术研究中心;
{Journal}: 农机化研究
{Year}: 2022
{Volume}: 44
{Issue}: 11
{Pages}: 24-30
{Keywords}: 农机自动驾驶;地头边界线检测;机器视觉;图像识别
{Abstract}: 农田地头环境感知与识别是农机自动驾驶系统实用化的瓶颈与关键技术。为此,以约翰·迪尔1204拖拉机为试验平台,在自动导航系统AMG-1102基础上,加装双目立体相机,构建农田地头边界线检测系统。针对较为典型的灰度突变型地头图像,提出相应的地头边界线检测方法,将图像沿水平方向平均分成8个区域,求解每个区域的位置特征点,采用稳健回归法提取地头边界。田间试验结果表明:算法能够快速准确地检测出地头边界线,并能较好地适应地头边界线的倾斜情况,平均每帧图像检测时间为0.32s,准确率均值为96.2%,能够满足实际农田作业生产需求。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2022.11.044
{DOI}: 10.13427/j.cnki.njyi.2022.11.044
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLO的车辆检测研究及车位检测系统的实现
{Author}: 李涵宇
{Tertiary Author}: 申铉京
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 车辆检测;深度学习;YOLO;车位占用检测
{Abstract}: 随着经济的快速发展,车辆在人们的日常生活中越来越普及,已经成为出行必备的交通工具,停车难的问题也随之而来并且日益突出。之所以停车难,一方面由于停车位数量不足,无法满足停车位的巨大需求;另一方面,司机无法及时、准确获取附近空闲停车位,导致停车位利用率不高。这不仅造成了资源浪费,在交通安全、环境治理等方面带来的影响也不容忽视。为了使司机能够快速获取车位信息,解决停车难问题,本文研究了车辆检测算法,并基于车辆检测算法设计并实现了车位检测系统。具体内容如下:(1)为了提高车辆检测精度,解决小目标车辆难以检测的问题,提出了自适应多尺度特征融合网络(Adaptive Multi-scale Feature Fusion Network,AMFFN),用来替换YOLO v4的特征融合网络,取得了更好的检测效果。首先,通过使用多个空间金字塔池化,提高特征的表示能力。然后,跨层融合多个尺度的特征并且为不同尺度特征分配可学习的权重。AMFFN作为一个可复用的模块,通过多次融合特征可获得更精细的特征。最后,为了避免复杂的网络结构导致的巨大参数量,使用深度可分离卷积替换普通卷积,以降低参数量,提高网络检测速度。(2)为了使车辆检测网络更加灵活,能够满足不同环境的需求,提出基于改进YOLO v5的车辆检测算法DY-YOLO。车辆检测在实际应用中,往往面临不同的环境,对网络的性能具有不同要求。在一些简单的应用场景,只需要简单的模型,而在一些复杂场景,需要比较复杂的模型以满足精度要求。YOLO v5包含多个不同大小的版本,可以适应不同的需求,相比单一的网络模型更加灵活,因此选择YOLO v5进行改进。首先,通过引入Dynamic Re LU使得激活函数随着输入动态变化,更好地适应不同输入特征;然后解耦预测分支,将分类和回归任务分离,让网络能够更好的完成分类和回归任务。改进后的网络保持了YOLO v5的灵活性,在保持网络轻量的同时具有较高检测精度。(3)基于本文提出的车辆检测算法,实现了车位占用检测系统,并部署在实际场景中。测试结果表明,该系统能够较好的完成车位占用检测检测任务,在实际场景中具有较好的检测效果。本文针对车位占用检测问题,介绍了现有方法的进展以及不足,将计算机视觉与深度学习结合,提出了基于改进YOLO v4的车辆检测方法和基于改进YOLO v5的车辆检测方法,并基于提出的方法设计并实现了车位占用检测系统,在实践中取得了较好的效果。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.006590
{DOI}: 10.27162/d.cnki.gjlin.2022.006590
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MAML算法的YOLOv3目标检测模型
{Author}: 沈震宇;朱昌明;王喆
{Author Address}: 上海海事大学信息工程学院;华东理工大学信息科学与工程学院;
{Journal}: 华东理工大学学报(自然科学版)
{Year}: 2022
{Volume}: 48
{Issue}: 01
{Pages}: 112-119
{Keywords}: 计算机视觉;图像识别;特征提取;目标检测;小样本学习
{Abstract}: 作为典型的一体化卷积神经网络，YOLOv3模型的网路传输途径简单，检测速度相对较快，但检测精度较低。当遇到新的目标在训练数据集中存在的样本较少时，模型检测会更加不准确，甚至会出现检测不到的情况。本文基于与模型不相关的元学习算法（MAML）改进了YOLOv3主干网络的结构，使其具有内循环和外循环的梯度下降，在初始参数基础上进行多步的梯度调整，达到仅用小样本数据就能快速收敛的目的。实验结果表明，该方法使得YOLOv3模型的检测精度提升了5.24%，且可以使梯度下降保持稳定，有效地满足YOLOv3模型在小样本数据训练情况下识别目标位置的精准性和泛化性。
{ISBN/ISSN}: 1006-3080
{Notes}: 31-1691/TQ
{URL}: https://link.cnki.net/doi/10.14135/j.cnki.1006-3080.20201128002
{DOI}: 10.14135/j.cnki.1006-3080.20201128002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾分拣机器人
{Author}: 陈艺海;黎莲花;谢昊璋;卢思琪;董晋瑜
{Author Address}: 桂林电子科技大学电子工程与自动化学院;
{Journal}: 仪器仪表与分析监测
{Year}: 2022
{Volume}: 
{Issue}: 01
{Pages}: 30-35
{Keywords}: 垃圾分拣机器人;深度学习;目标检测;机器视觉;图像处理;OpenCV;百度AI;YOLOv4
{Abstract}: 为了把人从环境恶劣、枯燥繁重的垃圾分类工作中解放出来，本项目设计了一款基于机器视觉的垃圾分拣机器人。机器人以STM32单片机为主控，根据树莓派发送的不同指令控制六自由度机械臂抓取垃圾。机器人的视觉系统部署在树莓派上，视觉系统使用CSI摄像头获取图像并通过YOLOv4目标检测算法求得图像中垃圾的分类信息和位置信息，最后通过串口将得到的结果发送给主控单元以便于控制机械臂抓取。本项目也使用了百度AI的EasyDL物体检测模型代替YOLOv4作为实现垃圾分拣的另一方法。在实验测试中该机器人能够通过学习垃圾样本实现自动分拣不同类型的垃圾，并且识别精确、效率高。该垃圾分拣机器人具有成长性强、可靠程度高、应用范围广的特点，可以为机器人代替人工完成复杂工作的研究提供参考。
{ISBN/ISSN}: 1002-3720
{Notes}: 11-2048/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyIRa28uyy4vFuGmY-YNKuPcGK4WjjxHFq_tjq_BU_U1UcZvur8ekpgc1rstNRNslFTvpBqzXbxYceSqo2LxSvxorCH6Ptjqf8rMnZqwpKPQ3_KCDd3Hkb6-yA_b9j4A32DvmJRQG-tlRTjsvcD14ZRKMvPa8qqfqi-eTtpQJRfFbJ7jhbRb6NzUyecyig1XoM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的多类型工件测量系统研究
{Author}: 刘志毅;杨桂华;唐卫卫
{Author Address}: 桂林理工大学机械与控制工程学院;
{Journal}: 机床与液压
{Year}: 2022
{Volume}: 50
{Issue}: 04
{Pages}: 6-12
{Keywords}: 机器视觉;工件测量;多项式插值;Hough变换
{Abstract}: 综合应用光电技术、数字图像处理技术和计算机技术，以薄片型机械零部件为主要测量对象，开发一套工件尺寸测量系统，主要包括照明系统、图像采集系统、图像处理系统和尺寸测量系统。根据检测要求，采用Canny算法进行边缘检测粗定位和8个方向模板的改进亚像素检测技术获得工件精确轮廓信息，再对轮廓进行分割和选择，采用Hough变换完成工件的二维尺寸测量，并利用Halcon与C++联合编程实现多类型工件二维尺寸测量系统。实验结果表明：直线和圆测量中，Hough变换测量值与千分尺测量值平均误差为0.042 mm;平均耗时32.543 ms。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw8CHcgMv-Cub5rI8oT1sJIj3xmsxp1rWDipXEgC8cqErb7_DcExUfZ63XU7EmxbEIuwaa5qrF2dqPtwRY89E4NiaeQ902MdZ4Y4DbWj9T_tR-FVXKT4sof5zl-eUlEcGFRQtv4L6yvGU-qZrHeOFZp12QL4rJFUZO9zxgk3gIKhV5erQfUgiLD9NRWnUu1Y7M=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Gabor滤波器的光纤缺陷检测方法
{Author}: 朱刘盅;李竞择;吴磊;季伟伟;严万万;胡姊娟
{Author Address}: 河海大学商学院;江东科技有限公司;南京理工大学计算机科学与工程学院;
{Journal}: 南京理工大学学报
{Year}: 2022
{Volume}: 46
{Issue}: 01
{Pages}: 119-126
{Keywords}: 缺陷检测;机器视觉;滤波器;级联分类器;工业互联网
{Abstract}: 为了评估工业产品的结构安全性，严格控制产品质量，该文从光纤工业生产的角度出发，结合机器视觉在缺陷检测方面的应用，提出了一种基于Gabor滤波器的光纤缺陷检测系统。使用一组包含中值滤波和Gabor滤波的滤波器来消除背景纹理的影响，增强缺陷特征；将滤波后的图像分成大小相同的小块，根据每个子块包含的缺陷特征的数量，将这些子块分为有缺陷块和无缺陷块；根据原始图像的灰度和缺陷区域的形状和位置特征进行筛选，从而判断光纤图像类型。实验结果表明，该文所提的方法能够有效地应用于光纤的无损检测，为光纤产品质量保证提供了可行的解决方案。
{ISBN/ISSN}: 1005-9830
{Notes}: 32-1397/N
{URL}: https://link.cnki.net/doi/10.14177/j.cnki.32-1397n.2022.46.01.017
{DOI}: 10.14177/j.cnki.32-1397n.2022.46.01.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和YOLOv4的破损鸡蛋在线检测研究
{Author}: 赵祚喜;罗阳帆;黄杏彪;袁凯;黄渊;曹阳阳
{Author Address}: 华南农业大学工程学院;广州广兴牧业设备集团有限公司;
{Journal}: 现代农业装备
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 8-16
{Keywords}: 深度学习;YOLOv4;破损鸡蛋;在线检测
{Abstract}: 破损鸡蛋导致的漏液会污染自动化生产线和完好鸡蛋，不仅影响生产效率，还会干扰裂纹鸡蛋的检测。为实现破损鸡蛋快速、准确、低成本的识别，本文利用机器视觉技术，并结合深度学习网络深层次特征提取、高精度检测分类的特性，提出一种基于YOLOv4网络的破损鸡蛋检测方法。构建破损鸡蛋图像数据集，搭建YOLOv4深度学习网络，训练含有破损蛋和完好蛋图像的分类模型；并对比YOLOv4与YOLOv3、Faster RCNN网络模型对破损蛋的识别精度；同时为验证YOLOv4的在线检测能力，模拟搭建鸡蛋实际生产环境，对比不同破壳鸡蛋比例、不同移动速度下的检测精度。研究结果如下：相同数据集下，YOLOv4识别精度高出YOLOv3、Faster RCNN网络模型平均值4.62%；在线检测时，YOLOv4模型对含不同比例的破损蛋识别正确率平均为86.22%；鸡蛋生产线移动速度在5～6 m/min下，识别正确率平均为84.91%。结果表明，本文提出的基于YOLOv4的破损鸡蛋检测方法对流水线上移动的鸡蛋有较好的检测效果，检测速率较高，为鸡蛋智能化生产、品质检测提供一种新的方法，具有一定的实用价值。
{ISBN/ISSN}: 1673-2154
{Notes}: 44-1616/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxoWCs0yCeaOa23DZ1hb3mdIuFBGYqIqND3zROusz3SaAHLOdsvtEiCZSddV04Cgwhjjkh2VIc-HR26_NHYLX99qQKoRsxcBbBtFZQr4v569QXvF9YX-h83iYHBnd87A3fGm9FA-deQ9uVCfzl6owYvJmKhcUR7o-KJPoSK88pgf9_oUbbpcrOg0AuPoDbJjH8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像特征检测与特征提取综述
{Author}: 索子恒
{Author Address}: 苏州大学计算机科学与技术学院;
{Journal}: 产业创新研究
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 33-35
{Keywords}: 深度学习;计算机视觉;特征检测;特征提取
{Abstract}: 在过去的几十年里，深度学习和计算机视觉在目标检测、目标跟踪、行人检测和自动驾驶汽车方面发挥了趋势引导作用。一些方法被提出来解决这些计算机视觉和基于深度学习的检测、跟踪技术、算法和数据源的问题。近年来，这一领域变得越来越重要，研究人员利用有关图像和视频的在线/离线数据，集中进行情绪建模和计算分析。本文主要强调了几种不同的趋势策略的目标检测，并展示了该领域现有的与潜在的未来发展方向。
{ISBN/ISSN}: 2096-4714
{Notes}: 12-1459/F
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwSGdrQZLH8kLwedZQCcvBJf3X8_odfO_N_W43g2rmox8avsb1jI4XXxbXknIZdKzs8GvFeDuySzxGedoneN0DbFPW57Pb7viyRrnYGbBvewu3DhZbabehSpakx1zXqi4z-0Gn4DYztUBRZUOi5htql2Vs0JPUfYPtzn0Fx_VQ9EqnqW77vdgkA8hwqx5tapc0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉技术的水稻病害图像识别研究进展
{Author}: 李辉;罗敏;岳佳欣
{Author Address}: 成都农业科技职业学院机电信息学院;四川水利职业技术学院信息工程系;
{Journal}: 湖北农业科学
{Year}: 2022
{Volume}: 61
{Issue}: 04
{Pages}: 9-15
{Keywords}: 水稻病害;图像识别;计算机视觉技术
{Abstract}: 从病害图像采集、图像处理、特征提取、分类识别4个方面对水稻常见病害的识别方法和技术进行了综述研究，分析了一些典型方法的基本原理、关键技术、实现方法和应用效果，总结了该领域现有研究存在的问题与不足，对未来的发展趋势和研究方向进行了展望。采用计算机视觉技术对农作物病虫害进行识别，具有无损、快速、实时、准确等特点，对于加速农业现代化建设、提高生产效率有重要影响。随着移动通信技术、大数据、物联网、人工智能、遥感技术的高速发展，通用性广、稳定性强、精确度高、实时性强的自然环境下大面积农作物病虫害图像智能识别与防治、病虫害海量数据标准化处理是农作物病虫害识别未来的重要研究方向。
{ISBN/ISSN}: 0439-8114
{Notes}: 42-1255/S
{URL}: https://link.cnki.net/doi/10.14088/j.cnki.issn0439-8114.2022.04.002
{DOI}: 10.14088/j.cnki.issn0439-8114.2022.04.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算光学成像：何来，何处，何去，何从？
{Author}: 左超;陈钱
{Author Address}: 南京理工大学电子工程与光电技术学院智能计算成像实验室(SCILab);南京理工大学江苏省光谱成像与智能感知重点实验室;南京理工大学智能计算成像研究院(SCIRI);
{Journal}: 红外与激光工程
{Year}: 2022
{Volume}: 51
{Issue}: 02
{Pages}: 158-341
{Keywords}: 计算成像;计算摄像;光学成像;光学传感
{Abstract}: 计算光学成像是一种通过联合优化光学系统和信号处理以实现特定成像功能与特性的新兴研究领域。它并不是光学成像和数字图像处理的简单补充，而是前端(物理域)的光学调控与后端(数字域)信息处理的有机结合，通过对照明、成像系统进行光学编码与数学建模，以计算重构的方式获取图像与信息。这种新型的成像方式将有望突破传统光学成像技术对光学系统以及探测器制造工艺、工作条件、功耗成本等因素的限制，使其在功能(相位、光谱、偏振、光场、相干度、折射率、三维形貌、景深延拓，模糊复原，数字重聚焦，改变观测视角)、性能(空间分辨、时间分辨、光谱分辨、信息维度与探测灵敏度)、可靠性、可维护性等方面获得显著提高。现阶段，计算光学成像已发展为一门集几何光学、信息光学、计算光学、现代信号处理等理论于一体的新兴交叉技术研究领域，成为光学成像领域的国际研究重点和热点，代表了先进光学成像技术的未来发展方向。国内外众多高校与科研院所投身其中，使该领域全面进入了“百花齐放，百家争鸣”的繁荣发展局面。作为本期《红外与激光工程》——南京理工大学专刊“计算光学成像技术”专栏的首篇论文，本文概括性地综述了计算光学成像领域的历史沿革、发展现状、并展望其未来发展方向与所依赖的核心赋能技术，以求抛砖引玉。
{ISBN/ISSN}: 1007-2276
{Notes}: 12-1261/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxRlYXzODHdv1vG50JFCJkZef-gm2-DYYh6VvN7PK5pRidPQDKb3GzqUFW2PK5DdiLfs90Ehkf8QfaemJ-NxmiNY1R1h2LsMbShHIQXgoAYB-LWk_kekyJXM1dPtqAfOfRkqdkWIFDpz0bl8sUtRHTwc1Z5-EUqrW3ke3Jdw5MaNcLBmWnj_YCM_qgHvqPlW00=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于无监督域适应的低空海面红外目标检测
{Author}: 宋子壮;杨嘉伟;张东方;王诗强;张越
{Author Address}: 北京遥感设备研究所;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 04
{Pages}: 127-134
{Keywords}: 机器视觉;红外探测器;无监督域适应;梯度反转层;稳定训练;目标检测
{Abstract}: 提出一种基于无监督域适应的低空海面红外目标检测方法。首先利用图像翻译网络将源域图像翻译为目标域图像并共享标签。其次在YOLOv5s目标检测网络中使用梯度反转层优化网络提取特征的域间适应性。此外利用最大均值差异损失进一步缩小从网络中提取的不同红外探测器图像的特征分布。最后采用AdamW异步更新优化算法进一步提高模型在训练过程中的稳定性与检测精度。将所提方法在不同红外探测器采集的低空海面红外船只与无人机数据集中进行实验。实验结果表明，相较于传统有监督学习方法，所提方法有效降低了人工标注成本，且源域检测精度提高6.56个百分点，目标域检测精度提高2.62个百分点，有效提升目标检测模型在不同红外探测器间的泛化能力。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvygGo0_2QwKTd77BWBjdkPDf0zNA79m6YiZSkb4CnXkT82dk6cgbIm0zOJkyqr3OG9QV7EeCH4zTrzQGU4SjWdxVImTwGQsHnGC5D5pvzSiXEXZGejNW4xDi2RiJBWqm_mzRqp7OzeAb3qPBArrI-gHPVvv8_BgxtU9FzRQWZHRkNbKK-6i602oVzGJInaQeeY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于生成对抗网络的图像去雾算法
{Author}: 仲伟峰;赵晶
{Author Address}: 哈尔滨理工大学自动化学院;黑龙江省复杂智能系统与集成重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 04
{Pages}: 337-345
{Keywords}: 机器视觉;图像处理;循环生成对抗网络;有雾图像;光学模型
{Abstract}: 近几年在图像去雾领域中基于深度学习的方法层出不穷，利用循环生成对抗网络（CycleGAN）设计图像去雾算法。在CycleGAN中，通过对生成器进行改进来达到预期的处理效果。在生成器的编码网络和解码网络中选用Leaky ReLU和tanh两种激活函数，并对转换网络的残差块进行减少数量处理和加权优化处理。本设计能够更好地展示单幅有雾图像的清晰度和细节方面，峰值信噪比、结构相似性及信息熵等客观评价指标都得到了提升。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzjROjwo2E0t7_tYxw-NAbnDMWhJTv22BXGov3owYCOlCu2I1WQt-FSko6kiDjuCDqw-B2UwsHRokVIt9XPdKGQ_qPbZWjV0Zm8zsuL28nOU519B2I0qnCRPChje0si-e80aVimAM_AAIJJruizBtSVcanG1FDr3jaoUFaEqkPhOAa4prF8eSsTPwQMNOJmCx8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 消毒机器人目标识别定位与包围盒优化
{Author}: 叶雅欣;王佳盛;吴烽云;陈思宇;艾璞晔;邹湘军;李兰云
{Author Address}: 华南农业大学工程学院;佛山市中科农业机器人与智慧农业创新研究院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 04
{Pages}: 346-354
{Keywords}: 机器视觉;视觉定位;点云拼接;Mask R-CNN;主成分分析
{Abstract}: 为实现公共场所定点消毒目标的识别与定位，确定消毒范围，首先采用深度相机获取公共场所的彩色图像和三维点云；其次训练Mask R-CNN深度网络，进行消毒目标的分类、检测与实例分割，进而获取目标点云；然后通过采样一致性初始配准（SAC-IA）和迭代最近邻点（ICP）精配准方法实现不同视角点云的拼接，获取完整的消毒目标点云；最后基于主成分分析（PCA）优化点云的包围盒。实验结果表明，基于Mask R-CNN目标检测的各类别平均精度（mAP）达到0.968，实例分割的平均交并比（IoU）达到0.879，目标包围盒的表面积和体积优化率分别达到了29.2%和28.8%。本研究能有效识别与定位消毒目标，为不同消毒目标采用不同消毒方式提供分类依据，同时能有效减小消毒范围，提高消毒作业效率。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyq1B_OyzLJYaqDem7mP0KdtEcdzwCDikEDEbTrDVX96FPO2MQ8O5J8s9TzMmPTxN2eAyruAV3X1gHJAd8iZmeR9O5BvUA1PtSRIrN8vB6aIyZ0aTlmKfAbn4jVCqoG10jn1AWgtOR0JOGO207I7ETKLlXAHMIb-GqWQNrykK-pkK-gVIonrr-LMkHzFrebWGE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像语义分割算法的应用研究
{Author}: 朱贺
{Author Address}: 华中科技大学;
{Journal}: 电子元器件与信息技术
{Year}: 2022
{Volume}: 6
{Issue}: 02
{Pages}: 196-198
{Keywords}: 计算机技术;数据;深度学习;图像分割
{Abstract}: 随着近年来计算机技术的高速发展，各种高科技的产品不断出现在我们的生活中，数据已经成为我们生活中不能分割的部分。图像分割技术已经在生活中有了很广泛的应用，同时随着计算机的发展，基于深度学习的数据处理方法能够处理大量的数据信息，同时其也有着比较好的图像语义分割效果。但是在实际使用过程中，由于深度学习仍存在许多不足，神经网络需要进行大量的训练准备工作才能够投入实际的使用过程中，不仅如此相关参数的设计和结构都决定着神经网络的工作效率，大量的专业人才、知识、时间和精力的投入使得效率不能得到提升。基于此，本文提出了使用边界框来实现对图像语义的分割，从而实现在弱监督条件下获得比较精准的分割精度，同时通过在实际交通中的应用进行了验证。验证结果表明，提出的改进算法能够获得比较好的图像语义分割效果。
{ISBN/ISSN}: 2096-4455
{Notes}: 10-1509/TN
{URL}: https://link.cnki.net/doi/10.19772/j.cnki.2096-4455.2022.2.075
{DOI}: 10.19772/j.cnki.2096-4455.2022.2.075
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 显著性物体检测研究综述：方法、应用和趋势
{Author}: 李婉蓉;徐丹;史金龙;黄树成
{Author Address}: 江苏科技大学计算机学院;
{Journal}: 计算机应用研究
{Year}: 2022
{Volume}: 39
{Issue}: 07
{Pages}: 1941-1950
{Keywords}: 显著性物体检测;视觉注意;关注点预测;目标建议;深度学习;弱监督学习
{Abstract}: 显著性物体检测旨在快速定位图像中的显著性目标，可用于目标检测和识别、关键点定位、视觉跟踪、语义分割等计算机视觉任务中。为梳理显著性检测研究的发展脉络，从方法、应用领域和研究方向等方面分析显著性检测的研究现状和发展趋势。首先，阐述了显著性检测与相关研究的区别和联系；然后，分析了目前主流的显著性物体检测算法的流程、创新点、性能和适用性；接下来，介绍了显著性检测领域数据集的发展和演化；最后，展望了显著性检测研究的发展趋势并总结了显著性检测的主要应用领域。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2021.12.0645
{DOI}: 10.19734/j.issn.1001-3695.2021.12.0645
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的语义分割综述
{Author}: 杨洁洁;杨顶
{Author Address}: 三峡大学计算机与信息学院;
{Journal}: 长江信息通信
{Year}: 2022
{Volume}: 35
{Issue}: 02
{Pages}: 69-72
{Keywords}: 深度学习;计算机视觉;传统算法;语义分割;卷积网络
{Abstract}: 语义分割是深度学习计算机视觉方面的核心领域，有着很深的研究价值。语义分割技术的发展在近几年趋于成熟，从传统的方法到基于卷积神经网络方法的突破，构建了端到端的语义分割深度学习神经网络算法。这些方法被用于人工智能当中，应用在无人驾驶，遥感影像检测，医疗影像研究等方面。基于对经典语义分割算法进行学习，每个经典算法都有自己的特点，值得在此一一总结阐述。文章将针对语义分割的发展，优秀算法的网络架构特色，应用的场景进行介绍，最后将对语义分割算法作小结和展望。
{ISBN/ISSN}: 2096-9759
{Notes}: 42-1914/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyQRevMvsZdjTJx0pj0MC98k9LkSiMmZeAGF_qD7F0dVQZlxEGT5dlW5ISj3I_7Wt0_fgugTL4tQfZQLtITdVWDs25aBJ-Mb8o2FUBSiPkSiNnimnQh8GqqQTpbEskFmw16ioBQ7Py2eglMBjQsK54yOCf1tHISpcxwf19nN_yXFhpgxsWAM8KjjWvdvkywUbY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于STM32的停车场车牌识别系统
{Author}: 毕得;刘志君;杨成龙
{Author Address}: 辽宁科技学院电气与信息工程学院;
{Journal}: 辽宁科技学院学报
{Year}: 2022
{Volume}: 24
{Issue}: 01
{Pages}: 23-24+35
{Keywords}: STM32;机器视觉;单片机
{Abstract}: 文章以OV7670摄像传感器模块实现车牌信息的采集，通过使用STM32主控芯片对车牌图像进行数据处理及提取，软件系统包括图像采集系统、车牌识别系统、应用软件、数据库和其他。车辆检测系统选用C语言编写，在Keil4平台上进行编译。应用软件与UI则是选用C#编写，在Visual Studio 2013平台编译，创建了车辆数据库，设计了停车信息表和VIP车辆信息表。通过数据比较，实现了停车费和语音提示的快速计算，以及贵宾车的快速放行。
{ISBN/ISSN}: 1008-3723
{Notes}: 21-1522/Z
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxbMjGAgTqxjJZzaizI-yj8ZFGYqYTHTMfJ__ieGj9LD2Y7Ol0ewGDzYJ421CCro4P5TgirzD0CaIG_u-3zvnYiNTMkdMf4DOwsL0-Q1KfnAf-umCbZBDvnTzVAcdnvrx7EuuZsbAywUqOIHPNzR7qSsi4CvZXEwnC4Yep3gqqtHhoTN_OzKjbPnUEONKHhV64=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉布料瑕疵检测方法综述
{Author}: 韩济阳;曹江涛;王贺楠;姬晓飞
{Author Address}: 辽宁石油化工大学信息与控制工程学院;沈阳航空航天大学自动化学院;
{Journal}: 辽宁石油化工大学学报
{Year}: 2022
{Volume}: 42
{Issue}: 01
{Pages}: 70-77
{Keywords}: 瑕疵检测;布料检测;目标识别;计算机视觉;图像处理
{Abstract}: 长久以来，布料的瑕疵检测工作一直由质检员完成，瑕疵判别过程受主观因素影响大,存在检测效率低、成本高等问题。随着计算机视觉技术的发展，基于视觉技术的布料瑕疵检测系统逐渐成为取代人工质检的重要解决方案。针对基于视觉技术的布料瑕疵检测，从行业发展情况、通用检测标准、系统整体结构、检测算法的关键技术等方面进行了综述，介绍了目前市面上已经存在的基于视觉技术的布料瑕疵检测产品，分析了目前常用的瑕疵检测标准与检测系统的基本结构，梳理并对比了近年来图像处理与深度学习技术在布料瑕疵检测领域的研究现状。最后，总结了各方面尚待解决的关键问题，并探讨了未来可能的发展方向。
{ISBN/ISSN}: 1672-6952
{Notes}: 21-1504/TE
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwpd-WyDbysui8j6YZnBgzF5MDSpBJftrfLWRXyB-vpssFBESwE_AAzSz5C3KYpEsw8cstWc8v9BcglaveZUqIe8iSfn5FkgARFInYGq2p_a2tMRLvxJO5-2yTYXHt_ufJhF1iwsCj0-BDN_Pc4SVAspp8uRe7NkbzP4XYrK4qV17k2KCgS9isbkg35itkmlnE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉：理论与应用专题序言
{Author}: 高新波;苗启广;公茂果;陶建华;孟德宇;夏勇
{Author Address}: 重庆邮电大学;西安电子科技大学;中国科学院自动化研究所;西安交通大学;西北工业大学;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: 02
{Pages}: 1-3
{Abstract}: <正>计算机视觉技术是人工智能技术的重要组成部分,也是计算机科学与信号处理研究的前沿领域。计算机视觉经过近年来的不断发展,在交通、医学、工业等多个领域得到了广泛应用。我国计算机视觉领域的研究者众多,研究成果在国际上具有很大的影响力,及时、集中、全面地报道计算机视觉相关理论、应用实践的最新成果与进展,以便研究人员快速、系统地了解新技术的发展动态和脉络,是策划本次专题的初衷。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxwuVu3SZ3QqmHFYvM-UjClgsowon3XwvTPpVUOsLq0knKTO0z135Xh9IzcZE5073wlvxyxRap9NYCLQKkc8Y1NLbI6_CiqsbTowO9OGfxOX1chYdWiiX3I_VealsUFwg3ahdNayY_xmSYmC_ZZqHLP4-UnzbkixB5HxaNmCHPqSBPi_IuGlEybfld-_rdT3Qs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Transformer交叉注意力的文本生成图像技术
{Author}: 谈馨悦;何小海;王正勇;罗晓东;卿粼波
{Author Address}: 四川大学电子信息学院;
{Journal}: 计算机科学
{Year}: 2022
{Volume}: 49
{Issue}: 02
{Pages}: 107-115
{Keywords}: 文本描述生成图像;生成对抗网络;交叉注意力编码;图像生成;计算机视觉
{Abstract}: 近年来,以生成对抗网络为基础的从文本生成图像方法的研究取得了一定的进展。文本生成图像技术的关键在于构建文本信息和视觉信息间的桥梁,促进网络模型生成与对应文本描述一致的逼真图像。目前,主流的方法是通过预训练文本编码器来完成对输入文本描述的编码,但这些方法在文本编码器中未考虑与对应图像的语义对齐问题,独立对输入文本进行编码,忽略了语言空间与图像空间之间的语义鸿沟问题。为解决这一问题,文中设计了一种基于交叉注意力编码器的对抗生成网络(CAE-GAN),该网络通过交叉注意力编码器,将文本信息与视觉信息进行翻译和对齐,以捕捉文本与图像信息之间的跨模态映射关系,从而提升生成图像的逼真度和与输入文本描述的匹配度。实验结果表明,在CUB和coco数据集上,与当前主流的方法DM-GAN模型相比,CAE-GAN模型的IS(Inception Score)分数分别提升了2.53%和1.54%,FID (Fréchet Inception Distance)分数分别降低了15.10%和5.54%,由此可知,CAE-GAN模型生成图像的细节更加完整、质量更高。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxIQLg-g7OaNpcNo17fVgnCWIg8Ve72TdnZ5ylZirN3JTv78KMuLPd6H2JcZU2ow-CXl9_FFC025SlLsxogSlX34Em0mBJz7oT4boyrYSlRZVrMJp4UMYgYEx_fUvFo3T-gN9N2oshU4bks0Hb4W0Es-l-oxgtP8Ckb2dL17ppc_iv3erpmlTNbOl-ldbPlQmM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于结构光视觉和光照模型的焊缝表面质量检测
{Author}: 余佳杰;周建平;薛瑞雷;许燕;夏磊
{Author Address}: 新疆大学机械工程学院;
{Journal}: 中国激光
{Year}: 2022
{Volume}: 49
{Issue}: 16
{Pages}: 170-178
{Keywords}: 激光技术;焊缝表面质量检测;图像处理;光照模型;机器视觉
{Abstract}: 为实现焊缝表面质量的自动检测，本团队设计了一种焊缝表面质量自动检测方法。首先对焊缝图像进行处理，提取出焊缝的中心线，并通过最小二乘法和K均值聚类算法提取焊缝特征点，进一步测量得到熔宽、余高等焊接参数；然后根据中心线数据建立三维光照模型，依据亮度的强弱与分布设立亮度特征，并根据亮度特征针对无缺陷焊缝以及咬边和气孔焊缝进行了识别。结果表明，所提焊缝表面质量检测方法对焊缝的自动识别准确率较高，而且稳定性高，效果好。
{ISBN/ISSN}: 0258-7025
{Notes}: 31-1339/TN
{URL}: https://link.cnki.net/urlid/31.1339.TN.20220211.1726.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于生成式对抗网络的图像修复研究进展
{Author}: 杨元英;王安志;何淋艳;任春洪;欧卫华
{Author Address}: 贵州师范大学大数据与计算机科学学院;
{Journal}: 计算机技术与发展
{Year}: 2022
{Volume}: 32
{Issue}: 02
{Pages}: 75-81+87
{Keywords}: 生成式对抗网络;图像修复;生成器;判别器;自编码器
{Abstract}: 图像修复是图像处理的一个重要问题，目的是利用计算机视觉技术自动恢复退化图像中损坏或丢失的部分，被广泛应用于影视特技制作、图像编辑、数字化文物保护等领域。近几年，以生成式对抗网络(GAN)为代表的深度学习技术在计算机视觉和图像处理领域大获成功，基于GAN的图像修复逐渐成为主流，受到了广泛关注。针对图像修复的关键问题，文章对GAN和基于GAN的修复方法进行理论分析，首先整理分析了传统的基于人工特征的经典图像修复方法，其次总结了近年来基于GAN的代表性图像修复算法，并进行归纳分类，探讨了各类方法的特点和局限性。然后对图像修复模型常用的评价指标和公开数据集进行整理和分析，最后阐述了图像修复面临的挑战，对图像修复技术未来的发展方向进行展望。
{ISBN/ISSN}: 1673-629X
{Notes}: 61-1450/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxu8U8Yrpj2X6iCfR3tNcCtzGey1GTilJD_-CDQoqbIwDF7f5BLzij-eoJgGY--r7oWfjCJhpcX0AaBCG6DSak8UybUQXp3lmHgTgiPFoHw6ghkbSdptnis-kWrFLv-9KP_rMcYdq4zz6lNqtPZWfQGTDvsyjljAB8_4bazLgtBCpmL14ov4UreTuIv9usQjAs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度卷积应用于目标检测算法综述
{Author}: 董文轩;梁宏涛;刘国柱;胡强;于旭
{Author Address}: 青岛科技大学信息科学技术学院;
{Journal}: 计算机科学与探索
{Year}: 2022
{Volume}: 16
{Issue}: 05
{Pages}: 1025-1042
{Keywords}: 计算机视觉;深度卷积;目标检测;单阶段;双阶段
{Abstract}: 目标检测作为计算机视觉中最基本、最具挑战性的任务之一，旨在找出图像中特定的目标，并对目标进行定位和分类，现已被广泛应用于工业质检、视频监控、无人驾驶等众多领域。近年来，随着计算机硬件资源和深度卷积算法在图像分类任务中取得突破性进展，基于深度卷积的目标检测算法也逐渐替代了传统的目标检测算法，在精度和性能方面取得了显著成果。综述了基于深度卷积的目标检测算法的研究现状以及今后可能的发展方向。以传统目标检测算法存在的局限性为引，首先介绍了目标检测算法权威的数据集和评估指标；再以时间和算法架构为研究主线，综述了近年来基于深度卷积的目标检测代表性算法的研究和发展历程，对比分析了单阶段、双阶段以及其他改进算法的网络架构，并归纳总结出各类目标检测算法所存在的特点、优势和局限；最后结合当下目标检测存在的问题与挑战对未来趋势进行展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20220129.1108.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的表面缺陷检测方法研究进展
{Author}: 赵朗月;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 仪器仪表学报
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 198-219
{Keywords}: 缺陷检测;机器视觉;机器学习;深度学习;数据集;性能评价指标
{Abstract}: 在半导体、PCB、汽车装配、液晶屏、3C、光伏电池、纺织等行业中，产品外观与产品性能有着千丝万缕的联系。表面缺陷检测是阻止残次品流入市场的重要手段。利用机器视觉的技术进行检测效率高、成本低，是未来发展的主要方向。本文综述了近十年来基于机器视觉的表面缺陷检测方法的研究进展。首先给出了缺陷的定义、分类以及缺陷检测的一般步骤；然后重点阐述了使用传统图像处理方式、机器学习、深度学习进行缺陷检测的原理，并比较和分析了优缺点，其中传统图像处理方式分为分割与特征提取两个部分，机器学习包含无监督学习和有监督学习两大类，深度学习主要囊括了检测、分割及分类的大部分主流网络；随后介绍了30种工业缺陷数据集以及性能评价指标；最后指出缺陷检测方法目前存在的问题，对进一步的工作进行了展望。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2108805
{DOI}: 10.19650/j.cnki.cjsi.J2108805
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于局部结构形态改进图像边缘限幅滤波算法研究
{Author}: 孙晓辉;蔡永洪;林雁飞
{Author Address}: 广州工程技术职业学院;广州计量检测技术研究院;
{Journal}: 计量学报
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 21-25
{Keywords}: 计量学;图像边缘滤波;限幅滤波算法;局部结构形态;机器视觉
{Abstract}: 应用经典限幅滤波算法(CFA)对边缘去噪处理时容易造成有效的高频边缘被抑制、破坏边缘连续性、丢失目标结构特征的问题。提出了一种基于局部结构形态特征的改进型限幅滤波算法，用于图像边缘滤波处理。该算法利用限幅滤波的原理，引入由5个相邻边缘点构成的滑动模子并遍历边缘各点，对滑动模子中增量超限的点加以结构形态预测和阈值判断，即通过滑动模子建立局部轮廓的结构形态模型，并应用模型进行边缘预测；对超限点与预测值的差异进行了比较，为判定是否遇到台阶、凸缘或尖锐的结构特征提供了依据。为了测试新算法在边缘保持和滤波降噪方面的能力，与传统限幅滤波算法进行了对比实验。实验结果表明：基于局部结构形态特征的改进限幅滤波算法不但具有高效的去噪能力，而且对目标结构中的高频边缘具有显著保护作用。
{ISBN/ISSN}: 1000-1158
{Notes}: 11-1864/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxyNwdHsQuYIsc8ybLOiHjOM82ZTcFlBdeU380xN5C86cvgwRmRG-zBb_SaIYLZbYFeLaUJzU1EOn1hBis5dfJSoFRmTlCQ3GCA94GgoituYa55YSxs0euTHYuup2ggyFjiePbnNx57NMf-pMiiUN7sJknNVHh6gX3xp2UBmO6cgKIAcrGCWB3OzyAdrpEHTzQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视频目标跟踪算法综述
{Author}: 刘艺;李蒙蒙;郑奇斌;秦伟;任小广
{Author Address}: 国防科技创新研究院;军事科学院;
{Journal}: 计算机科学与探索
{Year}: 2022
{Volume}: 16
{Issue}: 07
{Pages}: 1504-1515
{Keywords}: 计算机视觉;视频目标跟踪;相关滤波;深度学习
{Abstract}: 视频目标跟踪是计算机视觉领域重要的研究内容，主要研究在视频流或者图像序列中定位其中感兴趣的物体。视频目标跟踪在视频监控、无人驾驶、精确制导等领域中具有广泛的应用，因此，全面地综述视频目标跟踪算法具有重要的意义。首先根据挑战来源不同，将视频目标跟踪技术面临的挑战分为目标自身因素和背景因素两方面，并分别进行总结；其次将近些年典型的视频目标跟踪算法分为基于相关滤波的视频目标跟踪算法和基于深度学习的视频目标跟踪算法，并进一步将基于相关滤波的视频目标跟踪算法分为核相关滤波算法、尺度自适应相关滤波算法和多特征融合相关滤波算法三类，将基于深度学习的视频目标跟踪算法分为基于孪生网络的视频目标跟踪算法和基于卷积神经网络的视频目标跟踪算法两类，并对各类算法从研究动机、算法思想、优缺点等方面进行分析；然后介绍了视频目标跟踪算法中常用的数据集和评价指标；最后总结了全文，并指出视频目标跟踪领域未来的发展趋势。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20220125.1807.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Xception-TD的中华传统刺绣分类模型构建
{Author}: 周泽聿;王昊;张小琴;范涛;任秋彤
{Author Address}: 南京大学信息管理学院;江苏省数据工程与知识服务重点实验室;金陵图书馆;
{Journal}: 数据分析与知识发现
{Year}: 2022
{Volume}: 6
{Issue}: Z1
{Pages}: 338-347
{Keywords}: 数字人文;计算机视觉;迁移学习;Xception
{Abstract}: 【目的】将人工智能方法引入数字人文领域中，探讨如何解决中华传统刺绣图像分类背景下刺绣数据集较小、图像特征表示不足以及识别准确率不高等问题，为非物质文化遗产数字保护智能化提供方法支撑。【方法】将深度学习技术运用到刺绣图像上，利用图像处理技术提取其相应的特征，采用迁移学习的方法，对Xception模型进行微调改进，进而提出一种基于Xception-TD的中华传统刺绣分类模型，并探讨全连接层的数量与维度以及dropout取值对模型性能的影响。【结果】实验结果表明，针对中华传统刺绣分类的问题，通过微调的方法，发现提高全连接层数量以及增大全连接层维度可以得到更好的刺绣图像特征表示并产生更好的效果。基于Xception-TD中华传统刺绣模型准确率达到0.968 63，均优于基准模型。在进一步刺绣多分类的问题上，准确率也均优于基准模型。【局限】本文数据集仅来源于百度图片与少量人工标记，数据来源不够丰富。【结论】基于迁移学习，并结合微调能够有效提升刺绣分类的准确率。
{ISBN/ISSN}: 2096-3467
{Notes}: 10-1478/G2
{URL}: https://link.cnki.net/urlid/10.1478.G2.20220125.1801.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆柱形蜂窝陶瓷侧面裂隙检测
{Author}: 毛卫平;高伟;顾寄南;雷文桐;胡君杰;方新领
{Author Address}: 江苏大学机械工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 02
{Pages}: 117-122
{Keywords}: 机器视觉;圆柱形蜂窝陶瓷;图像处理;侧面裂隙;缺陷检测
{Abstract}: 针对圆柱形蜂窝陶瓷侧面裂隙检测困难问题，提出一种基于机器视觉的检测方法。通过对侧面裂隙检测需求分析，选用COMS相机和LED白色平行光源。对采集的图像进行滤波处理，选择中值滤波去除椒盐噪声。根据图像的特点选择ROI区域，使用全局阈值分割算子threshold进行图像分割，采用膨胀方法连接断裂区域。在提取表面缺陷时，先用connection算子对图像区域分割，再选择面积、长度和宽度3个特征对表面缺陷进行提取。将本检测方法与人工检测方法比较分析，试验结果表明在检测样品均为50个时，本方法检测合格、不合格和混合样品所需时间分别为12.50、6.64和10.58 min,具有更高检测速度，实时性更好；准确率分别为96%、84%和90%,准确率还有待提升，需要进一步的研究。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108082
{DOI}: 10.19651/j.cnki.emt.2108082
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的室内定位系统设计与实现
{Author}: 周字辉;朱晓强;曾丹
{Author Address}: 上海大学通信与信息工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 02
{Pages}: 43-47
{Keywords}: 无感知;室内定位;计算机视觉;投影变换
{Abstract}: 现在传统的室内定位技术大多需要在被定位物体上安装标签或者终端设备，在一些特定场合存在很大的局限性。为此提出了一种基于计算机视觉的室内定位系统。该系统通过目标检测算法检测出特定物体并获取其图像坐标，经过目标点判定算法判断该物体是否在待定位区域内，最后通过投影变换算法获取到该物体对应的地图坐标。在被定位物体无感知的情况下，完成对其定位且定位误差在1 m以内。为了方便用户直观地观察，采用网页的形式，将实际地图与物体位置显示在终端设备上。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2107977
{DOI}: 10.19651/j.cnki.emt.2107977
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的轮胎表面缺陷检测系统的研究与应用
{Author}: 孙贺;刘胜波;冷于浩;刘默嘉;丁涵
{Author Address}: 青岛中导辰远智能科技有限公司;
{Journal}: 工业控制计算机
{Year}: 2022
{Volume}: 35
{Issue}: 01
{Pages}: 29-30+34
{Keywords}: 机器视觉;轮胎;图像采集;缺陷分析;检测系统
{Abstract}: 在传统的轮胎表面缺陷依靠人工检测,存在劳动强度高、受人的主观影响大以及效率低下的问题。针对这一现象,研究了一种基于机器视觉的轮胎表面缺陷3D检测系统。该系统依靠机器视觉系统获取检测轮胎的表面图像,然后创建3D模型、判定缺陷类型,最终实现实时自动预警,为轮胎生产商提供一种自动化检测方案。系统集成了先进的技术、软件和工具,配套的信息管控系统可以对轮胎型号和生产数据进行采集、存储、分析,以便在生产过程中实现更高效、更可靠的质量控制,具有较高的实际应用推广价值。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvziWEE5DSxRxMqFPEl4JLRBBwFpp_8tOXnRS-PgLy9hmXlOExfDzkNoRrnR-RaEGNKhUfecn11SzZvEErUeEj8WcwmFEGKYTqq23yDTNerMjWxf0l30BlTKlBjgVKtXObeEvMIhWncoCuvUh1cDUyuC3mcVmLjPqf9N_2nAVyKeXiPTKTL9BIouS7uJn3QmZHg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果分级分拣系统关键技术研究
{Author}: 艾妮
{Author Address}: 南宁职业技术学院;
{Journal}: 自动化应用
{Year}: 2022
{Issue}: 01
{Pages}: 162-166
{Keywords}: 机器视觉;分级分拣;深度学习;位置检测;图像滤波
{Abstract}: 综合考虑自动分拣系统的各项功能要求,设计了自动分拣系统的整体方案。系统包括硬件和软件设计2部分。其中,硬件设计主要包括图像采集、机械手、传送带等模块,通过图像采集模块获取图像,通过机械手抓取水果。软件设计包括水果位置检测和分类识别两部分。通过研究水果的位置检测方法,对水果图像进行预处理,通过多种算子实施边缘检测,再基于边缘轮廓检测对中心关键点进行提取。最后,论文提出了基于卷积神经网络的深度学习方法,从不同数据源获取若干张水果图像数据并标注,实现92%的分类准确率。
{ISBN/ISSN}: 1674-778X
{Notes}: 50-1201/TP
{URL}: https://link.cnki.net/doi/10.19769/j.zdhy.2022.01.044
{DOI}: 10.19769/j.zdhy.2022.01.044
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 茶叶嫩芽视觉识别与采摘点定位方法研究
{Author}: 龙樟;姜倩;王健;朱泓霖;李波;温飞娟
{Author Address}: 西南石油大学工程学院;西南石油大学机器人工程与智能制造南充市重点实验室;
{Journal}: 传感器与微系统
{Year}: 2022
{Volume}: 41
{Issue}: 02
{Pages}: 39-41+45
{Keywords}: 机器视觉;茶叶嫩芽识别;图像处理;图像分割;采摘点定位
{Abstract}: 茶叶嫩芽识别和采摘点定位是实现精品茶制作过程中机器人选择性自主采摘的前提。提出了一种基于图像处理的自然场景下茶叶嫩芽视觉识别与采摘点定位方法。通过对茶丛图像特征分析,设计了基于超绿特征的茶叶嫩芽图像分割方法,提取茶丛图像的超绿特征,采用大津法(OTSU)进行阈值分割,并通过闭运算去除噪声,经色彩合并获得嫩芽分割图像。设计了结合边缘检测和骨架化处理的嫩芽采摘点定位算法,获得了采摘点在图像中的像素位置,为茶叶嫩芽识别与采摘点定位提供了理论参考。
{ISBN/ISSN}: 2096-2436
{Notes}: 23-1537/TN
{URL}: https://link.cnki.net/doi/10.13873/J.1000-9787(2022)02-0039-03
{DOI}: 10.13873/J.1000-9787(2022)02-0039-03
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的低对比度物体尺寸测量研究
{Author}: 王晓杰;莫绪涛;陶新宇;李轩;杨舟;黄仙山
{Author Address}: 安徽工业大学数理科学与工程学院;
{Journal}: 光学技术
{Year}: 2022
{Volume}: 48
{Issue}: 01
{Pages}: 27-33
{Keywords}: 机器视觉;图像处理;亚像素;尺寸测量;低对比度
{Abstract}: 工业零件的产品检测是保证零件质量合格最重要的环节。传统的接触式检测方法难以满足工业现场高效、高精度等需求,基于机器视觉的图像测量系统已广泛应用于检测产品的几何参数。非透明物体形成的高对比度图像的测量已经进行了大量的工作,针对透明物体形成的低对比度图像的研究相对较少。以直角棱镜为对象,开发了一种用于测量低对比度产品尺寸的图像测量系统。对不同光照强度下采集到的图像进行平均,得到平滑的图像;采用限制对比度的直方图均衡化算法增强图像的对比度和使用Zernike矩边缘检测算法确定精确的亚像素边缘。通过多个对比实验验证了改进算法的合理性和优越性。棱镜厚度的平均误差小于0.003mm,标准偏差小于0.0015mm。提出的方案为相对透明物体的高精度测量领域提供了一种可行性方案。
{ISBN/ISSN}: 1002-1582
{Notes}: 11-1879/O4
{URL}: https://link.cnki.net/doi/10.13741/j.cnki.11-1879/o4.2022.01.017
{DOI}: 10.13741/j.cnki.11-1879/o4.2022.01.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的红枣外部品质检测技术研究进展
{Author}: 李聪;李玉洁;李小占;喻国威;刘鑫;马本学
{Author Address}: 石河子大学机械电气工程学院;农业农村部西北农业装备重点实验室;
{Journal}: 食品工业科技
{Year}: 2022
{Volume}: 43
{Issue}: 20
{Pages}: 447-453
{Keywords}: 机器视觉;红枣;外部品质;检测技术
{Abstract}: 近年来，具有快速、准确、客观和无损等特点的机器视觉技术已经被广泛用于农产品外部品质检测，以解决人工检测中存在的人力成本高、标准不统一和效率低等问题。在红枣加工和销售过程中，外部特征是影响其品质的重要因素，快速准确地对红枣外部品质检测能有效保障食品品质及安全、提高企业生产效率。本文综述了机器视觉技术在红枣外部品质检测中的应用，针对缺陷、大小、纹理、颜色和综合外部品质等指标总结了机器视觉检测方法的特点、存在的问题并阐明了其发展趋势，为我国红枣高效、快速检测分级装备的研发提供参考。
{ISBN/ISSN}: 1002-0306
{Notes}: 11-1759/TS
{URL}: https://link.cnki.net/doi/10.13386/j.issn1002-0306.2021090322
{DOI}: 10.13386/j.issn1002-0306.2021090322
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向实时视频流分析的边缘计算技术
{Author}: 杨铮;贺骁武;吴家行;王需;赵毅
{Author Address}: 清华大学软件学院;
{Journal}: 中国科学:信息科学
{Year}: 2022
{Volume}: 52
{Issue}: 01
{Pages}: 1-53
{Keywords}: 边缘计算;视频分析;模型压缩;任务卸载;查询优化
{Abstract}: 实时视频流分析在智能监控、智慧城市、自动驾驶等场景中具有重要价值.然而计算负载高、带宽需求大、延迟要求严等特点使得实时视频流分析难以通过传统的云计算范式进行部署.近年来兴起的边缘计算范式,将计算任务从云端下沉到位于网络边缘的终端设备和边缘服务器上,能够有效解决上述问题.因此,许多针对实时视频流分析的边缘计算研究逐渐涌现.本文首先介绍了智能视频流分析和边缘计算的背景知识,以及二者结合的典型应用场景;接着提出了现有系统所关注的衡量指标和面临的挑战;然后从终端设备层次、协作层次、边缘/云层次对本领域的关键技术分别进行了详细的介绍,重点涉及了模型压缩和选择、本地缓存、视频帧过滤、任务卸载、网络协议、隐私保护、查询优化、推理加速和边缘缓存技术.基于对上述各项核心技术的有机整合,本文提出了基于边缘计算的视频大数据智能分析平台Argus,从数据采集、推理分析,到数据挖掘、日志管理,对实时视频流分析全生命周期提供支持,并成功应用到智慧油田中.最后,本文讨论了本领域尚待解决的问题和未来研究方向,希望为今后的研究工作提供有益参考.
{ISBN/ISSN}: 1674-7267
{Notes}: 11-5846/TP
{URL}: https://link.cnki.net/urlid/11.5846.TP.20220111.1614.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的VVT发动机转子缺陷检测系统设计
{Author}: 张爱云;王吉华;高崴;张美娟
{Author Address}: 无锡职业技术学院汽车与交通学院;中国第一汽车股份有限公司无锡油泵油嘴研究所;
{Journal}: 工程设计学报
{Year}: 2021
{Volume}: 28
{Issue}: 06
{Pages}: 776-784
{Keywords}: VVT发动机转子;机器视觉;最小二乘法;外径测量;缺陷检测
{Abstract}: 针对目前工业生产线上的VVT(variable valve timing,可变气门正时)发动机转子存在尺寸误差和外观缺陷等问题,大多数工厂采用人工方式来测量尺寸和检测缺陷,但人工测量和检测的精度易受外部环境和主观意识的影响,从而产生过检和漏检。为此,设计了一种基于机器视觉的VVT发动机转子缺陷检测系统。首先,针对VVT发动机转子凸台外边缘磕碰点对外径测量的干扰,提出一种基于梯度特征和位置序列的磕碰点检测算法,先通过分析轮廓点的距离-位置序列、梯度-位置序列曲线来筛选并去除凸台外边缘的磕碰点,再采用最小二乘法对筛选后的轮廓点进行圆弧拟合以实现外径测量。然后,针对VVT发动机转子端面上的划痕、划伤等缺陷,提出一种基于改进HOG(histogram of oriented gradient,方向梯度直方图)特征的SVM(support vector machines,支持向量机)分类算法,先采用连通域分析方法得到待检测的目标区域,再提取目标区域的改进HOG特征,并利用SVM进行分类,以实现端面缺陷的检测。实验结果表明,所设计的缺陷检测系统在测量VVT发动机转子外径时的绝对精度可达到0.01 mm,且能够准确地筛选出凸台外边缘的磕碰点;因改进的HOG特征优于传统的HOG特征,所设计的缺陷检测系统在检测转子端面缺陷时具有较低的过检率和漏检率。综上可知,基于机器视觉的VVT发动机转子缺陷检测系统可实现外径的精确测量和外观缺陷的有效检测,基本满足工业检测要求,具有较高的实用价值。
{ISBN/ISSN}: 1006-754X
{Notes}: 33-1288/TH
{URL}: https://link.cnki.net/urlid/33.1288.TH.20220104.2345.010
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向工业应用场景的深度学习缺陷检测方法研究
{Author}: 蒋羽
{Tertiary Author}: 赵春晖
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 缺陷检测;两阶段网络;无监督学习;特征重构;轻量化
{Abstract}: 缺陷检测是工业生产制造过程中不可或缺的关键环节,其检测的精度和速度将直接影响产品质量、生产效率和制造成本。随着工业4.0的提出,主观性强、效率低、精度差、成本高的人工检测方式逐渐被自动化检测方式所取代。而基于传统机器视觉的自动检测技术存在特征提取能力有限、实时性低、鲁棒性和环境适应性差等问题,已不能完全满足现代工业生产需求。近年来,飞速发展的深度学习技术为工业应用场景下的缺陷检测提供了新的解决思路。以卷积神经网络为代表的深度学习模型基于数据驱动的方式实现特征的自主学习,具有高效的特征提取能力以及强大的特征表达与泛化能力,在复杂的工业环境下具有更强的鲁棒性和更高的检测精度。本文开展了面向工业应用场景的深度学习缺陷检测方法研究,旨在提高模型对噪声的抗干扰性,降低对标注数据的依赖性以及实现模型轻量化设计。致力于解决工业应用场景下微小缺陷易受噪声干扰、训练数据不均衡且标注成本高、模型检测速度实时性不足等问题。具体研究内容如下:1.针对工业应用场景下微小缺陷的检测易受到复杂环境、纹理等噪声影响的问题,提出了一种基于分割分类两阶段网络的有监督缺陷检测方法,实现了对隐裂、划痕等微小缺陷的快速判别和精准分割。该方法的分割模块基于U-net分割网络进行架构改进,改进后的M型网络架构有效提升了模型对缺陷特征的学习和提取能力。并在跳跃连接处嵌入空间注意力模块,有效抑制环境噪声和纹理背景的干扰。该方法的分类模块基于迁移学习的思想,有效复用由分割模块编码器提取的多尺度特征,以实现缺陷的判别。所提方法有效解决了由于图像中缺陷像素和背景像素分布不均衡导致模型训练无效收敛的问题,仅需要少量缺陷标注样本进行有监督学习即可实现精准的缺陷检测。基于光伏组件数据集的实验验证了所提方法的有效性和优越性。2.针对工业应用场景下缺陷样本数据短缺、类型不确定性以及收集与标注成本高等训练数据问题,提出了一种基于卷积自编码器多尺度特征重构的无监督缺陷检测方法,有效弥补了有监督检测算法的局限性。该方法仅使用易于获得的正常样本数据进行训练,首先基于预训练网络提取图像的多级特征,然后进行多尺度特征融合得到深度特征,并基于所提的shuffle-CAE实现特征重构,最后通过深度特征的重构误差实现缺陷的判别和分割。实验结果表明,所提方法具有较好的通用性,在MVTec AD数据集的15类工业产品缺陷检测任务中均实现了较高精度的判别和分割。3.针对当前大多数基于重构和基于嵌入相似性的无监督模型在检测速度上较难满足工业应用场景下生产实时性需求的问题,提出了一种基于多级知识蒸馏的轻量化无监督缺陷检测方法。该方法基于多级特征匹配和通道对齐两种知识蒸馏策略,在师生网络的架构下实现由教师网络到学生网络的特征迁移,通过度量师生网络之间多级特征图的嵌入相似度误差实现快速高效的缺陷判别和分割。基于MVTec AD数据集的实验结果验证了所提方法在保证缺陷检测精度的同时,满足了工业检测实时性的需求。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.002054
{DOI}: 10.27461/d.cnki.gzjdx.2022.002054
{Database Provider}: CNKI

 