{Reference Type}: Journal Article
{Title}: 基于深度学习和图像处理的螺栓损伤检测研究
{Author}: 吴杰;黄楚越;韩贝林;邹超;黄仕平
{Author Address}: 武汉轻工大学土木工程与建筑学院;广东工业大学土木与交通工程学院;华南理工大学土木与交通学院;
{Journal}: 哈尔滨工程大学学报
{Year}: 2025
{Issue}: 09
{Pages}: 1-11
{Keywords}: 机器视觉;深度学习;目标检测;图像分割;螺栓检测;结构健康监测;YOLOv7;角度测量
{Abstract}: 螺栓连接是钢结构中最常见的连接形式，针对传统人工螺栓损伤检测效率低下等问题，提出一种基于深度学习与图像处理技术的检测算法，该算法能够检测出螺栓的正常、缺失、松动和锈蚀4种状态，并且对于难以识别的轻微松动状态也能做出针对性处理。该算法可分为2个部分：第一分支，对单阶段的目标检测算法YOLOv7-tiny进行改进，提出两阶段的YOLOv7-tiny-CM算法，直接进行螺栓损伤检测；第二分支，针对轻微松动情况，利用U-Net算法与图像处理技术直接检测出螺栓松动角度。经实验验证，第一分支所提的两阶段YOLOv7-tiny-CM算法在保持较低计算量的同时，能够达到更精准的检测性能；第二分支所提的松动识别算法能够直接计算出螺栓松动角度，不论是单螺栓识别还是多螺栓识别，误差均在1.7°以内，对于实际工程项目中的螺栓损伤检测有一定的参考价值。
{ISBN/ISSN}: 1006-7043
{Notes}: 23-1390/U
{URL}: https://link.cnki.net/urlid/23.1390.U.20250313.1329.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 锂离子电池极片表面缺陷检测方法研究进展
{Author}: 李博文;杨续来;葛肖尽;周帆;李渡阳
{Author Address}: 合肥大学安徽省锂离子动力与储能电池产业共性技术研究中心;国科能源技术创新中心;
{Journal}: 仪器仪表学报
{Pages}: 1-22
{Keywords}: 锂离子电池;极片表面缺陷;机器视觉;图像处理;深度学习
{Abstract}: 极片作为锂离子电池的重要组件,在涂覆、辊压等环节中,表面容易产生划痕、露箔等缺陷,这些缺陷会严重影响电池的质量和使用寿命,从而使得电池极片表面缺陷检测和管控工序是锂离子电池生产过程中不可缺少的工艺环节。首先对锂离子电池极片的生产工艺进行介绍,并对生产过程中可能产生极片表面缺陷的原因和缺陷种类进行分析;然后阐述了用机器视觉代替人工对极片进行自动化检测的极片表面缺陷识别方法,主要介绍了传统机器视觉缺陷检测方法的原理以及优缺点,并深入分析了深度学习在极片表面缺陷检测领域中应用的原理和流程,同时对目标检测算法中的单、双阶段算法在锂离子电池极片表面缺陷检测中的应用进行重点分析与比较;最后对基于深度学习的机器视觉检测方法在锂离子电池极片表面缺陷检测中的未来发展方向进行展望,为该领域的研究人员提供更多参考。总的来说,极片表面缺陷检测技术的发展不仅依赖于工业相机等硬件设备的技术突破,更需要软件算法的不断优化和创新,软件和硬件的协同工作才能在保证检测精度的同时,提高检测效率和降低检测成本,进一步推动锂离子电池产业的高质量发展。
{ISBN/ISSN}: 0254-3087
{Notes}: 11-2179/TH
{URL}: https://link.cnki.net/doi/10.19650/j.cnki.cjsi.J2413335
{DOI}: 10.19650/j.cnki.cjsi.J2413335
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的半导体晶圆缺陷检测方法综述
{Author}: 胡志强;吴一全
{Author Address}: 南京航空航天大学电子信息工程学院;
{Journal}: 中国图象图形学报
{Year}: 2025
{Volume}: 30
{Issue}: 01
{Pages}: 25-50
{Keywords}: 半导体晶圆;缺陷检测;机器视觉;深度神经网络(DNN);机器学习;晶圆缺陷数据集
{Abstract}: 当今许多新兴科技领域的发展需要集成电路（integrated circuit, IC）技术的支撑。半导体晶圆作为集成电路芯片中的关键角色，因制作工艺复杂，容易产生各种缺陷，其故障会极大地影响芯片的最终工作性能并增加成本。因此半导体晶圆的缺陷检测是保证其良品率和生产率的重要手段。结合机器视觉算法的晶圆缺陷检测方法普适性强、速度快，能更好地满足工业检测的相关需求。鉴于此，综述了近十几年来半导体晶圆缺陷检测方法的研究进展，介绍了晶圆制造的复杂工艺、表面缺陷检测的流程，根据不同的标准将晶圆缺陷进行分类。重点阐述了基于学习的方法，包括有监督机器学习、无监督机器学习、混合学习、半监督学习以及迁移学习5大类。对晶圆缺陷检测的深度神经网络分类为检测网络、分类网络、分割网络与组合网络。随后梳理了在晶圆缺陷检测领域常用的数据集以及性能评价指标。最后总结了晶圆缺陷检测当前存在的问题，对未来的研究方向进行了展望。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwfXYQYHtnDMejqA_1iZ4NcfgdVIkBrzDHA-ABWiZ0SQer7Jam3Lq2AA5vCE_FEYmadEMqU-nQs_N_uiYwiH8LfOPGdwXMgG2bLgNKCHvdVt-LwvgfZibW9J6gXKvXAC4aU3kvv_H1anq2suQrR75IIGrT3KFDi_O9tCzudrtoXdlARGYCdjISaLfkokSS72Zo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 基于深度学习的图像去雾算法综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2024年第二十八届网络新技术与应用年会论文集
{Author}: 陆翔宇;任义;胡津津;韩梦菲;景竑元;张萌萌
{Author Address}: 北京联合大学机器人学院(人工智能学院);北京联合大学智慧城市学院;
{Secondary Title}: 中国计算机用户协会网络应用分会2024年第二十八届网络新技术与应用年会
{Place Published}: 中国山东威海
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2024
{Pages}: 4
{Keywords}: 深度学习;图像去雾;数据集;评价指标;计算机视觉;卷积神经网络;生成对抗网络
{Abstract}: 随着无人驾驶技术的发展,对车道线检测、行人追踪、道路监控等高阶视觉任务的精度要求随之增高。由恶劣天气环境所导致的视觉图像降质问题是目前制约高质量图像识别和物体检测技术发展的痛点之一。传统的图像去雾方法存在着复原图像平均质量较差和对非均质雾图不敏感等问题。深度学习方法通过学习大量的真实数据,可以自动提取有利于去雾的特征,提升了去雾效果和泛化能力。因此,由深度学习技术驱动的图像去雾方法成为近年来图像复原领域的研究热点。对近年来图像去雾研究所取得的主要进展进行了系统性的梳理,着重分析了卷积神经网络与生成对抗网络技术在图像去雾领域的代表性论文;总结了图像去雾算法相关的评价方法,并结合现有的工作,进一步分析了图像去雾领域的未来发展趋势。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2024.047837
{DOI}: 10.26914/c.cnkihy.2024.047837
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于ResNet神经网络的花卉图像分类研究
{Author}: 赵友山
{Author Address}: 荆州市教育考试院;
{Journal}: 电脑知识与技术
{Year}: 2024
{Volume}: 20
{Issue}: 32
{Pages}: 23-25
{Keywords}: 深度学习;ResNet;花卉识别;花卉分类
{Abstract}: 本研究基于计算机视觉和深度学习技术，提出了一种高效、准确的花卉图像识别与分类方法，采用基于残差网络(ResNet)的ResNet50卷积神经网络模型。相较于传统的人工识别方式，该方法显著提高了识别速度与准确性，同时降低了成本。实验验证表明，ResNet50模型在花卉识别和分类任务中表现出卓越性能：验证集准确率达82.771%,Kappa系数为0.825，表明该方法具有出色的一致性和相对于随机性的显著改进。此外，本文对ResNet模型的结构和性能进行了深入分析和讨论，为未来在花卉分类领域的研究和应用提供了有益的指导。本研究对推动植物学领域的数字化、智能化发展具有重要意义，为相关研究提供了有益参考。
{ISBN/ISSN}: 1009-3044
{Notes}: 34-1205/TP
{URL}: https://link.cnki.net/doi/10.14004/j.cnki.ckt.2024.1644
{DOI}: 10.14004/j.cnki.ckt.2024.1644
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于雷达和视觉融合的多模态空中手写体识别研究
{Author}: 刘威;许勇;方娟;李城;祝玉军;方群;何昕
{Author Address}: 安徽师范大学计算机与信息学院;
{Journal}: 计算机科学
{Pages}: 1-11
{Keywords}: 毫米波雷达;计算机视觉;深度学习;多模态融合;空中手写体识别
{Abstract}: 空中手写体识别是一项前景广阔的人机交互技术。单一传感器挖掘手势特征，如毫米波雷达、相机和Wi-Fi，难以捕捉完整的手势特征。设计了一种灵活的双流融合网络（Two-Stream Fusion Networks，TFNet）模型。该模型既可以融合空中手写体能量图（Air-Writing Energy Images，AEIs）和点云时间序列特征图（Point Cloud Temporal Feature Maps，PTFMs），也可仅以单模态数据作为网络的输入。构建了一种鲁棒可靠的多模态空中手写体识别系统。该系统采用硬触发方式启动和结束多传感器数据采集，分别处理同时间序列内的图像和点云数据，生成AEIs和PTFMs，实现多模态数据时间对齐。经过分支网络，对手势外观和细粒度运动信息进行特征提取，结合自适应加权权重，融合双分支决策结果，避免了多模态中间特征的复杂交互，有效降低模型的损失。采集多名实验者空中书写0-9共10种数字的空中手写体数据对模型进行评估，结果表明，所提模型在识别精度方面优于其它基线模型，且具有较强的鲁棒性，在空中手写体识别任务中表现出了明显优势，可成为多传感器在空中手写体识别任务中的有效工具。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.tp.20241101.1104.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像中值滤波算法在智能采摘机器人中的应用
{Author}: 宋涛
{Author Address}: 吉利学院智能科技学院;
{Journal}: 农机化研究
{Year}: 2025
{Volume}: 47
{Issue}: 07
{Pages}: 245-250
{Keywords}: 采摘机器人;中值滤波;机器视觉;去噪;图像边缘检测
{Abstract}: 机器视觉系统是采摘机器人的重要组成部分，而对采摘目标进行快速识别和定位是决定采摘机器人采摘效率的关键。传统采摘机器人缺乏图像处理算法，对采摘目标的识别速度较慢、图像特征提取不准确，容易造成漏摘、错摘和损坏采摘目标等情况。为此，深入研究了采摘机器人视觉系统结构原理，完成视觉系统软硬件配套设计，引入图像中值滤波算法，完成采摘目标的图像采集，进行图像噪声分析、去噪，以及图像边缘检测等图像处理操作，并完成了图像中值滤波算法模块的硬件设计。同时，通过优化种植滤波算法流程，完成了采摘机器人图像检测的界面设计，最后应用在采摘目标识别中，完成功能仿真实验。实验结果表明：基于图像中值滤波算法的智能采摘机器人能够快速采集采摘目标图像，图像清晰度较高，去噪效果明显，确保了采摘机器人能够快速准确识别到采摘目标，提高采摘效率，有效提升采摘质量。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.issn.1003-188X.2025.07.037
{DOI}: 10.13427/j.issn.1003-188X.2025.07.037
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人分拣系统设计
{Author}: 张善燕
{Author Address}: 广州市机电技师学院;
{Journal}: 中国机械
{Year}: 2024
{Volume}: 
{Issue}: 28
{Pages}: 14-18
{Keywords}: 机器视觉;工业机器人;分拣系统
{Abstract}: 随着制造业的迅速发展，生产活动对于效率的提升有了更高的要求。本文以机器视觉技术为基础，致力于设计一种先进的工业机器人分拣系统。机器视觉技术的引入旨在提高工业生产线上的分拣效率和准确性，通过全面运用图像采集、物体识别和机器人控制等关键技术，构建了一个具备快速、精准地处理各类物体能力的、完善的分拣系统。系统整体架构的设计包括了先进的硬件配置和高效的软件算法，以实现对复杂生产环境中物体的智能识别和快速分拣。经过试验验证，该系统在提升工业生产自动化水平方面取得显著成效，为制造业的数字化转型提供了创新性解决方案。
{ISBN/ISSN}: 1003-0085
{Notes}: 11-5417/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxjI0fqOAe5jbL_lL96ZOYFQzs9Ek1oi9dDvkKjHXiiPC4OfNUCI-Rwv2FvZlwF5swZk4aE89fYEvoha_-hz1YQGLjI8xw8nRUoqy_3eCYFzHgS6GSkGOc5YR3HsfZQ4z2u0y9kEROJ1xYddoTWfy7y4r9-W9HjiShN0aEh6CEt0O0BAEuHGcpJ74j7boFlBuw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在工业领域的应用现状及展望
{Author}: 张艳梅;邓奥林;赵伟杰
{Author Address}: 上海电气集团股份有限公司;
{Journal}: 装备机械
{Year}: 2024
{Volume}: 
{Issue}: 03
{Pages}: 9-15
{Keywords}: 机器视觉;工业;应用;展望
{Abstract}: 介绍了机器视觉技术的发展历程，分析了包括图像采集、预处理、特征提取、识别判断等关键内容的机器视觉技术原理。聚焦于机器视觉技术在工业领域的应用现状，介绍了机器视觉技术的具体应用实例，并提出面向未来的发展展望。
{ISBN/ISSN}: 1672-0555
{Notes}: 31-1892/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyRO9orAYehwp3t2R_lkFvMhoUNw1YYu_3NWRkImUXZWBROYiwbrVPg6m5mWQqkmzQvVqpVuiTXODYbSXQhg7a-Ti5otsSb0yd4hLzId0NgK8i2KnOaBWPBua5wB95JXqtsJkMiaps8g9SRUgBs1rE7B2oWeDH3YwVnHgKy9sGXvh1iadMmB72HoWMJEvHMFnE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人分拣技术研究
{Author}: 刘远桃;秦龙;杨海能
{Author Address}: 邵阳职业技术学院;永州职业技术学院;
{Journal}: 机电工程技术
{Year}: 2024
{Volume}: 53
{Issue}: 09
{Pages}: 173-176
{Keywords}: 机器视觉;工业机器人;分拣
{Abstract}: 随着现代工业自动化程度的提高，分拣技术作为物流系统中的重要环节，其效率与准确性对整个生产流程具有重要影响。构建一种视觉系统，摄像机被用来获取分拣区域内金属工件的图像序列。这些图像序列经过一系列预处理操作，包括灰度化、滤波去噪等，以提高图像的清晰度和识别率。预处理之后，采用霍夫圆检测算法对图像中的圆形物体进行检测，以识别出规则几何形状的工件。角点检测算法则被用于确定工件的位置和方向信息。通过提取图像中的角点，可以准确定位工件的位置，并根据角点的分布情况计算出工件的方向，为后续的分拣提供依据。实验表明该系统能解决工件的分拣问题，达到分拣目的，提高分拣速度和精度，适应各种复杂工件的分拣需求。这对于提高现代工业生产效率、降低成本具有重要的意义。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxfnvZN620x-6QGpKb69iD4iZGfMmtnjzsTetF28XC85XSTYzao_tsAtGYBftJuwU1bXo5XiT-cpdbrAt1UDjZcRUEOFfGaRJ5WqaiWhc6zqDxuF3rkhGydjuHxu8oZNP3C2K3IKrLGLjLyuRA2dIBfq4FnuQmBVDGm1ORmvqoPTvK708QuG2RQHpF3cqlLb0s=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5s-Ghost的PCB缺陷检测系统设计
{Author}: 冯桑;温佳旺;张泳;陈兴彬
{Author Address}: 广东工业大学机电工程学院;广东省生产力促进中心;华南理工大学机械与汽车工程学院;
{Journal}: 机械设计与制造
{Year}: 2025
{Volume}: 
{Issue}: 03
{Pages}: 354-357+361
{Keywords}: 机器视觉;YOLOv5;缺陷检测;轻量化
{Abstract}: 这里针对常见的PCB制造缺陷，设计了一种了基于卷积神经网络的视觉检测系统。首先搭建了包括图像采集、检测结果显示与标记等模块的系统平台。通过数据采集平台拍摄PCB样本作为训练数据，使用均值滤波和数据增强技术对图像进行处理和扩充，并利用SRGAN算法进行了超分辨率重建。使用GhostNET中的Ghost module对YOLOv5s进行了轻量化改进，实验结果表明，该系统具有较高的准确率，在识别准确度方面达到93%，标记准确率达到98%，同时模型的参数量压缩了48%，能够满足实际检测需求。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20240913.006
{DOI}: 10.19356/j.cnki.1001-3997.20240913.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 实时机器视觉技术在纺织智能生产中的应用
{Author}: 闫玉刚;李成族;陈玉洁;季东晓;覃小红
{Author Address}: 东华大学纺织学院;东华大学机械工程学院;
{Journal}: 东华大学学报(自然科学版)
{Pages}: 1-12
{Keywords}: 纺织智能化;机器视觉;实时性;在线检测;纺织智能装备
{Abstract}: 在纺织行业的自动化生产中,面对高速连续的生产模式,实时处理大量图像数据成为一项关键任务。从传统图像算法、深度学习及硬件加速技术三个方面进行综述,详细分析了各种算法和硬件加速器的性能特点,并探讨了对于不同算法和硬件的优化策略。同时,还探讨了实时机器视觉技术在自动化异性纤维检测、条干检测、织物瑕疵检测和织物纬斜检测等场景的应用。最后,总结了实时实现机器视觉算法优化和硬件加速的方法,并展望了机器视觉在纺织领域的未来发展趋势。
{ISBN/ISSN}: 1671-0444
{Notes}: 31-1865/N
{URL}: https://link.cnki.net/doi/10.19886/j.cnki.dhdz.2024.0147
{DOI}: 10.19886/j.cnki.dhdz.2024.0147
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉技术的水果分级方法及应用研究
{Author}: 王明皓;李翠
{Author Address}: 青岛理工大学;
{Journal}: 商场现代化
{Year}: 2024
{Volume}: 
{Issue}: 19
{Pages}: 32-34
{Keywords}: 机器视觉;水果分级;分级方法;供应链
{Abstract}: 水果产业一直以来都是农业领域的重要组成部分，其市场前景备受瞩目，然而，随着水果市场需求日益增长，水果分级的效率和准确性成为亟待改进的重点。机器视觉作为一种新兴科学技术，在水果分级领域有巨大的发展空间。本文从我国水果分级现状入手，分析机器视觉技术及其对水果分级带来的好处，对中国现有的机器视觉分级技术进行简述，深入剖析现代化先进的水果分级技术及其设备难以在生产生活实施的问题，提出相应的解决措施，希望为我国水果市场的蓬勃发展和水果分级领域的研究创新做出积极贡献。
{ISBN/ISSN}: 1006-3102
{Notes}: 11-3518/TS
{URL}: https://link.cnki.net/doi/10.14013/j.cnki.scxdh.2024.19.001
{DOI}: 10.14013/j.cnki.scxdh.2024.19.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉领域对抗样本检测综述
{Author}: 张鑫;张晗;牛曼宇;姬莉霞
{Author Address}: 郑州大学网络空间安全学院;智能警务四川省重点实验室;四川大学计算机学院;
{Journal}: 计算机科学
{Year}: 2025
{Volume}: 52
{Issue}: 01
{Pages}: 345-361
{Keywords}: 深度学习;对抗样本攻击;对抗样本检测;人工智能安全;图像分类
{Abstract}: 随着数据量的增加和硬件性能的提升，深度学习在计算机视觉领域取得了显著进展。然而，深度学习模型容易受到对抗样本的攻击，导致输出发生显著变化。对抗样本检测作为一种有效的防御手段，可以在不改变模型结构的前提下防止对抗样本对深度学习模型造成影响。首先，对近年来的对抗样本检测研究工作进行了整理，分析了对抗样本检测与训练数据的关系，根据检测方法所使用特征进行分类，系统全面地介绍了计算机视觉领域的对抗样本检测方法；然后，对一些结合跨领域技术的检测方法进行了详细介绍，统计了训练和评估检测方法的实验配置；最后，汇总了一些有望应用于对抗样本检测的技术，并对未来的研究挑战进行展望。
{ISBN/ISSN}: 1002-137X
{Notes}: 50-1075/TP
{URL}: https://link.cnki.net/urlid/50.1075.tp.20240827.1150.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉的研究及应用进展
{Author}: 唐浩然
{Author Address}: 首都师范大学;
{Journal}: 科技与创新
{Year}: 2024
{Volume}: 
{Issue}: 16
{Pages}: 52-55
{Keywords}: 机器视觉;图像采集;特征提取;图像分析
{Abstract}: 机器视觉是利用机器代替人眼进行测量和判断的技术，是人工智能的重要分支。随着技术的发展，机器视觉已经从二维图像识别发展到三维立体视觉，图像采集技术也在不断进步，新的自监督学习框架和互中心化学习方法提高了数据效率和分类准确性。在特征提取方面，深度学习等方法的应用使特征提取更加准确和高效。在图像的分析和理解方面，深度学习、图表示学习、时间上下文信息等方法的应用为图像分析和理解的发展提供了更多可能性。未来，随着技术的进一步发展，机器视觉的应用前景将更加广阔。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2024.16.012
{DOI}: 10.15913/j.cnki.kjycx.2024.16.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 单目标跟踪中的视觉智能评估技术综述
{Author}: 胡世宇;赵鑫;黄凯奇
{Author Address}: 中国科学院大学人工智能学院;中国科学院自动化研究所智能系统与工程研究中心;中国科学院脑科学与智能技术卓越创新中心;
{Journal}: 中国图象图形学报
{Year}: 2024
{Volume}: 29
{Issue}: 08
{Pages}: 2269-2302
{Keywords}: 智能评估技术;竞赛和数据集;视觉跟踪能力;单目标跟踪(SOT);目标跟踪算法
{Abstract}: 单目标跟踪任务旨在对人类动态视觉系统进行建模，让机器在复杂环境中具备类人的运动目标跟踪能力，并已广泛应用于无人驾驶、视频监控、机器人视觉等领域。研究者从算法设计的角度开展了大量工作，并在代表性数据集中表现出良好性能。然而，在面临如目标形变、快速运动、光照变化等挑战因素时，现有算法的跟踪效果和人类预期相比还存在着较大差距，揭示了当前的评测技术发展仍存在滞后性和局限性。综上，区别于以算法设计为核心的传统综述思路，本文依托单目标跟踪任务、从视觉智能评估技术出发，对评测流程中涉及的各个关键性环节（评测任务、评测环境、待测对象和评估机制）进行系统梳理。首先，对单目标跟踪任务的发展历程和挑战因素进行介绍，并详细对比了评估所需的评测环境（数据集、竞赛等）。其次，对单目标跟踪待测对象进行介绍，不仅包含以相关滤波和孪生神经网络为代表的跟踪算法，同时也涉及跨学科领域开展的人类视觉跟踪实验。最后，从“机机对抗”和“人机对抗”两个角度对单目标跟踪评估机制进行回顾，并对当前待测对象的目标跟踪能力进行分析和总结。在此基础上，对单目标跟踪智能评估的发展趋势进行总结和展望，进一步分析未来研究中存在的挑战因素，并探讨了下一步可能的研究方向。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw0SuM_XDNKxUQAR1V2mPDWKY0gXcvL5gfvOK6aRzz7M9IQh1Y4clOFHc2SSLBSy7bTuE6cefV_thGsqu29Yz347sZMKraPzzemd-vicVWaz4aMze0yZAgMyEm__7nDyWW2BkrVDkTACHSb7rzymmsaVUgJoX2eiCoMnWNe3jk-Zjf1XS3nKXkDmFowhsiVY2A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在计算机视觉领域的应用研究
{Author}: 张远民;李冬冬;黄勇;古仁国
{Author Address}: 联通(四川)产业互联网有限公司;
{Journal}: 科技与创新
{Year}: 2024
{Volume}: 
{Issue}: 15
{Pages}: 40-42
{Keywords}: 智慧养殖;大数据;物联网;计算机视觉
{Abstract}: 智慧养殖业对准确高效监测动物生长信息、健康信息以及生长环境，以提高现代养殖水平的需求日益增长，大数据技术、物联网技术和计算机视觉的飞速发展为满足该需求提供了巨大的契机。计算机视觉对于采集到的图像、视频信息具有强大的解析能力和表示能力，适合于复杂养殖环境中动物特征的提取、动物生长环境的分析，有助于提升养殖水平。重点论述了目前计算机视觉在智慧养殖领域的研究进展，分析了应用中存在的问题，并对其未来发展方向进行了展望，旨在为推进中国养殖产业转型升级和可持续发展提供理论支持。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2024.15.011
{DOI}: 10.15913/j.cnki.kjycx.2024.15.011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的无人机自动巡检定位控制技术
{Author}: 刘硕
{Author Address}: 武汉交通职业学院智能制造学院;
{Journal}: 石河子科技
{Year}: 2024
{Volume}: 
{Issue}: 04
{Pages}: 26-28
{Keywords}: 机器视觉;无人机;自主感知
{Abstract}: 机器视觉技术在无人机领域中的应用正在不断扩展，实现自主感知、智能导航和目标跟踪等功能。随着深度学习和计算机视觉技术的发展，无人机的智能化和自主化得到了显著提升。通过结合3D机器视觉技术，无人机的环境感知和避障能力得到了加强。无人机技术包括各类平台和尺寸，满足军用和民用的不同需求。机器视觉系统包括照明、镜头、相机和图像处理等关键部件。本文主要介绍了无人机在图像获取、特征提取、三维重建和视觉定位等方面的技术应用，以及自动巡检中的实时路径规划和避障技术。
{ISBN/ISSN}: 1008-0899
{Notes}: 65-1162/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz6EAo3Vw59eX8FK1c1e5p9gyBqhw0UCLpcO918m-tJuAaIqrXoMpGvSAmCmDm_2RGFua7flcvavsInFNlHPsqwlHJoK8bQ_n9F_4QAxRuKdakTvHfvEOADa0DAoBjWxTTzqXwioJ3IIm4llulTmKdk0CdfW4ARMmYafrynOQm-0GRBcDAcai-_3-AopreXRAg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 刀具磨损检测技术综述
{Author}: 王海泉;郭修远;李辉;赫亚鹏;温盛军;周恩克
{Author Address}: 中原工学院中原彼得堡航空学院;中原工学院电子信息学院;洛阳阿特森精工科技有限公司;
{Journal}: 自动化技术与应用
{Year}: 2024
{Volume}: 43
{Issue}: 07
{Pages}: 1-6
{Keywords}: 刀具磨损;磨损检测;深度学习;机器视觉;信号处理
{Abstract}: 在机械加工过程中，为了提高零部件加工的精度和效率，对刀具磨损状态的检测就显得至关重要。随着计算机和人工智能技术的发展，刀具磨损检测技术从人工判断逐渐过渡到智能化分析。从刀具磨损状态检测的方法、步骤、相关技术等三个方面对刀具磨损检测技术进行了综述，对相关方法进行评价，并对未来刀具磨损检测技术进行展望。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2024)07-0001-06
{DOI}: 10.20033/j.1003-7241.(2024)07-0001-06
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的架空输电线路关键部件辨识方法研究
{Author}: 刘天娇
{Tertiary Author}: 刘家军
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 输电线路关键部件;改进YOLOv8模型;结构重参数化;注意力机制
{Abstract}: 架空输电线路的可靠运行对于电力系统的安全至关重要。为了防止输电线路中绝缘子、间隔棒、防震锤等关键部件损坏对电力传输造成影响,需要对其进行定期巡检。传统的人工巡检方式周期长,容易出现漏检、误检等问题。近年来,无人机辅助人工巡检的方式逐渐成为各大电网的重要巡检方式之一。然而,在无人机巡检过程中会产生大量图像,如何识别图像中的关键部件成为一项迫切需要解决的问题。基于此,本文提出了一种改进的YOLOv8模型用于输电线路巡检图像中关键部件的辨识。主要研究内容如下:(1)针对输电线路巡检图像存在目标物占比小、背景复杂等问题,采用基于OpenCV的图像处理方法进行图像扩充并使用LabelImg软件标注,改善输电线路关键部件数据集的质量。通过对比分析经典的目标检测算法,选用YOLOv8算法作为此次研究的基础模型。经实验验证,扩充后的数据集平均检测精度为91.6%,但其对间隔棒、防震锤这类小目标识别效果不佳。(2)为进一步提升YOLOv8模型对输电线路关键部件中小目标的识别效果,首先使用DBB模块对YOLOv8结构进行重参数化,在不改变模型复杂度的情况下,提高YOLOv8模型的性能。其次,针对数据集中小目标识别困难问题引入注意力机制,以增强关键部件中小目标在图像中的显著度。通过实验对比选择最合适的注意力机制LSK,实验结果表明,引入注意力机制LSK后YOLOv8模型对绝缘子闪络这类小目标的提升效果更明显,而对间隔棒的提升效果不明显。(3)考虑输电线路关键部件存在尺寸大小不一的问题,进一步选择基于注意力机制的目标检测头DyHead,自动地学习生成不同大小和形状的目标框,有助于提取多尺寸部件特征。通过WIoU损失函数为不同类别的边界框分配不同的权重,使得模型更关注数量少且难以识别的目标,以提升整体的检测效果。经实验验证,改进后的YOLOv8模型mAP值由91.6%提高至94.8%。为了验证本文提出的改进YOLOv8模型的性能,将其与SSD、Faster R-CNN、YOLOv5等经典模型进行对比实验。结果表明,本文提出的改进YOLOv8模型在计算量和参数量较低的情况下识别精度最高。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000574
{DOI}: 10.27398/d.cnki.gxalu.2024.000574
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积网络的行人车辆与驾驶员行为检测关联研究
{Author}: 杨旭阳
{Tertiary Author}: 王林
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 行人车辆检测;驾驶员行为识别;YOLOv5;OpcnPosc;ST-GCN
{Abstract}: 随着汽车保有量的持续上升以及城市化的推进,交通高峰现象愈发严重,这对辅助驾驶系统的精度和实时性提出了更高要求,同时计算资源的限制也变得更加突出。针对这一问题提出了 GCD-YOLOv5(GSConv Coord Decoupling-YOLOv5)行人与车辆目标检测算法和 LA-GCN(Lightweight Attention-Graph Neural Network)驾驶员行为识别算法,再将这两种算法进行模块化处理形成关联,从而使辅助驾驶系统得到完善。主要的研究内容如下:(1)为了保证行人车辆位置检测模型的实时性和准确率并尽可能节省算力成本,提出了 一种新的行人与车辆目标检测算法GCD-YOLOv5。首先将GSConv卷积引入YOLOv5骨干网络中,然后在颈部结构中加入CA(Coord Attention)注意力机制,接着将头部网络中的耦合头替换为解耦合头,随后将非极大值抑制进行优化,考虑目标重叠信息,最后加入单目测距用于检测安全距离。经过上述改进并在KITTI数据集混合自制数据集上进行实验,并进行可视化分析。(2)为了保证驾驶员行为识别模型的实时性和准确率并节省计算资源,提出了一种新的驾驶员行为识别算法LA-GCN。首先将深度可分离卷积引入OpenPose中第一阶段,然后将第二阶段的两个分支合并为一个分支,叠加多层小卷积核,接着将ST-GCN中的池化层替换为图自注意力池化,随后在网络最后一层卷积中加入ECA(Effificient Channel Attention)注意力模块,最后将原来单一的权重分配策略改为对时域和空域采取不同的分配策略。经过上述改进并在Drivers驾驶员行为数据集上进行实验,并进行可视化分析。(3)为了对行人车辆检测结果和驾驶员行为识别结果进行关联分析并实现辅助驾驶的功能,设计了一种基于目标检测和行为识别的驾驶员分析提示系统,该系统包含三个主要模块:行人与车辆位置检测模块、驾驶员行为状态检测模块以及综合分析提示模块。分别将行人车辆检测和驾驶员行为识别封装进前两个模块,最后使用逻辑分析进行第三个模块的构造,并在上述三个模块的基础上使用安卓虚拟机进行仿真。通过实验证明,GCD-YOLOv5精确率达到了 96.2%,并且较YOLOv5提高了 2.6%;LA-GCN在改进OpenPose后虽然没有精确度的显著提升,但检测速度提高了 4.28f/s并且参数量减少了 20.71%;LA-GCN在改进ST-GCN后相对于原模型在准确率上提高了 3.77%;结合两种改进的LA-GCN在准确度上提高了 3.81%,检测速度提高了4.64f/s,参数量降低了 23.01%,并且提出的算法与其他经典算法进行比较也较为突出,从而证明了所提出算法的有效性。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001540
{DOI}: 10.27398/d.cnki.gxalu.2024.001540
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机械零件缺陷检测研究进展
{Author}: 谭锦涛;王晓云;刘凤丽;杨淳升
{Author Address}: 沈阳理工大学机械工程学院;
{Journal}: 成组技术与生产现代化
{Year}: 2024
{Volume}: 41
{Issue}: 02
{Pages}: 16-23
{Keywords}: 缺陷检测;机器视觉;机器学习;深度学习;图像预处理
{Abstract}: 以齿轮和轴承两类典型机械零件为研究对象，总结了常见的缺陷种类，重点综述了近年来无接触检测的研究进展。对基于机器视觉的机械零件缺陷检测方法进行分析，并进一步探讨了检测过程的关键问题和缺陷检测的研究方向。
{ISBN/ISSN}: 1006-3269
{Notes}: 41-1226/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxMgN3Mnf5DOs17jpSZeAWUtFhF0wJ1O97BkIqY2E6pu1KmMma0AVMHTtk5boDQC9wb5Dm3zf_pTxGb84SnQOndYGhryEUtTv444Xsvda4rwyvr5EfouNpjQUJrnqx_irXGohDOQY8E_bBq7rbfeJ2Q9RZWxqdK93SPiLAh3NEyWPaxaKYCCi9rMUUCOqi3_VE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的浮游植物智能识别方法研究
{Author}: 李雪
{Tertiary Author}: 范文强;夏春雷
{Publisher}: 烟台大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 浮游植物;图像识别;Transformer;轻量化模型;注意力机制
{Abstract}: 浮游植物是海洋生态系统中最基本的组成部分,同时被广泛地应用于评价和监测水质,其分布和丰富度可以为自然灾害提供早期预警。传统的浮游植物分类方法大多是基于形态学的,这些方法耗时耗力且需要昂贵的设备和精细的操作。随着计算机视觉领域的快速发展,深度学习等先进的自动化监测技术被广泛用于浮游植物分类任务。然而,浮游植物不同种类之间的差异十分微小,加之水下动态特征显著且环境复杂,使得现有的深度学习方法难以准确提取到浮游植物的细微特征,这些特征在智能分类任务中是至关重要的。此外,尽管大部分基于深度学习的模型提升了图像识别的精度,但其引入了大量的参数,并且计算结构非常复杂,需要使用更多的计算资源和存储空间,这可能会限制模型在某些环境下的部署应用。针对上述问题,本文开展了对浮游植物智能图像识别的深度学习方法研究,具体工作内容和贡献如下:
(1)本研究提出了一种基于Swin Transformer的并行多级特征融合结构(DualSwin V2),该网络能够学习和融合浮游植物的全局语义特征和局部细节特征。一方面,单分支的网络结构难以同时精确地提取到全局和局部特征,因此本研究提出了一个双分支的网络结构,该结构的主干部分由两个并行分支组成,分别为全局特征表示分支和局部特征表示分支。考虑到浮游植物的局部特征极其细微,并且各个特征的提取难度有所不同,因此在局部特征表示分支中引入全尺度跳跃连接,使得模型可以尽可能全面地提取到浮游植物的细节特征。另一方面,在对两个分支所提取的特征进行融合时,采用坐标注意力特征融合策略动态且自适应地使全局特征表示分支和局部特征表示分支进行信息交互。同时采用分步训练策略,逐步学习并融合粗粒度和细粒度特征表示。实验结果表明,本文提出的Dual-SwinV2模型识别准确率高达97.54%,与其他主流模型相比具有明显优势。
(2)本研究提出了基于残差网络和简化的卷积神经网络的两种轻量化分类模型。这两种网络模型规模较小,网络结构较为简单,可以节省计算资源和存储空间。考虑到浮游植物图像存在大量的冗余信息并且判别性特征细微的特点,本研究将残差网络和边缘特征图像相结合,以此增强浮游植物图像上的关键细节特征,弱化与当下分类任务不相关的信息。此外,卷积神经网络的局部连接特性导致模型缺乏对全局特征的提取能力,因此,本研究在简化的卷积神经网络的基础上引入选择注意力模块,使网络更关注于图像的重点判别性信息,尽可能忽略冗余信息,以此提高模型的分类效率和准确性。实验结果表明,本文所提出的两个轻量化分类模型能够用很少的参数量达到甚至超过当前部分主流模型的分类效果,具备兼顾效率和准确率的特点,应用场景广泛。
{URL}: https://link.cnki.net/doi/10.27437/d.cnki.gytdu.2024.000354
{DOI}: 10.27437/d.cnki.gytdu.2024.000354
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视频分析的规模化奶牛智能监测技术研究进展
{Author}: 宋怀波;王云飞;邓洪兴;许兴时;温毓晨;张姝瑾
{Author Address}: 农业农村部农业物联网重点实验室/西北农林科技大学机械与电子工程学院;
{Journal}: 华南农业大学学报
{Year}: 2024
{Volume}: 45
{Issue}: 05
{Pages}: 649-660
{Keywords}: 奶牛;智能监测技术;目标检测;深度学习;机器视觉;畜牧养殖
{Abstract}: 奶牛智能监测是规模化奶牛养殖的重要环节，视频分析技术具备无接触、低成本及智能分析优势，已成为当前规模化奶牛智能监测技术研究的热点。奶牛目标检测、目标跟踪以及个体和行为识别技术对规模化奶牛监管具有重要意义，复杂养殖环境中的光照、昼夜交替变化、围栏遮挡以及牛群数量繁多导致的相互遮挡是影响规模化奶牛智能监测的重要因素。本文对基于视频分析的奶牛智能监测技术研究中常用的深度模型及应用情况进行综述，提出了当前研究中面临的问题与挑战。分析发现，注意力机制、混合卷积等技术是提高模型识别准确率的有效方法，轻量化模块有利于减少模型的复杂度与计算量；计算复杂度、普适性、准确性等是影响该技术推广应用的因素；具体应用时，需要针对奶牛养殖环境、奶牛状况等进行具体分析以不断满足规模化养殖的需求。
{ISBN/ISSN}: 1001-411X
{Notes}: 44-1110/S
{URL}: https://link.cnki.net/urlid/44.1110.S.20240605.1508.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多视图立体视觉的三维重建关键技术研究
{Author}: 张松
{Tertiary Author}: 李琳
{Publisher}: 青海师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 三维重建;多视图立体视觉;注意力机制;特征提取;文物保护
{Abstract}: 三维重建,旨在从二维图像中重构出物体的三维结构,是计算机视觉领域中的一项具有挑战性任务。多视图立体视觉(Multi-view Stereo,MVS)通过对不同角度拍摄的多张图像进行处理来恢复物体或场景的三维结构,目前已成为三维重建领域内的经典方法之一。传统MVS方法依赖几何关系,成本较高,且在复杂场景中效果有限。随着深度学习的快速发展,基于深度学习的MVS方法在三维重建任务中表现出色,能自动学习和提取有效特征,但仍面临一些问题。因此,本文主要针对基于深度学习的MVS方法进行深入研究,通过对两个经典的模型分别进行图像特征提取方法的改进,探索在处理不同任务时,多视图立体视觉方法的适用性。本文主要研究内容如下:(1)针对Cas MVSNet方法中存在局部重建效果不佳,缺失纹理的问题,本文提出了融合Transformer和重叠注意机制的重建方法。通过对图像的特征提取方式进行改进使得模型对局部信息提取的更加充分,从而实现良好三维重建。在算法设计中,首先对提取的特征图进行了细粒度分割,采用了一种重叠注意机制来将图像划分为小块。再在每个得到的小块中,运用Transformer结构实施注意力机制。实验结果表明,添加Transformer和重叠注意机制后的模型在DTU数据集上取得了良好的性能,重建后点云完整度误差降低了29.6%。(2)针对MVSNet方法中存在未能有效利用全局语义信息的问题,本文提出了基于跨空间语义特征的重建方法。通过对图像的特征提取方式进行改进来使得模型同时关注多空间的语义信息,从而达到更加精确的重建效果。在算法设计中,对提取的特征图采用了一种高效的多尺度注意模块,该模块通过并行不同分支的策略,有效聚合了来自不同空间的语义信息。实验结果表明,改进后的网络模型在DTU数据集上取得了良好的性能,重建后点云完整度误差降低了26.6%。(3)针对目前缺少规范且公开的文物数据集用于模型训练。本文采用一种成本低廉且操作简便的方式来构建文物数据集。该方法首先利用相机和转台对文物工艺品进行拍摄,随后通过一系列后处理步骤,利用所得图像信息生成深度图,最终用于模型的训练。实验表明本文所构建的数据集方法是切实可行的,同时对文物工艺品进行重建,有助于为文物保护工作提供新的思路。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2024.000414
{DOI}: 10.27778/d.cnki.gqhzy.2024.000414
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的金属表面缺陷检测方法研究
{Author}: 阴滮
{Tertiary Author}: 谢英红
{Publisher}: 沈阳大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 金属表面缺陷检测;计算机视觉;数据增强;纹理检测;深度学习
{Abstract}: 金属表面缺陷检测在工业生产中具有重要的意义。金属制品的质量直接影响到产品的可靠性、安全性和外观质量,因此及早发现和处理金属表面的缺陷对于提高产品质量、降低生产成本具有重要意义。传统的金属表面缺陷检测方法主要依赖于人工目视检查或简单的机械测量,这种方法存在效率低下、准确性不高、依赖经验与无法实时检测的缺点。
近年来,基于计算机视觉的目标检测方法被广泛应用于各种检测任务中。本文通过分析金属表面缺陷的特征,提出了一种新的基于计算机视觉的金属表面缺陷检测方法,其中包括对金属数据集的扩充,对金属表面缺陷的缺陷检测与复杂纹理的金属表面缺陷的检测,主要研究如下:
(1)本文提出了一种改进的辅助分类生成对抗网络(ACGAN),用于生成钢材表面缺陷图像,以提高数据增强效果。在生成器网络中引入了CA残差模块,结合通道注意力机制和残差学习,增强了特征提取和表示能力。同时,在判别器网络中采用了Wasserstein损失函数,引入Wasserstein距离作为判别损失函数,提供了更一致的梯度信号,实现了更平滑的梯度和更稳定的训练过程,减少了模式崩溃的风险。
(2)本文提出一种基于改进的YOLOv7算法的钢材表面缺陷检测算法。首先设计了TI模块,将Transformer模块和Inception DWConvolution结合起来,增加网络检测小物体的能力。其次引入SPPFCSPC结构来增强网络训练性能。第三设计GAM注意力机制,优化网络结构,弱化缺陷图像中的无关信息,增加算法检测小缺陷的能力。同时采用Mish函数作为特征提取网络的激活函数,提高模型的泛化能力和特征提取能力。最后设计了MPDIo U损失函数来定位损失,解决CIo U预测框与真实框方向不匹配的问题。
(3)本文提出了一种基于Res MLP和Cv T的深度学习模型,用于解决复杂纹理的金属表面缺陷检测问题。该模型结合了纹理提取模块和Agent注意力模块,有效提高了纹理缺陷检测性能。首先利用Res MLP生成多尺度特征图,并通过纹理提取模块增强低级特征图的纹理特征,接着采用Cv T提取不同尺度的特征图,并通过Agent注意力模块增强全局和邻近上下文信息,最后利用多分类损失函数进行分类预测。
(4)本文提出了一种改进的VGG16模型,用于金属表面缺陷图像分类。通过替换部分卷积层为DCNv3模块,并设计CNN分类器,在其中引入多个神经网络层,实现了多层次、多样性的特征提取,提高了对复杂特征的捕获能力。实验结果表明,该模型在分类任务中具有极高的准确性和鲁棒性。
{URL}: https://link.cnki.net/doi/10.27692/d.cnki.gsydx.2024.000249
{DOI}: 10.27692/d.cnki.gsydx.2024.000249
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉和机器学习的输电塔损伤识别方法研究
{Author}: 张楷
{Tertiary Author}: 李玉学
{Publisher}: 石家庄铁道大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 输电塔;损伤识别;计算机视觉;位移采集;机器学习;循环神经网络;样本增益
{Abstract}: 输电线路具有跨越区域范围大、服役环境恶劣、失效概率高等特点,输电线路中任意一座输电塔的损坏,都将可能会导致整条输电线路的失效。《2021年全国电力可靠性年度报告》中指出,截止2021年,全国220k V电压等级及以上的输电线路总长度为82.5万千米,按照每千米线路的输电塔数量为2.3基估算,全国220k V电压等级及以上输电塔总基数达到189.7万基,其中服役时间超过40年的输电塔已超过32万基,因此选择便捷、高效的输电塔结构损伤识别方法精准识别结构的损伤对于合理评估输电塔的工作状态并保证其安全稳定运行非常关键。针对目前传统输电塔结构损伤识别方法存在的耗费人力、物力多且安装传感器易对输电塔自身产生一定损伤等不足,基于计算机视觉和机器学习开展了输电塔位移响应数据采集和结构损伤识别方法研究,具体工作主要包括:（1）基于计算机视觉技术,提出了适用于输电塔位移响应数据采集的感兴趣区域关键点法（ROI,Region of Interest）,该方法通过感兴趣区域轮廓提取、关键点检测、坐标转换三步完成对输电塔结构关键点位移响应的采集。该方法在感兴趣区域轮廓提取步骤采用全局搜索,在图像复杂或轮廓数量巨大时,会出现在同一帧图像中的多个轮廓具有相同特征的可能,且全局搜索时间较长,针对这一问题,结合N近邻搜索方法和最小能量搜索方法建立了N近邻最小能量搜索方法（NMS,N-nearest neighbor&Minimum energy Search method）,将ROI方法改进为NMS-ROI法,该方法将感兴趣区域的搜索范围划定在其附近局部区域,提高了感兴趣区域轮廓提取的准确率和效率。（2）基于室内输电塔塔头缩尺模型台架试验,验证了所提NMS-ROI方法对输电塔结构位移响应采集结果的准确率和采集效率。采用视频采集设备对输电塔塔头模型整体响应过程进行拍摄,在此基础上使用NMS-ROI法对输电塔塔头模型关键点进行位移响应数据采集,并与采用激光传感器测量所得实际位移响应数据进行对比。结果表明:本文所提NMS-ROI方法采集的输电塔结构关键点位移响应与传感器测量结果吻合较好,平均误差Eme an和均方根误差ERMSE为1.1～2.1mm,同时准确率指标σ5（绝对误差小于5mm的数据个数占总数据个数的百分比）在92%以上,准确率指标σ10（绝对误差小于10mm的数据个数占总数据个数的百分比）在98%以上,每帧图像处理时长稳定在0.16～0.17s,据此验证了NMS-ROI法在进行输电塔关键点位移响应数据采集中具有较高的准确率和采集效率。（3）结合直方图均衡化、高斯滤波、锐化、腐蚀、膨胀等方法的特点和适用条件提出了联合图像除噪方法,对受到噪声影响的输电塔视频文件进行逐帧处理,有效降低了背景噪声及光照不均对输电塔关键点位移响应采集结果的影响。为了验证所提降噪措施的有效性,在室内输电塔塔头台架试验中分别设计了正常工况（TD-1）和不均匀光照工况（TD-4）,并对两个工况施加人工噪声,采用联合图像除噪的NMS-ROI法对输电塔塔头缩尺模型关键点进行位移响应数据采集,并与采用激光传感器测量所得实际位移响应数据进行对比。结果表明:无论是正常工况还是不均匀光照工况,在施加一般程度的人工白噪声时,采用联合图像除噪方法的NMS-ROI法采集的位移响应数据与激光传感器测量的实际数据相比平均误差Eme an为2.0～2.6mm、均方根误差ERMSE为1.7～2.4mm、准确率指标σ5在90%以上、准确率指标σ1 0达到99%,在施加更高人工噪声时,两者数据吻合度较好,各项准确率指标均维持在较高水平,据此验证了采用联合图像除噪的NMS-ROI法具有较高的抗噪性能。（4）设计了实际输电塔位移识别现场试验验证采用联合图像除噪的NMS-ROI法的性能,试验输电塔为双回路耐张塔,塔型SJ1,全高47.12m,采用钢绞线进行分级加载,级差10%。采用视频采集设备对试验输电塔整体加载过程进行视频拍摄,在此基础上采用联合图像除噪的NMS-ROI法对试验输电塔进行关键点位移采集,将各级荷载下的位移采集数据与全站仪测量的实际位移数据进行对比。结果表明:采用联合图像除噪的NMS-ROI法采集的实际输电塔关键点位移数据与全站仪测量的实际数据差值百分比在0.0%～5.9%之间,据此验证了采用联合图像除噪的NMS-ROI法在实际输电塔位移响应采集中仍具有较高的准确率。（5）以输电塔关键点位移响应数据作为输入,采用机器学习方法进行输电塔结构损伤识别研究。分别采用输电塔塔头缩尺模型和单输电塔有限元模型构建损伤工况,并采集关键点位移响应数据作为训练数据,对多层感知机神经网络（MLP,Multilayer Perceptron）、卷积神经网络（CNN,Convolutional Neural Network）和长短期记忆循环神经网络（LSTM,Long Short-Term Memory）进行训练和测试。结果表明:机器学习方法具有实际应用的可行性,训练样本数量对神经网络的性能影响较大,其中LSTM神经网络能够充分利用多种输入数据的特征达到最高的准确率,训练时长短,相比MLP和CNN神经网络,LSTM神经网络更适用于输电塔损伤识别。（6）建立更加贴近实际场景的“三塔四线”塔线体系模型,设计了14种损伤工况,采集了12个关键点在脉动风荷载作用下的关键点位移响应作为训练数据。由于采用塔线体系模型数据时样本数量减少、工况数量增加,LSTM神经网络准确率降低,针对此问题,采用贝叶斯优化方法选取最优神经网络结构的超参数、提出样本重叠分割方法增加样本数量、提出预先分析各节点与各工况关联性的方法选择多节点输入数据,提升LSTM神经网络在贴近实际的输电塔结构损伤识别中的适用性。研究发现,采用贝叶斯优化方法选取最优神经网络结构的超参数后的测试准确率提高了3.2%;采用样本重叠分割方法增加样本数量后的测试准确率提高了4.7%;采用预先分析各节点与各工况关联性的方法选择多节点输入数据后的测试准确率,较双节点数据提高2.1%～8.4%,较单节点数据提高9.5%～13.9%。LSTM神经网络在贴近实际场景条件下,输电塔损伤识别的测试准确率达到92.3%,表明其能够满足实际工程应用要求,具有较好的工程应用价值。
{URL}: https://link.cnki.net/doi/10.27334/d.cnki.gstdy.2024.000088
{DOI}: 10.27334/d.cnki.gstdy.2024.000088
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 三维点云模型重建算法研究
{Author}: 郝瑞冬
{Tertiary Author}: 魏仲慧
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 点云模型重建算法;点云配准算法;点云模型生成算法;纹理图像修复算法;注意力机制
{Abstract}: 随着信息化技术的发展,三维点云模型在现实社会中扮演了越来越重要的角色。三维点云模型能够真实地呈现出物体的空间形态和立体结构,被广泛应用于工程设计、医学影像、文物保护和虚拟现实等领域中。三维点云模型重建算法可以数字化表示物体的空间结构和表面纹理,实现对三维空间中物体的精确建模和分析,为各种领域的智能化系统提供关键的信息基础。然而,三维数据采集和处理过程中易受到传感器分辨率、遮挡、光反射、手动误差及视角问题等因素的影响,从而导致配准后的点云模型分布不均匀和结构缺失。随着人工智能和三维处理算法的快速发展,依据智能化重建算法可以快速、完整地重建出三维点云模型。三维点云模型重建主要包括点云配准、点云模型生成和表面纹理修复等过程。快速、鲁棒的点云配准算法是重建立体点云模型过程中至关重要的前提,优异的点云模型生成算法能够合理地将部分缺失的点云模型生成补全,再由纹理图像修复算法还原缺失部分的表面纹理,最终使之成为完整、致密、色彩丰富的三维模型。基于此,本文主要研究以下内容:1)针对配准算法在复杂情况下存在的失效问题,本文提出了一种基于深度学习的点间软对应的点云配准算法。该算法以端对端的形式设计了多尺度的点云特征提取结构和点间软对应模块,并在网络结构中的多个位置加入了不同的注意力机制,解决了在初始位姿相差较大、高噪声和不完全重叠等情况下配准失败的问题,无需迭代就可以实现鲁棒、准确、快速地配准。在标准的三维点云模型数据集ModelNet40中,相比于其他主流的配准算法,实验证明本文的算法在多种复杂情况下的配准结果有着明显的优势,比照基于深度学习的主流配准算法,本文算法在初始位姿相差较大、高噪声和不完全重叠的情况下旋转误差(MAE)分别降低了8.8%、7.2%、23.0%,平移误差(MAE)分别降低了2.7%、2.8%、14.0%。2)点云本身无序、非结构化的特性造成了难以获取到详细的空间结构和拓扑关系,这导致了现有的点云模型生成算法只能粗糙地补全点云模型大致的几何形状,而不能准确地预测出点云模型的细节。本文针对现有点云模型生成算法在准确性、合理性、智能化和生成效果方面的不足,提出了一种多级自适应生长的点云模型生成算法,通过改进复合编码器中的骨架特征生成一个稀疏分布的骨架点云,再利用点云生长特征在每个点的球邻域内自适应生长出局部的点云,逐步生长出点云的细节。在PCN和Completion3D两个标准数据集中,与其他先进算法进行对比,实验结果表明本文的算法提高了生成点云的质量,恢复了更多的局部结构细节信息,指标L1-CD分别提升了1.6%和4.1%;在稠密点云模型生成任务中优于其他点云模型生成方法,并在可视化对比中显示了其合理性和优越性。3)将二维图像处理的注意力机制引入到三维点云模型智能重建的过程中,在点云配准算法中改进了CBAM注意力机制和Transformer模块,由此提升了在高噪声、不完全重叠等情况下的配准能力,两种注意力机制使配准网络性能分别提升了11.4%和34.3%。为了兼顾点云局部结构特征与上下文之间的联系和骨架点云与在此基础上生成更加致密的点云之间的联系,本文在点云模型生成算法中引入了Offset-Transformer模块,该模块在特征提取过程中既关注了骨架点云与生长点云之间的结构、空间关系,又减轻了噪声点和不重要的相似特征对整体的影响,使生成的点云模型更加准确,实验结果证明该模块可提升点云模型生成算法的网络性能2.7%。4)针对复杂纹理图像中不同平面结构的样本规律难以利用等问题,本文提出了一种利用结构化特征线索引导补丁修复的图像修复算法。该算法通过计算平面投影的消失点来提取图像中的平面,利用SIFT描述符寻找重复区域的平移规律,通过变换补丁计算出匹配概率将其转换为最优补丁匹配问题。该算法以金字塔逐级细化的方式,在搜索最优补丁中利用PatchMatch方式加速了纹理图像修复算法的速度,同时加入了泊松融合以消除重叠区域不自然现象。可视化结果验证了本文中的纹理图像修复算法更加清晰、自然、合理。最后将修复后的二维纹理图像重映射回三维模型,构成一个完整、致密、色彩丰富的三维模型。本论文针对三维点云模型重建过程中的实际情况和具体存在的不足,分别提出并改进了点云模型重建过程中的点云配准算法、点云模型生成算法和纹理图像修复算法,实验结果表明文中所研究的算法能够有效地提升三维点云模型重建算法中各项关键技术的性能。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2024.000006
{DOI}: 10.27522/d.cnki.gkcgs.2024.000006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于驾驶员面部特征的疲劳驾驶检测算法研究与应用
{Author}: 刘鹏宇
{Tertiary Author}: 戴斌
{Publisher}: 太原师范学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 疲劳驾驶;计算机视觉;注意力机制;面部特征;轻量化网络
{Abstract}: 交通安全问题与每个人的生活都密不可分,造成道路交通安全事故的一个主要原因就是疲劳驾驶,如何有效检测和判定疲劳驾驶状态并进行合理疲劳预警,已经成为科学研究的热点。传统的疲劳驾驶检测方法基于人体生理参数和驾驶员行为判断,但这种方式易限于环境因素的影响。而基于人脸特征的检测方法准确可靠,但是模型结构复杂,不能较好满足实际需求。本文提出了一种以面部特征为基础的轻量化疲劳驾驶检测模型,并完成了疲劳驾驶检测预警系统设计。本文完成的主要工作如下:(1)设计了一种轻量化的人脸检测模型。该模型以Yolo-V4为基本框架,针对主干特征提取网络结构复杂且占用内存大的问题,利用轻量化网络Mobile Net-V3进行替换,经改进网络参数量减少70%。并且在加强特征提取网络中使用深度可分离卷积进一步实现模型的轻量化。为了捕获重要的人脸信息,引入注意力机制增强了网络在特征提取方面的能力。使用Yaw DD数据集经过训练后可知,设计的模型平均分类精度可达97.58%,模型大小仅为12M,可以较好的满足疲劳驾驶检测的实际需求。(2)为了解决单一指标造成的疲劳驾驶状态判断不准确的问题,研究了一种面部特征融合的疲劳判定方法。首先,借助Dlib算法,成功获取了EAR和MAR值,从而有效地提取了人脸的嘴部和眼部特征。然后,利用PERCLOS方法进行眼部疲劳判定,结合打哈欠阈值进行嘴部疲劳判定。最后,基于上述理论得出一种基于面部特征融合的疲劳驾驶判定方法。实验结果表明,该方法能够获得较好的判断结果。(3)设计了一个基于面部特征的疲劳驾驶检测及预警系统。系统功能包括目标检测功能,疲劳判定及预警功能,实时检测功能。系统能够满足基本功能需求,符合预期目标。
{URL}: https://link.cnki.net/doi/10.27844/d.cnki.gtysf.2024.000066
{DOI}: 10.27844/d.cnki.gtysf.2024.000066
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人体跌倒检测系统研究与实现
{Author}: 朱胜豪
{Tertiary Author}: 钱承山
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 跌倒检测;深度学习;轻量化算法;高精度算法;边缘智能
{Abstract}: 随着我国老龄化问题日益加重,老年人健康问题备受社会关注。跌倒作为老年人健康威胁最大的因素之一,愈加引起人们的关注。因此,开发高效的跌倒检测系统,以减少跌倒对老年人健康造成的危害,具有重要意义。虽然传统的基于穿戴设备和环境传感器的跌倒检测方法已被广泛采用,但是其存在低精确度和高侵入性的问题。计算机视觉和深度学习技术的进步为处理复杂环境中的实时跌倒检测提供了研究基础。然而,在计算资源有限和环境复杂的情况下,这些技术面临着挑战。本研究旨在通过利用深度学习技术开发一个精确而高效的跌倒检测系统,以解决上述挑战,并为老年人提供更安全可靠的监控方案。本文的具体研究工作:(1)为解决数据集多样性不足的问题,构建了两套数据集,用于算法的开发和评估。这些数据集覆盖了多种跌倒场景,并涵盖了不同的光照条件、摄像机角度和遮挡情况,以确保算法在实际环境中的有效性和适应性。(2)为解决计算资源限制,提出了CGNS-YOLO轻量化算法。CGNS-YOLO算法通过整合GDCN模块、GSConv模块和空间注意力模块,既实现了模型的轻量化,也提升了检测精度。实验结果表明,相比现有的YOLOv5s,该方法的平均检测精度提高了1.2%,模型参数数量降低了20.3%,模型浮点运算量减少了29.6%。(3)为应对复杂场景的挑战,提出了C2D-YOLO高精度算法。C2D-YOLO算法融合了可变形卷积、标准卷积和通道空间混合注意力机制,显著提高了模型在极端变形和高度遮挡条件下的检测精度。实验结果表明,相比现有的YOLOv5s,该方法的平均检测精度提高了3.2%,明显提升了检测精度,减少了误检率。(4)在NVIDIA Jetson Nano和NVIDIA Jetson TX2平台上部署了两种改进算法,并基于Py Qt5框架设计了易于操作的图形界面,该界面已在实际场景中测试。基于这些算法,实现了跌倒检测系统在边缘智能领域的应用。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2024.001029
{DOI}: 10.27248/d.cnki.gnjqc.2024.001029
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CNN和Transformer的图像特征提取方法研究
{Author}: 郭少聪
{Tertiary Author}: 谢博鋆
{Publisher}: 河北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: Transformer;自注意力机制;CNN;多尺度融合;特征表示
{Abstract}: 随着深度学习技术的发展,图像特征提取已成为计算机视觉领域中的关键技术,对于提升图像分类、目标检测和图像分割等任务的性能至关重要。卷积神经网络(Convolutional Neural Network,CNN)因其优秀的空间特征提取能力在计算机视觉领域取得成功,但在获取图像全局表示方面存在局限。近年来,Transformer被引入到图像特征提取的方法中,首先将图像划分成相同大小的图像块,然后图像块被转换为序列数据。通过利用自注意力机制,能够有效获取序列数据之间的全局依赖关系。然而,直接将Transformer应用于图像特征提取却面临若干挑战和限制。Transformer依靠自注意力机制处理序列数据,随着输入序列长度的增长,其计算复杂度显著提高,这在处理高分辨率的图像数据时尤为突出。除此之外,不同于CNN通过其内置卷积操作获得固有空间感知能力,Transformer在处理图像数据时缺乏必要的空间先验知识,这一先验知识的缺失使得Transformer在直接处理图像数据方面的效率和能力受到限制。针对上述问题,本文在现有研究工作的基础上提出以下解决方案,介绍如下:
1.针对Transformer模型计算复杂度高和缺少先验信息的问题,提出了一种新颖的CNN和Transformer多尺度融合的轻量化网络模型(Multi-Scale Res2Net-Transformer,Res2former)。Res2former将CNN的归纳偏置和多尺度特征提取能力引入到Transformer模型中,其中多尺度Transformer模块(Multi-Scale-Transformer,MS-Transformer)在Transformer的前馈层中提取多尺度信息,增强Transformer模型多尺度特征的表示能力。此外,Res2former模型有效地模拟网络从提取局部特征到提取全局特征的过渡,从而进一步提升模型的特征提取能力。在公共数据集上的实验验证了Res2former模型在图像分类、目标检测和实例分割等下游任务中的显著优势。
2.为了进一步提升特征表示能力,针对局部窗口注意力机制感受野有限和现有模型建模能力弱的问题,提出了一种混合注意力Transformer主干网络(Hybrid Attention Transformer,HAformer)。HAformer模型通过并行设计的混合注意力模块,将局部窗口注意力机制和通道注意力机制输出的特征进行有效的融合,扩大了局部窗口注意力机制的感受野。不仅如此,在通道注意力模块前加入两个连续的卷积模块并在Patch嵌入层使用重叠卷积嵌入模块以进一步提升模型抽取特征的能力。实验结果证明,提出的HAformer模型作为各种下游任务的主干网络具有一定的有效性。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2024.002355
{DOI}: 10.27103/d.cnki.ghebu.2024.002355
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的工厂化养殖鱼群测量技术研究
{Author}: 韦思学
{Tertiary Author}: 于红
{Publisher}: 大连海洋大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 鱼群体长测量;双目视觉;关键点检测;计算机视觉;YOLOPOSE
{Abstract}: 养殖鱼群体长数据可以反映养殖鱼生长状态,是实现养殖鱼品级分类及工厂化养殖的重要指标。随着计算机视觉技术的发展,国内外已有学者采用图像处理技术与深度学习技术实现无接触式养殖鱼群体长测量,但部分方法通过图像分割获取鱼类体长测量点,不仅需要计算养殖鱼边缘所有像素,而且还需要计算养殖鱼游动方向,这类方法计算量较大,不适用于复杂的工厂化养殖环境。同时养殖环境复杂多样,部分养殖鱼群体长测量方法由于无法有效检测养殖鱼群目标导致无法完成养殖鱼体长测量。为解决上述问题,本研究提出一个基于双目视觉与关键点技术的养殖鱼群体长测量方法,具体研究内容及创新点如下:
(1)基于通道非降维双重注意力机制的养殖鱼群目标检测方法。养殖鱼群目标检测可以确定被测量养殖鱼位置,是实现养殖鱼群体长测量的基础。真实养殖环境中养殖鱼群目标存在模糊、气泡遮挡等现象,导致养殖鱼群特征提取困难,使得目标检测精度较低。为解决该问题,基于通道非降维双重注意力机制与YOLO目标检测算法,提出一种养殖鱼群目标检测方法EB-YOLO(ECBAM-BIFPN-YOLO)。EB-YOLO通过使用通道非降维双重注意力机制ECBAM增强YOLO骨干网络特征提取能力,提取更多细节特征;同时通过使用BIFPN加强YOLO特征融合能力,增加有效特征的融合比重,减少特征丢失。在真实养殖环境鱼群数据集上进行消融实验,实验结果表明所提方法对养殖鱼目标识别效果有所提升,检测精准率与召回率分别达到了96.60%与95.40%。与先进水下目标检测模型进行对比实验,实验结果表明所提方法效果更优秀。
(2)基于双目视觉与关键点技术的养殖鱼群体长测量方法。当前养殖鱼体长测量方法通常采用图像分割确定养殖鱼体长测量点,这种方法不但需要计算养殖鱼边缘所有像素,而且还需要计算养殖鱼游动方向,计算量较大。为解决该问题,本研究提出使用基于EB-YOLO改进的YOLOv7POSE关键点检测模型检测养殖鱼群体长测量点。由于关键点具有位置信息,无需额外计算养殖鱼游动方向,可以减少计算量。同时当前养殖鱼体长测量方法,没有考虑养殖鱼上浮下潜时,体长测量点深度不同,导致体长测量结果存在误差。为解决该问题,本研究提出使用双目视觉技术测量养殖鱼体长测量点深度信息,通过关键点检测技术获得的养殖鱼体长测量点坐标信息与双目视觉技术获得的养殖鱼体长测量点深度信息,结合空间距离算法与像素长度转换公式,便可得到养殖鱼体长信息。在实验室环境单鱼数据集上进行养殖鱼体长测量实验,对三条被测量实验鱼体长测量精准率分别达到98.30%、95.79%与98.24%,实验结果表明所提方法可以实现精准度养殖鱼个体体长测量。在真实养殖环境鱼群数据集进行养殖鱼体长测量实验,本研究所提算法对两组养殖鱼群体长检测的准确率分别达到98.40%与98.65%,实验结果表明本研究所提方法可有效测量养殖环境下养殖鱼群体长,为鱼类工厂化养殖提供数据支持。
{URL}: https://link.cnki.net/doi/10.27821/d.cnki.gdlhy.2024.000071
{DOI}: 10.27821/d.cnki.gdlhy.2024.000071
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的自动装车机系统设计
{Author}: 白安乾
{Tertiary Author}: 王斌鹏
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自动装车系统;车厢定位;货物位姿估计;码垛机器人
{Abstract}: 随着中国制造业的蓬勃发展,传统的人工搬运和码垛已无法满足日益增长的生产需求。伴随人力成本的上升,传统的人工方式逐渐失去了竞争优势,因此,工业界开始广泛采用新兴的工业机器人技术。近年来,人们将机器人与先进的码垛系统相结合,不断提升系统的自动化和智能化水平,使自动化码垛系统成为生产领域的关键利器。国内许多厂商都推出了自动码垛系统,但多数系统仍然需要人工干预,自动化程度有限。在面对恶劣工作环境时,人工干预不仅效率低下,还可能损害工人的健康。因此,本文借鉴了装车行业的挑战和需求,结合机器视觉技术,设计了一种基于机器视觉的自动装车机系统。
本文根据工厂在装车过程中普遍遇到的问题,为自动化系统设计了解决相应问题的功能。参考装车技术需求将系统划分为图像采集模块、车厢角点定位及车厢尺寸计算模块、货物定位及姿态估计模块和装车执行模块。针对实际需求,对系统中的硬件进行了选型分析,并对每个模块进行了软件编程和功能实现。
本文以车厢数据检测、机器人运动控制和货物位姿估计为研究重心进行详细描述。首先,为了对车厢进行视觉检测,我们对工业相机进行了标定,获取内参和畸变参数。采用模板匹配的方法定位图像中的车厢角点像素坐标。在计算车厢角点实际的三维坐标时,提出了一种基于EPNP和双视角图像的目标物定位方法,该方法利用图像中的5个参考坐标,结合模板匹配算法获得的角点像素坐标,计算车厢角点的实际位置,进而推导出车厢尺寸,并规划出合适的码垛区域。
其次,本文对六自由度机器人进行了运动学分析,通过D-H参数法对机器人进行建模,推导了正逆运动学公式。通过Matlab仿真验证了公式的准确性,确保了机器人运动的精准性和可控性。此外,我们设计了机器人上位机控制软件界面,使操作者能够轻松实现对机器人末端执行器的位姿控制。
最后,本文通过PCA算法对货物进行位姿检测,确定货物的主轴方向和重心位置,为了实现机器人对货物的准确抓取,我们采用了手眼标定技术,获得机器人和相机之间的坐标转换关系。在上述实验结果的基础上,利用坐标变换和透视投影等原理,我们实现了在相机视野内确定货物相对于机器人的位置,为机器人精确地抓取货物提供了准确的参考。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000528
{DOI}: 10.27278/d.cnki.gsdqc.2024.000528
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的Affordance理解研究综述
{Author}: 信建佳;王立春;尹宝才
{Author Address}: 北京工业大学信息学部;多媒体与智能软件技术北京市重点实验室;
{Journal}: 北京工业大学学报
{Year}: 2024
{Volume}: 50
{Issue}: 07
{Pages}: 872-882
{Keywords}: Affordance;计算机视觉;人-物交互;语义分割;深度学习;机器学习
{Abstract}: 利用基于计算机视觉的Affordance理解研究行为者和周围环境之间的交互属性，对指导机器人导航、抓取具有重要意义。因此，全面、深入地综述了基于计算机视觉的Affordance理解研究现状。首先，对近年来提出的方法依据研究方向进行归类，综述不同方法的思路和特点；然后，对多个常用的公开数据集进行介绍，并对不同方法在这些数据集上的性能进行对比分析；最后，阐述基于计算机视觉的Affordance理解各类方法的优势与不足及未来的发展趋势。
{ISBN/ISSN}: 0254-0037
{Notes}: 11-2286/T
{URL}: https://link.cnki.net/urlid/11.2286.T.20240529.1421.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的裂纹鸡蛋分拣系统研究进展
{Author}: 郭建军;杨霖;何杰江;黄婷立;张恩威;李锡鸿;刘双印;罗智杰;李俊勇;姚赵忠;高学凯
{Author Address}: 仲恺农业工程学院信息科学与技术学院;广州东文环境技术有限公司;广州顺生生物科技有限公司;
{Journal}: 中国家禽
{Year}: 2024
{Volume}: 46
{Issue}: 10
{Pages}: 141-151
{Keywords}: 裂纹鸡蛋;机器视觉;无损检测;分拣系统
{Abstract}: 随着人们生活水平日益提高，对鸡蛋的质量要求更高。在生产过程中受磕碰产生裂纹的鸡蛋容易滋生细菌，影响鸡蛋品质，且影响其他正常鸡蛋的传输和存储，需要进行分拣。对于裂纹鸡蛋，传统的人工分拣耗时、耗力且工人在长时间工作下容易视觉疲劳，从而导致分拣稳定性差，难以满足大规模的高质量鸡蛋产品生产需求。声学检测则容易造成新的裂纹，也对设备有较高的要求。对于裂纹鸡蛋的无损裂纹检测及分拣，研究者提出基于机器视觉技术的实现方法。文章综述了基于机器视觉的裂纹鸡蛋分拣系统的构成及研究现状，探讨机器视觉的裂纹鸡蛋分拣系统在应用时面临的问题，并对该分拣技术未来的提升与拓展提出展望，为机器视觉技术在家禽产业甚至是在农业生产领域的应用提供参考。
{ISBN/ISSN}: 1004-6364
{Notes}: 32-1222/S
{URL}: https://link.cnki.net/doi/10.16372/j.issn.1004-6364.2024.10.018
{DOI}: 10.16372/j.issn.1004-6364.2024.10.018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的钢材表面缺陷检测研究
{Author}: 李延舜
{Tertiary Author}: 徐硕博;姜光远;孙丰山
{Publisher}: 山东交通学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;目标检测;多尺度特征;注意力模块;缺陷检测
{Abstract}: 近年来我国大力推进基础设施建设,钢材产能不断扩大,因此使用钢材表面缺陷检测技术保证钢材的质量变得更加重要。早期钢材表面缺陷技术主要依赖于手工设计特征,存在主观性强、泛化能力差等缺点。随着深度学习技术的发展,基于深度学习的钢材表面缺陷检测算法能够自动从数据中学习特征,识别更加复杂的缺陷,这一进展对推动制造业质量控制环节的自动化进程和智能化发展具有深远意义。虽然深度学习技术在钢材表面缺陷检测中展示了巨大的潜力,但在实际生产的应用过程中却暴露出两个主要的问题。首先在实际生产中钢材表面缺陷类型多样而且结构复杂,这对模型的识别能力提出了更高要求。此外基于大数据的深度学习模型意味着更多的参数和更复杂的计算,这直接增加了对计算资源的需求,特别是对于实际生产中计算能力有限的环境,深度学习模型的部署将面临诸多挑战。针对上述问题,为了实现更好的检测效果,本文提出一种在不增加模型尺寸的前提下提高检测精度的高效融合协调网络(Efficient Fusion Coordination,EFC-YOLO),并且提出一种适用低算力设备的轻量化高速检测模型(Lite-Speed Detect,LS-Detect),以极小的模型体积出色地完成钢材表面缺陷检测的任务。
本文的主要的研究内容如下:
(1)针对钢材表面缺陷检测算法对复杂缺陷和小目标缺陷识别准确率低的问题,本研究对目标检测模型进行优化提出高精度模型EFC-YOLO。本文使用FusionFaster模块作为特征提取网络的主要单元,Fusion-Faster模块的基本算子部分卷积(Partial Convolution,PConv)可以在保证速度的前提下加强浅层网络提取缺陷信息的能力。而在模型颈部网络采用去加权的双向特征金字塔网络(Bidirectional Feature Pyramid Network,BiFPN)结构,以低廉的计算成本增加阶跃分支实现不同尺度特征融合。最后在主干网络底层加入捷径协调注意力机制(Shortcut Coordinate Attention,SCA),更好的捕获位置信息依赖性,兼顾轻量化设计和识别精准度。最终EFC-YOLO在NEU-DET数据集上实现了良好的检测精度。
(2)针对工业设备计算资源有限的问题,本研究提出更加注重轻量化的高速模型LS-Detect兼容低算力生产设备。首先选择一个更加小巧的无锚框算法作为基线模型,为了弥补小模型丢失的精度,本研究加入空间分组增强模块(Spatial Group-wise Enhance,SGE)对通道进行语义分组,每个语义分组都能关注全局信息和长距离依赖关系,灵活调整每个特征的重要度,抑制缺陷背景的噪声。同时结合大核可分离注意力机制(Large Separable Kernel Attention,LSKA)在不增加计算负荷的前提下扩大感受野,进一步提高检测精度。最终在NEU-DET数据集上LS-Detect以轻量化的体积实现了理想的效果。
(3)针对使用深度学习算法操作繁琐的问题,本研究设计了钢材表面缺陷检测系统便于非专业人员直观地使用缺陷检测算法。它不仅提高了缺陷检测的直观性和易操作性,为调整参数提供即时反馈,还有助于研究人员和工程师分析检测结果,加速了算法优化和系统调整的过程。在实际应用中,能够大幅度提升生产线的自动化水平。
{URL}: https://link.cnki.net/doi/10.27864/d.cnki.gsjtd.2024.000226
{DOI}: 10.27864/d.cnki.gsjtd.2024.000226
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 大麦种子机器视觉检测识别关键技术与应用研究
{Author}: 石雅莹
{Tertiary Author}: 吴禄慎
{Publisher}: 南昌大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 大麦种子;特征提取;多种混杂目标;模型优选;注意力机制
{Abstract}: 大麦是全球主要农作物之一,其种子广泛应用于种植业、酿酒业、食品工业和饲料加工等行业。不同品种的麦种具有不同的特性和用途。啤酒酿造业和大麦种植业对大麦选种要求很高,使用非特定品种的大麦种子不仅会降低大麦和啤酒产量,还会导致啤酒风味改变等问题。准确识别和区分大麦品种对大麦种植业和啤酒酿造业至关重要。然而,大麦种子品类繁多,且存在类间相似性、类内多样性、外形残缺和多种混杂等问题。借助机器学习和数字图像处理手段代替传统人工甄别,可实现高效、高精度的麦种识别和筛选,确保麦种纯度和啤酒品质.以此为背景,论文展开了相关研究:
1、面向不同的麦种识别需求,自主构建大麦种子数据库(Barley-seed Dataset,BD),包括三个数据集:单品类麦种图像数据集(Sing Barley-seed Dataset,SBD);单个残缺麦种图像数据集(Single defected Barley-seed Dataset,SDBD);多个随机麦种图像数据集(Multi-Barley-seed Dataset,MBD)。首先,采用多阈值分割技术处理图像,以区分目标、背景及其他干扰信息,通过python程序设计自动切分单品类麦种图像;将图像按照70/15/15的比例划分训练集、验证集和测试集;通过数据增强技术扩充训练集数据,最终获得单品类麦种图像数据集(SBD)。然后,将增强后的SBD数据集自动切分为单个残缺大麦种子图像,形成单个残缺大麦种子图像数据集(SDBD)。最后,使用Image Lab工具将多品类麦种图像中的九类种子进行标注;按照80/20的比例划分训练集和测试集;通过数据增强扩充训练集,最终得到多个随机麦种图像数据集(MBD),同时选取了部分SBD数据集进行标注与数据增强,获得标注的SBD数据集。
2、针对不同品类麦种的残缺和完整外观鉴别问题,采用基于卷积神经网络(Convolutional NeuralNetworks,CNN)的模型优选方法展开对比实验研究。综合考虑大麦种子存在完整和残缺的形态,分析并获取完整和残缺种子的SBD和SDBD数据集。结合超参数微调和迁移学习策略,以分类效率与精度为目标优选出CNN模型。通过对混合SBD和SDBD数据集展开训练,分类精度高达93.7%,实现了对残缺和完整的九种大麦种子的全分类模型需求。同时,优选模型对仅SBD数据集展开训练,九类单品类麦种图像最佳分类精度高达95.7%,实现了高精度的完整的大麦种子分类需求。通过对SBD数据集中的六类和八类大麦种子展开训练,达到97%和96.5%的分类精度,分别高出文献的分类精度4%和7.53%。
3、针对单品类麦种类内多样性、类间相似性,提出了融合自注意力机制的双线性细粒度大麦种子识别方法,可有效提高训练速度和识别精度综合指标。该方法结合AlexNet和ResNet50的双线性卷积神经网络及自注意力机制。大麦种子图像(即SBD数据集),经AlexNet和ResNet50的特征提取,并通过自注意力机制进一步细化特征表达。经过特征张量展平与外积操作后,得到双线性池化特征,最终通过全连接层分类。理论分析与实验验证均证明该方法的可靠性及其优异的分类精度,最终取得高达97.0%的分类精度。最终,将训练完成的模型封装,设计普适性的单品类麦种识别系统,实现实验室环境下的单品类麦种图像识别技术的应用。
4、针对多品类混杂的麦种识别和纯度检测任务,提出了一种结合YOLOv5模型和Squeeze-and-Excitation(SE)注意力机制模块的方法,提高模型对细粒度特征提取的性能。为解决多个随机麦种图像数据集(MBD数据集)样本单一、数据量不足和样本均衡的问题,随机选取部分SBD数据集进行融合。通过分析数据并针对MBD和SBD数据集,分别应用相应的数据增强方法进行扩充。采用YOLOv5模型系列对数据集进行训练对比,实现了大麦种子的高精度多目标识别。实验结果中,改进YOLOv5x模型的精度为98.3%,相较于仅使用MBD数据集训练的结果,混合类型的SBD和MBD数据集表现更佳,识别精度高出38%。进一步地,基于改进YOLOv5x模型的识别结果,通过统计测量,实现对混合麦种随机铺放图像的实时检测与大麦种子纯度的实时判定。最终,将训练完成的模型封装,设计普适性的多品类麦种识别系统,实现多种环境下的麦种识别技术的应用。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2024.000005
{DOI}: 10.27232/d.cnki.gnchu.2024.000005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手势识别研究
{Author}: 王亚宁
{Tertiary Author}: 赵成贵
{Publisher}: 云南财经大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: YOLOv7-tiny;IoU;可变形卷积;注意力机制
{Abstract}: 计算机技术的飞速发展带动人工智能应用的火热,人们对于科技改变生活的需求也越来越强烈,在智能家居领域该种需求尤为明显。可是人工智能应用的革新离不开人机互动方式的创新,其中手势识别因自然直观、组合性强、灵活多样等特点成为许多研究者研究的重点。随着计算机算力的提升以及国内外深度学习的发展,研究者不在局限于传统的手势识别方法,而是开始了基于计算机视觉的手势识别研究。但是利用计算机视觉进行目标检测很大程度上受拍摄角度、拍摄时光线强弱和距离远近的影响,同时手势识别本身存在检测目标小、相似手势识别准确率低以及受背景环境的干扰等问题。针对以上问题,本文提出了一种基于深度学习的手势识别方法,该方法可以在保证检测精度的同时提高检测速度。主要工作内容包括以下三个方面:(1)手势数据集的构建。本文从公开手势数据集Hagrid中有选择性的选取了9000张图片,但是该数据集多为欧美人,鉴于该问题,自建了亚洲人手势数据1003张进行数据集的扩充。同时某些图片中存在二只手,故把这些图片的手部标注为no＿gesture,这样就一共定义了19种与手势相关的类别。最后基于该10003张图片构建VOC格式的手势数据集,为后续模型训练提供数据支持。(2)使用YOLO系列算法进行手势识别研究。在上述定义数据集的基础上,对比分析了YOLOv6n、YOLOv7-tiny、YOLOv7、YOLOv7x、YOLOv8n模型在手势识别中的实际应用,根据检测精度和检测速度优劣,最终选取了YOLOv7-tiny作为本次研究的基准模型。(3)针对实验中存在的问题对YOLOv7-tiny算法进行改进。为了进一步提升YOLOv7-tiny模型的应用性能,故本文将针对原模型的三个方面进行优化。首先,补充亚洲数据可能造成样本不平衡,因此采用Focal＿EIo U Loss改进原模型的边框损失函数,改进后的模型m AP＿0.5提高了0.029,FPS提高了78.432;其次,手本身大小不一,手部形态各异为不规则图形,所以在原模型的主干网络中融入可变形卷积模块,致模型的m AP＿0.5提高了0.014;接着,考虑到背景环境对检测目标的干扰,引入注意力机制使模型更加关注手势的位置信息,实验结果表明引入Sim AM注意力机制的加入提升效果更好,m AP＿0.5提高了0.031,FPS提高了78.432。最后进行消融实验,综合检测精度速度两方面表现,得到了一个最优模型YOLOv7-tiny+Focal＿EIo U+DCNv2+Sim AM模型,与原模型比较其m AP＿0.5提高了0.036,FPS提高了78.432。综上所述,针对手势识别中存在的问题,对YOLOv7-tiny算法进行改进,寻找到了合适的检测模型,并通过实验验证达到了预期研究目的,即提高了检测精度又提升了检测速度。
{URL}: https://link.cnki.net/doi/10.27455/d.cnki.gycmc.2024.000286
{DOI}: 10.27455/d.cnki.gycmc.2024.000286
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于卷积神经网络的人群密度分析防踩踏系统
{Author}: 夏军;王鑫一;鄢嫣;姚平
{Author Address}: 长江大学物理与光电工程学院;
{Journal}: 物联网技术
{Year}: 2024
{Volume}: 14
{Issue}: 05
{Pages}: 128-132
{Keywords}: 防踩踏;人群计数;人群密度:卷积神经网络;照相机;机器视觉
{Abstract}: 随着城市化进程的加快，节日聚会等大型活动越来越多，在这种人群密集的环境中，人民群众的生命安全受到很大的威胁。鉴于此问题，提出了一种基于卷积神经网络的人群密度分析防踩踏方法，利用已有的人群计数手段CAN人群计数模型和ShanghaiTech数据集，辅以计算图片中场景的实际面积，实现了图片中人群密度的识别，并按照3种不同的密集程度划分预警状态，给出相应的防范措施，以达到防踩踏的目的。实验结果表明，本系统对于防止人群密集程度过大导致的踩踏事故具有较大的可行性和较高的可靠性。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2024.05.033
{DOI}: 10.16667/j.issn.2095-1302.2024.05.033
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉与Canny算法的服装纸样轮廓提取
{Author}: 庹武;杜聪;陈谦;吴超;魏新桥;张欣汝;刘思雨
{Author Address}: 中原工学院服装学院;河南工学院电气工程与自动化学院;
{Journal}: 纺织学报
{Year}: 2024
{Volume}: 45
{Issue}: 05
{Pages}: 174-182
{Keywords}: 服装纸样提取;计算机视觉;相机标定;图像处理;Canny边缘检测算法;轮廓后处理;样板转化
{Abstract}: 为提高服装二维纸样轮廓信息采集转换的准确性及方便性，设计了一种基于计算机视觉的服装纸样轮廓提取方法。将手机相机作为图像采集设备，采用相机标定的方法进行图像畸变矫正，对图像灰度化处理后进行伽马变换。通过改进的Canny算法对纸样图像进行边缘信息的提取，使用自适应双边滤波保边去噪；在原Sobel算子上增加了45°和135°方向的梯度模板计算梯度；采用自适应双阈值确定边缘；融合形态学算法处理轮廓；最后按需进行轮廓骨架提取。结果表明：本文方法适用于二维纸样的轮廓提取，其提取误差在0.15～1.50 cm之间，可实现单独对服装纸样的外轮廓、内轮廓及内外轮廓图的提取，完成轮廓的无差别提取，减少后期人工对轮廓图的编辑，提高二维纸样数字化录入效率。
{ISBN/ISSN}: 0253-9721
{Notes}: 11-5167/TS
{URL}: https://link.cnki.net/doi/10.13475/j.fzxb.20230502901
{DOI}: 10.13475/j.fzxb.20230502901
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5的加油站不安全行为检测算法研究
{Author}: 张泽明;曹金凤;贾舒安;薛茂林;彭博
{Author Address}: 青岛理工大学机械与汽车工程学院;
{Journal}: 工业安全与环保
{Year}: 2024
{Volume}: 50
{Issue}: 05
{Pages}: 80-85+91
{Keywords}: 加油站;不安全行为;深度学习;机器视觉;YOLOv5
{Abstract}: 针对传统方法检测加油站场景下人员不安全行为存在检测精度低、速度慢等问题，提出了改进的YOLOv5-MVB算法来检测加油站不安全行为（抽烟、打手机等）框架。首先，建立针对加油站场景的不安全行为数据集；其次，对不安全行为数据集进行图像增强及改进Mosaic增强，提高数据集的泛化能力；然后，搭建改进的YOLOv5s网络结构，采用基于IoU度量距离的K-means算法对不安全行为数据集重新聚类，获得多组锚框，引入深度可分离卷积网络及多尺度注意力机制，提高网络的收敛速度与检测精度。实验结果表明：改进后的YOLOv5-MVB模型精度达到82.2%，精确率达到85.3%，召回率为77.1%，参数量只有8.15M，相比于原版YOLOv5s算法以及主流小目标检测算法（SSD、YOLO系列算法等）均可在保持较低参数量和计算量的情况下有效提高不安全行为的检测精度。所提算法实现了对加油站不安全行为的近实时检测，具有较好的推广应用价值。
{ISBN/ISSN}: 1001-425X
{Notes}: 42-1640/X
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzrfXto-DL_C0p9aHei4LLgwrLPBlpE6Mma1AcCXqz2GgLhaYymryvVlyudUcopqxuuqJKZa9ZsXX11k_z1HfIEyP9_Ut0bOi4ufZXdzo0DgOPeYRfAVIMx7jRsG0H7gV-a42dAJ2aO6-dXI24dQd7IYsP9irPg45FHCCjLhyjEf8--AoGNCLpW_m5itbOd7i0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 低慢小目标空间定位与跟踪技术研究
{Author}: 张永霖
{Tertiary Author}: 冯斌;宋岩峰
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 低慢小目标;双目视觉;空间定位;目标跟踪
{Abstract}: 低慢小目标的空间定位与跟踪技术备受计算机视觉领域关注,因其广泛应用潜力而受到众多学者的密切关注。低慢小目标具有目标尺寸小、不易侦察等特点,使用传统雷达进行防控难度较大且成本较高。近年来随着计算机技术的快速发展,使用计算机视觉对小目标进行空间定位与跟踪任务受到了青睐。本文以双目立体视觉为基础,对低慢小目标空间定位和跟踪技术进行了研究,并通过实验验证分析了双目视觉系统对无人机等低慢小目标空间定位与跟踪的可行性。主要研究内容如下:
(2)首先针对低慢小无人机目标尺度变化大、目标的识别率低的问题,提出一种基于YOLOv5s改进的深度学习卷积神经网络目标检测器。引用重复加权的自顶向下和自底向上的特征金字塔结构对深度学习原有的PANet结构进行替换;将原有的三个目标分类检测头改为由四个特征图输出的四个检测头;引入归一化高斯最优传输距离对定位损失度量函数进行替换,实验数据表明网络在自建无人机小目标数据集上的识别准确率平均提升1.1%。
(1)为了实现对低慢小目标的空间定位,对目前基于计算机视觉的目标空间定位基本理论方面进行了研究,推导出空间中四大坐标系之间的关系。并设计了基于双目相机作为观测站的低慢小目标的空间定位系统,建立了以双目相机左相机镜头光心为坐标原点的坐标系。首先通过拍摄到的左右相机画面结合目标检测算法得到目标中心在图像上的坐标,研究左右相机图像的立体匹配算法,计算给出低慢小目标相对于双目系统的坐标信息,实验数据表明,本文建立的双目视觉系统可以有效地对低慢小目标进行空间定位。
(3)对于低慢小无人机目标在运动空间的跟踪预测准确率低的问题,本文对卡尔曼滤波算法进行深入研究,建立了包含空间中低慢小目标的六维状态量的测量方程与状态转移方程;对卡尔曼滤波的算法中识别到低慢小无人机目标时的处理机制和对目标误识别和目标丢失情况做出改进,以此提高了目标轨迹预测的效率;将匹配关系进行了改进,引入了结合空间欧氏距离与归一化高斯最优传输距离的匹配关系,提高了同一目标在不同时刻的匹配准确率。实验结果表明,通过改进后的卡尔曼滤波跟踪效果较好,能够更好的基于历史轨迹和运动模型预测低慢小无人机目标未来的运动轨迹,相较改进前跟踪算法,其MOTA提升1.7869%,IDF1提升3.0961%,平均HOTA提高了12.1894%。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000453
{DOI}: 10.27391/d.cnki.gxagu.2024.000453
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于细节特征增强的小目标检测方法研究
{Author}: 公鹏
{Tertiary Author}: 潘晓
{Publisher}: 山东财经大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 目标检测;小目标检测;卷积神经网络;超像素
{Abstract}: 当今时代,随着图像与视频数据的爆炸性增长,计算机视觉技术已经成为许多领域发展的关键驱动力。计算机视觉是研究如何使机器“看”并理解图像或视频的学科,涵盖了从图像获取、处理、分析到理解的一系列技术和方法。目标检测是计算机视觉中的一个重要任务,旨在识别图像或视频中感兴趣的目标物体,并确定它们的位置。小目标检测是目标检测的一个子任务,专注于解决在图像中检测小尺寸目标物体时遇到的问题。随着智能交通、无人机应用等实际任务的出现,小目标检测也越来越受到关注。
但在实际应用中,由于尺寸小、分辨率低、背景复杂等原因,相较于常规大小物体的检测,小目标物体的检测更加困难,传统目标检测算法往往难以准确识别小目标。因此,研究小目标检测算法对于实现更精准的目标检测具有重要意义。本文以小目标检测为研究方向,以增强对小目标物体的检测能力为研究目标,从细节特征增强的角度对小目标检测进行了研究,具体研究内容如下:
第一,本文提出了一种基于小步长卷积的小目标检测算法。由于小目标物体在图像中占据的像素较少,其特征信息也相对有限,在卷积神经网络的传播过程中,卷积或池化等下采样操作的不得当,都会使小目标的特征信息在网络传播初期就产生大量丢失,本文因此提出了具有较小卷积步长的S1CP模块,来更好的提取浅层网络中的小目标细节特征;随着网络的加深,特征图逐渐减小,小目标本就微弱的特征信息会被淹没在大量的通道中,本文针对这一问题提出了一种新的目标检测网络结构SC-YOLO,通过多尺度特征融合,充分利用小目标在浅层网络中的特征信息;另外,针对CIo U对预测框与目标框之间高宽比的模糊定义问题,本文提出了一种新的损失函数CIo U-hw loss,该损失函数可以反映出边界框之间高宽的真实关系。实验结果表明,本文提出的方法可以提高小目标检测精度。
第二,本文提出了一种基于晶格状超像素的小目标检测算法。小目标物体多出现于复杂的场景下,因其尺寸小、分辨率低、边界模糊等问题,容易被背景信息所干扰,或被其他物体所遮挡,这使得目标检测网络难以从输入图像中完整地准确地提取小目标特征,如果小目标的特征信息在进入网络时就已经十分微弱,那么无论在后续的网络传播过程中如何减少特征丢失,都无法得到详细可靠的小目标特征信息。针对这一问题,本文提出了一种基于晶格状超像素的小目标检测算法,通过引入超像素技术来增强目标检测网络对输入图像中的小目标物体定位与识别,以获得更完整的小目标特征信息。为了使晶格状超像素成功融入到目标检测网络中,本文提出了SPXP模块;同时本文提出了一种新的目标检测网络结构SPX-YOLO,该网络结构能够良好兼容超像素技术,更好地捕捉图像中的小目标;此外为了使该目标检测网络更专注于图像中的小物体目标,本文将卷积块注意力模块CBAM加入到了SPX-YOLO网络中。通过实验表明,本文所提方法对提高小目标检测能力起到了积极作用。
{URL}: https://link.cnki.net/doi/10.27274/d.cnki.gsdjc.2024.001090
{DOI}: 10.27274/d.cnki.gsdjc.2024.001090
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的课堂专注度检测研究
{Author}: 邓子豪;梁艳
{Author Address}: 华南师范大学软件学院;
{Journal}: 软件导刊
{Year}: 2024
{Volume}: 23
{Issue}: 08
{Pages}: 254-260
{Keywords}: 线下教学;专注度检测;计算机视觉;人脸检测;ViViT
{Abstract}: 为了检测课堂学习时班级整体专注程度，设计了一套基于计算机视觉的课堂专注度检测系统。该系统根据面部关键点位置计算头部偏转角度，进而判断视线是否位于专注区域，采用ViViT模型对学习者的专注度进行四分类，最后综合人脸检测信息、视线信息、专注度分类信息计算班级整体专注度。实验结果证明，该系统能根据监控视频快速、有效地评估班级在某时刻的整体专注度，为教师提供客观、准确的专注度数据，有助于教师有针对性地及时调整教学方式，提高教学质量。
{ISBN/ISSN}: 1672-7800
{Notes}: 42-1671/TP
{URL}: https://link.cnki.net/urlid/42.1671.TP.20240425.1140.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与BA-BP的苹果分级系统研究
{Author}: 刘佳浩;高军伟
{Author Address}: 青岛大学自动化学院,山东省工业控制技术重点实验室;
{Journal}: 中国农业科技导报
{Year}: 2024
{Volume}: 26
{Issue}: 11
{Pages}: 117-125
{Keywords}: 水果分级;机器视觉;蝙蝠算法;BP神经网络
{Abstract}: 为实现水果的精确分级，以苹果为分拣对象，设计了基于机器视觉与BA-BP的苹果分级系统。首先，对实时采集的苹果图像进行预处理，得到轮廓图像，采用改进的Canny边缘检测算法提取苹果轮廓，使用最小外接圆法、颜色模型转换和灰度共生矩阵等方法提取苹果果径、色泽度、圆形度和纹理特征；其次，对采集的训练组数据进行滤波和归一化处理，将处理好的数据输入到BP神经网络模型中，再利用蝙蝠算法对BP网络模型进行优化，完成网络模型的训练；最后，将测试组数据分别输入到完成训练的BA-BP神经网络系统和BP神经网络系统中。结果表明，BA-BP神经网络系统识别准确率达到96%，性能明显优于BP神经网络系统，平均分级时间在1.25 s以内。因此，该系统满足实际生产中对于苹果分级的需求，有助于实现对于苹果品级的准确识别。
{ISBN/ISSN}: 1008-0864
{Notes}: 11-3900/S
{URL}: https://link.cnki.net/doi/10.13304/j.nykjdb.2023.0506
{DOI}: 10.13304/j.nykjdb.2023.0506
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的钢轨表面面型缺陷分类实验设计
{Author}: 李珂嘉;张璐薇;马跃洋;尹昱东;杨帆;张璐
{Author Address}: 西安交通大学仪器科学与技术学院;西安工业大学光电工程学院;西安交通大学机械工程学院;西安交通大学化学学院;
{Journal}: 实验室研究与探索
{Year}: 2024
{Volume}: 43
{Issue}: 03
{Pages}: 122-127+134
{Keywords}: 钢轨表面缺陷检测;机器视觉;图像处理;缺陷分类
{Abstract}: 随着城市轨道交通的飞速发展，实现钢轨表面缺陷实时检测对铁路行业稳步发展意义重大。如何实时检测钢轨表面缺陷是保障铁路运行安全亟须解决的一个关键问题。鉴于此，设计了一套基于机器视觉的钢轨表面缺陷检测实验仿真方法。搭建图像采集、图像预处理和缺陷分类等模块；提出自拟合亮度调整算法完成像素值统计，得到清晰的缺陷特征图像；用750组数据训练网络权值，实现缺陷分类预测；经过数据分析和误差评估，识别准确率在90%以上，相关系数高达0.96,单幅图像平均耗时1.267 s,测试表明，所提方法能准确、高效地实现钢轨表面缺陷信息的缺陷分类与识别。
{ISBN/ISSN}: 1006-7167
{Notes}: 31-1707/T
{URL}: https://link.cnki.net/doi/10.19927/j.cnki.syyt.2024.03.024
{DOI}: 10.19927/j.cnki.syyt.2024.03.024
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的种子质量检测综述
{Author}: 宁孝梅;马慧敏;王小申;胡健威;张帅男;张宸曦;胡宇豪
{Author Address}: 安徽农业大学信息与人工智能学院;
{Journal}: 河南工业大学学报(自然科学版)
{Year}: 2024
{Volume}: 45
{Issue}: 02
{Pages}: 140-149
{Keywords}: 粮食种子;深度学习;外观品质;无损检测;机器视觉
{Abstract}: “种优则粮丰，粮安则民安”。我国是粮食大国，为保障粮食安全，需要紧抓种子质量，健康的种子和适宜的品种可以显著提高农作物的产量和质量。因此实现快速、无损地检测种子质量的技术对于粮食生产具有重要的意义。近年来，机器视觉作为一种无损检测方法在粮食种子质检领域得到了广泛应用。通过对粮食种子图像数据进行训练，最终得到能够准确、快速识别种子外观品质的模型。重点从数据集角度出发，总结了基于深度学习算法在小麦、稻米、玉米等主要粮食种子的外观品质检测方面的研究进展，并根据这些研究存在的不足对该领域未来的研究方向进行了展望。
{ISBN/ISSN}: 1673-2383
{Notes}: 41-1378/N
{URL}: https://link.cnki.net/doi/10.16433/j.1673-2383.2024.02.017
{DOI}: 10.16433/j.1673-2383.2024.02.017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的视觉语言多模态推理方法研究
{Author}: 姚俊豪
{Tertiary Author}: 沈复民
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 视觉语言推理;提示学习;思维链提示;文档视觉问答
{Abstract}: 随着数字化时代的快速发展,大量的文档资料被电子化存储,这为自动提取信息和知识提供了可能。然而简单的文本识别和数据提取已经无法满足日益增长的信息处理需求。因此,文档视觉问答任务应运而生,它不仅要求机器识别和理解图像中的文字内容,还要求它能够根据问题的上下文来链接视觉信息与文本信息,进行推理和分析,最终给出准确的答案。文档视觉问答任务具有巨大的潜力和价值,研究人员正在探索各种先进的算法和技术,以推动文档视觉问答系统的发展。虽然这些方法在文档视觉问答任务上取得了一定的进展,但仍然存在一些问题:(1)使用预训练-微调范式来进行文档视觉问答任务,在少样本或零样本学习条件下,未能充分挖掘和利用文档图像信息,进而影响了它们在处理文档视觉问答任务时的性能表现。(2)简单地使用大语言模型在处理少样本时的上下文学习能力,很难有效地掌握文档数据的视觉信息,且不同的演示示例也会导致推理效果变化。(3)大语言模型在处理复杂的推理任务时,不透明度的决策过程有时会引发一些细微的错误,最终可能导致不正确的推理结果。针对当前文档视觉语言问答任务中存在的推理方法局限性,本文展开了深入研究,并提出了两种基于提示学习的推理方法。首先,本文通过引入布局感知提示方法,利用OCR算法处理后的文档图像数据,结合文本与位置信息的映射,保证了文档视觉语言数据能够被大语言模型更好地理解,可以从少样本学习中提取出有效的信息,从而提升了推理结果的准确性。紧接着,为了解决大语言模型在复杂推理任务中不可见的思考过程以及可能导致的推理错误,本文提出了一种基于思维链提示的零样本方法。该方法通过引导模型生成推理计划与执行结果,再整合推理过程得出答案,这样的方法能够提供更为细致的指导,从而确保大语言模型在零样本学习条件下进行文档视觉问答任务时,能够准确地进行逻辑推理。这一过程显著地提高了大型语言模型在文档视觉问答任务中的逻辑推理精确度。本文提出的方法通过实验和对比证明了有效性与可靠性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.001846
{DOI}: 10.27005/d.cnki.gdzku.2024.001846
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MediaPipe的无人小车手势识别控制系统设计与实现
{Author}: 薛宾田;申玉斌
{Author Address}: 河南牧业经济学院信息工程学院;
{Journal}: 电脑编程技巧与维护
{Year}: 2024
{Volume}: 
{Issue}: 03
{Pages}: 137-139+143
{Keywords}: 无人小车;手势控制;MediaPipe技术;人机交互;计算机视觉
{Abstract}: 主要研究了基于MediaPipe的无人小车手势识别控制系统的设计与实现。首先，介绍了国内外相关领域的发展现状和存在的问题。其次，对MediaPipe技术进行了详细的研究分析，并结合该技术的特点提出了一种新的基于MediaPipe的无人小车手势识别控制方法。在实验部分中，通过搭建一个基于MediaPipe的无人小车手势识别控制平台，验证了所提出的方案的可行性。通过实验验证了所提出的基于MediaPipe的无人小车手势识别控制系统的有效性、稳定性和鲁棒性。
{ISBN/ISSN}: 1006-4052
{Notes}: 11-3411/TP
{URL}: https://link.cnki.net/doi/10.16184/j.cnki.comprg.2024.03.047
{DOI}: 10.16184/j.cnki.comprg.2024.03.047
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能搬运机器人设计
{Author}: 兰天翔;刘英
{Author Address}: 南京林业大学机械电子工程学院;
{Journal}: 林业机械与木工设备
{Year}: 2024
{Volume}: 52
{Issue}: 03
{Pages}: 30-35
{Keywords}: 搬运机器人;机器视觉;路径规划
{Abstract}: 搬运机器人作为一种工业生产设备，为了进一步适应工作环境，解放劳动力，对其智能化程度的要求越来越高。在此背景下，为了满足实际生产的需求，在保证搬运机器人现有功能的情况下，需尽可能进一步提高搬运机器人的智能化程度，设计并实现了一种基于机器视觉的智能搬运机器人，探索机器视觉在搬运机器人中的应用。具体选择直角坐标结构作为机器人的机械结构，选用同步带型直线模组作为搬运机器人的传动机构。采用STM32F103C8T6最小系统板，设计并实现了下位机的搭建及控制程序编写。使用tkinter作为开发工具，设计并编写了上位机软件。使用OpenCV,通过摄像头捕捉画面，经过图像处理后，获取物块颜色及位置信息。并针对搬运任务的路径规划进行了研究，通过图与网络模型及方法，对搬运机器人的路径规划任务进行了分析，建立了相应的图与网络的数学模型，使用KM算法实现了搬运机器人的路径规划。
{ISBN/ISSN}: 2095-2953
{Notes}: 23-1405/S
{URL}: https://link.cnki.net/doi/10.13279/j.cnki.fmwe.2024.0018
{DOI}: 10.13279/j.cnki.fmwe.2024.0018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: ConvFormer：基于Transformer的视觉主干网络
{Author}: 胡杰;昌敏杰;徐博远;徐文才
{Author Address}: 武汉理工大学汽车工程学院;武汉理工大学现代汽车零部件技术湖北省重点实验室;武汉理工大学汽车零部件技术湖北省协同创新中心;武汉理工大学湖北省新能源与智能网联车工程技术研究中心;
{Journal}: 电子学报
{Pages}: 1-12
{Keywords}: 机器视觉;自注意力;主干网络;Transformer
{Abstract}: 针对主流Transformer网络仅对输入像素块做自注意力计算而忽略了不同像素块间的信息交互，以及输入尺度单一导致局部特征细节模糊的问题，本文提出一种基于Transformer并用于处理视觉任务的主干网络ConvFormer. ConvFormer通过所设计的多尺度混洗自注意力模块（Channel-Shuffle and Multi-Scale attention,CSMS）和动态相对位置编码模块（Dynamic Relative Position Coding,DRPC）来聚合多尺度像素块间的语义信息，并在前馈网络中引入深度卷积提高网络的局部建模能力.在公开数据集ImageNet-1K,COCO 2017和ADE20K上分别进行图像分类、目标检测和语义分割实验，ConvFormer-Tiny与不同视觉任务中同量级最优网络RetNetY-4G,Swin-Tiny和ResNet50对比，精度分别提高0.3%,1.4%和0.5%.
{ISBN/ISSN}: 0372-2112
{Notes}: 11-2087/TN
{URL}: https://link.cnki.net/urlid/11.2087.TN.20240311.1735.014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的芯片封装基板表面缺陷检测研究
{Author}: 李研
{Tertiary Author}: 车艳秋;姚文达
{Publisher}: 天津职业技术师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 计算机视觉;深度学习;YOLOX算法;注意力机制
{Abstract}: 半导体芯片是电子产品最为关键的元器件。作为半导体芯片的载体,芯片封装基板在实际生产过程中,其表面会产生各种缺陷从而影响芯片整体性能。传统的人工目检法存在检测速度慢、检测结果不准确且一致性差、人工成本高等问题,鉴于此,本文提出应用深度学习技术实现芯片封装基板表面缺陷的快速准确自动检测。
(1)使用Label Img标定图像缺陷区域的位置信息和类别信息,实现目标检测任务所需数据集的标签标注;针对芯片封装基板数据集样本不均衡、尺度不同问题,采用添加局部图、数据增强的方法,将数据集从1231张图像扩展到1871张。
(2)针对芯片封装基板表面缺陷数据集,对常用目标检测算法进行对比实验研究,得出Yolox-l算法对本文数据集检测性能最均衡。
(3)针对芯片封装基板数据集中缺陷易于与底板混淆、缺陷尺寸差异大的问题,提出了改进Yolox-l检测算法,并进行了实验验证。将YOLOX的加强特征提取网络替换为融合了有效通道注意力的双向加权特征提取网络;将主干特征提取网络中的3×3卷积块替换为COTNet卷积块;将Yolox-l的Io U损失函数替换为CIo U;将Yolox-l的Swish激活函数替换为Mish激活函数。实验对比研究了改进前后Yolox-l算法对各类芯片封装基板表面缺陷的自动检测效果,结果表明,改进后的Yolox-l算法的综合检测性能更佳。
本文提出改进Yolox-l算法并实现对芯片封装基板外观缺陷进行快速、准确的自动检测,具有重要的实用价值。
{URL}: https://link.cnki.net/doi/10.27711/d.cnki.gtjgc.2024.000114
{DOI}: 10.27711/d.cnki.gtjgc.2024.000114
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进的RetinaNet大豆外观品质无损检测
{Author}: 周春欣;霍怡之;杜有海;蒋敏兰;曾令国;张长江;石小威
{Author Address}: 浙江师范大学物理与电子信息工程学院;新疆阿克苏教育学院;浙江光电子研究院;台州学院电子与信息工程学院;杭州海康威视数字技术股份有限公司;
{Journal}: 中国粮油学报
{Year}: 2024
{Volume}: 39
{Issue}: 09
{Pages}: 172-180
{Keywords}: 卷积神经网络;大豆外观品质检测;RetinaNet;FPN;ECA模块
{Abstract}: 快速、准确、有效地区分大豆外观品质是大豆食品质量检验和食品安全与包装中的一项重要而艰巨的任务。本研究提出了基于改进的卷积神经网络Retina Net的大豆外观品质检测模型。将原始主干网络ResNet50替换为ResNet34,在保证准确度的同时降低了模型参数量，提高了运算速度，降低了运算时间。在主干网络和特征金字塔(FPN)的输出端分别嵌入ECA模块，进一步提取有利特征，减轻了冗余特征对网络的影响，提高了网络性能。同时，为保证不失原有特征的丰富性，将FPN后嵌入的ECA模块的输出与主干网络的输出结果相叠加，所得特征作为输入，传入分类器中进行识别检测。结果表明，本研究提出的改进的RetinaNet大豆品质检测模型的精确率达97.39%,mAP值达98.64%。
{ISBN/ISSN}: 1003-0174
{Notes}: 11-2864/TS
{URL}: https://link.cnki.net/doi/10.20048/j.cnki.issn.1003-0174.000750
{DOI}: 10.20048/j.cnki.issn.1003-0174.000750
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的驾驶员危险驾驶检测系统的设计与实验研究
{Author}: 张贝宁;郜健铭;王靖涵;张敬;顿媛雅;许留洋
{Author Address}: 周口师范学院;
{Journal}: 科学技术创新
{Year}: 2024
{Issue}: 03
{Pages}: 48-51
{Keywords}: 机器视觉;驾驶员危险驾驶检测系统;人脸检测;图像预处理
{Abstract}: 本文基于机器视觉技术设计了驾驶员危险驾驶检测系统，该系统的硬件部分包括DSP芯片、摄像头和音频芯片等；软件部分包括图像采集和预处理模块，目标检测模块和疲劳驾驶检测模块。实验结果表明，该系统的人脸检测准确率较高，疲劳驾驶检测的准确度达到86%，较好地完成了驾驶员危险驾驶行为的检测任务。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvweW0cReaidFSj-REnKqiRBUxbU39x-N55Exi1VlUPLych6Iz3Ctmlf6h6nmANNoYucEx6QzXhSkSbjTqmuTiUSUtyTh-Q9SJ2SuOCmq0KR8NrOvEtVYLwGOuqKXmO9bAxy8VkN_J6Qyg6rmaiPoH4u6MejAQVSqCfunQnXTbT2DCBTj2Ot_xExUSa7ZzJW-98=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的菠萝自动去眼方法与试验
{Author}: 刘安稳;谢方平;向阳;李亚军;雷翔茗
{Author Address}: 湖南农业大学机电工程学院;智能农机装备湖南省重点试验室;北京农林科学院智能装备研究中心;
{Journal}: 农业工程学报
{Year}: 2024
{Volume}: 40
{Issue}: 01
{Pages}: 80-89
{Keywords}: 农业机械;机器视觉;设计;菠萝眼;YOLOv5;三维定位
{Abstract}: 菠萝加工过程中的去眼作业目前主要依赖人工手动操作，劳动成本高且作业效率低。为实现自动化菠萝去眼作业，该研究运用YOLOv5目标检测算法对菠萝眼进行快速识别，将所有角度相差90o的两张图片作为一组进行立体匹配分析以获取菠萝眼的三维位置信息。通过旋转菠萝和轴向移动去眼刀具将专用去眼刀具依次对准每一个菠萝眼并快速去除。试验结果表明：YOLOv5目标检测算法对菠萝眼识别效果良好，验证集的准确率、召回率和平均精度均值均高于96%；菠萝眼实际中心与探针刺入位置的平均误差为1.01 mm，最大误差为2.17 mm，均方根误差为1.09 mm；菠萝眼的完全去除率为89.5%、不完全去除率为6.2%，漏检率为4.3%，单个菠萝去眼时间为110.9 s，基本满足自动化去眼作业需要。研究结果可为菠萝自动去眼机研发提供技术参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20240126.1908.048
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的公路桥梁变形测量及安全预警
{Author}: 苏子玥;杜文康;雷冬
{Author Address}: 河海大学力学与材料学院;河海大学苏州研究院;
{Journal}: 中外公路
{Year}: 2024
{Volume}: 44
{Issue}: 05
{Pages}: 248-258
{Keywords}: 公路桥梁;机器视觉;结构动态位移;有限元分析;安全分析
{Abstract}: 公路桥梁结构安全对交通安全运营和区域经济发展起到关键作用，但由于交通荷载的快速增加和复杂变化，桥梁结构变形及安全状况实时监测的需求日益凸显。然而，以接触式传感器为主的结构健康监测系统存在安装施工难、维护更换繁、需要中断交通等局限。为此，该文提出了一种基于机器视觉的非接触式变形测量系统，利用模板匹配和特征点识别方法，实现结构表面标记的识别和关键位置的位移提取，并通过实验室和现场试验对视觉方法的准确性和稳定性开展测试。此外，针对实际桥梁结构运营状况建立相匹配的有限元分析模型，通过动静力学试验设定多级预警阈值，进一步判定结构的安全状况。试验结果表明：(1)所建立的视觉变形测量系统位移测量误差在5%以内，振动频率误差在1%以内；(2)基于模板匹配和特征点识别的测量技术能够对结构自有特征进行识别，满足长期性变形监测的需求；(3)通过多工况下有限元分析，可以为结构长期位移监测设置预警阈值。
{ISBN/ISSN}: 1671-2579
{Notes}: 43-1363/U
{URL}: https://link.cnki.net/doi/10.14048/j.issn.1671-2579.2024.05.028
{DOI}: 10.14048/j.issn.1671-2579.2024.05.028
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的受电弓非显性异物检测及去雪关键算法研究
{Author}: 吕文剑
{Tertiary Author}: 谭平
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 受电弓;图像处理;深度学习;入侵检测算法;受电弓结构检测算法
{Abstract}: 受电弓是高速列车的关键部件,通过与高铁线路上方接触线的摩擦接触取电,为动车组提供所需动力。在列车运行时,受电弓有时面临着异物附着的风险,这可能严重影响电力供应进而引起弓网事故。因此对受电弓工况进行实时监测显得尤为关键。为提高高铁动车组的安全性和稳定性,本文对受电弓状态的实时监测进行了深入研究。目前,异物入侵检测技术主要依赖于深度学习的目标检测算法模型和传统运动目标检测算法,然而,在高铁列车实际运行中,受电弓区域的异物入侵往往是偶发事件,样本数量少,难以构建足够的训练数据集来支持深度学习模型的训练。同时,由于高铁运行环境复杂,监控视频背景受到照明、天气、阴影、运动物体等多种复杂因素的干扰,例如在运行过程中,监控视频背景经常存在太阳,闪光灯等光源,监控视频背景也存在着其它运动物体(如接触网,腕臂支撑装置)的遮挡,可能引入大量噪声,进而影响传统运动目标检测算法的准确性。为了解决训练数据不足和复杂背景引起的问题,本文通过系统研究,提出了一种高效的机器视觉算法。该算法不仅能够准确检测受电弓的故障和状态,而且在高铁快速运行的复杂环境中表现卓越,为高铁动车组的安全运行提供了可靠的技术支持。其主要内容包括:
(1)从高铁受电弓监控视频中不同的运动物体具有不同的运动特征方向出发,论文提出了结合Farneback稠密光流法和LSTM神经网络的入侵异物检测算法。研究Farneback稠密光流法提取高铁受电弓监控视频中不同运动物体的运动信息,包括入侵异物、接触网和其他背景物体,形成了光流特征时间序列数据集,通过LSTM-Attention模型对时间序列数据进行检测分类,融合光流位移长度和角度特征以提高分类准确性,并引入了注意力机制以增强模型的特征提取能力。最后,通过形态学图像处理方法获得动态半透明异物的区域。
(2)针对雨雪天气下图像水滴黏附因素导致目标检测模型(YOLOV4)检测受电弓结构性能降低的问题,本文提出了基于改进型attentive-gan-derain模型和YOLOV4目标检测模型的雨雪环境下受电弓结构检测算法。将受到黏附水滴遮挡的受电弓图像送入改进型attentive-gan-derain模型进行图像去水滴操作,然后再引进YOLOV4目标检测模型进行检测。试验结果表明,本文所设计的算法模型相对于单独使用YOLOV4,更适用于雨雪天气下的受电弓结构检测,能够获得更好的目标检测精度和效率。
(3)本文在不同场景下的高铁受电弓异物数据集和雨雪天气受电弓监控视频数据集进行上述算法的实验和验证。试验结果表明,受电弓区域异物入侵检测算法对于入侵异物像素点检测准确率均达到90%以上,在不同高铁受电弓监控视频中都能准确定位异物区域。基于深度学习的雨雪环境下受电弓结构检测模型算法能够有效地对不同场景下的水滴黏附受电弓视频进行准确结构检测,解决了单一目标检测算法因为图像中水滴遮挡,受电弓部分部件边缘模糊造成漏检测的问题。
论文的最后进行了总结与展望,本文研究的算法在不同的高铁受电弓视频数据集上都取得了良好的效果,为未来该领域的研究和应用提供了有益的方向。本文对未来在异物入侵检测和复杂天气下目标检测方法的潜在改进方向进行了阐述,例如数据增强和模型融合等方法的应用,以提高算法模型的准确性、效率和适应性。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000254
{DOI}: 10.27840/d.cnki.gzjkj.2024.000254
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的注塑件缺陷检测系统研究
{Author}: 王亓才;冯小辉;史卜凡;冀国正;曹怀祥;袁涛;黄元凤
{Author Address}: 山东特检科技有限公司;
{Journal}: 化工自动化及仪表
{Year}: 2024
{Volume}: 51
{Issue}: 01
{Pages}: 113-119
{Keywords}: 机器视觉;注塑件缺陷检测;图像处理;视觉控制平台
{Abstract}: 提出并设计了一种基于机器视觉的注塑件焦料杂质缺陷检测系统，通过对多光源非线性自动调光算法的研究，提高了复杂生产环境下注塑件图像采集质量，并经高斯滤波、灰度图像、自适应阈值处理、Canny边缘检测等图像处理技术，可实现注塑件不同检测精度下缺陷检测。经现场测试证明，在1 mm以上缺陷检测精度下，杂质缺陷的召回率为0.918，误检率为0.046，识别速度为每秒30帧，图像处理算法性能稳定，解决了复杂注塑件生产环境下检测精度低、检测效率低的问题。
{ISBN/ISSN}: 1000-3932
{Notes}: 62-1037/TQ
{URL}: https://link.cnki.net/doi/10.20030/j.cnki.1000-3932.202401018
{DOI}: 10.20030/j.cnki.1000-3932.202401018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Halcon的焊缝识别技术研究
{Author}: 毛东宸;孔令云;李博;李明科
{Author Address}: 西京学院电子信息学院;河南省睿卡机器人制造有限公司;
{Journal}: 电子制作
{Year}: 2024
{Volume}: 32
{Issue}: 02
{Pages}: 59-63
{Keywords}: 机器视觉;缺陷检测;图像处理;Halcon;相机标定
{Abstract}: 随着科技的不断发展创新，焊接技术依旧在工业生产中得到广泛应用。在焊接过程中，焊缝缺陷是很难避免的，如开裂、未熔合、堆积等问题，这些缺陷将会对焊接工件的外观及质量产生严重影响。传统的焊缝检测方法主要依赖于专业的焊接工程师来进行质量评估，但由于准确度受到了环境及光线等因素的影响，同时也存在主观性较强、检测效率低等问题。因此，通过引入机器视觉技术，可以有效地去除人为干扰，提高检测的准确率。本文提出了一种基于Halcon的焊缝缺陷检测方法。在图像采集部分，本文采用Kinect v2相机对焊缝进行采集，通过相机标定消除相机畸变及标定板角点的提取，从而获取高清晰度的焊缝图片，结果表明该方法能够有效地解决焊缝缺陷检测的精度问题。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2024.02.003
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2024.02.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进ResNet18的干香菇等级识别
{Author}: 王莉;董鹏豪;王瞧;牛群峰
{Author Address}: 河南工业大学电气工程学院;河南工业大学粮食信息处理与控制重点实验室;
{Journal}: 国外电子测量技术
{Year}: 2024
{Volume}: 43
{Issue}: 01
{Pages}: 117-125
{Keywords}: 干香菇分级;机器视觉;ResNet18;高效通道注意力机制
{Abstract}: 为解决干香菇等级识别技术复杂及识别精度不高的问题，提出了一种基于残差神经网络ResNet18的干香菇等级识别方法。首先将传统的ResNet18中Stem的7×7卷积层替换为3个3×3卷积层串联，保证在感受野保持不变的情况下进一步减小计算量；其次针对残差块中线性变换和非线性变换不足的问题，引入融合非对称卷积和h-swish激活函数，增加了模型的复杂性，使其能够进行更深层次的特征学习；最后在ResNet18骨干网络中引入高效通道注意力机制，加强模型提取特征的能力。实验结果表明，改进后的ResNet18网络模型准确度达97.04%,相比ResNet18网络模型方法提升了4.81%,且性能优于VGG16、MobileNetV2、DenseNet121、ResNet34等网络模型方法，可提高干香菇等级的识别精度，单幅图像的检测时间为5.91 ms,对干香菇智能分拣过程中的等级识别具有借鉴意义。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2305387
{DOI}: 10.19652/j.cnki.femt.2305387
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的钢桥螺栓松动检测方法
{Author}: 劳武略;徐威;张清华;罗纯坤;崔闯;陈杰
{Author Address}: 西南交通大学土木工程学院;保利长大工程有限公司;
{Journal}: 铁道学报
{Year}: 2024
{Volume}: 46
{Issue}: 01
{Pages}: 91-102
{Keywords}: 钢桥螺栓;松动检测;计算机视觉;目标检测;关键点检测
{Abstract}: 为提高螺栓松动检测的智能化水平，提出一种基于计算机视觉的钢桥螺栓松动检测方法。首先基于深度学习理论建立关键点检测模型，对采集的螺栓图像进行标注并建立数据集；然后分别训练目标检测模型YoloV5和关键点检测模型，并利用训练后的模型自上而下检测螺栓关键点，根据关键点确定螺栓中心点位置，以中心点的相对位置求解透视变换矩阵，利用透视变换矩阵对关键点进行重投影；最后根据关键点的位置变化检测螺栓是否发生松动。结果表明：训练后的YoloV5模型和关键点检测模型可准确检测出螺栓的关键点；关键点的检测精度受图像采集条件影响且对角度更为敏感；利用所有中心点拟合透视变换矩阵的最小二乘解可提高图像几何矫正的精度；不同图像采集环境下，松动螺栓的检测误差在0%～9.6%之间，误检率为2.7%,表明本方法的检测精度和稳定性均较高，具有较好的实用价值和广阔的工程应用前景。
{ISBN/ISSN}: 1001-8360
{Notes}: 11-2104/U
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxlWiISHvDY5TplOGe7OfiQ25QjlLvh4fLwITpfXyM3DgO5NfvaVytyN1cZJH9eCm2uqwohW1rMVb6CuPdPVJK-ES_ZX3kT4u8Lu5r_cv4fpx1a6u64qA88mymIKyir6vs5PfRusN3bY1EWNm_EmVill1yLxhv3p-gRr4D4hl_aQlLWO4t_0ZDAGwcurvuqoYs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 简单场景中基于计算机视觉的智能小车设计
{Author}: 张萍
{Author Address}: 广东工贸职业技术学院计算机与信息工程系;
{Journal}: 物联网技术
{Year}: 2024
{Volume}: 14
{Issue}: 01
{Pages}: 122-124+129
{Keywords}: 计算机视觉;图像处理;深度神经网络;YOLOv3-tiny;PID;OpenCV
{Abstract}: 基于计算机视觉技术设计可在简单场景中自动行驶的智能小车，模拟真实场景，对保持行进路线、识别交通标志、控制小车运行状态等关键技术进行研究。给出主要硬件选型参考，使用图像处理技术和OpenCV开发库实现行进路线保持，使用深度学习框架识别交通标志，对小车运动原理进行分析，使用PID算法控制小车状态，验证了关键技术的可行性。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2024.01.033
{DOI}: 10.16667/j.issn.2095-1302.2024.01.033
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于纹理特征增强的重载铁路钢轨缺陷检测算法
{Author}: 王耀东;于航;李宁;朱力强;史红梅;余祖俊
{Author Address}: 北京交通大学轨道交通安全协同创新中心;北京交通大学载运工具先进制造与测控技术教育部重点实验室;比亚迪通信信号有限公司;
{Journal}: 铁道学报
{Year}: 2024
{Volume}: 46
{Issue}: 11
{Pages}: 93-101
{Keywords}: 重载铁路;钢轨缺陷;机器视觉;深度学习;目标检测
{Abstract}: 为实现重载铁路轨道典型缺陷的准确、快速、智能检测，基于深度学习算法，提出一种针对重载铁路钢轨图像的特征加强卷积神经网络模型，研制一套基于机器视觉的便携式轨道图像采集系统；整理创建重载铁路钢轨表面多目标图像数据集，并基于此数据集进行训练，实现裂纹、擦伤、块状损伤、接缝4种典型缺陷目标的智能识别；针对数据集中目标尺度分布不平衡的特点，使用聚类算法重新设置锚框的尺寸和数量；对比分析重载铁路钢轨缺陷图像的纹理复杂性与固有特点，引入加权融合池化模块和纹理特征增强模块对自适应训练样本选择(ATSS)算法进行改进。应用所提算法对重载铁路轨道进行检测，4类典型缺陷目标的全类平均正确率达到85.8%。通过与其他9种检测算法的对比，充分验证了所提算法的有效性。
{ISBN/ISSN}: 1001-8360
{Notes}: 11-2104/U
{URL}: https://link.cnki.net/urlid/11.2104.u.20240110.1638.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于农业搬运机器人的障碍物视觉识别技术研究
{Author}: 余娜;晁阳;孙小春;卿笛
{Author Address}: 杨凌职业技术学院;
{Journal}: 南方农机
{Year}: 2024
{Volume}: 55
{Issue}: 02
{Pages}: 145-146+167
{Keywords}: 机器视觉;农业搬运机器人;图像检索;特征提取
{Abstract}: 【目的】随着农业自动化水平不断提升，研究农业搬运机器人如何优化搬运目标信息、定位及图像检索等功能具有重要现实意义。【方法】课题组提出了一种基于机器视觉的内容图像检索视觉识别技术，采用特征提取方法将图像纹理作为机器视觉障碍物特征识别的重要信息，通过实时更新障碍物信息，利用相似度距离计算，将采集的图像数据与数据库中的图像距离进行对比，并利用MATLAB仿真平台验证了CBIR系统对搬运机器人障碍物识别的精确度。【结果】利用小波滤波器优化的CBIR系统的对比结果优于其他方法的平均检索率，且前20张图像的检索率均能保持在98%以上。【结论】该方法有效提升了CBIR系统的障碍物检测性能及识别系统的精确度，可为系统数据库中障碍物图像特征对比提供高质量图像数据。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxoG8e95_DRzuNVA-X5Ff7_qfLfrg-TEzoVIrem0uMCkQX5eRcBqRbWgWrSBmm--HsQizcrnXgObmaQ5L-YNlsd5jeT6u8X4ut0OHNBz6-o_Xs-uEeGh6VZoTj11A2J0_-FQwTIIQec2SMFY3rkluX4VmaB4T-VBwkUqVsWdNNOHy0qs7ytW1fihpXm0ZOIrjo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉技术的裂缝特征参数提取方法研究与裂缝检测系统设计
{Author}: 顾征宇;潘钻峰;秦建宇;杨毅超;李文迪
{Author Address}: 上海烟草集团有限责任公司;同济大学土木工程防灾减灾全国重点实验室;
{Journal}: 结构工程师
{Year}: 2023
{Volume}: 39
{Issue}: 06
{Pages}: 1-8
{Keywords}: 混凝土结构;裂缝检测;计算机视觉;图像处理
{Abstract}: 目前国内外学者针对混凝土结构所提出的裂缝图像处理算法可移植性较差，还未有较为通用的算法。对目前常用的图像预处理算法及特征参数提取算法在混凝土裂缝图像识别方面的适用性进行了研究，从相机的拍摄和校正、图像预处理、裂缝特征参数提取等方面对比了不同的算法处理效果，并自主开发了一套混凝土裂缝检测系统。
{ISBN/ISSN}: 1005-0159
{Notes}: 31-1358/TU
{URL}: https://link.cnki.net/doi/10.15935/j.cnki.jggcs.2023.06.001
{DOI}: 10.15935/j.cnki.jggcs.2023.06.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5的皮革抓取点识别及定位
{Author}: 金光;任工昌;桓源;洪杰
{Author Address}: 陕西科技大学机电工程学院;
{Journal}: 皮革科学与工程
{Year}: 2024
{Volume}: 34
{Issue}: 01
{Pages}: 32-40
{Keywords}: 皮革;抓取点定位;机器视觉;YOLOv5;CA注意力机制
{Abstract}: 为实现机器人对皮革抓取点的精确定位，文章通过改进YOLOv5算法，引入coordinate attention注意力机制到Backbone层中，用Focal-EIOU Loss对CIOU Loss进行替换来设置不同梯度，从而实现了对皮革抓取点快速精准的识别和定位。利用目标边界框回归公式获取皮革抓点的定位坐标，经过坐标系转换获得待抓取点的三维坐标，采用Intel RealSense D435i深度相机对皮革抓取点进行定位实验。实验结果表明：与Faster R-CNN算法和原始YOLOv5算法对比，识别实验中改进YOLOv5算法的准确率分别提升了6.9%和2.63%，召回率分别提升了8.39%和2.63%,mAP分别提升了8.13%和0.21%；定位实验中改进YOLOv5算法的误差平均值分别下降了0.033 m和0.007 m，误差比平均值分别下降了2.233%和0.476%。
{ISBN/ISSN}: 1004-7964
{Notes}: 51-1397/TS
{URL}: https://link.cnki.net/doi/10.19677/j.issn.1004-7964.2024.01.005
{DOI}: 10.19677/j.issn.1004-7964.2024.01.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 浮选泡沫图像特征提取方法研究进展
{Author}: 宛鹤;陆笑科;屈娟萍;薛季玮;张崇辉;王森;卜显忠
{Author Address}: 西安建筑科技大学资源工程学院;奥卢大学奥卢矿业学院;
{Journal}: 中国钼业
{Year}: 2024
{Volume}: 48
{Issue}: 01
{Pages}: 1-8
{Keywords}: 泡沫浮选;泡沫图像;机器视觉;泡沫图像特征
{Abstract}: 机器视觉作为设备操作人员的工具，在泡沫浮选设备的监测中得到了广泛的应用。利用泡沫图像数据集建立预测识别模型，以初级泡沫特征参数为输入，以品位和回收率等浮选指标为输出。根据是否需要手动提取浮选泡沫图像特征，可以将特征提取算法划分为两大类别：一种是基于颜色、形态特征等的传统手动特征提取方法，另一种是基于深度神经网络的自动特征提取方法。本文总结并归纳了近年来浮选泡沫图像特征提取算法领域的研究进展，分析了各种方法的优势和不足，对当前难以人工识别泡沫状态及实现浮选自动化提升浮选效率，具有一定的指导价值。
{ISBN/ISSN}: 1006-2602
{Notes}: 61-1238/TF
{URL}: https://link.cnki.net/doi/10.13384/j.cnki.cmi.1006-2602.2024.01.001
{DOI}: 10.13384/j.cnki.cmi.1006-2602.2024.01.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 从局部到全局的零参考低照度图像增强方法
{Author}: 杨伟;王帅;吴佳奇;陈伟;田子建
{Author Address}: 中国矿业大学(北京)人工智能学院;国家矿山安全监察局内蒙古局;中国矿业大学计算机科学与技术学院;
{Journal}: 西安交通大学学报
{Year}: 2024
{Volume}: 58
{Issue}: 04
{Pages}: 158-169
{Keywords}: 图像处理;机器视觉;轻量级网络;低照度图像;图像增强;目标检测
{Abstract}: 为解决现有的低照度图像增强方法存在的色彩失真、细节损失以及暗区增强不足和亮区增强过度导致低照度图像增强效果不理想的问题，提出了一种从局部到全局的零参考低照度图像增强方法。采用局部照度增强对低照度图像进行像素级增强，改进了自适应光照映射估计函数，提升了照度调整能力，避免了生成大量的迭代参数，提高了模型的推理速度；采用基于Transformer结构的全局图像调整对局部增强后的图像进行全局调整，解决了亮区照度增强过度的曝光问题和暗区照度增强不足的问题，提升了图像的整体对比度；优化损失函数，对低照度图像特征和增强图像特征进行相似性约束，提升了目标检测精度。实验结果表明，LOL数据集上的客观指标峰值信噪比和结构相似性达到了20.18 dB和0.80,MIT-Adobe FiveK数据集上达到了23.31 dB和0.87,ExDark数据集上增强后图像的目标检测精度提高了7.6%,有效提升了低照度图像可视化质量和目标检测效果。
{ISBN/ISSN}: 0253-987X
{Notes}: 61-1069/T
{URL}: https://link.cnki.net/urlid/61.1069.T.20231207.0953.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多目标跟踪算法研究
{Author}: 刘浩东
{Tertiary Author}: 吴小俊;卢惠林
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多目标跟踪;深度学习;光流信息;时序信息;注意力机制
{Abstract}: 多目标跟踪是计算机视觉领域的一项关键任务,目的在于对视频序列中感兴趣的多个目标完成逐帧检测和跨帧关联。多目标跟踪在国防军事、工业生产和商业领域有着广阔的应用前景,目前被广泛应用于自动驾驶,安防监控,行为识别等场景。随着深度学习热潮的到来和大规模公开的多目标跟踪数据集的发布,多目标跟踪任务取得了突破性的进展。但在具有挑战的场景下多目标跟踪的性能仍然受到限制,例如复杂的运动背景、目标的高速移动以及遮挡等问题。针对上述问题,本文基于深度学习的方法对多目标跟踪进行研究,通过有效地挖掘运动信息和时序信息来提升复杂场景的多目标跟踪性能。本文的主要研究内容和贡献如下:
(1)提出了一种基于光流的运动感知多目标跟踪算法,该算法利用一个轻量的神经网络计算相邻帧之间的光流信息,用以直接区分背景和前景区域,有效提升了算法在复杂背景和发生遮挡等情况时的鲁棒性。同时该算法对空间特征表示和光流信息进行了有效地融合,进一步提升了算法的性能。在多个多目标跟踪数据集上的实验结果验证了该算法的有效性。
(2)提出了一种融合注意力机制和上下文信息的多目标跟踪算法。在检测方面,该算法以YOLOX作为检测器,引入注意力机制提升目标检测效果;在跟踪方面,提出了一种基于LSTM的深度卡尔曼滤波方法,利用LSTM模型来捕捉上下文信息,同时发挥卡尔曼滤波器利用观测信息对状态估计进行修正的能力,提高了系统对运动模型的建模能力。在多个多目标跟踪数据集上的实验结果表明,所提出的算法可以有效地提升跟踪性能。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.002649
{DOI}: 10.27169/d.cnki.gwqgu.2023.002649
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的热轧带钢表面缺陷检测系统研究与设计
{Author}: 王源
{Tertiary Author}: 张玉成;郭艳艳
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;热轧带钢;表面缺陷检测
{Abstract}: 近年来,随着工业生产水平的不断提高,对于产品质量的要求也越来越高。在钢铁行业中,热轧带钢是一种广泛使用的材料,但是其生产过程中往往会出现表面缺陷,如果这些缺陷不能及时发现和处理,就会影响产品的质量,甚至造成安全事故。因此,如何快速准确地检测热轧带钢表面缺陷成为了一个重要的问题。传统的热轧带钢表面缺陷检测方法主要依赖人工目视检查,效率低下、精度不高,且容易受到环境、个体差异等因素的干扰。随着深度学习技术的逐渐成熟,基于深度学习的表面缺陷检测逐渐成为了解决这一问题的有效手段。
本文将从数据集的分析、模型选择和改进、实验结果等方面对热轧带钢表面缺陷检测进行探究。首先对国内外缺陷检测技术进行了研究,对比了从人工检测到机器视觉再到深度学习检测技术的优劣性。其次对相关理论知识进行了梳理,说明了深度学习在理论上的可行性。接着对常见的热轧带钢表面缺陷及成因进行了分类剖析,然后对NEU-DET数据集做了详细介绍及统计分析。对NEU-DET数据集进行了扩充增强,对比了不同网络结构的性能并选择YOLOv5做为基础模型。针对数据集中小目标缺陷居多的情况,对YOLOv5的Anchor初始值尺寸进行重新计算。为提升模型的准确率和鲁棒性,分别引入了SE注意力机制、CBAM注意力机制、ECA注意力机制、CA注意力机制。针对原模型提取小目特征提取不够准确的情况,分别使用了SPP金字塔池化、SPPF金字塔池化特征、ASPP空洞空间金字塔池化、Sim SPPF简化金字塔池化特征、及SPPCSPC金字塔池化以增强对小目标的感知和局部结构的理解。针对YOLOv5的IOU损失函数不够准确的情况,分别使用了CIOU、DIOU、GIOU、EIOU、SIOU损失函数。为提高准确率和检测速度,降低对计算资源的要求,通过对模型主干结构轻量化和使用基于性能感知的多任务全局通道剪枝的方法来减小模型体积,进一步压缩和优化模型。模型经改进和轻量化,最后给出了各种改进结构的实验对比数据,并与YOLO最新版本的YOLOv8s在检测精度、检测速度、计算量、参数量和模型文件大小等方面进行了对比及分析。
最后,结合模型特点和实验结果,设计了热轧带钢表面缺陷检测系统,以使检测模型能进一步应用于实践生产。结果表明,本文的改进方法较原始模型在检测准确率和检测速度上有较大提升。同时,本文还探讨了未来工作的方向,包括更好的数据增强方法、更高效的网络结构以及更加智能化的算法优化等。基于深度学习的热轧带钢表面缺陷检测是当前解决该问题的有效手段之一,在未来的研究中,将进一步优化算法,提高检测的准确率和鲁棒性,为钢铁行业的自动化生产提供更加可靠的支持。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2023.000030
{DOI}: 10.27831/d.cnki.gxjxy.2023.000030
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于统一视觉与语言表征学习的多模态智能研究
{Author}: 黄羽盼
{Tertiary Author}: 卢宇彤
{Publisher}: 中山大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 视觉-语言表征学习;多模态智能;预训练模型;掩码视觉建模;图文生成
{Abstract}: 随着智能设备、社交媒体和电子商务的蓬勃发展,图像和文本数据的快速增长带来了对多模态智能技术的新需求。在计算机视觉与自然语言处理交叉领域,多模态智能技术致力于协同处理视觉与语言信息,以实现信息的高效理解、创造与应用。这项技术不仅提高了生产效率,也激发了创造力,并对社会产生了广泛的价值。利用多源数据和任务的通用技术,能够挖掘多模态数据间的内在联系,从而提升模型在各种任务中的性能和通用性。
本文聚焦于视觉-语言表征学习,旨在提升多模态智能模型的性能与通用性。然而,在这一领域中,视觉与语言信息间的结构和属性差异带来了显著的挑战。在多模态预训练领域,现有模型在图像表征提取与跨模态表征学习阶段分离,同时也缺乏有效的掩码视觉建模方法,或是图像和文本的掩码建模方式差异较大。这些问题导致视觉表征的学习有限,跨模态对齐的学习难度加大,从而影响模型在下游任务中的性能。此外,多模态应用领域中的图文双向生成模型往往采用特定任务的设计框架并进行独立训练,而多模态对话模型则通常无法支持多图文交互,这限制了模型的应用场景,降低了多模态智能技术的通用性。为应对这些挑战,本研究基于统一的视觉与语言表征学习,从以下四个方面展开,旨在缩小模态间的差异并提升多模态智能模型的性能和通用性:
1、针对预训练模型图像表征提取与视觉-语言表征学习阶段分离和缺乏有效地掩码视觉建模的问题,本文提出了一种基于视觉语义标记的端到端预训练方法。该方法联合抽取基于网格的卷积视觉特征,并优化视觉-语言表征。通过将图片转换为视觉语义标记进行掩码视觉建模,直接从自然图像和文本数据中提取视觉与语言的联合表征,有效捕捉两者间的复杂关联性,从而提升模型性能。
2、针对预训练模型中视觉与语言表征及优化目标不统一引起的图像和文本的掩码建模方式差异较大的问题,本文提出了统一视觉与语言掩码建模的预训练方法。该方法基于离散掩码标记统一视觉-语言预训练目标,并采用自注意力机制的表征方式。这一方法不仅减少了跨模态表征学习的差异,提升了模型性能,还适应于以文本或图像为主的多种文档任务,并被有效拓展到了中文数据集应用于中文任务。
3、针对图文双向生成模型的结构不统一的问题,本文提出了一种统一的图文双向生成模型。该模型基于Transformer架构,将图像和文本统一表示为标记序列,实现跨模态双向生成。此外,引入了两级粒度表征和序列级别训练方法,旨在提升双向通用模型的性能。这一方法简化了任务特定模型的设计,优化了存储利用率,并显著提升了模型通用性。该统一图文双向生成模型还被拓展为一个能够生成多样化图像描述和丰富图像内容的双向图像-文本统一框架,显著提升了生成的多样性。
4、针对图文交互方式单一和数据集形式局限的问题,本文提出了拓展图文交互方式和构建新型数据集的方法。这种方法旨在训练支持多种图文交互的对话模型,提升了模型在处理图文输入时的交互灵活性和通用性。本文构建了一个结合细粒度图像和文本交互的对话数据集,并基于此数据集训练了一个多模态开放式对话指令跟随模型。此外,本文还构建了一个由GPT-4协助的基准测试集,用以定量评估模型在处理多轮图文对话的能力。这一方法不仅适应于复杂的图文交互场景,还具备高度的灵活性和可扩展性。
本文的四个部分相互关联,旨在统一视觉与语言的表征学习,共同推进了多模态智能领域的发展和创新。本文工作不仅增强了多模态模型理解自然图像和文档图像相关任务的性能,也扩展了模型在图文生成和多模态对话应用中的通用性。本文研究成果均已开源,为后续研究和实际应用提供了参考和支持。
{URL}: https://link.cnki.net/doi/10.27664/d.cnki.gzsdu.2023.000017
{DOI}: 10.27664/d.cnki.gzsdu.2023.000017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO卷积神经网络的水下海参检测
{Author}: 翟先一;魏鸿磊;韩美奇;黄萌
{Author Address}: 大连工业大学机械工程与自动化学院;中国科学院空天信息创新研究院/传感技术国家重点实验室;
{Journal}: 江苏农业学报
{Year}: 2023
{Volume}: 39
{Issue}: 07
{Pages}: 1543-1553
{Keywords}: YOLO;目标检测;深度学习;机器视觉;卷积神经网络
{Abstract}: 为了实现水下海参的自动化捕捞，需要利用机器视觉方法实现水下海参的实时检测与定位。本研究提出一种基于改进YOLOv5s的水下海参检测定位方法。针对海参与水下环境对比度较低的问题，引入多尺度视觉恢复算法对图像进行处理，增强图像对比度；为了提高模型特征提取能力，加入了注意力机制模块；原始模型对YOLOv5s小目标的检测效果不佳，改进后的YOLOv5s模型替换了原有的激活函数，并在Head网络中加入了新的针对小目标的Detect层。使用改进的YOLOv5s模型与YOLOv5s、YOLOv4和Faster-RCNN在相同的图像数据集上进行试验，结果表明，改进的YOLOv5s模型的检测精度和置信度，尤其是对小目标的检测效果优于其他模型。与YOLOv5s模型相比，改进后的YOLOv5s模型的精度和召回率分别提高了9.6个百分点和12.4个百分点，能够满足水下海参的实时检测要求。
{ISBN/ISSN}: 1000-4440
{Notes}: 32-1213/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxAVNeYJrAfQh4M1Kv0FnvmG8FVPjCs7748seZDPLGU_B0puYTr_TWgKjwLS6lQnuA_7O1p_rLLMJQZyoyeH4PkQYD5l2NLlQtYK1mL8h9dkKZyFr9iZnHnSNOnt3QXSIQeh3VjTIuU6Q5EMU_byJxjP21vRV-zGNrffT26ulVh3FFUGxYt_rVzNi9XRD8-1rE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于MultiResHNet的结构光三维重建技术
{Author}: 杨丽婷;刘孝良;储修祥;周路
{Author Address}: 浙江农林大学光机电工程学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 20
{Pages}: 157-166
{Keywords}: 条纹图;结构光;卷积神经网络;3D形状;机器视觉
{Abstract}: 随着深度学习和结构光条纹投影三维成像技术的发展，直接从单幅条纹图中恢复物体的三维形状的研究近年来受到了多个领域的关注。提出改进的全局引导路径网络MultiResHNet，实现对单幅条纹图的3D形状重建，将现有结构光学三维成像方案与深度卷积神经网络结合，对仿真数据和实验数据分别进行了验证。实验结果表明，所提方法预测的3D形状比已有的U-Net神经网络预测的3D形状更加准确，误差更小，精度更高。实验结果证明了所提技术的有效性和鲁棒性，为后续的3D形状重建技术的提高提供了科学依据，具有一定的参考和应用价值。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230207.1612.051
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习回归密度图的水稻植株计数方法研究
{Author}: 刘丕超
{Tertiary Author}: 赵来定;白晓东
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 水稻植株计数;深度学习;数据集;注意力机制;无人机
{Abstract}: 水稻是我国三大粮食作物之一,其产量的稳定在我国粮食安全中起着重要的作用。在水稻育种和产量的估计中,水稻植株数量是一个重要的特征参数,它能够反应水稻的生长状况和产量情况。近年来,在作物表型研究中水稻植株数量信息的获取已成为精细农业研究中的关键。本文以大田环境下获取的具有高通量水稻植株的图像为研究对象,利用基于深度学习的方法实现水稻植株计数。具体研究内容如下:1.在作物表型研究中,采集具有高通量水稻植株的图像数据已成为一项重要的任务。本文首先确定数据源区域,然后利用现代无人机技术采集水稻植株RGB图像数据,以供创建数据集使用。2.由于目前可用训练和验证的水稻植株数据集较少,本文构建了一个新的水稻植株计数(UAV-based rice counting,URC)数据集。通过对采集的水稻植株图像进行系统性筛选,选择出了符合实验要求的图像,并使用基于Matlab设计的人工标注程序完成了数据集的标注工作。根据数据集的规模和多样性,本文对数据集进行了训练集和测试集的随机分配,以便为后续的网络模型评估实验提供更充分的数据支持。3.为了更好地应对新数据集带来的挑战,本文提出了一个新的基于深度学习的水稻植株计数方法(Rice Net)。该方法包含一个特征提取器和三个特征解码模块,它们分别是密度图估计模块、植株定位模块和植株大小估计模块。所设计的密度图估计模块结合了注意力机制,以提高估计密度图的精度。该算法中的植株定位模块和植株大小估计模块输出植株位置和大小信息,这些更高层次的语义信息在作物表型研究中有着重要意义。此外,本文还提出了一个新的像素级正负损失函数,实验证明了它能够有效地抑制图像中的背景和噪声,提高计数精度。4.本文在新的数据集上验证了所提出的网络模型的有效性。所提出的Rice Net在测试集上的平均绝对误差和均方根误差分别为8.6和11.2。此外,本研究还进行了两个其他作物数据集的计数实验。在这三个数据集上,与一些基准方法相比,本文所提出的计数模型在计数性能方面均有所提升。结果表明,Rice Net可以准确有效地估计水稻植株数量,并取代传统的人工方法。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001481
{DOI}: 10.27251/d.cnki.gnjdc.2023.001481
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于程序切片和深度学习的代码漏洞检测
{Author}: 卢跃
{Tertiary Author}: 张迎周
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 静态切片;切片度量;预训练模型;动态切片;Swin Transformer
{Abstract}: 随着互联网的普及和软件的广泛应用,漏洞的存在可能导致严重的安全威胁和损失。在这个背景下,漏洞检测技术的发展和创新成为了保障软件系统安全性的关键。软件开发的快速发展,软件迭代速度越来越快,这意味着漏洞检测技术需要能够快速适应新的软件版本和更新。深度学习模型可以通过学习大量的代码和漏洞样本,从中提取特征和模式,并准确地识别和预测潜在的漏洞。然而,现有的基于深度学习的漏洞检测方法检测的粒度较粗,通常是文件级、函数级或行级别,存在准确率较低、误报率较高等问题。为了克服这些挑战并提升漏洞检测技术的性能,本研究关注于深度学习和程序切片结合的方法。针对现有基于深度学习和程序切片的漏洞检测方法仅获取代码的语义信息,存在可能无法全面准确地捕捉到潜在的漏洞的问题,研究了一种基于LLVM IR的静态切片语义与度量代码的漏洞检测方法。提出了基于LLVM IR的漏洞兴趣点检测算法,使用符号化切片工具Sym Pas来获取兴趣点的切片,通过指令级嵌入方法Inst2vec来获取IR指令的向量表示,并融合指令级切片度量紧密度、重叠度、覆盖度和认知复杂度度量,可以深入分析切片语句之间的关系和特征。构建了混合模型Res CNN-GRU来进行训练,将提取的特征进行有效融合和学习。这种混合模型能够充分利用切片的语义信息和度量信息,进一步提高了漏洞检测的性能。本文方法使用LLVM IR作为中间表示语言具有很好的适应性,充分利用切片语义和度量信息,在准确率和漏报率上有较好的表现。针对上述静态切片方法在漏洞检测中存在一些局限性,尤其是在发现特定执行条件下的漏洞方面存在不足之处,研究了基于动态切片与预训练模型的代码漏洞检测方法。动态切片技术能够反映程序的实际执行情况,它能够发现一些只有在特定执行条件下才会出现的漏洞。此外,动态切片方法能够将程序表示为更小粒度的代码块,从而更详细地捕捉代码的语义特征。使用Code BERT预训练模型将程序切片语句块表示为二维张量。把这些切片块视为灰度图像,将代码的结构和语义信息编码为像素值,能够更全面地捕捉代码的语义特征,包括局部结构和上下文信息。此外,借助计算机视觉模型Swin Transformer的特征提取能力,进一步从图像中提取关键的漏洞特征。这种方法可以更准确地进行漏洞检测,因为计算机视觉模型能够有效地学习图像中的重要特征,从而帮助准确地识别代码中的缺陷。通过结合动态切片技术和预训练模型的优势,本文的方法能够更全面地捕捉代码的语义特征和关键漏洞特征,提高代码漏洞检测的准确性并降低了误报率。本文通过实验验证了本研究提出的两种方法,实验结果表明本文的方法取得了较好的效果。降低了误报率和漏报率,提高了漏洞检测的准确性和可靠性,而且具有较好的适应性,拓展了漏洞检测的应用范围。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.002073
{DOI}: 10.27251/d.cnki.gnjdc.2023.002073
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于单头自注意力轻量级视觉Transformer骨干网的研究
{Author}: 孙振涵
{Tertiary Author}: 周全
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: Transformer骨干网;轻量化;注意力算法;前向传播网络;图像分类;语义分割;目标检测;实例分割
{Abstract}: 近年来,随着深度学习的迅速发展,相关计算机视觉的研究取得了极大的进步。而视觉骨干网的研究对核心的视觉任务如图像分类、目标检测、语义分割、实例分割等有重要的意义。最近,基于Transformer结构的骨干网络已经逐渐成为视觉骨干网研究的主流方法,众多基于Transformer结构的骨干网络通过使用大量标注数据集训练网络从而得到最佳拟合模型并展现出了在计算机视觉任务方面的巨大的潜力。现有方法通过堆叠大量的Transformer模块（Transformer Block）的方法构建复杂的网络,尽管取得了显著的性能提升,但是面临严重的消耗计算资源等问题,使得其无法在应用场景中得到推广。本文从注意力算法的应用、轻量级网络设计、高效特征提取模块设计手段等多角度出发,对基于Transformer的骨干网设计方法进行了有效的研究,设计了多种高效的骨干网算法。通过在多个基准数据集上的训练、验证以及测试,验证了以上算法的有效性,具体研究内容如下:（1）从减少自注意力结构的计算复杂度的角度出发,本文提出了一种较轻量级的基于Transformer的骨干网络,单头Transformer骨干网（Single-Head Transformer Backbone,SVT）。该网络通过构建低计算复杂度的自注意力网络以降低基于Transformer的骨干网络的计算资源消耗。SVT提出了一种新颖的基于单头自注意力（Single-Head Self-Attention,SHSA）的自注意力模块,其中包含了一个多尺度池化的特征提取模块,以提取多尺度特征。与传统方法,即计算多头部自注意力（Multi-Head Self-Attention,MHSA）的Transformer不同,SHSA将输入Token的表示限制在单个集合之中,从而实现了低维嵌入,大大降低了计算复杂性。减少模型参数的同时,SHSA极大地减少了输入Token的数量。该方法实现了分类精度和效率之间的平衡,是一种高效的基于Transformer的骨干网络。（2）虽然SVT使用单头自注意力,取得了不错的性能,但是仍然存在着以下一些问题:1)模型的参数量居高不下;2)模型的精度仍存在很大的进步空间。基于上述问题,本文进而提出了多分支轻量化Tranformer骨干网络（Multi-branch Lightweight Transformer,MLT）,包含SHSA模块和多尺度特征提取模块（Multi-scale Feature Extraction Module,MFEM）。其中MFEM取代MLP[19]使用了一系列并行的不同感受野的卷积层提取输入的不同层次特征以提高模型的精度,同时卷积层大量使用深度可分离卷积,以降低模型整体的参数量。综合实验对比,本方法已经在图像分类、目标检测和语义分割的任务上评估了MLT。它只有14.11M模型参数,但在图像分类（Image Net-1K上的79.3%Top-1%精度）、语义分割（Cityscapes和ADE20K上实现了的77.4%和44.3%的m Io U）、目标检测和实例分割（COCO数据集上取得了42.3%box-AP和38.6%mask-AP）方面产生了具有竞争力的结果。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001061
{DOI}: 10.27251/d.cnki.gnjdc.2023.001061
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的钣金折弯加工精度检测与补偿研究
{Author}: 徐帅
{Tertiary Author}: 徐丰羽
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉检测;钣金折弯加工;加工误差补偿;麻雀搜索算法;Elman神经网络
{Abstract}: 在钣金折弯加工过程中,需要机器人和折弯机配合完成折弯加工的各道工序,但由于机器人自身存在的定位精度问题和金属折弯件的材料特性,折弯成品的精度受到影响。针对折弯加工中存在的尺寸误差和成型角度误差问题,采用神经网络前馈和机器视觉实时反馈联合补偿方法、机器视觉实时采集误差信息并反馈补偿方法分别补偿。主要研究内容如下:首先,设计机器视觉误差检测系统。以折弯加工检测精度要求对硬件选型,设置合适的光源、光圈和焦距等参数,并编写相应上位机程序。建立相机镜头畸变模型并对相机标定,计算重投影误差评价标定精度,并得出实际长度与像素长度的转化关系。此外,分别针对尺寸信息、旋转角度和成型角度的检测进行相应实验,以验证系统的测量精度。其次,图像处理并获取折弯尺寸和角度误差信息。对所采集的折弯件源图像预处理,并在Canny像素级粗定位基础上,以Zernike矩算法得到亚像素边缘,在Harris角点检测算法基础上细分并筛选出折弯件角点的亚像素级角点坐标。以折弯件实际位置和理想位置的亚像素角点坐标依次得出X、Y直线轴向定位误差、需补偿的旋转角度和当前成型角度,其中通过多次采样实验获取机器人X、Y直线轴向定位误差数据集,录入数据库中待用。再次,采用神经网络前馈和机器视觉实时反馈联合补偿尺寸误差。尺寸误差本质由于机器人X、Y直线轴定位误差和旋转轴旋转误差,补偿X、Y直线轴定位误差时,以Tent混沌映射生成麻雀初始种群优化麻雀搜索算法(ESSA),并通过ESSA算法优化Elman神经网络的初始权值阈值得到ESSA-Elman定位误差预测模型。实验测试机器人重复定位精度满足补偿要求后,通过ESSA-Elman预测X、Y直线轴定位误差值,并以此修正机器人理想操作参数来补偿折弯尺寸误差。补偿旋转轴旋转误差时,机器人末端吸附折弯件一次旋转后,机器视觉误差检测系统采集当前折弯件需补偿的旋转角度反馈给机器人末端,以二次旋转进一步补偿折弯件尺寸误差。然后,采用机器视觉实时反馈补偿折弯成型角度误差。成型角度误差本质由于金属折弯件材料回弹特性,补偿时折弯机以理论下压量一次折弯后,机器视觉误差检测系统采集实际成型角度,以此修正理论下压量并反馈给折弯机上模二次下压补偿折弯成型角度误差。最后,补偿前后折弯成品精度对比实验。采用以上方式补偿尺寸误差和成型角度误差后的折弯组A、未补偿的折弯组B在相同工序和参数下各折弯加工5块相同折弯件,测量得出折弯组A折弯成品的尺寸误差和折弯成型角度误差比折弯组B分别降低了79.7%和68.1%。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000078
{DOI}: 10.27251/d.cnki.gnjdc.2023.000078
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于高分辨率网络的人体姿态估计方法研究
{Author}: 张子屹
{Tertiary Author}: 李群
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人体姿态估计;拥挤人群姿态估计;高分辨率网络;轻量级网络;注意力机制
{Abstract}: 人体姿态估计的目的是对给定的二维图像或视频中人体的所有关键点进行检测与定位,并根据人体结构的先验知识对它们进行连接,从而得到人体姿态的基本表示。作为人体姿态估计任务中最常用的骨干网络模型之一,高分辨率网络能够从图像中提取出包含多尺度信息的人体关键点特征,但在其实际应用中仍存在一些难点和挑战。第一,它多阶段、多分支的网络结构使其具有较高的计算复杂度,从而限制了其在实际应用中的性能和效率。第二,由于它只能提取图像局部范围内的特征信息,无法有效地捕捉人体关键点之间的长距离空间依赖性关系,因此在应用于现实生活中包含拥挤人群的场景时性能衰退严重,易受到人体之间相互遮挡的影响。针对这些难点和挑战,本文对基于高分辨率网络的人体姿态估计方法展开了深入的研究,具体工作如下:(1)提出了一种基于动态轻量高分辨率网络(Dynamic lightweight High-Resolution Network,Dite-HRNet)的人体姿态估计方法,对高分辨率网络进行了轻量化改进,有效地提升了人体姿态估计模型在实际应用中的性能和计算效率。具体而言,提出了一种名为动态分组卷积的新型卷积操作和一种自适应上下文建模方法,并提出两种专门针对高分辨率网络结构设计的轻量级网络构建模块,进而利用它们构建出Dite-HRNet网络模型,其具有低于原始高分辨率网络数十倍的参数量和计算量,且依然保持着较高的人体姿态估计精度。(2)提出了一种基于高分辨率上下文网络(High-Resolution co Nte Xt network,HRNe Xt)的拥挤人群姿态估计方法,针对拥挤人群场景中的重遮挡问题对高分辨率网络进行优化改进,使模型能够更好地理解图像中的空间上下文信息以及人体遮挡关系,更准确地估计出被遮挡人体的姿态,从而提升人体姿态估计算法在实际应用场景中的精度和鲁棒性。具体而言,提出了两种专门针对视觉任务设计的前馈网络单元结构,进而利用它们构建出HRNe Xt网络模型,并在三个公开的人体姿态估计数据集上对其进行实验,数据集的人群拥挤程度越高则其在精度和性能上的优势就越为显著,证明了其针对重遮挡问题进行优化改进的有效性。(3)考虑到在人体姿态估计的实际应用中对于实时检测的需求,将本文提出的Dite-HRNet和HRNe Xt模型应用到标准的自上而下人体姿态估计算法流程中,并部署于搭载单目RGB摄像头设备和Windows操作系统的计算机终端,从而实现了一种基于单目RGB摄像头的实时多人姿态估计系统,能够在Windows平台上调用外接单目RGB摄像头设备,实时读取摄像头捕捉到的RGB图像帧并对其进行同步的多人姿态估计。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001329
{DOI}: 10.27251/d.cnki.gnjdc.2023.001329
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多视角的动态人体自由视角合成
{Author}: 吕逊
{Tertiary Author}: 高浩
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人体自由视角合成;人体重建;神经辐射场;SMPL模型
{Abstract}: 基于多视角的人体视角合成长期以来都是计算机视觉和计算机图形学领域一个重要的研究问题,旨在通过人体的多视角图像或视频合成出人体的任意视角图像或视频。目前,相关技术已经被应用于增强现实/虚拟现实、体育赛事转播、游戏以及电影产业等领域。相比采用稠密的阵列相机系统或者深度传感器进行人体视角合成或三维重建,从稀疏的多视角图像或者视频完成此任务应用范围更广、成本更低,但也更具有挑战性。近些年来,随着深度学习技术的快速发展以及计算设备性能的不断提升,以神经渲染技术为主导的方法推陈出新,正在逐步弥补传统的方法存在的不足。其中,基于神经辐射场(Neural radiance fields,NeRF)的方法因其令人惊叹的效果引起了广泛地关注。目前,基于NeRF的人体自由视角合成依然面对诸多挑战,其中主要包括如下问题:动态人体的自由视角合成问题、新的人体的自由视角合成问题、人体重建问题。本文针对上述三个问题进行研究,利用多人蒙皮线性模型(A Skinned Multi-Person Linear Model,SMPL)作为人体的先验信息改进现有基于NeRF的方法,并以多视角相机采集系统制作的数据集和公开数据集验证提出方法的可行性。具体的研究内容如下:(1)针对动态人体的自由视角合成缺乏纹理细节问题,本文提出一种动态人体神经辐射场模型。该模型利用SMPL的纹理图和顶点提供人体的先验外观信息。首先,利用SMPL模型的纹理图生成可以使不同的人体姿态共享的纹理特征图;然后,在SMPL模型的顶点上放置表征人体外观和形状的隐代码,利用三维稀疏卷积网络Sparse Conv Net扩散隐代码到三维空间;最后,通过NeRF的体积渲染术合成出人体的图像。实验结果表明,该方法在训练过以及未训练过的人体姿态相比于其他先进算法具有更好的视角合成结果。(2)针对人体的自由视角合成泛化能力差问题,本文提出了一种以几何模型引导的可泛化神经辐射场模型。该模型在利用SMPL模型作为先验几何模型的基础上,增加人体的稀疏视角图像信息和深度信息作为额外输入,从而可以合成新的人体的图像,即未训练过的人体的图像。首先,借助深度信息设计可判断遮挡的颜色融合模块以聚合多视角的图像信息,从而获取人体的外观;然后,利用SMPL模型提供的稀疏点云和多视角一致性特征推断人体的几何形状;最后,通过体积渲染术合成出人体的图像。实验结果表明,该方法不仅能够渲染新的目标人体图像,而且有效地处理了稀疏视角图像输入情况人体自遮挡问题。与其他先进方法相比,该方法具有更强的泛化能力。(3)针对三维人体重建几何细节差的问题,本文提出了一种基于表面场和辐射场的人体重建模型。该模型利用表面场的符号距离函数表达取代了辐射场的体密度表达。首先,利用人体的运动将观察空间的采样点变换到标准空间;然后,利用多视角图像融合的信息计算变换到标准空间的采样点相对人体表面的偏移量;最后,利用神经网络存储标准空间人体模型的几何信息和颜色信息,借助体积渲染技术合成图像以及Marching Cubes算法重建出人体的三维模型。实验结果表明,此方法相对于基于辐射场体密度的重建方法效果更好。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000213
{DOI}: 10.27251/d.cnki.gnjdc.2023.000213
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的手语双向通信系统
{Author}: 王鸽;千学明;罗振刚;赵培智;刘涛;杨子琪
{Author Address}: 西安工业大学机电工程学院;
{Journal}: 物联网技术
{Year}: 2023
{Volume}: 13
{Issue}: 10
{Pages}: 59-62
{Keywords}: 手语识别;手语生成;CNN;GRU分类器;OpenCV图像合成;状态机
{Abstract}: 手语研究涉及多个领域和交叉学科。目前，手语识别领域正以两大主流研究方向蓬勃发展：数据传感手套和手语视觉识别。前者通过传感器采集动作数据进行手语识别和翻译，后者采用计算机视觉技术捕捉用户手部特征实现手语识别和翻译。针对大多数研究内容仅关注手语识别、翻译的单向通信，而忽略实际交流过程中手语双向通信问题，本文基于Alex Net网络模型、卷积神经网络（CNN）和门控循环单元（GRU）实现手语识别、翻译，基于状态机完成手语动画生成，以此实现手语双向通信。进入系统后，用户可以选择手语识别、翻译功能，开启Open CV设备捕捉图像，通过Alex Net神经网络模型、CNN-GUR混合神经网络模型分别对静态手语和动态手语进行识别和翻译，并将结果以文字或语音的形式显示输出。用户还可以点击手语生成功能，系统可以根据录入的语音或文本信息生成相应的手语动画视频。实验结果表明，与相似识别算法相比，该手语识别率为95.52%，生成准确率为93.2%。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2023.10.017
{DOI}: 10.16667/j.issn.2095-1302.2023.10.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在智能化农业机械中的应用分析
{Author}: 董帅;李杰
{Author Address}: 成都市技师学院(成都工贸职业技术学院);
{Journal}: 南方农机
{Year}: 2023
{Volume}: 54
{Issue}: 21
{Pages}: 94-96+135
{Keywords}: 视觉技术;智能农机;应用分析
{Abstract}: 计算机视觉技术通常用于复杂物体的自动化检测、识别、分割和定位，将计算机视觉技术应用在农业机械中，有利于实现农业生产的自动化、智能化，提高农业生产效率。基于此，研究小组首先介绍了计算机视觉技术在农业机械中的应用范围，主要包括农产品质量检测、农作物病虫害诊断、农机作业监测、农机自动导航等；分析了计算机视觉技术在农业机械中的应用优势，如实现智能化作业、提高作业精度、实现精确采摘、减少劳动力消耗、降低生产成本等；提出了计算机视觉技术在智能化农业机械中的应用方法和未来的发展趋势，包括开发高分辨率、高帧率和大视场相机，提高智能控制算法的实时性和准确性，加快计算机视觉技术的商业化进程等。以期为提高农业生产效率，推动我国农业现代化发展提供重要支撑。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx_SCp-9eTmJOhwKZQ_9Ay6GSB149WLbShBIvNeGek0WuEv-uyjjS0eFFzUG1iKDZ2eGqB2yXJ0tDX-xEZHSz0GyUh0BhRKoN2wG8NqnT6JgS0NHFsd4UWKFfz7HJcef4pK2vF81uSHPe3J62uGICo-ntvolj9C_LRmPKpandzYL2G0pulnAlbnKpJos99cCoY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种提高机器视觉检测精度的方法
{Author}: 孙红芳
{Author Address}: 唐山百川工业服务有限公司;
{Journal}: 航空精密制造技术
{Year}: 2023
{Volume}: 59
{Issue}: 05
{Pages}: 9-13
{Keywords}: 机器视觉;定位;尺寸测量;提高精度;工业制造
{Abstract}: 本文提出一种提高机器视觉标定精度的方法。首先，设置标准参考点位置，对机器视觉系统进行标定获得初始标定矩阵；其次，对图像进行处理，视觉检测算法提取标准参考点的准确位置；最后，通过修改初始标定矩阵参数，使计算结果无限接近标准参考点，从而获得更高精度的标定矩阵。实验表明，该方法可提高狭缝测量和圆孔定位的检测精度，为实现高精度机器视觉检测提供了新途径。
{ISBN/ISSN}: 1003-5451
{Notes}: 11-2847/V
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzfS3SB-AAXuvDtwzMQL6crAMlKoN0ELYu2t2Nhm4uVH4awOhcFjwGFw3btujF8pEW74wpmNhm_Mk02zJzNZ4qt6J2gsbcKDlbtrK8SL9cJs4Uw_Czr8PDnaXfQRHCWRrKKkJEVC03QdZb9EbHBl-_IwqgSTzknYI3-MkZWXhmcs-2yD-RS4oW6xClzdKuxdyM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 智能交通系统中的行人检测与行为分析
{Author}: 贾云飞
{Author Address}: 浙江吉利技师学院;
{Journal}: 中国信息化
{Year}: 2023
{Volume}: 
{Issue}: 09
{Pages}: 85-86
{Abstract}: <正>本文研究了智能交通系统中的行人检测与行为分析，以实现交通安全和优化交通流量的目标。研究通过采用计算机视觉技术和机器学习算法，对交通场景中的行人进行检测和行为分析。通过目标检测和跟踪算法，能够成功地识别和定位行人，实现对行人行为的分类和统计。该研究的结果将为智能交通系统的开发和应用提供重要的数据支持，并对交通安全和交通流优化产生积极影响。
{ISBN/ISSN}: 1672-5158
{Notes}: 11-5119/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyX1dJySxV-k6WxH9E5oBaIbmEbCpRlSS4T38FlzIgBJrSonZ7Tn0hF6jrwEKKsmOncJDIjJhmu9jxGgaX_IM0B8VZ6QOzc1IrnJ18pJDO2mwe4_Kf_qznN7CMtX58-t5w0qEm8e97I8K2K5Z2JkZ3QRTD3sqELiwo7oMk-00_LnV5sdsDOZyNhRQKlLbIsebA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的类球状水果采摘机械目标识别方法
{Author}: 赵毅
{Author Address}: 南阳技师学院;
{Journal}: 现代农机
{Year}: 2023
{Volume}: 
{Issue}: 05
{Pages}: 65-67
{Keywords}: 机器视觉;采摘;类球状;水果;机械;识别;目标
{Abstract}: 常规水果采摘机械目标识别方法多数采用特征阈值化法，对水果图像进行分割处理，不能根据水果图像中某些目标存在的共同特征将其分割为特定区域，无法为目标识别提供有力支持，降低了水果采摘机械目标识别的精确率。基于此，引入机器视觉技术原理，以类球状水果为例，提出了一种全新的水果采摘机械目标识别方法。利用高性能的拍摄相机，随机选取类球状水果进行图像采集与预处理，获取特征突出、不存在噪声点的图像，采用机器视觉技术设计图像分割算法，将图像划分为多个超像素块，对类球状水果图像边缘进行平滑处理，获取融合特征的类球状水果采摘机械目标识别显著图，完成机械目标识别。实验分析可知，通过这方法识别类球状水果采摘机械目标，其识别结果的精确率、召回率与调和平均值等三个评测指标均≥95.38%，识别效果优势显著。
{ISBN/ISSN}: 1674-5604
{Notes}: 33-1357/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw06rAETJFMxYOUiYgj2bclT8S3p8cBVE5IwV7aRVb-sREIMPs17o1HLaOvtmoELMMD5OWJeN07psVtIv4EWpD4KPaj7zmkamslcHkCUxpmFy4PrXyEggzoTxt7YFuGZ6XN_ATHSiWm8iDKg1G7GtzjHmIOEX793CvmRF4EGOVCJOFaepKfFKYMy3dEaQrrGpo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉在道路成像和坑洞检测中的应用研究综述
{Author}: 李锐;王鑫;杨威朋;屈焘;贺帅
{Author Address}: 重庆交通大学;
{Journal}: 汽车工程师
{Year}: 2023
{Volume}: 
{Issue}: 09
{Pages}: 1-8
{Keywords}: 计算机视觉;道路成像;坑洞检测;深度学习;3D道路点云
{Abstract}: 针对道路坑洞的自动检测和道路状况的客观评估问题，对计算机视觉技术在道路坑洞检测中的应用研究成果进行了全面综述。通常采用摄像机和各类深度传感器获取二维、三维道路数据实现道路成像，并基于计算机视觉技术开展坑洞检测，主要检测算法包括经典二维图像处理、三维点云建模与分割、深度学习及其混合方法，其中混合方法利用各类算法的优势，可大幅提高检测的准确性。然而，现有算法在坑洞检测领域取得良好效果的同时依然面临道路几何重建鲁棒性有待提升、算法复杂度高、模型效果高度依赖大规模良好标注数据集等诸多挑战，故未来应更多关注无监督的立体匹配算法及少样本的深度学习算法。
{ISBN/ISSN}: 1674-6546
{Notes}: 22-1432/U
{URL}: https://link.cnki.net/doi/10.20104/j.cnki.1674-6546.20230308
{DOI}: 10.20104/j.cnki.1674-6546.20230308
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和深度学习的智能制造缺陷检测技术与应用
{Author}: 李锦棠
{Author Address}: 广州市机电技师学院;
{Journal}: 现代制造技术与装备
{Year}: 2023
{Volume}: 59
{Issue}: 08
{Pages}: 190-192
{Keywords}: 机器视觉;深度学习;智能制造;缺陷检测
{Abstract}: 在工业智能制造行业中，质量缺陷检测工作面临一定的困难。在传统的物体表面缺陷检测中，人工目测不但过于主观，而且效率低下。基于机器视觉和深度学习的智能检测技术借助光学成像及图像处理等功能，能够准确计算待测物体的坐标信息，然后对物体实施自动定位并引导，同时完成自动装配。该检测技术具备非接触、无损伤、准确性高、连续工作时间长和高效率等优势，是目前智能制造检测较理想的方式。
{ISBN/ISSN}: 1673-5587
{Notes}: 37-1442/TH
{URL}: https://link.cnki.net/doi/10.16107/j.cnki.mmte.2023.0507
{DOI}: 10.16107/j.cnki.mmte.2023.0507
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 几何特征约束的SIFT特征匹配改进算法
{Author}: 张喜民;詹海生;余奇颖
{Author Address}: 陕西国际商贸学院信息工程学院;西安电子科技大学计算机学院;
{Journal}: 计量学报
{Year}: 2023
{Volume}: 44
{Issue}: 08
{Pages}: 1182-1187
{Keywords}: 计量学;机器视觉;图像配准算法;尺寸不变特征变换;特征匹配;边界跟踪;随机抽样一致算法
{Abstract}: 图像配准精度直接影响机器视觉尺度检测的精度，针对尺寸不变特征变换(SIFT)特征匹配未考虑特征点之间的几何关系，对于小插件等灰度变化较平滑的图像易产生误匹配点的问题，提出了几何特征约束的SIFT特征匹配改进算法。首先，用基于边界拓扑分析的图像跟踪算法提取目标轮廓；然后，用轮廓特征对SIFT算法进行约束并利用随机抽样一致(RANSAC)算法去除“离群点对”;最后，估计变换矩阵并完成图像精确配准。基于高分辨率工业相机和高性能计算机构建精密尺度检测系统，以手机USB接口插件为对象进行实验，实验结果表明：该算法图像配准精准度可达95.31%,与SIFT算法、SIFT+RANSAC算法相比较，配准精准度得到了较大提高，该算法已应用于某检测设备研制中。
{ISBN/ISSN}: 1000-1158
{Notes}: 11-1864/TB
{URL}: https://link.cnki.net/urlid/11.1864.TB.20230731.1658.004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向行人重识别的度量学习与评测方法研究
{Author}: 袁鑫
{Tertiary Author}: 徐新
{Publisher}: 武汉科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 行人重识别;度量学习;损失函数;样本排序优化;评测方法
{Abstract}: 行人重识别技术能够有效帮助侦查人员在海量视频中发现、追踪嫌疑人,进而提高公安机关破案率,具有重大的研究意义和实际的应用价值。近年来,前沿行人重识别方法已经在公开数据集上取得了极高的准确率,甚至超越了人类的辨识能力。但是,现有行人重识别研究仍然存在一些挑战,这些挑战主要体现在:优化策略度量空间受限、度量学习方法设计效率受限、评测方法评价层面受限。在这三个方面的研究挑战,具体表现为:(1)现有行人重识别算法训练过程中,采用的是批次内部分样本的碎片化优化策略,导致度量空间的样本局部优化。(2)现有度量方法设计采用人工设计的方式,需要大量的专业知识积累和资源消耗来设计,导致设计效率低下。(3)现有评测方法在评测行人重识别算法时,无法对检索和验证进行综合一体化评价,导致算法评价不完善。为此,本文开展面向行人重识别的度量学习与评测方法研究,重点在度量学习方法优化策略、度量学习方法自动化设计、多场景评测方法设计等三个方面,并取得了如下创新性成果:(1)面向批次样本全局化的行人重识别度量学习方法针对现有行人重识别度量学习方法优化策略度量空间受限的问题,考虑模型训练与测试的一致性度量优化,然而由于评测方法不可微分的特性,导致度量学习方法训练困难,研究面向批次样本全局化的行人重识别度量学习方法,实现基于评测方法的度量优化方法设计,进而正常地指导模型训练。实验结果表明,本文提出的方法不仅优化了类之间距离分布,而且保持了类内相似性结构,并在公开的行人重识别任务的三个数据集Market1501、CUHK03、MSMT17上进行了验证,性能优于当前前沿的度量学习方法。(2)基于设计自动化的行人重识别度量学习方法针对现有行人重识别度量学习方法设计效率受限的问题,探索度量学习方法的自动化设计,借助自动机器学习实现度量学习方法自动搜索,完成度量学习方法自动化设计。然而,自动搜索得到的度量学习方法无固定形式且扩展性差,极度依赖网络结构和数据集,使得到的度量学习方法无法实用。为此,提出基于设计自动化的行人重识别度量学习方法,联合优化检索与验证任务,引入参数化函数来替代检索与验证评测方法中的不可微操作并进行参数搜索,实现基于评测方法的度量优化方法自动化设计。实验结果表明,本文提出的方法在公开的行人重识别和车辆重识别数据集上,展示出相比于其他度量学习方法的优越性。(3)联合检索与验证一体化的行人重识别评测方法针对行人重识别评测方法评价层面受限的问题,关注检索集中无特定行人和输出结果的自动研判,研究多场景检索与验证综合评价,提出完善的行人重识别评测方法体系。进一步,针对开放集场景与验证模式无法度量,行人重识别评测方法实用性差的问题,提出联合检索与验证一体化的行人重识别评测方法,全面掌握算法的适用范围。实验结果表明,无论是在封闭场景的检索或验证模式,还是开放场景的验证模式,本文提出的评测方法体系相比于现有的评测方法体系,对于多场景的重识别研究有更好的适用性。综上所述,本文针对批次内样本相似性关系度量挖掘、多任务自动化度量设计模式探索、多场景综合一体化评价规律发现等科学问题进行研究,创新地为研究优化策略度量空间受限、评测方法评价层面受限、度量学习方法设计效率受限这三个挑战提出解决方案,有效探究了行人重识别中度量学习方法的相似性关系度量挖掘和自动化设计模式,研究了行人重识别方法的多样化评价,在度量学习与评测方法两方面的研究成果为解决行人重识别在实际场景中的应用提供了新的思路。
{URL}: https://link.cnki.net/doi/10.27380/d.cnki.gwkju.2023.000009
{DOI}: 10.27380/d.cnki.gwkju.2023.000009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的螺钉外形尺寸测量系统
{Author}: 石磊
{Author Address}: 重庆工程学院软件与人工智能学院;
{Journal}: 仪表技术与传感器
{Year}: 2023
{Issue}: 07
{Pages}: 71-74+87
{Keywords}: 机器视觉;六边形;图像分割;最小二乘法;Canny算子
{Abstract}: 针对螺钉头部正六边外形几何特征人工测量精度低、不利于自动测量的问题，提出了基于机器视觉的螺钉外形尺寸测量系统。首先对原始图像进行滤波、增强预处理解决成像图像细节信息不突出、对比度低的问题；其次，采用基于类间方差最大度量法的图像分割算法处理目标与背景灰度差异不明显的图像，改善算法鲁棒性；最后，结合改进Canny算子和最小二乘法拟合出最优六边形参考边缘，并设计基于质心与参考边缘的坐标系定位策略，在此基础上进行螺钉头部正六边形边缘查找及几何尺寸测量。进行了螺钉头部正六边形测量实验，结果显示该系统尺寸测量误差不超0.09%,满足工程实际需求。
{ISBN/ISSN}: 1002-1841
{Notes}: 21-1154/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzU8AfquJmGG1b0z3myCZ6Uak8iylD-WocSEaE0onWfqBZsTHQlWxdT9HY66ObuUS43FHovMVxF7Q_Mz_olLhehVTFe4ZVYhJojXGk7UGS0PoWhnPtJzD_Zej3vQ5RdhGCj9zZbJcn-gNIOkWRmNHL65ZilpgI-DymGAYUnWlWuqBOT2WkBOCWNeQnF_uLbXaY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机图像处理技术的发展与未来创新
{Author}: 张晓闯
{Author Address}: 郑州工业应用技术学院;
{Journal}: 家庭影院技术
{Year}: 2023
{Volume}: 
{Issue}: 14
{Pages}: 76-81
{Abstract}: <正>随着计算机技术的不断发展，计算机图像处理技术也得到了快速的发展。从最初的黑白图像处理到现在的彩色图像处理、多媒体图像处理以及医学图像处理等领域，计算机图像处理技术的应用范围越来越广泛。基于此，本文将探讨计算机图像处理技术的发展历程和未来的趋势。
{ISBN/ISSN}: 1008-0945
{Notes}: 44-1432/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzU8AfquJmGG1b0z3myCZ6Uak8iylD-WoccKww-gZVfifgbMTKImOz4tN3Gv15nz0wyUjI4cvmEJytvctwPVjW65l4m3pW_0xx9LNGtzWQAAhMUXsfDwu-GMG3klgUPKAZa6qxZ5AlxO1UPJkJeQhEnURoAM3M6qrVG2wadlDdQvW63Jid--XFoUBeVlT8sZgs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多特征融合的深度伪造人脸视频检测方法研究
{Author}: 卢凌雪
{Tertiary Author}: 康晓兵
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度伪造检测;卷积神经网络;视觉Transformer;双分支网络;特征融合
{Abstract}: 随着人工智能技术的高速发展,深度伪造得到大众的认可,因为其生成效果逼真度高,深度伪造相关软件层出不穷,给数字媒体安全带来了严峻挑战。因此开展针对深度伪造人脸视频检测技术的研究就显得尤为重要。目前,深度伪造人脸视频检测技术正处在快速发展时期,但仍存在面对层出不穷的新兴深度伪造方法时,泛化性能较差及面对低质量视频上的检测准确率较低的难点,本文基于深度学习相关理论设计了两种方案,具体如下:（1）提出一种基于视觉Transformer的深度伪造人脸视频检测方法。卷积神经网络（CNN）只能计算临近像素的相关性,无法充分利用图像的相关空间信息的问题,但考虑到CNN具有较好的对图像数据的归纳偏置,Transformer结构能够从长输入序列中学习有意义的关联,具有较好的全局建模的能力,因此提出一个CNN与视觉Transformer的组合模型来综合两种网络的优势,以提升模型的检测性能。将预处理之后得到的视频帧图像首先输入特征提取模块,通过两种CNN对其进行特征提取并融合,再将得到的融合特征输入特征再学习模块,做出最终的真伪视频二分类,其中,采用了不同于Transformer架构中传统的绝对位置编码的相对位置编码;并在Transformer编码器中添加了MAD（Multi-Attention Dropping）单元,可以进一步提升模型对于真伪人脸的重点区域注意力关注,有效提升模型准确率。同时强调了数据预处理对实验结果的影响,为该方法选择了一种人脸识别精度更高的facerecognition库,提升了检测结果。实验结果表明,本文提出的基于视觉Transformer的深度,在检测伪造人类视频方面的准确率平均达到了96%以上,高于现有几种代表性深度伪造人脸检测方法;面对DFDC数据集时检测AUC值达到了 97.29%,可以说明该模型泛化性能高。（2）基于空频特征融合提高检测深度伪造人脸视频的方法。由于当前特征提取网络一般为深层结构,存在对于高频分量学习优先级低的固有缺陷,在分类决策时对于高频信息的利用率较低。而Deepfake技术的合成方式会使得合成人脸与周围像素间变化较大,这种不连续的变化一般存在于频域中的高频信息中。且深度伪造人脸视频检测的本质并不依赖于图像的语义信息,因此利用频域信息进行检测分类的方法是有效可行的。基于此,提出的双分支结构中频域分支利用离散余弦变换将深度伪造数据集中提取到的视频帧图像变换到频域空间,通过特征提取模块进行特征提取;空域分支利用RGB图像输入到特征提取模块中进行特征提取,再通过“十字绣”单元将DCT分支与RGB分支结合,充分利用不同信息空间进行最终分类。这两种类型的特征都有助于区分真实视频帧图像以及深度伪造人脸视频帧图像,将二者深度融合可以得到更具有区分性的特征,最终提升了模型准确率。实验结果表明,本文基于融合空频特征提出深度伪造人脸视频检测方法在高质量视频上的准确率AUC值均有所提升,在低质量数据集上的准确率达到了 89.63%且AUC值达到了 90.16%,优于目前多种先进方法,具有一定的鲁棒性。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.001435
{DOI}: 10.27398/d.cnki.gxalu.2023.001435
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向智能视频监控的多目标跟踪系统设计与实现
{Author}: 刘春雷
{Tertiary Author}: 李志华;张明月
{Publisher}: 河北工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智能监控;多目标跟踪;目标检测;YOLOv5
{Abstract}: 多目标跟踪在视频监控中对行人事务分析提供基础支撑,承载着智能视频监控系统中的核心功能,具有重要的研究意义。目前多目标跟踪算法中目标检测的速度和精度均还存在一定的优化空间。本文围绕目标检测的速度和精度的提升展开研究,研究内容具体如下:首先,以轻量化特征提取网络为出发点,设计了一种轻量化的目标检测模型。基于YOLOv5的网络模型在检测精度和速度上均有着较好的表现,但当其在终端设备上部署使用时,往往受到算力的限制,阻碍了模型的应用普及。故本文基于Rep VGG模型改进了主干网络,实现了网络轻量化设计。同时本文加入了坐标注意力机制,在扩大感受野的同时增强了感兴趣区域的权重,提高了算法在密集人群和复杂环境下的鲁棒性。经实验测试,所提出的轻量化网络在参数量和计算量方面均有较明显下降,且检测精度和鲁棒性也较高,能够在一定程度下满足工程应用的要求。其次,将改进后的检测算法与ByteTrack跟踪算法进行结合,以提升检测的精度。原ByteTrack跟踪算法中检测模型使用的是YOLOX,在本文实验中YOLOX检测器虽然准确率高,但因其有着相对较多的参数导致了检测速度的降低。本文将改进的轻量化的YOLOv5算法应用于多目标的跟踪,在检测速度和精度方面进行了优化平衡,改进后的算法在MOT17数据集上有较好的表现。本文中相关检测和跟踪算法的实现与测试都以操作系统的命令行来执行。考虑到系统的良好人机交互性,用Py Qt5将本文的算法设计实现了图形化用户界面。经测试,在图形化界面下,各个功能模块均正常运行,实现了多目标跟踪系统,且用户能够便捷地调整参数,用户体验良好。
{URL}: https://link.cnki.net/doi/10.27104/d.cnki.ghbjy.2023.000538
{DOI}: 10.27104/d.cnki.ghbjy.2023.000538
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工件识别与定位算法
{Author}: 余浪;苗鸿宾;申光鹏;苏赫朋
{Author Address}: 中北大学机械工程学院;山西省深孔加工工程技术研究中心;
{Journal}: 自动化与仪表
{Year}: 2023
{Volume}: 38
{Issue}: 06
{Pages}: 29-33+38
{Keywords}: 机器视觉;图像处理;Hu矩;最小外接矩形
{Abstract}: 针对表面贴装生产线上，机器人在抓取工件的过程之中能够实时地更新调整工件的位置信息，达到准确抓取工件的目的，该文提出了一种基于机器视觉的工件识别与定位算法。通过对工件图像进行预处理并提取出图像的边缘特征，结合图像的Hu矩特征对工件进行识别判断，然后对工件图像外轮廓进行分割，结合图像最小外接矩形的中心点与分割点对工件图像进行定位计算。实验结果为工件的识别匹配度在0～0.02之间，位置定位误差在0.5像素以内，角度定位误差小于0.3°，满足工件的识别定位精度要求。
{ISBN/ISSN}: 1001-9944
{Notes}: 12-1148/TP
{URL}: https://link.cnki.net/doi/10.19557/j.cnki.1001-9944.2023.06.007
{DOI}: 10.19557/j.cnki.1001-9944.2023.06.007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度卷积神经网络的目标检测研究
{Author}: 王泽吉
{Tertiary Author}: 何小卫
{Publisher}: 浙江师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;卷积神经网络;目标检测;视觉Transformer
{Abstract}: 随着计算机硬件和深度学习算法的快速发展,目标检测算法的精度越来越高、性能越来越好。然而尽管现有的目标检测技术已经能够应用于实际场景,其现有的性能依然无法达到人类视觉的水准,不能完全替代人工,存在巨大的改进空间。本文主要基于卷积神经网络,在大量研究现有的目标检测算法后,提出了新型的主干网络和新型的目标检测头部网络,并达到了较高的精度。本文具体的研究内容如下:
(1)基于对主干网络的研究,受到Meta Former和Conv Ne Xt的启发,设计了纯卷积类似Transformer结构的新型主干网络Embed Former。首先分析了视觉Transformer与Conv Ne Xt的具体区别,提出利用添加嵌入层的深度卷积来作为令牌混合器,实例化一个纯卷积的Meta Former。提出的Embed Former在Image Net-1K图像分类任务中取得了81.7 Top-1准确率,比Swin Transformer高出0.4。在MS COCO目标检测与分割任务中,在Cascade Mask R-CNN算法中作为主干网络,Embed Former取得了48.6 Box AP和42.7 Mask AP。在ADE20K语义分割任务中,在UPer Net算法中作为主干网络,Embed Former取得了45.3 m Io U。实验证明了提出的Embed Former在视觉任务上有着出色的性能。
(2)基于对两阶段目标检测算法Sparse R-CNN的研究,证明了现有的对特征金字塔的简单应用并不能很好地适合Sparse R-CNN,并提出区别利用特征金字塔不同特征层的概念。设计了双臂式动态实例交互头,利用特征金字塔底层和顶层分别进行目标位置和类别的预测,以更好地利用特征金字塔。将双臂式动态实例交互头应用在Sparse R-CNN的结构上,提出新型目标检测算法TASD,并在MS COCO数据集上进行验证。以Res Net-50作为主干网络的TASD,在建议数量设为100的条件下能达到44.0 m AP,高出Sparse R-CNN 1.4,而在建议数量为300的条件下更是取得了45.8的SOTA成绩,超越了大多主流的目标检测算法。
(3)将提出的新型主干网络Embed Former和新型头部网络TASD组合起来得到一个目标检测模型,在MS COCO数据集上进行训练和验证,取得了46.7 m AP的成绩,并将检测结果可视化。
综上,本文主要研究基于深度卷积网络的通用目标检测算法。基于对大量目标检测算法的研究,创新性地提出新型的目标检测网络模块,并在公开数据集上训练和验证了模型的可行性与高性能。
{URL}: https://link.cnki.net/doi/10.27464/d.cnki.gzsfu.2023.000720
{DOI}: 10.27464/d.cnki.gzsfu.2023.000720
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 工业机器人联合机器视觉工件搬运系统的研究
{Author}: 张旭成
{Tertiary Author}: 王少锋;刘文婧
{Publisher}: 内蒙古科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;视觉点云;图像处理;视觉定位;工业机器人
{Abstract}: 以往搬运机器人是采用离线编程或者示教的方式控制搬运机器人实现工件的抓取与搬运,当工件位置不同时该类方式无法判断工件位置从而导致工件搬运失败。针对此类问题,本文提出一种由机器视觉搬运系统的解决方案对液化气空罐工件进行钩取搬运,该系统具备较高的灵活性、无需精度较高的工装夹具等优势。本文结合实际,开展针对液化气空罐工件视觉搬运系统的研究,主要工作如下:
(1)确立课题研究的总体方案。分析项目需求并确定机器视觉工件搬运系统的整体方案,根据总体方案设计课题实验平台并完成平台硬件的选型设计和视觉处理程序开发工具选择及开发环境配置。
(2)完成整体系统的硬件标定。构建机器视觉工件搬运系统的参数化模型;通过手眼标定、工具坐标系标定得到图像像素坐标系中目标位置与目标位置在机械臂工具坐标系下二者间的坐标系转换关系。
(3)开发视觉处理定位程序。针对液化气空罐工件顶部安装吊钩,基于Open-CV视觉算法库设计开发实现了吊钩的开口朝向判定,基于Pcl-py点云算法库设计开发实现对应吊钩颈部边缘点的定位提取,经由坐标系转换处理完成目标点定位;视觉处理定位程序实现了对工件吊钩的识别及关键位置的实时定位;经实验验证程序定位精准度在1mm以内,定位精度满足使用预期要求。
(4)验证整体方案的可行性。搭建实验验证平台进行机器视觉引导方式工件钩取搬运实验,经30次钩取实验所得系统的工件钩取成功率为93.3%;以示教的方式进行工件钩取搬运实验,经过相同次数的实验所得的工件钩取成功率为63.3%。经实验对比,本文方案的可行性得到验证且较传统的示教方式具有更高灵活性。
本文提出的工业机器人联合机器视觉的工件搬运系统方案,经实际实验验证可实现对液化气空罐工件的钩取搬运,系统视觉定位程序准确性基本满足使用预期要求,较传统示教方式具有可实时工件定位、系统灵活性高等优势。
{URL}: https://link.cnki.net/doi/10.27724/d.cnki.gnmgk.2023.000297
{DOI}: 10.27724/d.cnki.gnmgk.2023.000297
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的柑橘目标识别与定位方法研究
{Author}: 朱世雄
{Tertiary Author}: 葛动元
{Publisher}: 广西科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 摄像机标定;深度学习;柑橘识别;双目立体视觉;三维定位
{Abstract}: 我国柑橘的栽培规模和生产率居全球前列,在如此庞大的柑橘生产作业中,柑橘采摘环节就占据了大比例的作业劳动力。而如今面对人力成本高昂、工作效率低、劳动力紧缺等问题,采用智能化水平较高的采摘机器人来解放劳动力是必然选择。因此研究能够精准识别且定位柑橘目标的视觉系统,对于实现自动化采摘具有重要价值。本文旨在为柑橘采摘机器人的生产作业提供必要的视觉信息。为此,以柑橘果实为研究对象,针对复杂果园环境下的柑橘目标识别和定位进行了研究,研究内容主要包括以下几个方面:(1)研究分析了摄像机的成像模型,对张正友标定方法进行了原理介绍,并提出了一种由矩形图像确认摄像机参数的自标定方法,基于灭点的性质求解出与矩形两组平行线相互正交的第三组平行线所决定的灭点。而后通过三灭点的几何关系进一步得到旋转矩阵,继而根据相机的旋转矩阵与单应性矩阵之间的约束关系,计算出摄像机内参数与平移向量。该方法易于操作,实现简单,模拟实验表明该方法具有较高的鲁棒性,而真实图像实验则显示其具有较高的精度,为果园环境中特定情况下的视觉任务提供了新的解决方案。(2)对YOLOv5目标检测算法的原理进行了介绍,并基于此提出了一种改进的轻量化网络模型。具体改进策略如下:利用K-means++算法对锚框进行重新聚类,以获得柑橘数据集最适合的锚框尺寸、将主干网络替换为Mobile Net V3轻量化模块。同时为有效缓解模型简化带来的精度下降问题,引入CBAM注意力机制模块与Si LU激活函数,以及针对单类别目标检测损失函数的改进,最终得到改进后的MC＿YOLOv5模型。实验表明,本文设计的MC＿YOLOv5模型以略微降低2.6%的m AP为代价,使得模型体积缩小80%,并在GPU、CPU平台分别提高24%、59%的检测速率,更适用于果园柑橘目标的识别检测。(3)通过双目立体标定与立体校正消除畸变并使左右图像的对应特征点实现行像素对齐。将半全局块匹配(SGBM)算法与块匹配(BM)算法进行对比试验发现,前者所表现的综合性能更佳。本文定位方法完全满足采摘机器人对于柑橘目标三维空间定位的精度要求,经实验数据显示:x,y,z轴三个方向平均定位误差大小分别为4.27mm,3.11mm,1.1mm,其定位误差率与总定位误差率也均在合理范围内,满足柑橘目标的定位要求。
{URL}: https://link.cnki.net/doi/10.27759/d.cnki.ggxgx.2023.000041
{DOI}: 10.27759/d.cnki.ggxgx.2023.000041
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的柑橘病虫害动态识别系统
{Author}: 张勇
{Tertiary Author}: 杨力军
{Publisher}: 西南民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 精准农业;无人机;深度学习;目标检测;病虫害识别
{Abstract}: 柑橘是四川省眉山市支柱型的经济林果,种植面积超过100万亩,产值突破了110亿元,为当地主导产业之一。柑橘自然种植环境多为丘陵坡地,在大规模种植柑橘的过程中,不同生长阶段均会出现各种特殊的疾病,而同一种病虫害症状在不同时期也有不同的特征,所以要进行大面积的且快速精准的病虫害防治极其困难。频繁的大面积使用各种农药,使得柑橘的农药含量超标,极大的影响了消费者的身体健康。如何改变目前极其粗犷的疾病防治管理措施,进行精准病虫害防治,减少农药使用量,是当前面临的一个重大问题。
针对以上问题,本论文着重研究了深度学习算法在精准农业中的应用,开发一套能够在开放环境下,能够实时、快速和准确的柑橘病虫进行精准检测的深度学习模型。从而为柑橘病虫害的精准治理提供技术支持,实现小规模、精准化农药喷洒防止病虫害,降低柑橘生长过程中农药的使用量。本文的主要工作包括:
(1)通过人工田间采集大量柑橘病虫害图像,包括果实和叶片病变图片。并通过图像增强等技术,实现图像数据集的多样性,进一步丰富柑橘病虫害图像数据,从而构建了柑橘常见病虫害数据集,为后续病虫害识别算法提供数据支持;
(2)对获得的柑橘病虫害图像数据集进行人工打标签,并使用YOLOV5模型训练柑橘病虫害目标检测模型,对训练模型进行参数优化,从而获得高精度柑橘病虫检测算法。使用图像、视频和手机摄像头等方式验证该算法的效果;
(3)为了实现实时、快速检测的目的,并克服丘陵坡地对数据采集的影响,使用目前流行的无人机进行数据终端采集,并使用RTMP直播推流技术将无人机采集的图像数据传输到电脑端,并调用训练好的病虫害识别模型进行识别,将识别到的柑橘疾病信息进行预警提示。实现对病虫害进行大面积、快速、实时识别与病虫害预警。
实验结果表明,本系统针对柑橘果实及叶片病虫害检测的MAP达到88.5%,识别的准确率达到95%以上,解决了开放自然环境下对柑橘植株叶片、果实图像进行大面积、实时采集、传输以及快速准确识别的问题,为病虫害精准防控提供了技术支撑。
{URL}: https://link.cnki.net/doi/10.27417/d.cnki.gxnmc.2023.000028
{DOI}: 10.27417/d.cnki.gxnmc.2023.000028
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的配准算法与三维重建技术研究
{Author}: 李想
{Tertiary Author}: 魏翼飞
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;图像配准;点云配准;三维重建
{Abstract}: 三维重建是计算机视觉和计算机图形学领域的关键问题。基于RGB图像和深度图像的三维重建算法的关键都在于找到两个数据之间的对应,进而估计变换关系,即图像或者点云的配准,然而现有图像配准算法往往只使用最深层的特征寻找对应点,这造成了模糊;现有点云配准算法没有考虑到点云的全局特征以及两个点云之间的互信息对点云配准的关键影响。本文旨在研究和改进现有基于深度学习的图像、点云配准算法,提高配准算法的精度,并在此基础上研究基于多视角点云配准的三维重建问题,从而提高三维重建的效果。本文的主要研究内容如下:(1)基于多层次特征聚合的图像配准算法研究。为了解决现有图像配准算法在特征提取步骤中存在的问题,设计了一种新的卷积神经网络MLFPoint,该网络一方面在原图尺寸上检测关键点,提高了关键点的定位精度;另一方面,该网络利用多层次特征恢复底层细节,生成鲁棒的关键点描述符。在通用的图像配准数据集HPatches上的详细实验证实了该网络相对于传统方法和基于学习的方法的优越性。(2)基于注意力机制的双视角点云配准算法研究。提出了一种基于Transformer网络的点云配准方法TransFCGF,该方法首先利用全卷积几何特征网络(FCGF)提取两个待配准点云的局部特征,并使用动态图卷积网络(DGCNN)加强点云的全局特征,随后使用Transformer交换两个点云之间的互信息,然后关键点选择模块筛选出重叠分数较高的对应点,使得网络更加关注两个点云之间的重叠区域。在合成数据集ModelNet40上的详尽实验结果表明,所设计的网络对噪声和异常值具有较强的鲁棒性,能适应范围更广的配准场景。(3)基于多视角点云配准的三维重建研究。设计并实现了一个多视角点云配准算法,将本文提出的双视角点云配准算法TransFCGF集成到一个通用的基于图优化的多视角点云配准管道中,得到多视角点云配准的结果后,使用两种表面重建算法得到最终的三维模型。实验结果表明,所设计的方法能够在保证点云配准精度的基础上,提高重建模型的质量。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.002354
{DOI}: 10.26969/d.cnki.gbydu.2023.002354
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 智慧牧场牛脸识别系统应用设计
{Author}: 叶孟珂
{Tertiary Author}: 李宝山;李琦
{Publisher}: 内蒙古科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 牛脸识别;牛只个体身份识别;目标检测;实例分割;特征提取
{Abstract}: 近年来人民的生活水平不断提升,对牛羊等肉类的消费也不断增长,这促使畜牧业快速发展。在此背景下,传统的畜牧业模式正朝着规模化、精准化、智能化的方向发展,牛只等大型牲畜的保险业务不断增长,对牛只身份识别的要求也在提高。
牲畜身份识别作为畜牧业精细化养殖的核心内容,本文提出了一种基于计算机视觉的牛脸身份识别方法。主要研究内容包括牛脸数据集的采集与制作、牛脸目标检测模型的选择、牛脸实例分割模型的选择、牛脸身份识别模型的选择和牛脸识别应用系统设计五个部分。具体如下:（1）数据集的制作,本课题在内蒙古自治区几个牧场进行牛脸图像数据采集,分别建立牛脸目标检测数据集CFOD、牛脸实例分割数据集CFCOCO、牛脸身份识别数据集CFO与CFSEG。（2）牛脸目标检测,分别使用DETR、Faster RCNN、YOLOv5和YOLOv8模型,对CFOD数据集训练,通过对比分析,选择性能优异的YOLOv5模型进行牛脸目标检测,YOLOv5的AP50:95达到了94.3%。（3）牛脸实例分割,将Mask RCNN和SOLOv2模型在CFCOCO数据集上进行训练,经过实验对比,选择SOLOv2模型用于牛脸前景图像的提取,m AP50:95达到了82%以上。（4）牛脸身份识别,通过Face Net模型对牛脸进行特征提取,使用Inception＿v3,Inception＿resnet＿v1和Inception＿resnet＿v2作为主干特征提取网络分别在CFO和CFSEG数据集进行训练,最后选择在CFSEG数据集训练得到效果最好的Inception＿resnet＿v1网络提取牛脸特征进行牛脸身份识别的任务,达到了92.4%的验证率和98%的准确率。（5）牛脸识别系统应用设计,通过Tensor Flow Serving（TF Serving）框架结合Tornado Web服务对三个子系统进行部署,利用Docker进行服务管理,实现了牛脸目标检测子系统、牛脸实例分割子系统和牛脸身份识别子系统共同构建的牛脸识别系统。
本文将牛脸目标检测模型、牛脸实例分割模型和牛脸身份识别模型相结合进行牛脸身份识别,使用My SQL数据库存储牛只档案信息,Elastic Search数据库存储牛脸特征向量。将TF Serving、Tornado和Docker作为总体架构,搭建基于牛脸生物特征的牛脸识别系统,进行牛只个体身份识别,对牲畜的精细化饲养、监测牲畜生物体征、管理牲畜溯源数据以及预防牲畜保险的欺诈等方面有着推动作用。
{URL}: https://link.cnki.net/doi/10.27724/d.cnki.gnmgk.2023.000250
{DOI}: 10.27724/d.cnki.gnmgk.2023.000250
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向目标检测的模型轻量化方法研究
{Author}: 李迁迁
{Tertiary Author}: 田青
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;轻量化网络;标签分配;网络剪枝
{Abstract}: 目标检测技术是计算机视觉中最热门的研究方向之一,它是从图像或视频中获取到相关目标的类别信息和位置信息的一项技术,在自动驾驶、机器人导航、智能安防等领域中被广泛应用。目前,基于深度学习的目标检测算法为了追求高精度的目标,导致网络结构越来越复杂,参数量和计算量都过于庞大,难以在边缘计算平台下部署,无法满足实时检测的需求。因此,平衡模型精度和复杂度的关系成为了轻量化目标检测的关键之处,本文从人工设计轻量化且紧凑的网络结构和结构化网络剪枝两个方面展开研究,主要研究内容如下:(1)在人工设计轻量化且紧凑的网络结构方面,首先针对传统目标检测算法中根据不同数据集需重新设计锚框大小的问题,本文将无锚框策略引入到轻量化目标检测模型上,解决了重新设计锚框的问题;其次,利用深度可分离卷积重新设计了轻量化的主干网络,并引入Ghost module模块,减少冗余特征的产生,然后添加改进的注意力机制,对每个通道进行加权运算,以获得更多的关键特征,同时改进了颈部的轻量化结构,提高了网络的特征提取能力;最后,改进了动态标签分配策略和损失函数,提高了检测准确率。在COCO数据集上进行了测试,结果表明本文的模型在只有0.99M参数的情况下,实现了30.5%的m AP,较于当前主流的目标检测网络有了明显提高,且参数量更低,在精度和复杂度之间实现了更好的平衡。(2)在结构化网络剪枝方面,主要采用基于卷积核骨架的剪枝策略,改进卷积核骨架的正则化惩罚项,使其学习到最佳的卷积核形状,然后指导裁剪策略,删除不重要的卷积核条纹形状,最后通过改变卷积计算方式,结构化地实现网络裁剪。在CIFAR-10数据集上进行验证,相对于原始的方法,裁剪参数量提高了3.4%,裁剪计算量提高了2.9%,验证了改进正则化惩罚项的有效性。最终应用到上文中人工设计的轻量化模型,实现了在m AP降低了1.5%的情况下,参数量和计算量分别达到了减少38%和40%的效果。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2023.000144
{DOI}: 10.26926/d.cnki.gbfgu.2023.000144
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的寄递安全智能检测技术研究
{Author}: 魏元喜
{Tertiary Author}: 刘晓平
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 迁移学习;注意力机制;截断损失函数;合作式知识蒸馏;小样本学习
{Abstract}: 随着互联网和电子商务的出现与发展,人们越来越依赖快递进行网上购物,同时快递的日寄递量也在逐年稳步增长,但随之而来的寄递安全也成了难以回避的问题。随着基于深度学习的机器视觉技术的快速发展和广泛应用,在寄递安全检测场景中应用机器视觉技术完成违禁物品自动检测已经成为了未来发展的重要趋势。本文主要研究X光图像中基于深度学习的违禁物品智能检测技术。在X光图像中检测违禁物品存在一些困难性问题,例如正样本数据收集困难、复杂的图像背景及遮挡、目标多视角造成的形状差异大等。为了解决上述问题,本文对目标检测器模型进行了相关探索与研究:分别从迁移学习、注意力机制、损失函数、知识蒸馏和小样本学习等方面展开。本文的主要贡献如下。(1)针对X光图像的正样本数据收集困难,缺少足够的数据来训练复杂模型的问题,本文提出了一种基于微调的浅层迁移学习方法,采用“增量网络结构+部分微调”的方式实现迁移。本文算法相较传统微调方式性能更优,该方法能够使得在较小X光图像数据集上训练的复杂模型快速收敛,完成了 SSD300的检测“能力”从自然光图像数据集到X光图像数据集上的知识迁移。(2)针对密闭包裹的X光图像存在复杂背景以及X光图像缺少颜色视觉特征等问题,本文提出了一种通道上下文注意力机制算法,用来提高目标检测器模型的主干网络鲁棒性。本文通过可视化分析实验用“热图”的方式展示了该结构在图像上对目标的“聚焦”能力;违禁物品检测实验表明,将这种注意力机制应用在常见的目标检测器模型上能够有效地提升X光图像中违禁物品检测性能。(3)针对X光图像中目标多视角造成的形状差异大问题,本文提出了一种截断损失函数。本文证明了这种截断损失函数能够迫使分类模型增大不同类别目标特征之间的余弦间隙;在CIFAR-10上的实验验证了该损失函数能够有效提升模型的分类性能;违禁物品检测实验表明将这种截断损失函数应用在目标检测器模型上能够有效地提升X光图像中的违禁物品检测性能。(4)针对密闭包裹的X光图像中有些因相互堆叠、遮挡的违禁物品难以被检测的问题,本文提出了合作式的知识蒸馏算法。本研究利用教师模型来挖掘图像级和实例级的困难样本,用以增强学生模型。不同于学生模型模仿教师模型的知识蒸馏方式,本算法采用了教师模型和学生模型合作方式实现。(5)本文完成了基于X射线安检机的违禁物品智能检测系统研究与开发。一方面,本文提出了一种基于增量结构的两阶段微调小样本目标检测算法。通过实验验证了该方法不但能够有效扩展仅有少量样本的新类别违禁物品,而且还能有效保持目标检测器模型在基础数据集中学习到的检测能力。另一方面,本文设计并开发了一种基于分布式的小样本实时在线违禁物品智能检测系统。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000279
{DOI}: 10.26969/d.cnki.gbydu.2023.000279
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的道路伤损检测模型研究
{Author}: 陈建坤
{Tertiary Author}: 牟凤云
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 道路伤损;目标检测;数据增强;轻量化模型;模型部署
{Abstract}: 道路伤损危害道路安全,严重时会对行车安全、人身安全以及城市建设构成障碍,及时发现道路伤损对道路灾害风险防范以及后续道路养护至关重要。因此,高效智能的检测方法成为当前道路伤损检测的迫切需求。近年来,基于深度学习的计算机视觉技术成为了目标检测发展的新方向。本研究以开源数据集GRDDC2022为基础,基于一阶段目标检测算法YOLOv5m提出了精度更高、参数量更低的YOLO-RDD算法,并将算法部署到PC端和Web端,可满足实际应用场景的需求。主要研究成果和相关结论如下:(1)以GRDDC2022数据集内中国地区数据源为基础,进行了单样本数据增强处理和多样本数据增强处理,单样本数据增强方法使用了:几何变换、颜色变换、噪声变换、局部擦除;多样本数据增强使用了:混合图像、标签平滑、Gridmask。同时针对原始数据集中伤损类别数量差异较大,鳄鱼纹裂缝(D20)和坑塘(D40)样本数量较少的问题,本文选取了性能优秀的FAST＿GAN模型分别训练并生了200张D20和D40伤损实例,并使用泊松图像融合方式将生成的伤损实例图像与道路背景图像混合以产生新的道路伤损图像,之后在Labelimg中完成标签后,补充为训练数据集的一部分,至此,完成新的道路伤损数据集构建,共形成训练数据集7004张,验证数据集876张。实验结果表明,使用增强数据集后的模型具有更高的检测精度,未使用数据增强前,YOLOv5m模型的MAP@0.5仅为0.732,使用增强数据集后模型MAP@0.5达到了0.878,提升达到了14.6%,且各个类别的检测精度也都有较大的提升,这表明数据增强操作对于提升模型精度至关重要。(2)以一阶段目标检测模型YOLOv5m作为基准模型,使用Kmeans++算法对数据集进行预选框聚类,选择出更合适的Anchor;将Ghostnet引入到网络结构中改进传统Conv和Bottleneck模块,同时使用Sim Conv重新设计空间金字塔池化层Sim SPPF,并将注意力机制引入到网络的Neck部分,以增强对于小目标的特征提取能力,在特征图上采样部分采用性能更加优越的CARAFE算子,最后在模型的Neck部分借鉴Efficient Det的多尺度特征融合网络Bi FPN以改进特征图融合方式,并将角度损失考虑到边界框损失函数中,以加快模型训练。至此,完成轻量化检测模型的构建,将其命名为YOLO-RDD。在增强后的数据集上进行训练,并与当前主流的5类检测模型进行对比,实验结果表明:YOLO-RDD模型在检测精度和模型参数量上的表现都非常优秀,在MAP@0.5与F1-Sorce两个指标上都取得了最好的成绩,相较于baseline模型,MAP@0.5由0.878提升至0.911,MAP提升了3.3%,F1-Sorce由0.827提升到0.865,提升幅度达到了3.8%,其检测性能也已经超过了尺寸更大的YOLOv5L模型以及新版本的YOLOv6、YOLOv7、YOLOv8算法。同时模型做到了轻量化,YOLO-RDD模型在所有的算法中参数量最少,整个模型参数量总计16726284,比YOLOv5m减少4138773,同时也远少于参数量第二少的YOLOv7模型。YOLO-RDD模型最终的训练权重仅为32.4Mb,比YOLOv5m减少7.9Mb,是所有对比算法中最小的,这表明YOLO-RDD做到了轻量化。在检测速度方面,YOLO-RDD模型的检测速度达到30.9FPS,虽不是所有对比算法中最快的,但高于YOLOv5L与YOLOv6,达到了实时检测的标准。(3)为了满足不同用户对于道路伤损检测算法的应用,本文将YOLO-RDD算法部署到PC端和Wbe端,实现了对于道路图片和视频流数据的实时检测,同时验证了本文算法改进的实用性和有效性。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2023.001001
{DOI}: 10.27671/d.cnki.gcjtc.2023.001001
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的板材表面缺陷智能检测技术
{Author}: 魏子喻
{Tertiary Author}: 王丰贵
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 轻量化网络;深度学习;缺陷检测;YOLOv5
{Abstract}: 随着国家制造业的不断发展,板材广泛应用在工业化的各个领域,需求量巨大。但是由于生产工艺、环境等原因,会产生各类缺陷影响板材的使用。人工肉眼检测主观性强费时费力,传统的图像处理算法需要自制模板并且精度低、速度慢,因此板材表面缺陷检测问题需要新的方法解决。本文以铝材数据集为研究对象,采用深度学习中的YOLOv5算法对铝材表面缺陷进行检测,进行对比实验分析实验结果,并迁移到其它板材数据集中进行测试,最终完成的主要工作如下:(1)本文比较了不同目标检测模型的优缺点,综合考虑网络模型的检测速度和检测精度,最终选择YOLOv5算法。比较了4种不同YOLOv5目标检测模型的精度、算法复杂度和模型训练成本,最终选择YOLOv5s模型作为铝材缺陷检测的基础算法。(2)由于不同数据集检测框大小和数量不同,为了让模型更好的回归,使用KMeans聚类算法和auto Anchor算法重新生成模型的检测锚框,使用auto Anchor比不使用预设锚框的模型m AP提高了12.9%。为了增强特征金字塔模块提取和传递特征信息的能力,使用Sim SPPF、SPPCSPC和ASPP三种不同的特征金字塔模块改进YOLOv5的特征金字塔结构(SPP),改进后的各模型m AP分别提升了2.9%、1.9%、1.7%。为了增强模型的分类和回归能力,使用Decouple head改进YOLOv5的检测头后模型m AP提升了2.3%。(3)为了让网络模型更加关注重要的特征信息,使用各类注意力机制SE、ECA和CBAM模块,分别添加到网络的骨干网络后和CSPX-1结构后。其中,将注意力机制模块添加到骨干网络后模型m AP分别提升了0.3%、1.2%、1.0%,添加到CSPX-1结构后模型m AP分别提升了1.8%、2.9%、2.5%。将注意力机制模块添加到CSPX-1结构后在使用Decouple head改进YOLOv5的检测头部分,对应模型m AP分别提升了3.2%、1.5%、3.7%,ECA模块放在CSPX-1结构后效果不如放在骨干网络后,SE和CBAM对应的模型m AP都有很好的提升。(4)为了将模型部署移动设备和嵌入式设备中,本文使用轻量化网络Moblie Net V3、Shuffle Net V2和Ghost Net改进YOLOv5网络模型的Backbone部分,使用深度可分离卷积可有效降低模型复杂度。在网络模型m AP变化很小的前提下,各模型参数量分别下降了28.4%、45.8%、32.2%,计算量分别下降了28.8%、50.6%、49.9%。由于Neck部分的CSPX-2模块的参数量依然很大,在替换轻量化骨干结构的基础上利用C3Ghost模块替换Neck部分的CSPX-2模块进一步降低网络的参数量和计算量。改进Neck部分的CSPX-2模块后,各模型参数量分别下降了59.6%、59.5%、45.8%,计算量分别下降了66.9%、61.9%、62.5%。(5)针对深度学习的黑箱问题,为了证明网络模型可以学习那些重要的特征信息,对图像进行特征图可视化和热力图可视化分析。将训练好的模型迁移到钢材和PCB电路板数据集中进行测试也取得了良好的效果。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000332
{DOI}: 10.27278/d.cnki.gsdqc.2023.000332
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向多层信息保持的红外与可见光图像融合方法研究
{Author}: 杨馨
{Tertiary Author}: 霍宏涛
{Publisher}: 中国人民公安大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 红外与可见光图像;图像融合;局部特征;长距离相关性;语义信息;目标检测
{Abstract}: 图像融合技术日渐成为计算机视觉领域的研究热点,旨在整合同一场景下的多模态图像,生成一幅能够准确、全面描述该场景的图像。在众多图像融合类型中,红外和可见光图像的融合与公安实战应用贴合最为紧密。红外传感器通过捕捉场景中的热辐射来反映目标信息,即便在低照度或遮挡隐藏等条件下也能较好地识别如人、车辆等公安敏感目标。但红外图像的空间分辨率较低,场景的纹理细节信息少。与之对应,可见光图像由物体的反射光成像,具有分辨率高、细节丰富的特点。但可见光图像容易受雨、雾等客观环境因素影响,成像质量不稳定。因此,二者的融合图像能够将两种互补的图像信息进行整合,提高信息利用率,更好地为公共安全风险防范以及取证、处置工作提供有力保障。目前,红外和可见光融合技术在公安工作中的重要应用包括各类风险隐患的识别、监测、预警等,并逐渐服务于反恐、治安、禁毒、边防等公安实战部门。近年来深度学习在特征提取与数据表达方面的优势日渐凸显,被广泛应用于计算机视觉的多项任务。其中最具有代表性的卷积神经网络（Convolutional Neural Networks,CNN）以及生成对抗网络（Generative Adversarial Networks,GAN）已逐渐发展为红外与可见光图像融合研究的主流架构。针对目前基于CNN及GAN的融合算法对源图像局部信息聚焦度不足、长距离相关性信息提取度不足、以及语义信息关注度不足的问题,本文从图像多层信息保持的角度出发,设计并实现了三种融合算法:（1）针对当前算法中图像局部信息聚焦程度不足,导致融合结果细节纹理不清晰、边缘模糊的问题,提出一种基于生成对抗网络及导向滤波的融合算法（DSG-Fusion）。DSG-Fusion将导向滤波器引入生成器结构设计,促进生成器提取更多深层的背景信息,并且为融合结果补充更多纹理细节。此外,考虑到两种源图像的模态差异性,在生成器中使用两条独立的数据流对源图像进行特征提取,以学习更多具有代表性的图像特征。DSG-Fusion使用双鉴别器结构与该生成器进行生成对抗,并且设计了由强度和结构相似度构成的损失函数约束网络模型的训练,提升生成器保留源图像信息的能力。通过参数分析及消融实验,验证了DSG-Fusion中导向滤波模块的引入及双流结构的设计能够明显提升融合效果。同时,通过与7种具有代表性的算法在两个公开数据集中的对比评估,证明DSG-Fusion算法在细节纹理和目标边缘信息保留方面明显优于其他算法,但该算法在图像长距离相关性信息提取程度方面略有欠缺。（2）针对常见算法中图像长距离相关性信息提取度不足,导致重要的全局纹理信息丢失问题,提出一种基于Transformer与CNN的融合算法（DGLT-Fusion）。本文在DGLT-Fusion的网络结构设计中,将长距离Transformer模块与局部CNN模块交互堆叠并且密集连接,图像的长距离相关性学习和局部特征提取被解耦为两种模块的信息处理过程,使提取到的源图像信息能够更充分地融合。通过参数分析及消融实验验证了DGLT-Fusion算法将Transformer引入融合任务中并采取解耦网络结构的优势。同时,对比实验证明,DGLT-Fusion算法在图像全局纹理保持方面明显优于其他算法,但该算法缺乏对图像语义信息的充分关注。（3）针对目前主流算法中图像语义信息关注度不足,导致图像场景及目标可读性不高的问题,提出一种基于语义感知的融合算法（SePT）。SePT算法采用CNN模块和Transformer模块分别提取图像的局部特征和长距离相关性,并基于Transformer结构设计了两个语义信息学习模块以提取图像高级语义信息。其中一个语义信息学习模块将图像浅层特征映射为高级语义,另一个语义信息学习模块则负责学习不同感受野尺度中的图像语义。最终将图像局部特征、长距离相关性特征以及语义特征进行融合得到结果图像。参数分析和消融实验验证了SePT算法的合理性,同时,通过实验对比分析证明,SePT在图像语义信息保持及目标可读性方面明显优于其他算法。最后,基于公开数据集M3FD比较本文三种算法的融合性能以及目标检测任务表现,分析各算法的公安实战应用前景,为公安业务部门提供可参考的技术依据。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2023.000462
{DOI}: 10.27634/d.cnki.gzrgu.2023.000462
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手势识别在手指康复训练中的应用研究
{Author}: 冯晓敏
{Tertiary Author}: 李华玲;胡欣宇
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手势识别;手指康复;数据增强;康复系统
{Abstract}: 手势在人类交流过程中具有自然、通用等优势。受限于多种因素当今社会中患有手部功能障碍患者的不断增多。在此背景下,利用人工智能技术进行手部功能康复已经是目前研究的下一个热门课题。本文综述了针对手部功能障碍患者进行康复治疗的国内外研究现状,并对其发展方向进行了分析。本文从康复医学的角度,阐述了手的生理构造特征、手的康复训练特点、手的康复训练的要求。提出基于YCb Cr颜色空间和卷积神经网络融合的手势识别算法,同时为了实现手势识别在手指康复训练中的应用,设计一套基于视觉的手势康复训练系统,具体研究内容如下:(1)介绍了深度学习的基本概念,包括一些典型的神经网络及其模型,以及各个神经网络模型的结构和原理过程等内容。给出深度学习模型评估的方法和具体打分指标。对目前主流深度学习目标检测算法进行对比分析,为后文选择基础深度监测模型提供理论支撑。(2)对常用手势数据集进行分析,分别阐述了其优缺点,发现不同数据集以及数据集的完整性数对检测模型训练结果都有很大的影响。同时为了避免导致模型检测效率低下的数据问题,我们使用无监督和有监督的数据增强方法来增强原始数据集。这种数据增强方法不仅增加了数据集的数量,还增加了目标数据的多样性。(3)针对现有手势识别方法在复杂环境下识别率低的问题,本文提出了一种基于Ycbcr颜色空间和卷积神经网络相结合的手势识别算法。实验结果表明,该算法与本文列出的其他算法相比,其收敛效果最好、模型综合性能最佳,该算法可以有效去除复杂背景方面的影响,大大提高了精度,并能够在复杂环境中准确识别静态手势。(4)为了实现手势识别在康复系统中的应用,设计了一种基于深度学习的计算机视觉手势识别系统。通过摄像头采集数据,通过加载深度学习模型进行预测,通过显示界面等技术来构建康复系统,给出具有趣味性并且高效便利的康复训练方案,治疗方法弥补传统康复治疗的缺陷。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.001227
{DOI}: 10.27470/d.cnki.ghbgc.2023.001227
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的板材冲孔质量在线检测系统研究与开发
{Author}: 步亚昆
{Tertiary Author}: 郭俊美
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;板材质量检测;边缘检测;特征提取;尺寸测量
{Abstract}: 大尺寸金属冲孔板材作为金属材料的常用形式之一,被广泛应用于机械、汽车、建筑等领域。其在冲孔加工过程中往往会受到不可控因素的影响,导致板材冲孔质量出现瑕疵,例如圆孔偏移、孔数不足等问题。此外,人工质检审核也会存在误审的现象,从而降低了产品质量和生产效率。针对上述问题,本文提出了一种基于机器视觉的板材冲孔质量在线检测系统。深入研究与学习机器视觉、图像预处理、图像特征提取和标准件板材模型数据库等相关知识,成功设计并开发了一套检测精度高、检测速度快、成本低的实时在线检测系统。主要的研究内容和研究成果如下:(1)介绍了该课题的背景及意义,分析了国内外研究现状。根据企业的生产技术指标要求和生产车间的现场环境,设计了检测系统的总体架构,并对检测系统的工业相机、光学镜头、照明光源和嵌入式工控机等硬件部分进行了设计与选型。(2)详细介绍并分析了针对冲孔板材图像预处理的相关算子。首先,在提取感兴趣区域(ROI)的基础上,研究分析了不同滤波算子的图像平滑效果。其次,研究分析了各种图像分割算法,分别选用了基于深度学习的卷积神经网络(CNN)法以及基于最大类间方差(Otsu)的自动全局阈值法进行了图像分割,并对两种算法优缺点进行了比较分析。为了保留必要的图像轮廓边缘特征信息,对分割后含有杂点、空洞的二值图像进行了形态学处理。(3)重点研究并分析了粗-细两级边缘定位技术对图像轮廓边缘的定位提取。首先,对粗-细两级边缘定位技术的相关算子进行研究和分析,选用了Canny边缘检测算子进行粗级边缘定位。其次,采用优化改进的任意方向的多项式插值法在粗级边缘定位的基础上进行细级边缘定位,成功提取了冲孔板材图像中的圆孔和图像边缘直线。然后,研究分析了基于霍夫变换和最小二乘法的圆拟合技术,通过实验对两者的拟合结果进行了对比。最后,选用了基于最小二乘法的圆拟合技术,经图像轮廓特征检测,得到了冲孔板材的相关尺寸数据。(4)设计开发完成了一套简单实用的板材冲孔质量在线检测系统,并进行了实验结果分析与验证。首先,本文选用了Halcon图像处理软件和Visual Studio 2019软件开发平台进行混合编程,开发了自动检测系统软件及人机交互界面,实现了操作的便捷性。然后,创建了基于标准件的板材模型数据库、定义了匹配值参数,使系统检测时可直接调用板材模型即可,方便企业员工进行生产,体现了该检测系统的实用性。最后,进行了实验结果分析与验证,实验结果表明本检测系统在检测实时性、运行稳定性、测量准确性等方面实现了设计性能,满足了企业实际需求。(5)对投入企业实际应用的自动检测系统进行了相关介绍及说明。首先,对实际应用的自动检测系统相关硬件及功能展示界面进行了介绍。然后,对自动检测系统由设计到投入实际应用的相关过程进行了说明。最后,对自动检测系统投入前后的检测效率、经济效益等进行了对比分析。经工厂实际应用验证,该检测系统具有良好的检测实时性、运行稳定性和测量准确性,符合企业生产要求。本检测系统有效提高了产品质量检测效率,节省了人工,降低了板材冲孔质量的检测成本,提高了企业的生产效率。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000523
{DOI}: 10.27278/d.cnki.gsdqc.2023.000523
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的农田杂草检测研究
{Author}: 谭炎金
{Tertiary Author}: 陈西曲
{Publisher}: 武汉轻工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;杂草识别;迁移学习;对抗生成网络;注意力机制
{Abstract}: 农田杂草对农作物生长和产量有着极大的影响,因此及时有效的杂草防控是确保国家粮食储备的重要措施。然而,当前大多数的杂草识别技术在实际应用中存在不足,例如传统的目标识别算法无法实现大规模样本训练、泛化能力差且识别精度低下。本文以农田复杂场景下的甜菜和伴生杂草为研究对象,利用深度学习算法对获取的数据集进行训练,旨在提高模型识别精度和加快模型收敛速度,从而实现田间杂草的精准清除和农作物的精准施肥。为完成上述研究,做了如下工作:(1)介绍了卷积神经网络的基本结构,并探讨目前主流的目标检测算法,包括基于One-stage的算法:如SSD和Yolo系列,以及基于Two-stage的算法:如Fast R＿CNN和Faster R＿CNN。鉴于农田这种复杂场景下的目标检测对识别精度有着较高的要求,因此本文选择使用Faster R＿CNN作为农田杂草识别的网络模型。(2)构建了以Faster R-CNN为基础的新目标检测算法模型。首先,利用公开数据集并采用数据增强技术(比如Augmentor库和对抗生成网络)生成满足实验需求的数据集,使用标注工具进行处理。其次,通过迁移学习来验证迁移学习技巧能够加快模型的收敛速度。然后,对主干特征提取网络进行优化,保证特征信息提取得更加充分。最后,引入不同的注意力机制以实现自适应关注检测目标。实验结果表明,本文改进的算法不仅缩短了训练时间,加快了模型的收敛速度,而且有效的提高了模型的检测精度。(3)搭建了基于Faster R＿CNN的GUI调参界面,该调参界面还融入了语音系统来指导用户完成检测流程;针对同一张图像数据,按照控制变量法的思想来调节超参数,尽量使模型的检测精度达到最优;此外使用多张检测图像来验证调参界面的有效性、便捷性,并将所有的检测结果可视化。通过本文的深入研究,改进的Faster R＿CNN算法能够实现在复杂场景下的杂草识别,该算法借助迁移学习不仅加快模型收敛而且有效提高了识别精度,这为农田杂草识别技术提供了一定的理论支撑。
{URL}: https://link.cnki.net/doi/10.27776/d.cnki.gwhgy.2023.000058
{DOI}: 10.27776/d.cnki.gwhgy.2023.000058
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于工业机器人与机器视觉的红外传感器装配系统设计
{Author}: 袁海亮;薛强;王海玲;邵帅
{Author Address}: 天津机电职业技术学院;天津博诺智创机器人技术有限公司;
{Journal}: 制造技术与机床
{Year}: 2023
{Volume}: 
{Issue}: 06
{Pages}: 33-38
{Keywords}: 工业机器人;机器视觉;自动装配;红外传感器
{Abstract}: 针对红外传感器装配过程存在工件位置不准确等问题，设计了基于视觉定位技术的红外传感器自动装配系统。机械结构由工业机器人、供料单元、输送单元、视觉检测单元、快换工具单元和机器人第七轴等组成；利用视觉系统识别传感器端盖的位置和角度，并将结果换算到机器人世界坐标系，使机器人能够准确抓取到工件；搭建了基于以太网通信的PLC控制系统，完成红外传感器各零件的出料、输送、抓取及自动装配控制。实验表明，所设计的系统自动化程度高，运行可靠，具有较高的推广应用价值。
{ISBN/ISSN}: 1005-2402
{Notes}: 11-3398/TH
{URL}: https://link.cnki.net/doi/10.19287/j.mtmt.1005-2402.2023.06.006
{DOI}: 10.19287/j.mtmt.1005-2402.2023.06.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向环境理解与目标跟踪的SLAM关键技术研究
{Author}: 孙天
{Tertiary Author}: 刘永
{Publisher}: 南京理工大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 视觉SLAM;目标识别;目标跟踪;地图构建
{Abstract}: 同步定位和建图(SLAM)已成为机器人技术的热门研究课题,它是许多新兴技术的基础模块,例如自动驾驶汽车、机器人导航、无人机、虚拟现实和增强现实。但是,在很多情况下,无人系统工作的环境是完全未知的。这时,无人系统就需要高精度、高鲁棒性的里程计,以确保无人系统在失去GPS信号的情况下也能长时间工作。与此同时工作空间的三维地图对于机器人实现定位、避障、导航和自主任务也非常重要。
本文研究的内容是SLAM在无人系统中如何更好的理解周围的环境信息,主要包括语义信息,识别障碍物(正障碍和负障碍),动态物体识别,构建动态与静态三维地图以及目标跟踪等。这不仅可以提高SLAM估计的精度,还能让机器人具有仅次于人类的对环境的理解能力,使无人系统更好的服务于相应的工作,从而提高无人系统的人机交互能力,更好地为人类服务。
本文围绕视觉SLAM的关键技术进行研究工作。视觉SLAM在十几年的发展中,取得了一系列的突破,但是应用在实际领域的鲁棒性还是不够,其主要原因之一便是底层中的特征提取,在动态环境下的特征点无法准确的提取和匹配。然而随着语义分割技术在计算机视觉等相关领域取得了很大进展,其大数据的自动学习提取相关的特征,使得视觉SLAM可以通过网络分类大多数物体。对于视觉SLAM系统中的一些问题,可以引入语义分割技术进行性能增强或替换,从而可以提高视觉SLAM系统的性能。于此同时,复杂环境下的正障碍和负障碍的检测和跟踪也可以优化SLAM的鲁棒性。因此,本文在SLAM初始化,负障碍的检测与跟踪,视觉SLAM中动态障碍以及动态环境的稠密点云构建的问题进行了研究,并取得了一定的成果。具体内容主要包括:
1针对紧耦合的视觉惯性SLAM更好的初始化的问题,本文采用四个连续关键帧的数据进行初始化,并计算了加速度计和陀螺仪的偏置以及尺度和重力方向,在此基础上求得关键帧的速度。将所提出方法在Eu Roc数据集和实际场景中进行实验,并将准确性与现有VISLAM系统进行了比较。实验结果证实了所开发系统有令人满意的精度和效率。
2针对目前对负障碍检测的准确率和实时性无法兼顾的问题,以及提高SLAM的环境理解能力。本文通过点云的高度分析提取3D负障碍候选区域,并从中获得2D负障碍候选区域,并采用图像特征跟踪来确保检测精度和实时操作。同时,本文提出了一种类似RANSAC的方法来解决3D重建中点云错误匹配产生噪声的问题。所提出的方法在相关数据集和20Hz的相机加Jetson Xavier NX平台上进行了实验验证。
3针对目前主流SLAM在动态场景鲁棒性差的问题。本文将目标检测技术引入SLAM来获得更好的场景感知能力,从而形成更鲁棒的SLAM系统。然而,目标检测依赖于深度学习的网络,没有进行视觉几何关联,不能准确地识别物体的运动。同时,SLAM操作过程中的丢帧会增加特征点匹配错误的概率。因此,本文结合目标检测技术,提出了一种基于图像分割的位姿优化算法来进行更好的多帧关联特征匹配。提出了一种在识别出运动目标后筛选最稳定的目标跟踪方法。实验在TUM数据集上的5个序列上进行了验证。首先,我们进行了跟踪性能的消融实验。之后与ORB-SLAM2,原始语义ORB-SLAM2,RS-SLAM以及DS-SLAM系统进行了全面的比较,证实了我们的算法在动态环境下具有更好准确性和鲁棒性。
4针对目前SLAM在动态环境中实时构建动态物体不精确的问题。使用MaskRCNN作为语义先验信息,利用RGB-D相机模型,算出图像中的像素点对应的空间坐标,并统一映射到三维空间坐标系中,得到对应的稠密语义点云。利用负障碍中的平面识别部分进行地面提取,并利用动态物体识别的方法构建实时的动态环境的点云。在TUM数据集上分别进行了稠密点云、语义点云、八叉树点云、静态场景点云和动态场景点云、动态物体的三维框的提取等实验,之后进行了KITTI三维重建实验,证明了所提系统可以在动态环境中构建清晰的三维点云图。为了显示出我们基于动态跟踪优化的三维重建具有更好的效果,与ORB-SLAM2,RTAB MAP,RS-SLAM系统进行了比较实验,最后还给出了各模块的运行时间。
{URL}: https://link.cnki.net/doi/10.27241/d.cnki.gnjgu.2023.000082
{DOI}: 10.27241/d.cnki.gnjgu.2023.000082
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向农产品品质光学无损检测的建模技术研究
{Author}: 杨宇
{Tertiary Author}: 朱启兵
{Publisher}: 江南大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 农产品品质;光学检测;建模技术;遗传规划算法;深度学习;多任务学习;自监督迁移学习
{Abstract}: 农产品品质光学检测技术开发是推动农产品质量安全监管体系建设,实现农业数字化、网络化、智能化的关键环节。农产品品质光学检测技术(例如:高光谱成像技术、近红外光谱分析技术)本质上是一个软测量技术,其核心是构建农产品光学信息与其品质属性(如缺陷类型及分布、理化指标等)的数据驱动模型。光学信息的高维特性,被测样品的形态和感兴趣属性的多尺度变化所导致的特征提取困难、理化指标难以测量所导致的小规模训练样本集,以及样本之间潜在的域迁移问题,都会影响数据驱动模型在农产品品质检测领域的精度。本文围绕检测农产品外部品质和内部品质所涉及的数据驱动建模问题,从计算机视觉技术和光谱定量分析建模方法的角度开展研究,以期推动农产品品质光学检测技术的发展。论文的主要研究内容如下:1.针对不规则形状农产品表面反射光分布不均匀、污渍干扰、特征易丢失造成的小尺寸缺陷检测困难的问题,提出了协同有监督多阈值分割模型和Canny边缘检测器的检测方法。该方法利用利用遗传规划(genetic programming,GP)算法生成分割模型,模型可将原始多光谱(multi-spectral,MS)图像转化为缺陷与背景的对比度增强的灰度图像,以克服不均匀反射光造成的不同位置处缺陷之间的语义混叠,进而利用阈值分割方法分割灰度图上缺陷的初始区域;利用Canny边缘检测器从MS平均灰度图中抽取缺陷的精确边缘信息,进而融合缺陷初始区域获得精确的小尺寸缺陷区域。在食用马铃薯和马铃薯种子MS图像数据集上的实验结果验证了所提出方法的有效性。2.农产品缺陷检测往往面临着多种类缺陷并存、尺寸多样所导致的检测精度偏低问题,针对此问题,本文提出了用于检测多尺寸缺陷的目标检测网络。该网络级联1个卷积模块和6个Res2Net模块构建骨干网络,以从MS图像中提取多个尺度卷积特征(单尺度特征融合了缺陷的细粒度空间信息和语义信息);将两个不同尺度的卷积特征分别输入颈部网络和检测头网络以准确定位和分类多种类缺陷。在包含五种缺陷的马铃薯MS图像数据集上的检测结果验证了该网络的有效性。3.针对农产品高维光谱数据信息冗余、多重共线性导致的光谱定量分析模型精度、泛化能力不足的问题,本文提出了基于GP算法的光谱定量分析建模方法。利用多维树编码原始光谱数据,实现高维数据降维的同时抽取多级别多种类特征,进而利用多元线性回归方法(multiple linear regression,MLR)构建预测模型;以种群个体进化的方式实现多维树与MLR模型的信息交互与参数更新。在六种不同种类光谱数据集上的实验结果验证了该方法可构建精确的光谱定量分析模型。4.针对单任务预测模型难以满足农产品多品质参数高精度快速测量需求的问题,本文提出了多任务GP算法以实现农产品多个品质参数联合学习建模。利用多维树从原始光谱数据种抽取多个任务的共享特征;利用LS-SVR抽取每个任务的私有特征,并构建预测模型;利用带有非支配排序和剪枝操作的多目标优化方法搜索共享特征、私有特征和预测模型的最优组合。在苹果(2个品质参数)和甜菜(3个品质参数)光谱数据集上的实验结果验证了该方法的有效性和泛化性。5.针对域偏移导致的源模型预测未知目标域农产品样本性能退化的问题,本文提出了一种自监督迁移学习方法。利用无标签源域数据在自监督学习框架下训练光谱编码器,以获得多尺度、多种类域不变特征;迁移光谱编码器,其后依次接入特征融合层和预测头网络构建光谱定量分析模型;利用部分有标签目标域数据在监督学习框架下重训练预测模型,以提高模型预测未知目标域数据的精度。在苹果、药片和三聚氰胺光谱数据集上的实验结果显示提出的方法可有效地去除多种域偏移对定量分析模型的负面影响。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.000102
{DOI}: 10.27169/d.cnki.gwqgu.2023.000102
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的盘类零件识别与尺寸检测研究
{Author}: 陈朝伟
{Tertiary Author}: 黄伟莉;陈建华
{Publisher}: 东华理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 零件识别;检测系统;卷积神经网络;边缘形态学处理;最小二乘法
{Abstract}: 随着科技的发展,工业产品零件识别和尺寸测量技术朝着高效率、高精度方向发展,人工测量方法已经无法满足当下测量要求,基于机器视觉的图像测量技术具有非接触、高精度、速度快的优点,图像测量方法逐渐成为当下工业生产检测的热点。本文以机器视觉技术为基础,针对盘类零件的外形特征与尺寸大小,进行识别与检测方面的研究。
(1)本文基于盘类零件识别与检测系统的需求,设计了识别与检测系统的整体方案。依据系统需求,选择了合适的相机、光源以及其他硬件设备等,并完成系统硬件配置与实验平台搭建。
(2)基于盘类零件识别针对零件位置、尺寸、结构等特征,采用卷积神经网络结构框架进行视觉识别,并对神经网络中的优化算法分析,搭建两种卷积神经网络模型,通过网络模型的损失函数和准确率分析模型的优略。实验识别结果表明零件的识别率在96.8%左右,符合系统识别要求。
(3)基于盘类零件图像预处理和边缘检测方法研究,对图像进行灰度化、直方图均衡化、滤波、二值化、边缘检测以及边缘形态学处理,目的是增强有关信息的可检测性和特征提取,然后采用改进的小波模极大值边缘检测和传统边缘检测对比,依据结果表明使用改进的小波模极大值边缘检测方法更优,为尺寸测量提供了重要参考。
(4)基于盘类零件视觉检测系统,先对相机参数进行标定,用霍夫变换法计算齿轮中心点坐标,并用最小二乘法拟合齿轮的参数边界。通过系统测量其齿顶圆直径、齿根圆直径、齿数和模数等参数。从实验结果可知,机器视觉检测方法同传统检测方法测量精度误差在0.05mm左右,符合工业精度要求。实现了齿轮参数的快速检测系统,节省了测量时间,满足工业实际应用场合,具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27145/d.cnki.ghddc.2023.000698
{DOI}: 10.27145/d.cnki.ghddc.2023.000698
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去雾算法研究
{Author}: 李燕
{Tertiary Author}: 孙建德
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 单图像去雾;细节恢复网络;一致性正则化;对比学习;图像重构
{Abstract}: 图像数据是推动计算机视觉任务不断发展的重要基础,图像数据的质量更是决定各类计算机视觉任务性能表现的关键因素。现实世界中拍摄的图像往往会受到各种恶劣天气环境的干扰,而有雾图像就是其中一种常见的情况。在有雾天气环境下拍摄的图像往往表现出模糊、对比度低、颜色失真等图像质量退化现象。将有雾图像作为各种计算机视觉任务(如目标检测、自动驾驶、场景理解等)的输入数据会大大降低其真实的性能效果。因此,图像去雾作为计算机视觉领域的一项关键工作引起了广泛的关注。特别是近年来,随着卷积神经网络的发展,图像去雾领域涌现出了许多显著的研究成果。图像去雾旨在从给定的有雾图像中重建出其对应的清晰图像,从而减轻恶劣天气环境造成的图像退化对各类计算机视觉任务的影响。现有的单图像去雾方法主要分为两大类:一个是基于先验的图像去雾方法,另一个是基于深度学习的图像去雾方法。基于先验的图像去雾方法利用图像的统计特征设计先验知识并将其作为图像去雾过程的约束条件,尽管这些先验知识在某些环境条件下能够表现出不错的效果,但是缺乏对不同环境条件的泛化能力。随着卷积神经网络的发展和大规模数据集的创建,基于深度学习的图像去雾方法不断涌现,该类方法基于数据驱动可以直接学习有雾图像与其对应的清晰图像之间的映射关系。近年来,基于深度学习的图像去雾算法取得了显著的进展,但是仍然面临一些挑战亟待解决。例如,如何有效地恢复去雾后图像中的细节信息以获得更加自然真实的清晰图像;如何在保证模型去雾性能的同时,提升模型的鲁棒性,使其在同一场景不同雾霾密度情况下输出一致的去雾结果。针对以上问题,本文分别从如何有效提取有雾图像的细节信息以提升模型的去雾性能和如何提升去雾模型在不同雾霾密度场景下去雾的鲁棒性两个方面展开了深入研究。本文提出一种基于独立细节恢复网络的单图像去雾方法。现有大多数去雾方法忽视了对去雾后图像细节信息的恢复,而本方法并行考虑有雾图像的去雾问题及细节恢复问题。本方法由两个并行的子网络组成:一个是去雾骨干网络,用于对有雾图像进行初步去雾并生成粗糙的去雾图像;另一个是细节恢复网络,用于从有雾图像中提取局部和全局的细节特征,并生成细节特征图。通过细节特征图的引导,从而将粗糙的去雾图像细化为更高质量的去雾图像。此外,本方法提出了多方面损失函数,该损失函数同时考虑图像的像素级损失、感知损失和重构损失,进一步增强了去雾模型的稳定性。本文提出了一种基于一致性和对比辅助重建的鲁棒单图像去雾方法。该方法是首个针对不同雾霾密度场景下去雾模型鲁棒性问题进行研究的方法,提出了一种新颖的针对不同雾霾密度学习的图像去雾模型。本方法提出了对比辅助重建算法,利用去雾图像的各类负样本数据从不同的方向将网络输出的去雾图像压缩到清晰的目标图像上,优化了传统的正样本导向的去雾目标函数。此外,本方法设计了一个一致性正则化框架用于图像去雾,保证了去雾模型对于同一场景不同雾霾浓度的图像能够输出一致的去雾结果,提高了去雾模型的鲁棒性。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2023.000660
{DOI}: 10.27280/d.cnki.gsdsu.2023.000660
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的新型语义分割模型与杂草识别研究
{Author}: 刘思岐
{Tertiary Author}: 韩静;牛文祥
{Publisher}: 黑龙江八一农垦大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像识别;计算机视觉;深度学习;杂草分割
{Abstract}: 玉米作为国家重要粮食产物,在农业生产上,受到草害的危害异常严重,在极端情况下,玉米由于杂草的作用,产量可下降20%以上。常规大面积全淋式农药除草方式,不能对杂草随用随施,容易造成农药的极大浪费、生产成本偏高、环境污染问题严重等等,进而影响玉米产量与质量。以及已有机械除草、化学除草及其他手段又有种种弊端,如环境污染、提高劳动力的成本等等,因此,研究高效智能除草技术具有现实意义。针对以上问题,需进行玉米杂草精准变量施药。应用图像识别技术对作物田间杂草进行识别操作,本实用新型能有效地降低田间杂草给农作物带来的伤害,有效的增加作物的产量与质量。同时将本论文提到的方法与一般连续喷洒方法进行了比较。得到了以下结论:利用图像识别技术进行除草,可以降低对环境的污染,为农业可持续发展做出贡献。本研究的目的是对玉米幼苗及杂草进行快速,准确地鉴定;并运用计算机视觉,深度学习等方面的技术进行研究,对能自动识别玉米幼苗及杂草的技术进行了分析研究。具体研究内容如下:(1)对杂草和玉米生长速度及后续处理,根据图像质量需求进行了分析对比,为了决定图像采集时间及镜头的高度与角度,采用几何转换:图像翻转,图像缩放,图像归一化;颜色变换、伽马变换对图像进行数据增强处理;利用Label Me软件对图像进行手动标注,将玉米和杂草用不同颜色进行区分。(2)为提高复杂环境下田间玉米与杂草和密集分布杂草的识别定位准确率,提出一种改进Res Net50网络的杂草分割算法。首先,在特征提取过程中,通过卷积残差层下采样,使图像符合对应的显示区域。再经过一个转置卷积一步上采样,每次将图片尺寸扩大一倍,最终将图像尺寸还原到原始大小,解决了精度问题。最后使用Softmax层进行输出,得到分类图。(3)为了研究不同模块对特征融合的杂草分割识别模型的效果,首先选择不同的主干提取模块分别为VGG网络、Res Net网络。把原始Unet的提取网络换成Res Net网络,使得模型有更好的提取能力,选用Res Net作为Unet分割网络的提取模块的基础上,分别对CA注意力模块和FFM特征融合模块进行消融实验。之后使用CA注意力模块对提取网络进一步加强,最后使用FFM特征融合模块对不同语义的特征信息进行融合,证明了使用FFM特征融合模块和CA注意力机制有利于提高玉米和杂草分割效果。
{URL}: https://link.cnki.net/doi/10.27122/d.cnki.ghlnu.2023.000208
{DOI}: 10.27122/d.cnki.ghlnu.2023.000208
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态学习的食品营养评估方法研究
{Author}: 邵文静
{Tertiary Author}: 侯素娟
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 食品营养;多模态融合;营养评估;计算机视觉;深度学习
{Abstract}: 随着社会经济的发展和人民生活水平的不断提高,食品的安全与健康已成为公众持续关注的重要问题,而食品中营养素的含量也是衡量食品是否健康的重要指标。2022年国务院发布的《中国居民营养与慢性病报告》指出,我国大多数居民仍存在不健康的生活方式,成年人口的超重、肥胖率超过50%以上,高血压、糖尿病等慢性病患病率和发病率呈现上升态势。理解和评估食品中各种营养素的含量,对公众自我健康的管理和疾病预防具有重要意义。食品营养含量的评估已经成为食品科学、计算机视觉和营养健康等各个领域研究的热点。专业食品营养评估人员的数量不能够满足人们日常食品营养评估的需求,同时智能膳食评估应用程序、食品营养估计系统准确性仍然欠佳。为缓解营养评估专业人员短缺,提高营养评估的准确性和高效性等问题,本文以餐饮环境下的食品图像为研究对象,结合多模态融合与深度学习方法,提出了基于计算机视觉的自动化食品营养评估方法,具体工作如下:(1)针对食品RGB图像的营养评估效果不佳的问题,本文提出了一种端到端学习的食品营养评估方法Swin-Nutrition,实现对食品营养素含量的评估。该方法旨在从食品的RGB图像中充分捕获特征信息,进而提高营养素含量估计的准确性。Swin-Nutrition采用Swin Transformer、特征融合模块以及营养素预测模块来评估营养素含量。其中,Swin Transformer作为主干网络进行食品图像的特征提取。为了捕获更有效的特征表示,设计了金字塔结构式的特征融合模块来融合多尺度的特征图,增强特征表示进而提高营养含量预测的准确性。(2)针对单一RGB图像营养预测存在的局限性,本文提出了基于多模态融合的食品营养评估方法RGB-D Net。目前的食品营养评估方法是对单一的RGB图像或者把RGB和深度(depth)图像简单的融合,未考虑不同模态图像之间所具有特征的差异性,忽略了不同模态图像之间的共性和特性。引入多模态特征融合模块(Multimodal Feature Fusion,MMFF),充分融合了RGB和depth图像中丰富的特征信息。采用多尺度特征融合(Multiscale Feature Fusion)方法对不同分辨率的特征进行融合,提高营养评估的准确性。(3)本文在营养评估数据集上进行广泛的实验,验证了本文所提出的食品营养含量估计方法的可行性和有效性。对四种营养素的预测结果进行可视化分析,直观地呈现模型预测的可靠性。综上,本文针对食品营养含量评估所存在的问题,提出了两种自动高效的营养评估模型。通过广泛的实验评估表明:本文所提出的研究方法提升了模型营养预测的准确性,为食品营养评估的进一步发展提供一个新颖的视角,同时也满足了人们对饮食监测的需求,保障公众的膳食均衡。与此同时,该研究也推动了自动化的食品营养评估方法进一步部署在公众日常生活中。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2023.000850
{DOI}: 10.27280/d.cnki.gsdsu.2023.000850
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 显微镜下血细胞的智能检测和分割算法研究
{Author}: 王若霏
{Tertiary Author}: 张彦春
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;血细胞检测;血细胞分割;YOLOv7
{Abstract}: 人体血细胞成分分析是通过医学仪器的检测对人体血液内红细胞、白细胞等进行分析,从分析结果中判断患者的健康状况,是血常规检测常用的一种技术。随着人工智能技术的发展,深度学习越来越多地被应用于医疗中,其中计算机视觉算法已经可以应用到血细胞的检测和分割任务中,为辅助医疗提供服务。然而,目前的深度学习检目标测模型仍存在速度与精确度难以兼容的问题,并且由于显微镜下观察到的血细胞非常多,存在细胞重叠和粘连现象,因此要实现对血细胞精确的检测和分割是一个很有挑战性的任务。本文主要针对显微镜下血细胞图像的检测和分割两个任务,研究构建了一个能够实现速度与精度得以兼容的方法。血细胞检测与分割是医学影像分析中的重要任务之一,近年来血细胞的自动化检测与分割技术逐渐得到普及应用。然而,目前常用的针对血细胞进行检测和分割的深度学习目标检测算法还存在一些不足。本文针对当前血细胞检测算法中存在的速度与精度不兼容的问题,在目前表现较好的目标检测模型YOLOv7的基础上,提出了一种新型的轻量型算法模型——Mobile-YOLOv7。本文采用引入软注意力机制和自适应空间特征融合等方法,来提高模型检测的准确率。本文还采用一种更加轻量的结构Mobile Vi Tv3模块来替换YOLOv7的主干网络中原本的E-ELAN卷积组合模块,减少参数量的同时,还能提高模型的检测速度。由于在临床医学上,对血细胞成分进行分析不仅需要检测功能,有时候也有进行血细胞分割的需求,因此本文还在YOLOv7目标检测算法的基础上,增加分割功能的实现,使得模型具有更强的泛化能力。上述模型已在三个显微镜下血细胞数据集上进行了广泛的实验和测试,并取得了良好的性能指标。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.000943
{DOI}: 10.27040/d.cnki.ggzdu.2023.000943
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的ROV水下设施裂缝检测关键技术研究
{Author}: 李忠义
{Tertiary Author}: 姜晓勇
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: ROV;水下图像处理;语义分割;裂缝检测
{Abstract}: 水下设施长时间受到水流的冲击和微生物的腐蚀,表面容易受损开裂,常用有缆水下机器人辅助人工进行结构损伤探测。而水下设施复杂多样,水域情况也比较复杂,在不同水域精确并且快速判断出损伤情况,对提高检修效率显得十分重要。为此,本文研究了水下设施裂缝损伤检测的相关技术,以解决水下图像质量低的问题,以及实现裂缝损伤的快速精确检测。论文主要内容如下:(1)针对本文应用场景,设计了一款用于辅助水下设备维护与检修的ROV系统。包括本体外形结构设计、驱动设计、电源板设计、单片机控制电路设计和辅助传感设备的选型。经过测试,ROV可以实现在水下前进、转向、定艏和定深等运动,完成了图像采集的任务,并且能够适应多种水域环境。(2)针对水下裂缝图像的质量低、不利于检测的问题,本文提出了一种图像预处理方法。充分分析了水下图像退化的机制,根据水下裂缝图像的特征,首先采用基于物理模型的恢复方法,估计相关参数反推得到相对清晰的图像,再经过基于导向滤波的算法去噪,最终得到利于检测的图像。对水下图像的预处理能够获高质量的图像,实验验证了对提高裂缝损伤识别精度有促进作用。(3)针对水下设施裂缝损伤图像的检测精度不高,本文提出了基于U-Net网络改进的图像裂缝实时分割算法。首先根据裂缝语义信息的特点,确定了基于语义分割技术的检测方法,然后分析了语义分割网络,选取基于U-Net网络进行改进,提高识了别精度,并且通过模型压缩得到轻量化的网络模型,最终实现裂缝损伤高精度实时分割。本文设计的ROV系统满足对水下设施的即时检测,能够辅助人工提升检修的效率,对水下复杂结构的损伤检测领域具有一定的参考价值。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2023.000047
{DOI}: 10.27840/d.cnki.gzjkj.2023.000047
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的图像语义分割方法研究
{Author}: 张鑫
{Tertiary Author}: 姚庆安
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像语义分割;卷积神经网络;Transformer;轻量级网络;编-解码结构
{Abstract}: 图像语义分割一直是计算机领域具有挑战性的课题研究,但随着卷积神经网络在图像语义分割领域的研究逐渐趋于饱和,目前的语义分割精度难以提升是一个急需解决的问题。因此,研究人员开始把目光转向自然语言处理领域大火的Transformer,该网络基于自注意力机制不受局部相互作用的影响,既能挖掘长距离的依赖关系又能并行计算,取得与卷积神经网络相当的实验结果。然而图像局部关联性缺失、复杂计算量等一直是Transformer网络研究的痛点。本文在基于Transformer的基础上展开研究,保留图片局部相关性,设计轻量级图像编-解码分割网络。具体的研究内容如下:(1)本文提出基于Transformer的图像语义分割框架。主要结合图像金字塔的分割思想来分割不同层图像的语义信息,从而获取不同维度的语义特征图,采用计算机视觉常用的编-解码结构,设计更加符合下游分割任务的模型结构,进一步完善Transformer用于图像分割任务。(2)编码部分。提出重叠图像切割模块,保留图片中相邻位置的语义关联性。不同于自然语言处理,该模块保留图片本身的局部相关性,保持高分辨率的分割特征图,提高语义分割精度。对于本文中间阶段的网络,同样输入重叠后的切割图片,保证不同层次图片的高分辨率。(3)解码部分。本文采用更加简易有效的解码结构,不同于以往的复杂设计,而是消减模型的计算量。本文提出的轻量级解码部分适用于主干网络Transformer,不仅大大减少冗余的参数量,而且精度也大大提高。基于以上内容研究,与传统卷积神经网络模型相比,本文模型在ADE20K、Cityscapes和VOC 2012数据集上取得40.18%、77.61%和64.64%的精度。进一步验证模型的有效性,为进一步实际应用奠定基础。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000728
{DOI}: 10.27805/d.cnki.gccgy.2023.000728
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于目标检测和密度估计的大豆幼苗计数算法研究
{Author}: 朱轩池
{Tertiary Author}: 冯江
{Publisher}: 东北农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 大豆;出苗率;目标检测;密度估计;图像处理
{Abstract}: 大豆是全球重要的粮食作物,提高大豆产量是现今我国农业的迫切需求。大豆的增产离不开早期田间管理。快速准确地获取出苗率,有利于农民及时地间苗和补苗,也有利于评价种子质量的优劣。目前,大豆苗期出苗率的统计工作主要通过人工观察统计完成,需要大量的时间,不仅浪费人力物力资源,而且人工统计方法准确性较差。因此,在大豆生产与深度学习技术结合的趋势下,大豆出苗率的统计方法需要提高信息化和智能化水平。为了快速地获取大豆出苗率,及时间苗、补苗和评价种子质量,进而提高大豆产量。本文基于目标检测和密度估计方法提出了大豆幼苗的计数方法,达到快速地和准确地获取大豆出苗率信息的目的。本文的主要工作内容如下:(1)制作大豆幼苗数据集。本文选用大疆M600pro无人机航拍大豆幼苗,获得图像数据经过筛选、拼接、裁剪得到可以使用的大豆幼苗图像。对图像中的幼苗进行人工计数和标注,得到大豆幼苗数据集。使用了传统数据增强方法扩充数据集,并使用直方图均衡化和明度提升的数据增强方法,提升模型的计数性能。经实验证明,三种方法均能有效提高模型的识别性能,并且三种方法叠加使用时提升的性能最多。(2)提出了一种基于YOLO v5s的大豆幼苗计数算法。首先,选取YOLO v5s作为基础模型,引入Bi FPN和CBAM模块,并且将原有算法的检测头更换为Transformer Predict Head,用于提高模型的检测性能。在大豆幼苗数据集上进行实验,模型的MAE为1.73,RMSE为4.57。对比其他目标检测方法,结果证明了该算法的有效性和优越性。(3)提出了一种融合卷积注意力的密度估计大豆幼苗计数算法。首先把大豆幼苗的计数问题看作是与密度图的映射关系。为了生成高质量密度图,在CSRNet的基础上将原有模型的前端网络更换为vgg19,提高网络深度和特征提取能力。同时引入卷积注意力模块,进一步提高模型的计数性能。最后对生成密度图进行像素点概率求和,得到大豆幼苗的预测数量。在大豆幼苗数据集上进行实验,模型的MAE为2.35,RMSE为4.69。对比其他密度估计方法,结果证明了该算法的有效性和优越性。(4)设计实现了一个大豆幼苗计数系统。该系统部署在PC端,整合了本文提出的两种大豆幼苗计数算法,通过简单的界面操作,用户可以选择模型和大豆幼苗图像进行大豆幼苗的出苗率计算,或者添加新数据集进行新模型的训练,并且可以把计数得到的结果存入数据库。经过实验验证了该系统的可行性。本文结合计算机视觉中目标检测方法和密度估计方法,实现了对大豆幼苗出苗率的快速统计。降低了人的劳动强度,节约了人力成本。同时,也为其他农作物出苗率快速获取奠定了基础。
{URL}: https://link.cnki.net/doi/10.27010/d.cnki.gdbnu.2023.000193
{DOI}: 10.27010/d.cnki.gdbnu.2023.000193
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的轻量化小目标检测算法研究
{Author}: 孙凤乾
{Tertiary Author}: 刘海英
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;深度学习;小目标检测;算法轻量化;YOLO
{Abstract}: 本文针对如何提高计算机视觉与人工智能技术中目标检测算法在小目标检测领域的检测性能并实现算法显著轻量化进行了研究,基于深度学习与神经网络理论,以YOLO系列目标检测算法为基础,提出了一系列包括复杂远距离密集人脸检测、海面小物体搜索检测、通用生活场景检测、无人机空对地小目标检测等场景在内的复杂与未知环境下的小目标检测与算法轻量化提升及改进策略。通过实验对比,结合本文改进策略所形成的新算法,在各种小目标检测场景下都有优于传统算法的检测性能及轻量化效果。本文的具体研究内容如下:针对现有的目标检测算法多专注于对全尺寸目标的检测,而较少考虑对特殊场景下的小目标进行检测优化及在算法部署时存在的模型过大、部署难度大的问题,本文综合分析了主流目标检测算法的模型构成、检测原理,以YOLOv5为基础算法,提出了多项提升算法精度、降低算法计算资源消耗的原创策略。如通过合理裁剪模型特征提取网络部分的最终特征图输出,显著降低模型需要的计算资源并实现模型显著轻量化;提出一种基于PANet与Bi FPN的小目标检测改进特征融合方式(PB-FPN),有效提高模型的小目标检测能力;通过将特征提取网络中的空间金字塔池化层(SPPF)引入特征融合网络并与模型预测头衔接,有效提升模型的综合检测性能。同时,本文以研究轻量化小目标检测算法为基础,以目标检测算法结合无人机空对地检测场景为应用,针对常见的目标检测算法在无人机空对地检测场景下所存在的算法模型过大、部署难度高、小尺度目标检测困难等问题,对经典的YOLOv5算法进行了一系列的改进。提出一种新型的双支路CSPNet(DR-CSPNet)结构,有效降低了算法模型的复杂度和计算量;提出一种新型的特征融合路径(FS-FPN),有效提升了模型的综合检测精度;通过融合新型的注意力机制(ACmix),有效提升算法在无人机空对地检测场景下的性能。我们将整合本文提出的改进理论与策略的原创算法命名为SF-YOLOv5、UAV-YOLOv5,并通过详细的实验论证了改进算法优越性、有效性和泛用性。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000936
{DOI}: 10.27278/d.cnki.gsdqc.2023.000936
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的六足步行消防机器人避障系统研究
{Author}: 曾繁歌
{Tertiary Author}: 韩成浩
{Publisher}: 吉林建筑大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;步行消防机器人;目标检测;自主避障;路径规划
{Abstract}: 伴随着国家工业现代化理念的不断完善,多足机器人在不同的领域都得到了极大的发展,尤其在消防救援方面应用十分广泛,可以很好的代替人类去完成危险的工作任务。六足机器人因为其良好的机动性能、应用环境广泛等优势引起了国内外实验室学者的研究,其中并联六足步行机器人因整体刚性大、承载能力强、运动稳定性等特点成为了重点研究的对象。因为消防机器人工作时需要面对复杂多变的火灾现场,所以对消防机器人的自主运动提出了极高的要求。对于当前环境的感知以及检测到障碍物后实行的路径规划自主避障都是亟需解决的问题。本文基于长春市科技计划项目(非仿生步行爬楼梯消防机器人的应用研究),旨在解决六足步行消防机器人工作过程中对于火灾的检测以及对于躲避障碍物的路径规划问题,实现六足步行消防机器人的火灾预警、障碍物自主躲避、路径规划等功能。首先本文对六足步行消防机器人总体避障方案进行设计,采用基于机器视觉的方式去感知当前环境信息,其中选择张氏棋盘格以及MATLAB工具箱获取所选双目摄像头内外参数并完成标定,再通过Open CV图像处理软件进行左右视图的立体匹配获取当前环境的深度信息。其次在获取当前环境信息后,本文选择在YOLOv5这一端到端的目标检测算法的基础上针对三个方面进行改进极大的提高了检测速度以及检测精度。最后对六足步行消防机器人进行运动学分析,通过仿真设计了三种不同的步态并且根据障碍物的不同大小执行相应的避障策略,同时针对路径规划算法在传统A-star路径搜索算法的基础上进行了改进提升了搜索效率,减小了搜索误差。在完成以上研究内容后,搭建软件测试环境。借助MATLAB软件自带的仿真测试工具,对本文设计的基于机器视觉的六足消防机器人避障系统进行仿真测试,并在现实环境中进行了实机测试。测试结果证明,方案设计符合逻辑,系统功能正常。不同距离下的测距实验表明结果满足设计需要,在火焰检测测试中表明改进后算法识别精度与速度均得到一定提升,在路径规划仿真测试当中表明改进后算法搜寻精度提升以及搜寻误差降低。最后在现实环境当中,六足步行消防机器人能够安全通过障碍物并到达指定地点且成功率较高。因此本文提出方案具有一定的可行性,为基于机器视觉的六足消防机器人的避障技术的进一步研究提供了参考价值。也使六足步行机器人在国内消防救援领域应用更加智能化。
{URL}: https://link.cnki.net/doi/10.27714/d.cnki.gjljs.2023.000043
{DOI}: 10.27714/d.cnki.gjljs.2023.000043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的货车碰撞预警系统研究
{Author}: 钱宇清
{Tertiary Author}: 左付山;黄孙俊
{Publisher}: 南京林业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 运输安全;图像增强;目标检测;单目测距;碰撞预警
{Abstract}: 近年来公路交通运输行业快速发展,货车在运输行业承担了极其重要的任务,同时也带来更加严重的运输安全问题。疲劳驾驶、超速超载、后视镜视野受限等因素使货车行驶时极易发生追尾及侧面碰撞事故。针对以上问题,本课题结合提升货车运输安全性的需求,设计开发了基于机器视觉的货车碰撞预警系统。主要研究内容如下:（1）图像增强方法研究与改进。预警系统基于单目视觉完成目标检测、测距及预警工作。首先针对基于CMOS传感器的单目相机在恶劣及低照度环境采集的图像质量差、对比度低的问题,分析了暗通道先验增强算法的原理并通过改进自适应修正透射率实现对图像的分区处理,减少失真和Halo现象,利用直方图均衡化算法去噪并增强动态范围偏小区域的对比度。改进算法适用于不同照度环境的图像增强,获得了更大的图像信息量、保留了更多图像特征细节;时效性上较原暗通道先验算法帧均处理时间减少了35%。（2）构建和优化基于SSD的目标检测模型。在图像预处理完成的基础上,分析并改进了SSD网络结构以实现对车辆、行人目标的高效检测。首先基于轻量化特征提取网络Mobile-Netv2替换SSD主干网络VGG16建立目标检测模型,然后融合特征增强模块和改进先验框筛除机制以优化模型检测能力、缩减计算规模,最后基于KITTI和PASCAL VOC搭建数据集、配置网络参数。改进算法缩减了计算量、提升了检测帧数;在KITTI测试集中,相较SSD模型、Mobile-Net+SSD模型,m AP值分别上升了2.13%与0.5%,证明了改进后模型在多环境场景检测中的精确度与泛化能力。（3）单目视觉成像和测距模型建立。在目标检测完成基础上,分析对比逆透视变换等单目测距模型,考虑到测距稳定性、精确性,选择基于相机参数标定方法建立单目测距模型。首先分析单目视觉成像模型,然后基于标定板计算摄像头内外参数并矫正图像畸变,在目标检测分类基础上建立了单目测距模型。最后基于KITTI数据集、Open CV加雾图像数据集、实地测距实验分析评价模型测距效果,利用决定系数R2、均方根误差RMSE等指标验证了测距模型的精准度和稳定性。（4）融合图像预处理、目标检测测距模型和预警策略以构建碰撞预警系统。基于Trucksim车辆动力学软件计算和仿真验证F590型货车的内轮差数据,然后针对单一预警策略易误报的问题,分析TTC相对碰撞时间、安全制动距离预警模型并提出融合预警策略,划分了车辆前向及侧向的分级预警区域。基于上述研究设计了基于单目视觉的货车碰撞预警系统,涵盖前向及侧向碰撞预警,利用pyqt5设计了碰撞预警系统软件。经实验验证,预警系统在侧向内轮差盲区和前向及右转弯碰撞预警实验分别获得90%及83.3%的预警准确率,并且在低照度环境下能实现高效稳定的预警。本研究设计的碰撞预警系统可以提高货车行驶的安全性,有效降低货车前向和侧向交通事故发生率,为运输安全提供保障。
{URL}: https://link.cnki.net/doi/10.27242/d.cnki.gnjlu.2023.000434
{DOI}: 10.27242/d.cnki.gnjlu.2023.000434
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于航拍视角的早期森林火灾识别研究
{Author}: 管志浩
{Tertiary Author}: 高德民
{Publisher}: 南京林业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 林火识别;目标检测;语义分割;计算机视觉;深度学习
{Abstract}: 近年来,全球气候变暖趋势越来越明显,由此引起的气候干旱和厄尔尼诺现象导致各地森林火灾频发。森林火灾具有突发性强、破坏范围广以及扑救难度大的特点,是一种严重威胁到人类生命财产和生态系统的自然灾害。若能及时发现早期森林火灾,防止火灾蔓延,对于减小扑救难度、降低损失至关重要。随着科学技术的进步,使用“深度学习+无人机”的林火识别方案成为了目前的发展趋势,但是也存在若干问题亟待解决,比如行业内缺乏高质量的航拍林火数据集、通用模型在林火识别上性能欠佳、下游任务单一化等。针对上述问题,本文旨在探究深度神经网络在航拍图像上的林火识别能力,并就以下若干方面展开了深入的研究:1)构建了一组高质量的航拍林火数据集现有的林火数据集缺乏航拍场景样本图像,并且普遍存在分辨率低、火灾面积大等诸多问题,对于早期航拍林火识别效果较差。针对这一问题,本文依托张家口市重点研发计划项目“科技冬奥专项——崇礼区森林智慧防火”(项目编号:201001D),使用无人机自采集构建了一组航拍视角下的早期林火图像。考虑到拍摄场景单一的问题,额外整合了网络开源林火数据集FLAME作为补充。整个构建过程包括了数据采样、数据预处理以及数据标注等步骤,以适应不同林火识别下游任务的需求。2)提出了一种新颖的林火目标检测模型AENet通用视觉模型直接应用于林火检测任务往往性能欠佳,主要原因是没有充分考虑航拍视角下火点的特点,比如面积偏小、位置隐蔽等;再者,航拍林火目标的边界框分布与通用数据集之间也有巨大差异。针对上述问题,本文参考了YOLO的设计思想,提出了一种单阶段的实时林火检测模型AENet。模型的主干部分采用了剪枝后的轻量化网络Conv Ne Xt,并在特征金字塔融合层引入了特征增强模块和注意力机制提升模型的表征能力,以此来实现检测精度与速度之间的平衡。此外,还采用了Mosaic数据增强、标签平滑以及Focal Loss等多种训练策略,进一步提升网络的检测精度。最后,通过大量对比实验来验证AENet的有效性。3)提出了一种新颖的林火语义分割模型MCCNet考虑到检测模型只能对粗粒度的林火个体进行识别而缺乏细粒度的表征能力,并且在一些极不显眼的火点目标上存在漏检的问题,本文提出了一种端到端的语义分割模型MCCNet。具体地,在编码器部分设计了一种多尺度上下文对比结构和密集金字塔模块,前者通过不同膨胀率的空洞可分离卷积构建局部差异特征,拉大前景与背景之间的差异,后者通过多尺度错位融合提升高阶语义的表征。此外,还设计了分类辅助模块,将图像的全局分类信息嵌入到有效特征层中进一步细化分割结果。最后,通过大量的对比实验和消融实验来验证MCCNet在复杂环境下分割小目标火点的有效性。4)设计了一种新颖的林火实例分割模型Mask SU R-CNN考虑到不同的林火识别任务需要通过设计不同的网络模型来完成。本文进一步设计兼具检测和分割功能的林火实例分割模型Mask SU R-CNN。具体地,采用U形结构的网络重构MS R-CNN的Mask Io U分支,以进一步提高林火实例分割的性能。再者,通过Mask Io U分支预测得到的掩膜交并比,用于评价分割置信度,以克服将分类置信度作为分割置信度的弊端。最后,通过实验对比来验证Mask SU R-CNN在航拍火点上的多任务识别能力。
{URL}: https://link.cnki.net/doi/10.27242/d.cnki.gnjlu.2023.000788
{DOI}: 10.27242/d.cnki.gnjlu.2023.000788
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的番茄叶部病害识别方法研究与应用
{Author}: 张东东
{Tertiary Author}: 许正荣;彭勇俊
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 番茄叶部病害;深度学习;卷积神经网络;图像识别
{Abstract}: 番茄作为我国传统的农作物之一,它的栽培面积和总产量都位居全球前列。然而,在生长过程中,番茄植株除了受到气象影响之外,还易遭受到多种病害的侵害。近年来,随着种植技术的进步,番茄遭受的病害种类越来越多,这些病害对番茄产量和果实品质都会产生影响,病害严重时甚至会因此造成番茄产量的大幅度降低和果实品质的劣质化,从而给种植户造成极大的经济损失。因此,在番茄遭受病害侵害后,既迅速又准确地识别出番茄所遭受的病害类型,对于番茄病害的防治,具有很重要的意义。自从深度学习等相关技术进一步的发展,其在图像识别方面的研究取得了较好的效果,因而得到研究人员的重视,在病害识别等领域被广泛使用。其中,深度卷积神经网络能够自动对病害图像进行特征提取,极大的提高了病害识别的准确率。为了对番茄病害识别过程中的难题进行研究,实现番茄病害的精准防治。本文在依据深度学习相关理论,通过改进常用的卷积神经网络对收集处理后的9种番茄叶片进行识别分类,其中包括番茄健康叶片、番茄早疫病、番茄叶霉病等。其主要研究内容如下:(1)构建番茄病害数据集。以Plant Village番茄数据为基础数据,对番茄叶部图像数据进行预处理,然后使用数据增强等技术扩充数据集。采用AlexNet、VGG16、Inception V3、ResNet50这四种经常见的卷积神经网络,然后在数据集中使用网络模型对数据集进行训练测试。依据实验结果,对四种卷积网络模型在番茄病害上的识别效果进行分析。(2)提出使用注意力机制和特征融合算法提升基础模型性能的方案。将SE、ECA和CBAM三种注意力模块嵌入模型中,引导模型关注图像中重要的病斑区域;使用特征融合的方法将不同类型的深度特征有效融合后的网络模型进行研究。实验结果表明改进后的实验模型识别效果相较于上述四种常见的卷积神经网络有了较高的提升。(3)番茄叶部病害识别系统的实现。为使病害识别结果具有可视化、可操作性,利用基于Python语言,设计了一种番茄叶部病害识别系统,该系统具有番茄病害检测识别功能,可以显示病害识别结果和相应的防治建议,除此之外,还包括病害症状和发病规律的番茄病害知识科普功能。其中,病害检测识别功能作为主要功能可以实现对番茄叶部病害图像的识别,并显示识别结果。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2023.000844
{DOI}: 10.26919/d.cnki.gannu.2023.000844
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的指针式仪表读数识别研究
{Author}: 陈浩
{Tertiary Author}: 孙顺远;王旭辉
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;卷积神经网络;图像处理;仪表读数识别
{Abstract}: 传统指针式仪表因其具有结构简单,生产成本低等优势,在工业生产过程中有着广泛的应用。然而,目前指针式仪表读数方式多为人工判读,效率低下。为解决人工判读的低效问题,仪表自动读数方法不断被提出,此类方法多基于机器视觉,效率和准确率相对于人工判读均有所提高,为指针式仪表出厂精度校准以及性能定期检测提供了可行的方案,有效推动了工厂的现代化改造。为进一步优化指针式仪表读数识别方法,论文提出了基于机器视觉的指针式仪表自动读数方案,其中包括仪表目标检测、倾斜校正、量程识别、示数读取、分度值检测以及在此基础上的读数识别系统软硬件实现。课题的研究内容主要分为以下几个部分:(1)针对指针式仪表目标检测方法易受环境干扰的问题,提出一种基于旋转目标检测网络的目标检测方法。该方法在水平目标检测网络YOLOv5s的基础上做出改进,将网络改建为更适合指针式仪表的旋转目标检测网络,同时分别从角度回归、小目标检测、损失函数三个方面入手,提升网络性能。经测试分析,相较于传统目标检测方法以及水平目标检测网络,该方法在检测效果和检测速度上均有一定优势。(2)针对目前指针式仪表倾斜校正方法泛化能力不强的问题,对倾斜校正方法做出改进。充分利用旋转目标检测网络输出信息,对存在倾斜的仪表进行旋转校正和形变校正。同时,针对目前指针式仪表读数识别方法中,往往需要将量程作为先验知识,手动输入的问题,提出了基于改进Res Net18分类网络的指针式仪表量程识别方法。真正做到指针式仪表读数的自动识别,进一步减少人工的参与。(3)针对读数识别系统的实际需求,规划识别流程、分析系统架构。从硬件和软件两个方面,设计系统相应的硬件结构和软件框架,实现了不同功能模块的软件设计。最后将指针式仪表读数识别方法应用到硬件系统中,实现了指针式仪表的图片检测与视频检测。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.000850
{DOI}: 10.27169/d.cnki.gwqgu.2023.000850
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的PCB异型插装元件AOI检测系统
{Author}: 孙成路
{Tertiary Author}: 张法全
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: PCB;自动光学检测;模板匹配;尺度不变的特征提取;仿射变换
{Abstract}: 随着封装尺寸的减小和安装密度的增加,PCB(Printed Circuit Board)异型元件的检测变得更加复杂。人工检测不但耗费大量人工成本,而且存在漏检或误检的问题。自动光学检测设备高效、准确、可靠,能有效提升产品质量,降低生产成本。论文以PCB异型插装元件为研究对象,开发了一套基于机器视觉的AOI(Auto Optical Inspection)检测系统,能够实现PCB异型插装元件的识别、定位及缺陷检测等目标。介绍了国内外PCB检测系统和基于机器视觉的PCB缺陷检测技术的研究现状,设计了基于机器视觉的PCB异型插装元件AOI检测方案,对系统的相机、镜头、光源等硬件设备进行了选型,设计了硬件系统,开发了相应的软件。PCB上料时会出现偏移和旋转,采集的图像需要进行矫正与配准,论文提出了基于尺度不变的特征提取算法,并结合仿射变换实现MARK点精确定位。针对异型插装元件识别与定位问题,本文提出了基于组合特征的目标识别算法和基于形状的改进模板匹配算法。对感兴趣区域进行组合特征选择,采用最小外接矩形的方法来将每个感兴趣区域分别生成单独的矩形区域,再进行模板匹配。常规基于形状的模板匹配算法归一化计算量很大,耗时较长,论文对常规算法进行了改进,采用快速傅里叶算法进行归一化处理,运算效率明显提升。针对异型插装元件的缺陷检测,本文根据异型插装元件的特征,对缺件、极性反转等缺陷分别创建ROI,进一步创建特征模板,然后组合多个特征模板进行缺陷检测。基于上述算法,论文设计了一套基于机器视觉的PCB异型插装元件的AOI检测系统,并进行了实验测试。实验结果表明,MARK点中心坐标定位误差在0.3mm以内,对PCB上六类异型插装元件的识别率达到95%,缺陷检测准确率达到96%。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2023.000285
{DOI}: 10.27698/d.cnki.gwhxj.2023.000285
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体骨骼点信息的坐姿识别技术及应用
{Author}: 冯吉生
{Tertiary Author}: 郭莉
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 坐姿检测;人体姿态估计;骨骼关键点;AlphaPose;集成学习
{Abstract}: 在现代社会中,人们面临的工作、学习压力不断增大,经常会长时间保持不良的坐姿,容易引发各种健康问题。在此背景下,人体坐姿识别成为备受人们关注的热门研究领域。本文以探究如何准确识别人体坐姿,并使用坐姿监测软件对不良坐姿进行纠正为目的,旨在能为人体坐姿识别领域的相关研究提供一些参考和启发,主要工作及创新点包括:第一,邀请56位志愿者,采集了9类坐姿动作的图像。经筛选过滤,舍弃部分不合格图像,保留6913张组成人体坐姿图像数据集。然后根据不同坐姿的特点,依托特征工程构建了包含有30维特征的人体坐姿骨骼点特征数据集,为后续坐姿识别算法的研究提供了坚实的数据基础。第二,构建了一个用于识别人体坐姿的多模态融合神经网络模型。在该模型中,设计了两类网络分支来同时处理图像类型数据与数值类型数据,并将这两类分支的输出特征进行拼接融合,送入分类器中得到最终的坐姿识别结果。实验结果表明,该多模态融合模型对9种坐姿的识别准确率达到93.85%,比单一类型数据输入的模型取得了更好的效果。第三,提出了一种基于人体骨骼点检测算法Alpha Pose和集成学习Stacking策略的人体坐姿识别模型。该模型通过对视频流间隔抽帧,并使用Alpha Pose算法快速处理所抽取的图像,得到图像中的人体骨骼点坐标信息;然后依据不同坐姿的特点,使用骨骼点坐标信息构建30维的特征向量;最后使用Stacking融合模型实现对坐姿的准确识别。测试结果表明,该模型对9种坐姿的平均识别率达到98.55%,并且实施成本较低,具备较高的应用价值。第四,设计并实现了一款基于Windows平台的坐姿监测软件,在坐姿识别算法的基础上,加入了多种实用功能,例如坐姿图像显示、不良坐姿提醒、自定义坐姿校准以及对坐姿数据的进一步统计分析等。通过实际应用测试,验证了本款软件的有效性和可靠性,可以为用户提供更全面的坐姿监测服务。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2023.001865
{DOI}: 10.27262/d.cnki.gqdau.2023.001865
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 现代养殖场中基于深度学习的影像中动物检测与多目标跟踪
{Author}: 范方舟
{Tertiary Author}: 贺志强
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;动物检测;行为识别;多目标跟踪
{Abstract}: 随着人们对于肉类的需求迅速增长,畜牧业养殖者需要利用有限的土地更高效地养殖更多的牲畜。在数字化养殖方向上,利用影像可以对养殖场中动物的进行各类信息的提取以帮助养殖者提升养殖效率。其中基于影像的动物检测与跟踪成为了研究者的研究重点。在动物检测方面,本文提出使用无锚点架构的检测网络CenterNet进行养殖场影像中的动物检测,并利用该网络获取动物位置的天然优势以辅助动物的行为识别。该架构可以基于动物影像的语义特征直接提取出动物的位置与大小,在动物大小,体态及数量都差异较大的养殖场景中相较于需手动设置锚点的架构鲁棒性更高。通过在养殖场景中的消融对比试验,本文证明了 CenterNet可以更好地平衡检测速度与检测精度之间的关系。检测结果相较于基于锚点的检测架构的网络更贴合动物的实际位置与大小,其获取的动物位置也能有效利用养殖场监控视频背景中的相关先验信息提升动物行为识别的精度。在养殖场的跟踪任务中,本文考虑到同一动物的位置和外观在连续帧间具有的相似性,同时与其他动物又有一定差异的特点,提出了利用动物检测结果,以动物位置和外观语义特征作为相似度判别标准的多目标跟踪方案。并在此基础之上进一步设计出中心点预测模块以利用动物在视频中位置的连续性辅助检测与跟踪。该方案通过对连续帧进行动物检测以减小动物轨迹的建模难度,相比于传统的直接对动物的运动轨迹进行建模的多目标跟踪方案,在真实养殖场景中鲁棒性更高。同时在多个养殖场景数据集中的消融实验证明,中心点预测模块能够有效地提升许多同类动物出现在同一场景中的检测与跟踪精度。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000083
{DOI}: 10.26969/d.cnki.gbydu.2023.000083
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习技术的增强现实手势识别研究
{Author}: 李乐意
{Tertiary Author}: 侯文军
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手势识别;人机交互;计算机视觉;深度学习;语义分割;手部姿态识别;注意力机制;特征恢复;迁移学习
{Abstract}: 随着人们对人机交互体验的要求日益提高与计算机技术的发展,手势交互成为新一代热门人机交互方式。手势识别是手势交互技术中关键的组成部分,手势识别能通过识别用户特定的手势图像解析出用户给计算机传递的指令信息,能大幅提升用户体验与交互效率。在增强现实等新兴交互场景下,基于视觉的手势识别技术是热门研究方向。手势识别的识别精度已经达到了较高的水平。现有的基于视觉的手势识别方法多为研究理想输入下的手势图像识别,而在增强现实交互场景下,由于交互场景复杂多变、相机捕捉范围有限、交互手势迭代频繁、用户手部残障或手持物品等原因,分析总结出增强现实下的手势识别容易受到“弱信息条件”的影响,现有手势识别算法都面临着相应的问题,使得识别准确率下降,进而导致手势设计受限,用户体验不佳,甚至严重的安全问题。复杂场景下的手势识别、存在局部遮挡的手势识别,以及手势图像训练数据有限等情况下都会面临上述的问题。针对增强现实中出现的这些问题,提出了改进的手势识别方法。主要的研究内容有以下三个方面:(1)针对复杂场景下难以有效提取手势图像整体语义信息的问题,提出了一种基于多模态特征融合的手势识别算法。引入语义分割以及手部关键点识别的方法提取手势图像特征,基于注意力机制融合上述多模态特征识别手势,改善复杂场景下手势识别的准确率。(2)针对手势图像存在局部遮挡时,关键区域存在信息丢失的问题,提出了一种于特征恢复的局部遮挡手势识别算法。构造特征恢复网络,在不同位置添加相应的正则项约束并作训练,提高了局部遮挡场景下的手势识别准确率与鲁棒性。(3)针对手势识别场景丰富多变,而收集处理新数据集成本高昂的问题,提出了一种基于迁移学习的有限样本手势识别算法。引入迁移学习的思想,使得大样本模型与小样本模型在训练中相互引导,强化大样本模型的特征提取能力,同时强化小样本模型的特征提取能力,提升小样本数据集上训练模型的准确率。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.003160
{DOI}: 10.26969/d.cnki.gbydu.2023.003160
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于智慧养老的摔倒检测算法研究与实现
{Author}: 高知巍
{Tertiary Author}: 张宁波
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 摔倒检测;神经网络;传感器;多模态融合
{Abstract}: 近年来,中国的人口老龄化和空巢问题越来越严重,独居老人经常处于无人看护的情况。根据数据显示,摔倒已经成为我国65岁以上老年人因伤致死的首位原因,对老人实施实时的摔倒检测已经成为重要的安全保障和社会需要。随着计算机视觉技术、传感器技术和深度学习等人工智能算法的发展,摔倒检测已成为智慧养老的研究热点。当前用户的摔倒检测算法主要是基于计算机视觉和基于可穿戴传感器来实现。其中,基于计算机视觉的摔倒检测算法是通过摄像头来获取视频信息作为数据的输入,这样存在诸多问题,比如会受到复杂背景或者遮挡物的限制而影响识别准确率、单模态检测鲁棒性较差和复杂度较高等问题。针对单模态鲁棒性差的问题,本论文通过可穿戴传感器来获取另一模态的数据,通过摔倒检测模型提取对应的特征信息,最终与视频信息进行多模态融合,提高了鲁棒性。但是,基于可穿戴传感器的摔倒检测算法仍存在诸多问题,比如特征提取不全面且没有考虑到不同通道特征信息的重要程度、摔倒检测算法复杂度较高以及准确率不高等问题。针对现有研究的不足,本论文进行了以下几个方面的研究:(1)针对计算机视觉中摔倒检测算法准确率不高和复杂度较高的问题,提出了基于特征金字塔和卷积块注意力机制网络(Feature Pyramids and CBAM Networks,FPCN)摔倒检测模型。该模型由目标检测模块和人体姿态估计模块组成,目标检测模块能对数据进行预处理和摔倒预判断,降低了模型的复杂度。同时,在该模块中加入了卷积块注意力模块(Convolutional Block Attention Module,CBAM),能同时关注通道和空间两个不同维度中的有效信息从而提高识别准确度。通过了目标检测摔倒预判断的人体检测框会被裁剪出来送入到人体姿态估计模块中,后续进行关键点的标注和摔倒检测,降低了模型的时间复杂度,提高了实时性。(2)针对单模态鲁棒性较差的问题,本文选择传感器数据来进行第二模态的摔倒检测,传感器数据的来源是可穿戴传感器。基于可穿戴传感器的摔倒检测算法在提取特征时不全面且复杂度高,因此,本文在DeepConvLSTM的基础上进行改进,提出了一种基于挤压激励网络和张量分解的摔倒检测网络(Squeeze-and-Excitation and Tensor-Train Decomposition Networks,STDN)模型。该模型利用卷积神经网络(Convolutional Neural Networks,CNN)和长短期记忆神经网络(Long Short Term Memory Networks,LSTM))分别提取时间维度和空间维度的特征,并且将两个维度特征进行融合。在该模型中加入了挤压激励模块(Squeeze and Excitation,SE),能对特征进行重标定,弱化无关特征,强化重要特征从而提高识别准确度。同时,本文利用张量分解来优化整个模型的参数量和计算量以提高实时性。(3)针对两个模态融合的问题,采用了一种决策层融合的策略来进行摔倒检测,将上述的基于计算机视觉的FPCN模型和基于可穿戴传感器的STDN模型在分类层进行融合,通过加权求和的方法输出结果,最终准确度得到提升。(4)在公开数据集UR Fall Detection Dataset(URFD)和自定义数据上验证了上述所有模型,通过全面的实验证明了模型的有效性。实验结果表明,基于计算机视觉的摔倒检测模型FPCN通过目标检测能有效提取人物检测框并进行预判断,减轻了系统的计算量,并且能够高效地完成摔倒检测。基于可穿戴传感器的摔倒检测模型STDN通过加入SE网络可以有效地提高摔倒检测的准确度,同时使用张量分解降低了整个模型的参数总量和计算量,有效地降低模型的复杂度。多模态融合的摔倒检测进一步提高了识别的准确度,证明了多模态融合的有效性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.001281
{DOI}: 10.26969/d.cnki.gbydu.2023.001281
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的足球比赛视频目标检测与跟踪研究
{Author}: 亓淼
{Tertiary Author}: 郑凯东
{Publisher}: 西安石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;目标跟踪;足球视频
{Abstract}: 足球是世界第一大运动,对足球比赛视频中的目标进行检测与跟踪,具有重要的实用和商业价值。近些年深度学习技术被广泛用于计算机视觉任务,取得了巨大成功。因此,本文基于深度学习技术,分析当前目标检测与跟踪中的难点,进行针对性的模型改进,提高模型的检测和跟踪性能。本文的主要工作如下:(1)针对足球视频目标检测中存在检测速率慢,目标遮挡、体积小影响检测精度等问题,本文改进YOLOv5检测算法,首先精简骨干网络,使模型的参数量减少了50%。其次融合多尺度特征,降低了模型对小目标的漏检率;最后将注意力机制嵌入网络结构,提升了模型整体的检测精度。在数据集上验证,本文改进的YOLOv5检测速度提升了17%,精度提升了3%。(2)针对足球视频中球员目标运动速度快、运动轨迹不规律的问题,本文在DeepSORT算法的基础上,引入无迹卡尔曼滤波算法和DIoU匹配,增强了模型对非线性运动目标的跟踪能力。在数据集上验证,本文改进的DeepSORT算法跟踪性较原始算法具有提升。(3)在目标检测的基础上,本文进行了视频分析下游任务球员队类判别的实验。通过提取检测出的球员颜色特征,分别使用相似性度量和聚类算法进行球员队类判别。实验结果表明,使用聚类的算法达到了97%的判别精度。
{URL}: https://link.cnki.net/doi/10.27400/d.cnki.gxasc.2023.000954
{DOI}: 10.27400/d.cnki.gxasc.2023.000954
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的岩石裂隙动态识别方法研究
{Author}: 邵立昂
{Tertiary Author}: 姚池;姜清辉
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 卷积神经网络;TransUNet;多源岩石裂隙数据集;裂隙动态识别;面积计算
{Abstract}: 如今随着深度学习的兴起,利用计算机视觉进行图像处理解决相关问题已经成为国内外各种领域专家的关注热点。深度学习与土木工程相结合逐渐成为未来研究的热点方向之一。本文通过建立多源岩石裂隙数据集,结合岩石裂隙图像特征对经典卷积神经网络进行改进,实现了岩石裂隙的动态识别,并根据识别结果进行裂隙的面积自动计算,主要研究内容如下:(1)对深度学习与卷积神经网络的相关理论与研究现状进行简要综述,为后续研究提供理论支撑。详细概述了卷积神经网络各组成部分,并分别介绍其作用与意义;介绍与对比了几种常用的深度学习框架,根据其特点结合本文研究需求选取了Tensorflow作为本文研究所使用的深度学习框架。(2)基于岩石裂隙图像特征改进U-net结构,将U-net与Vision Transformer算法结合得到Trans UNet算法,分析其针对岩石裂隙分割的适用性与不足,通过添加注意力机制、优化Vi T算法编码结构、优化解码器的卷积层,从而得到适用于岩石裂隙图像分割的改进Trans UNet算法。针对现有岩石裂隙缺少公开数据集的问题,通过整理网络收集的岩石裂隙CT图像、拍摄实验室制备的花岗岩试块裂隙图像以及基于无人机航拍的自然山体岩石裂隙图像,运用数据增强方法对其进行扩充,使用labelme对其进行精细标注,从而得到后续模型训练所需的多源岩石裂隙数据集。(3)搭建实验环境,安装所需的库与框架,输入建立后的数据集并调整训练参数,得到基于改进Trans UNet算法与岩石裂隙识别的语义分割模型,利用相关评价指标将该模型的性能与5种具有代表性的语义分割算法的性能进行对比,证明该模型的优越性。同时选取了两种不在数据集范围的其他种类的裂隙图像来验证该模型的泛化能力。通过拍摄花岗岩标准试样单轴压缩试验的破坏过程,得到其破坏过程的视频文件,然后利用Open CV库编写程序来对其破坏过程的视频进行识别,从而实现动态识别,并根据像素统计原理对岩石裂隙图像与动态视频中的裂隙区域面积进行自动计算,实时显示当前裂隙的面积值与裂隙率。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2023.001709
{DOI}: 10.27232/d.cnki.gnchu.2023.001709
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的玉米种子检测分选系统设计
{Author}: 王发
{Tertiary Author}: 索雪松
{Publisher}: 河北农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 种子质量;分选系统;自动化;玉米;图像识别;YOLOv5
{Abstract}: 我国是农业大国,作物种子作为农业根基,其质量好坏直接或者间接影响到农作物产量,所以种子质量的检测分选对保障国家和农民的经济利益具有重大意义。传统的机械分选装置对虫蚀、病斑、破损等坏粒分选效果较差,原有的好种也容易造成损伤。还有地区人工在分选作物种子,其费时费力、长时间分选带来的视觉疲劳和主观偏差也难以避免。机器视觉应用种子分选方面,色选机、光学分拣机等设备提高了分选质量,但价格昂贵,制造出总体上价格低廉、快速、无损、准确的检测装置还需进一步研究。种子检测装置设计与种粒品种检测方法研究是提高种子分选技术的关键。根据上面原因,针对分选玉米种子,本文搭建了一种基于机器视觉的玉米种子检测分选系统,并设计一个有效的深度学习检测模型。主要研究内容如下:(1)根据种子检测分选需求设计并研发了一个玉米种子检测分选系统,依据系统工作原理和工作流程,完成了系统总体设计与落种、传动、图像采集和分选等各机构的部件选型、设计。(2)按照图像获取要求与系统分选方法完成系统控制部分的设计,主要包括传动机构的变速控制设计、图像采集机构的同步相机采集速率设计和图像采集软件设计、分选机构的PLC接线方式和控制程序设计等。(3)选取国审玉米种郑单958作为模型实验用种,对种子图像进行滤波和增强图像对比度等预处理方法提高图像质量。选用YOLOv5系列网络作为种子检测模型。利用制作好的数据集训练YOLOv5-s深度学习网络模型并进行模型结果测试,结果表明YOLOv5网络对好玉米种子检测的AP值达到96.66%,F1值为89.6%,对坏玉米种子检测的AP值达到92.35%,F1值为86.2%,得出mAP值为95%,平均F1值为87.9%,平均每检测一幅图像耗时约0.27秒,检测单粒种子耗时0.027秒。对模型训练结果进行性能分析,并利用相同的实验方法对YOLOv5-m、YOLOv5-1、YOLOv5-x三种模型进行训练,获取检测模型的性能指数。通过对比几种模型的性能指数,选取YOLOv5-s作为种子分选系统的目标检测模型。本课题研究为玉米种子分选实现系统化、自动化提供了方法支撑,克服人工分选费时费力和机械分拣造成种子损伤等缺点,对实现种子快速、精准、无损分选具有必要的参考。
{URL}: https://link.cnki.net/doi/10.27109/d.cnki.ghbnu.2023.000353
{DOI}: 10.27109/d.cnki.ghbnu.2023.000353
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的元器件视觉识别和定位技术
{Author}: 雷文桐;顾寄南;胡君杰;高伟
{Author Address}: 江苏大学机械工程学院;
{Journal}: 电子测量技术
{Year}: 2023
{Volume}: 46
{Issue}: 08
{Pages}: 65-73
{Keywords}: 目标检测;智能装配;电子元器件;机器视觉;深度学习
{Abstract}: 为解决当前装配机器人视觉系统对元器件误检率高、效率低、难获取有效定位信息的问题，提出了一种基于深度学习的元器件视觉识别和定位方法。首先，设计基于深度聚合和解耦头的高精度检测算法，提高元器件识别和主体检测的精度；其次，设计标注和判定规则，细化定位主体轮廓和抓取点；最后，设计基于网络剪枝的轻量化检测算法，实现模型压缩，提高引脚检测和装配点定位的效率。研究结果表明：该方法在元器件的识别和定位上取得了较好表现，类别识别平均错误率仅为0.27%,计算量减少了29.8%,参数量减少了22.7%,并将传统的元器件轮廓检测扩展到抓取点和装配点定位，得到丰富的类别和位置指引信息，为工业机器人精准、可靠、稳定地抓取和装配做好基础。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2211947
{DOI}: 10.19651/j.cnki.emt.2211947
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和特征融合的叶片图像识别方法研究
{Author}: 周钢强
{Tertiary Author}: 王斌
{Publisher}: 南京财经大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 叶片图像识别;深度学习;特征融合;知识蒸馏;正交融合
{Abstract}: 叶片图像模式分析是计算机视觉的一个重要的应用研究问题,在植物分类、作物表型、环境生态等研究领域扮演者重要的角色。由于植物种类(species)繁多,新的植物种类不断被发现,许多不同种类的的叶片视觉模式的高度相似性和同种类叶片的自然变形的问题使得叶片图像模式的识别问题仍然具有非常大的挑战性。特别是近些年来,随着作物栽培技术的飞速发展,对同一种作物下的细粒度的品种(cultivar)识别,这一个更具挑战性的模式识别问题,需要高性能的识别算法,以满足精准农业的实际应用需求。为解决叶片图像的粗粒度的种类识别和细粒度的品种识别问题,本文聚焦于基于深度学习和特征融合的叶片图像分析方法研究。图像的手工特征能描述图像底层的视觉信息、不依赖于训练数据、且具有可解释性,而深度特征虽然依赖于训练数据,可解释性差,但能有效获取图像抽象语义特征信息,能端对端的完成图像分类任务。鉴于手工特征与深度特征的强的互补性,近年来,融合这两类特征的研究工作受到研究者们的关注,但所提出的融合方法大多存在模型参数多、无法端对端、泛化能力差等缺点。本文提出了一种通过知识蒸馏方式融入手工特征信息的深度网络:HDFF,来解决叶片图像的粗粒度识别问题。该网络既充分发挥手工特征对深度特征的互补性,又在模型部署时只保留独立的深度网络结构,能完成端对端的预测任务,不需要携带和执行手工特征提取器,从而节省了参数,提升了预测速度。HDFF模型由有深度特征分类网络和手工特征分类网络两个部分组成,在深度网络与类标信息训练的前向过程中,将深度网络的特征拷贝,动态嵌入到手工特征网络中(该过程相当于知识从深度网络流向手工网络),让融合后的特征训练分类器,再将其预测概率向量以知识蒸馏的方式与深度网络预测概率形成动态相互学习过程(该过程相当于知识在两个网络的双向流动)。本文选用了Res Net50和Dense Net121作为深度骨干网络,将叶片形状方法Ho GCV、叶片纹理方法PRICo LBP的特征作为手工特征方法。HDFF模型在Leaf220和MEW2012数据集上分别取得了96.3%和83.2%的准确率,比未融合之前基线模型分别提高了2.4%和2.0%,证明了手工特征和深度特征存在互补性,HDFF融合方法可以提升叶片识别的准确率,也为今后手工特征和深度特征的融合研究工作,拓展了一个新的思路。针对细粒度识别任务,用植株的单个部位的叶片进行识别,很难获得满意的识别效果,本文发展了现有的融合植株上、中、下三个部位的叶片特征,以提升品种识别准确率的方法,提出了一种基于对比学习的三联体图像的深度特征融合网络:CLFF。对植物叶片进行细粒度的品种识别由于类间差异小带来分类难度极大,加之数据的标注成本带来的训练样本较少的问题,使得该任务极具挑战性。本文提出由大豆植株的上、中、下三个部位叶片组成的三联体叶片图像的深度学习特征联合训练,计算三联体图像的共信息特征,再和各子图的差异化特征进行正交融合,并使用对比学习方法,使得网络在优化过程中,避免陷入局部最优解,从增强了模型的泛化能力。CLFF模型不仅在大豆品种识别数据库Soy Cultivar200上取得了远高于现有方法的92.6%的准确率,还缓解了由于数据集过少可能带来的过拟合问题,再次验证了多部位叶片互补性信息用于细粒度品种识别的有效性。CLFF模型相较于先前的多部位特征融合方法,第一、取得了更好的分类表现,第二、模型具有端对端的优势,第三、拥有更好的鲁棒性和泛化能力。
{URL}: https://link.cnki.net/doi/10.27705/d.cnki.gnjcj.2023.000359
{DOI}: 10.27705/d.cnki.gnjcj.2023.000359
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的藏式古建筑石砌体壁画墙裂缝生长变形监测
{Author}: 杨娜;王烁;汪德佳
{Author Address}: 北京交通大学土木建筑工程学院;
{Journal}: 工程力学
{Year}: 2025
{Volume}: 42
{Issue}: 01
{Pages}: 129-142
{Keywords}: 藏式古建筑壁画墙;裂缝;阈值分割算法;神经网络模型;特征参数
{Abstract}: 对单一背景下裂缝的定期检测研究已取得一定成果，但对复杂背景下裂缝预防性长期生长变形监测的研究尚处于起步阶段。该文综合古建筑壁画墙变形微量和不宜扰动的特点，基于计算机视觉研究了传统图像分割处理技术和裂缝图像智能语义分割神经网络模型，建立了一套非接触式、预防性生长变形监测系统。为降低壁画墙裂缝特有的彩绘壁画、环境光照及噪声等干扰，有效地将裂缝从复杂背景中分离出来，在传统阈值分割算法系统中，通过SIFT特征匹配和单应性矩阵的求解，解决图像视角差异问题，通过对比不同滤波算法，选择更适用于壁画墙裂缝分割的双边滤波算法与阈值分割相结合的监测算法；在智能语义分割系统中，采用多层卷积、采样和拼接等操作，去除多余特征，重构裂缝高级语义特征图，选择多步优化策略改进原U-Net模型网络架构，提升模型测试平均准确率至0.9899。监测12天典型藏式古建筑石砌体壁画墙裂缝，提取裂缝轮廓及裂缝骨架线等相关特征参数作为关键指标定量描述裂缝生长变化信息，发现：传统阈值分割算法二维特征指标(如裂缝面积、密度、宽度)的变异系数COV值处于4.50%～6.52%，改进的U-Net模型将传统方案中数据波动最大的裂缝面积COV由6.52%降至3.53%，提高了监测系统对壁画色彩、光照和阴影干扰的鲁棒性；系统中两类算法分别处理了不同视角下的同一裂缝的12张图像，输出的数据具备均匀一致性，COV不超过7%，证明了该监测系统为壁画墙裂缝的生长变形提供实时无损监测的技术可行性。
{ISBN/ISSN}: 1000-4750
{Notes}: 11-2595/O3
{URL}: https://link.cnki.net/urlid/11.2595.O3.20250102.1649.034
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的多模态图像融合算法研究
{Author}: 王梓萱
{Tertiary Author}: 孙彬
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多模态图像融合;深度学习;Transformer;ViT;双线性模型
{Abstract}: 多模态图像是不同传感器对同一场景采集到的图像数据,它们表达着不同的内容。多模态图像融合的意义在于将包含着不同模态信息的源图像做模态配准、表征与融合等工作,并得到一幅信息量更为丰富的融合图像。本文的研究对象主要聚焦在红外与可见光图像,通过深度学习模型来构建可用于多模态图像融合任务的网络。首先本文将深度学习模型分类为显式模型与隐式模型,并分析不同发展阶段分别面临的问题与对应的优化方案。其次对多模态融合网络的搭建过程展开分析,该任务最主要的待解决问题是如何多尺度地提取并保留单模态图像的特征,如何设计融合策略以减少多模态图像特征差异性对融合结果的影响,以及如何确认适用于特定任务和算法的训练数据等。基于对以上问题的分析,本文提出一种基于Transformer的交叉模态融合算法,设计CNN与Transformer串联结构的特征编码器来保留图像的局部和全局特征,设计跨模态注意力融合网络来交互并融合两个模态特征,设计神经网络解码器来重构融合图像。本文将所提出模型与五种深度学习算法对比。客观指标数据显示本文提出的模型在MI、SSIM和QCV指标上效果显著,其中在MI指标上达到最优,模型在纹理细节和全局信息的保留上有着良好的表现。但是在AG、EI等指标上有待提升。在以上模型的基础上,本文对网络进行优化并提出一种基于双线性模型的跨模态融合模型,设计CNN与Transformer并行的编码网络结构和一种二阶段融合策略。本文引入双线性注意力融合策略对多模态源图像的局部特征和全局特征做交互性融合,得到两个一阶融合特征。将此结果与两个模态的全局特征分别同时输入跨模态注意力融合网络并得到二阶融合结果。最后在通道维度拼接得到最终融合特征,并输入到解码器网络中重构融合图像。本文提出的模型与八种前沿深度学习算法对比,实验结果显示本文模型在MI、QAB/F和QCV等指标上获得了最优的效果,说明在纹理细节和信息量的保留上取得良好的结果。最后本文对深度学习模型在此研究方向上的待解决问题提出优化建议,并对多模态图像融合领域的应用前景提出展望。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.002404
{DOI}: 10.27005/d.cnki.gdzku.2023.002404
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的行人重识别方法研究
{Author}: 杨寒
{Tertiary Author}: 冯好娣
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 行人重识别;Transformer;图神经网络;注意力机制;可变形Transformer
{Abstract}: 行人重识别(Person Re-Identification,简称ReID)是指给定一目标行人,在不同场景中的摄像头所拍摄到的行人图像中检索到该目标行人的技术,通常被认为是图像检索领域的一个子问题。行人重识别技术可以被应用于智能安防、智能商超、相册聚类、人机交互等多个领域,具有切实的研究和应用价值。光线变化、行人姿态多变、拍摄角度不同、遮挡、摄像头分辨率低等问题,使行人重识别成为了一项非常具有挑战性的任务。大多数现有的ReID研究都将注意力放在了如何提取更能鉴别行人身份的特征表达上,而忽略了多张行人图像之间潜在的关系。单张图像容易因为遮挡、模糊等现象而丢失部分信息,而行人重识别数据集中通常会包含同一个行人的多张图像,单张图像缺失的信息有望从其他图像中得到补充。因此,构建多张行人图像之间的联系对于提升算法识别准确率或许是有效的。本文正是从这一角度出发,设计了自适应图注意力模型和基于可变形Transformer的ReID模型,分别利用图注意力网络和基于采样点的注意力机制来构建多张图像之间的关系,从而获取更具有鉴别力的行人特征表达。大量实验表明,本文所提出的两种模型能够有效融合多张行人图像特征,提升行人重识别算法的识别准确率。本文的主要研究内容如下:1.本文提出了一种基于自适应图注意力网络的ReID模型。将一批次输入的行人图像特征作为图的顶点,依据顶点之间的相似度关系自适应地确定图的边集,构建图神经网络结构;并在此基础上,设计了两种图注意力机制,并分别添加到图模型中,构建完整的自适应图注意力模型。实验表明,该模型能够有效聚合多张行人图像特征,提高行人特征的鉴别力。2.鉴于局部特征方法对于行人重识别任务的有效性,本文提出了一种基于Trans-former 结构的双分支注意力机制模型,包括全局和局部两个分支。其中,全局分支用于提取行人单张图像的全局特征表示;局部分支中设计加入了一种掩码交叉注意力机制,用于提取单张行人图像的若干局部特征。为了使局部特征在保证鉴别力的同时,尽可能关注行人图像的不同区域,本文又引入了局部损失,对模型进行约束。3.本文在双分支注意力模型的基础上,又设计了一种可变形的Transformer结构。在该结构中,采用本文所提出的基于采样点的多头自注意力机制,能够高效地融合多张行人图像的全局与局部特征,从而获取更有鉴别力的行人特征表示。4.本文在DukeMTMC-ReID等几个大型公开的行人重识别数据集上进行了大量的消融对比实验,实验结果充分说明了本文所提出的算法的有效性和先进性。同目前我们已知的一些最先进的行人重识别算法相比,本文所提出的模型获得了较为出色的表现效果。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.001259
{DOI}: 10.27272/d.cnki.gshdu.2023.001259
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的电路图纸智能识别技术研究
{Author}: 薛程伟
{Tertiary Author}: 贾建芳;刘璇
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 电路图纸;智能识别;目标检测;计算机视觉;卷积神经网络
{Abstract}: 随着各种工业制图软件的大规模普及,电网企业已经积累了大量的电路工程图纸。但是大量电路工程图纸也造成了数据处理方面的困难,特别是电网图纸数据的一致性、准确性和及时性等问题。因此,实现电力图纸的数字化和信息化,方便电网工作人员在使用过程中进行图纸的检索和提取就成为迫切需要攻克的技术难关。为了解决这些问题,本文详细分析了电力图纸的成像特点和固定规律,总结了图纸识别的影响因素。在此基础上,采用基于卷积神经网络的检测和识别框架对图纸进行准确识别,提高了电力图纸识别算法性能。本文的主要研究工作如下:(1)建立用于电路图纸识别的专用数据集。针对电路图纸数据匮乏,图纸识别任务难以开展学习的问题,首先搜集来源于厂站的真实数据,其次对数据进行筛选,保证数据的丰富度,然后采取人工标注的手段对数据进行标注,完成高质量的电路图纸数据集构建,为后续开展文字识别和图元识别任务奠定基础。(2)提出基于全卷积单阶段目标检测算法(Fully Convolutional One-Stage,FCOS)的深度学习光学字符识别(Optical Character Recognition,OCR)方法。针对电路图纸中存在的文字标注,将深度学习与OCR技术进行结合,采用目标检测的经典无需锚框(anchor-free)算法FCOS,对数据预处理和扩增后的电力图纸进行文字识别,从而替换传统的手动方法,准确判断电力图纸中文本的类别及位置信息,并根据相应位置文本信息自动识别文本内容。(3)提出基于YOLOv5算法的电路图纸图元识别技术。结合前述工作,使用训练好OCR模型将电力图纸中的文本标签数据提取出来,使图纸仅保留设备和电路信息。同时本文对YOLOv5模型进行改进,保留YOLOv5识别模型速度快,效果好等特点。针对电力图纸尺寸不一致,统一缩小图纸会导致部分设备识别失败的问题,采取滑动窗口切分方案,将一张图纸切分成多张图片进行训练,得到结果后再进行合并。实验结果表明,本文算法能够有效提高设备识别的准确率,实现对电力图纸中小型目标的设备专有化检测。(4)基于前述工作实现电路图纸识别系统。对涉及到的算法模块进行编程整合并设计出一套符合电站实际应用的识别流程架构,完成整个系统搭建与实现。经过实验测试结果分析可知,本文采用的算法以及设计的系统能够有效满足电站实际工作需求,达到预期目标,从而应用到电力系统中提高图纸数字化效率。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000861
{DOI}: 10.27470/d.cnki.ghbgc.2023.000861
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于目标检测的智慧教室视频分析系统研发
{Author}: 孟祥晴
{Tertiary Author}: 赵永健;贺红
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;目标检测;智慧教室;课程视频分析系统;教学评价
{Abstract}: 教育的现代化和信息化是中国教育发展中至关重要的一步,而智慧教室的建设与使用则是教育信息化的基础。随着新兴技术的发展,云计算、大数据和人工智能等技术齐头并进,支撑着智慧教室这一信息技术手段与人才培养体系实现了深度融合。与国内其它重点高校一样,山东大学已经将大多数的教室建设成智慧教室,实现了教师在智慧教室授课的直播和录播等功能。然而,现有的智慧教室云平台对于硬件设备和课程视频数据的应用还不够完善,相关软件应用不够丰富和智能。大量的课程视频存放在智慧教室云平台上,除了方便学生自学,学校也在寻找方法,使其为教学管理、学生选课和教学评价等提供大数据支撑。针对现有智慧教室云平台应用软件不能满足各种教学管理需求的问题,基于山东大学智慧教室云平台的课程视频大数据集,面向教学管理需求,本文设计研发了一个智慧教室视频分析系统。系统使用目标检测技术处理课程视频图像,提取图像中的数据信息,并以简洁客观的方式呈现给系统用户,作为辅助手段,帮助教学管理人员做出更加客观准确的教学评价。本文主要研究工作包括:(1)详细阐述了智慧教室视频分析系统的研究、设计和实现过程。通过文献调研和国内外智慧教室数据处理现状调查,对智慧教室的发展历程进行了深入了解。然后,在与智慧教室建设和管理人员充分探讨后,对系统进行了需求分析和总体架构设计,确定了系统的五大功能模块:教师管理模块、课程管理模块、教室管理模块、用户管理模块和视频处理模块。对系统各功能模块进行了详细设计与实现并介绍涉及到的关键技术。(2)对于视频处理模块,采用基于深度学习的目标检测技术对智慧教室视频进行图像处理。针对智慧教室的多路视频数据和应用场景制作了单独的数据集,将BiFPN模块融入YOLOv5s模型形成了更加适合本文场景的BiFPN-YOLOv5s网络模型,相比于原模型在速度不下降的情况下提升了 2.1%的准确率。(3)系统采用B/S架构,使用前后端分离的方式进行开发。前端采用React框架和Ant Design等技术进行开发,后端采用Spring Boot和MyBatis框架进行开发。为充分发挥GPU处理图像的优势,视频处理模块采用Python语言的Flask框架并将本文研究的BiFPN-YOLOv5网络模型部署在GPU服务器上,通过RESTFul风格接口进行系统间通信。最后,通过单元测试和黑盒测试方式对系统进行了测试,确保系统的功能完整、运行平稳。本文建设的智慧教室视频分析系统作为智慧教室数据处理的辅助手段,能为师生提供更加全面、准确的课堂信息,为教学管理人员在教学评价时提供客观全面的课堂数据,同时也可以帮助学生在选课前期了解某课程和某教师的课堂状况,确定是否选课。本文的研究工作是智慧教室视频数据分析的一种有意义的尝试。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.003224
{DOI}: 10.27272/d.cnki.gshdu.2023.003224
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多视觉传感器的协同感知系统研究
{Author}: 于洋
{Tertiary Author}: 许庆阳
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多传感器融合;深度学习;视觉传感器;目标检测;目标搜索
{Abstract}: 随着技术进步,当今社会逐渐由信息化社会向智能化社会转变。视频监控已遍布道路、城市、安防、工厂、家庭等各种场景。当前的视频监控系统主要利用视觉传感器拍摄和存储相应场景的视频信息,不具有智能性,视频监控系统无法综合利用各视觉传感器信息。随着视频分析技术的发展,视频监控逐渐向智能分析、多视觉传感器信息融合的方向发展。区域监控摄像头通常布置在建筑墙体等位置,具有较大的视角,便于监视相关区域。但是,由于建筑结构等原因,监控摄像头往往存在监控死角区域。因此,本文研究区域监控摄像头与机器人视觉传感器相融合,形成全局与局部互补式视觉场景感知系统。通过构建多任务实时目标检测分割与定位系统,实现场景的精细化分析;融合区域监控摄像头与机器人视觉传感器信息,实现机器人工作场景特定目标的搜索。主要研究内容可以概括如下:(1)对多传感器协同感知与融合深度学习的多视觉传感器协同感知研究现状进行阐述,基于目前对复杂环境缺乏清晰的认知与多源视觉传感器融合较浅等问题,提出了多源传感器深度融合系统等解决方案。(2)针对复杂环境认知不足的问题,构建多任务实时目标检测分割与定位系统。构建基于one-stage结构的多任务模型,提出了 TLFDNet网络模型来实现对视频监控下的场景内移动或静止目标的定位,该方法利用单目视觉深度检测方法,对检测出的目标进行目标定位,优化传统的检测框定位算法误差较大的问题。同时,利用采集到的环境数据集对该模型进行目标检测与分割多任务训练,使其能够对场景内的可移动区域进行划分,辅助下游任务的进行,实验验证了算法的有效性。(3)针对单一传感器目标检索能力有限的问题,本文提出了基于多源视觉传感器融合的目标检索系统。结合移动机器人在场景内的灵活性,将移动机器人视觉传感器与视频监控摄像头进行多源信息融合,克服单一视觉传感器在目标检索能力有限的问题,提高了目标检索系统的时效性,实验验证了方法的有效性。(4)在实际场景中搭建实验环境,构建多源视觉感知系统,利用Socket通信实现各层级的信息交互,实现机器人视觉传感器与区域监控信息的有效融合,在实际场景中验证了该系统的实用性。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006978
{DOI}: 10.27272/d.cnki.gshdu.2023.006978
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CMT和Swin Transformer特征提取网络的图像实例分割方法研究
{Author}: 查政夷
{Tertiary Author}: 杨威
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 实例分割;特征提取网络;滑窗转换模块;掩膜生成分支;激活函数
{Abstract}: 图像是最普遍的信息之一,电子摄像录像设备的演进和互联网的蓬勃发展让当下各种图像数据指数级爆发,仅靠人类肉眼和手工已经难以处理数以万亿记的图像内容。图像相关的计算机视觉任务在当下的社会生活中越来越广泛的普及和进入更加深入细化的应用场景,在医学图像、自动驾驶和视频处理等领域已经起到举足轻重的作用。图像实例分割方向是计算机视觉领域的一项基本任务。给定一幅图像,实例分割任务的目标是针对图像中指定类别的实例与背景进行像素级的区分。在实例分割任务中,常会遇到图像特征提取低效,短距长距特征无法兼顾导致生成的特征图无法全面反映图片的不同物体的有效信息的问题,也会有目标相互层叠遮挡,大物体边界分割模糊不精确,掩膜生成效率低,精度差的问题。本文针对以上问题,提出新的特征提取网络,并引入新的掩膜生成方法。在不同数据集上实现了更好的效果。本文的主要贡献如下:提出了一种基于卷积计算和自注意力机制的特征提取网络,充分利用短距和长距特征抓取的优势以及滑动窗口算法的全局特征提取能力。该网络结合了CMT模块和Swin Transformer模块,其中CMT模块提出的局部感知单元增强了局部信息提取的能力,又使用了轻量级多头自注意力机制模块和反向残差前馈网络,提高了网络的效率,取得更好的效果Swin Transformer模块则利用滑窗机制,弥补窗口化多头自注意力机制中不同窗口之间缺乏交互的缺点,从而增强了全局特征信息提取的能力。为了评估本方法对于实例分割的效果,选取COCO和Cityscapes数据集进行实验。观察到本方法不仅在许多分割指标上比基本模型效果更好,在COCO数据集上,大中小不同尺度物体分割效果都要比原MaskRCNN模型提升3%以上,而且从实例分割效果图可以看出在兴趣区域推荐和输入数据有效性方面也取得了更好的结果。在Cityscapes数据集上,不同景深的实例,分割效果相较于原MaskRCNN模型都取得了明显提升。不同数据集的实验共同验证了本文方法的有效性。为了解决大尺度实例对象数据集中生成掩膜效率低下的问题,引入了一种基于快速余弦变换的掩膜生成方法,该方法综合了低复杂度和高质量的优势。在COCO数据集中的大尺度对象上,实验表明,基于DCTMask的掩膜生成方法比原始掩膜生成方法效果更好,在不同尺寸的实例分割效果中,都取得了比原MaskRCNN模型更好的分割效果。针对大尺度目标掩膜生成效率低,引入DCTMask掩膜生成方法,引入Swish激活函数,兼顾了低复杂度和高质量,在大尺度目标图像上,获得更好的掩膜生成效果。在Cityscapes数据集上,在较近景深的实例分割效果中,也取得了比原MaskRCNN模型更好的分割效果。实验验证了本文方法的有效。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001340
{DOI}: 10.27517/d.cnki.gzkju.2023.001340
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的齿轮参数测量系统
{Author}: 陈朝伟;范芳蕾;黄伟莉
{Author Address}: 东华理工大学机械与电子工程学院;
{Journal}: 机电工程技术
{Year}: 2023
{Volume}: 52
{Issue}: 05
{Pages}: 113-116
{Keywords}: 机械视觉;非接触式测量;齿轮参数测量;小波变换模极大值;最小二乘法
{Abstract}: 针对传统的机械接触式齿轮测量仪器操作复杂、易产生主观误差等问题，提出一种基于机器视觉齿轮参数非接触式测量系统。首先利用图像灰度变换、直方图均衡化方法对图像进行预处理，提出小波变换模极大值法计算图像的矢量模值和相角，寻找梯度方向极大值点，选取自适应阈值方法提取目标图像边缘。对齿轮的边缘轮廓形状特征，采用最小二乘法拟合原理，计算齿轮的齿根圆直径、齿顶圆直径、齿数和模数等参数。以两种参数的齿轮零件测量为例进行实验分析，结果表明，测量值满足测量精度要求，证明了所提测量系统的可行性。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwp3AnYFeA3T2wBeZyVIk2SyKbHtiotne_3Q0COnzh2vHaMle9tM0rb7e93EK2kx3XdN43p7SBfvqeATf_phdkRbde8JezUf-FB8JTd03q-y0FPixjTIl2xTj0DTvJ5SVLkkKG9IHlWB_TfVDwoZ5mcLBK_TaPMDUorm4bVVLLapamATD6qKlTSrvOS0EAPXw8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向公共安全的异常行为识别方法与技术研究
{Author}: 高辉
{Tertiary Author}: 张德贤;邓淼磊
{Publisher}: 河南工业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 公共安全;异常行为识别;人群计数;人群定位;车辆重识别
{Abstract}: 面向公共安全的异常行为识别是公共安全风险防控与应急管理领域的重要保障技术。本文针对公共安全风险防范和应急应用需求,研究公共安全风险防控所涉及的异常聚集人群分析与异常车辆重识别等异常行为识别方法与技术,为智能化、网络化、实用化的异常行为识别系统开发提供支撑技术。本文在深入分析面向公共安全的异常人群和车辆聚集风险的基础上,探究透视效应与人群非均匀分布、尺度变化、遮挡和光照变化等受限条件下异常聚集人群分析与车辆重识别所涉及的特征提取与模型建模问题。研究异常行为识别深度网络结构、密度估计和损失函数等设计方法,探索多种因素影响下异常行为识别性能提升途径,创新基于深度学习的场景密集程度感知、人群计数、人群定位与车辆重识别方法。本文的主要工作和创新性成果如下:(1)针对异常人群聚集风险感知所涉及的人群非均匀分布及相互遮挡问题,提出了基于人群计数的自适应分割网络场景密集程度感知方法。该方法采用更深的网络模型,提取图像中的高层次、抽象的特征信息,融合空间金字塔网络,通过级联的方式进行融合,以获取更高质量的语义上下文信息;设计了一种场景自适应分割模型,自动提取场景图像的判别特征;引入了一种新的正则化方法,自动寻找合适的不相交组分配,提高模型对不同场景下目标的检测能力。在此基础上,设计了两种基于卷积神经网络的人群计数模型,分别采用反卷积和空洞卷积获得远景和近景区域的密度图,用于回归人群人数,提高人群计数准确性。实验结果表明,所提出的基于人群计数的自适应分割网络场景密集程度感知算法具有较高的计数准确性,适用于人群密度不均匀和相互遮挡等复杂场景密集程度感知任务。(2)针对在异常人群聚集的高度拥挤场景下,人群计数任务中存在的人头尺寸变化大的问题,提出了基于多尺度特征自适应融合网络的人群计数方法。该方法基于截断的深度网络模型,设计了不同层次特征提取方法,并保留三个最大池化层以强化不同尺度的特征;引入了轻量级的混合注意力机制,以减少通道竞争造成的特征信息损失,突出有效信息,抑制无用信息,增强特征图的表达能力;设计了扩张卷积模块,融合传统卷积和空洞卷积,加速网络的收敛速度,从而生成高质量的估计密度图。实验结果表明,所提出的基于多尺度特征自适应融合网络的人群计数算法显著提升了人群计数的精确性和鲁棒性,可更好地适应高度拥挤场景下人头尺寸变化等复杂情况。(3)针对异常人群分析任务中,单一模型上无法对不同类型的关系进行统一建模的问题,提出了基于局部接受域的弱监督人群分析方法。该方法将Transformer引入人群分析任务,设计了基于局部接受域的弱监督人群分析框架,实现了人群计数和人群定位功能;设计了基于全局最大池化的头部细节增强方法,提取图像中的多尺度特征并保留头部更多的细节信息;设计了一种二值化模块,搭载自适应阈值学习器,减少额外的监督标签,获得准确的置信度二值化图;提出一种连接组件检测器,用于头部位置检测和初始框,提升人群计数和人群定位精度。实验结果表明,所提出的基于局部接受域的弱监督人群分析方法实现了人群计数与人群定位的统一建模,显著提升了算法的跨域特征学习能力。(4)针对异常车辆风险感知的特殊性和快速重识别要求,提出了基于混洗视觉转换网络的轻量级异常车辆重识别方法。该方法采用深度网络模型,融合ShuffleV2作为基本卷积模块,减少了网络参数量,降低了网络提取特征的计算量,提高了重识别速度;设计了ShuffleViT模块,引入自注意力机制,提取车辆图像中的语义信息并保留图像特征间的空间位置关系,增强了模型对全局上下文信息和局部细节信息的分辨率;引入了监督对比损失函数,融合交叉熵损失函数进行联合训练,拉大了不同车辆图像的特征距离,同时也增强了对同一车辆图像间的特征距离的约束,提升了模型的判别能力。实验结果表明,所提出基于混洗视觉转换网络的轻量级异常车辆重识别方法能有效地辨识车辆图像间的细微差异,满足异常车辆快速重识别要求。
{URL}: https://link.cnki.net/doi/10.27791/d.cnki.ghegy.2023.000006
{DOI}: 10.27791/d.cnki.ghegy.2023.000006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer网络模型和多重注意力机制的医学影像分割算法研究
{Author}: 齐俊
{Tertiary Author}: 郭树旭
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学影像分割;注意力机制;门控机制;Transformer模型;局部-全局训练策略
{Abstract}: 深度学习技术在近些年发展迅速,其应用涵盖自然语言处理和计算机视觉等领域。尤其是在医学影像分割领域,深度学习在辅助医生进行疾病诊断和病理研究过程中所起的作用不可小觑。Transformer模型的出现很好地解决了卷积神经网络对于远距离信息无法进行有效捕获的问题,同时也克服了循环神经网络在并行计算时遇到的困难。然而在批量处理视频和图片过程中,Transformer依然会产生很大计算开销。本文将卷积神经网络和几种注意力机制相结合,同时将Transformer模型作为整个网络的特征提取器,提出一种基于多重注意力机制的门控轴向Transformer模型(Gated Axial Transformer with Comprehensive Attention,CA-GAT),用于解决在医学影像分割中遇到的问题。首先,在编码器部分,使用轴向注意力机制代替传统Transformer模型中的自注意力机制,通过这种方式可以达到与自注意力机制相同的训练效果,但计算复杂度大大降低。同时引入门控机制,让模型在训练数据量较小时仍能够学习到准确的位置偏差。其次,对于医学影像分割任务而言,待分割目标区域可能在位置、形状和尺度上存在差异。在模型中同时引入了空间注意力机制、通道注意力机制和尺度注意力机制,可进一步增强模型对于图像边缘信息提取能力。最后,在网络中引入局部-全局训练策略,该策略通过将整幅图像输入到全局分支进行训练的方式更好地建立远距离依赖关系,并且更好地捕获全局特征信息。而将分割后图像块送入局部分支中,让网络学习到更加精细的细节特征。在皮肤黑色素瘤分割数据集ISIC2018和全景X射线牙齿分割数据集上,对所提出的模型CA-GAT进行了验证。在黑色素瘤分割实验中,与现有的几种主流模型U-Net、CA-Net和Med T相比,所提模型的Dice系数分别提高了6.29%、0.46%和1.20%,其它指标也有所提高,证明该模型具有较好的分割性能。在全景X射线牙齿分割实验中,额外引入豪斯多夫距离(HD),来评价模型对于边缘信息的敏感程度,与U-Net和CE-Net相比,所提模型的豪斯多夫距离分别下降了3.288mm和1.268mm,表现出较强的边缘信息提取能力。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.001174
{DOI}: 10.27162/d.cnki.gjlin.2023.001174
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 注意力机制在点云和图像融合目标检测中的研究
{Author}: 张何晴
{Tertiary Author}: 宋俊峰
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 点云;注意力机制;多模态融合;目标检测
{Abstract}: 目前,单一传感器在感知任务中存在局限性,为了提高感知任务的准确性,许多工作采用了多传感器融合方法。在三维场景感知技术迅速发展的背景下,多模态融合在三维目标检测中已广泛应用。然而,当前的多传感器融合方法存在以下问题:对于多传感器信息的利用效率较低,难以有效解决复杂场景下成像分辨率低以及部分物体被遮挡的检测问题。此外,多模态融合需要考虑多个传感器的数据,算法鲁棒性差,容易受到传感器故障、数据缺失等因素影响。因此,当前的多传感器融合方法仍需要进一步改进,以提高感知任务的准确性和鲁棒性。在深度学习技术中,注意力机制通过实现对不同特征的自适应选择和加权提升深度网络表征、分析和理解数据的能力。针对多模态融合中存在的问题,本文主要研究在点云和图像信息融合的目标检测任务中,注意力机制对检测结果的影响,并验证了本文算法的有效性。具体的工作内容如下:1)基于注意力机制的单模态检测算法研究。该部分,研究单模态数据实现目标检测任务。实验采用编码-解码结构,在编码器和解码器之间插入局部-全局注意力机制模块,以获取更丰富的全局上下文信息。局部-全局注意力机制模块由局部模块、全局注意力机制模块及跳跃连接结构组成。实验结果表明,本文提出的检测算法在图像和点云单模态下都能有效地提升检测效果。2)基于注意力机制的多模态检测算法研究。该部分,研究采用包含多种传感器数据的Nu Scense数据集。在基于第一部分的研究基础上,实验首先采用初始化目标查询机制,将提取的图像特征作为引导信息得到Query;接着在编码-解码结构中添加交叉注意力机制融合图像特征和点云特征;最后通过两个解码器层分别预测候选框和输出目标检测结果。其中,交叉注意力机制模块分别将点云特征和图像特征的Query交叉计算得到融合特征。检测头中的每个解码器层之后添加前馈神经网络和监督,利用预测候选框限制交叉注意力。交叉注意力机制可以对不同传感器特征图之间进行建模,能够充分利用特征图中的语义信息。实验结果表明,相同场景下,多模态比单模态的目标检测指标m AP提升了4.1%;不同场景下,本文的多模态融合方法的网络检测性能更加稳定。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.004959
{DOI}: 10.27162/d.cnki.gjlin.2023.004959
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的无人驾驶中小型障碍物检测
{Author}: 陈如意
{Tertiary Author}: 刘堂友;郁雷
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像平滑;边缘检测;特征提取;目标检测
{Abstract}: 近年来无人驾驶技术得到了快速发展,目前国内外都已有无人驾驶车辆上路测试,将来无人驾驶车辆很可能会大规模地出现在国内外城乡道路上。当前的研发测试主要集中在保证车辆安全顺利地到达目的地,未来在此基础之上,车辆乘坐的舒适性自然会成为新的需求。道路中的小型障碍物,比如砖头石块、减速带、路面坑洼等,可能不会影响无人驾驶的安全性,但是会引起车辆颠簸振动,必然会影响汽车行驶过程中的平稳性和乘坐的舒适性。本文以砖块、减速带和路面坑洼为例,对道路中影响车辆行驶平稳性的小型障碍物检测进行了研究,期望未来能实时检测和规避。首先,本文基于传统边缘检测算法的优缺点,提出了一种改进的Canny边缘检测算法。用所提出的改进的中值滤波算法替代原始Canny算法中的高斯滤波进行图像平滑。由于传统Canny边缘检测的滞后阈值化处理中的双阈值是凭借经验人为设定且全局固定,所以算法缺乏自适应性,本文利用滑动窗口结合Otsu算法为Canny边缘检测自动设定双阈值,提高Canny算法的自适应性。利用改进的Canny算法提取原始道路图像中可能为目标障碍物的子图像。其次,本文设计了一种DT-SVM(Decision Tree SVM)分类器,对可能为目标障碍物的子图像进行分类识别。将HOG(Histogram of Oriented Gradient)特征和LBP(Local Binary Patterns)特征进行改进融合,得到HOG-LBP联合特征提取算法,提高分类器的准确率。针对传统SVM(Support Vector Machines)算法只适用于二分类的问题,设计一种基于决策树的SVM用于多分类任务。先按照与其他所有类之间的最小距离最大的类优先分离的原则对数据进行分类,在遇到多个类的距离相等时,再按照出现概率大的类优先分离的原则对数据进行分类。保证准确率最大,同时尽可能地减少其分类判断的次数,缩短分类器的分类时间。最后,基于透视变换进行影响行驶的障碍物的判定,判断DT-SVM分类器所识别出的目标障碍物是否会影响车辆的行驶。先进行相机标定消除畸变,并且通过透视变换将原始道路图像转换为鸟瞰图形式。通过鸟瞰图中车辆的行驶路径与分类器识别出的目标障碍物的位置关系,判断目标障碍物是否影响车辆的行驶,完成最终的检测任务。本文主要对道路中影响无人驾驶车辆平稳性的小型障碍的检测进行了研究,检测出道路中的小型障碍物并且判断其是否影响车辆的行驶,辅助无人驾驶车辆避障或减速,从而提高无人驾驶车辆乘坐的舒适性。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.001342
{DOI}: 10.27012/d.cnki.gdhuu.2023.001342
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于ConvNeXt网络的服装图像检索研究与应用
{Author}: 张逸玮
{Tertiary Author}: 石秀金
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: ConvNeXt;服装图像检索;注意力机制;全局特征;局部特征
{Abstract}: 随着互联网和电子商务的高速发展,越来越多的消费者选择线上购物。特别是在服装行业,线上交易量逐年持续增长,导致网络服装图像数据呈现爆炸性增长,如何快速准确地检索出用户有兴趣的时装图像成为一个具有挑战性的问题。传统的基于标签的服装图像检索方法由于人工标注耗时、主观性强、标签信息不完整准确等问题,导致检索结果难以令人满意。而基于传统的视觉内容特征的服装检索技术面临特征选取和语义鸿沟等难题,仍存在瓶颈。考虑到深度学习在图像领域表现出色,本文提出了一种基于卷积神经网络的服装图像检索方法。本文提出了一种基于ConvNeXt网络的服装图像特征提取模型。ConvNeXt网络以Res Net为出发点,融合了Transformer网络的思想,在图像分类和识别的任务取得了不错的效果,故本文基于ConvNeXt网络对服装图像进行特征提取。考虑到仅使用全局分支会存在一定局限性,因此本文增加了一个局部分支,在训练过程中将全局分支和局部分支联合训练。最后,开发了一个基于该模型的服装图像检索系统。以下是本文的主要所做内容:(1)本文提出了一种基于ConvNeXt网络的新型服装图像检索算法。ConvNeXt网络在关注服装图像中的重要区域方面具有更强的能力,并且充分考虑了服装图片中的细节。为了加强模型对服装图像重点区域的关注,提出了一个加入了GCT(Gated Channel Transformation)通道注意力机制的GCT-ConvNeXt-Block模块,进一步提升了模型的准确率。本文采用了加入温度缩放和标签平滑的交叉熵损失函数和难样本三元组损失函数,这些损失函数的使用,使得模型可以很好地识别差异较小的服装样本。为了验证算法的有效性,本文在Deep Fashion服装数据集上测试了模型,比较了Res Net、SE-Res Net、Res Ne Xt、Swin-Transformer等模型在服装图像检索实验中的表现。经过详细的实验比较分析,验证了模型在服装图像检索方面的有效性和先进性。(2)ConvNeXt网络在捕捉图像细节和特定关系方面表现出强大的性能,但是在处理复杂背景、不同拍摄姿势或者拍摄条件不佳的服装图像数据时具有局限性,单全局分支网络提取到的信息不足。为进一步提高检索效果,本文采用了联合全局分支和局部分支一起训练的方法,并使用全局特征进行相似度计算。局部分支对提取到的局部特征进行计算得到一个距离方阵,用最短路径算法动态地从上到下匹配局部部分,将连接的最短路径作为它们局部特征之间的距离,这显著缩小了同款服装在姿态差异较大时的距离,使得模型能够更好地关注图像的整体风格和细节信息,实现高精度检索。经实验验证,加入局部分支取得了更好的检索效果。(3)基于本文模型开发了一个基于B/S三层架构的服装图像检索系统,实现了多个功能,如服装图像检索、用户历史图像检索信息查询、用户管理以及用户登录和注册等。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.000254
{DOI}: 10.27012/d.cnki.gdhuu.2023.000254
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的疲劳驾驶检测算法研究与设计
{Author}: 徐壮壮
{Tertiary Author}: 霍羽
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 疲劳检测;RetinaNet;自注意力机制;轻量化
{Abstract}: 随着经济的逐步发展及人们消费需求的日益增长,汽车作为消费品也逐渐成为不可替代的通行工具。然而家庭汽车持有量的高速增长,也导致了交通事故、交通拥堵等问题的攀升。据统计,疲劳驾驶及由此导致的不当驾驶行为是造成高速公路、城市公路交通事故的重要原因之一。智能化设备及技术在监测、分析和预防驾驶员疲劳驾驶行为方面具有极大潜力。目前疲劳驾驶检测存在实时性不够、灵敏度和可靠性差等问题。本文基于深度学习方法研究并设计了驾驶员疲劳检测系统,采用单阶段的Retina Net算法作为基准模型,通过融入自注意力机制和轻量化及损失函数的改进,算法的精确度和计算效率得到提高,为实时监测驾驶员的疲劳状态提供了有效帮助。本文的研究内容和主要贡献如下:(1)针对传统单阶段算法检测精度较低的问题,本文提出了基于Retina Net模型的疲劳驾驶状态检测改进算法。所提算法舍弃了常用的Res Net主干网络,设计了融入自注意力机制的混合神经网络,通过对全局信息的有效利用,建立了长程依赖关系。其次,根据应用领域及对数据集的分析,舍弃了部分预测大目标的高层输出特征图,并采用较小的锚框尺寸获取面部人眼、嘴部状态信息,减少模型运算量。实验表明,相比于原Retina Net模型,本文的改进检测算法在疲劳驾驶检测数据集上的精确度提高了约2.6%,召回率提高了约3.3%左右。(2)针对传统注意力模型中线性层参数量较大,检测实时性差的问题,本文基于所提的Retina Net改进模型,进行了轻量化设计,优化了损失函数。首先,在主干网络的设计中引入深度可分离卷积和倒残差结构,对改进的注意力模型进行轻量化设计。其次,结合目标框的几何信息,对边界框坐标的损失函数进行改进优化。实验表明,改进的轻量化模型,不仅具备较高的精确度,还将DW深度可分离卷积层模型的参数量减少至原来的1/9,提高了模型的计算效率。在引入改进的损失函数后,改进模型的收敛速度及边界框坐标预测的准确性也得到了验证。基于上述研究,本文设计了一套疲劳驾驶检测系统。该系统对单位时间内人眼状态、嘴部状态的变换进行了监测,并根据疲劳判定指标对驾驶人员的疲劳状态进行定性分析。本文包括图40幅,表6个,参考文献82篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.001890
{DOI}: 10.27623/d.cnki.gzkyu.2023.001890
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的隧道结构病害图像智能识别表征与可视化
{Author}: 徐晓华
{Tertiary Author}: 李元海;刘庆方
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 结构病害;数字图像;深度学习;计算机视觉;参数表征
{Abstract}: 自21世纪以来,我国隧道工程建设的速度逐渐加快,建设里程和规模均处于世界领先地位,隧道也逐渐由“建设为主”向“建养并重”转变。由于建设速度快、工期紧张、技术人员及现场工人短缺、隧道施工问题、运营后隧道周边环境扰动等原因,隧道运营中存在不同程度的结构病害,如裂隙、渗漏水和掉块等,因此提高隧道修建中支护技术的要求和增强日常维护与检修技术水平迫在眉睫。传统方法受限于人力和主观判断难以满足日渐增长的检测需求,故亟需一种更高效快捷的检测手段。随着深度学习的快速发展,基于计算机视觉对隧道结构病害检测的研究也日益增多,可以明显看到其在检测速度与检测准确度方面都具有传统方法不可比拟的优越性。本文基于计算机视觉和深度学习技术,采用Python编程语言、开源计算机视觉库Open CV以及深度学习框架Tensor Flow2.0,对隧道衬砌中出现的主要病害进行识别研究并针对各类病害分别进行量化分析。通过Py Qt5、Qt等应用程序开发工具研制了一套隧道衬砌结构病害智能识别表征与可视化软件系统,最后利用研发软件对隧道图像开展实际应用研究。主要成果及结论如下:(1)建立了用于深度学习模型训练用的隧道衬砌病害样本库,并给出了基于图像几何特征的隧道衬砌病害图像分类方法。通过线阵CDD相机、佳能80D相机拍摄以及网络搜集的方式获得图像,并通过图像裁剪与数据增强处理原始样本,最终建立了包含8020张裂隙、4140张渗漏水及3070张掉块图像的病害图像样本库;依据病害的几何与分布特点,将裂隙分为了分离式、单点交叉式及多点交叉式裂隙三种类型,将渗漏水与掉块划分为简单型与复杂型两种类型。(2)确定了基于深度学习中语义分割技术的隧道结构病害精确分割方法,构建了针对病害识别的MRC-Unet模型。MRC-Unet模型采用了Unet网络作为框架,引入了混合注意力机制CBAM和设计的多尺度残差模块MRFB对模型进行改进,经试验验证,其识别性能得到了提升;其次,针对相似干扰物难以排除问题,选择将干扰物作为单独分类加入训练的方法开展裂隙识别试验,取得较好效果。(3)研究了隧道结构病害的空间特征与几何特征提取方法,给出了一种基于迹线方向判断的交叉裂隙分离算法和包含裂隙在内的衬砌病害表征算法。设计了微分累加法、方框法和线性回归法用于提取裂隙特征;利用连通域统计和最小包围盒算法计算渗漏水/掉块的数量及面积;试验分析验证了裂隙分离算法的有效性以及病害表征算法的精确性和实用性。(4)基于隧道结构病害智能识别与表征算法研究,开发了一套适用于隧道衬砌结构病害智能识别表征的软件系统。该软件系统由隧道衬砌病害智能识别、表征及可视化展示等3个程序组成。其中智能识别程序主要用于对病害进行识别及自定义模型训练;表征程序主要用于处理分割图像以及提取病害特征;可视化展示程序主要用于对病害识别结果进行平面或3D展示。(5)通过隧道衬砌病害示例图像特征分析,建立了自主研制的隧道衬砌病害识别与表征软件的工程应用方法。首先将实际隧道图像进行拼接,并通过人工添加病害的方法制作模拟样本;然后通过研制软件对模拟样本进行识别表征操作,对结果进行可视化展示并生成对应的统计表,均取得了较好的效果;最后利用模糊分析法对模拟样本进行了风险评估。本论文共79幅插图,26张表格,96篇参考文献。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.002562
{DOI}: 10.27623/d.cnki.gzkyu.2023.002562
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的西甜瓜叶部病虫害识别方法研究
{Author}: 陈清源
{Tertiary Author}: 徐艳蕾
{Publisher}: 吉林农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 西甜瓜;病虫害识别;计算机视觉;YOLO v5;通道修剪
{Abstract}: 西瓜与甜瓜是我国居民日常食用水果中的重要品类,年生产量与消费量排名均长期处于世界前列。鉴于我国庞大的人口基数带来的西甜瓜消费需求,保证我国国内西甜瓜产量、人民的食用需求得到满足十分有必要,而病虫害一直是农业生产中作物产量的重要影响因素之一,病虫害的有效防治是农业生产技术的一个重要研究方向。本文针对西甜瓜植株生长过程中常见的四种病虫害开展研究,通过计算机视觉技术实现西甜瓜四种常见病虫害的快速检测,为西甜瓜病虫害防治工作提供了有效的检测手段。本文主要研究内容及结果如下:(1)通过智能手机和物联网设备针对温室环境下的西甜瓜患病叶片进行数据采集,获得了5871张包含四种病虫害的西甜瓜叶片图像,并以此建立了自有数据集。(2)针对温室内环境复杂、硬件设备算力限制两种实际问题,原始的YOLO v5无法满足工作需要,本文使用Shuffle Net v2改进了YOLO v5主干,对重构的模型进行了针对性的改进,最终取得了较好的检测效果。(3)本文使用通道修剪的方法将改进的卷积神经网络模型——Pruned-YOLO v5+Shuffle(PYSS)网络模型体积压缩至1.3 MB,同时保持了原模型98%的识别精度。压缩后的模型更加适合部署在边缘设备上,使得本文研究方法的可应用平台更加丰富。(4)通过物联网设备与边缘计算设备的有效结合,实现西甜瓜的病虫害数据采集、神经网络模型的定期训练,进行高效快捷的数据库更新、模型迭代,能够保证模型的长期可用性。本文的研究可以快速有效的实现西甜瓜叶部病虫害的高精度识别检测,为西甜瓜病虫害防治快速响应提供了技术保障,方便后续工作人员进行西甜瓜病虫害的精准、有效处置提供了理论基础及技术支持。
{URL}: https://link.cnki.net/doi/10.27163/d.cnki.gjlnu.2023.000480
{DOI}: 10.27163/d.cnki.gjlnu.2023.000480
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的管道缺陷检测方法研究
{Author}: 李飞
{Tertiary Author}: 胡青松
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;EDSR;管道缺陷;YOLOv4
{Abstract}: 管道是石油和天然气等能源重要的运输工具,但随着管道里程及工程规模的增大,其安全隐患也随之增大。油气管道的安全是确保我国石油和天然气正常运输的关键。但是,因为运输管道很长,所以收集到的数据很庞大,采用传统的人工判读方法进行管道中各种缺陷的检测存在着效率低、精度差、漏检和误检等问题。在最近几年,随着计算机视觉的迅速发展,本文对基于深度学习的管道缺陷检测方法进行研究,主要的研究工作如下:(1)针对管道缺陷数据集缺失问题,本文提出了对漏磁信号灰度化处理和图像增强的方法制作数据集。首先,基于对漏磁信号进行图像化处理,生成曲线图、伪彩图和灰度图。根据管道缺陷在图像中的特征以及图像背景选择最适合的灰度图作为原始图像。其次,为了增加缺陷图像和提高管道缺陷检测数据集的多样性,提出对缺陷图像进行翻转旋转、降噪等图像增强方法。最后,根据管道缺陷特征对图像进行标注,制作样本丰富的管道缺陷检测数据集。(2)针对目前管道缺陷检测领域在缺陷检测时检测网络复杂度较高、缺陷识别能力不足、泛化性不强的问题,本文以目标检测算法中的YOLOv4为基础,结合管道缺陷的特点进行研究改进。首先由于待检管道数据量较大,对检测的效率要求很高,因此对YOLOv4的骨干网络CSPDarknet53进行轻量化改进,将其替换为Mobile Netv2网络,从而降低模型复杂度,提高了推理速度;然后针对YOLOv4网络对数据集中的小目标检测能力不足的问题,提出在融合网络PANet中增加小目标检测层,提高对小目标的特征提取能力;同时为了增加感受野,丰富管道缺陷特征信息,在网络中引入增强感受野模块RFB;最后为了获取图像中管道缺陷的关键特征,同时降低背景噪声带来的影响,在网络中引入CBAM注意力机制。实验表明,改进YOLOv4的网络模型能够快速、有效检测出管道缺陷。(3)针对当前管道缺陷数据集中小尺寸缺陷特征信息不足以及缺陷与背景信息融合度较高的问题,本文提出将超分辨率重建网络EDSR与改进YOLOv4检测网络相融合。首先为了提升检测效率,选择对管道缺陷先检测,提取出低质量检测图像进行超分辨率重建,再送回检测子网络的方式;然后通过分析数据集中小目标占比和尺寸分布,以及小目标在检测结果中的置信度分布情况,得出判断低质量检测依据;最后为了降低超分网络的计算复杂度,提升推理速度,对低质量图像重叠分块,送入超分网络EDSR丰富缺陷特征信息,降低缺陷和背景的融合度,检测后再把目标框回归到原图像中。实验结果表明,融合超分辨率重建网络EDSR和改进YOLOv4的管道缺陷检测算法有效提升了缺陷小目标的召回率,进一步提高了管道缺陷检测精度。本文中包含图72幅,表6个,参考文献83篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.002661
{DOI}: 10.27623/d.cnki.gzkyu.2023.002661
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于FPGA与YOLO的手机镜片缺陷检测系统的研究与实现
{Author}: 王国鹏
{Tertiary Author}: 王习东
{Publisher}: 三峡大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 镜片缺陷检测;机器视觉;YOLO;FPGA;软硬协同检测
{Abstract}: 手机光学镜片作为拍摄照片和视频的重要组件,其制造工艺复杂且高精度要求难以避免缺陷。为确保镜片质量,最有效的方式是严格遵循标准进行缺陷检测。目前,国内企业通常采用人工目视法检测镜片缺陷。然而,此方法效率低且误检率高,难以适应自动化生产趋势。因此,越来越多的研究人员开始探索采用机器视觉技术进行镜片缺陷检测,包括传统图像处理算法和基于神经网络的方法。传统方法难以实现多缺陷检测,而基于神经网络的方法则存在检测时延高、功耗高、成本高和部署条件苛刻等问题。鉴于上述挑战,本文将从以下三个方面展开研究:(1)本文提出了一种解决YOLOv2中重排序层Slice(切片)操作加重数据处理负担的方案。该方案采用卷积层替代重排序层进行网络退化,以降低缓存占用。同时,设计了基于FPGA的动态可重构加速IP,采用多种加速计算优化策略,包括动态定点16位量化、批归一化层融合至卷积层、循环展开与分块、快速卷积算法(Winograd和GEMM)、参数重排序、双缓冲流水线,以及多DMA通道数据传输等,以提高传输性能和数据吞吐量,同时降低计算复杂度和硬件资源消耗。实验结果表明,该加速IP在FPGA(PYNQ-Z2)平台上获得了51.89 GOP/s的计算性能,比基于典型滑动窗口卷积计算方法的性能提高了0.76倍。加速单张图像的时延为433ms,功耗为1.07W。与未经量化的CPU平台(Intel Core i5-10500)相比,该加速IP的能效是其365.27倍。(2)本文在FPGA硬件平台上设计了一款手机镜片缺陷检测系统,包括FPGA模块、XY平台模块、图像采集模块和HDMI显示模块。该系统采用PYNQ框架,通过软硬协同检测的方式,实现小型设备对手机镜片进行低时延、低功耗的多缺陷检测。本检测系统将成为手机镜片制造行业的重要工具,为自动化生产和质量控制提供有力支持。(3)本文提出了一种基于改进YOLOv4-tiny的YOLO-LD缺陷检测算法,并将其应用于手机镜片缺陷检测场景。该算法通过融合P3特征层、跨接特征金字塔池化、引入空间注意力模块,以及采用距离交并比非极大值抑制,以提高目标细节特征的提取能力和空间感知能力,并减少误判和漏检。实验结果表明,该改进算法的m AP@0.50和Average＿Io U指标分别为96.28%和77.37%,相比基准模型,分别提高了5.11%和10.38%。
{URL}: https://link.cnki.net/doi/10.27270/d.cnki.gsxau.2023.000087
{DOI}: 10.27270/d.cnki.gsxau.2023.000087
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像超分辨率重建研究
{Author}: 张祥
{Tertiary Author}: 唐英干;杨会龙
{Publisher}: 燕山大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像超分辨率;轻量级;自注意力机制;无监督;盲超分辨率
{Abstract}: 图像超分辨率是一个经典的低维计算机视觉任务,其目的在于将一张退化后的低分辨率图片恢复成一张视觉上令人满意的高分辨率图片。图像超分辨率问题本质上是一个不适定问题,没有唯一解,单纯依靠数学表达式难以很好地解决这个问题。近年来基于深度学习的图像超分辨率方法开始崭露头角。目前基于深度学习的图像超分辨率方法为了获得更好的重建性能会不断加深网络深度,但是这种做法会让整个网络模型的参数变多和计算量过大,从而限制了这些算法在移动设备上的应用。除此之外,现有研究大都数是建立在理想退化模型(例如双三次退化)的基础上的,而在真实场景中图像的退化模型是十分复杂且难以建模。因此以双三次下采样为退化模型训练得到的网络应用在真实场景中会有较大的性能退化。本文针对以上问题进行深入研究,主要工作如下:(1)针对现有图像超分辨率重建算法计算复杂度过高这一现象,本文提出了一种基于自适应稀疏性的轻量级图像超分辨率重建算法。通过引入稀疏自注意力机制构建了一个浅层特征提取模块,该模块能够以较少的计算量为代价提取出包含全局信息的浅层特征,为恢复图像的高频细节打下坚实的基础。为了考虑图像超分任务中固有的稀疏性,提出了改进的稀疏掩膜模块,该模块能够在网络的前向推理过程中跳过图像平坦区域的冗余计算以节约计算量。接着设计了一个特征融合模块,该模块将前面多个级联的稀疏掩膜模块的输出融合在一起以提供包含更多高频细节的特征给图像重建模块。此外,整个超分辨率网络各模块间使用了跳跃连接以保证图像的低频细节不丢失。实验证明,本文提出的算法以较少的计算复杂度在各个公共测试集上都取得了比其他轻量超分算法更好的重建结果。(2)针对现有图像超分辨率重建算法在真实场景的退化模型下无法恢复出高质量的图像这一现象,本文提出了一种改进的基于无监督退化表示学习的盲超分辨率重建算法。该算法主要有两个分支网络组成。第一个分支网络为对比学习框架下的基于残差思想的编码器网络,使用编码器网络可以从输入的低分辨率图像中学习到一个高维抽象的退化表示向量,该退化表示向量能够给超分重建网络提供待重建的低分辨率图像的退化模型信息。另一个分支为可以利用编码器学习到的退化表示向量灵活地适应各种退化模型的退化感知融合超分网络。退化感知融合超分网络的主干块为退化感知融合模块,该模块的核心思想是使用三个分支对输入的低分辨率图像特征和退化表示向量进行融合。此外,为了从输入的低分辨率图像中提取到包含图像全局信息的特征,本文为退化感知融合超分网络设计了一个浅层特征提取模块。在真实图像和合成数据集上大量的实验结果表明,本文所提出的算法能够在盲超分任务上取得比其他盲超分算法领先的重建性能。
{URL}: https://link.cnki.net/doi/10.27440/d.cnki.gysdu.2023.000915
{DOI}: 10.27440/d.cnki.gysdu.2023.000915
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的镍基高温合金表面缺陷检测系统开发
{Author}: 郭慧文;刘晓鸣;陈浩天;葛良辰
{Author Address}: 南京航空航天大学机电学院;
{Journal}: 制造业自动化
{Year}: 2023
{Volume}: 45
{Issue}: 04
{Pages}: 81-87
{Keywords}: 镍基高温合金;表面缺陷;机器视觉;检测系统
{Abstract}: 在镍基高温合金棒料表面缺陷检测中，为避免人工目检方法的缺点、提高检测的效率和准确度，设计了一套基于机器视觉的镍基高温合金棒料表面缺陷检测系统。首先，采用工业相机采集棒料表面图像并采用高斯滤波方法进行图像降噪；其次，采用自适应二值化及形态学方法（如膨胀和腐蚀）对图像进行预处理，有效提取缺陷区域；然后，采用Canny边缘检测、轮廓查找等方法，对缺陷区域的边缘轮廓进行精准识别，并得到相应坐标；最后，系统通过与STM32的串口通讯，实现对相机移动和棒料旋转的节拍控制及相机位置和棒料转角的获取，并通过其与缺陷在视场中坐标的整合，最终得到棒料中所有缺陷相对于棒料原点的坐标信息。实验证明，的系统能较为准确地检测得到棒料表面的缺陷坐标信息。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx21YLv7bAjEallz04VHeIJOjXSkTxOibIMgjj1Gc3Ah_iQ0dwxZ35VEdDm0gdzmYF08oorzj17Asr-HE1hoqSPW1-yUkFarBq2-nmdR09fVyQR2JrTh8KYU3Yd90fhJhmrcQ8VqOr26OAjORY1GX72wrbRjUopLaIjDgFaL0vKFM3OhHR1wbIrACy5PobYnuM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数据投毒的神经网络后门攻击与防御研究
{Author}: 萧晓彤
{Tertiary Author}: 丁建伟
{Publisher}: 中国人民公安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 神经网络模型;后门攻击;后门防御;交叉熵损失;图像识别
{Abstract}: 深度学习是近年研究的热点,在智能视频分析、人脸识别和自动驾驶等领域得到了广泛的应用。深度学习的成功依赖于大量的训练数据和强大的计算资源。为了降低成本,用户可以使用公开的数据集训练模型,或者在应用中直接调用预训练好的神经网络模型。这使得攻击者可以将后门嵌入到神经网络模型中,使神经网络做出预定的不利于用户的后门行为。攻击者只需在训练数据中加入少量后门样本便可以改变神经网络的分类行为。为了降低这种危害,需要研究合适的后门防御策略。传统的后门防御主要基于输入消毒处理,但由于其作用阶段的局限性,许多后门难以被抵御。和传统方法相比,基于检测后门触发器的后门防御方法通过检测和剔除后门来修复后门模型,已经成为目前最流行的防御方法之一。虽然检测后门触发器在后门防御领域展现出了良好的应用潜力,但该技术仍然存在后门难以检测和后门清除不彻底等问题。因此,如何提高后门检测能力一直是学术界的研究重点。本文基于后门攻击和后门检测展开研究,从分析后门攻击过程和后门检测两个方面探索提高神经网络模型的防御能力和鲁棒性。具体而言,本文的主要创新和贡献总结如下:1.基于图片边界后门嵌入的图像识别攻击。通过研究后门生成与嵌入的原理,提出了一种有效的后门触发器实现后门攻击。该后门是在图像边界加入一条细长的窄有色带,将边界像素值的微小突变作为后门触发器。通过边界后门的嵌入,可以改变神经网络的分类行为,将加入后门触发器的样本分类为目标标签。针对两个主流的训练数据集,使用后门触发函数和目标标签函数向图片嵌入后门触发器。对于图片边界后门嵌入的图像识别攻击实验结果表明,本文提出的边界后门在两个主流训练集上均取得良好的攻击效果。2.基于局部和全局梯度上升的分段后门防御。基于检测后门触发器的防御方法,提出了分段后门防御。使用局部梯度上升将干净与后门样本之间的训练损失差距扩大化,隔离出小部分高精度的后门样本。使用全局梯度上升,将神经网络中已经学习的后门样本遗忘,从而在妥协的数据集上训练出干净的神经网络模型。本文使用交叉熵损失函数来计算训练损失的梯度,实验在三个主流训练数据集上制作6种常见后门的数据集,在宽残差网络上训练后门模型。实验表明,本文提出的局部和全局梯度上升的分段后门防御在6种常见后门上具有良好的防御效果。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2023.000213
{DOI}: 10.27634/d.cnki.gzrgu.2023.000213
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Qt的钢管壁厚在线检测软件设计
{Author}: 刘坤;涂德浴;朱庆;刘庆运
{Author Address}: 安徽工业大学机械工程学院;特种重载机器人安徽省重点实验室;安徽科达机电股份有限公司;
{Journal}: 机床与液压
{Year}: 2023
{Volume}: 51
{Issue}: 07
{Pages}: 93-99
{Keywords}: 钢管壁厚;在线检测;机器视觉;Qt技术;人机交互界面
{Abstract}: 针对目前钢管端面壁厚的测量多采用人工抽检的方式，从而导致测量效率低、精度低、测量数据少的情况，对机器视觉测量技术进行了研究。基于机器视觉，设计钢管壁厚在线检测系统。通过对相机进行标定，获得图像像素值与实际值之间的关系，使用相机采集钢管端面图像，对采集得到的图像进行图像预处理、边缘特征点提取等操作；改进RHT圆检测算法，完成钢管端面圆形轮廓的检测，进而实现对钢管端面壁厚的测量。为了便于操作，基于Qt跨平台开发框架设计了钢管壁厚检测系统人机交互界面软件。结果表明：该系统具有良好的稳定性，检测误差约为0.1 mm,可以高效地完成壁厚检测任务。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy4tmSKjxxSB2Whkl-d6cjySmNh-B3kPKEkBlsyWIfYYOCR0NzG4clWCJrBQg-zkYjYqEUQTHaRoruQcMf8dU5KNiHmdhqI4S8Ex-A2O4qBgqXLvWIGofnexWPEBbh6KYoZSELXZLvmO_1RtLM9L7Xup1SotVj27qUz_oGV1L78xd5yoL311I9Q_xM2jlnxIeA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的PCB孔环类缺陷检测算法研究及系统实现
{Author}: 肖承兴
{Tertiary Author}: 白金平
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 孔环;PCB;机器视觉;图像配准;缺陷检测
{Abstract}: 电子产业对于一个国家的意义十分重大,其在国防、制造、信息传输和软件服务等行业都扮演着很重要的角色。在电子产业链中PCB是至关重要的部件,所以对于PCB进行质量检测是提升产品质量的重要步骤。PCB中的焊盘和过孔起着固定元器件、连接元器件和线路、固定基板的作用,焊盘、过孔是整个PCB实现连通的关键所在。随着技术的发展,PCB的复杂度不断地提升,尺寸不断的缩小,现阶段对于检测的需求已超出了传统的人工检测的能力范围,这对PCB的缺陷检测提出了新的挑战。因此研究一套PCB孔环类缺陷检测的系统具有非常重要的意义。本文基于机器视觉技术,结合图像处理算法,制作了从图像采集到图像缺陷检测的自动化缺陷检测系统。系统由硬件和软件两部分构成,硬件系统包括照明系统、运动控制系统、图像采集系统,运动控制系统负责传输PCB,图像采集系统负责获取PCB图像。软件系统使用Python编写图像处理程序,实现图像的采集、预处理、配准、缺陷检测等功能,并且使用Py Qt制作人机界面,实现人机交互。在图像预处理部分,为了解决因为焊盘边缘色散和焊锡凹凸不平而导致的目标区域无法被准确分割的问题。本文运用拉普拉斯算法对目标区域进行增强,分析背景和目标区域的RGB特性,结合生长算法,设计分割准则、生长准则对图像进行准确分割,最后运用形态学操作消除细小瑕疵。针对模板图像和样本图像配准耗时过大的问题。本文结合图像的特点以及系统对实时性的要求,优化SURF算法,基于在缩放变换条件下特征描述符的不变性,利用缩放因子和变换矩阵的关系,降低程序的计算量,缩短配准时间。在对孔环进行定位、测量时,梯度霍夫算法在检测效率和准确度方面存在一些不足。本文通过预估目标区域相关参数去优化算法的参数,提高检测的准确度和精度,缩短检测时间。通过对焊盘凸起、凹陷、空洞,孔内毛刺,孔变形、过大、过小等缺陷的特征进行分析,设计相关的缺陷检测算法和定量评估标准,实现了这些缺陷的快速识别、智能判定。实验显示,系统可以实现对PCB板上孔环类缺陷进行快速识别和智能判定,并且准确率达98%,检测一张PCB的时间在8s内,基本满足工业检测的需求。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.000413
{DOI}: 10.27005/d.cnki.gdzku.2023.000413
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的微小振动测量技术研究
{Author}: 王威
{Tertiary Author}: 王科盛
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;微小振动测量;全息谱;振动可视化;三维振动
{Abstract}: 振动是机械设备工作状态的重要指标,对其进行监测和分析,有利于保证设备的正常运行以及发现潜在隐患。近年来,随着图像处理技术的不断发展和硬件成本的降低,基于机器视觉的振动测量成为了振动测量领域的研究热点。然而,现有研究仍存在一些不足:针对设备监测领域内的微小振动测量技术研究和工程实践相对较少。此外,大多数研究是针对结构上某点进行测量,没有充分利用机器视觉多点同步测量的优势,且难以反映结构整体的振动情况。本文聚焦于微小振动的测量和可视化技术,主要研究内容如下:(1)介绍两种基于机器视觉的振动测量算法,分别为基于光流法的振动测量和基于相位的振动测量,并利用工业相机、光源等设备搭建了视频采集系统。进行悬臂梁微小振动测量实验,结果表明两种方法均可用于微小振动测量。(2)针对传统旋转机械全息谱分析中传感器安装繁琐、需要至少两个传感器同步测量等约束性问题,提出了一种基于机器视觉的轴承座全息谱分析方法,实现全息谱分析一次视频完成。利用基于相位的振动测量方法同时获取水平和垂直方向的振动,简化了全息谱测量流程。以机械故障综合实验台为研究对象,获取了三种不同转子的全息谱。对传统通过传感器测量数据构建的全息谱和机器视觉全息谱进行了比较,并分析提出了两种方法的区别。(3)针对设备状态监测过程中,结构整体微小振动难以直接观测的问题,研究了微小振动可视化技术。介绍了两种视频放大方法,并对比了两者的放大效果。对悬臂梁和轴承座分别进行了微小振动放大实验,实验表明视频放大算法可以将特定频段的微小振动可视化,该方法可以用于结构模态振型检测和系统各向异性的判定。(4)针对二维振动测量在设备状态监测时,不能全面反映空间振动特性的问题,将光流法与双目视觉理论结合,实现了基于机器视觉的三维振动测量。通过悬臂梁微小振动测量实验,验证了该方法的可行性和准确性。最后,将该方法应用在医疗器械评价问题中,成功测量出了电动吻合器末端的空间运动轨迹。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004633
{DOI}: 10.27005/d.cnki.gdzku.2023.004633
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低光照图像增强方法研究
{Author}: 马琦钧
{Tertiary Author}: 程建
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 低光照图像增强;全卷积神经网络;Retinex分解;动态网络;深度学习
{Abstract}: 在夜晚、背光等低光照环境下,由于无法得到充足的曝光,导致成像设备拍摄的图像不仅存在严重的噪声,并且所包含信息量也极低。这不仅会影响人们的视觉体验和日常分享的需求,还会显著影响如目标检测、物体分类等计算机视觉任务的性能。低光照图像增强技术可以将欠曝光图像中的噪声降低、增强其光照强度、提高其对比度,有较高的研究和应用价值。近年来,低光照图像增强技术已经有了较大的发展,产生了以直方图均衡、伽马矫正和Retinex理论模型等为代表的传统方法和基于成对数据集、非成对数据集以及单图像数据集的深度学习方法。但是现有多数方法得到的结果仍存在对比度低、受噪声污染严重、细节缺失严重等问题;此外,很少有方法考虑到对于不同使用者其所期望的增强效果可能存在差异,这个低光照增强任务所具有的特点。针对以上问题,本文主要开展了以下工作:(1)基于全卷积神经网络的低光照图像增强。本文对全卷积神经网络的构成以及特性进行了详细的分析。基于Res-Net和U-Net构建了新的全卷积神经网络模型,并与目前主流的全卷积神经网络在低光照图像增强任务上进行了对比实验和分析,最终得出最适合本文任务的参数、损失函数以及网络。(2)基于图像分解的低光照图像增强。针对在极端情况下,大部分低光照图像增强方法的结果仍存在目标轮廓模糊、颜色昏暗、细节缺失以及色彩不连续的问题,本文在研究工作(1)的基础上根据Retinex理论模型构建了基于深度学习的图像分解模块、反射分量恢复模块以及亮度增强模块,分别实现将低光照图像分解为其反射分量与照度分量,对反射分量进行噪声去除以及颜色矫正,以及对照度分量进行增强。最后将恢复和增强后的反射分量与照度分量融合得到增强后的图像。通过分析并与同领域具有代表性的算法进行实验对比,验证了本文方法的有效性。(3)基于动态网络的低光照图像增强算法研究。针对使用传统深度学习方法进行低光照图像增强,无法同时满足不同用户主观需求的问题。本文设计了一个使用不同数据集分阶段训练不同参数的动态训练方法,实现了用户可以按照自身主观喜好对增强效果进行调节的动态网络模型。在不同数据集、不同亮度等级的图像上进行了主观、客观以及泛化性的对比实验,并且召集了志愿者对多种方法的增强结果进行评判,选出最符合其审美的图像。通过以上实验验证了本文的动态网络能满足不同使用者的主观喜好。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003166
{DOI}: 10.27005/d.cnki.gdzku.2023.003166
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的TFT-LCD显示异常缺陷检测
{Author}: 帅玲玉
{Tertiary Author}: 陈怀新
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: TFT-LCD;缺陷检测;自适应差影法;色度特征化;色偏检测
{Abstract}: 随着TFT-LCD行业突飞猛进的发展,显示缺陷检测是保证生产合格率至关重要环节。本文以基于机器视觉的TFT-LCD缺陷检测为研究问题,重点研究了TFTLCD点亮为复杂画面下显示异常缺陷和色偏缺陷等检测方法,主要研究工作与创新如下:(1)设计与搭建了基于机器视觉的TFT-LCD显示异常缺陷检测实验,提供了TFT-LCD显示异常缺陷数据采集及其分析平台。并针对实际生产过程中缺陷样品少、种类不齐、收集周期长等问题,模拟生成了两类TFT-LCD显示缺陷的样本数据:一是采用添加不同程度的畸变合成复杂画面缺陷数据集;二是基于混合色原理,添加不同程度的偏色量合成了色偏缺陷数据集,有效支撑了算法研究及测试评估。(2)针对TFT-LCD点亮为复杂画面下缺陷检测难、容易受环境影响等问题,提出了一种空间特征匹配与颜色校正的缺陷检测方法。首先,使用巴特沃斯低通滤波处理消除TFT-LCD阵列的周期性纹理干扰;其次,利用结合SURF与MSAC算法进行检测模板图与待检图的特征点配对与优化,通过计算投影变换矩阵得到空间精确配准的图像,采用自适应直方图匹配进行颜色匹配消除色彩背景的影响;然后,使用消除几何、色彩背景的差影信息的自适应局部阈值分割得到检测缺陷图。本方法的缺陷检测准确度达99.43%,平均时耗小于1s,具备工程应用性。(3)针对TFT-LCD色偏缺陷,提出一种色度特征化的色偏缺陷检测方法。首先使用CCD相机和色彩分析仪采集TFT-LCD图像和三刺激值,验证了TFT-LCD满足通道独立性和色品恒定性,对TFT-LCD进行色度特征化,建立色偏缺陷GOG模型;之后将待检图像输入GOG模型得到对应的三刺激值,再将三刺激值转换到颜色均匀的CIE-Lab颜色空间,使用CIEDE2000色差公式计算色差。本文的色偏缺陷检测准确率达95%,平均时耗小于107ms,提供了一种使用CCD的显示屏色偏缺陷检测方法。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004744
{DOI}: 10.27005/d.cnki.gdzku.2023.004744
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的工地异常行为检测系统设计与实现
{Author}: 卢俊
{Tertiary Author}: 周彦晖;黄武胜
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 工地异常行为检测;YOLOv5s;网络模型轻量化;HRNet
{Abstract}: 随着中国经济的迅速发展,建筑工业化进程正在加速推进,但每年因施工人员操作不规范而导致的安全事故仍频繁发生。传统的异常行为管控措施主要依赖人工方式,但由于其力度不足、效果不佳,监控相机所拍摄的大量图像未能得到有效处理,因此需要引入更加智能化且自动化的解决方案,提高安全管控的效率。近年来,智能信息技术的快速发展为异常行为的自动检测提供了有效支持。尤其是以深度学习为代表的计算机视觉技术能够实现海量图像数据的高效精确处理,被广泛应用于施工工地场景。然而,目前相关研究主要侧重于生产效率分析,较少探讨异常行为检测研究,且多局限于单个异常行为检测。同时,异常行为检测对情景特征、动作实时性等要素识别要求较高,也为其检测准确性带来了挑战。鉴于此,本文提出一种基于计算机视觉技术的工地异常行为检测方法,综合考虑了系统性、实时性和精确性等多方面,以提高检测效果。基于国内外研究现状,本文将施工现场的异常行为分为静态行为和动态行为两种类型。其中静态行为检测是针对施工人员的穿戴行为和工地烟火场景的检测,动态行为检测则是针对施工人员摔倒和翻越栏杆行为的检测。本文采用监控视频的方式对上述两类异常行为进行检测,主要工作内容如下:(1)采用目标检测算法实现静态行为检测。针对已有开源数据集不适用于实际现场环境的问题,本文与碧桂园相关工程建设单元合作,利用工地监控录像获取图像数据,并通过调整亮度、镜像翻转及左右旋转等数据增强方式将原始数据扩增5倍,并进一步提出了一种基于YOLOv5s改进的轻量目标检测模型YOLOv5sMobile Net V3。经过实验数据验证,YOLOv5s-Mobile Net V3模型在保持精度基本不变的前提下,具备更快的推理速度。改进后的模型大小仅为7.4MB,参数量比原模型减少了50%,FPS提升了3.6倍。YOLOv5s-Mobile Net V3模型的检测性能优异,在静态行为检测方面具有较好的表现,能够满足实际工地应用需求。(2)采用HRNet和BiLSTM实现动态行为检测。首先自建了工地行为数据集,利用HRNet模型提取骨骼关键点位置将其转换成CSV格式数据集。为减轻模型的计算复杂度,本文通过基于关键帧的方法从所有骨骼点数据中提取有效的动作数据样本,并进行数据预处理操作,如删除冗余关节点、补充缺失关节点等。经特征提取后,采用SVM、Random Forest、XGBoost、LSTM及Bi LSTM构建了动态行为检测模型。通过实验对比发现,Bi LSTM网络模型在自建数据集中表现出较高的精度,能实现动态行为的实时检测。(3)工地异常行为检测系统设计与实现。基于上述研究内容,本文设计并开发了工地异常行为检测系统,对系统进行详细的需求分析后把系统分为多路视频处理模块、静态行为检测模块、动态行为检测模块和离线训练模块,并对四个模块进行详细介绍。最后,完成该系统的实现并对功能和界面进行展示。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.002385
{DOI}: 10.27684/d.cnki.gxndx.2023.002385
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 嵌入式智慧工地安全帽检测系统设计与实现
{Author}: 焦双健;王超
{Author Address}: 中国海洋大学工程学院;
{Journal}: 工业安全与环保
{Year}: 2023
{Volume}: 49
{Issue}: 04
{Pages}: 26-28
{Keywords}: 嵌入式系统;计算机视觉;智慧工地;安全帽检测
{Abstract}: 针对施工作业人员不佩戴安全帽的问题，设计了一种基于计算机视觉的嵌入式智慧工地安全帽检测系统并进行了实用性的算法改进，解决了人力检测效率低下、标准不一的问题，同时提升了在目标检测领域小目标检测的精度。介绍了人工和传统算法在安全帽佩戴监管方面的弊端以及嵌入式系统的优势，详细介绍了算法优化的方法以及本系统的实验结果。
{ISBN/ISSN}: 1001-425X
{Notes}: 42-1640/X
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz3Z0wiFNi9sHwogLJNjQmUOEjs-MfMv3JBzT5n-7TPTVlK_G1pNCfHLsjv1ifDFoY4F00Hjw6UEJRSsuNkNY3sZoH1bOhxfsZQdkgMTFv016Ll-hHuJn_4lttGTh3SBr5ceXPmHXoRpF7qMumHruqPibHMLqKyK5KMszC5kSN-6TS_cSlDSrytBPHojDZ6msE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的铝型材表面缺陷检测方法研究
{Author}: 张鹏展
{Tertiary Author}: 邓辉文;邢镔
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;缺陷检测;目标检测;铝型材
{Abstract}: 铝型材作为一种常见且重要的金属材料,在国防、航天、建筑、汽车、电力等领域具有广泛应用。然而,在生产过程中,部分铝型材表面会不可避免地产生缺陷,影响产品质量与安全性。因此,在生产线上及时有效地检测出带有缺陷的铝型材产品是非常必要且具有挑战性的工作。传统的检测方法存在诸多局限性。例如,人工肉眼方法不但效率低下,并且易受主观因素干扰,图像处理方法则需要大量的先验知识和参数调节,难以适应不同类型和程度的缺陷。近年来,研究人员通过将深度学习方法应用于计算机视觉领域,取得了突破性进展。同时,深度学习方法也被引入到铝型材表面缺陷检测当中。但是,在工业生产环境下,实时检测速度要求越来越高,并且由于铝型材缺陷存在目标细小且不明显等问题,需要网络结构复杂且精度高的检测模型对其进行检测,这与工业现场设备的算力和存储能力有限之间存在着矛盾。针对这些问题,本文将深度学习技术应用于铝型材表面缺陷检测任务当中,并围绕基于骨干网络替换的模型轻量化、基于加强特征提取网络改进的模型优化以及基于损失函数的模型优化几个方向进行研究,使得模型满足缺陷检测任务的要求,并利用前后端框架,开发出相应的检测工具。本文的具体研究内容如下:(1)检测模型的选取与轻量化研究。本文首先对目标检测模型在铝型材表面缺陷检测任务中的应用进行分析和思考,选取了三种具有代表性和高精度的目标检测模型作为铝型材缺陷检测研究的候选模型,并根据实验结果选出了综合性能最优的YOLOX检测模型。其次针对当前检测模型存在计算量大、参数量多且在铝型材表面缺陷检测任务中的实时性不高等问题,本文在尽量保证YOLOX模型精度的前提下,提出了一种轻量化改进方案,利用截取后的Mobile Net系列轻量化网络作为YOLOX模型的骨干网络,以提高模型的检测速度,降低模型资源消耗。实验结果表明,在融入Mobile Netv2网络后,所得到的轻量化检测模型具有最佳效果。(2)模型识别效果研究。针对小目标缺陷难以有效识别和定位的问题,本文将加强特征提取网络进行改进,分别将不同轻量化注意力机制融入加强特征提取网络的FPN+PAN结构中,增强检测模型对铝型材表面擦花、脏点、喷流和漆泡等小目标缺陷类别的关注度,在保证模型大小和检测速度的情况下提升其识别精度,并通过实验比较选出ECANet注意力机制为最佳选择。(3)模型损失函数优化。针对模型在训练过程中负样本过多,导致模型训练困难的问题,本文在模型检测头中引入Focal Loss损失函数,在训练过程中,提升模型对关键缺陷特征的学习,降低背景负样本对模型训练的影响,同时提高难分类样本的训练权重,使模型在学习中聚焦于容易误检的样本,提升模型的训练效果。为了验证本文所提出的改进模型在铝型材表面缺陷检测任务中的有效性,本文在相同数据集上,将其和体量相似的YOLOv5m模型进行了横向对比实验。实验结果显示,在检测速度、模型计算量和模型参数量略微领先的情况下,本文所提出的检测模型在平均精度(m AP)指标上相比于YOLOv5m检测模型提高了5.16%,验证了本文所提出的改进模型的有效性。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.001006
{DOI}: 10.27684/d.cnki.gxndx.2023.001006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于单目视觉目标检测的车辆测距模型及算法研究
{Author}: 郑荣天
{Tertiary Author}: 李毅超
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 单目测距;目标检测;计算机视觉;先进驾驶辅助系统
{Abstract}: 在驾驶环境中具备实时准确的目标距离测量能力是自动驾驶的关键技术,有各种传感器可用于距离测量,视觉传感器因为成本低廉且信息丰富,可作为激光雷达等高成本技术的替代方案完成距离测量任务。然而现有视觉方案需要大量的数据和计算资源,且稳定性和落地能力不足,虽然部分方法准确率高,但有更高的设备要求和复杂性。因此本文以深度学习神经网络算法和传统机器视觉测距技术为研究对象,提出一个结合深度学习及传统视觉技术的两阶段测距模型,在真实驾驶环境中收集视觉信息,预测前方车辆距离并提高距离估计的精度和稳定度。本文主要的工作内容如下:(1)构建了Dual-YOLO神经网络架构,可以对车身及车头尾一同检测。Dual-YOLO利用Kalman滤波和ROI算法对检测目标进行处理,在保证速度的情况下,有效减少了测距结果的抖动,提升了车辆目标位置预测精度。(2)提出了动态修正的相机几何测距算法,配合神经网络构成两阶段测距模型TSDistance,在基于车宽的先验知识上,关注相机俯仰角对测距的影响,进行了单点测距和车宽测距的差值计算,补偿相机姿态角的变化,减少了车辆颠簸导致的测距误差,提高了测距模型的鲁棒性。(3)采集驾驶环境中的视觉及雷达信息,进行数据整理及拆分,利用本文提出的TSDistance模型对车辆目标进行测距并分析其性能和误差,验证了本文基于单目视觉目标检测的车辆测距模型在实际驾驶场景下的精度和运行效率。本文提出的测距模型及内部算法,结合了深度学习和传统视觉技术的优势,并通过优化目标检测算法及动态修正外参数的技巧,解决测距结果不稳定的问题,为未来自动驾驶中车辆测距任务提供了一个可行的思路。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003227
{DOI}: 10.27005/d.cnki.gdzku.2023.003227
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于优化DeepSORT的多目标视觉跟踪方法研究
{Author}: 郑繁亭
{Tertiary Author}: 邢关生
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多目标跟踪;DeepSORT;YOLOX;行人重识别;注意力机制
{Abstract}: 随着深度学习的发展以及算力水平的提升,基于深度学习的多目标视觉跟踪算法发展迅速,并广泛用于行人检测与跟踪领域,具有较高的学术研究与应用价值。本文面向复杂场景下的行人多目标跟踪问题,基于目标检测理论以及目标跟踪理论提出了一种改进YOLOX与改进DeepSORT相结合的多目标跟踪算法,具体研究内容如下:(1)提出一种基于改进YOLOX的目标检测算法。首先,针对目标检测网络在复杂背景以及遮挡等情况下表现不佳的问题,本文在对比了多种注意力机制后,在YOLOX主干网络中嵌入CA注意力机制来增强网络的特征提取能力,从而提高了在复杂环境下的行人目标检测精度;其次,针对正负样本不均和网络收敛过慢等问题,本文采用Focal Loss损失函数替换原YOLOX的交叉熵损失函数,加强网络对难分类样本的侧重程度;采用DIOU损失函数替换原YOLOX的IOU损失函数,提升网络的定位精度及收敛速度;最后,针对网络对小目标检测效果差的问题,本文在YOLOX原网络三尺度预测层的基础上增加了一个大尺度预测层,从而能够输出更细致的空间和位置信息,提高网络对小目标的检测能力。(2)提出了一种改进的DeepSORT算法。DeepSORT通过加入行人重识别网络WRN的方式,有效的增强了算法的跟踪性能,降低了身份编号更换的次数。但是WRN存在参数量大、性能低等问题。针对这些问题,本文基于Ghost Net的主要思想和特征金字塔FPN设计了一种新的行人重识别网络WRN-Ghost,并使用行人重识别数据集Market1501完成了对WRN-Ghost的训练,最后用训练完成的WRNGhost模型替换原DeepSORT的行人重识别网络,有效增强了DeepSORT算法对行人表观特征的提取能力,进而提高了算法的精度。(3)最终,用改进YOLOX算法优化改进DeepSORT的检测网络,得到一种新的行人多目标跟踪算法。然后通过进行消融实验,验证了本文算法的性能以及改进策略的有效性。实验结果表明,本文设计的行人多目标跟踪算法与原算法相比,检测准确率和速度均有明显提升,并且能够较好的处理因遮挡产生的身份编号更换等问题,即使在复杂的环境下也能保持较好的跟踪效果。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2023.000566
{DOI}: 10.27264/d.cnki.gqdhc.2023.000566
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的6自由度机械臂路径规划研究
{Author}: 杜畅
{Tertiary Author}: 杜亚江;李宗刚;白顺平
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机械臂;目标检测;MobileNetV3-YOLOv5s算法;路径规划;RRT-connect算法
{Abstract}: 随着当代科学技术的不断进步和发展,工业机械人已广泛应用于各个领域。而今,面对越来越复杂的作业环境,装配制造业对工业机器人执行任务的效率、精度和稳定性提出了更高的要求。本论文以6自由度机械臂为研究对象,对基于机器视觉的机械臂路径规划问题展开研究,主要内容如下:第一,搭建了基于视觉的机械臂实验系统。根据机械臂结合机器视觉完成自主路径规划的需求,通过机械臂本体、控制柜、深度相机等硬件及ROS系统软件搭建了机械臂实验平台,完成了ROS系统下对机械臂模型的创建,并对机械臂与深度相机完成了标定实验,得到机械臂基坐标系与相机坐标系间的转换关系。利用D-H参数法建立了机械臂运动学模型。第二,给出了一种基于改进的YOLOv5s网络结构的目标检测算法,有效地提高了系统的响应能力。针对YOLOv5s网络结构计算量较大导致系统响应能力不强的问题,通过将轻量级网络Mobile Net V3的主干网络代替CSPDarknet作为算法的主干特征提取网络,得到了Mobile Net V3-YOLOv5s轻量级网络,并通过自制数据集展开训练检测,比较了两类网络模型的性能,改进后的网络模型大小大约变为了原来的50%,检测速度大约提升27%。再将改进的算法模型应用部署到机械臂实验平台上进行测试,测试结果表明改进后的Mobile Net V3-YOLOv5s算法不仅减少了网络的计算量,优化了算法模型大小,提升了整个系统的响应性能,同时能够保证机械臂对物体的准确识别和定位。第三,给出了一种改进型RRT-connect算法,提高了障碍物环境中机械臂路径规划速度,并缩短了路径长度。针对RRT-connect算法扩展方式随机性较强、步长固定的问题,通过将起始点与目标点连线的中间位置以一定概率(20%)作为每次随机采样点,引入动态步长对RRT-connect算法进行改进,得到了RRT-connect改进算法。通过仿真实验结果表明,改进后算法规划时间大约减少了28%,所规划路径长度大约缩短了22%,证明了所提算法是有效的。再将两种算法应用机械臂实验平台上验证,改进后算法规划时间大约减少了27%,机械臂作业时间大约减少了23%,与仿真结果基本一致,证明了改进算法应用在机械臂实验平台上的适用性和优越性。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2023.001145
{DOI}: 10.27205/d.cnki.gltec.2023.001145
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人脸图像深度特征学习与解耦研究
{Author}: 李艳德
{Tertiary Author}: 路永钢
{Publisher}: 兰州大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 深度学习;遮挡人脸识别;人脸表情识别;注意力机制;特征解耦;多模态学习
{Abstract}: 人脸蕴含着包括种族、肤色、性别、年龄、身份和表情等要素在内的丰富的个人信息,是身份辨识和情感表达的主要渠道,在社会人际交往中扮演着重要角色,也在人机交互中发挥着不可替代的重要作用,具有重要的研究价值和广泛的应用前景。深度特征学习与解耦是当前人脸图像特征学习的主流方法,在包括人脸识别、人脸表情识别、人脸年龄评估、伪造人脸识别和人脸属性编辑等方向都取得了很大的进展。近年来,随着人脸应用需求的提升和深度学习技术的进步,解决实际应用中的复杂挑战成为了研究主流。针对不同的人脸应用挑战,本文提出了一系列人脸图像深度特征学习与解耦方法,具体介绍如下:在第三章中,提出了基于裁剪和注意力机制的口罩遮挡人脸图像特征学习方法。新冠疫情的大流行使人们意识到戴口罩是保护自己和他人免受病毒侵袭的最有效的方法之一,这对传统的人脸识别系统造成了巨大的挑战。当前的口罩遮挡人脸识别存在两个主要问题,一是人脸检测系统难以准确检测戴口罩的人脸图像,二是嘴部和鼻子周边的面部特征被严重破坏,人脸图像有效特征显著减少。本文提出基于裁剪的方法来高效地去除遮挡特征的负面影响,探索了口罩遮挡人脸图像的最优裁剪位置,省去了遮挡检测所需要的时间和计算资源的开销。同时提出了基于注意力机制的方法来聚焦眼部周边特征的学习,赋给眼部周边有效特征更大的权重。最后,融合上述两种方法,在三种不同的口罩遮挡人脸识别场景下均取得了优异的表现。在第四章中,提出了基于多模态对比学习的面向自然场景的人脸表情特征学习方法。自然场景下的人脸表情识别面临着遮挡和头部姿势变化等外界干扰问题,并且标注者的主观认知能力不一、低质量的人脸图像和复合表情等原因导致了严重的标注歧义问题。本章提出融合卷积神经网络和Vi T网络的混合学习架构,该架构充分利用卷积神经网络的局部特征学习能力和Vi T网络的全局特征学习能力。具体地,本章设计了一个特定于表情识别的编码器,其中的混合注意力可以同时表征用于表情分类的独热编码标签和文本标签。为缓解上述的不确定性外界干扰问题,提出了多粒度特征融合的方法来学习不同粒度的特征。更重要的是,通过监督图像特征和文本特征之间的余弦相似度,使得图像特征同样具有不同表情在文本语义空间中的关联性,以此缓解标注歧义问题。在多个公开数据库上的实验结果显示,该方法对标注歧义图像展现了很好的鲁棒学习能力,并且取得了优异的表情分类表现。在第五章中,提出了基于双通道特征解耦的身份信息无关的人脸表情特征学习方法。人脸身份特征和表情特征非线性纠缠在一起,导致表情识别问题具有两个内在挑战,即不同人的同种表情图像之间差异较大,同一个人的不同表情图像之间的差异很小。为解决上述挑战,本章提出双通道交替训练方法。通过构建同一个人的不同表情图像对和不同人的同一表情图像对,交替训练孪生网络。在训练过程中增加不同表情特征之间的距离,同时减小同种表情特征之间的距离。此外,为降低被身份特征污染的表情特征对表情识别带来的负面影响,本章将面部特征解耦为身份特征、表情特征和共享特征三部分。然后,基于希尔伯特-施密特独立性准则精心设计了一个对比学习损失函数,进一步增大不同表情特征之间的距离,减小同一种表情特征之间的距离。最后,在几个公开的表情识别数据库上验证了该方法的优越性。综上所述,本文针对口罩遮挡人脸识别和人脸表情识别研究中的特征损坏、标注歧义和特征纠缠等问题展开了深入的研究。通过灵活设计网络结构和损失函数,实现了针对性的深度特征学习。大量的实验结果表明,本文提出的方法可以有效提高多个应用背景下的人脸图像深度特征学习能力。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2023.000011
{DOI}: 10.27204/d.cnki.glzhu.2023.000011
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工业钢带表面缺陷检测
{Author}: 贺智勇
{Tertiary Author}: 谢刚
{Publisher}: 太原科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 钢带;缺陷检测;YOLO;Swin Transformer;注意力机制
{Abstract}: 钢带是一种以碳钢为原材料的工业精密制品,常用于牵引构件、捆扎货物,其质量好坏与工业安全息息相关,缺陷检测是避免其残次品流入市场的一道重要关卡。目前,基于机器视觉的缺陷检测主要依赖于人为设计的图像特征,无法实现多类缺陷的通用性,而且模型的准确度和鲁棒性较差,具备较高的错判率,难以满足现代工厂自动化产线的生产需求。本文充分调研工业钢带图像缺陷机理和机器视觉相关算法理论,旨在提高检测模型性能,使之更加适配工业生产。为此本文基于实际工业钢带缺陷图像开展研究,主要研究内容如下:(1)本文分析工业钢带数据图像特点,从钢带不同缺陷类型开展研究,提出一种基于改进YOLO V5的工业钢带表面缺陷检测模型。针对工业钢带图像存在小缺陷占比高、特征信息难以提取等特点,本文在YOLO V5S骨干网络中引入SE(Squeeze-andExcitation)注意力机制,来强化模型对缺陷重要信息的提取能力,解决特征信息损失较大问题;在此基础上分析YOLO特征金字塔结构,通过增大网络的检测区域来实现四尺度特征提取,加强模型深层与浅层语义信息的融合;并通过k-means++算法分析钢带图像,重新设计模型锚框大小,解决部分小目标检测困难问题;最后结合工业钢带数据集开展了实验对比,结果显示改进模型在保证检测速度的同时有效地提升了小目标的检测精度。(2)为进一步提升缺陷检测模型的准确度和检测效率,使之适配精密工厂制备需求,本文融合Swin Transformer模块进行进一步优化。首先引入滑动注意力机制,通过滑动窗口交互,让信息在相邻的窗口中进行传递,达到了一种全局建模的效果;之后采用新型上采样算子,使模型具备较大感受野,能更好地利用周围信息,而且计算参数量少;同时为了保证检测网络的检测效果,还引入自适应空间特征融合(ASFF),对特征金字塔结构输出的3个水平特征图分别进行加权特征融合,充分利用不同尺度的特征,通过设置可自适应学习的参数来抑制模型在训练过程中由于梯度反传而导致的不一致性;最终在数据集上的结果显示,模型在牺牲较少检测速度的情况下,均值平均精度提高了7个百分点,达到较高的缺陷检测效果。综上所述,本文以工业钢带为研究目标,基于机器视觉开展研究工作,针对不同应用场景设计出相应的检测模型,具有一定的理论价值和实际意义。
{URL}: https://link.cnki.net/doi/10.27721/d.cnki.gyzjc.2023.000675
{DOI}: 10.27721/d.cnki.gyzjc.2023.000675
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv7的跌倒检测算法研究
{Author}: 兰布莉
{Tertiary Author}: 李春树
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 跌倒检测;YOLOv7;注意力模块;损失函数;深度可分离卷积
{Abstract}: 老年人口的不断增多,导致了我国的老龄化问题日趋严峻,老年群体的健康问题也随之引起了人们的广泛关注。经过调查,意外摔倒是影响老人健康的重要因素之一,如果独居老人在摔倒之后,能在最短的时间内得到及时的救助和治疗,可以最大限度地保证他们的生命安全。所以,对老年人跌倒检测问题的研究具有重要意义。论文主要对基于计算机视觉的跌倒检测方法进行研究。由于YOLOv7算法是目前目标检测算法中检测速度最快并且检测精度较高的算法之一,所以本文基于YOLOv7目标检测算法,针对该模型计算量大影响检测速度,跌倒检测时背景信息冗余影响检测精度的难点,提出了一种更加轻量化且精度更高的跌倒检测网络模型。具体改进如下:(1)针对背景因素干扰问题,采用添加注意力机制模块的方法来解决。在跌倒检测算法中,通过引入ECA注意力机制模块,使得算法更集中于人物跌倒行为,获得更多相关的细节信息,忽略不相关的背景信息,达到提高网络模型检测精度的目的。(2)针对YOLOv7损失函数纵横比表现模糊问题,将边界框回归的向量角度损失与距离损失相结合,采用SIoU损失函数替换原有的CIoU损失函数,减少损失函数自由度,从而有效提高模型训练的速度与推理的准确度。(3)针对模型计算量大影响检测速度的问题,对YOLOv7网络模型进行轻量化改进。将深度可分离卷积与FReLU激活函数结合组成新的卷积模块,对基础网络模型中的ELAN模块和ELAN-W模块进行改进,在计算量减少的同时保证检测精度的有效提升。实验结果表明,改进后的YOLOv7模型相较于基础YOLOv7模型的浮点运算量(FLOPs)减少了 42.1%,平均精度均值(mAP)从92.1%提升到了 93.3%,检测速度从之前的87FPS提升到了 91FPS,说明改进后的网络模型能够更好地应用于老年人跌倒检测任务中。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2023.001505
{DOI}: 10.27257/d.cnki.gnxhc.2023.001505
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的复杂道路场景下遮挡中小目标检测算法研究
{Author}: 苏山杰
{Tertiary Author}: 冉险生
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视觉感知;复杂道路场景;遮挡中小目标;特征融合;注意力机制
{Abstract}: 近年来,随着汽车智能化驾驶技术的不断深入研究,基于深度学习的复杂道路场景目标检测技术得到了迅猛发展。但因受到目标尺度变化大、遮挡、复杂背景、光照强度变化、复杂天气状况等诸多因素的影响,导致模型检测识别的漏检率和误检率较高,难以满足检测任务的需求,且现阶段算法模型存在对于复杂场景适应能力弱、鲁棒性较差,模型不够轻量化等问题。针对上述问题,本文以深度学习目标检测算法为依托,提出了能适应复杂道路场景的遮挡中小目标检测算法,结果表明:所改进算法具有较好的检测识别性能,同时又平衡了模型的计算效率和硬件成本。主要进行了以下三部分的研究工作:(1)针对交通场景的目标检测数据集大多为国外开源的数据集,国内公开数据集较为缺乏的问题,以车载行车记录仪为依托,构建了一个新的复杂道路场景数据集CQTransport,包含18091张图像样本。数据集构建过程中进行了数据采样、严格的筛选与标注,保证了数据集的数量与质量的提升。对图像进行数据增强,解决了样本不均衡问题,并使得CQTransport场景多样化,在训练过程中提升模型的泛化性能。(2)针对复杂道路场景下遮挡目标、中小尺度目标漏检率、误检率较高的问题,提出了基于自适应特征融合机制的改进算法。在YOLOv5s基准模型中融入改进的相邻尺度特征有效融合模块,缓解了模型特征融合过程产生的负面影响;提出了多尺度宽感受野自适应融合模块,增强模型对上下文信息的有效提取与利用;并通过融入注意力机制与改进损失函数、增加预测尺度等方法提升模型的检测性能,改善了道路场景中小目标、遮挡目标的漏检率和误检率高的问题。通过多个数据集实验结果表明,提出的改进方法有效提升了复杂道路场景下中小目标的检测精度,并具有较好的鲁棒性。其中改进算法算法在BDD100K、Udacity、Cqtransport三个数据集上分别提升了6.7%、4.9%、7.9%的m AP。(3)针对目前环境感知算法在移动端设备和嵌入式设备的部署需求,提出了多尺度轻量级的道路场景目标检测算法。以YOLOv5s和YOLOX-s算法为基准模型进行了轻量化改进,首先在主干网络中融入Ghost Net模块实现参数量和计算量的削减;针对融合Ghost Net模块后主干网络特征提取不充分的问题,进一步提出改进策略,通过在网络模型加入Vo VGSCSP、Sim AM、ODConv、SPD-Conv等高效的方法提升了模型的性能。在BDD100K数据集上改进算法检测速度分别达到了126.6帧/s、117.6帧/s,更能满足在移动端设备的配置条件,同时提升了复杂道路场景下中小尺度目标、遮挡目标的检测效果,有效解决了智能驾驶环境感知算法部署难,性能低等问题。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2023.000698
{DOI}: 10.27671/d.cnki.gcjtc.2023.000698
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的车门内拉手表面缺陷检测技术研究
{Author}: 袁雨鑫
{Tertiary Author}: 曾勇
{Publisher}: 盐城工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;车门内拉手;缺陷检测;语义分割;DeeplabV3+;RobotStudio
{Abstract}: 随着我国汽车市场需求的激增,汽车零部件产业也得到迅速发展。作为汽车车门的重要组成部分,车门内拉手在生产过程中必须进行质检环节,当前仍依靠人工目视检测来实现,这种方式存在精度低、稳定性差以及成本高等问题。因此,本文提出了一种基于机器视觉的车门内拉手表面缺陷检测系统。本文详细研究了检测系统的关键部件选型、车门内拉手图像采集、车门内拉手表面缺陷检测算法以及工业机器人集成应用。最后在Robot Studio软件中建立了实际检测环境,对基于机器视觉的车门内拉手表面缺陷检测系统进行仿真测试。本文完成的主要工作内容如下。(1)根据基于机器视觉的车门内拉手表面缺陷检测系统的设计需求,设计了整体的硬件系统和软件系统方案。硬件系统方案的设计全面考虑精度、效率、稳定性和操作性等因素,对相机、镜头、光源、机器人和光电传感器等关键部件进行选型和集成设计。软件系统基于硬件系统设计,结合自动化车门内拉手视觉检测流水线的工作需求,给出了检测系统运行流程方案。(2)针对车门内拉手表面存在曲面和拥有高反射性的特点,带来采集图像中缺陷特征被覆盖的问题,通过对机器视觉常规的照明方式和球形光源的光照特性进行分析,提出了采用球形光源正向照明和降低采集表面夹角的方案来获取无干扰的图像。通过实验对比发现,该方案能够有效抑制局部亮度饱和的情况出现。最后,为了避免算法在训练过程出现过拟合的情况,将常规数据增强方法和滑动窗口算法相结合,实现了自动化数据增强,完成检测数据集制作。(3)车门内拉手表面缺陷具有随机性强、尺度变化大和同背景区域相似度高等特点。这些特点给视觉检测算法带来图像特征不明显和检测精度低等问题。本文在对比了语义分割网络中编码器-解码器架构和特征金子塔架构的特点之后,得出兼具编码器-解码器架构和特征金字塔的语义分割网络具有高效地利用多尺度特征信息、较强的特征表示能力和可拓展性强等优点,因此采用Deep Lab V3+网络作为检测算法的基础框架。针对传统的Deep Lab V3+网络存在缺陷检测精度不高的问题,提出将Conv Ne Xt模块作为主干特征提取网络,通过反向瓶颈加残差连接的设计来实现图像特征的提取,从而提高网络对于缺陷特征的解析能力。同时,提出了引入密集连接的方式对ASPP(空洞空间金字塔池化网络)模块进行改进,以提高对多尺度特征的提取效果,避免ASPP空洞卷积导致的特征遗漏。通过消融实验表明,改进的Deep Lab V3+网络和传统网络相比,m Io U(平均交并比)和MPA(平均像素精度)分别提升13.9%和11.5%,能够达到92.7%和95.3%,同时检测速度达到25张/s。(4)完成了检测系统的仿真。首先在Qt Creator上完成上位机软件的开发,上位机作为检测系统服务端采用多线程技术设计,其内部集成了相机采集画面显示、数据存储、检测算法、通信等模块。然后,在Robot Studio中建立仿真工作站,其作为检测系统客户端用于模拟实际检测场景,通过Smart组件库、I/O信号和RAPID程序,完成通信、夹具和输送线等模块的设计。最后对仿真工作站和上位机软件进行仿真验证。经过测试,检测系统运行稳定,在工作过程中未发生任何报警情况,验证了本文提出的检测系统是可行的。本研究课题所设计的基于机器视觉的车门内拉手表面缺陷检测系统,结合了深度学习算法和机器人集成应用技术,经过仿真验证,可以有效提升车门内拉手表面缺陷检测的精度和稳定性,具有广泛的应用前景。该系统不仅可应用于传统车门内拉手生产领域,还可为智能化制造提供技术支持,对于推进工业自动化进程具有重要意义。
{URL}: https://link.cnki.net/doi/10.44381/d.cnki.gycit.2023.000099
{DOI}: 10.44381/d.cnki.gycit.2023.000099
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer与MAE的多模态医学图像融合方法研究
{Author}: 张炯
{Tertiary Author}: 王丽芳
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学图像融合;Transformer;特征耦合;交叉尺度注意;MAE
{Abstract}: 由于具有不同模态医学图像的成像原理各异,因此对不同器官或组织信息表征效果也不同,如CT图像对于骨骼以及肝脏等器官成像效果较好,但在不同软组织间的对比度表现较差,而MR图像具有较高分辨率的软组织细节信息,可以较好的反映脑部和脊髓中的血液和代谢变化,但在空间分辨率方面不如CT。这些模态的医学图像各有其优势和局限性,单一模态图像很难包含当前病灶区域全部的关键信息。然而,多模态医学图像融合技术通过综合不同模态医学图像之间的互补与冗余信息,有效地解决了单一模态成像对于人体组织器官信息的局限性,提高医学影像信息的利用效能,有利于医疗工作人员实现更准确的诊断与治疗。本文通过深入研究多模态医学图像融合理论、Transformer网络结构和MAE掩码预训练策略,明确了其存在的问题并进行了改进,主要内容如下:针对现有的基于深度学习的多模态医学图像融合方法中存在的全局特征表示不足的问题,提出了一种基于局部全局特征耦合与交叉尺度注意的医学图像融合方法。该方法由编码器,融合规则和解码器三部分组成。编码器中采用并行的CNN和Transformer双分支网络分别提取图像的局部特征与全局表示,在不同尺度下,通过特征耦合模块将CNN分支的局部特征嵌入到Transformer分支的全局特征表示中,最大程度的结合互补特征;同时引入了交叉尺度注意模块来有效的利用多尺度特征表示。该编码器提取待融合原始图像的局部、全局以及多尺度特征表示,经过融合规则融合不同源图像的特征表示后再输入到解码器中生成融合图像;采用图像重建任务训练编码器-解码器网络,避免了大量预配准医学图像数据集的需要。针对局部全局特征耦合与交叉尺度注意力的多模态医学融合方法中存在的训练任务较为简单,网络无法获取高水平的特征表示来满足图像融合任务需要的问题,提出一种基于MAE预训练的多模态医学图像融合方法。该方法分为预训练和融合两阶段,预训练阶段采用MAE掩码重建任务来训练编解码器网络;在融合阶段中,设计了一种基于自注意力的特征融合模块代替手工融合规则,并针对多模态医学图像融合任务进行网络参数的微调。最终获取完整的图像融合模型,采用编码器提取源图像特征,特征融合模块将不同图像的特征进行合并,最后通过解码器重建获取融合图像。针对上述提出的两种网络,使用Py Charm和Matlab分别进行了相关的实验,并与最新提出的图像融合方法进行对比实验,得到的融合结果在客观指标和主观视觉方面均有较好表现,表明了以上工作的有效性。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000501
{DOI}: 10.27470/d.cnki.ghbgc.2023.000501
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件高精度尺寸测量方法研究
{Author}: 赵延
{Tertiary Author}: 宋涛;宋千
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;尺寸测量;远心标定;亚像素边缘检测;边缘拟合
{Abstract}: 随着工业化水平的提升,工厂对于产品的检测要求越来越高,人工检测已经没办法达到要求,基于机器视觉的尺寸测量效率高、检测精度高,并且能够实现在线测量,尤其是对于小型工件的测量,其优势比人工检测更为突出。当前机器视觉的尺寸测量技术已经逐步应用工业生产中,但仍然存在一些棘手的问题,如测量精度还有待提高,无法满足精密测量的需求,因此实现高精度的工件尺寸测量具有重要的研究意义及应用价值。基于以上背景,展开了基于机器视觉的高精度尺寸测量技术的研究,主要研究内容有:
(1)设计了远心镜头高精度测量的硬件实验平台。根据对应的实验需求,对光源、照明方式、相机选型、镜头选型以及标定板设计进行了详细的选型分析,并结合工件高精度测量的需求,选取了MV-CE060-10UC海康工业面阵相机、MD65-05F50远心镜头、3×3的实心圆阵列标定板以及方形平行发光二极管(Light Emitting Diode,LED)可调背光光源等硬件,搭建了相应的硬件实验平台。
(2)针对传统的标定方法不适用于小视场远心系统的问题,提出了基于仿射变换的远心系统小视场标定方法和基于定制九点标定板的小视场标定方法。第一种标定方法通过标定板仿射变换的方式满足小视场标定要求,标定结果用于实现二维亚像素边缘测量;第二种标定方法通过定制九点标定板满足小视场标定要求,标定结果用于一维亚像素边缘测量。通过标定实验可得,两种方法能够实现远心系统的小视场标定。针对图像受噪声干扰的问题,为了满足高精度尺寸测量的要求,需对图像进行预处理,采用了基于插值法优化的局部自适应对比度增强算法(Adaptive contrast enhancement,ACE),通过内插法以及外插法优化ACE算法,结合可视化结果评估结果可得,本文算法图像质量更高,视觉效果更好,具有可行性。
(3)针对传统的像素级边缘轮廓提取算法无法满足工件高精度尺寸测量的问题,提出了工件目标轮廓亚像素细化及高精度定位算法。通过改进的亚像素边缘检测算法分别在工件一维和二维边缘实现定位和测量。一维测量方式主要是基于双三次插值法的卡尺法进行测量;二维方法主要是在像素级轮廓提取的基础上,利用改进的高斯拟合法对亚像素边缘轮廓进一步提取并测量。通过对比实验表明,一维测量精度可达到±0.01mm,二维测量精度可达到±0.02mm,满足可接受的误差范围,测量精度和效率都满足工件高精度尺寸测量的要求。
(4)针对轮廓存在毛刺、边缘突触等问题,介绍了一种基于随机抽样一致(RANdom SAmple Consensus,RANSAC)算法与最小二乘法结合的改进亚像素轮廓拟合算法。该方法通过RANSAC算法对存在的较大离群点集进行筛除,并采用基于Tukey权重函数最小二乘法对直线和圆进行拟合,实现了对于亚像素边缘轮廓的拟合工作;针对实际边缘分割问题,采用基于Ramer多边形递归算法的圆轮廓循环并归算法,解决了Ramer算法仅适用于直线轮廓分割的问题,实现了工件轮廓分割为直线轮廓和圆轮廓的工作。通过实验表明,本文算法能够实现圆弧轮廓和直线轮廓的工件亚像素轮廓的分割。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2023.001292
{DOI}: 10.27753/d.cnki.gcqgx.2023.001292
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的吸烟行为分析方法及系统
{Author}: 胡国昌;王诗太;邓俊芳;龙涛;李轩;赵俊伟;华辰凤;杜文;刘金云
{Author Address}: 湖南中烟工业有限责任公司技术中心;深圳爱莫科技有限公司;中国烟草总公司郑州烟草研究院;
{Journal}: 中国烟草学报
{Year}: 2023
{Volume}: 29
{Issue}: 06
{Pages}: 102-112
{Keywords}: 计算机视觉;吸烟行为分析;图像处理;抽吸参数
{Abstract}: 【目的】为了更加便捷高效地研究消费者吸烟行为特征，设计了一套基于计算机视觉的吸烟行为分析系统。【方法】该系统以可见光-红外线双目摄像头为传感设备，采集吸烟场景中的可见光和红外视频图像；采用人脸检测算法和人体姿态检测算法跟踪识别可见光图像中的人物及其动作，初步判断吸烟行为；采用烟头（燃烧锥）状态检测算法实时检测红外图像中烟头光斑位置与面积变化，进一步判定吸烟行为；同时，根据烟头光斑的位置与面积变化精确定位抽吸起始和结束的时间点，并自动计算抽吸口数、抽吸持续时间和抽吸间隔时间等抽吸参数。【结果】在湖南中烟技术中心招募30名志愿者进行系统测试，分别抽吸常规卷烟和细支卷烟，使用吸烟行为分析系统和CReSS吸烟行为记录仪同步记录抽吸参数，以CReSS吸烟行为记录仪记录的数据作为标准对照，验证吸烟行为分析系统的识别准确性。结果表明，吸烟行为分析系统对常规卷烟和细支卷烟抽吸口数识别的平均误差率分别为1.79%、2.06%，抽吸持续时间识别的平均误差率分别为9.73%、9.96%，抽吸间隔时间识别的平均误差率分别为6.59%、6.91%。【结论】该系统可以无感式、准确地识别吸烟行为并记录抽吸参数，在吸烟行为研究方面具有广阔的应用前景。
{ISBN/ISSN}: 1004-5708
{Notes}: 11-2985/TS
{URL}: https://link.cnki.net/doi/10.16472/j.chinatobacco.2021.T0162
{DOI}: 10.16472/j.chinatobacco.2021.T0162
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的舌象多特征识别研究
{Author}: 李阳辉
{Tertiary Author}: 赵千川;纪东升
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中医舌诊;图像识别;深度学习;卷积神经网络
{Abstract}: 中医图像识别是一种交叉研究领域,涉及到综合运用中医影像、数学建模、人工智能等多项技术。传统中医舌诊主要依赖医生肉眼观察舌头的形态特征来诊断疾病,但这种方法受到环境和医生主观经验的影响,难以达到客观化和标准化的诊断。随着计算机技术的不断发展,人们开始探索使用计算机技术来解决这个问题。其中,以卷积神经网络为代表的深度学习方法具备直接从医学图像中隐式的自动进行特征学习的优点,因此逐渐在传统中医舌象分析任务中被应用,并取得了一定的成绩。目前,基于深度学习的舌象图像诊断主要分为舌象识别和舌象分类两个部分。本文针对如何使用深度学习快速有效的完成舌象颜色的区分;如何提高深度学习的效果,使得能够有效的完成舌象形体的区分;如何扩展深度学习的功能,使其能够直接检测出舌象异常的特征,这三个问题提出了基于深度学习的多特征模型,有效的完成了多类型任务。本文的主要研究工作如下:(1)针对舌象中“颜色”和“体形”的识别客观化问题,提出了 TDNet网络来解决。在本文,首先介绍了两种特征分类的难点。然后提出增强对比度的方法来预处理舌象图片,以求得舌形分类任务能够取得更好的效果;使用色域转换的方法预处理舌象图像,以求得在舌色分类任务上能够取得更好的效果。最后提出了 TDNet网络一次性完成两种分类任务。通过混淆矩阵、ROC曲线图以及AUC指数等实验结果,可以看出本文提出的融合模型能够比单一的模型更好的完成两种分类任务。(2)针对于舌象中的“齿痕舌、裂纹舌、苔腻舌”三种病态舌象特征,本文章提出了基于注意力机制的YOLOX-s模型来完成这三种特征的目标检测任务。首先对原始的数据集进行了数据集增强工作,然后介绍了 SENet注意力模块和YOLOX-s模型的融合方式,最后介绍了损失函数的改进方式。实验结果表明,该融合模型对3种特征的总体识别效果显著提高。总体mAP值为91.95%,其中齿痕舌的AP值为0.85,裂纹舌的AP值为0.96,苔腻舌的AP值为0.95。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2023.001671
{DOI}: 10.27206/d.cnki.ggsgu.2023.001671
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉Halcon软件的齿轮参数检测系统
{Author}: 李颖;段玉坤;秦浩然;朱灿灿;孙晓敏;尹笑疑
{Author Address}: 沈阳理工大学机械工程学院;
{Journal}: 机电工程技术
{Year}: 2023
{Volume}: 52
{Issue}: 03
{Pages}: 188-193
{Keywords}: 机器视觉;齿轮;Halcon;非接触式;角点检测算子
{Abstract}: 为了实现快速、非接触准确测量齿轮参数，利用机器视觉软件搭建齿轮视觉参数检测系统。该系统基于Halcon软件平台设计，包括软件和硬件两部分组成，首先通过标定的工业相机拍摄清晰的待测齿轮图像，再利用Halcon软件的基本视觉与图像原理处理齿轮图像，经过阈值、滤波和形态学处理等操作识别齿轮图像轮廓，进一步利用角点检测算子提取并测量齿轮的齿顶圆直径、齿根圆直径、齿数、模数、分度圆直径、齿距等各项参数。通过实验测试结果表明，该法所测量出的齿轮各项参数基本上与参考数值一致，符合无接触测量的基本要求，可以准确迅速地测量齿轮的基本参数。与传统的接触式测量方法相比，具有测量精度高，稳定性好等特点，对于非接触实时测量提供了简便有效的解决方法。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxow1Y36ojiKM-JOtDfjicEwXE2AishYxcESdohZv9Sxdiy0Ucfk8_Ml-i_4qvxD8kQK-mxSXR2bNXTToanOL7nIBk1TCW4X_hPNk5TwDRjeTaCRkCgEUVfl4XG7BUjp9MIsJXWD5wU8PBHeOB3DNw40DjEYnEeY5tL_LaZY0PLRvVxg3XEAzlA0ttUM6VmGvg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和图像分类的桥梁缺陷检测方法设计与实现
{Author}: 陈丝璐
{Tertiary Author}: 路永钢
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 桥梁缺陷检测;注意力机制;多尺度特征融合;特征分离
{Abstract}: 随着桥梁运营时间的增长,其结构表面极易出现蜂窝麻面、破损露筋、修补、渗水和裂缝等损伤,若不及时处理将会影响桥梁的使用寿命和承载能力。近年来,随着机器视觉的不断发展,桥梁缺陷检测技术取得了长足进步,但现有方法主要针对单一裂缝设计检测模型;此外,当面对小目标缺陷时,模型的定位与检测精度性能不佳,甚至会直接漏检。为解决上述问题,本论文提出了一种基于深度学习和图像分类的桥梁缺陷检测方法。首先,将待检测的大图像均匀切割为固定大小的小块图像。其次,利用基于多尺度特征融合网络的二分类桥梁缺陷检测模型实现待测桥梁图片正常类和缺陷类的二分类判定,并构造潜在的桥梁缺陷类数据集;再次,利用提出的基于注意力的特征分离多分类桥梁缺陷检测模型,将潜在的桥梁缺陷类数据集细分为蜂窝麻面类、裂缝类、破损露筋类、渗水类和修补类;最后,搭建了一套集成二分类和多分类的桥梁缺陷检测系统,实现待测桥梁图片二分类到多分类的检测。本论文的主要研究内容如下:为了缓解正常桥面类图像过多导致用于训练缺陷类图像分类模型的数据集不平衡问题,另一方面为了消除正常桥类图像对缺陷类图像分类结果的影响,本文构建了一种基于多尺度特征融合网络的二分类桥梁缺陷检测模型。首先,利用Swin Transformer网络和预训练网络将桥梁图片映射到局部和全局特征空间;其次,设计了一种双通道多尺度特征融合模块,在融合全局和局部特征的同时,聚合桥梁缺陷形态和细节的上下文信息;最后,利用分类器将待检测的桥梁图像划分为正常类和缺陷类,并构造潜在桥梁缺陷类数据集。在二分类检测的基础上,提出了一种基于注意力的特征分离多分类桥梁缺陷检测模型,同时将潜在桥梁缺陷类数据集进一步细分为蜂窝麻面类、裂缝类、破损露筋类、渗水类、修补类。首先,利用Co T注意力机制改进主干网络Res Net,并在Image Net数据集上对改进后的主干网络进行预训练,提取潜在桥梁缺陷类图片的深度注意力特征图,使其能够更好地识别小目标缺陷;然后,利用特征分离模块将深度注意力特征图分离为等大小的蜂窝麻面类、裂缝类、破损露筋类、渗水类、修补类特征图;最后,利用上述细粒度特征图预测输入图片的标签,根据预测值与原始标签之间的损失端到端优化多分类模型。此外,本文以上述两种深度学习网络模型为核心算法搭建了一套集成二分类和多分类的桥梁缺陷检测系统。利用自主设计的桥梁图像数据采集云台,实地采集桥梁缺陷图像数据集,并分别用于训练模型二分类和多分类网络模型;通过利用实际场景中采集的桥梁缺陷数据对该系统进行测试,结果表明系统检测效果良好,验证了该桥梁缺陷检测系统具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2023.001926
{DOI}: 10.27204/d.cnki.glzhu.2023.001926
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的口罩人脸检测方法的研究
{Author}: 张茂松
{Tertiary Author}: 于晓
{Publisher}: 天津理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 口罩人脸检测;YOLOv5;注意力机制;多尺度特征融合网络
{Abstract}: 以呼吸道为主要传播途径的病毒通常情况下都可以被口罩有效阻挡,口罩已广泛应用于普通群众与医护人员对病毒的防护。食品安全关乎群众的切身利益,保证食品品质刻不容缓。在食品生产环境下,保证工作人员正确佩戴口罩是食品车间生产工作的基本任务。因此在车站、超市、食品生产车间等公共场合,都会设置人工检测点,进行口罩佩戴的提醒和检查。然而人工检测的方法存在较为明显的弊端,完全依赖人力检查将会存在工作强度大、实施性较差等问题,依靠人力的方法并不可取。因此,口罩人脸自动检测成为新的需求。针对现实场景下口罩人脸目标存在多目标、密集、遮挡等挑战,本文展开了口罩人脸检测方法研究,论文主要工作如下:(1)针对口罩人脸检测数据集比较匮乏的情况,提出了一个可用于实际场景下的口罩人脸数据集images-mask,该数据集共包含12010张图片,为后续研究工作的模型训练和模型效果测试提供数据基础。该数据集包含机场、超市、食品生产车间等国内外公共、复杂场景,涵盖多种口罩样式以及密集、遮挡的情况,从而保证数据的多样性,并根据模型检测要求使用了Label Img进行标注。(2)针对现实场景下口罩人脸目标存在尺度较小、较难被检测且易受背景信息干扰的问题,基于CBAM注意力机制提出了一种改进后的WCBAM注意力机制,同时将该机制与YOLOv5主干网络的CBL卷积层融合,得到CBLW模块。以YOLOv5算法为基础,提出了基于注意力机制思想和K-means聚类算法改进的YOLOv5＿M算法。通过实验结果证明了YOLOv5＿M的检测性能的优越性,在自制数据集上,YOLOv5＿M算法在检测速度和YOLOv5算法相近的情况下,检测精度提高了2.2%。(3)针对现实场景下口罩人脸目标尺度大小不同较难检测的问题,基于SPP模块和多尺度特征融合网络思想提出了SPP＿A模型,并以YOLOv5算法为基础,尝试引入Bi FPN模块和SPP＿A模块来对YOLOv5的Neck部分和SPP模块进行改进,提出YOLOv5＿B网络模型。经实验证明,YOLOv5＿B的检测性能优于YOLOv5网络,YOLOv5＿B算法在自制数据集上相比于YOLOv5算法检测精度提高了1.5%,一定程度上解决了多尺度口罩人脸目标较难被检测问题。(4)针对现实场景下往往同时存在口罩人脸目标尺度较小、易受背景信息干扰和口罩人脸目标尺度大小不同较难检测的问题,对YOLOv5算法的Backbone部分和Neck部分进行了改进,提出了YOLOv5＿BW算法。通过自建数据集以及公开数据集验证算法在实际场景下的口罩人脸检测性能,并与经典算法进行效果对比。实验结果验证了YOLOv5＿BW算法的有效性,适用于现实场景下的口罩人脸检测。基于YOLOv5的口罩人脸检测算法YOLOv5＿BW在AIZOO数据集上相比于其他7种方法的m AP50至少有0.4%的领先;在FMDD数据集上,YOLOv5＿BW算法相比较于其他的经典目标检测算法的m AP50指标至少有1.2%的提升。实验证明,YOLOv5＿BW算法基本上解决了上述现实场景下口罩人脸检测方法所存在的问题。综上,本文针对现有口罩人脸数据集所存在的缺点,提出了自建口罩人脸数据集images-mask;针对现实场景下口罩人脸目标存在尺度较小、较难被检测且易受背景信息干扰的问题,提出了YOLOv5＿M算法;针对现实场景下口罩人脸目标尺度大小不同较难检测的问题,提出了YOLOv5＿B网络模型;针对现实场景下往往同时存在口罩人脸目标尺度较小、易受背景信息干扰和口罩人脸目标尺度大小不同较难检测的问题,提出了全新的YOLOv5＿BW算法。通过在自建数据集以及公开数据集上的性能对比试验,实验结果验证了所提出算法的有效性。
{URL}: https://link.cnki.net/doi/10.27360/d.cnki.gtlgy.2023.000254
{DOI}: 10.27360/d.cnki.gtlgy.2023.000254
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的车牌定位与字符识别实验设计
{Author}: 宋金华;刘改霞;吴晓军
{Author Address}: 哈尔滨工业大学(深圳)实验与创新实践教育中心;哈尔滨工业大学(深圳)机电工程与自动化学院;
{Journal}: 实验科学与技术
{Year}: 2023
{Volume}: 21
{Issue}: 01
{Pages}: 37-42
{Keywords}: 车牌定位;模板匹配;MLP分类器;字符识别
{Abstract}: 针对机器视觉课程理论内容抽象、理解难度大、相关实验教学装置欠缺的问题，基于机器视觉设计了一种车牌模型的定位与字符识别实验平台，平台由下位机控制系统和上位机软件组成。下位机由图像采集与传输系统、运动控制系统构成，上位机软件由人机交互界面、定位算法与字符识别算法组成，基于VS2019联合Halcon设计包括目标物体的定位与跟踪、MLP分类器训练、字符分割与识别等功能模块在内的控制软件，实现了车牌模型的定位跟踪与字符识别。实验设计具有实用性、趣味性和扩展性，可辅助学生理解机器视觉技术的真实应用场景，提高学生实践能力和创新能力。
{ISBN/ISSN}: 1672-4550
{Notes}: 51-1653/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwLIR3Sj8T9qioLN-quZfTM0ob1JprqvX-C2xY8_vlVs0UQxJJWHAO3QsABbTNtmM_Eaj-ascXEIzDHiJS1pTEoibslMXYd88OY32seGusm-2NnLh9sbAUgBipBNWw3uWz6CdYHl1uPhLzo6MnetGNLVdxL0gP3jJQRhCsCDFm5NPz59BOb5fUqOPxr90rpEHI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的垃圾分类系统设计
{Author}: 覃振鹏;梁承权
{Author Address}: 南宁学院智能制造学院;
{Journal}: 今日制造与升级
{Year}: 2023
{Volume}: 
{Issue}: 02
{Pages}: 101-105
{Keywords}: OpenMV;单片机;机器视觉;垃圾分类
{Abstract}: 针对垃圾分类效果不佳、效率过低和成本过高的问题，提出一种基于机器视觉的垃圾分类系统。系统通过OpenMV摄像头模块采集垃圾的图像信息，上传数据集到EdgeImpulse官网，进行数据的整理和数据集训练，之后迁移学习构建其神经网络模型，OpenMV输出识别的结果传递给单片机。单片机收到传递信息后，控制机械臂抓起垃圾并放入可回收垃圾桶和不可垃圾桶内。测试表明，设计的垃圾分类系统识别正确率达92%以上，具有识别正确率高、使用便捷和易操作等优点。
{ISBN/ISSN}: 2095-6932
{Notes}: 10-1196/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz0szyxcIzJZdmIl-MjeqYN-EdEtgiq0oSka0IFbQuy3P250RN_trQrm7Q2s4mtxrHdi_VAzcNlQlVLJWLNVv8ofe8P4ZbF1kHD-e6QcGMOH00gCdh6EDtg3a6WadZweB9d1GiAACk0u9oArT2kuEZ3B-fSpefgG5gZJpR8jyox_Tes1WClLHnCXx5zzPFR-2E=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的木材特征提取与树种识别研究综述
{Author}: 计恺豪;庄子龙;刘英;杨雨图
{Author Address}: 南京林业大学机械电子工程学院;
{Journal}: 世界林业研究
{Year}: 2023
{Volume}: 36
{Issue}: 02
{Pages}: 58-62
{Keywords}: 机器视觉;木材特征;特征提取;树种识别
{Abstract}: 我国是木材及木制品加工大国，近年来家具、装修等市场需求的快速增长推动了木材加工行业的发展。由不同树种制作而成的木材材料性质与价值大相径庭，因此准确识别木材树种具有重要意义。相较于传统人工识别，基于机器视觉的木材树种识别大幅度提高了准确率。文中通过分析近5年来木材识别领域的相关文献，总结了木材特征提取的相关技术与树种识别的各种方法，提出要深度融合木材的多个特征并加强各种算法间的配合使用；此外，针对机器视觉在木材树种识别中的应用普遍停留在学术研究阶段的问题，提出木材树种识别应向装备数字化方向发展，以期提高木材树种识别的工作效率。
{ISBN/ISSN}: 1001-4241
{Notes}: 11-2080/S
{URL}: https://link.cnki.net/doi/10.13348/j.cnki.sjlyyj.2023.0006.y
{DOI}: 10.13348/j.cnki.sjlyyj.2023.0006.y
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合注意力机制的金属锅圆柱表面缺陷检测
{Author}: 乔健;陈能达;伍雁雄;吴阳;杨景卫
{Author Address}: 佛山科学技术学院机电工程与自动化学院;季华实验室;佛山科学技术学院物理与光电工程学院;
{Journal}: 光学精密工程
{Year}: 2023
{Volume}: 31
{Issue}: 03
{Pages}: 404-416
{Keywords}: 机器视觉;特征金字塔;注意力机制;金属表面缺陷
{Abstract}: 为实现高亮反射金属圆柱形锅的自动快速检测及分拣，破解目前金属锅表面缺陷检测速度慢、效率低的技术难题，在YOLOX网络基础上引入双向特征融合网络，提出基于注意力机制的轻量化特征融合网络模型，实现计算模型的轻量化设计；同时，通过注意力机制模块对特征信息进行通道与空间的学习，有效缓解多尺度特征的语义鸿沟问题，提高了模型的检测精度；考虑网络对难易分类样本学习权重分配不平衡，设计基于衰减因子的分类损失函数；利用金属锅圆柱表面缺陷数据集完成了特征融合网络对比实验、分类损失函数对比实验和注意力机制模块位置消融实验。实验结果表明，融合注意力机制模型可有效识别6种不同形态的缺陷，测试集的平均检测精度mAP0.5达到90.92%，检测帧率达到30.84 frame/s，实现了金属锅圆柱表面缺陷的高精度快速识别与定位。
{ISBN/ISSN}: 1004-924X
{Notes}: 22-1198/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyQk1YE9VG41xxk8m-nvCysEvKE6sHVwj7gQkC4bqc9C1cxG66K0jSnqKtkQn45Cdg1Xs4ps9NXkhYElcpjQNVt7nXGDs7JffkfY3T0tp5GzrF6SKRmb9jqwpvHTEzKodRcgrEMp7aXKwMRwxcUVS4zuuKxZgSKc2MeMnZBn4m4j7VMyUVh43kRNEec7MMDdWE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于多相机系统的高精度标定
{Author}: 肖一帆;胡伟
{Author Address}: 河南理工大学电气工程与自动化学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 20
{Pages}: 134-140
{Keywords}: 机器视觉;低像素相机联合;透视偏差矫正;非线性优化
{Abstract}: 随着工业机器视觉的深入发展，大视野高精度视觉系统的需求越来越多。针对大视野导致的精度过低问题，提出一种基于多个低像素相机联合标定的方法。在多相机中选择一个相机作为主相机，求取其他相机的像素坐标系与主相机像素坐标系的映射矩阵，使得主相机的视野无限扩展。同时，为了更精确地得到标定板图像中的圆心像素坐标位置，采用两步标定法提升标定精度。提取标定板圆心像素坐标进行第1次粗标定，获取相机内参以及标定板位姿，从而获取图像平面与世界坐标系的平面Z=0之间的映射关系。对其进行透视偏差矫正，提取矫正后标定板的圆心，再利用逆映射变换把相应的圆心转换回原始位置，用转换后圆心像素坐标位置对主相机进行第2次精标定。最后通过LevenbergMarquardt算法进行非线性优化获取全局最优解。实验结果表明，所提标定方法的重投影误差在0.005 pixel～0.01 pixel之间。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230207.1600.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业零件尺寸测量算法设计
{Author}: 桂进;刘文翰
{Author Address}: 铜仁职业技术学院;
{Journal}: 信息记录材料
{Year}: 2023
{Volume}: 24
{Issue}: 02
{Pages}: 16-18
{Keywords}: 图像校准;图像坐标系;工件尺寸测量
{Abstract}: 针对人工测量工业零件尺寸存在测量精度低、速率慢及用工成本高等问题，设计了一种基于机器视觉的工业零件尺寸测量算法。算法先对机器视觉系统进行畸变校准，获取图像校准信息。再对标准图像与被测零件图像进行形态学等预处理，并在此基础上根据设定的固定特征建立参考坐标系与测量坐标系。在基于测量坐标系相对于参考坐标系发生的平移、旋转量进行调整后测量区域内测量被测零件像素尺寸，根据图像校准信息将像素尺寸转化为真实尺寸。经实验证明，该算法在被测工件发生平移、旋转的情况下，具有较高的尺寸测量精度。
{ISBN/ISSN}: 1009-5624
{Notes}: 13-1295/TQ
{URL}: https://link.cnki.net/doi/10.16009/j.cnki.cn13-1295/tq.2023.02.075
{DOI}: 10.16009/j.cnki.cn13-1295/tq.2023.02.075
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水面垃圾清理装置
{Author}: 周鑫;李乔硕;陈君君;姜家旺;王文品
{Author Address}: 河南科技大学;
{Journal}: 智能城市
{Year}: 2023
{Volume}: 9
{Issue}: 01
{Pages}: 95-97
{Keywords}: 水面垃圾;机器视觉;ROS;深度学习
{Abstract}: 文章介绍一种基于机器视觉的垃圾清理装置，解决水面漂浮垃圾问题。装置通过视觉识别对水面垃圾进行准确抓取清理回收。装置主控采用树莓派3B+，视觉处理采用OpenCV，使用Keras框架建立深度学习模型，实现对垃圾的检测识别，配合机械抓取结构对垃圾进行拾取，自主巡航功能对整个水域全覆盖，提高了水面垃圾的处理效率，实现水面垃圾处理的自主化和智能化。
{ISBN/ISSN}: 2096-1936
{Notes}: 21-1602/N
{URL}: https://link.cnki.net/doi/10.19301/j.cnki.zncs.2023.01.028
{DOI}: 10.19301/j.cnki.zncs.2023.01.028
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在胶囊表面缺陷识别与分拣中的应用
{Author}: 吴雪松
{Author Address}: 康元医疗科技(大连)有限公司;
{Journal}: 设备管理与维修
{Year}: 2023
{Volume}: 
{Issue}: 02
{Pages}: 96-97
{Keywords}: 机器视觉;胶囊;表面缺陷;识别;分拣
{Abstract}: 机器视觉技术应用于制药公司胶囊检测环节，能够快速自动成像、对胶囊表面缺陷进行分析，分检出质量不合格的产品，提升药品生产的稳定性和效率，控制人力资源成本的支出。结合图像识别原理，分析机器视觉技术要点和图像识别装置的应用。
{ISBN/ISSN}: 1001-0599
{Notes}: 11-2503/F
{URL}: https://link.cnki.net/doi/10.16621/j.cnki.issn1001-0599.2023.01D.42
{DOI}: 10.16621/j.cnki.issn1001-0599.2023.01D.42
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 嵌入SENet的卷积神经网络的零件缺陷检测方法
{Author}: 张雪明;茅健
{Author Address}: 上海工程技术大学机械与汽车工程学院;
{Journal}: 农业装备与车辆工程
{Year}: 2023
{Volume}: 61
{Issue}: 01
{Pages}: 94-98
{Keywords}: 缺陷检测;特征压缩激活;Unet;损失函数;机器视觉
{Abstract}: 针对回转体零件的表面倒偏角、拉伤、线形纹等缺陷检测识别效率低、误检、漏检等问题，提出一种在编码器中嵌入特征压缩激活模块的Unet网络的零件缺陷检测方法。通过建立Unet网络架构模型并嵌入SE模块实现缺陷分割，完成缺陷图像的细节特征提取。采用BCEloss和Diceloss的混合损失函数进行训练，缓解缺陷图像分类不平衡的问题。该算法与Seg Net、FCN、Unet模型对比表明，Unet-SE在准确率、召回率和F1分数3个指标中表现最优，分别为0.929 8,0.892 9,0.911 0，且测试集中具有更好的分割效果。
{ISBN/ISSN}: 1673-3142
{Notes}: 37-1433/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwVU35A3QeAmp3C3Cf-PznhGHE5htZUsT6U0Rc93K4Y7XrbjPqLasylhXUnmSZPW9ah28e8gNxoStPXxAOrA57p7D3qUE4jaFAbeiQVe8-nYdY__6nlB-a9yt4FzyagNlJlRaiEdV0cpcz7eSrxUQCt12Q15QgRVEsVbaHaSZnOnH_ZpWq4Hk5jVD9xGNYVnpg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的施工现场钢结构焊缝坡口识别
{Author}: 成佳明;靳慧;郑子健;蒋朗坤;罗琴丽;董凯;周军红;陈小飞
{Author Address}: 东南大学土木工程学院;东南大学江苏省工程力学分析重点实验室;中建科工集团江苏公司;中建钢构江苏有限公司;
{Journal}: 东南大学学报(自然科学版)
{Year}: 2023
{Volume}: 53
{Issue}: 01
{Pages}: 86-93
{Keywords}: 智能建造;机器视觉;图像处理;焊缝识别;误差分析
{Abstract}: 基于线结构光视觉传感技术建立了一种适用于施工现场钢结构焊缝坡口识别方法.以南京某超高层建筑钢结构为工程背景，首先设计开发了适用于施工现场的图像采集装置，通过识别算法从采集图像中截取结构光线条感兴趣区域图像；其次，提出了基于分组教学优化算法-大津法(GTO-Otsu)的图像局部阈值分割方法，实现了结构光线条与背景的有效分割；然后，构建了线性结构元素用于修复结构光线条断裂区域；最后，通过比较相邻像素点的灰度和与一阶差分值的方法提取了结构光线条中心线及特征点坐标，并建立了像素转化方法，完成特征点像素坐标的转换，实现坡口几何尺寸测量.3组施工现场钢结构焊缝坡口图像处理和识别结果表明了该方法的准确性与适用性.
{ISBN/ISSN}: 1001-0505
{Notes}: 32-1178/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwOUeTaiIu9-BhRRyJZQeN4aXgOf8MFKwvle5Tl4N5LOg0V5Mfa1tZ_jQA3X1QA0RLkgzCWT1IWAVlKXZH_LBoXpcEuIByHPvx895pg1sywpqKUSbW9NVtfq561pL0lpc9vwLt0blk_jd25QxCdmrZHoShnobmclyv8xKYEly4O0e8EcJTHWqFe-zWhtUEiWXI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于SURF-PROSAC法的高铁桥梁位移测量技术研究
{Author}: 杜文康;雷冬;杭宗庆;白鹏翔;朱飞鹏
{Author Address}: 河海大学力学与材料学院;
{Journal}: 铁道科学与工程学报
{Year}: 2023
{Volume}: 20
{Issue}: 09
{Pages}: 3579-3591
{Keywords}: 高铁桥梁;机器视觉;特征检测;位移测量
{Abstract}: 快速、便捷、有效的结构变形监测技术是保障高铁桥梁运营安全的重要手段。目前，桥梁变形监测大多采用接触式传感器，如加速度传感器、应变计以及位移计等设备。这些设备通常需要固定在表面或埋入结构内部，由于施工难度大、系统造价高、后期维护较为繁琐，难以广泛应用于数量大且封闭性高的高铁桥梁。为此，提出一种基于机器视觉的高铁桥梁位移测量技术，将SURF(Speeded Up Robust Features)特征检测方法与FLANN-PROSAC(Fast Library for Approximate Nearest Neighbors-Progressive Sampling Consensus)匹配算法相结合。利用智能手机采集结构变形视频，实现了结构位移的快速测量。在实验室内，通过对汉字标记进行识别，探索了视觉方法在光照变化、雾气条件、物体遮挡等多种工况下的适应性。模型试验结果表明：在光照变化条件下，特征点数量会随着光照强度的降低而减少；而在物体遮挡和雾气条件下，特征点数量则会由于遮挡面积和雾气浓度的改变而出现波动变化。同时，机器视觉方法的测量结果能够较好地与位移计结果相吻合，最大偏差率少于5%。在现场实验中，进一步验证了机器视觉方法在不同表面特征(稳固标记和随机标记)识别中的稳定性，清晰测量出高铁桥梁在运营过程中的结构关键位置的位移变化趋势。此外，基于智能手机的测量系统具有良好的便携性，能够适应跨越道路、河道等多类型测量环境。研究成果可实现结构动态位移的非接触式测量，为高铁桥梁定期管养检测、长期性变形监测提供新的解决思路。
{ISBN/ISSN}: 1672-7029
{Notes}: 43-1423/U
{URL}: https://link.cnki.net/doi/10.19713/j.cnki.43-1423/u.t20222039
{DOI}: 10.19713/j.cnki.43-1423/u.t20222039
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习与多视图一致性的物体位姿估计
{Author}: 周彦宏
{Tertiary Author}: 刘山;徐伟锋
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 物体位姿估计;机器人抓取;合成样本;深度学习;多视图一致性
{Abstract}: 物体位姿估计在许多任务场景中都具有重要的研究和应用价值,但同时也存在干扰因素频现、物体聚集遮挡以及特征提取困难等挑战。本文针对物体位姿估计重要应用场景之一的工业机器人抓取任务,研究快速有效的目标识别与位姿估计方法,提出了基于深度学习与多视图一致性的物体位姿估计与优化算法,引导机器人更高效地完成物体抓取任务。本文的主要研究内容及取得的成果如下:
(1)进行数据集构建与机器人抓取系统搭建工作。针对深度学习方法对样本数据需求量较大但标注数据的获取成本较高的问题,本文借助模块化实现框架,通过渲染合成的方式高效地构建带标签样本数据集,为算法的实现与验证提供基础。为验证物体位姿估计与优化算法的有效性与实用性,搭建了结合视觉引导的协作机器人抓取系统,进行算法的部署应用。
(2)针对纹理缺失的物体特征提取困难的问题,本文提出了一种基于深度学习的物体识别与位姿估计算法,对YOLOX算法进行扩展改进,在对物体进行快速识别的基础上,通过预测关键点建立场景图像与物体模型间的对应关系进而计算物体位姿。为增强算法的泛化能力,设计了离线扩充与在线增强相结合的数据增强方法,进一步丰富样本数据。LINEMOD数据集与合成工件数据集上的测试结果验证了算法的准确性,机器人抓取实验结果进一步验证了算法的有效性。
(3)针对视角固定带来场景信息缺失进而影响算法准确性的问题,本文提出了基于多视图一致性的物体位姿优化算法,通过联合多个视角的场景信息对估计结果进行优化。在各视图位姿估计结果的基础上,应用RANSAC算法思想,进行多视图物体实例一致性检验,快速鲁棒地获得不同视图对应相机的相对位置关系,进而通过投票机制对关键点预测结果进行错误剔除与偏差优化,从而获得更优的物体位姿估计结果。合成样本数据集与机器人抓取系统上的对比实验结果验证了算法的有效性与实用性。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.000039
{DOI}: 10.27461/d.cnki.gzjdx.2023.000039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于航拍图像与改进U-Net的建筑外墙裂缝检测方法
{Author}: 刘少华;任宜春;郑智雄;牛孜飏
{Author Address}: 长沙理工大学土木工程学院;中国建筑第五工程局有限公司;
{Journal}: 土木与环境工程学报(中英文)
{Year}: 2024
{Volume}: 46
{Issue}: 01
{Pages}: 223-231
{Keywords}: 建筑外墙裂缝;无人机;计算机视觉;语义分割;U-Net
{Abstract}: 针对建筑外墙裂缝人工检测方法检测效率低、检测效果和安全性差的问题，提出基于航拍图像与计算机视觉的裂缝检测方法。使用无人机绕建筑物航拍采集裂缝图像，并构建裂缝数据集；优化U-Net模型以解决细长裂缝分割不连续、复杂背景下裂缝漏检及背景误检的问题。将模型编码网络替换为预训练的ResNet50以提升模型特征表达能力；添加改进的多孔空间金字塔池化（Atrous Spatial Pyramid Pooling,ASPP）模块，获取多尺度上下文信息；采用改进的损失函数处理裂缝图像正负样本分布极度不均的问题。结果表明：改进的U-Net模型解决了原模型存在的问题，IoU指标和F1＿score分别提升了3.53%、4.18%；与经典分割模型相比，改进模型的裂缝分割性能最优。与人工检测方法相比，所提方法可以安全、高效且准确地进行建筑外墙裂缝检测。
{ISBN/ISSN}: 2096-6717
{Notes}: 50-1218/TU
{URL}: https://link.cnki.net/urlid/50.1218.TU.20221229.1652.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉创新实验课教学研究与实践
{Author}: 刘改霞;刘能锋;陈如香;戴坤添
{Author Address}: 哈尔滨工业大学(深圳)实验与创新实践教育中心;
{Journal}: 实验科学与技术
{Year}: 2022
{Volume}: 20
{Issue}: 06
{Pages}: 136-140
{Keywords}: 人工智能;机器视觉;创新实验课;项目引导案例驱动式教学
{Abstract}: 为促进综合创新实践能力的培养，以基于智能硬件的机器视觉项目开发与实践创新实验课为基础，设计了项目引导案例驱动式教学方案。以项目为主导，通过分解项目所涉及知识内容，构建知识点图；再将知识划分并归纳总结为若干相互关联又可相互独立的模块；然后，针对各个模块均设计若干典型实验案例，采用案例驱动式推动各模块相关理论知识的学习；最后，通过项目的正向综合训练，使学生进行高效的知识构建、整合及内化。教学实践表明，项目引导案例驱动式教学方案能有效提升学生创新实践能力。
{ISBN/ISSN}: 1672-4550
{Notes}: 51-1653/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzEUAOwIoCszCE869eByy_pFBAtbzaTeKT5LrymRu-p7LS28SWWDiuwS4vk9kD9ReuUs2QuaGV8wY_6oYNT9Xely4jTVtSrtiykaOpbk06-0B5-Z8xN78lLzcEkzTEc4X-AUJKGbhl8euQaOjlFTpFxmi99YN3ofqqzEnNjJz2T_l1wGkSEbYTXdPPQc18M_xo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的车道线检测与识别算法
{Author}: 谷峥
{Author Address}: 重庆交通大学;
{Journal}: 无线互联科技
{Year}: 2022
{Volume}: 19
{Issue}: 24
{Pages}: 138-140+144
{Keywords}: 车道线检测;高斯滤波;边缘检测;Hough变换
{Abstract}: 车道线检测与识别技术就是从含有多个车道标识线的道路图像中，将车辆目前正在行驶区域内的连续或间断的车道标识线重建成连续直线的图像处理技术，是自动驾驶的重要核心技术之一。文章主要围绕基于机器视觉的车道线检测与识别算法进行了深入的研究。首先，针对路面环境特点对图像进行预处理；其次，为了减小运算量，利用掩模图形对图像进行感兴趣区域划分；最后，使用Hough变换实现车道线的检测。实验结果表明，文章所提出的方法具有一定的实际应用价值。
{ISBN/ISSN}: 1672-6944
{Notes}: 32-1675/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzEUAOwIoCszCE869eByy_pFBAtbzaTeKT_BOhn-5V04nhrDRlbpfVkFef7O8tM953iQPqLbDjqQTPK1kegWdMSSTXX8d0ag1tE12cqpMB_3d8jj-EZZDpnjJFlau5zZsVj-vLZENs6ffQ7GfHPhf-O3ngdlONExkpher6g9GndEfZ4-lBO77EcjezQozdojXw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的粮食外观品质检测研究进展
{Author}: 陈卫东;李宛玉;李智
{Author Address}: 河南工业大学信息科学与工程学院;河南工业大学粮油标准化研究所;
{Journal}: 河南工业大学学报(自然科学版)
{Year}: 2022
{Volume}: 43
{Issue}: 06
{Pages}: 118-128
{Keywords}: 粮食;外观品质;无损检测;机器视觉;分类算法
{Abstract}: 外观品质是粮食收购、定等的重要依据，其检测结果的准确度直接关系到购销双方。快速无损检测技术对于提高粮食收购效率、降低劳动强度、提升基层粮食企业质检能力具有重要意义。同时，机器视觉技术在农产品无损检测领域的研究日趋成熟，在粮食外观品质检测方面的应用也逐渐深入。综述了图像采集、图像处理、特征提取以及分类算法在粮食外观品质检测中的成果和应用，讨论了这些方法的发展现状及不足，同时对该领域的发展趋势与未来研究方向进行了展望。
{ISBN/ISSN}: 1673-2383
{Notes}: 41-1378/N
{URL}: https://link.cnki.net/doi/10.16433/j.1673-2383.2022.06.016
{DOI}: 10.16433/j.1673-2383.2022.06.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在印刷领域的应用现状
{Author}: 郑元丰;高艳飞;赖凯锑;陈科科;张毅;吴霖华
{Author Address}: 中山火炬职业技术学院;仲恺农业工程学院;
{Journal}: 绿色包装
{Year}: 2022
{Volume}: 
{Issue}: 12
{Pages}: 35-38
{Keywords}: 机器视觉;印刷;人工智能
{Abstract}: 机器视觉技术是一项综合多学科交叉的人工智能技术，具有效率高、信息量大、功能齐全等优点，在印刷领域展现出广阔的应用前景。首先系统介绍了机器视觉技术的原理、组成及应用，分析了其在印刷领域的应用优势，随后总结了机器视觉技术在印刷领域的应用现状，为促进智能印刷的快速发展提供一定的理论参考。
{ISBN/ISSN}: 2096-4838
{Notes}: 10-1400/TB
{URL}: https://link.cnki.net/doi/10.19362/j.cnki.cn10-1400/tb.2022.12.005
{DOI}: 10.19362/j.cnki.cn10-1400/tb.2022.12.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机械臂双目测距系统研究
{Author}: 汪凌阳;朱璠婷;蒋文萍
{Author Address}: 上海应用技术大学电气与电子工程学院;
{Journal}: 应用技术学报
{Year}: 2022
{Volume}: 22
{Issue}: 04
{Pages}: 383-387
{Keywords}: 工业机器人;机器视觉;测距;双目标定;立体匹配
{Abstract}: 针对工业机器人在非接触式的工作环境下获取目标三维信息的潜在问题，设计出了一套基于机器视觉的机械臂双目测距系统。该系统采用Matlab和OpenCV对CMOS双目工业相机进行双目标定，并根据标定得到的相机内外参数进行立体校正，然后结合双目视觉的SGBM立体匹配算法计算出相应环境下的深度信息，最后利用二维图像和深度信息辅助机械臂控制中心获取目标工件的三维信息并作出相应命令操作。根据实验分析，该测距系统测量时间短、鲁棒性好、测量精度高。
{ISBN/ISSN}: 2096-3424
{Notes}: 31-2133/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzYOTEfqlARKpSTdSEfQGmpwlPUDFAD0Ba7GsOasfpR1RELiSMt9KuxXntalDsJXYFg0iQYrMddjL5ZYIn_Yg7Vp4UNgZxjXAlHUCOCYLF_tm8reKtWwek9mcfVHH5Gai8nEAYl9WMtX0wxv_L5JXpGUgQCLEaKcuqvY7ouBbpdr_dvr2DRLCNBNPtF4vGxmQo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的猴头菇品质快速无损检测与分级
{Author}: 张银萍;朱双杰;徐燕;李魏
{Author Address}: 滁州学院生物与食品工程学院;
{Journal}: 现代食品科技
{Year}: 2023
{Volume}: 39
{Issue}: 03
{Pages}: 239-246
{Keywords}: 机器视觉;智能分级;猴头菇;图像识别;图像处理
{Abstract}: 传统的猴头菇品质检测与分级主要依靠人工分拣来完成，其主观性强、精度相差大、效率低，浪费了大量人力物力资源。鉴于此，为了实现猴头菇的快速无损等级评估，该研究引入机器视觉技术，提出了一种猴头菇品质的快速无损检测与分级方法，设计一套基于机器视觉的猴头菇品质快速无损检测与智能分级设备，并通过图像处理和软件设计开发一套猴头菇智能快速无损检测分级系统。通过加色法混色模型（RGB）对猴头菇的颜色特征的快速检测与等级的判定；采用图像阈值分割和Canny边缘检测，实现猴头菇完整度的判定；使用最小外接圆法对猴头菇的大小进行实时计算，完成猴头菇直径大小的判别；基于Microsoft Visual Studio 2017平台开发一套猴头菇品质快速无损检测可视化平台。试验证明，基于机器视觉的猴头菇品质快速无损检测与分级系统检测准确率达到97.07%，速度达到人工的5倍多。验证了系统的可靠性和可行性，为食品工业的智能化生产和加工提供了技术支撑，推动了机器视觉技术在食品行业的应用。
{ISBN/ISSN}: 1673-9078
{Notes}: 44-1620/TS
{URL}: https://link.cnki.net/doi/10.13982/j.mfst.1673-9078.2023.3.0467
{DOI}: 10.13982/j.mfst.1673-9078.2023.3.0467
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多尺度特征融合与增强的细粒度图像分类方法研究
{Author}: 杨昕祁
{Tertiary Author}: 雷景生
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 细粒度图像分类;特征增强;特征融合;渐进式训练;层间交互
{Abstract}: 细粒度图像分类是计算机视觉领域中一个非常热门且具有挑战性的研究课题,在工业界与学术界都有着广泛的研究需求与应用场景。在实际生活中,识别不同的子类别存在着巨大的应用需求,如:智能零售场景下的商品识别、公共安防场景下的车辆识别、危险品检测和识别、生物多样性监测等,特别是在智能新经济和工业互联网的产业应用中展现出巨大应用价值。但目前细粒度图像分类任务的主要挑战是类间差异小和类内差异大的固有属性,具体包含以下几点:(1)训练过程中会存在细节纹理的丢失问题;(2)不显著但同样具有区分性的特征无法得到充分挖掘;(3)细粒度图像数据集中存在较为复杂的背景噪声;(4)主干网络不同卷积层提取的不同特征无法得到有效融合等。本文将针对以上挑战对细粒度图像分类展开一系列的分析与研究。
基于特征增强与特征融合思想,本文提出两种通用模型,均可从不同角度解决上述问题,以提高细粒度图像分类的准确率;此外,本文通过剖析两个模型所用方法,将两个模型的优势方法融合进一个集成模型中,从而进一步提升细粒度图像分类的性能。本文的主要工作如下:
1.针对细节纹理丢失和区分性特征难以挖掘的问题,本文提出了一种渐进式训练的互补特征提取网络模型(Progressive Complementary Feature Extraction Network,PCFE-Net),具体包括:(1)一种多尺度渐进式训练方法:将不同尺度的随机拼图图像进行多步骤渐进式训练。这能够使网络提取到多粒度的局部特征信息,并随着训练的推进将注意力逐渐扩展到全局结构信息,以进行多粒度信息融合。(2)一个即插即用的特征互补增强模块(Feature Complementary Enhancement Module,FCEM),它能够显式的增强当前层网络提取到的特征,同时还能使下一层网络提取潜在的互补特征信息。该模型在四个细粒度图像基准数据集上进行了各项实验。
2.针对复杂背景噪声干扰和层间特征融合效果不佳的问题,本文提出了一种显著性特征抑制与交叉特征融合网络模型(Significant Feature Suppression and Cross-feature Fusion Network,SFSCF-Net),具体包括:(1)对象级图像生成器(Object-level Image Generator,OIG):将主干网络最后两个卷积块输出特征图的交集作为对象掩膜,映射到原始图像上进行裁剪即可得到对象级图像,这能有效减少复杂背景带来的干扰。(2)显著性特征抑制模块(Significant Feature Suppression Module,SFSM):通过特征提取器获取对象图像中最具区分性的部分,并通过二维抑制的方法将该部分进行遮盖,提高了特征抑制的精度。(3)一种基于层间交互的交叉特征融合方法(Cross-feature fusion method,CFM):将不同网络层的输出特征图进行交互集成,并在池化后得到高维特征,之后将高维特征进行通道压缩从而得到层间交互特征表示,丰富了输出特征语义信息。所提出的SFSCF-Net可以进行端到端训练,并在四个细粒度图像基准数据集上进行了各项实验。
3.为了将上述两个模型的优势进行最大化集成,以进一步提高模型的识别性能,本文提出了一种多尺度渐进式互补特征融合网络模型(Multi-scale progressive complementary feature fusion network,MPCF-Net),该模型进一步优化了一种显著性特征互补增强模块(Significant Feature Complementary Enhancement Module,SFCEM),能够最大化融合不同尺度和不同网络层的互补特征。通过对该模型进行大量的消融实验,验证得出了一种最优模型架构,并在四个细粒度图像基准数据集上均取得了较好的结果。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000183
{DOI}: 10.27840/d.cnki.gzjkj.2022.000183
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自然场景下基于深度学习的文字检测方法研究
{Author}: 陈静娴
{Tertiary Author}: 周全
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然场景文本检测;深度学习;语义分割;注意力机制;特征融合;空洞卷积
{Abstract}: 场景文本作为一种日常生活中的信息载体,蕴含着丰富且精确的信息。因此对自然场景图像中文字的检测与识别在基于计算机视觉的应用中有着广阔的适用范围和极高的商业价值。近年来深度学习的出现为计算机视觉提供了新思路,并在多项基础任务中取得了突破性的成果。由于场景文字在排布、尺度、字体、成像条件等方面均具有高度复杂性,因此对其进行精准定位是一项极具挑战的任务。现有的工作在复杂场景文本检测上已取得了较大进展,但仍存在许多方面亟需改进:第一是如何进一步提高检测准确率,减少误检与漏检;第二是如何精准地检测文本边界;第三是如何简化模型,提高检测效率。针对上述问题,本文基于深度学习算法,从模型特征提取融合、远程信息获取、轻量化等方面,围绕场景文字检测任务展开了一系列研究:(1)针对背景噪声干扰和小尺寸文本漏检的问题,设计了一种基于注意力特征融合与增强的场景文本检测模型(AFFE-Net)。首先,利用注意力机制对有效特征提取的优势,在解码阶段通过提取不同层级特征的细节和全局信息来有效加强特征的信息表达能力。其次,在检测头之前对拼接特征进行通道、空间位置间的关系建模,并生成联合特征权重mask对特征做加权,以此消除背景噪声对文本检测的负面影响,从而有效减少误检与漏检;(2)针对不同尺度文本边缘检测完整性问题,设计了一种基于多尺度联合预测的文本检测模型(MFJP-Net)。首先,通过对多尺度级联特征使用空洞卷积特征金字塔来扩大感受野,从而获取更多远程信息从而对文本边缘进行精准分割。其次,采用双检测头以得到多尺度的预测结果并对其进行融合。此外,在模型训练途中使用Dice损失函数来缓解训练数据正负样本不均衡情况下模型偏向背景的问题,从而提升模型性能,加速模型收敛;(3)针对文本检测模型参数量大,计算时延长,轻量化骨干网络特征提取能力不足的问题,设计了一种基于全局指导双向特征融合的轻量型文本检测模型(BFPF-Net)。首先,通过双向特征融合的方式来增加卷积层数,从而提高网络的特征提取能力。其次,设计全局语义指导分支在特征融合过程中为其补充空间和语义信息,以提高融合特征的信息丰富度。此外,运用深度可分离卷积替代部分普通卷积,从而精简模型复杂度,降低模型的参数量。在不规则文本数据集Total-Text和多方向文本数据集ICDAR-2015上的实验结果表明,本文设计的模型表现良好。在精度P,召回率R、综合指标F1和检测速度、边缘检测完整性上相对于对比方法均有一定的提升。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001358
{DOI}: 10.27251/d.cnki.gnjdc.2022.001358
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于表示学习的轻量级图像超分辨率方法研究
{Author}: 王正学
{Tertiary Author}: 高广谓
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 轻量级图像超分辨率;多尺度特征交互;特征去冗余自校准;递归Transformer
{Abstract}: 图像超分辨率的主要目的是将一张低分辨率图像重建为一张具有丰富细节纹理、高质量视觉感官的高分辨率图像,在医疗图像、视频监控等领域有着重要意义。近年来,随着深度学习在计算机视觉等领域取得了很大的进展,基于深度卷积神经网络的图像超分辨率方法成为了一个热点问题。但是现有的图像超分辨率模型为了实现更好的重建效果,不断的增加网络的深度和复杂度,导致网络模型参数量和计算量过大从而难以应用于现实场景中的问题。本文主要的研究重点是如何在充分提取和利用图像特征信息重建出纹理细节丰富的高分辨率图像前提下,降低网络复杂度、减少模型参数量和计算量。对此,本文主要提出了三种解决方案:(1)以往图像超分辨率方法大多仅选择对被下采样后的图像进行特征提取,并在网络的尾端进行上采样处理。考虑到不同尺度大小图像包含不同的特征信息,本文提出了一个有效的基于多尺度特征交互的轻量级图像超分辨率方法。该模型以轻量级循环残差通道注意力模块为基本单元,搭建了一个三层的深度特征提取融合网络,每层分别提取不同尺度大小的图像特征和融合来自其他层的不同尺度的特征信息。在Set5、Set14、BSDS100和Urban100四个基准测试数据集上的实验充分验证了本文提出方法的有效性。(2)基于Transformer可以对图像中的全局依赖进行建模,同时具有很强的特征表示能力并有助于恢复图像的纹理细节,本文提出了一种基于对称CNN和递归Transformer实现图像超分辨率的轻量级双峰网络,用于探索结合CNN和Transformer的方式以提高轻量级图像超分辨性能。该模型利用基于CNN的特征精细对偶注意力模块构建子对称CNN网络进行局部特征提取和粗糙的图像重建。然后通过递归Transformer模块以提取图像的全局依赖信息对图像的细节特征做进一步修正。在Set5、Set14、BSDS100、Urban100和Manga109五个基准测试数据集上的实验充分验证了本文提出的方法的有效性。(3)考虑到目前基于卷积神经网络的图像超分辨率方法会随着网络宽度和深度的增加提取到很多重复的特征,这些重复特征会加重网络的计算资源消耗,本文提出了一个用于轻量级图像超分辨率的特征去冗余和自校准模型。该模型以特征去冗余自校准模块为基本构造单元,用于提取和融合特征去冗余和自校准模块提取到的特征以减少重复特征信息。在Set5、Set14、BSDS100、Urban100和Manga109五个基准测试数据集上的实验充分验证了本文提出的方法的有效性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.000851
{DOI}: 10.27251/d.cnki.gnjdc.2022.000851
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的钢卷尺表面缺陷检测系统设计
{Author}: 陈佳星;沈毅;周浩;邓晓辰
{Author Address}: 浙江理工大学机械与自动控制学院;
{Journal}: 软件工程
{Year}: 2022
{Volume}: 25
{Issue}: 12
{Pages}: 21-25
{Keywords}: 机器视觉;钢卷尺;缺陷检测;图像处理
{Abstract}: 针对钢卷尺生产过程中表面缺陷检测效率低下的问题，构建一套应用于实际工业环境下的基于机器视觉的钢卷尺表面缺陷在线检测系统。首先，设计一种实验检测平台用于获取钢卷尺表面的图像；然后，通过图像分割的数字图像处理手段准确定位钢卷尺区域轮廓；最后，采用基于灰度值的模板匹配算法、边缘检测算法及颜色聚类方法对预处理后的图像进行匹配和特征计算，实现对目标物体和区域图像的快速定位和特征提取。结果表明：该检测系统的正确率达95.83%，平均检测速度达5.025 秒/根，基本代替了人工检测，为钢卷尺表面检测提供了一种检查正确率和效率较高的新方法。
{ISBN/ISSN}: 2096-1472
{Notes}: 21-1603/TP
{URL}: https://link.cnki.net/doi/10.19644/j.cnki.issn2096-1472.2022.012.005
{DOI}: 10.19644/j.cnki.issn2096-1472.2022.012.005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的果树树冠检测与特征提取方法研究
{Author}: 王文静
{Tertiary Author}: 肖珂;姚永清
{Publisher}: 河北农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 果树检测;精准喷施;计算机视觉;深度学习;特征提取;三维重建
{Abstract}: 我国果园种植面积稳居世界前列,但是果树在生长过程中经常受到病虫害的侵扰,目前,化学防治方法最常用于防治病虫害。然而传统的化学防治方法非常容易造成农药的浪费,对环境也有很大的危害。在“精准农业”概念的大力推广下,果园喷施过程中逐渐将精准对靶喷施技术应用其中,该技术可以有效提高农药利用率。在精准喷施过程中,复杂背景下的果树树冠区域检测较为困难,不同的果树修剪树形也会影响喷施效果,同时,果树的相关特征信息提取也存在困难。针对上述问题,论文提出 了基于 B-Mask R-CNN(Balanced-Mask Region-based Convolutional Neural Network)复杂背景下多种树形果树的检测与识别方法,另外,提出了多视角立体视觉与飞行时间相机融合的果树树冠三维重建方法。主要的研究内容和成果如下:
(1)针对目前没有公开的多种树形果树数据集的难题,本研究选取矮化密植、小冠疏层、自然开心、自然圆头和Y形5种常见的修建树形果树作为研究对象,建立了多种树形果树图像数据集。首先,通过互联网平台搜集5种树形的果树图像,使用图像标注工具对收集的数据加以标注;其次,为了提高数据集的数据量与提高数据的丰富程度,对原始数据集进行了数据增强,生成的数据集共1500个样本用于后续研究。
(2)针对复杂背景下果树冠层难以识别的问题,本文提出了一种B-Mask R-CNN深度学习模型,对自然环境下的多种树形果树进行检测与识别。本研究使用自制数据集进行训练,改进Mask R-CNN网络模型,在网络模型中引入了 IoU(Intersection over Union)平衡采样,在边界框损失中引入平衡L1损失,并在区域推荐网络中调整锚框比例适应数据集中的目标,最终提出B-Mask R-CNN用于果树的树冠区域检测与树形的识别。试验结果表明,改进后的网络模型,相较于改进前的Mask R-CNN损失能够更快收敛,准确率也得到了提高,最终均值平均精度达到98.7%。与其他算法的检测效果对比,不仅能够同时实现果树区域分割与树形分类,也不易出现误识别的问题,所提算法的平均准确率可以达到99.3%。除此之外,对不同光照、不同树形、不同复杂背景下的果树具有更强的鲁棒性,所提的B-Mask R-CNN模型能够为后续树冠喷施区域的检测与树形识别提供技术支持。
(3)针对果树树冠形状不规整,获取树冠体积与稠密度存在困难的问题,本文提出了基于深度学习的多视角立体视觉(Multi-View System,MVS)与飞行时间(Time of flight,TOF)相机融合的三维重建法用于重建果树三维模型,从而获取果树树冠体积与冠层稠密度。首先,采集果树的彩色图像与深度图像,将采集的多视角彩色图像通过基于深度学习的多视角立体视觉法进行三维重建生成点云模型,深度图像通过转化得到三维点云模型;另外,改进精配准算法,对两个点云进行配准融合,得到更完整的果树点云模型;其次,使用累积法获取点云冠层体积,并使用点云最小外接距中的点云数量来描述冠层密度。将冠层分为上、中、下三个区域,计算不同区域的点云数量,以分析不同区域的密度分布;最后,使用点云数量的比率来量化不同区域的树冠密度。结果表明,与传统MVS算法中的Colmap方法相比,PatchmatchNet深度学习算法重建的平均时间减少了 9.75倍,所提的多视角立体视觉与飞行时间相机融合的三维重建法得到的三维点云模型能够较好地获取到果树冠层体积,其误差在±8%以内。
{URL}: https://link.cnki.net/doi/10.27109/d.cnki.ghbnu.2023.000066
{DOI}: 10.27109/d.cnki.ghbnu.2023.000066
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像降噪与超分辨率重建技术研究
{Author}: 李思泽
{Tertiary Author}: 钱鹏江;吴宴华
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像去噪;多尺度融合;生成对抗网络;超分辨率重建;非局部自相似性
{Abstract}: 图像去噪和超分辨率重建是图像处理领域的重要技术,在国防军事、航天航空、医疗等诸多领域都有重要的应用。图像去噪是提高分类、分割和目标识别等高级计算机视觉任务性能的基础,同时也是解决各种计算机视觉问题的重要组成部分。经典的图像去噪和超分辨率重建方法主要是基于滤波器的方法和基于插值的方法等,这些方法普遍存在对于不同场景的普适性较差的问题。已有的研究成果表明,深度学习用于解决图像去噪和超分辨率重建问题通常比传统的机器学习方法有更好的性能表现。然而,现有的研究大多将图像去噪和超分辨率重建作为两个不同课题开展工作。为此,本文的第一个工作将这两种技术进行整合衔接,目的在于提高处理效率的同时获得更好的处理质量。此外,本文的第二个工作针对图像去噪中的非局部特征开展了深入的研究,利用非局部相似性获得了更好的图像去噪性能。具体来说,本文主要包含以下两个工作:(1)第一个工作针对受噪声干扰图像的去噪和高分辨率重建问题,基于生成对抗网络,提出了新颖的多尺度融合对抗网络模型一体化实现图像去噪和超分辨率重建任务,以恢复受噪声干扰的图像质量。如此将图像去噪和图像超分辨率重建相结合的模式简化了模型学习和分析过程中对图像进行上采样和下采样的过程,避免了重复的输入输出图像操作,有效提高了整个图像分析过程的效率。所提模型的另一个重要改进是多尺度特征融合技术,该技术使用多重不同大小的卷积核来并行扩展感受野,并配合融合感知损失和对抗性损失的新损失度量以优化网络学习。实验研究表明,所提模型受益于多重感受野的多元化特征感知能力,能获得比现有方法更佳的高分辨率图像重建性能,同时消融实验也验证我们设计的新损失度量每项的有效性。(2)第二个工作为了克服已有的图像去噪算法无法获取非局部相似性的缺陷,提出了一个新颖的基于图卷积神经网络的图像去噪方法。所提方法基于图卷积操作,创建了具有非局部感受野的神经元。图卷积是传统卷积操作的推广,用来处理不规则结构的数据。图卷积操作将经典的卷积操作推广到任意的图结构中。在我们提出的方法中,图结构是根据网络中隐含层特征之间的相似性动态构造出来的,从而利用图卷积网络强大的表示学习能力来表达自相似性。更特别的是,我们使用图卷积网络层以一种灵活的方式定义每个像素点的邻域。利用这种方法,我们不仅可以提取依赖于空间相邻像素的特征,而且更能提取出依赖空间距离像素的特征,这些像素可以在隐空间中显示出潜在的特征相关性。实验研究表明,所提模型受益于非局部图卷积操作的特征感知能力,能获得比现有经典图像去噪方法更佳的图像去噪性能。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.002166
{DOI}: 10.27169/d.cnki.gwqgu.2022.002166
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的多车道线检测和分类算法
{Author}: 朱贤臻;魏霞;黄德启
{Author Address}: 新疆大学电气工程学院;
{Journal}: 现代电子技术
{Year}: 2022
{Volume}: 45
{Issue}: 23
{Pages}: 49-54
{Keywords}: 机器视觉;车道线检测;Gamma校正;Gabor滤波器;Hough变换;直方图;截距约束
{Abstract}: 为解决机器视觉在多车道线检测时出现车道线漏识别、误识别、分类难和准确率低等问题，提出一种检测多车道线和快速分类的方法。首先获取原始图像的感兴趣区域并使用Gamma校正增强多车道线特征信息；然后使用多相位Gabor滤波器叠加滤波图像提取车道线纹特征，获得其边缘梯度；接着基于改进带多参数Hough变换提取出直线线段，基于累加角度值的直方图和双截距约束法实现多车道线快速分类；最后只需提取出线段上少量关键点，通过最小二乘法拟合出完整的车道线，生成动态有效的检测区域，减小后续检测时间。实验结果表明：该设计算法在Tusimple数据集与实际拍摄拥挤、夜间环境的道路中进行验证，识别准确率分别为95.4%,96.22%和95.22%，高于其他常用方法；该算法充分利用车道线多个特征信息，不易受检测环境变化带来的影响。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2022.23.010
{DOI}: 10.16652/j.issn.1004-373x.2022.23.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 水下光声图像空间配准算法研究综述
{Author}: 郭银景;马新瑞;许越铖;孔芳;吕文红
{Author Address}: 山东科技大学电子信息工程学院;青岛智海牧洋有限公司;山东科技大学交通学院;
{Journal}: 计算机工程与应用
{Year}: 2023
{Volume}: 59
{Issue}: 05
{Pages}: 14-27
{Keywords}: 水下声光图像;图像配准;图像处理;特征提取;机器视觉
{Abstract}: 水下光声图像配准是水下设备实现信息融合的关键技术。在简述了水下光声图像配准的概念及实例的基础上，分析了目前水下光声图像重建与复原的相关算法，详细综述了水下异源图像基于区域和特征的配准算法研究进展，重点论述了基于图像域和形状特征相似度的两个准确度较高的研究方向的发展现状，并根据其他领域的异源图像配准的研究热点，从增加成像模型的结构性约束、引入相位一致性和生成对抗网络等算法提高配准精度，展望了水下声光图像配准研究的发展趋势。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20221124.1034.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于轻量化卷积神经网络的桥梁斜拉索PE护套损伤识别方法
{Author}: 刘啸宇;黄永;徐峰;李惠
{Author Address}: 上海交通大学船舶海洋与建筑工程学院;哈尔滨工业大学土木工程学院;
{Journal}: 土木与环境工程学报(中英文)
{Year}: 2025
{Volume}: 47
{Issue}: 01
{Pages}: 167-178
{Keywords}: 桥梁斜拉索;智能损伤识别;轻量化神经网络;计算机视觉;深度学习
{Abstract}: 深度神经网络和计算机视觉技术近年来在结构健康监测中发挥了越来越重要的作用。利用无人机航拍采集的桥梁斜拉索损伤图像数据,研究基于深度学习技术的斜拉索PE护套损伤识别方法。为实现在较低运算能力设备上对大跨度桥梁斜拉索表面局部损伤的智能快速识别，解决传统深度卷积神经网络的运算效率相对较低、模型参数规模较大的问题，提出轻量化处理的区域推荐型卷积神经网络模型。介绍区域推荐网络与其轻量化改进方法的理论基础，分析轻量化模型处理的必要性，其能在保证识别精度的前提下降低模型训练与预测的设备性能需求，达到节约计算资源与时间的目的；通过数据增广等多手段解决损伤样本数据量不足的问题，设置对比试验，统计分析结果，验证了轻量化神经网络模型的优越性。结果表明，轻量化网络在牺牲少量识别准确度的前提下，能够在较大程度上实现对模型复杂度与计算量的改进，在工程应用中能有效拓展神经网络的实用性。
{ISBN/ISSN}: 2096-6717
{Notes}: 50-1218/TU
{URL}: https://link.cnki.net/urlid/50.1218.TU.20221121.1737.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度卷积神经网络的小型民用无人机检测研究进展
{Author}: 杨欣;王刚;李椋;李邵港;高晋;王以政
{Author Address}: 南华大学;军事科学院军事认知与脑科学研究所;北京脑科学与类脑研究中心;中国科学院自动化研究所;
{Journal}: 红外技术
{Year}: 2022
{Volume}: 44
{Issue}: 11
{Pages}: 1119-1131
{Keywords}: 计算机视觉;目标检测;视频目标检测;无人机检测;深度卷积神经网络
{Abstract}: 小型民用无人机预警探测是公共安全领域的热点问题，也是视觉目标检测领域的研究难点。采用手工特征的经典目标检测方法在语义信息的提取和表征方面存在局限性，因此基于深度卷积神经网络的目标检测方法在近年已成为业内主流技术手段。围绕基于深度卷积神经网络的小型民用无人机检测技术发展现状，本文介绍了计算机视觉目标检测领域中基于深度卷积神经网络的双阶段算法和单阶段检测算法，针对小型无人机检测任务分别总结了面向静态图像和视频数据的无人机目标检测方法，进而探讨了无人机视觉检测中亟待解决的瓶颈性问题，最后对该领域研究的未来发展趋势进行了讨论和展望。
{ISBN/ISSN}: 1001-8891
{Notes}: 53-1053/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvykHm0La4zwzAfkl_3KtRpObGqyiujH5pAUtd3YtB-946iBmLzOuEwgqpH24Vhjx1gWgAnla1uVDeudoczDwtVb0HUwTYRWlTUXxhrfaOG6ALK_WNST_luV82iJBMvOq488TLuVHtvp2fc4fjpHIckx6qdYSo7sEFmYBJRK72ar0lQWvAoa45_uzlDHbilPf5I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 地铁隧道裂缝图像采集与智能识别方法研究
{Author}: 王耀东;史红梅;朱力强;周维桢
{Author Address}: 北京交通大学智慧高铁系统前沿科学中心;北京交通大学载运工具先进制造与测控技术教育部重点实验室;
{Journal}: 现代城市轨道交通
{Year}: 2022
{Issue}: 11
{Pages}: 1-6
{Keywords}: 地铁;机器视觉;图像采集;图像处理;边缘检测;隧道裂缝
{Abstract}: 文章对盾构隧道表面图像采集系统进行设计，提出一种新颖的隧道裂缝图像智能识别方法。图像采集系统包括面阵相机及光源一体化模块、相机支架、工控机和供电系统，该系统可实现隧道表面图像多目相机同步采集，图像辨识精度达到0.2mm。裂缝图像智能识别方法主要包括：基于边缘检测的深度卷积网络和基于图像后处理的裂缝识别算法，该图像识别算法可实现像素级的裂缝纹理检测以及精细化提取。通过现场实验和数据分析，文章提出的图像采集系统和智能识别方法可为实际隧道裂缝检测提供较好的技术支持。
{ISBN/ISSN}: 1672-7533
{Notes}: 11-5183/U
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzd0JEEhMdme8RE1B06CdIGF0p6J90VVn5swjYDLD6FhTSdkiVGiwhSDVL7sLeGa2dLhUfN0ruSE_xvC4lyGn8gXzW2MTy5tkeqk2T-UfzSEbs9vahOihJ0rk1oAech0eFYn-fn8uf6ieIZOC2VoBNNaBLUGB-W6wZ3rzlwUFKperLxI_wy_kGyhps-RZk1hzk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于RGB-D图像的语义场景补全研究综述
{Author}: 张康;安泊舟;李捷;袁夏;赵春霞
{Author Address}: 南京理工大学计算机科学与工程学院;
{Journal}: 软件学报
{Year}: 2023
{Volume}: 34
{Issue}: 01
{Pages}: 444-462
{Keywords}: 三维场景;语义场景补全;环境理解;计算机视觉;深度学习
{Abstract}: 近年来随着计算机视觉领域的不断发展,三维场景的语义分割和形状补全受到学术界和工业界的广泛关注.其中,语义场景补全是这一领域的新兴研究,该研究以同时预测三维场景的空间布局和语义标签为目标,在近几年得到快速发展.对近些年该领域提出的基于RGB-D图像的方法进行了分类和总结.根据有无使用深度学习将语义场景补全方法划分为传统方法和基于深度学习的方法两大类.其中,对于基于深度学习的方法,根据输入数据类型将其划分为基于单一深度图像的方法和基于彩色图像联合深度图像的方法.在对已有方法分类和概述的基础上,对语义场景补全任务所使用的相关数据集进行了整理,并分析了现有方法的实验结果.最后,总结了该领域面临的挑战和发展前景.
{ISBN/ISSN}: 1000-9825
{Notes}: 11-2560/TP
{URL}: https://link.cnki.net/doi/10.13328/j.cnki.jos.006488
{DOI}: 10.13328/j.cnki.jos.006488
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的自动驾驶行人检测专利技术综述
{Author}: 李朋原
{Author Address}: 国家知识产权局专利局电学发明审查部;
{Journal}: 专利代理
{Year}: 2022
{Volume}: 
{Issue}: 04
{Pages}: 20-27
{Keywords}: 自动驾驶;行人检测;深度学习;特征提取;图像分割;目标识别
{Abstract}: 行人检测技术是一种利用计算机视觉的手段，来判断图像中是否存在行人，并给出行人位置的检测技术。在自动驾驶中，行人检测主要是指对车载摄像设备获取的实时视频进行检测，通过获取行人的相关信息来辅助车辆自动行驶的相关技术。汽车行业对于行人检测的准确性要求极高，行人姿态变化、衣着打扮各异、遮挡问题、运动随机、室外天气光线因素变化等问题都会影响到行人检测技术的准确性乃至可行性，因此行人检测在自动驾驶中一直是一个研究热点和难点。本文介绍了行人检测的技术构成，针对自动驾驶中行人检测领域的专利进行了分析，介绍了行人检测的主要分类，统计并分析了相关专利在全球的申请时间、地域分布，并分析了关键的专利申请、技术发展脉络等，最后对自动驾驶中的行人检测未来可改进的方向进行简要阐述。
{ISBN/ISSN}: 2096-0549
{Notes}: 10-1332/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwGEFQ6E1v2j-LBcm3CAFY_VTOKJpiw6a3deCR33PGIzqv7GJSr0khl4sDVsuz9IX632sWKxcWOchpQihqQgn45CGlF-6tSAnmHSaxOnHfQ2cq755Pyk0zfk6X5K4PcdfpowT0Cacvm_LFAipOlzlKSaZ2KwxFGqvhbjbhdG3C2bSOramw1DqDhiOwojCkWKnM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的运动目标识别与定位
{Author}: 赵佳冉;张爱华;姜超群;蒋群;李建军
{Author Address}: 中原工学院电子信息学院;新郑市恒凯电子科技有限公司;
{Journal}: 智能计算机与应用
{Year}: 2022
{Volume}: 12
{Issue}: 11
{Pages}: 117-121
{Keywords}: 机器视觉;目标识别;灰度重心法;目标定位;物体分拣
{Abstract}: 随着机器视觉技术的持续发展，分拣技术在工业生产中得到了广泛应用。本文提出了一种基于机器视觉的目标识别与定位装置的设计方案，通过识别运动状态物体的形状对其进行分类，同时估计运动物体轨迹，实现物体抓取。本方案中，由工业摄像机采集物体图像，利用全局阈值图像分割大津法(Otsu)进行阈值分割，轮廓逼近确定物体的形状，实现物体形状分类。采用灰度重心法确定物体中心像素坐标，然后利用旋转矩阵和偏移向量之间的矩阵关系将物体中心像素坐标转换为相机坐标，通过刚体变换把相机坐标转换为传送带坐标，获取运动物体坐标信息，实现目标定位。实验结果表明，智能分拣系统对不同运动目标物体抓取率达90%以上，分拣效果较好。
{ISBN/ISSN}: 2095-2163
{Notes}: 23-1573/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxsPsYMPxL58y910DDjDLebW76eKET0EAYv_AuzeVSvesBnLNDhA8cE3ukmkhmn4HVdQnXcNdv3HqBkC01AKzTuLz-fD1uhNCdcIhqk4kRNe4iYKRrK6y0U0sGqO9V_Tvy0xICK-r1iEzVkdn5qTfveVxRpcYo1jmqRAEycS3XQqWBDjb3s87ImQBZWfwG7MVQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的线上教学专注度视觉评估系统
{Author}: 谢沈惟
{Author Address}: 北京邮电大学人工智能学院;
{Journal}: 互联网周刊
{Year}: 2022
{Volume}: 
{Issue}: 20
{Pages}: 32-34
{Keywords}: 线上教学;计算机视觉;人脸识别;深度学习;学生专注度
{Abstract}: 随着互联网技术的高速发展，线上课堂逐渐成为重要的教育场景，并不断促进教育改革创新。与此同时，基于计算机视觉技术的课堂观察和教学评估方法在学者的深入研究下愈发成熟，为教育理念的发展提供了新的思路，也为教育质量提供了可靠的保障。本文分析如何将线上课堂场景与基于计算机视觉的专注度评估技术紧密地结合起来，以人脸识别、情感计算等相关的深度学习技术为核心，设计出实时高效的线上教学专注度视觉评估系统。文中提出的系统通过人脸检测和关键点识别等技术验证学生身份，并检测头部转动角度、眼睛张合度、视线聚焦点、人脸情感积极性等特征来综合判断学生专注度，为线上教学的专注度评估提供可靠的视觉算法解决方案。本文首先探讨线上教学专注度视觉评估的研究背景和意义，然后深入分析相关技术的研究，并提出线上教学专注度视觉评估系统的整体框架，最后发表对研究的总结和展望。
{ISBN/ISSN}: 1007-9769
{Notes}: 11-3925/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwAznFyQjGN4cLPGxVE8FLNJC6FLfqzyr5NwC9MK1tp8R0x7PWG9tO6X0vRDXZVyzLH7mHyHeeMHKSBzOMdL7LHaBIgcneBwsAKuA6YSkZs-xgNJEYcS-eH9kAPNwSt3xLzDHdeR4m9rA8GTYrVNhqWZGDuF1VgK__cU88kqlHB0JuopmNIGixg3FvXJiHZAJM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Halcon的单目相机标定方法与测量实验
{Author}: 李晓晓;吴昊荣;孙付春;杨涛
{Author Address}: 成都大学机械工程学院;成都大学电子信息与电气工程学院;成都农业科技职业学院机电信息学院;
{Journal}: 山东工业技术
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 8-12
{Keywords}: 机器视觉;单目相机;Halcon;标定;测量
{Abstract}: 机器视觉已经在现代工业自动化生产中得到了广泛应用，尤其是在三维测量领域。物体三维空间与二维图像间的关系求解离不开相机标定，尤其是相机标定结果的优劣直接决定了机器视觉的测量精度。通过搭建单目相机视觉系统实验平台，先分析了相机标定的工作原理，再利用Halcon软件的标定助手功能对型号为GB050-2-7×7的圆点标定板进行相机标定，获得了相机的内参和外参。在进一步测量实验中验证了单个特征圆点测量偏差为0.03862 mm、多个特征圆点测量平均偏差为0.05655 mm，二者测量精度都高于0.1 mm，说明了利用机器视觉进行测量能够满足常用精度需求。
{ISBN/ISSN}: 1006-7523
{Notes}: 37-1222/T
{URL}: https://link.cnki.net/doi/10.16640/j.cnki.37-1222/t.2022.05.002
{DOI}: 10.16640/j.cnki.37-1222/t.2022.05.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 语义驱动的特征融合策略及应用研究
{Author}: 翟强
{Tertiary Author}: 程洪
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度视觉推理;场景语义建模;特征融合与交互;目标感知;场景理解
{Abstract}: 特征学习是保障计算机视觉感知算法有效性的关键步骤,特征融合策略是提高特征表征能力的重要技术。现有视觉感知方法还存在对场景语义信息建模不充分以及融合策略单一的不足,无法满足复杂场景对智能系统提出的感知要求。本文研究如何通过建立复杂场景的视觉语义模型,并以此来引导Transformer和图模型实现特征间的交互融合,完成知识传递及认知推理,提高视觉感知精准度。主要研究内容及创新点包括:首先,针对现有方法在理解场景全局上下文信息时忽略了特征间语义一致性而导致跨视图检索次优性能的不足,本文利用深度聚类网络建立跨模态视图全局共性语义模型,并在Transformer框架下实现该共性语义模型与各模态个性化特征的交互融合与增强,提取模态不变性表征,完成跨视图检索。本文在两个挑战数据集上的实验表明该算法获得了同期最优跨视图检索精度。其次,针对现有确定性建模方法忽略了推理过程中的因纹理相似引入的固有不确定性的不足,本文提出基于贝叶斯神经网络的不确定度量化网络模型,设计了原型化语义模型建模目标局部语义,在Transformer框架下建立局部和全局语义间的强化映射,实现场景中隐藏目标识别。此外,本文研究成果表明,目标边缘位置是推理过程中不确定度较高的区域,本文进一步设计了聚合语义模型将网格特征映射至图特征空间,并在图空间实现两个子任务特征交互与推理,充分挖掘目标边缘与区域的互补作用,有效区分目标前景与背景语义。本文提出的两种算法在三个公开验证集上均超过了同期最优隐藏目标检测精度。最后,针对现有方法因视图间特征错误匹配和几何仿射关系估计误差导致的多视图场景人群密集程度估计性能损失,本文提出了协同通信图卷积方法,在聚合语义图特征空间完成视图内推理和视图间通信,充分利用多相机视图间的相互引导信息,无需场景结构先验信息实现视图特征融合。本文在三个公开场景集上验证了该算法的有效性,并超过同期最优场景人群密度估计精度。本文的研究将进一步提高现代智能系统的感知能力,对推动智能系统的迭代升级具有重要的理论意义和实用价值。本文的研究成果可以应用于智能驾驶、智慧医疗、智慧农业、机器人等领域。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004794
{DOI}: 10.27005/d.cnki.gdzku.2022.004794
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于边缘检测与霍夫变换的螺钉视觉识别
{Author}: 程鑫;刘一鹏;彭程;夏一恒
{Author Address}: 武汉理工大学机电工程学院;湖北省磁悬浮工程技术研究中心;
{Journal}: 数字制造科学
{Year}: 2022
{Volume}: 20
{Issue}: 03
{Pages}: 163-168
{Keywords}: 边缘检测;霍夫变换;机器视觉;螺钉识别
{Abstract}: 针对工业生产中螺钉识别精度、效率不高的问题，设计了一种基于机器视觉的螺钉识别系统。通过工业CMOS相机采集图像，对工件图像进行自适应滤波，并基于特征颜色进行图像RGB到HSV的转换和均衡化，克服了不确定的外部因素干扰；基于特征颜色的边缘检测方法实现了目标定位，设计了基于霍夫变换的螺钉识别方法，并在Qt Creator平台内进行了测试与验证。结果表明，所提出的方法能有效识别工业生产环节中的螺钉，具备较好的检测精度与实时性。
{ISBN/ISSN}: 1672-3236
{Notes}: 42-1693/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyny5sBLWtsO2VOZ2e4ssBgiTGNoojUTn_DVcoLBdkSATjGTqyC6qFJxtQRYyLTZLtL1ozQh9tkzoShErvNB6SywDuTYRV5-hNxhXs1wtOAVU6yumRxkPv2MMZkas3GnOa875NAQAzgUMJQfdKnM9iU3a1xjHx4SH4CMuZr3FEEK0ap91lUmXeeyOAq33VAZUk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合视觉与雷达数据的改进粒子滤波车辆目标跟踪
{Author}: 张翔;郑玲;李以农;张志达
{Author Address}: 重庆大学机械与运载工程学院;重庆大学机械传动国家重点实验室;
{Journal}: 重庆大学学报
{Year}: 2022
{Volume}: 45
{Issue}: 09
{Pages}: 28-38
{Keywords}: 车辆跟踪;机器视觉;毫米波雷达;信息融合;粒子滤波
{Abstract}: 针对视觉跟踪中由于尺寸变化累积误差导致目标丢失的问题，提出一种融合视觉与毫米波雷达数据的改进粒子滤波车辆跟踪算法。首先，引入遗传算法改善标准粒子滤波中的粒子退化与粒子衰退问题，根据退化程度计算动态自适应的遗传交叉概率，并利用高斯分布替代平均分布计算种群适应度。然后，将图像HSV直方图特征与改进粒子滤波算法结合，实现车辆多目标跟踪。最后，通过雷达目标投影点与视觉跟踪框的位置关系实现关联匹配，利用深度信息修正跟踪框的位置与尺寸。实验结果表明，相对于标准粒子滤波，改进的粒子滤波算法可以使平均跟踪准确率与精度分别提高22.1%与21.1%。相对于仅采用视觉跟踪，融合雷达数据的跟踪算法能够使车辆目标跟踪精度再次提高9.2%。
{ISBN/ISSN}: 1000-582X
{Notes}: 50-1044/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyvqry9I8UoDLNWhYaiKSY8SnkIrfJZynUuZKHKw_WK1vQTSINdOnwYG61F9lvGH78GKYp7-vsviYLxYjG5Ff1iHl_p9DrXvLr4EIk72SAjmEa37G5PfdnjA8FWftaw3bKIucp-OTp-fPnOFZHl53U3y4iKtiH0hkQ1MXZq7WvOKDcx9JvwCPEElhzKoqvRtfY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于无人机技术的交通数据采集
{Author}: 尹万杰;申明亮;温双银
{Author Address}: 中国市政工程中南设计研究总院有限公司;武汉大学;
{Journal}: 黑龙江交通科技
{Year}: 2022
{Volume}: 45
{Issue}: 09
{Pages}: 152-155
{Keywords}: 占道施工;交通疏导;无人机数据采集;数字图像处理;计算机视觉技术
{Abstract}: 以孝感市董永北路立交桥工程占道施工对城市交通造成的负面影响及减缓措施研究为背景，需对施工前路网交通状况进行调查和数据采集，并利用交通仿真及评价软件对拟采取的施工期间交通疏导方案进行择优选取。现场交通调查和数据采集是较重要的一部分，利用无人机技术进行道路交通数据视频采集，结合数字图像处理和计算机视觉技术，对车流量进行高效化、便捷化、智能化的自动读取和统计，再结合软件调整优化疏导方案，为降低工程建设对城市交通的影响提供基础数据和决策依据。
{ISBN/ISSN}: 1008-3383
{Notes}: 23-1207/U
{URL}: https://link.cnki.net/doi/10.16402/j.cnki.issn1008-3383.2022.09.057
{DOI}: 10.16402/j.cnki.issn1008-3383.2022.09.057
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于双目仿鹰眼视觉与超分辨的果园三维点云重建
{Author}: 张自超;陈建
{Author Address}: 中国农业大学工学院;自然资源部超大城市自然资源时空大数据分析应用重点实验室;
{Journal}: 吉林大学学报(工学版)
{Year}: 2024
{Volume}: 54
{Issue}: 05
{Pages}: 1469-1481
{Keywords}: 机器视觉;仿鹰眼感知;超分辨率重建;双目视觉;果园三维点云
{Abstract}: 针对双目视觉受限于分辨率与基线距，对远距离目标感知精度不足，在室外光照条件复杂的情况下，无法完成稳定感知，获取三维点云质量无法满足果园作业需求的问题，提出一种基于双目仿鹰眼视觉与超分辨的果园三维点云重建方法。本文模拟鹰眼双中央凹高清成像，通过超分辨率重建改善感知精度；模拟捕食经验所得鹰眼注意力机制，融合参考目标图像特征，提高目标候选区域感知精度与稳定性。针对果园三维点云导航地图，在多种光照条件下，误差比最大降幅为12.2%，标准差最大降幅为2.305。针对果树作业三维点云，点云质量改善较大，可以提供精确的三维空间信息，较为完整地还原果树各枝干三维空间信息。
{ISBN/ISSN}: 1671-5497
{Notes}: 22-1341/T
{URL}: https://link.cnki.net/doi/10.13229/j.cnki.jdxbgxb.20220816
{DOI}: 10.13229/j.cnki.jdxbgxb.20220816
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉与深度学习的防疫垃圾识别系统研究
{Author}: 陈家俊
{Author Address}: 宁波职业技术学院;
{Journal}: 科技传播
{Year}: 2022
{Volume}: 14
{Issue}: 17
{Pages}: 145-149
{Keywords}: 垃圾分类;计算机视觉;深度学习;OpenCV;MobileNet结构模型
{Abstract}: 基于计算机视觉与深度学习的防疫垃圾识别系统，由能进行图像特征加强的目标定位系统和基于深度学习的识别分类系统构成，对待识别垃圾完成二维图像采集后，使用OpenCV检测和定位目标物品，识别分类系统利用基于深度学习的MobileNet模型对目标图像进行识别与分类。本研究以常见的医用防护口罩、医用橡胶手套、防护面罩、消毒药剂瓶为例，对它们进行自动识别和分类，以实现在垃圾处理中有效减少人工投入，降低垃圾处理环节的感染风险的目标。
{ISBN/ISSN}: 1674-6708
{Notes}: 11-5820/N
{URL}: https://link.cnki.net/doi/10.16607/j.cnki.1674-6708.2022.17.032
{DOI}: 10.16607/j.cnki.1674-6708.2022.17.032
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉微小螺纹孔缺陷智能检测技术的研究
{Author}: 林杰;宣寒玉;宋学勇;赵敏
{Author Address}: 苏州凌云视界智能设备有限责任公司;苏州电加工机床研究所有限公司;
{Journal}: 制造技术与机床
{Year}: 2022
{Volume}: 
{Issue}: 09
{Pages}: 104-110
{Keywords}: 机器视觉;微小螺纹孔;缺陷检测
{Abstract}: 针对手机结构件中微小螺纹孔质量检测难题，使用多相机组合的创新设计和光学结构系统创新，通过包含图像采集技术、数据传输技术、多种缺陷的分类技术，以及缺陷图片存储和分析等技术的研究，设计了一种基于机械视觉微小螺纹孔缺陷智能检测系统性方法。不仅介绍了该检测方法的硬件系统如相机、镜头、光源和棱镜等硬件的设计方法，还介绍了螺纹小径的测量算法、螺纹圈数检测算法等螺纹检测算法和软件的设计方法。最后，通过实验研究，该技术方法的先进性和可行性得到了验证，为该技术的推广应用奠定了理论与实验基础。
{ISBN/ISSN}: 1005-2402
{Notes}: 11-3398/TH
{URL}: https://link.cnki.net/doi/10.19287/j.mtmt.1005-2402.2022.09.016
{DOI}: 10.19287/j.mtmt.1005-2402.2022.09.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉技术在印刷品检测领域的进展
{Author}: 郑元丰;邱妍;高艳飞
{Author Address}: 中山火炬职业技术学院;
{Journal}: 丝网印刷
{Year}: 2022
{Volume}: 
{Issue}: 15
{Pages}: 46-48
{Keywords}: 机器视觉;印刷检测;人工智能
{Abstract}: 机器视觉技术用于印刷品质量检测环节推动了产业发展。综述了近年来机器视觉技术在印刷领域的研究进展，为印刷技术的智能化发展提供新的视角。
{ISBN/ISSN}: 1002-4867
{Notes}: 11-2348/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyBQG5c4tYYHjwdjh83Ud3a_7MWRJwi1GQ1CST8Z9N4RYuLAljpbwFc-naxLO32ouqmAi_dq4iEh9Qd7-ZheLdd-ChQ0DQcVk-pwB9sbyk4V5vpP9wXjTOXdXBHVm8X8UVBM7gwTdUbDvO0l007E8CMFfJmjAI6pI6eYD5C8qnCKWAz_BVDHJ9D332CiZvCjx8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 无人机自主着舰技术研究
{Author}: 刘丰;于洋;郭璇;毕卫红;高佳玥
{Author Address}: 燕山大学信息科学与工程学院;河北省特种光纤与光纤传感重点实验室;
{Journal}: 燕山大学学报
{Year}: 2022
{Volume}: 46
{Issue}: 04
{Pages}: 353-361
{Keywords}: 无人机;自主降落;机器视觉;PD控制
{Abstract}: 无人机与无人艇协同工作是进行海洋生态灾害面积调查最为先进的技术之一。为了实现无人机能够自主降落在无人艇，以灵活适应生态灾害调查的实际工况需求，提出了一种基于机器视觉与降落平面姿态主动反馈相结合的无人机自主降落方案。利用机载摄像头获得无人艇及周围环境信息，对捕获到的图像使用双边滤波法进行噪声去除以及图像增强等处理。在OpenCV环境下通过霍夫变换识别出为降落而设计的独特降落标志，使无人机运动到无人艇的正上方。同时，设计了一套用于无人机在动态平面上降落的检测装置，实现无人机在无人艇上自主可靠降落。研究结果表明：采用上述方案，在降落平面与水平面的夹角以6°为阈值的情况下，能够使无人机在动态平面上的降落成功率得到约30%的提升。
{ISBN/ISSN}: 1007-791X
{Notes}: 13-1219/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwWlfFKm6v6kYXFbCeXsYue0JjzlmilyxEW2rnjow6XzvwOat2Wpe_KTjIeDrdNKwxGcvzrPOWJCk_3N7ZtrLyGOE47DB1PS8NNVZEC47GJV8ye_G2klM7p9TuuWNTG-IP9TcrK2z0cM-QxAzbLxGRAVgxYOEwroIual3WkCQ3N4gvJfcyHIL2uDtOP7YlgOdQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 依据批归一化卷积神经网络算法的木材类别机器视觉识别方法
{Author}: 袁科文;张贯宇;刘送永;杨建华;卢硕辰;刘后广
{Author Address}: 中国矿业大学;
{Journal}: 东北林业大学学报
{Year}: 2022
{Volume}: 50
{Issue}: 07
{Pages}: 94-98
{Keywords}: 木材分类;批归一化;卷积神经网络;机器视觉
{Abstract}: 以巴西植物区系的树种为研究对象，提出一种依据批归一化的卷积神经网络算法的木材类别机器视觉识别方法。以VGG-16模型为基础，通过批归一化对输入数据进行处理调整卷积神经网络的中间输出参数，以2个全连接层替换VGG-16模型原全连接层，使用5标签的SoftMax分类器替换原SoftMax分类器，构建一个依据优化后的全连接层和SoftMax分类层相结合的新型木材种类识别模型(模型包括卷积层、批归一化层、激活层、池化层、全连接层、SoftMax分类层)。以桃花心木(Swietenia macrophylla)、苏里南维罗蔻木(Virola surinamensis)、轴状独蕊木(Erisma uncinatum)、酸枝木(Dalbergia cochinchinensis)、黄金檀木(Cordia elaeagnoides)5种木材纹理图片为训练样本(原始样本455张、增强样本2 730张),输入模型进行训练并测试，检验模型对木材类别的识别准确率。结果表明：依据批归一化卷积神经网络算法对木材类别的识别准确率，比AlexNet、VGG-16、GoogLeNet模型更好；经批归一化和数据增强处理后，构建的卷积神经网络模型可以加快模型的收敛速度，提高模型的泛化能力，木材类别识别准确率达到99.46%。
{ISBN/ISSN}: 1000-5382
{Notes}: 23-1268/S
{URL}: https://link.cnki.net/doi/10.13759/j.cnki.dlxb.2022.07.010
{DOI}: 10.13759/j.cnki.dlxb.2022.07.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的光纤端面缺陷检测技术应用
{Author}: 周猛;杨兰玉;王超
{Author Address}: 中国矿业大学;
{Journal}: 自动化技术与应用
{Year}: 2022
{Volume}: 41
{Issue}: 07
{Pages}: 129-131+136
{Keywords}: 机器视觉;表面缺陷;检测算法;图像处理
{Abstract}: 针对传统的人工检测具有准确性不高、效率低、劳动强度大等缺点，研究机器视觉代替人工检测相关技术，阐述利用机器视觉检测光纤端面缺陷的研究现状、现有的视觉软件和硬件组成，综述图像处理算法以及缺陷判定算法，并对未来可能的发展方向进行展望。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2022)07-0129-04
{DOI}: 10.20033/j.1003-7241.(2022)07-0129-04
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的玉米种子分类识别方法
{Author}: 吕晨曦;杨冬风
{Author Address}: 黑龙江八一农垦大学电气与信息工程学院;
{Journal}: 乡村科技
{Year}: 2022
{Volume}: 13
{Issue}: 14
{Pages}: 155-158
{Keywords}: 玉米种子;分类识别;支持向量机;主成分分析
{Abstract}: 随着图像处理技术和机器视觉技术的应用越来越广泛，利用计算机视觉技术来识别玉米种子已经成为可能。基于此，利用主成分分析法（PCA）与支持向量机（SVM）对3种玉米种子进行分类识别，以提高玉米种子的纯度。采用高斯滤波、图像裁剪、图像分割及区域二值化对采集的3个种类（甜糯黄玉米、甜妃、昌甜）的玉米种子图像进行预处理，采用数据增强方法提高样本容量和普适性。对经过处理后的图像从颜色、几何、纹理3个方面进行特征提取，总共提取15种特征。采用主成分分析（PCA）、线性判别分析（LDA）、等距特征映射（ISOMAP）、T分布随机近邻嵌入（T-SNE）、多维尺度变换（MDS）等方法对特征数据进行降维处理，并将处理后的数据放入Bayes分类器与支持向量机（SVM）中进行玉米种子的分类识别。将两种分类器分别与五种降维算法相结合，对比其对玉米种类识别的准确度。结果表明，经过主成分分析降维后的数据结合支持向量机对玉米种子的品种识别具有较高精度，可以提高分类识别的准确率。
{ISBN/ISSN}: 1674-7909
{Notes}: 41-1412/S
{URL}: https://link.cnki.net/doi/10.19345/j.cnki.1674-7909.2022.14.034
{DOI}: 10.19345/j.cnki.1674-7909.2022.14.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在食用菌生产中应用现状研究
{Author}: 白冰;卢闯;马世宇;杨镇
{Author Address}: 辽宁省农业科学院;葫芦岛农函大玄宇食用菌野驯繁育有限公司;
{Journal}: 辽宁农业职业技术学院学报
{Year}: 2022
{Volume}: 24
{Issue}: 04
{Pages}: 60-64
{Keywords}: 食用菌生产;机器视觉;智慧农业;三维空间信息
{Abstract}: “一带一路”国家倡仪的提出，对食用菌出口带来前所未有的发展机遇，同时面临食用菌产业转型升级的挑战。如何有效保质增产是目前食用菌生产中亟待解决的重要问题。机器视觉作为智慧农业的重要组成部分，其在食用菌生产中的应用研究对实现食用菌智能化生产及保质增产有重要的意义。介绍了国内外机器视觉在食用菌生产中应用的研究现状，分析了目前机器视觉在食用菌生产中应用存在的问题，提出了促进机器视觉在食用菌生产中应用的三项对策建议，即使用特殊光源采集食用菌二维图像、保持食用菌栽培环境光线均匀、使用三维机器视觉采集食用菌三维空间信息。
{ISBN/ISSN}: 1671-0517
{Notes}: 21-1448/G4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw_AHhDfGH5ORArmY8gGLehdSpp2i7OHosxICQS7xAlxB8CtuzdQ65vmfZLp1decINni36tCsqBIazk8K0Uhr4ec18ZtGVJS8__G-rB4PhmLyDTpMToqGnV1FHC0IxLXOHRm4j-DHVJaAJj5kQP_pAAoAapYaYIS_0_j82jNFICx535WCrgMT8yO51Mgk9xm7A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的编织袋表面缺陷检测系统设计与实现
{Author}: 钟飞;赵子丹;夏军勇;黄露
{Author Address}: 湖北工业大学机械工程学院;
{Journal}: 包装工程
{Year}: 2022
{Volume}: 43
{Issue}: 13
{Pages}: 247-256
{Keywords}: 机器视觉;编织袋缺陷;改进遗传算法;二维最大熵;缺陷识别
{Abstract}: 目的 针对编织袋生产中表面缺陷检测效率和精度低等问题，应用机器视觉技术于编织袋表面缺陷检测，进而提高编织袋的生产效率。方法 基于机器视觉设计编织袋表面缺陷检测系统：首先为了降低背景灰度变化对缺陷检测的影响，研究一种同时具有噪声滤除与图像增强功能的预处理算法；其次选取二维最大熵值法对预处理后的编织袋图进行分割，并采用改进遗传算法对它进行优化以增强算法的收敛速度和效果；然后利用特征提取结合形态学处理的方法实现了编织袋表面缺陷的识别与分类；最后应用连通域进行分析，对分类出的缺陷进行统计与定位以获取缺陷的尺寸以及位置信息。结果 采集了200个编织袋缺陷样本，采用文中编织袋表面缺陷检测系统对编织袋样本进行缺陷识别，平均识别准确率为94.0%，处理一幅编织袋图像的时间约为600ms。结论 该系统具有较高的识别效率和正确率，可实现编织袋表面缺陷的快速检测，满足工业生产的需求。
{ISBN/ISSN}: 1001-3563
{Notes}: 50-1094/TB
{URL}: https://link.cnki.net/doi/10.19554/j.cnki.1001-3563.2022.13.032
{DOI}: 10.19554/j.cnki.1001-3563.2022.13.032
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的表情识别算法研究
{Author}: 路延
{Tertiary Author}: 黄树成
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;深度学习;多尺度特征提取;FM-Meta伪标签算法
{Abstract}: 表情识别技术是机器学习领域的一个热点和难点问题,在很多领域有着较好的应用前景,快速、精准识别人类面部表情可以满足日渐增长的社会需求。但是,目前的识别技术还存在不同的问题:在表情识别模型进行特征提取阶段,由于表情发生时间短暂、发生的动作幅度小、不同的面部区域发生的表情动作幅度不同,若提取不到更为细致的表情特征,则会导致表情模型的识别率低且泛化能力不足;在表情识别模型训练阶段,由于表情数据样本量不充足,样本类别不平衡,训练集和测试集存在分布差异问题,会导致表情识别模型对个别类表情识别能力弱且鲁棒性差。为了解决上述问题,本文的工作和成果如下:(1)设计了一种用于表情识别的多尺度特征提取深度模型(FCNet)。FCNet包括两个部分——多尺度表情特征提取模块(Fef)和坐标注意力机制算法。Fef模块主要由3个Tfe结构组成。Tfe是一种三分支的特征提取结构,其使用了不同尺度的卷积核,在每一个卷积层后都使用了BN层,并使用Relu激活函数进行非线性变化,增强了FCNet的泛化能力和表情特征学习能力,提升了训练速度和收敛速度。在Tfe结构完成特征提取后,通过跳跃连接的方式,使FCNet获取了融合浅层信息和深层信息的特征。这之后,使用坐标注意力机制对这些融合特征分配基于人脸位置信息的通道权重,增强了FCNet对表情数据的学习能力,最终提升了表情识别的性能。(2)为了继续提升表情识别性能,首先设计了一种过采样算法——FM算法。FM算法包含两种策略:针对相同类别表情的过采样策略和针对不同类别表情的过采样策略。FM算法通过数据扩增的方式缓解表情样本的不充足、不平衡问题。其次基于FM算法,进一步设计了FM-Meta伪标签算法。FM-Meta伪标签算法使用两种数据训练表情识别模型——无标签数据和有标签数据。FM-Meta伪标签算法包含两个神经网络——教师网络和学生网络。相较伪标签算法,教师网络会自适应的根据学生在标签数据集上的表现反馈进行调整,这种调整是依据有标签数据和无标签数据分布差异来进行的。更新后的教师网络以基于无标签数据生成伪标签的形式来指导学生网络训练。通过教师网络与学生网络并行训练,学生网络的表情识别性能会得到提升且更具鲁棒性。在FER2013和MMA数据集上进行了实验验证。实验结果表示,与传统算法相比,FCNet在表情识别准确率上显示出较好的鲁棒性。而进一步使用FM-Meta伪标签算法之后,不仅提升了FCNet的表情识别的效果,而且为模型处理无标签数据提供了一种新的训练方式。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2022.000173
{DOI}: 10.27171/d.cnki.ghdcc.2022.000173
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轴套尺寸测量技术的研究
{Author}: 吕宁
{Tertiary Author}: 周亮
{Publisher}: 哈尔滨工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;Zernike矩亚像素;轴套;光平面标定;光平面参数优化
{Abstract}: 近年来,我国的航天事业不断发展,对火箭的发射成功率有了更高的需求。轴套是火箭发动机中应用极为广泛的一种零件,通常可达上万个。精密可靠的轴套对于火箭发动机有非常重要的作用,对航天事业的发展有着重要的意义。在实际测量中,通常采用传统接触式测量方法进行人为的抽样检测,存在主观因素影响、可能划伤轴套表面等问题。其他的非接触式测量如激光法等主要应用于满足一定材料条件的大型工件中。三坐标测量仪测量较慢,且对测量环境要求很高,不适合于大批量的轴套测量。因此要设计出一套基于机器视觉的轴套测量机构,从而实现对一系列不同规格的铜套进行测量,经过图像处理,获取其内外圆同心度、内外圆直径、厚度信息,判断其是否合格。主要研究工作包括:进行轴套视觉检测系统的原理性结构设计,设计整体控制流程,开发相关的视觉测量软件;针对其中的测量环节,分别分析计算并选型搭建二维尺寸与厚度的视觉测量环境;开发二维视觉测量算法,通过图像预处理、像素级边缘检测、Zernike矩亚像素边缘检测等技术得出轴套内外径、圆心距;开发厚度视觉测量算法,建立相机标定数学模型;结合激光细化的Steger算法以及投射交比不变性进行光平面的标定,并对光平面法三维测量的原理进行分析以实现厚度测量;设计二维尺寸与厚度视觉测量实验,测得同心度的最大测量误差为14μm,内外径最大测量误差19μm,厚度最大测量误差为23μm,达到了设计标准。针对光平面标定中存在的结果不稳定、易受外界影响的问题,提出一种基于LM算法的光平面参数优化算法,采用数个标准量块对测量系统进行二次标定;开展二次标定实验,以人为干扰的形式来创造一个不准确的测量系统,之后对其进行优化,得到轴套厚度的测量误差从0.1mm减少到了最大19μm,证明了优化算法的可靠性。本文分别对轴套的内外径与厚度的视觉测量进行了研究,搭建了硬件环境并开发了相关算法;进行了相关测量实验,结果表明达到了设计精度;开发了视觉测量软件,设计了轴套的自动化视觉检测流程,实现了轴套的高精度视觉测量。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.001634
{DOI}: 10.27061/d.cnki.ghgdu.2022.001634
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制骨架动作识别的算法研究
{Author}: 何璠
{Tertiary Author}: 兰红
{Publisher}: 江西理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 动作识别;有向图卷积;注意力机制;中心差分网络;转换器
{Abstract}: 随着现代信息技术的发展,视频增长非常迅速,现已成为当今主流媒体之一。视频内容的理解成为了现阶段计算机视觉领域的研究热点。动作识别发展从传统的手工提取特征到如今利用图卷积网络模型,用于研究的方法越来越高效,模型越来越自动,所取得的效果也越来越显著。大部分提出的模型为在固有的数据集中获得较好的视频表示,可模式化视频中的空间静态和时间动态信息。但由于人体动作识别使用三维运动信息,在获取时空信息和在真实视频中快速准确的识别人的动作仍存在很多问题。为解决这些问题,本文从人体骨架、图像卷积特征、视频时空卷积几方面进行研究,利用图卷积进行动作识别。本文的主要工作如下:(1)为了增加更具特征性的骨架运动信息获取的准确率,提出了一个注意力增强有向图卷积网络(Attention Enhanced Direct Graph Convolutional Network,ADGCN)。由于在日常生活中对于骨架动作识别的应用通常是将骨骼和关节信息作为输入数据,并对输入数据统一进行特征提取,这种方式获取的输入数据没有考虑到关节与骨骼之间的运动信息以及动作视频中的关键动作或关节。因此本文提出的ADGCN模型首先采用一个四流框架,将关节信息、骨骼信息、关节运动信息和骨骼运动信息这四种信息输入到四流框架中。然后将输入的数据传送到有向图卷积网络模型中提取关节和骨骼之间的依赖关系,再利用提出的时空通道注意力网络,增强每个视频的关键帧或每一帧中的关键关节的时间、空间以及通道的信息。模型在NTU-RGB+D和Kinetics-Skeleton数据集上进行训练、验证和测试,并在NTU-RGB+D数据集上进行消融实验,结果表明,提出的ADGCN模型相比于已有的模型具备一定的优势。(2)为使骨架模型能识别出特征提取的时空信息,提出一个中心差分转换器图卷积网络(Central Difference Transformer Graph Network,CDTG)。由于大部分骨架动作识别模型都聚焦节点信息,并获取局部的时空依赖关系,这种方法获取的信息没有意识到节点间梯度信息和全局时空上下文对动作识别的重要性。而本文提出的CDTG模型首先将关节和骨骼的运动信息输入到模型中,经过处理后将数据传送到本文网络中进行聚焦节点和节点间的梯度信息,增加网络的表示能力和泛化能力,随后利用提出的时空转换器图卷积,提取出中心差分网络中的时空特征,和被关节标记的空间和时间依赖关系。最后将CDTG模型运用到NTU-RGB+D和Kinetics-Skeleton数据集上,结果证明,与其他已有模型对比,CDTG模型具有更好的识别性能。
{URL}: https://link.cnki.net/doi/10.27176/d.cnki.gnfyc.2022.000459
{DOI}: 10.27176/d.cnki.gnfyc.2022.000459
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 化妆棉卷的缺陷检测系统设计
{Author}: 梁云峰
{Tertiary Author}: 陈革;赵建刚
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;棉卷缺陷检测;特征提取;缺陷分类;功能模块设计
{Abstract}: 化妆棉卷是用于化妆棉裁切机生产化妆棉棉片的原料。现有的自动化裁切机无法识别剔除缺陷棉料,在实际生产中,需要在前道工序中检测棉卷质量并记录缺陷位置以便在自动裁切过程中剔除废料。目前的缺陷检测工序是通过检测人员通过肉眼观察棉卷来检测棉卷缺陷,存在检测效率和准确度低下的问题。为此,本文针对化妆棉卷的缺陷进行了自动检测系统的设计,以金属屑、污点、折痕、水刺、撕裂缺陷作为检测对象,确定了化妆棉卷缺陷检测系统的整体方案,设计并测试了化妆棉卷的缺陷检测算法,完成了缺陷检测原型软件的开发。本文的研究内容包括如下:(1)设计了化妆棉棉卷缺陷检测系统整体方案。结合检测系统的设计需求,在现有检测设备的基础上完成了检测系统总体架构的设计。对图像采集系统的各个组成部分归纳总结后,根据检测要求对相应的硬件进行计算和选型,完成了图像采集系统和处理系统的设计。(2)设计了棉卷缺陷检测的算法。首先进行缺陷区域提取,对比研究多种缺陷提取算法,设计了根据不同缺陷进行不同处理的缺陷提取方法,该方法能够高效完整地提取图像中的缺陷信息。通过对多种棉卷缺陷样本的分析,确定了以缺陷的特征参数作为判定标准来进行缺陷分类的方案。对比研究高斯混合模型(GMM)和多层感知器模型(MLP)后,选择了检测精度更高的高斯混合模型分类算法。实验结果表明本文提出的化妆棉棉卷缺陷检测算法检测精度可以达到98.07%,速度可以达到73.39m/min,满足化妆棉棉卷的检测需求。(3)完成了棉卷缺陷检测软件原型系统的开发。使用Halcon与C#混合编程集成了本文提出的缺陷检测算法,用户登录后,可以对相机参数进行设置并控制相机采集图像,检测到缺陷后对棉卷进行评级,使用数据库作为缺陷数据和棉卷数据存储的中心,具备直观友好的人机交互页面。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000113
{DOI}: 10.27012/d.cnki.gdhuu.2022.000113
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉在质量检验检测中的应用研究
{Author}: 沈浩淳
{Author Address}: 南车投资管理有限公司;
{Journal}: 机车车辆工艺
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 11-13
{Keywords}: 人工智能;机器视觉;质量检验
{Abstract}: 文章介绍了机器视觉的基本原理，以及在质量检验检测中的典型运用，运用效果良好。随着智能制造技术的不断深入，后期发展前景广阔。
{ISBN/ISSN}: 1007-6034
{Notes}: 32-1181/U
{URL}: https://link.cnki.net/doi/10.14032/j.issn.1007-6034.2022.03.004
{DOI}: 10.14032/j.issn.1007-6034.2022.03.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于均值滤波和小波变换的单幅图像去雾算法
{Author}: 崔建伟;王冬青;刘金燕
{Author Address}: 青岛大学自动化学院;
{Journal}: 计算机与数字工程
{Year}: 2022
{Volume}: 50
{Issue}: 06
{Pages}: 1339-1342
{Keywords}: 图像去雾;Haar小波变换;均值滤波;环境光;HSV颜色空间
{Abstract}: 雾霾天气造成图像质量下降,进而影响计算机视觉系统的特征提取。论文提出一种改进的单幅图像去雾算法。先通过正交Haar小波变换进行处理得到图像的低频分量和高频分量,然后基于大气物理模型将低频分量利用均值滤波对环境光和大气光进行估计,得到低频去雾图像。然后将低频去雾图像与小波分解后的高频图像进行重构。最后将重构后的RGB图像转换到HSV颜色空间增强图像亮度。实验结果表明,论文算法简单有效,改善了图像质量,增强了去雾图像的边缘特征,利于计算机视觉进行特征提取。
{ISBN/ISSN}: 1672-9722
{Notes}: 42-1372/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxzRp3788gcm0OF6rfmHkJsDrOxyX-nNCkKrKAWcXWWMEdLZXjK52NzUNnaP0MeJibWqP4CinfBClTlf_k_AtPS4aD6nytMADe56a9EfOs7-Ufm8SwVJgj-8NZRbbsY7LiNH-HOYL-SSj8U-YYe_sapVEyx5tlmJdt3CjgY2Wq95v5caaPWwKestX9zze8CBaA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的擦玻璃机器人研制
{Author}: 杨向东;潘文彬;麦铠芮;张陈宏;周汶锋
{Author Address}: 广州华立学院机电工程学院;
{Journal}: 智能制造
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 55-58
{Keywords}: 机器视觉;擦玻璃;机器人
{Abstract}: 本文研发了一款擦窗机器人结构，在机器人下方产品上设计了真空吸盘，利用真空泵抽出吸盘内空中产生的负压气体，将机械人完全贴合于花窗玻璃上；使用机器视觉OpenMV软件的AGAST算法并结合硬件STM32F103的控制识别，控制电机驱动；最后进行机器人样机开发工作，并对该机器人进行了负载检测和擦试效果检测。试验测试结论：(1)在正常光照射的情况下，污点的识别率为93%，污点擦除率为100%；(2)采用像素延迟低的通用加速分割检测（AGAST）算法，可提高样机的定位准确度；(3)机器人与玻璃间的负压比为2.8 kPa。
{ISBN/ISSN}: 2096-0581
{Notes}: 10-1315/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvysaUC16J_LBRTKXMFdK4yG5UajlEk-0XWprsoKyDc-Fbq7TaL_TfpnKFjCTyPFYuOPKayVWotlDHAbcwdetTKi0zzTf09ipiol0y1G24jyCbOOEl76vPLhjzNnqkGMSlkWlcVJc1BEQsHCyN2BrpHTDK0tUNWZvJC7ImA7u-WFJmolyUgMbaWzVF3uu36LhbE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向真实场景的图像超分辨率算法研究与识别应用
{Author}: 佘宇
{Tertiary Author}: 徐焕宇
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像超分辨率;多尺度卷积;模糊核估计;级联网络
{Abstract}: 图像超分辨率算法能够在成像设备性能受限的情况下,提高图像分辨率,恢复图像高频细节,提升视觉感官效果,是计算机视觉领域的一个重要分支。目前基于深度学习的图像超分辨率算法研究趋向于通过加深和加宽网络来提升性能,但这样做也可能带来梯度弥散和特征冗余等问题,从而引起网络退化,并且大多数研究忽略了不同尺度特征的充分利用,进而影响了网络重建效果。此外,目前研究主要使用理想降质模型(例如双三次插值降采样)获取低分辨率图像,而在真实场景中图像降质会受到噪声、模糊和机械振动等诸多因素的影响,过程比较复杂且难以量化,不符合理想降质模型的假设,导致超分辨率算法应用在真实场景时性能严重下降。本文针对以上问题进行深入研究,主要工作如下:(1)提出基于多尺度卷积和残差密连注意力结构的图像超分辨率重建算法。通过引入多尺度卷积和残差密连方法以及注意力机制对SRRes Net中的特征提取结构进行改进,设计一种多尺度残差密连注意力结构,充分利用了丰富的多尺度特征信息,促进了信息的筛选与流通,并通过融合局部和全局特征来解决网络长期依赖的问题。在对比实验中本文提出的算法在客观与主观指标上均取得了较好的效果。(2)改进基于模糊核估计的图像降质方法。改进的降质模型从真实场景的低分辨率图像中提取模糊核信息和噪声信息,并将这些先验知识作用在高分辨率图像中生成接近真实场景的低分辨率图像,以此构建符合真实场景分布的数据集。经实验证明,使用改进的降质方法训练的超分网络在模拟和真实图像实验中性能均优于理想降质方法训练的网络,有效提升了超分辨率网络在真实场景中的应用效果。(3)将上述超分辨率方法应用到交通标志识别场景。交通标志图像由于现实场景的限制,图像质量普遍不高,识别准确率较低。本文利用超分辨率技术提升交通标志识别效果,并提出超分级联网络对目标任务进行针对性优化。通过实际应用证明了超分辨率技术不仅可以提升真实场景的图像质量,也有助于提升其他计算机视觉任务的效果。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.001133
{DOI}: 10.27248/d.cnki.gnjqc.2022.001133
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的救援机器人的设计与研究
{Author}: 全瑞琴;刘岩;徐媛媛;陈振兵
{Author Address}: 新疆工程学院控制工程学院;
{Journal}: 工业仪表与自动化装置
{Year}: 2022
{Volume}: 
{Issue}: 03
{Pages}: 64-68+74
{Keywords}: 救援机器人;图像处理;视觉识别;目标定位
{Abstract}: 随着人工智能的快速发展，救援机器人要能快速准确地实施救援，最重要的就是要能看见，机器视觉的提出解决了这个问题。机器视觉是一项综合技术，主要用计算机来模拟人的视觉功能，从客观事物的图像中提取信息，进行处理并加以理解，最终用于实际检测、测量和控制，这也是救援机器人寻找被困者、处理地形环境以及将图像传送至操作者的根本。机器视觉的加入使救援机器人更加灵活，同时也为救援机器人智能化提供了必要条件。该文将工业相机作为视觉传感器，完成目标识别与定位任务。利用C语言编程在keil5软件平台开发，植入嵌入式实时操作系统FreeRTOS的STM32F427IGHx芯片中，以完成对机器人的实时控制。通过实验验证了视觉识别及定位方法的可行性。
{ISBN/ISSN}: 1000-0682
{Notes}: 61-1121/TH
{URL}: https://link.cnki.net/doi/10.19950/j.cnki.cn61-1121/th.2022.03.014
{DOI}: 10.19950/j.cnki.cn61-1121/th.2022.03.014
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉域泛化技术及研究进展
{Author}: 徐海;谢洪涛;张勇东
{Author Address}: 中国科学技术大学信息科学技术学院;
{Journal}: 广州大学学报(自然科学版)
{Year}: 2022
{Volume}: 21
{Issue}: 02
{Pages}: 42-59
{Keywords}: 域偏移;域泛化;模型鲁棒性;深度学习;人工智能
{Abstract}: 近年来，机器学习理论和深度学习算法在计算机视觉领域发展迅速，并且在目标检测、语义分割、动作识别等任务场景中得到广泛应用。然而，实际部署中模型效果往往依赖于训练域和测试域服从独立同分布这一假设，受域偏移(Domain shift)现象影响严重。域偏移(即目标域数据分布与训练域不一致)对模型的泛化性提出了巨大挑战，使得域泛化(Domain generalization)技术成为计算机视觉领域一个重要的研究方向。域泛化研究如何在单一或者多个源域上进行模型训练，使其能够在具有不同数据分布的未知目标域上保持良好的泛化性，为模型应用提供了重要的保障。文章对近年来计算机视觉领域中域泛化研究具有代表性的论文进行梳理和总结，概述视觉域泛化技术及其研究进展。首先对域泛化的任务定义、任务特点和研究思想进行详细阐述；其次，遵循域泛化研究思路，从增广数据空间、优化模型求解和减小域间差异3个大方向分类总结域泛化领域的最新研究成果；随后介绍了域泛化技术在计算机视觉任务中的应用以及已公开的大规模数据集；最后讨论了域泛化研究领域未来可能的研究方向。
{ISBN/ISSN}: 1671-4229
{Notes}: 44-1546/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz7l8sHLjVGaKAo7AT9pubbm2QYJ7_p7PvYgqp_tthjPWiMDycHoALVpuMbeW_3Wq0tOli39Oru4ZFYNT5VuSlS06K9-aihGHB7rRdCmQyUhxmsj18_xSCOt79EBQQDA7xbc9Eiy1uBEtjSD049muzHHwcT6hLBGabW_nnk4Iq4H3WMD874Brma_ujSskyc0uo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的无接触快速尺寸测量方法
{Author}: 龙丹丹;吴文麟;周军
{Author Address}: 西南科技大学制造过程测试技术省部共建教育部重点实验室;
{Journal}: 航空精密制造技术
{Year}: 2022
{Volume}: 58
{Issue}: 03
{Pages}: 10-13
{Keywords}: 尺寸测量;机器视觉;非接触式测量;图像处理
{Abstract}: 本文基于机器视觉技术提出了一种非接触式的零件尺寸快速测量方法。该方法同时可以做到以较快的速度和较低的成本对零件进行测量。经过大量实验测试，本文算法测量精度在±0.002mm以内，可以适用于大多数需要快速高精度测量工件的场合。
{ISBN/ISSN}: 1003-5451
{Notes}: 11-2847/V
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxCmN4F-UNBaRnZc0sjajWz4NjKyhMsEOWmmvc7Q-JdDqhedJuxfP0S-8tann5AOYWyO4OevFp3FrwXXPVOAUxwFKo5ShEw1HwgCgnB7DTOE_I3FufpG-VKcmuzwGorsVe8VlCjdSkGC9vhaSXzydPw78ftcfyaLQQ5UJbvnWzAxcrM1fXI1WYN3vJSavHAxbo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的焊缝缺陷识别方法研究
{Author}: 张思;石峰
{Author Address}: 中石化工程质量监测有限公司;洛阳欣隆工程检测有限公司;
{Journal}: 河南化工
{Year}: 2022
{Volume}: 39
{Issue}: 06
{Pages}: 15-19
{Keywords}: 焊接缺陷;检测;预处理;机器学习;深度学习
{Abstract}: 焊接技术被广泛应用于航空航天、机械、核能、船舶及石油化工等领域。为保证焊缝质量，提升焊接件的可靠性，对焊接件进行无损检测是一个不可或缺的环节。随着计算机技术的发展，焊缝缺陷的识别方法已成为目前的研究热点。基于机器视觉的焊缝缺陷识别方法进行了综述，分别介绍了焊缝缺陷图像的预处理、基于机器学习的缺陷检测以及基于深度学习的缺陷识别，指出了未来的研究方向，为该领域进一步深入研究提供参考。
{ISBN/ISSN}: 1003-3467
{Notes}: 41-1093/TQ
{URL}: https://link.cnki.net/doi/10.14173/j.cnki.hnhg.2022.06.007
{DOI}: 10.14173/j.cnki.hnhg.2022.06.007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 复杂背景下基于LBP纹理特征的运动目标快速检测算法
{Author}: 裘莉娅;陈玮琳;李范鸣;刘士建;李争;谭畅
{Author Address}: 中国科学院上海技术物理研究所;中国科学院大学;中国科学院红外探测与成像技术重点实验室;
{Journal}: 红外与毫米波学报
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 639-651
{Keywords}: 机器视觉;背景建模;LBP纹理特征;运动目标检测;复杂背景
{Abstract}: 在雨雪天气、树叶晃动、水面闪烁等有复杂背景的可见光与红外场景中，快速准确地提取完整目标一直是运动目标检测中的首要难题。为了满足实时性，并针对现有视频的前景提取算法依赖先验信息、召回率低、缺乏纹理和噪声较大等问题，提出了一种基于直方图统计和改进的局部二值模式（Local Binary Pattern,LBP）纹理特征相结合的背景建模方法。首先，使用各像素直方图的众数作为参考背景，无需先验知识，节省了大量存储空间，再采用邻域补偿策略提出了一种改进的S＿MBLBP纹理直方图与参考背景进行背景建模，消除了大部分动态背景和光照变化影响，实现目标的精确提取。实验表明，所提的算法在红外和可见光的多种复杂场景下，能快速提取前景目标的同时，提高了准确率和召回率。
{ISBN/ISSN}: 1001-9014
{Notes}: 31-1577/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw7uY5fVtN3Gk6fSK5EevwvsHHh0q6RF5pr3e2voNCQtAvp4lyzaP8yoP3gcnQt79nAjhFI8cl93DuyfIIj-0douhRwNZDMvyR4Z8PoRxZd7BIARTJbZeG0D3mABLmzW9KJbxjqVAtC4JZ1a4SO5w9eLrWpBfXBjsN_Ge6mN5hwetdlkhQKxujOvB8I34yat-g=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于孪生网络的目标跟踪技术研究与实现
{Author}: 李雪辉
{Tertiary Author}: 张拥军
{Publisher}: 军事科学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;目标跟踪;孪生网络;注意力机制;无锚框
{Abstract}: 目标跟踪作为计算机视觉领域中的基础研究内容之一,在智能视频监控、自动驾驶、智慧农业和智能交通等领域中被广泛应用。随着大规模公开标注的图像数据资源的出现与计算机硬件计算能力的进步和发展,优秀的目标跟踪方法不断涌现,其相关研究也取得了极大的进展。虽然目标跟踪技术在当前有着良好的发展环境和发展势头,也促进了许多其他计算机视觉任务的发展,但是由于实际应用场景的多样性,跟踪环境和目标自身运动规律的复杂多变,目标跟踪仍是一项具有诸多挑战的任务,实现一个高性能的跟踪器也仍然需要克服很多难点。为此,本文针对复杂环境下的目标跟踪问题展开研究,以孪生网络为基础,首先提出了一种融合注意力机制的目标跟踪算法,其次提出了一种无锚框的目标跟踪算法,最后基于以上算法进行了原型系统设计与实现,并且选取权威数据集对本文提出算法的有效性进行了验证。本文的主要贡献包括以下两个方面:(1)针对跟踪算法在复杂场景中易受干扰因素影响,导致判别能力下降的问题,提出了一种融合注意力机制的孪生网络目标跟踪算法。首先,该算法解除了孪生网络结构的平移不变性,采用深度神经网络提取具有不同特性的多层次特征,尽可能地捕获相关信息。然后,引入注意力机制,分两阶段对响应图的计算进行了调整和设计,在第一阶段构建了交叉相关模块DCAM(Depth-wise Cross-correlation with Attention Mechanism,DCAM),第二阶段设计并实现了一种高效的自适应响应图融合策略。两阶段的设计使响应图在计算的过程中,能够具有全局视角,对获取到的信息进行有侧重的筛选,更加关注目标的相关信息,抑制干扰因素带来的影响,从而实现稳定准确的目标跟踪。(2)针对回归任务设计复杂和跟踪模型性能不理想的问题,提出了一种基于孪生网络的无锚框视觉目标跟踪算法。首先,该算法在前述算法的基础上,通过无锚框的方式回归目标边界框,在简化回归任务复杂程度的同时,保证了跟踪结果的准确性。然后,为缓解网络训练中样本类别不均衡的问题,采用可动态缩放的交叉熵损失作为目标定位网络的损失函数,修正模型的优化方向,提升了跟踪算法的整体性能。最后,设计相应的学习率调整策略,对一定数量的模型进行随机权重平均,增强了跟踪模型的泛化能力。基于上述研究成果,我们进行了原型系统的设计与实现,搭建配置了实验所需环境,并对实验内容进行了详细设计,用于验证本文提出算法的有效性。本文选择权威数据集VOT2018与VOT2019对提出的算法进行了测试和评估,并且与当前主流的目标跟踪算法进行了对比。实验结果表明,与现有方法相比,我们提出的算法在准确度和鲁棒性上均有明显提升,同时算法在整体性能上也有不错的表现。
{URL}: https://link.cnki.net/doi/10.27193/d.cnki.gjsky.2022.000120
{DOI}: 10.27193/d.cnki.gjsky.2022.000120
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的链轮尺寸测量方法
{Author}: 包昊菁;刘思远;任真;张云辉;胡正乙;葛宇鹏
{Author Address}: 吉林大学机械与航空航天工程学院;长春大学机械工程学院;华南理工大学机械与汽车工程学院;长春汽车工业高等专科学校产教融合发展中心;
{Journal}: 吉林大学学报(工学版)
{Year}: 2023
{Volume}: 53
{Issue}: 10
{Pages}: 2795-2806
{Keywords}: 机器视觉;链轮;尺寸测量;参数标定
{Abstract}: 由于链轮形状的限制及现场测量对效率的要求，现有的外参标定方法很难应用于链轮轮毂端面的外参标定。因此，本文提出了一种基于二次曲线不变性的外参标定方法，该方法将加工有同心圆环的圆柱体放置在链轮中心孔内，利用圆环上大、小圆及链轮轮毂孔的半径计算出3个圆所对应的方程系数，并以此为基础获得链轮轮毂端面的外参。根据链轮齿廓的形状特征，提出齿顶与齿根圆区域上最高点及最低点筛选模型，并利用最高点数组及最低点数组通过椭圆拟合获得直径。在实验中，将4个不同尺寸的链轮作为被测对象，并将采用本文测量方法获得的结果与三坐标测量仪获得的结果进行对比，结果表明，本文提出的链轮齿根圆与齿顶圆的直径测量误差小于40μm。
{ISBN/ISSN}: 1671-5497
{Notes}: 22-1341/T
{URL}: https://link.cnki.net/doi/10.13229/j.cnki.jdxbgxb.20211384
{DOI}: 10.13229/j.cnki.jdxbgxb.20211384
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于双目立体视觉系统的测量研究
{Author}: 闫小宇;陆凡凡;葛芦生;伍孟涛;刘彬
{Author Address}: 安徽工业大学电气与信息工程学院;
{Journal}: 重庆工商大学学报(自然科学版)
{Year}: 2023
{Volume}: 40
{Issue}: 03
{Pages}: 48-55
{Keywords}: 计算机视觉;双目测距;块匹配算法;摄像机标定
{Abstract}: 为了实现摄像机与目标物体之间距离的信息，由双目测量原理，采取结合OpenCV与Matlab的方式，设计出一套关于双目测距的立体视觉系统；系统首先对双目摄像机的内外参数进行标定，从黑白格组成的标定板中获得角点信息，使用亚像素角点检测法对角点坐标信息进行更精确检测，在黑白格组成的标定板分别距离双目摄像机300、400、500、600、700 mm处获取不同位置的标定图像，经过张正友标定法最终可以得到双目摄像机所需内外参数；其次通过BM(Block Matching)立体匹配算法在VS2017坏境与opencv 3.4.7库配合下完成了摄像机的立体校正、立体匹配进而得到视差图；最后在实验中使用了双目摄像头，并编写了代码通过鼠标点击所得到的视差图获取对应的世界坐标来实现物距的测量；实验结果表明：被测物距离摄像头光心500～700 mm这一范围时，实测距离和实际距离相对误差百分比在0.171%～0.192%之间，且实测距离在2 950 mm内实验误差小于5%满足实验精度要求。
{ISBN/ISSN}: 1672-058X
{Notes}: 50-1155/N
{URL}: https://link.cnki.net/doi/10.16055/j.issn.1672-058X.2023.0003.007
{DOI}: 10.16055/j.issn.1672-058X.2023.0003.007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的输电线路巡检研究
{Author}: 黄世鸿
{Tertiary Author}: 张兆云
{Publisher}: 东莞理工学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人工智能;智能巡检;图像处理;图像识别;故障检测
{Abstract}: 目前,人工智能在电力行业得到了广泛的应用,基于机器视觉输电线路巡检是其中的一种典型应用。通过无人机采集线路图片,然后采用人工智能方法对图像进行分析处理,对线路的异常进行判别。系统中,输电设备的识别和故障检测是其关键技术之一。输电线路巡线图像检测目标主要包含绝缘子、防震锤和间隔棒三种输电设备,针对输电设备的识别,提出了基于集成学习和基于深度学习两种类型输电设备识别算法。并针对绝缘子自爆缺陷检测提出了一种基于形态学的缺陷检测算法。在基于集成学习的识别算法中,采用所提出的候选框生成算法获取输电设备的候选框;并设计一种基于集成学习的分类器对候选框截取的图像进行检测;提出一种冗余预测框消除算法除去检测过程中产生的多余预测框;实现输电设备识别。实验证明所提出的冗余预测框消除算法能更好地筛选处定位框,检测精度提高了0.03。所提出的基于集成学习识别算法相比于其他的基于浅层分类器的检测方法更具有优势。在基于深度学习输电设备算法中,以Faster RCNN作为基础框架,采用改进的残差网络作为其特征提取网络。并提出一种聚类算法对样本的标记框进行分析,以获取网络中的预设锚尺寸。实验证明该聚类算法能使得模型对输电设备检测的m AP值提高0.83%。所提出的深度学习算法相比之下具有更强大的输电设备识别能力。在输电设备识别的基础上,对绝缘子的自爆缺陷进行检测,提出了一种基于形态学的绝缘子缺陷检测算法。首先提出一种图像分割算法将绝缘子从目标图像中提取出来。然后提出绝缘子空间形态调整算法将绝缘子形态归一化,简化检测过程。最后建立数学模型描述绝缘子的状态,实现绝缘子的缺陷检测。该算法不仅能够有效定位绝缘子的缺陷位置,还能检测绝缘子的损伤程度。采用现场采集的数据集,对基于集成学习和基于深度学习的两种类型输电设备识别算法以及基于形态学的绝缘子缺陷检测算法进行了测试和验证,结果表明:新提出的三个算法均优于其它对比算法,具有一定的学术创新性和工程应用价值。
{URL}: https://link.cnki.net/doi/10.44357/d.cnki.gdgut.2022.000027
{DOI}: 10.44357/d.cnki.gdgut.2022.000027
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的多层多道动态排道规划及焊缝定位
{Author}: 贾文龙
{Tertiary Author}: 薛龙;杨拴岐
{Publisher}: 北京石油化工学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 焊接机器人;多层多道;动态排道;焊缝初始点定位
{Abstract}: 中厚板焊接工件通常选用多层多道的焊接方式进行填充。在焊接前一般通过人工示教的方式进行焊缝初始点定位,然后通过人工布道的方式进行多层多道焊接填充。为进一步降低机器人在工作过程中人为干预的工作量,提升焊接机器人的焊接质量,本文基于机器视觉方法,针对中厚板焊接的焊缝初始定位及多层多道焊动态排道规划两个方面展开研究工作。全文主要成果如下:(1)搭建了一套机器人焊缝初始点定位及多层多道动态排道焊接实验系统。以遨博机器人、视觉传感器、奥太焊机等相关设备组成移动焊接机器人系统,并设计了校核界面和各设备之间的通讯程序,方便进行焊缝初始点定位及多层多道动态排道焊接实验。(2)基于图像卷积神经网络及机器视觉的视觉处理方法,实现焊缝初始点的自动精确定位。使用卷积神经网络算法,训练出用于识别焊缝区域的深度学习模型,然后通过分析V形坡口的结构光成像,给出了结构光焊缝坡口成像特征点的图像处理算法,实现了焊缝坡口初始点定位目的。(3)编写了焊道检测视觉处理算法,实现多层多道焊接动态排道。通过焊接实验获得焊道截面积与焊接电流等焊接参数的关系式,并给出了多层多道焊接过程中填充层的焊缝轮廓特征点识别算法,在焊接过程中在线计算焊缝坡口剩余宽度及高度信息,实现中厚板工件多层多道动态排道焊接。(4)为了验证动态排道和初始点定位算法的有效性,依据搭建好的实验平台,进行了中厚板焊接多层多道动态排道和焊缝初始点定位试验。试验结果表明动态排道试验获得的中厚板焊道填充合理,未出现气孔、未焊透、夹渣、咬边等焊接缺陷;焊缝初始点定位精度达到0.2mm,满足机器人焊接初始点定位要求。
{URL}: https://link.cnki.net/doi/10.27849/d.cnki.gshyj.2022.000081
{DOI}: 10.27849/d.cnki.gshyj.2022.000081
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向小样本的目标检测技术研究
{Author}: 张涛
{Tertiary Author}: 陈金龙
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;数据增强;小样本学习;注意力机制;自动编码器
{Abstract}: 目标检测技术在计算机视觉领域无论是学术研究还是现实应用中都是最热门的技术之一。目前,主流的基于深度学习的目标检测方法大都需要大规模的标注数据以实现检测模型的训练过程,但是在部分特殊场景,如稀有动物、军事安全与罕见疾病等领域想要获得大量的样本数据进行标注以及完成目标检测模型的训练任务是比较困难的。因此,基于小样本情景下的目标检测技术应运而生。本文基于样本数据增强,图片特征提取,网络模型调整这三个方向,提出了面向小样本的目标检测的理论与思路,本研究主要实现的工作内容如下:(1)提出了一种基于BIG-GAN与Mosaic相结合的数据增强方法。通过将Mosaic与传统数据增强对样本数据进行初步增强,并在一阶段增强的基础上使用BIG-GAN网络进行二次增强,通过二阶段的数据扩充的方式,对小样本数据进行扩充处理,从数据稀疏这一基本问题出发,对检测模型性能进行优化提升。(2)搭建了一个基于自动编码器的小样本特征提取网络。在VGG16网络的基础上,添加通道注意力机制,通过自动编码器搭载算法网络,实现在小样本情况下对样本特征学习提取能力的提升,并设计基于样本图像与重构图像多种相似度计算的评价方法,量化特征提取能力指标。(3)设计了一个基于改进残差网络的目标检测算法,通过对特征提取网络上的残差结构进行了宽度加深,修改正则化,添加通道与空间注意力,并通过自动编码器构建特征池,使用特征匹配实现注意力对于特征区域加权机制的完善。以此改善小样本情景下的注意力机制对特征图关键区域的权重调整不合理,对目标特征与位置信息的提取不充分问题进行消除,从模型调整的方向实现小样本情景下目标检测精度的提升。实验结果显示,将本文给出的算法方法与普通的深度学习检测算法比较,在小样本数据集上具有较良好的效果,小样本数据增强目标检测的平均精度在公开数据集上提升了6%左右,图像还原相似度提升4%左右,改进的残差网络在VOC2007数据集和RSOD-Dataset在平均精度上分别提升了5.2%与8%。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000911
{DOI}: 10.27049/d.cnki.ggldc.2022.000911
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的手术导航定位系统的设计与实现
{Author}: 吴杰
{Tertiary Author}: 陈辉
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 手术导航;双目视觉;三维重建;空间配准;ICP算法
{Abstract}: 当前,颅内外科手术主要依靠医生的经验,操作复杂,手术后创伤大,极大地延长了患者的康复期。随着人工智能技术的迅速发展,手术导航定位系统已成为当前的研究热点。脑部手术定位要求导航系统具有高精度、高实时性,目前国外手术的导航定位技术较高,但仪器价格昂贵,国内的手术导航系统定位精度较差,因此研究一款高精度、高实时性的手术导航系统已成国内亟需解决的重要问题。为了提高手术导航定位的精度和实时性,本文基于机器视觉的手术导航定位系统进行了研究。具体研究内容如下:第一,构建了基于机器视觉的光学手术导航定位系统。为解决开颅手术中穿刺精度低、术后效果差的问题,本文构建了应用于开颅手术的光学手术导航系统,设计了双目相机,红色标记球,自制手术器械,患者头模等辅助工具。第二,研究了脑部图像三维重建方法。通过对比面绘制和体绘制方法的优劣,选择光线投射法进行三维重建。本文使用的光线投射法能够产生质量较高的图像且能够很好的反应不同组织边界处的变化情况。通过开展体绘制实验,实验结果表明本文的光线投射法进行三维重建的效果更佳,符合医学图像处理对于准确性的要求。第三,研究了手术导航的患者配准方法。通过使用红色标记球作为标记点,该标记球可以分别在患者空间和图像空间显示,基于该标记球实现了患者空间配准方法。患者配准方法分为两步执行:第一步实现患者空间和图像空间的粗配准,提出了多特征点法的粗配准方法代替传统的三点法,该方法可以使初始配准阶段产生更好的初始变换值;第二步实现患者空间和图像空间的精配准,提出了点到面的ICP算法对传统ICP算法进行优化,该方法将传统的以点到点的距离构造误差函数改进为以点到平面的距离构造误差函数,不仅进一步提高了配准精度,且减少了求解陷入局部最优解的可能。通过实际实验验证,结果表明本文的方法的配准误差小于2.5mm,能够满足一般手术导航定位系统所需的精度要求。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000358
{DOI}: 10.27049/d.cnki.ggldc.2022.000358
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于关注机制的图像语义理解方法研究
{Author}: 苏静
{Tertiary Author}: 戴青云
{Publisher}: 广东工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 层级图像分类;视觉叙事;关注机制;CNN-LSTM
{Abstract}: 图像作为人类视觉感知的重要途径,是人工智能时代海量数据的主要来源,因此,如何对海量的图像数据进行智能化理解是当前图像理解领域需要解决的主要问题。近年来,深度学习在图像分类和图像描述等图像理解研究与应用中取得了显著的研究成果,但是,具有复杂语义的图像理解,例如层级图像分类和视觉叙事等任务,仍然存在很大的探索空间。层次图像分类和视觉叙事任务需要对图像本身高层复杂语义进行理解,它们相对于当前流行的图像分类与图像描述任务显得更加复杂、也更具挑战性,有着很强的理论研究与应用价值。层级图像分类问题中,由于层级图像中的类别之间具有严格的层级关系,且精细级类别之间相似度较高,准确识别这些层级类别对计算机仍然是个难点问题。视觉叙事旨在为连续的图像生成连贯的和富有表现力的故事性描述,它不仅需要对复杂场景以及图像之间的关联关系进行识别,更需要对抽象语义进行理解,这给当前计算机图像理解技术提出了更高的挑战。基于以上问题,本文在对深度学习相关理论研究基础上,采用关注机制分别从双关注、局部特征关注-全局语义以及多层级关注这三个方面对于图像理解中的层级图像分类和视觉叙事问题展开了深入研究。论文的主要研究工作如下:(1)提出了一种基于双关注机制的层级图像分类模型。针对现有层级图像分类方法多用于固定层级的识别,本文构建了一种基于CNN-LSTM的通用识别模型DACL(dual-attention CNN-LSTM),引入空间特征维度和空间语义维度的双关注模块,用于同时解决固定和可变层级分类问题。该模型通过空间特征关注机制学习不同类别对应的更具判别性的细粒度特征,并且通过空间语义关注机制对各类别间的相关性进行建模,从而增强模型关键信息的判别能力,有效提升模型的泛化性。本文使用CIFAR10、CIFAR100和外观专利图像数据集对所提方法进行了验证,实验结果表明了所提出的DACL方法在精准度和准确率方面相对其他现有的层级图像分类方法的优越性。(2)提出了一种融合局部特征关注机制和全局上下文语义的视觉叙事方法。本方法采用一种端到端的长短时记忆网络模块并行方法实现视觉叙事,解决了传统的视觉叙事方法采用串行长短时序记忆网络模块,网络参数过多,计算量大,过度耗费网络资源的缺陷。本文在考虑全局上下文语义的条件下结合局部特征关注机制,将序列图像信息作为全局图像特征,通过多层感知器学习序列图像的故事主题信息,同时将单张图像信息作为局部特征并引入关注机制,得到文本对应的特征关注图,分别实现对图像与图像间、图像与文本间依赖关系的构建。本方法有效解决了传统长短时记忆网络模块方法中因序列图像分开输入,只关注单图像与文本之间的关系,忽略了序列图像间关联关系存在的不足。本文的方法在两个公用图像数据集(DII和SIS)上进行了实验,实验结果显示本文的模型取得了良好的效果。(3)提出了一种基于层级关注机制的视觉叙事生成算法。本文利用BERT模型丰富的语义提取能力,构建了句子级和词语级两层长短时记忆网络模型,并引入句级与词级关注机制实现序列图像的故事性描述。该模型在底层首先对句级语义进行建模,关注每个图像与对应句子语义间的映射关系同时也关注图像与图像、句子与句子间的关联关系,负责提取每个图像的高层主题信息,再在第二层基于该主题对词级语义进行建模,重点关注每个图像与该句文本中的每个单词的映射关系,负责学习每个单词对应的图像特征信息。本方法能够有效改进传统视觉叙事方法生成的句子语法问题多,表达方式过于简单的缺点。实验结果表明,在自动评估指标BLEU和CIDEr下,本文的模型优于大多数方法,同时,本文的方法在人类评估中的各项指标中表现良好。综上所述,本文基于关注机制的图像理解中的若干关键问题,结合最新深度学习理论方法展开研究,其内容是计算机视觉与自然语言处理交叉学科的创新研究,对解决现实中的应用问题有着十分重要的研究意义。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000055
{DOI}: 10.27029/d.cnki.ggdgu.2022.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于红木微观结构的分类与识别算法研究
{Author}: 杨霄霞
{Tertiary Author}: 刘晓平
{Publisher}: 山东建筑大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 红木;纹理特征融合;卷积神经网络;图像分割
{Abstract}: 红木作为一类珍贵的木材,具有极高的经济价值、艺术价值和研究价值。古代名贵的家具和部分木结构建筑使用红木作为连接构件或装饰性材料,现代部分家具、装饰品也使用红木提高建筑环境舒适性。准确、快速鉴定和识别红木的种类对古代木结构建筑构件修复、红木家具市场材种鉴定和木材进出口贸易检验都具有十分重要的意义和价值。目前红木材种的辨识方法有化学方法、DNA方法、光谱鉴定方法和解剖学方法,基于图像对红木辨识的研究以解剖学方法为主,该方法存在的问题主要有两点:一是,红木微观图像获取困难,需对木材进行取样、染色、脱水等处理制作成木材切片,借助显微镜采集红木微观图像;二是,基于计算机视觉方法对红木的辨识研究较少,多依靠有经验的专家对红木完成材种鉴定。本文从红木微观图像采集、多维纹理特征融合、卷积神经网络、管孔特征提取等方面进行研究,以解决红木鉴定中自动辨识问题。本文的研究内容和创新点如下:(1)应用显微CT重构红木横切面、径切面和弦切面微观图像,为山东建筑大学木结构建筑用材标本馆创建红木数字标本库,为采用计算机视觉方法在红木材种辨识方面的研究奠定基础。(2)根据红木微观结构不同组织分布的特点与规律,针对红木单一纹理特征材种辨识方法的局限性问题,本文提出多维纹理特征融合的红木辨识方法。将单一的LBP(Local Binary Patterns)特征及变形形式分别与GLCM(Gray-level Co-occurrence Matrix)和Tamura特征融合,构建5种特征融合方法,分别结合径向基、BP神经网络和极限学习机实现红木横切面、径切面和弦切面图像的分类与识别。实验结果表明,特征融合的分类准确率普遍高于单一特征。(3)为探究多种切面组合对红木辨识准确率的影响,构建一种卷积神经网络模型(Con Net Model),分别以红木横切面、径切面或弦切面图像作为模型输入,实现材种辨识。该模型的Inception模块使用多个不同尺寸的卷积核获得多尺度特征,同时在Leaky Re LU激活函数前和残差块跳线上加入增益层对模型进行优化,与经典的分类模型相比,该模型能显著提高辨识准确率和分类效率。分别将红木试件的单一切面、两切面组合、三切面组合作为Con Net Model模型的输入,训练卷积神经网络红木辨识模型,比较不同切面组合方式对材种辨识准确率的影响。经过多次实验比较得出,单一切面辨识准确率结果高于两切面组合或三切面组合。(4)基于红木横切面微观图像不同组织、结构分布的规律和特点,提出基于管孔特征的红木辨识方法。首先构建管孔分割模型(Onet),该模型由上、下2个“U”形网络结构构成。2个“U”形结构接受同一个输入,经特征提取和带有不同卷积操作的特征融合,实现管孔的精确分割。其次,提出管孔特征的红木辨识模型(Dual Resnet18)。该模型引入上下并行的残差块结构,并且在Re LU激活函数前和残差块跳线上引入增益处理,与经典模型相比,此模型在红木材种辨识方面具有显著的优越性。综上所述,本文提出的多维纹理特征融合红木辨识算法、卷积神经网络红木辨识算法和管孔特征红木辨识算法,实现了红木分类与识别的智能化与“机器专家”决策系统化。保证木结构建筑构件的准确材种鉴定,尊重建筑构件修复过程中的相同材种等比例替换原则,保留建筑原有制式和时代特色,实现建筑文物修旧如旧。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2022.000658
{DOI}: 10.27273/d.cnki.gsajc.2022.000658
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 串番茄目标精准识别定位与采摘策略研究
{Author}: 荣佳诚
{Tertiary Author}: 王蓬勃
{Publisher}: 苏州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 番茄采摘机器人;机器视觉;深度学习;抓取姿态估计
{Abstract}: 随着我国人口老龄化和城镇化的快速发展,从事农业生产的劳动力持续减少,农业生产面临着劳动力短缺和人力成本快速上升的问题。尤其是番茄生产逐渐由小农户生产转向规模化温室种植,用工矛盾日益突出,因此,推动番茄收获工作由人工采摘向机器人自主采摘转变十分必要。本文以玻璃温室中种植的樱桃番茄为研究对象,重点研究番茄采摘机器人在非结构化环境中整串收获和单粒收获番茄的目标识别定位、抓取姿态计算以及采收策略等技术难题。本文主要研究内容如下:(1)番茄采摘机器人视觉伺服系统的设计和构建。根据温室樱桃番茄种植农艺和机器人智能采收作业空间的需求,构建“Eye-in-hand”手眼视觉系统。首先,以六自由度协作型机械臂为例,介绍了采摘机器人视觉伺服系统的控制原理和“Eye-in-hand”手眼标定原理。然后,对构建的视觉伺服系统进行手眼标定,求解出手眼变换矩阵。最后,对相机和手眼视觉系统的定位精度进行校验测量,在室内测得相机与目标距离600 mm时的平均定位误差为2.91 mm。(2)番茄整串收获的果梗识别定位和姿态计算方法研究。针对串番茄果梗细小造成定位误差较大、容易误切割的问题,提出了一种基于远近景结合的果梗切割点精准定位方法。首先,使用YOLOv4目标检测算法对整串番茄进行识别和粗定位。然后,相机靠近目标番茄串,使用YOLACT++实例分割算法对近景番茄串和果梗像素进行分割。接着,对果梗像素进行曲线拟合,定位果梗切割点,现场测试得到果梗切割点定位成功率为93.4%。最后,基于果梗切割点和其余特征点建立数学几何模型,计算果梗姿态。果梗切割点的精准识别和果梗姿态的计算为机械臂运动的精准轨迹规划提供依据。(3)番茄单粒收获的目标识别定位、采摘策略和姿态计算方法研究。在番茄单粒果实的采摘过程中,为减少末端执行器与目标番茄周围障碍物的碰撞,本文提出了末端执行器抓取姿态计算方法和采摘策略。首先,研究基于深度学习的目标检测算法,用YOLO算法对图像中的番茄果实和番茄串识别和定位。然后,基于聚类判定和番茄串内最近距离方法,优化番茄采摘顺序。最后,为了进一步减少末端执行器靠近目标番茄过程中柔性手指与邻近果实的碰撞,提出一种末端执行器抓取姿态调整方法。通过现场试验验证,结果表明,单粒番茄果实的识别成功率为97.3%,采用优化的采摘策略和末端执行器抓取姿态计算方法,在整机测试中的单粒番茄果实采摘成功率达到72.1%。(4)生产型温室番茄采摘机器人优化设计与试验研究。对手眼视觉系统、番茄果实采摘视觉算法与单粒番茄果实自主采摘机器人硬件设备进行集成,搭建单粒番茄果实自主采摘机器人样机,并对整机控制系统进行设计。然后,在生产型温室场景中对采摘机器人进行多轮测试,验证各个视觉算法模块有效性。综合测试结果显示,本文所提出的番茄采摘机器人的整体采摘成功率达到72.1%,单个番茄的平均采摘时间为14.6 s。
{URL}: https://link.cnki.net/doi/10.27351/d.cnki.gszhu.2022.001819
{DOI}: 10.27351/d.cnki.gszhu.2022.001819
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进Faster-RCNN行人检测算法的研究
{Author}: 王小玉
{Tertiary Author}: 张凯
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;Faster R-CNN;特征融合;SENet
{Abstract}: 在计算机视觉的应用场景中,目标检测有着举足轻重的地位和极高的研究价值。所谓目标检测,就是用闭合的矩形框在图像中标定出符合任务需求的物体,并且输出该物体是行人的概率值。目前,行人检测技术已经被广泛应用于自动驾驶,智能机器人以及智能城市等领域,兼具实际应用和学术研究的价值。本文对国内外广为流传的卷积神经网络做了深入研究,并且阐述了卷积神经网络的设计方法和优化准则。现如今,随着计算机硬件的研发技术的进步,计算机的运算能力被提升到了前所未有的高度,这直接促进了基于深度学习算法进行行人检测这一技术的落地。经过在大量的公开数据集上的实验表明:应用深度卷积神经网络的行人检测算法的工作性能远远超过传统的机器学习检测方法和另外的图像处理手段。在现实生活中,存在着许多干扰因素,比如光线太强或者过于阴暗,距离远以及云雨雪雾等不理想的天气状况,这些因素直接导致采集得到的图像或者视频效果不理想,导致漏检率的升高。针对以上问题,本文提出了一种基于改进Faster RCNN的行人检测方法,主要的研究工作如下:1.运用特征图可视化方法,能够对卷积神经网络的输出层有更明确的认识。我们研究了解到特征图的抽象能力会随着网络层数的加深而变大,语义信息的抽象能力也会越来越强,但是图像的细节信息丢失比较严重,空间几何特征的表征能力减小。浅层网络拥有较小的感受野,空间信息拥有较强的表达潜力,但是,像素数量级高,语义信息抽象能力弱。在本文中,将深层语义信息和浅层高分辨率特征进行融合,对行人目标的检测标准更严格。经过实验证明,基于多尺度特征融合的Faster RCNN行人检测方法在INRIA行人数据集上的MR值下降到10.08%,在City Persons行人数据集上的MR值下降到15.21%。2.对于基于深度卷积神经网络的行人检测任务,检测框架的参数量级直接影响检测任务的检测效率。在下文中,我们以Faster RCNN为模板,借鉴Squeeze-and-Excitation Networks网络(SENet)的设计规则,重新设计了检测框架的特征提取模块。SENet以其独特的特征结构,能够学习到每个特征通道能够发挥的作用的大小,以此来强化更重要的特征并且削弱对检测任务作用小的特征。借助这种“升强抑弱”的机制,能够提高整体框架的检测性能。更重要的是,使用SENet的Faster RCNN行人检测方法并没有增加整体的参数量级。经过实验证实,使用SENet的行人检测方法在City Persons数据集上的漏检率下降到13.14%,在INRIA数据集上的漏检率下降到10.20%。3.对于目前目标检测网络采用一种池化方法对于行人检测任务普遍存在的特征提取效果不好的问题,本章提出了融合增强池化方法的行人检测网络。结合多种池化方法,通过学习机制为不同的池化操作分配不同的权值,使得网络能够拟合各种特征信息并且准确的抽象出重要的检测信息,经过多个公开数据集上与目前流行的目标检测网络训练测试对比,证实了本章的方法在行人检测领域良好的检测效果和突破成果。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2022.001182
{DOI}: 10.27063/d.cnki.ghlgu.2022.001182
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的金属表面缺陷检测技术研究
{Author}: 陈昭霏
{Tertiary Author}: 任秉银
{Publisher}: 哈尔滨工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 缺陷检测;深度学习;图像处理;电池壳
{Abstract}: 圆柱形电池钢壳生产制造过程中,由于原材料、冲压工艺、模具、设备环境等原因,部分电池壳会出现划痕、砂眼、凹坑等缺陷,这会影响产品的美观性,造成电池性能下降,严重的可能会有安全隐患。本课题基于机器视觉技术,采用深度学习分类网络模型识别电池钢壳外表面缺陷,对柱状金属表面的缺陷检测应用提供技术上的思路。本文的主要研究内容包括:说明了电池外壳缺陷的特征,阐述了缺陷识别任务的难点,设计了识别系统的整体流程。本文基于计算机视觉技术,设计了电池壳缺陷检测算法,缺陷识别系统根据作用划分为图像获取模块、预处理模块、检测识别模块、后处理模块,一次检测任务依次经过四个模块处理,最后将所有模块功能整合,开发可视化用户界面。图像采集模块的任务是搭建硬件系统采集到电池壳的图像,本文选择了工业相机和镜头的型号,根据电池壳曲面的反光特性,通过实验选择合适的光源,设计适用的打光方案。预处理模块作用是前景分割,本文给电池壳设定了单一的背景,选择阈值分割方法,针对噪声比较严重的情况,提出了一种基于固定阈值分割方法的算法,能够较好地框选出只存在电池壳主体的部分,即我们感兴趣的区域。由于相机拍摄有偏色问题,本文还改进了一种白平衡算法,能较好地还原图像色彩。采集到的电池壳图像反光严重,研究了去反光算法。本课题采集了电池壳图片数据集,用于训练VGG16分类网络,网络设置为二分类,只判断电池壳是否存在缺陷。通过实验验证,设置合适的网络超参数,使用三种不同大小的图片输入对比网络的效果,分析存在的小样本问题、类别不均衡、小目标问题,并提出对应的解决办法。针对类别不均衡问题,对比数据集重采样方法和Focal Loss对网络的改进,对比测试改进后的网络检测准确率。对于神经网络难以识别的小目标缺陷,使用传统图像处理操作设计了针对性的检测算法。设计了后处理算法,对于神经网络预测为缺陷的图片,标记出可能是缺陷的像素位置。最后,使用Py Qt5开发软件界面,使得用户能够可视化操作,缺陷检测准确率为99.33%,识别一张图片平均约需0.2508s。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.003063
{DOI}: 10.27061/d.cnki.ghgdu.2022.003063
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 柑橘视觉分级小型系统研究
{Author}: 解孟娇
{Tertiary Author}: 黄博
{Publisher}: 哈尔滨工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 柑橘分级;分级机构;视觉检测;深度学习
{Abstract}: 我国作为柑橘生产大国,在柑橘种植产业中小型化农场及家庭农场还是占大多数,水果分级主要依靠人工检测,分级效率低下。本文以柑橘为样本,设计并开发了一套小型智能化视觉分级系统,用于柑橘的瑕疵检测和尺寸检测,实现柑橘分级的全自动化。主要内容包括柑橘分级装置的机械结构设计,控制系统的设计,视觉检测系统的开发以及样机搭建与系统分级实验,具体的内容如下:首先,制定本设计的柑橘分级标准以及系统设计原则与功能需求,研究总体的设计方案,进行模块化功能设计,设计各模块的机械结构。系统主要包括上料排序模块、输送识别模块和分级卸料模块。机械结构设计主要有上料箱和两个小型输送带的设计,同步带和托盘结构的设计,卸料气缸和水果等级箱的设计以及各模块动力元件的选型。其次,研发柑橘分级装置的控制系统。根据系统功能需求和机械结构设计方案,进行软硬件系统设计。先进行主控制器选型、传感器选型、驱动系统设计、气动系统搭建、图像处理器选型与通讯以及相机和光源的选型。在硬件系统设计之后进行软件系统设计,包括人机交互界面的开发和整体控制程序的编写。最终完成整个控制流程设计。然后,设计基于深度学习的柑橘瑕疵检测和尺寸检测的分级方法。先制作两种视觉检测网络所用数据集,并进行图像预处理。之后使用Res Net50网络训练柑橘瑕疵检测模型,使用Center Net网络训练尺寸检测模型,训练获得瑕疵检测模型准确率为97.65%,尺寸检测模型平均精度为0.99。最后,结合总体的设计内容进行样机搭建与系统分级实验。首先,根据机械结构设计控制系统设计方案搭建样机。之后,调试分级装置,测试系统运行的稳定性。然后进行柑橘检测实验,测试两种检测模型的准确率均在95%以上。最后,进行系统分级实验,测试各模块功能的协调性和系统工作效率。传送装置在6.5～8.0m/min的速度区间内,系统分级效果最好。每个柑橘的检测耗时约1.3s,每分钟能分级45个以上的柑橘。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.002232
{DOI}: 10.27061/d.cnki.ghgdu.2022.002232
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 海上船舶目标的识别与跟踪算法研究
{Author}: 宣茜
{Tertiary Author}: 陈余庆
{Publisher}: 大连海事大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 船舶识别;船舶跟踪;YOLOv5;DeepSort
{Abstract}: 在计算机视觉技术中,目标识别与跟踪方法俨然已经成为当前热点研究问题,并被广泛应用于自动驾驶、行人监测等领域。尤其是在海上交通监控、海洋安全监管等任务中,船舶具备高效准确的海上船舶目标识别与跟踪能力是非常重要的。然而该技术容易受到船舶种类、船舶分布以及目标距离各异等诸多不确定性因素的影响,无法保证海上船舶目标的识别与跟踪任务的快速性、可靠性和准确性。针对以上问题,本文提出了一种兼顾多种综合性能指标的海上船舶目标识别与跟踪算法。本文具体的研究内容如下:
在经典深度学习识别算法基础上,本文提出了一种融合轻量级主干网络与自适应感受野特性的SKMobile Net V3-Bi FPNYOLOv5目标识别网络结构。该网络首先引入了Mobile Net V3作为船舶识别算法主干部分,其轻量级特性提升了整体网络识别速度。进而在网络主干部分引入了具有自适应感受野的SK卷积模块,并通过构建Bneck-SK结构,有效提升了船舶目标识别准确性。最后基于Bi FPN思想,设计了YOLOv5颈头部Bi-PANet网络结构,使目标识别算法可以充分利用其低层级特征,并扩大网络模型感受野,从而提升船舶目标识别算法的检测精度。
针对传统目标跟踪算法的多目标识别能力不足和缺少运动参数分析等问题,本文提出了一种YOLOv5-Deep Sort船舶目标跟踪算法。本文将离线训练的海上船舶目标识别模型作为多目标跟踪算法Deep Sort的目标检测器,构建YOLOv5-Deep Sort算法,并强化该算法海上船舶目标跟踪效果。针对海上船舶运动目标,通过张正友标定和坐标转换方法,推理在设定拍摄角度和高度下的单个像素距离与实际距离的拟合函数关系,进而得到海上船舶目标实际运动距离等有效信息,解决给定观测约束条件下海上船舶目标运动距离等参数计算问题。
为了验证该算法的有效性,本文分别对海上船舶目标识别与跟踪算法性能评价指标进行了归纳总结,并对本文目标识别与跟踪算法和传统算法做了对比实验分析。实验结果验证了本文研究的算法满足海上船舶识别与跟踪任务的准确性、可靠性与快速性要求,保证了海上船舶目标识别与跟踪任务的可实现性。
{URL}: https://link.cnki.net/doi/10.26989/d.cnki.gdlhu.2022.001401
{DOI}: 10.26989/d.cnki.gdlhu.2022.001401
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度学习驱动的计算机视觉方法在作物生长态势及病害诊断的应用
{Author}: 刘恒
{Tertiary Author}: 王秋平;耿娜
{Publisher}: 东北电力大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;深度学习;植物病害识别;水稻生长态势评估;数据增强
{Abstract}: 作物的生长态势评估和病害检测是农业生产的必要环节,是实现智慧农业和农业自动化的重要组成部分。传统方式下的病害检测和生长阶段的判断主要依赖于农民和农业专家的经验,这种人工的方式不但低效费时,而且难以推广。随着深度学习的发展,深度学习驱动的计算机视觉由于其快速、准确、以及无损等优点被广泛应用于农业领域。本文将深度学习驱动的计算机视觉方法应用到水稻生长态势评估、以及训练样本不足和不均衡条件下的苹果病害检测。本论文的主要研究内容如下:(1)基于通道注意力机制和空间注意力机制提出了一种三通道孪生神经网络TCSNet,并在小样本的条件下对苹果病害进行检测,解决了训练样本不足条件下的苹果病害检测。通过与多个基线模型的小样本性能对比,验证了TC-SNet网络结构的有效性。此外,还讨论了四种基于基本图像处理的数据增强方式对TC-SNet模型性能的影响,验证了模型具有很强的鲁棒性。TC-SNet的综合评价结果表明,在每类25个训练样本的条件下,网络的准确率高达98.5%。最后,将TC-SNet应用到野外真实环境下对苹果病害进行检测。结果表明,TC-SNet在复杂环境中同样具有出色的小样本学习能力。(2)基于多头注意力机制和空间注意力机制提出了一种生成对抗网络Attention GAN,并在病害数据不均衡的条件下提高了植物病害检测性能。通过对比Attention GAN和基线模型DCGAN的生成图像的质量、多样性、以及生成图像与原始图像之间的相似度,证明了Attention GAN网络结构的合理性和优越性。结果表明,将Attention GAN应用到植物病害检测分类任务中,检测病害的准确率提高至96.81%。在病害数据不均衡的条件下,使用Attention GAN对不均衡类进行数据扩充,不均衡类的准确率从81.82%提高至95.56%,有效解决了不均衡类准确率低的问题。(3)基于计算机视觉的特征提取方法和支持向量机提出了一种水稻完整生长阶段的无损检测方法以及相应的评价指标GSR。首先将水稻的RGB图像转换到HSV颜色空间,并对水稻不同生长阶段下H通道像素频数的分布进行了讨论和分析。在此基础上,对图像中的绿色像素和黄色像素进行阈值分割,从而得到绿色区域指数和黄色区域指数,以此作为颜色特征。本实验结合不同水稻生长阶段的图像,分析了所提取的颜色特征和纹理特征的合理性,并通过实验验证了基于灰度共生矩阵的方式提取水稻图像中的纹理特征能进一步的提高水稻生长态势评估的准确率。结果表明,在水稻农田上GSR能准确地评价水稻生长阶段,其检测的准确率为98%。
{URL}: https://link.cnki.net/doi/10.27008/d.cnki.gdbdc.2022.000158
{DOI}: 10.27008/d.cnki.gdbdc.2022.000158
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的小麦籽粒品种识别系统
{Author}: 冯继克
{Tertiary Author}: 李艳翠;陈永光;王德永
{Publisher}: 河南科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;小麦籽粒;品种识别;特征选择;贝叶斯优化
{Abstract}: 小麦是我国重要的粮食作物,我国约有40%的人口以小麦为主食。极端天气和病虫害等都会造成小麦的减产,培育优良品种对提高小麦产量有重要作用。籽粒品质的好坏是育种的基础,传统的籽粒识别方法已不能满足现代化育种的需求,提高籽粒识别准确率对培育优良小麦品种具有重要意义。本文提出一种基于机器视觉的特征选择与建模技术的小麦籽粒品种识别方法对8个品种小麦进行识别,主要工作如下:(1)小麦籽粒图像数据集构建。采集到百农207、百农307、百农419、新麦26、徐农14084和豫源916等市面上推广种植面积比较广的22个品种的小麦籽粒图像,通过研究对比选取展示小麦主要特征的三个角度(腹沟向上、腹沟朝前45°和腹沟向下)进行图像采集,每个品种采集1000粒小麦籽粒。为区分不同品种、不同颗粒以及不同角度,对小麦籽粒图像进行重命名。同时对小麦图像进行去背景,构建小麦籽粒图像数据集。(2)小麦籽粒图像特征的提取与分析。本文首先对去除背景的图像进行灰度化、滤波降噪和二值化等预处理。提取到小麦籽粒图像的颜色特征(R、G、B、H、S、V以及HSV的均值、标准差和斜度),形态特征(面积、周长、长轴轴长、短轴轴长、离心率、外接矩形面积、惯性矩、圆形度和矩形度)和纹理特征(逆方差、能量、熵和对比度)三方面共计28个特征参数,并对提取的特征分别进行相关性分析。(3)基于特征的小麦籽粒图像分类,采用贝叶斯优化BP神经网络结合不同特征处理方法对8个品种小麦籽粒进行分类。分别构建了单角度及角度融合识别模型;形态、纹理、颜色、形态+纹理、形态+颜色、纹理+颜色和形态+纹理+颜色共7个特征融合模型;主成分分析法、线性判别分析法和sklearn-Select KBest函数重要特征选择等数据降维模型;同时构建了小麦籽粒图像亮度、色度、锐度和对比度的数据增强模型。对比KNN和BP神经网络识别模型,并结合不同的特征处理方法,对8个品种的小麦籽粒图像进行识别分析。经过贝叶斯优化BP神经网络后识别准确率均有了较大提升,基于贝叶斯优化BP神经网络+数据增强模型,准确率最高达95.58%,提高小麦籽粒品种识别准确率,同时提升了模型泛化能力。(4)小麦籽粒品种识别系统设计与实现。将本文所做工作整合,实现了基于特征的小麦籽粒品种识别系统,用户登录系统后,可以上传小麦图像,通过图像预处理、数据增强、图像特征自动提取与处理和品种识别,实现了小麦籽粒品种的自动识别。
{URL}: https://link.cnki.net/doi/10.27704/d.cnki.ghnkj.2022.000098
{DOI}: 10.27704/d.cnki.ghnkj.2022.000098
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向果园环境的树上果实识别与大小测算技术研究
{Author}: 陈文康
{Tertiary Author}: 陆声链
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;机器视觉;小目标检测;三维重建;果实大小测算
{Abstract}: 果树产业是我国农业的重要组成部分。近年来,在人工成本逐步提升、劳动力资源不断减少的背景下,实现农业生产作业的机械化、自动化成为我国现代农业的重要发展趋势。水果采摘机器人是农业生产自动化的研究热点之一,而树上果实的实时识别是水果自动采摘的核心技术。在果园环境下,果实重叠、与枝叶相互遮挡,以及光照和天气变化等复杂因素使得树上果实的准确识别和大小测算成为一个挑战。本文围绕果实自动采摘的现实需求,针对果园环境中果实目标小、遮挡严重、光照影响大等问题,研究适用于果园环境下树上果实的实时识别与大小测算技术,提高果实识别算法的鲁棒性和实用性,为水果采摘机器人提供核心技术支撑。论文主要工作如下:1.提出了一种适用于果园环境的树上果实准确快速识别算法Fruit YOLO。该算法在目标识别模型YOLOv4的基础上优化得到,主要优化措施包括:一是在网络训练前使用Canopy算法和K-Means++算法自动计算适合当前数据集的先验框数目与大小,使网络模型更容易学习不同果实的特征;二是在原YOLOv4网络中每个不同尺度的特征输出层前添加了一个注意力模块,以提取图像中的关键信息并确保不同层间特征信息的传递;同时将原来的三个尺度检测扩展为四个尺度检测,并将密集连接网络与残差网络结构相结合,以提高整个网络的信息传输效率和信息复用能力;三是对检测网络中利用率不高的网络层与通道进行剪枝;四是优化了回归框损失函数,使网络能够识别复杂背景下的小果实。在多个品种的柑橘、苹果和百香果数据集与2个公共数据集上的实验结果表明,本文提出的Fruit YOLO算法对果园环境下树上果实的检测平均准确率达95.62%,平均检测速度为每张图像0.07s。2.提出了一种基于多视图三维重建的树上果实大小测算技术。该方法首先通过上述Fruit YOLO算法从图像中进行果实的识别,并记录下每个果实在图像中的坐标信息和参照物预测框的坐标信息,并提取果实预测框作为ROI区域的前景信息,过滤掉其余部分的背景信息,然后对图片中的每个前景信息进行均值滤波和轮廓提取,获得图片中的果实信息。在此基础上,利用OPENMVG与OPENMVS算法对多个视角的果实图片进行三维重建,获得稠密的果实曲面,然后利用OPEN3D过滤重建果实点云的孤立点、离散点,再通过DBSCAN聚类分割出每个果实的点云信息。最后利用最小二乘法将果实曲面点云拟合成椭球面,通过计算参照物和果实点云的包围盒坐标及比例关系算出果实的实际长、宽、体积等参数信息。实验结果表明,该方法计算得到的果实大小具有较高的准确度,长宽的绝对误差均小于8mm。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.001657
{DOI}: 10.27036/d.cnki.ggxsu.2022.001657
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉和深度学习的带式输送机煤量识别方法研究
{Author}: 李学晖
{Tertiary Author}: 王桂梅
{Publisher}: 河北工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;深度学习;煤量识别
{Abstract}: 煤炭开采过程中,带式输送机是运输原煤的主要设备,同时也是耗电的主要设备,启动后常保持恒高速运行,容易出现低载高速、甚至空载高速的“大马拉小车”现象,浪费了大量的电能。根据实时煤量变化调节皮带速度可以有效缓解上述问题,因此,煤量实时准确的检测成为带式输送机节能调速的关键。传统的检测方法受多种因素的影响,检测精度不稳定,且考虑到带式输送机的调速过程并非无级调速,本文提出了一种基于机器视觉和深度学习的煤量识别方法。通过煤量识别模型将煤流图像进行类别划分,依据煤量大小调节带速,为带式输送机节能调速提供依据。本文主要研究工作如下:针对带式输送机运输物料的特征,基于机器视觉的方法进行煤流图像采集研究。分析了带式输送机结构及运输物料的形态特征,鉴于直接采集的煤炭图像与皮带背景颜色接近容易混淆的问题,本文采用煤流截面图像制作数据集;分析了单目视觉和双目视觉的采集方案,结合机器视觉的成像理论,选择单目视觉结合激光线条纹的图像采集方案,用以增强煤流表面纹理的图像特征;最后,进行了采集设备的选型研究,在图像采集过程中,通过ROI设定,降低了图像边缘信息对后期图像处理的影响。针对目前缺乏煤流截面数据集的问题,建立了5类共计5000张图像的煤流截面数据集。为了使网络具备更好的训练效果,采用数据增强策略进一步扩充数据集,最终将数据集扩充到16850张,包括13480张训练数据集和3370张测试数据集。煤流截面图像的获取过程中,采用中值滤波去除原始图像的噪声;根据煤流图像的激光条纹特性,采用有向滑动自适应阈值的二值化方法进行图像二值化处理,采用有向生长的激光条纹细化算法对激光条纹进行细化处理;针对激光条纹断裂问题,采用Cardinal样条曲线进行条纹修补。最后,将以上算法处理后的煤流图像与空载时的基线图像对比形成煤流截面图像。针对直接构建煤量识别模型训练任务大、识别准确率不高的问题,采用基于迁移学习和改进Inception-Res Net-v2网络的方法构建煤量识别模型。通过对经典图像识别模型和迁移学习方法的研究,选择大规模数据集预训练好的Inception-Res Net-v2网络作为煤流截面图像的特征提取器。在该网络基础上,采用特征融合的方法对模型改进,在改变Inception-Res Net-v2网络输出层的基础上,对网络的Input到Pre Aux Logits的每一层进行了特征融合处理,实现了浅层图像特征与深层图像特征的融合,提高了模型的识别准确率。进行了网络优化实验和动态煤量识别实验研究。首先,通过多组网络优化实验,选择了模型训练的最优参数。其次,通过多组对比实验研究,验证了改进后模型的识别性能,与经典模型的对比实验中表明,改进后的Inception-Res Net-v2模型的Top-1准确率高达97.26%,识别性能最佳。最后,将训练好的模型嵌入带式输送系统实验平台,验证不同运量、不同带速下的煤量识别效果。实验结果表明,带式输送机在中低速运行下,煤量识别的平均准确率为93.42%,单帧图像处理时间为0.143s,动态识别性能较好。
{URL}: https://link.cnki.net/doi/10.27104/d.cnki.ghbjy.2022.000184
{DOI}: 10.27104/d.cnki.ghbjy.2022.000184
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉与机器学习的育肥猪体重估测方法研究
{Author}: 万世主
{Tertiary Author}: 何秀文;戴星照
{Publisher}: 江西农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 育肥猪;机器视觉;机器学习;体重;图像处理
{Abstract}: 随着生猪养殖业的规模化程度越来越高,对计算机技术的各方面需求也随之增加。为提高生猪养殖业的信息化水平,需改进传统方式中获取猪体重困难、易导致猪应激现象发生等问题,实现高效快速的生猪体重估测。本研究基于机器视觉与机器学习相结合的方式,提出使用Mask R-CNN实例分割算法实现猪轮廓分割,获取猪图像特征信息,利用Stacking模型拟合猪图像特征与体重关系,实现猪体重估测。本研究主要工作内容如下:（1）研究各类图像分割算法的原理与实际效果,结合猪场实际环境,分析各类分割模型的适用程度,最终选取Mask R-CNN模型作为图像分割研究算法。搭建Detectron2平台,保障模型的训练效率。（2）优化Mask R-CNN模型结构,主要包括调整Resnet50的网络结构,构建4种不同类型的特征提取网络,用于满足猪图像特征提取多样化,结合猪图像特征,通过区域建议网络RPN的参数优化获取3种目标框输入尺寸,共组成12种图像分割模型。比较模型分割评价指标,得出优化后的模型对像素的平均分割精度m PA达到96.95%,可较有效地对猪特征进行分割提取。（3）利用图像处理方式,对分割后的图像进行特征提取,得到猪轮廓像素面积、周长、体长、体宽、离心率与偏差等特征,制作特征与体重对应的数据集。（4）构建以Xgboost、随机森林RF与BP神经网络为初级训练器,简单线性回归为次级训练器的Stacking模型,用于猪图像特征与体重的模型建立,试验结果表明:Stacking模型效果比各初级训练器模型更好,模型泛化性更强,模型估测值与真实值决定系数R2为0.9889,平均绝对误差MAE为1.272kg以及均方误差MSE为2.760kg。（5）以Python中Py QT5的框架编辑用户图像操作界面,开发智能体重估测软件。该软件可实现猪图像特征信息获取以及体重估测,可为养殖人员提供有效的体重估测软件帮助,有效地缓解传统称重压力。本文研究育肥猪体重估测方法对生猪养殖业的发展有一定的促进作用。
{URL}: https://link.cnki.net/doi/10.27177/d.cnki.gjxnu.2022.000424
{DOI}: 10.27177/d.cnki.gjxnu.2022.000424
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度残差网络的视频图像去雨雾研究
{Author}: 安彦霖
{Tertiary Author}: 臧景峰
{Publisher}: 长春理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像增强;深度学习;图像去雨;图像去雾;深度残差网络
{Abstract}: 图像质量增强是物体识别和检测、三维重建、目标跟踪等计算机视觉任务中不可或缺的预处理过程。视频图像去雨雾算法的目标是将被雨雾污染的图像恢复为不含有雨雾的清晰图像,从而达到图像增强的目的,现有的视频图像去雨雾技术只在去雾或去雨中的一项任务中表现很好,具有一定的单一性。本文研究能够同时完成去雨和去雾两种任务的算法,提出一种基于深度残差网络的视频图像去雨雾算法,主要工作如下:1)针对目前的去雾去雨算法网络模型过深而造成的实时性低、参数复杂、去雨雾效率低的问题,本文提出了一种基于改进的深度残差网络的去雨雾网络模型,用注意力机制对深度残差网络进行改进,注意力机制从通道和空间两个维度自适应的学习雨、雾特征,使网络模型得到了精简。本文提出的算法既能去除雨滴和各个方向的雨纹,又能去除不同浓度的雾,具有较高的实时性,对于单幅图像的处理运行时间在0.1 s以内;本文中设计的基于深度残差网络的去雨雾网络模型误差值收敛在0.004附近,具有较高的精度,有广泛的应用价值。2)针对一些去雨雾算法的图像处理结果过于平滑、丢失背景细节信息的问题,本文从两个角度解决了问题:细节保持模块和损失函数。首先,本文在网络模型中加入了细节保持模块,由生成对抗网络中的判别器构成,能够学习输出的图片与干净背景图的差别,使输出的图像更接近真实图像,从而保证图像细节不丢失;其次,一些算法中仅使用均方误差函数作为损失函数,会造成效果过度平滑,本文在均方误差函数的基础上加入了结构相似度函数和对抗损失函数,较好的解决了过度平滑的问题,本文采用的损失函数方法效果相较于其他损失函数的PNSR值达到了27.6 d B,在SSIM指标上达到0.936。3)本文选用现有去雾数据集RESIDE、雨纹数据集Rain12000和Rain100L数据集、雨滴数据集Raindrop,并采集大量真实世界动态场景雨雾视频和图像来训练和测试网络模型,使本文网络模型能够去除不同浓度的雾和雨,更具有鲁棒性。
{URL}: https://link.cnki.net/doi/10.26977/d.cnki.gccgc.2022.000060
{DOI}: 10.26977/d.cnki.gccgc.2022.000060
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的车道线检测与交通标志识别
{Author}: 李昊
{Tertiary Author}: 李飞
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 交通标志识别;车道线检测;联合神经网络;Gabor滤波器
{Abstract}: 伴随着车辆持有量的不断上升,交通安全问题日益受到社会各界的广泛关注。辅助驾驶系统是近年来汽车生产行业的重点研究对象之一。一个功能良好的辅助系统可以给驾驶员带来安全且良好的驾驶体验,也可以使公共交通安全得到有效的保障。在辅助驾驶系统的诸多功能中,车道线检测系统和交通标志识别系统都是关键性的研究课题。针对轻量型网络对小目标检测能力不足以及弯曲车道线拟合效果较差的问题,本文从以下两个方面进行研究:(1)在交通标志识别方面,采用深度学习的方法对交通标志进行定位和识别。在解析YOLO-V5s网络结构的同时对部分结构进行改进,提出了一种联合型神经网络模型,在利用YOLO-V5s网络对图像内交通标志进行定位的基础上,采用VGG网络的深度卷积结构对图像进行识别,网络采用多个FPN-PAN结构组合,增强对小目标的识别能力。同时利用全局平均池化层代替传统VGG网络的全连接层进行输出,减少全连接层带来的庞大参数量,提升网络运算效率。(2)在车道线提取方面提出了一种基于Gabor滤波器对路面纹理信息具有良好识别特性的车道线信息提取算法。在检测开始前,首先利用HSI色彩模型对图像进行数据增强,提升算法对磨损车道线的检测能力。检测过程中首先利用路面的纹理方向性特征对行车道路消失点进行搜索,之后基于初次提取的消失点对道路边界进行迭代搜索并更新消失点。为减少周围环境干扰,利用逆透射变换将提取出的路面区域由车辆行驶视角转换为俯视图视角,对逆透射变换后的路面区域降噪处理后从中提取出单一车道线区域并进行车道线拟合。利用基于Catmull-Rom样条的拟合算法进行车道线拟合,从每条车道区域中心线上进行控制点采样,提升算法对弯曲车道线的拟合程度。最后将以上两个部分进行软件整合,并利用建立好的测试集进行检测实验。实验表明在交通标志识别部分,本文采用的联合神经网络在准确率方面比传统VGG网络提高4.21%,比YOLO-V5s网络提高2.08%,同时对小目标的检测效果较YOLOV5s网络提高2.66%。车道线检测方面经过数据集测试,误检率为1.9%,较现有的RANSAC车道线拟合算法提高0.9%,本文所用算法具有可行性。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.001205
{DOI}: 10.27322/d.cnki.gsgyu.2022.001205
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人体姿态估计算法研究
{Author}: 曹丹丹
{Tertiary Author}: 刘渭滨
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;人体姿态估计;注意力机制;特征融合;人体先验知识
{Abstract}: 人体姿态估计是目前具有挑战性的热门研究方向之一,其目的是从图片或者视频中将每个人体的关键点检测出来,绘制出人体骨架图。随着人体姿态估计技术的发展成熟,人体姿态估计在智能监控、虚拟现实、运动分析等方面都具有广泛的应用。本文采用目前流行的深度学习方法,对人体姿态估计算法进行研究,主要研究内容如下:(1)提出了一种基于双注意力与多尺度融合的人体姿态估计算法。在人体姿态估计任务中,卷积神经网络提取了包含不同重要程度信息的特征,本文使用双注意力机制对骨干网络提取的特征进行增强,以获得更丰富的细节信息。而特征提取过程中的下采样操作会丢失很多空间信息,本文通过堆叠不同扩张率的空洞卷积增加特征感受野,并且保持特征的分辨率大小不变,使得网络模型获取人体关键点的多尺度特征信息。实验结果表明,通过对特征进行增强并进行多尺度融合,能够提高人体关键点的检测精度。(2)提出了一种基于上下文信息聚合的人体姿态估计算法。在人体姿态估计的特征提取阶段中,使用自注意力机制捕捉特征图远距离的上下文信息,通过远程像素点间的依赖关系获取全局约束,提取全局上下文信息并进行聚合。对于骨干网络提取的高层特征与低层特征,设计了多级分支特征融合机制,对不同层次的特征进行组合,逐级扩大特征图,以恢复特征图分辨率输出预测关键点热图。最后在将预测的关键点热图解码为人体关键点坐标过程中,采用分布感知坐标解码方式显著提高坐标回归的准确性。实验结果表明,该算法可以更加准确地检测人体关键点,进一步提升网络模型性能。(3)提出了一种基于图编码优化的人体姿态估计算法。在人体姿态估计任务中,人体关节点之间存在一定的连接关系。本文对人体相邻关节点之间的连接关系进行建模,根据人体图结构模型建立人体关节点骨架图作为先验知识,利用人体相邻关节点间的连接关系,使得网络学习关节点连接信息辅助人体关键点的检测。最终的实验结果表明,该方法通过引入先验知识对人体姿态估计算法进行优化,能够实现更好的算法性能。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.003014
{DOI}: 10.26944/d.cnki.gbfju.2022.003014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的排水管道缺陷检测算法研究
{Author}: 王卓阳
{Tertiary Author}: 赵鹏兵
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 排水管道;缺陷检测;深度学习;机器视觉;YOLOX
{Abstract}: 在城市和工业排放中,铺设了大量的排水管道,其工作状况直接影响着城市人民的生活和工厂的运转。为了及时发现管道损坏情况并做好修复,需要通过定期监测来评估排水管道缺陷状况。排水管道通常埋置在地下,路径错综复杂,且管径较小,人工很难直接进入管道检测其缺陷。目前主要利用机器人携带摄像头进入管道内部拍摄视频,然后在地面上通过人工分析海量视频数据进行判断。这会使工作人员在长期观看视频后因疲劳产生误判,且效率低下。随着机器视觉技术的发展,使用计算机自动分析视频图像来检测管道内部缺陷成为一种可能,本文结合机器视觉技术研究排水管道缺陷检测算法,主要研究内容如下:首先,根据使用机器视觉技术自动识别排水管道缺陷的需求,研究了基于梯度方向直方图(HOG)的统计特征提取技术和基于支持向量机(SVM)的机器学习算法。详细介绍了HOG缺陷特征提取的梯度直方图构建流程和SVM分类算法的基本原理及数学模型。整个算法通过将训练数据集图像输入到HOG算法进行特征提取后,使用SVM机器学习算法训练特征参数,然后在测试数据集上验证算法性能。实验表明,基于HOG+SVM的检测算法对管道缺陷识别的多类别平均精度(m AP)为66.94%,所设计的检测算法能够对管道缺陷进行有效识别。其次,针对传统缺陷检测技术性能较差的问题,研究了基于深度学习的YOLOX检测算法。详细介绍了YOLOX的主干网络结构、预测及训练过程。同时,引入了马赛克(Mosaic)和混淆(Mixup)数据增广方法扩充原始数据集。在使用迁移学习和冻结主干网络优化训练过程后,基于YOLOX的缺陷检测算法对管道缺陷识别的m AP最高为87.61%,检测速度为21ms。实验表明,在相同测试数据集下,相比于传统缺陷检测算法和其他基于深度学习的检测算法,YOLOX算法在检测精度和检测速度之间实现了最佳平衡。最后,针对YOLOX算法存在漏检率较高和检测精度有待提升等问题,对其从四个方面进行了改进。第一,引入了注意力机制模块改进网络结构,加强特征提取;第二,引入了完全交并比损失(CIo U Loss)改进损失函数,解决训练过程中的梯度消失问题;第三,引入了为视觉任务设计的漏斗激活函数(FRe LU)激活函数,拓展了网络的空间属性;第四,引入了软化非极大值抑制(Soft-NMS)改善漏检率问题。实验表明,改进的YOLOX算法对排水管道缺陷识别的m AP为90.64%,检测时间为25ms,同其他深度学习算法相比,其检测精度和检测速度都达到了最佳。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.003017
{DOI}: 10.27389/d.cnki.gxadu.2022.003017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向机器视觉的图像压缩算法研究
{Author}: 陈俊如
{Tertiary Author}: 赵耀
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像压缩;深度学习;机器视觉;最小可觉察误差
{Abstract}: 随着多媒体技术的蓬勃发展,图像、视频数据占用了越来越多的网络带宽,对多媒体数据高效压缩的技术需求越发迫切。现有的大多数图像、视频压缩方法主要服务于人眼视觉系统,以高清晰、高保真为目标。然而近年来,越来越多的图像、视频数据主要应用于监控网络中,通过监控系统的自动分析实现异常检测和自动报警。由此可见,越来越多的图像、视频数据开始主要为机器视觉任务服务,这给图像、视频的压缩编码提出了新的挑战。本文重点研究了面向机器视觉任务的图像压缩算法。论文的主要贡献概括如下:(1)提出任务驱动的图像压缩算法,解决压缩-分析任务无法实现联合优化的问题。算法设计了端到端形式的网络框架,并引入任务感知损失函数用于改进率失真损失,以实现码率-准确度优化。针对特定任务的特性,利用分阶段优化的模式,进一步提升任务性能。在语义分割和目标检测两个机器视觉任务上进行实验,结果验证了所提算法的有效性。(2)提出图像压缩与语义分割互增强算法,进一步解决压缩重建图像的信息丢失导致机器视觉任务精度下降的问题。算法以语义分割任务为机器视觉任务的代表,将多尺度特征融合模块嵌入编码器中,有效增强语义特征;增强模块利用语义特征对重建图像进行增强,实现压缩-分割任务的互增强。实验结果表明,该算法的压缩性能明显优于BPG,语义分割精度也有0.4%的提升。(3)提出基于最小可觉察误差视觉特性的图像压缩算法,解决单一压缩模型无法得到多种码率的重建以及视觉系统存在最小可觉察误差视觉特性的问题。算法利用质量图引导图像压缩网络,实现从一个压缩模型中获取多个码率下重建图像的目标。同时,嵌入最小可觉察误差估计模块,利用人眼视觉系统和机器视觉任务可以容忍此种误差的特性,提高压缩重建图像的主观质量。此外,算法还构建了分类任务感知框架,可以仅经过少量的迭代优化使压缩后的分类任务精度在较低码率下迅速接近原始分类精度。实验验证了该算法在图像压缩和分类任务中的有效性。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.001347
{DOI}: 10.26944/d.cnki.gbfju.2022.001347
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向自动驾驶的交警手势识别研究
{Author}: 王中石
{Tertiary Author}: 田丽霞
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 坐标注意力;TransPose;CenterGroup;骨架特征序列;交警手势识别
{Abstract}: 近年来,得益于硬件技术和人工智能技术的进步,自动驾驶(ADS)相关研究发展迅速。快速且准确地识别复杂交通状态下的交警手势并作出正确的反应,是自动驾驶技术推向实际应用的必要条件之一。本文基于以上背景,致力于面向自动驾驶的交警手势识别研究。当前,获取交警手势的方法主要有基于传感器的识别和基于视觉的识别,本文关注如何基于单目摄像头捕获的交警视频图像,结合有效的深度学习算法,突破交警手势识别所面临的一些关键技术难点,比如交通路口情况复杂、光照欠佳、手势遮挡、以及视野中交警人物偏小(“小人物”)等因素导致的手势识别精度较低、复杂模型导致的实时性较差等问题。本文借鉴计算机视觉领域的前沿方法,分别以骨架序列图和特征热图作为手势识别依据,探究了交警手势识别的识别精度和识别效率的提升策略。具体地,本论文主要开展了以下三项研究工作:(1)基于坐标注意力的交警手势识别研究。针对实际交通路口情况复杂以及光照不佳等因素导致的交警手势识别精度较低的问题,该研究引入了Open Pose模型以减低光照等外界因素干扰提取骨架特征,引入了坐标注意力机制进一步加快识别速度并增强关键点生成精度。实验结果表明,本研究提出的方法识别精度优于同类算法,且在包含弱光照情况的交警手势数据集上有明显优势。(2)基于TransPose的交警手势识别研究。针对实际应用中可能存在的交警手势被部分遮挡的问题,该研究引入了可以预测被遮挡关键点的TransPose模型,该模型利用HRNet可以保持丰富的高分辨率表征的优势,结合Tansformer的自注意力机制,发掘交警人体关键点之间的依赖关系,最终生成骨架图推进交警手势识别。实验结果表明,本研究提出的方法识别精度优于同类算法,且在包含遮挡情况的交警手势数据集上有明显优势。(3)基于CenterGroup的交警手势识别研究。为了综合应对弱光照、关键点遮挡、“小人物”等问题导致的交警手势识别精度偏低的问题,以及满足实际应用对运行帧率的要求,该研究引入了基于CenterGroup生成的特征热图的方法。该模型先使用Higher HRNet尺度感知的高分辨率网络生成人物中心,再引入Tranformer思想应对关键点遮挡等问题。实验结果表明,本研究提出的方法识别精度优于同类算法,且在包含弱光照、关键点遮挡、“小人物”情况的交警手势数据集上有明显优势。本文研究创新性在于:(1)引入基于坐标注意力机制的轻量化特征提取主干网络,增强关键点特征,有效提升了弱光照条件下的交警手势识别精度;(2)引入TransPose模型,通过关键点之间的依赖关系预测被遮挡的关键点,有效解决了手势部分关键点被遮挡的问题;(3)通过中心点定位和自注意力机制结合生成特征热图,综合解决了交警手势识别中存在的弱光照、关键点遮挡、“小人物”、帧率低等问题。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.002694
{DOI}: 10.26944/d.cnki.gbfju.2022.002694
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像的水下动物目标识别与行为分析研究
{Author}: 徐文凯
{Tertiary Author}: 李娟
{Publisher}: 青岛农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;计算机视觉;水下动物
{Abstract}: 海洋是国家战略中的“蓝色粮仓””和“蓝色药库”,海洋牧场是海产品养殖的主要方式,而水下动物的识别、行为分析和预警研究是实现海产品高产、高值、高效养殖和捕捞的前提和基础。然而,目前对水下动物的监测主要是以人工观察或植入电子标签为主,存在主观性强以及标签易脱落且对目标易产生应激反应的影响,因此,通过深度学习方法研究水下动物的识别和行为分析势在必行。为此,本文以海参和鱼两种典型水下动物为研究对象,针对目前在识别和行为分析方面存在的问题,进行了深度学习方法的研究。主要研究内容如下:(1)建立了真实海底环境下海参图像数据集现有的真实海洋环境下海洋动物图像数据集较少,特别是缺乏海参自然生长形态下的图像数据集。为此,本文通过水下相机进行了图像的采集,建立了真实海底环境下海参图像数据集,包含了各种复杂海底环境下的状况如光照影响、遮挡等。该数据集的建立为提高海参目标检测模型的泛化能力提供了数据支持。(2)提出了一种水下小目标识别的深度学习模型区别于以往的实验室环境及单一目标海参图像的识别研究,本文基于真实海底环境下获取的海参图像,提出了以海参为代表的小目标检测的SO-YOLOv5模型。该模型在YOLOv5的基础上通过增加小目标检测层以实现对小目标的有效检测,并对感兴趣的目标区域进行识别及定位,解决了目前广泛使用的目标检测模型在真实海底环境下海参检测中存在的误检和漏检等问题,m AP达到94.79%。通过与目前主流的深度学习模型Faster R-CNN、SSD和YOLOv5相比,本文提出的模型的m AP分别提高了3.79%、6.11%和4.78%。(3)提出了一种多目标检测模型和一种行为轨迹绘制方法为了解决患有腐皮综合症的海参的检测准确率低和行为分析困难的问题,本文提出了一种CA-YOLOv5的多目标检测模型和一种多目标自动取帧匹配坐标的行为轨迹绘制方法。所提出的模型引入了CA注意力机制和Bi FPN,实现了海参多目标的准确识别,识别准确率达到99.71%。通过提出的多目标自动取帧匹配坐标方法,实现了海参行为轨迹的绘制和运动量统计。通过与正常环境下海参行为的对比,分析了海参在感染腐皮综合症时的异常行为,为养殖过程中对海参的监测提供了一种无损、高效的方法。(4)提出了一种氨氮胁迫下的行为轨迹识别分析方法在集约化养殖过程中,鱼的呼吸、排泄和饵料的残留会产生氨氮,即便其浓度较低但仍然会影响鱼的生存。为了研究鱼类在不同氨浓度下的行为,本文通过在水中加入氯化铵模拟不同的氨环境,提出了一种基于深度学习的行为轨迹识别分析方法。首先,通过Faster R-CNN模型对鱼类目标进行识别和定位;其次,根据位置信息进行三维重建以绘制鱼的三维时空轨迹;最后,根据不同浓度氨中鱼的行为轨迹,分析了不同浓度氨对鱼类的影响。对比实验结果表明,在氨环境下,鱼的运动和活力显著下降,鱼常处于停滞状态,该方法为动物行为的智能化分析提供一种新的思路。
{URL}: https://link.cnki.net/doi/10.27203/d.cnki.glync.2022.000004
{DOI}: 10.27203/d.cnki.glync.2022.000004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的摄像头模组焊接缺陷检测研究
{Author}: 冯彪
{Tertiary Author}: 彭艳华
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;摄像头模组;缺陷分类;神经网络;焊接检测
{Abstract}: 摄像头模组(Camera Compact Module,CCM)是智能设备的重要组成部分。随着智能设备行业的快速发展,对CCM的需求量快速增加,也对CCM产品的焊接质量检测提出了更高的要求。针对现有质量检测方案存在成本高、误判率大、效率较低的不足,研究一种低成本高效的CCM焊接缺陷检测方法是行业发展当前所需。本文围绕CCM焊接存在的桥接、漏焊和少锡缺陷展开研究,重点讨论了机器视觉光学成像方案和图像处理算法等关键技术,主要内容如下:(1)基于摄像头模组焊接缺陷的检测标准,设计了焊接缺陷检测系统的总体方案;通过分析待检测焊接区域的光学成像特点,构建CCM焊点检测成像模型后,选取了低成本、高效率的光学成像设备,并设计了突出焊接特征的打光方式,完成光学成像实验平台的搭建。(2)针对CCM在检测中存在微小偏移导致焊接区域难以准确定位和焊锡存在高反光、曝光不均匀的问题。首先,采用多尺度金字塔分层搜索策略的特征匹配方法对焊接区域进行快速精准定位;其次,研究并提出一种基于曝光度函数和同态滤波函数共同确定权重的多曝光图像融合算法,减少焊接区域的高反光并增强了细节,获得了高质量的焊接区域图像。(3)为满足CCM焊点高精高效的检测要求,设计了以模组为单位的初步质量检测和以焊点为单位的二次缺陷检测方案。首先,初步质量检测使用图像增强后的焊接区域图像提取焊点的轮廓几何特征,通过可调节风险函数的最小风险贝叶斯决策方法快速判断模组是否合格。其次,二次缺陷检测设计了贝叶斯方法的Cbayes-Le Net神经网络对融合的高质量焊点图像进行缺陷识别,并将其与多种传统神经网络模型在本文数据集进行比较,实验结果表明本文检测方法准确率更高、速度更快。(4)搭建了实验平台并介绍软件模块的流程设计,开展实验对本文研究方法有效性进行验证。结果表明本文方法对CCM焊接缺陷检测能达到较好的效果,检测准确率达98.96%。本文方法有效地实现了CCM焊接的桥接、漏焊和少锡缺陷检测,为加快我国CCM焊接质量自动化检测产业的快速发展提供了重要的参考价值。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000951
{DOI}: 10.27049/d.cnki.ggldc.2022.000951
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于网络摄像机的桥梁挠度非接触识别
{Author}: 朱前坤;崔德鹏;杜永峰
{Author Address}: 兰州理工大学防震减灾研究所;兰州理工大学甘肃省减震隔震国际合作研究基地;
{Journal}: 工程力学
{Year}: 2022
{Volume}: 39
{Issue}: 06
{Pages}: 146-155
{Keywords}: 计算机视觉;实时监测;桥梁挠度;非接触;HSV
{Abstract}: 针对传统的桥梁挠度识别系统可达性差、效率低、不能全天候实时监测，建立了一种基于网络摄像机的桥梁挠度非接触识别系统。系统采用LED光源作为标志物，以网络摄像机作为采集设备，通过无线传输图像信息，利用计算机搭载基于HSV的快速模板匹配和基于颜色追踪(cvCamShift)的几何匹配算法获取目标的挠度时程信息，进而实现对桥梁挠度的非接触识别。通过在人行桥模型上进行四种工况的振动试验以及现场实桥测试，以此验证系统的可行性。研究结果表明：在模型试验中，系统识别得到的时域和频域信息与激光位移传感器对比的误差都小于0.6%，在雾气干扰下识别的误差仍可小于0.7%；实桥测试下，系统的识别结果与桥梁挠度仪对比的误差小于1.9%。由此表明系统鲁棒性强且经济性好，具备广泛的应用前景。
{ISBN/ISSN}: 1000-4750
{Notes}: 11-2595/O3
{URL}: https://link.cnki.net/urlid/11.2595.O3.20220527.1700.026
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的轻量化实时目标检测深度网络研究
{Author}: 李卓
{Tertiary Author}: 陈利民;李勇
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 实时目标检测;特征融合;注意力机制;网络轻量化
{Abstract}: 计算机视觉技术随着卷积神经网络快速发展取得了巨大突破,在视觉检测领域,已经出现了众多如YOLO、Fast-RNN等经典高精度模型。然而这些网络模型也存在着两个问题:一是经典目标检测模型参数、浮点计算量庞大,不能在性能较弱的移动设备推理部署,二是随着网络模型参数、浮点计算量减少,网络模型性能直线下降,即网络轻量化后检测精度不足。这些问题限制了目标检测算法的落地应用和检测效果。针对上述问题,本文基于主流目标检测网络YOLOv3进行了改进,提出了一种轻量级目标检测网络YOLO-SNet-tiny,该网络模型主要进行了网络模型轻量化和提升网络模型检测精度两个方面研究与创新。针对网络模型轻量化:一是将YOLOv3模型骨干网络直接替换为Shuffle Net v2轻量级特征提取网络。二是将颈部网络、检测头网络中常用的标准卷积替换为轻量级的深度卷积。这两种方法大量减少了网络模型中的参数与浮点计算量。针对提升网络模型检测精度:一是提出了轻量级颈部网络结构PAN-Tiny,进行自上而下和自下而上双向特征融合。二是提出一种新混合注意力机制模块,增强网络对重要信息的关注度。三是提出一种全新的轻量级解耦检测头Head-Lite,精细化分类与回归任务。这三种方法缓解了模型轻量化后导致目标检测模型性能大幅度下滑的情况。为验证YOLO-SNet-tiny性能,本文以COCO2017为训练和验证数据集在嵌入式设备Jetson Nano Bo1 CPU上进行了实验,实验结果显示,YOLO-SNet-tiny在COCO数据集上m AP(0.5)达到了30.4%,与前沿模型YOLOv4-tiny相比,在相同分辨率的情况下,YOLO-SNet-tiny以比YOLOv4-tiny低10%m AP(0.5)的精度损失,获得了约3倍于YOLOv4-tiny的模型推理速度,浮点运算量仅约为YOLOv4-tiny的1/14、网络参数量约为YOLOv4-tiny的1/6。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.002025
{DOI}: 10.27232/d.cnki.gnchu.2022.002025
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向非特定人群的动态手语识别系统研究
{Author}: 张福明
{Tertiary Author}: 张涛;王光鼎
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 手语识别;关键帧提取;MediaPipe;非特定人
{Abstract}: 中国有2057万的聋哑人,占中国人口总数的1.67%,由于语言的隔阂使得健听人生活中很难接触到聋哑人。聋哑人和健听人分别生活在各自的圈子里,互相很少有交流,长此以往会使聋哑人更难融入到社会群体中。因此开发一款能够促进双方交流的手语识别系统有很好的学术价值和应用前景。目前,针对特定人的动态手语已经有了大量研究,并且取得了很好的成绩。但是一个手语识别系统要想具有实用性一定可以对非特定人进行手语识别。因此,本文设计了一种面向非特定人群的动态手语识别系统,本文主要研究如下:1.在一个动态手语中可以通过几个关键动作就能完整表达出语义,这几个动作所在的帧称为关键帧。本文提出一种基于特征匹配的关键帧提取算法,通过本算法可以将动态的手语识别变成对静态手势图片的识别,减少了数据量,加快识别速度。本算法需要提前获取手指关节角度和关节点的相对位置特征并存入特征库,在提取关键帧时利用Media Pipe框架获取手部21个关节点坐标并计算手指关节角度和关节点的相对位置特征,如果当前手部特征符合特征库中某个特征时,将当前帧列为关键帧。虽然不同人做同一手语时手的大小、胖瘦、使用习惯不同,但是在做同一个手语时关键帧处的手势基本相同,因此本方法同样适用于非特定人的手语关键帧提取。2.由于目前手势数据集存在着图像模糊和每类样本数量不一致等问题,并且在后续的识别时也会受到环境和手部的大小、肤色等影响,因此本文将自制手势数据集,首先利用摄像头在每类手势拍摄相同数量的图像,预处理方式为Media Pipe框架提取图像中手的21个关节点,并将这些关节点绘制在白底图片上并连线,形成新的手势骨架数据集,该数据集既能看出手势,又能忽略环境和手部的大小、肤色等影响。3.为了验证卷积神经网络能否对本文预处理方式进行有效识别,本文将分别用Res Net-50、Mobile Net V2、Conv Ne Xt网络分别对经过本文预处理的美国手语数据集和未经预处理的美国手语数据集进行训练,证明本文预处理方法可以提高卷积网络的识别准确度。之后采用相同的预处理方式对自建数据集进行处理,选择准确度最高的Conv Ne Xt模型进行训练。4.根据以上的研究方法结合TensorFlow、OpenCV、Py Qt等设计实现了一个动态手语识别系统,该系统可以面向非特定人群。整个系统只需要一台带有摄像头的计算机,不仅使用方便简洁而且对环境没有特殊要求。通过测试该系统对非特定人拥有很好的准确度和稳定性,可以实时的进行手语识别。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2022.000643
{DOI}: 10.26926/d.cnki.gbfgu.2022.000643
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉与触觉感知融合的物体描述研究
{Author}: 周茂辉
{Tertiary Author}: 张鹏
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;机器触觉;多模态信息融合;深度学习
{Abstract}: 机器视觉与机器触觉融合能有效提高机器人对外部环境的感知能力。本文针对如何提高机器人的视触融合感知能力和物体描述能力进行了研究。首先,研究了基于深度学习的视触融合方法,通过对比实验系统分析了影响视触融合模型感知能力的因素;然后,在视触融合模型基础上,充分挖掘视觉和触觉的互补特性,从多角度描述物体。最后,在机器人实验平台上研究机器人对抓取物的描述能力。具体研究过程如下:在基于深度学习的视触融合模型研究中,分别进行了视觉和触觉单模态实验,并选出了3个视觉模型和3个触觉模型进行视触融合实验,找出视觉模型和触觉模型的最佳组合形式。此外,还将9种视觉和触觉的组合模型分别进行决策级融合和特征级融合对比实验。最终,对视触融合机理进行进一步分析得出如下结论:第一,特征级数据融合极易受到模型结构和参数量的影响导致训练速度慢,识别效果差,而决策级数据融合几乎不受影响;第二,视触融合模型的性能会受到融合策略、视觉和触觉模型匹配程度、模型结构、参数量等多重因素影响。在基于视触融合的物体描述研究中,充分利用视觉和触觉互补的优势,从物体的材料属性、形状、颜色和类别四个角度描述物体。为实现精准的多角度物体描述,提出一种多任务-多标签分类方法,该方法能有效均衡各描述角度。在物体描述实验中,本文提出的物体描述方法能以最小的参数量实现最精准的物体描述。在机器人抓取描述实验中,使用包含视觉和触觉的机器人平台建立了一个抓取描述数据集,并在该数据集上训练了物体描述算法。实验结果显示,基于视觉和触觉感知融合的物体描述方法可以有效应用于机器人的抓取描述中。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2022.000016
{DOI}: 10.27278/d.cnki.gsdqc.2022.000016
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于光流信息的运动目标检测、定位、跟踪系统研究
{Author}: 王顺
{Tertiary Author}: 郭庆强;徐升
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;光流;小孔成像;空间定位跟踪;容积卡尔曼滤波器
{Abstract}: 运动目标检测、定位、跟踪是计算机领域的核心研究课题,在视频监控、军事对抗、智能交通等领域具有重要的研究价值。目前关于运动目标检测、定位、跟踪的相关算法种类繁多,不过随着新问题的不断涌现,还有很多理论与应用的难点可以进一步研究与解决。本文以三维空间中的运动目标为研究对象,以单目相机为研究工具,以光流为研究起点,综合图像处理、深度学习、聚类、非线性滤波等方法,设计了集运动目标检测、空间定位、立体跟踪为一体的完整系统。本文的主要工作如下:在运动目标检测方面,为满足大量噪声干扰下大位移运动目标的检测要求并持续提升检测效果,本文基于传统方法与深度学习策略分别开展了前后两阶段研究工作。第一阶段,构建了基于传统计算机视觉的光流预测与运动目标提取网络,包括预处理图像、改进Lucas-Kanade光流法计算光流、提出粗精结合两级运动目标提取策略。第二阶段,在第一阶段基础上构建了基于学习算法的光流预测与运动目标提取网络以进一步完善检测算法,具体通过丰富图像预处理、应用改进PWC-Net计算光流、创新K-means与凝聚聚类算法并融合帧间差分法来提取特征区域。实验表明本文检测算法可以准确完整地获取运动目标。在运动目标定位方面,为完成仅利用单目相机单帧图像获取运动目标三维位置的任务,本文根据检测结果设计了基于小孔成像的单目视觉空间定位算法。首先,结合相机参数建立定位模型并对单帧图像进行坐标转换以获取目标的空间方位信息。然后,利用空间方位信息、相机自身安装位置以及几何关系获得目标的空间坐标信息、深度信息。实验表明,本文定位算法简单经济、实用精确,位置信息平均相对误差仅为3.91%。在运动目标追踪估计方面,为解决通过二维图像实现运动目标三维跟踪的问题,本文根据定位结果构建了基于容积卡尔曼滤波器的立体跟踪策略。首先,建立运动目标运动模型,并以运动目标的速度与位置为状态变量,以运动目标的像素坐标为量测输出构建系统状态空间表达式。最终,将不同模型与容积卡尔曼滤波器融合以实现对运动目标空间位置与速度的稳定跟踪。实验中同步引入扩展卡尔曼滤波器对比验证了容积卡尔曼滤波器的可行性、先进性、稳定性。实验表明,在运动预测时间内容积卡尔曼滤波器跟踪策略关于6维跟踪变量的均方根误差平均值、曼哈顿距离平均值、欧氏距离平均值均明显优于扩展卡尔曼滤波器跟踪策略。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.004032
{DOI}: 10.27272/d.cnki.gshdu.2022.004032
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂交通场景下基于DeepSort的多目标多类别跟踪算法研究
{Author}: 牟亮
{Tertiary Author}: 赵红
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智能交通系统;复杂交通场景;深度学习;多目标多类别跟踪
{Abstract}: 随着社会的快速发展,人们对交通出行的多样化需求愈发强烈,导致了交通的复杂程度越来越高,在复杂的交通环境中容易发生交通拥堵以及交通安全问题,并且准确获取该场景的交通信息是一项非常必要以及非常困难的任务。在计算机视觉领域,目标跟踪是一个热门的研究方向,应用到交通领域中可以为通过视觉传感器来获取交通的实时状况,为及时做出交通决策避免交通问题的发生提供技术理论支持。主要选择基于检测的目标跟踪策略进行研究,使用具有代表性的简单的在线和实时深度关联度量算法(Deep Sort),在其基础上提出一种针对复杂交通场景的多目标多类别跟踪算法。目标检测部分,使用Vis Drone数据集,该数据集中包含城市交通场景中常见的十个目标类别,是使用无人机拍摄得到的,为研究对于该场景下多目标多类别跟踪算法提供数据支持。将该数据集应用到目标检测和目标跟踪算法的实验部分,目标检测作为获取场景中目标信息的第一步,其性能好坏直接影响跟踪算法。本文对比Faster-RCNN、YOLO v3以及YOLO v5检测算法,其中YOLO v5共有从小到大四种规模的网络模型:YOLO v5s、YOLO v5m、YOLO v5l和YOLO v5x,在Vis Drone数据集上训练及检测的性能,综合评价各种算法检测精度及速度,选择YOLO v5m模型作为跟踪算法的检测器。目标跟踪部分,目前的跟踪算法无法在复杂的交通场景中对目标类别信息进行准确跟踪,这是没有意义的,针对目前的多目标跟踪策略中缺乏对于目标类别信息判别的问题,提出一种多目标多类别跟踪算法。Deep Sort算法的原始表观模型是基于行人数据集训练完成的,对于其他类别的特征提取能力较差,构建数据集来对其表观模型进行重训练,提高算法对于目标位置信息跟踪的准确率。将类别信息融入到Kalman滤波器中,重新对状态变量、观测变量等进行定义;然后基于Deep Sort跟踪得到的类别共现矩阵,使用Jaccard指数构建类别相似度网络,结合该网络统计分析当检测类别发生错误检测时的置信度变化,通过曲线拟合获得动态阈值函数,构建了类别匹配模块,完成对类别的匹配以及修正任务,提高算法对目标类别信息跟踪的准确率。经过实验验证,本文建立的多目标多类别跟踪算法在复杂交通场景中,跟踪准确度(MOTA)相比YOLO v5m+Deep Sort算法提升5.5%,跟踪类别准确度(MOTCA)提高8.3%,阈值25下的目标中心精准度提升5%,阈值0.5的重合率提升9%。该结果表明,多目标多类别跟踪算法可以更加准确、完善的在复杂交通场景中完成目标跟踪任务,这对智能交通系统的发展具有重要意义。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2022.000517
{DOI}: 10.27262/d.cnki.gqdau.2022.000517
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于轻量化深度神经网络的目标检测方法研究
{Author}: 朱熙宇
{Tertiary Author}: 吴庆波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;模型压缩;深度学习;轻量级神经网络
{Abstract}: 目标检测是计算机视觉以及图像和视频处理技术的重要应用领域,其任务是根据图像或者视频的视觉特征来定位和分类其中的目标实体。随着深度学习技术在计算机视觉领域的应用,目标检测模型的性能比以往有了很大提升,然而实际中大部分模型因为计算量和参数量庞大,导致在边缘侧部署起来困难,因此轻量化目标检测算法的研究和应用越来越重要。设计轻量级目标检测网络,需要结合应用场景来考虑问题,因为这种模型通常部署在移动设备上。首先需要根据设备算力的差异灵活的调整模型尺寸;其次当考虑轻量级目标检测模型的平台兼容性,要求在不改变网络结构的基础上压缩模型;再次,当考虑存储空间及功耗开销时,一般的深度学习模型中有大量的浮点运算,不适合直接用于移动设备上运行。因此针对上述提到的问题,本文的开展的工作如下:(1)针对轻量级目标检测模型无法灵活适应不同算力的设备,从优化网络结构的角度出发,采用通道剪枝的方法来压缩目标检测模型,并通过减小训练迭代时BN层的相关性提高剪枝的准确度。对于性能不同的移动设备,可以根据其算力,调节网络剪枝的比例,提高了模型部署的灵活性,让模型能适应多种不同的移动设备。(2)针对轻量级目标检测模型对系统软硬件环境有特别的要求,从不改变模型基本结构的角度出发,采用知识蒸馏的方法提升轻量化目标检测模型输出的目标位置和类别准确度,并通过域对齐的方法进行特征谱线索蒸馏来改善学生网络的特征。经过蒸馏后的轻量级模型可以直接部署在原来的系统中,而不需要软硬件对其针对性优化。(3)针对轻量级目标检测网络浮点数存储及计算开销大的问题,从目标检测模型参数的存储形式出发,提出通过定点量化网络参数的方法,采用感知量化训练后再进行参数量化,并通过引入软量化函数让量化误差能够参与训练。将原始目标检测模型从浮点计算转换为定点数计算,能够减少处理器的功耗开销和延长移动设备的工作时间。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.005056
{DOI}: 10.27005/d.cnki.gdzku.2022.005056
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的飞机外观智能检测算法研究与应用
{Author}: 张学林
{Tertiary Author}: 王洪君
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 飞机外观检测;深度学习;目标检测;双目测距;嵌入式系统
{Abstract}: 飞机作为一种快速便捷的交通工具在现代社会中发挥着重要作用。随着航空科技的不断发展,飞机部件的稳定性也不断提高,然而飞机安全检查工作仍然是一项重要的任务,其中起飞前的绕机检查作为飞行的最后一道保障措施具有极为重要的意义。该检查涉及对飞机若干重要部位外观的检查,不仅需要耗费大量的人力、物力,也会因为地勤人员的失误出现误判漏判。人工智能和计算机视觉技术的飞速发展,使得该问题可以引入智能化的方式解决。本文提出搭载于机场巡检机器人的飞机外观智能检测算法,该算法能够根据巡检机器人在绕机过程中利用相机采集到的画面对飞机各关键部位进行检测,找出安全故障并对故障进行定位与记录。算法主要包括目标检测算法与双目测距算法两大部分,为了能够搭载在巡检机器人上,本文最后将算法部署在NVIDIA嵌入式平台Jetson AGX Xavier上,并通过对算法改进与优化完成精准检测与实时运行的目标。在目标检测算法部分,针对传统一阶段目标检测模型对小目标检测精度较低的问题,本文以YOLOX网络为框架,使用Swin-Transformer结构改进了 YOLOX骨干网络部分,提高了骨干网络的特征提取能力;同时为了提高对难检测目标的检测能力,本文使用Focal Loss改进网络的损失函数,使模型更加专注于难样本。实验结果表明,在飞机外观检测数据集上本文改进网络达到86.24%的准确率,相比于YOLOX网络提升1.27%。在经过NVIDIA平台TensorRT加速后单帧运算速度达到7.03ms,保证了运行的实时性。在双目测距算法部分,针对传统双目测距算法实时性较差的问题,本文提出了一种基于感兴趣目标提取的快速测距算法,双目视觉中最常用的SGBM算法虽然精度较高,但在实时性方面无法满足本文的要求,本文改进算法基于SGBM算法改进而来,能够与目标检测算法的结果结合,在不丢失精度的情况下极大地减少匹配过程中的运算量。同时本文提出了 MAD-Census变换改进了 SGBM算法基于互信息的匹配代价计算方法,此方法不仅直接降低了计算复杂度,而且对多线程有很好的适配性,在应用过程中极大地提高了运算速度,距离测试实验表明,该算法的测距误差在10%以下。在公开数据集上的测试实验表明,以72.97%的速度提升相对于SGBM算法误匹配率仅提高了 7.58%。最后,本文根据此算法设计了飞机外观智能检测系统,并对系统各个模块的功能以及系统的实时性进行了测试,系统包括目标检测与测距模块、机器人运动控制模块、网络模块。测试结果表明各模块都能够正确地输出结果,在经过对各个模块算法的改进和多线程优化后,显著的提升了运行效率。系统单帧运算的耗时约为60ms,每秒可达16至17帧,处理时间能够满足实时性要求。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.005202
{DOI}: 10.27272/d.cnki.gshdu.2022.005202
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进DeepLab V3+的语义地图构建
{Author}: 李琳;吴怀宇;张天宇
{Author Address}: 武汉科技大学信息科学与工程学院;武汉科技大学机器人与智能系统研究院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 10
{Pages}: 255-265
{Keywords}: 机器视觉;语义地图;语义分割;三维稠密地图;点云拼接;区域生长
{Abstract}: 为了提高移动机器人感知环境、执行高级任务的能力，针对传统视觉同时定位与建图（SLAM）构建的地图缺乏语义信息无法对场景内容进行理解的问题，提出一种基于物体分割的语义地图构建方法。首先，通过改进的语义分割模型DeepLab V3+对二维图像进行分割，获取物体的标签；然后，根据改进的迭代最近点（ICP）点云拼接方法构建稠密地图，并且采用区域生长算法对三维点云进行分割；最后，将二维标签映射到三维稠密地图中，构建出语义地图。实验结果表明：所提改进的DeepLab V3+算法与原方法相比，检测速度提高了约4倍；采用改进的ICP算法进行点云拼接时，在TUM数据集的fr/360序列上其相对轨迹误差较ORB-SLAM算法减小了约16.4%；最后，与ORB+YOLOv3、ORB+MASK-RCNN、ORB+DeepLab V3+方法相比，所提方法减少了语义地图的冗余信息，而且建图速度更快，并且占用储存更少。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvynxRjoPveLjHzx0vKUm8x7y9mArRc_fbDLeuu1qiKEkJ1ttea6d28Rt2htebB-Y-kiOeQ__BvYldbm9fO7vm_L_R7vCBEkjERn7fs9Ai7kZTTUnKvBTmdRP4WL50YbD7X3w6u29jjsh0Le9jiLnwTSD6WJnhRm4AdOHvOjcUC3tYdbceShUBsGPqX7-eShmSU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低照度图像增强算法研究
{Author}: 陈文
{Tertiary Author}: 胡超;刘飞飞
{Publisher}: 江西理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;计算机视觉;生成对抗网络;图像处理;低照度图像增强
{Abstract}: 不仅人类需要通过视觉系统来接收外界信息了解世界,而且一些使我们生活更加便捷的高科技技术也需要通过图片或者视频来获取信息。例如医学影像、智能交通和安防监控等领域,都需要大量的高品质图像资源来提供驱动。其中常见的就有在低照度情况下所拍摄的图像质量差的问题。低质量的图像数据会严重影响后续的操作效果,所以需要设计相对应的方法来进行低照度图像的增强。现有的低照度图像增强方法大多只能从成对的数据集中学习,这使得现有的模型大多数存在着鲁棒性和实时性等方面的不足。很多模型对数据有着严重的依赖,一旦把模型放在其他数据集上,效果就不明显。本文在现有的用于低照度图像增强的深度学习技术的基础上,结合不同方法的诸多优点,做出了如下改进:1.设计了EBGAN(Energy-based GAN)与Patch GAN相结合的判别器架构:虽然WGAN(Wasserstein GAN)避免了JS散度值为常数带来梯度消失问题,但是其具体的操作十分简陋。这使得判别器变成了一个二分器。因此,WGAN中的重量剪裁的方法发挥不了深度神经网络的卓越拟合能力,相关计算将导致网络训练困难、收敛速度慢等问题。本文使用EBGAN将判别器从WGAN的二分器变为自动编码器,使得判别器更加高效。Patch GAN则通过对各个部分进行了互不影响的判断,从而完成了对局部图像特征的获取与表示。2.设计了由全局与局部组成的注意力机制模块:可以通过借鉴人类大脑对图像处理的注意力原理,着重关注注意力区域的图形特性,从而改善模型的效果。局部注意力机制使得模型对局部的曝光细节更加敏感,避免了只有全局注意而导致的局部过曝。3.针对人眼衡量两幅图像之间差距的方式,改动了损失函数,使用贴近人类感知的结构相似性作为损失函数。4.设计了一个自适应的双边滤波器:通过反向传播神经网络来预测双边滤波器中的标准差,并使用双边滤波器对生成的图像进行滤波。对比高斯滤波等方式,双边滤波对边缘细节能起到很好的保护作用。
{URL}: https://link.cnki.net/doi/10.27176/d.cnki.gnfyc.2022.000499
{DOI}: 10.27176/d.cnki.gnfyc.2022.000499
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的单目图像深度估计方法研究
{Author}: 蒋思
{Tertiary Author}: 杨巧宁;张忠伟
{Publisher}: 北京化工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 单目图像;深度估计;多尺度特征;结构损失函数;小波变换
{Abstract}: 单目图像深度估计是根据RGB图像估计每个像素点的深度值,即物体离摄像头的距离。它作为计算机视觉领域的热门研究方向之一,已广泛的应用到自动分拣机器人、VR虚拟现实、自动驾驶等人工智能领域。目前,在基于深度学习的单目图像深度估计方法中,存在特征提取、表达不够充分的问题,导致深度估计精度不高。本文围绕特征提取、表达展开研究,旨在提高深度估计精度,主要工作如下:1.设计了基于多尺度特征提取和结构相似性的单目图像深度估计方法模型。该方法引入Res2Net网络作为特征提取器,Res2Net在单个残差块中对输入特征图进行通道分组,对分组后的特征图采用阶梯型卷积提取更细粒度的多尺度特征,提高了网络多尺度特征提取能力,最终提升了深度图的整体精度。其次,设计了边缘增强模块,使用高通滤波器保留了物体的边缘特征,解决了原网络下采样过程中边缘像素丢失问题,提高深度图质量。最后,在损失函数中引入了结构相似性,通过计算图像块的损失值,加强了网络学习局部特征的能力,提高深度估计的精度。实验结果表明,该方法可以有效提高深度估计精度,均方根误差RMSE达到了0.508,相比于基础网络减小了2.2%,阈值δ<1.25达到了0.875,相比于基础网络提升了0.9%。2.设计了基于有效特征提取和小波损失的单目图像深度估计方法模型。该方法首先设计了一种上采样模块,该模块分为两部分,一部分采用亚像素卷积生成高密度有效像素的特征图,避免了原网络中产生大量的冗余像素的问题;另一部分采用不同大小卷积核对亚像素卷积后的特征图进行特征提取,提高网络对有效特征的提取、表达能力。其次,在损失函数中引入了小波变换,将图像划分为高频区域和低频区域,通过对不同区域计算损失函数监督网络训练,提高了网络表达特征的能力。实验结果表明,该方法可以实现深度图整体精度的提升,均方根误差RMSE达到了0.509,相比于基础网络减小了2.1%,阈值δ<1.25达到了0.875,相比于基础网络提升了0.9%3.设计了基于多尺度有效特征提取和小波损失的单目图像深度估计方法模型。该方法综合了Res2Net网络、边缘增强模块、上采样模块、小波损失函数的优点,提高网络的多尺度特征、有效特征的提取和表达能力。实验结果表明,该方法提高了深度图的整体精度,均方根误差RMSE达到了0.506,相比于基础网络减小了2.4%,阈值δ<1.25达到了0.876,相比于基础网络提升了1%。
{URL}: https://link.cnki.net/doi/10.26939/d.cnki.gbhgu.2022.000274
{DOI}: 10.26939/d.cnki.gbhgu.2022.000274
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的架空输电线路缺陷检测
{Author}: 朱轩
{Tertiary Author}: 邱志斌;王栋
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 输电线路;缺陷检测;鸟种检测;绝缘子;异物;YOLOv4
{Abstract}: 架空输电线路经过山川、河流、森林等复杂坏境,同时相关附属电力设备也长期处于各种气候环境下,不可避免地遭受雷击、鸟害、外力破坏等影响,导致输电线路附件及电力设备发生老化、损坏、短路等故障。如果不及时检查并替换已经出现故障的器件,则易引起供电中断、大范围停电等事故,因此有必要周期性地检查输电线路,及时发现线路中存在的不安全因素。本文基于计算机视觉技术对架空输电线路开展缺陷检测方法研究,针对渉鸟故障危害鸟种、绝缘子破损、悬挂异物等案例进行目标检测与识别。通过电力巡检图像与网络公开数据建立样本数据库,结合图像增广技术扩充样本,以提高模型整体精度及泛化性能;利用轻量级卷积神经网络、卷积类型、注意力机制等改进YOLOv4目标检测模型,减少了模型参数量以实现模型轻量化,降低边缘设备的内存需求,同时提升模型检测性能。具体研究工作如下:(1)提出了一种基于YOLOv4-tiny目标检测模型的输电线路涉鸟故障危害鸟种检测方法。根据国家电网公司的调查统计结果,构建了20种典型危害鸟种图像数据集;采用分阶段训练、Mosaic数据增强、标签平滑、余弦退火等技巧训练YOLOv4-tiny目标检测模型,以节省训练资源并提高模型精度;结果表明本文方法鸟种检测精度可达92.02%,检测速度可达40FPS;此外,采用散焦模糊、运动模糊、亮度与对比度调整预处理方法,模拟出模型在图像模糊、极亮、极暗下的检测效果,同时对实际杆塔构件与鸟巢部分遮挡情况下的鸟种图像进行检测,其结果验证出YOLOv4-tiny模型在实际运行环境下能够具有良好鲁棒性。(2)提出了一种基于改进YOLOv4的输电线路绝缘子缺陷检测方法。为扩充图像并解决样本不均衡问题,采用Graphcut分割算法生成新的缺陷绝缘子图像,构建输电线路绝缘子图像数据集;以Mobile Net V1轻量化卷积神经网络替换YOLOv4中的特征提取网络,并基于深度可分离卷积设计DSC-SPP与DSCPANet网络,建立改进YOLOv4检测模型;通过多种训练技巧与拉普拉斯图像锐化提高模型的检测精度。结果表明,改进YOLOv4模型的检测精度和速度分别可达97.26%、53FPS。此外,采用图像雾化、亮度与对比度调整预处理方法,模拟出模型在雾天、曝光、光照极暗下的检测效果,结果验证出改进YOLOv4模型能够具有良好的鲁棒性。(3)提出了一种基于嵌入式双注意机制的轻量级YOLOv4模型(YOLOv4-EDAM)输电线路悬挂异物检测方法。采用泊松融合算法合成新的异物图像样本,基于真实与合成异物图像构建鸟巢、风筝、气球、垃圾四类输电线路异物图像数据集,并通过Dn CNN抑制图像中的噪声。基于SENet与Mobile Net V2设计SENet-Mobile Net V2替换YOLOv4中的特征提取网络,采用卷积块注意模块(convolutional block attention module,CBAM)设计CBAM-SPP与CBAM-PANet网络,建立YOLOv4-EDAM异物检测模型。结果表明,YOLOv4-EDAM模型的检测精度与速度可达96.71%、45FPS,且在多目标、雾天、夜间三种特殊情况下的检测效果优于其他检测算法。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.002718
{DOI}: 10.27232/d.cnki.gnchu.2022.002718
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv3的疲劳驾驶检测算法的研究与应用
{Author}: 吴子强
{Tertiary Author}: 陈萌;郭晓峰
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;疲劳驾驶检测;YOLOv3网络;EfficientNet;注意力机制
{Abstract}: 针对传统疲劳驾驶检测模型存在的网络模型较大以及检测精度低等问题,本文提出了一种基于改进YOLOv3的疲劳驾驶检测算法,并通过实验验证了其可行性,最终基于该模型实现了疲劳驾驶监督预警系统以及疲劳驾驶监管系统。本文的主要研究内容及工作如下:1.为了加快模型收敛的速度并且提升检测精度,本文改进了YOLOv3算法的Anchor Boxes以及回归损失函数Io U。利用K-Means++聚类算法结合本文所采用的疲劳驾驶数据集重新聚类,生成了新的Anchor Boxes,优化由于检测数据集不同而带来的收敛速度下降,精度损失等问题。实验结果表明重新聚类的先验框不仅可以加快模型的收敛速度,而且提升了模型检测的精度。之后采用CIo U边界回归损失函数替换原有的Io U边界回归损失函数,以优化Io U回归损失函数存在的梯度消失问题,实验结果表明,改进后的损失函数不仅解决了上述问题,并且提高了算法检测的精度。2.提出了一种新的基于改进YOLOv3算法的疲劳驾驶检测模型ESAYOLOv3(基于EfficientNet、SPP以及注意力机制的疲劳驾驶检测网络)。为了解决Darknet53存在参数量多,计算量大等问题,本文采用EfficientNet替换原有的Darknet53作为ESA-YOLOv3算法新的主干特征提取网络。实验结果表明,基于EfficientNet的检测模型有效的降低了模型的参数量并且模型大小降低了69.7%;同时为了进一步提升该网络对于疲劳驾驶数据的检测精度,本文在改进网络的主干特征提取网络之后添加了DBL×3以及SPP模块,并且在多尺度特征融合之后添加了ECANet高效通道注意力机制。实验结果表明,基于SPP以及注意力机制的ESA-YOLOv3的疲劳驾驶检测算法,有效的提升了网络对于关键特征的捕获能力,并且检测的精度提高了1.85%。3.本文基于ESA-YOLOv3疲劳驾驶检测算法并且结合Python、Pyqt5以及Django框架全面实现驾驶员疲劳驾驶监督预警系统以及交管部门疲劳驾驶监管系统,最后通过功能测试,验证其满足基本使用要求。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.002580
{DOI}: 10.27232/d.cnki.gnchu.2022.002580
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向智慧安全管控的复杂人体行为识别技术研究及应用
{Author}: 姚磊岳
{Tertiary Author}: 黄伟;徐子晨
{Publisher}: 南昌大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 智慧安全管控;人体行为识别;零样本学习;动作时序定位;样本增强;多尺度学习
{Abstract}: 安全是一切工作的前提与基础。通过视频监控对人体行为进行识别和理解一直是智慧安全管控领域的重点研究内容。目前,对单一人体动作识别的研究已经取得了显著成果,但对由多种基本人体动作所构成的复杂人体行为识别的研究较少。现有复杂人体行为识别方法普遍存在成本高、效率低、通用性差等不足,无法满足安全管控系统的多样化需求,阻碍了安全管控系统的智能化运作。本文针对智慧安全管控中视频监控系统实施成本高、无法满足个性化人体行为监控需求,以及难以与其它信息系统整合等工程管理问题,设计并实现了一套基于语义定义的复杂人体行为识别视频监控系统。相关研究工作以零样本复杂人体行为识别为目标,围绕人体行为量化表示与数据增强、动作时序定位、复杂人体行为语义层特征学习三个方面开展研究,提出了一种基于紧凑型存储思想的人体行为三维矩阵表示方式,一系列基于人体生理结构和人体运动特点的行为样本增强策略,以及一种基于大尺度时间窗口优先的探进式单步动作时序定位方法。并根据“任何复杂人体行为是基本动作时序组合”的定义,将复杂人体行为识别问题转换为“动作词及其特征在长时视频中的提取”和“动作组合语义相似度判断”两个主要问题,设计并构建了一个零样本下也可有效习得复杂人体行为语义特征并进行准确识别的神经网络模型。主要研究工作如下:(1)针对人体行为特征因时空重叠导致运动信息丢失,以及样本不足易导致模型过拟合的问题,开展了基于人体骨架序列的多特征融合行为表示与数据增强策略的研究,提出了一种“人体行为视频→运动图谱/矩阵”的通用表示方法,实现了人体运动信息的紧凑型存储,并基于此表示方法,提出了多种基于骨架运动信息的样本增强策略。首先,提取每一帧视频中人体各关节点的运动速度、加速度、运动方向等原始运动信息以及相对坐标信息和人体几何结构信息;然后,将上述信息独立存储于由“时间、关节点、关节点特征”所构建的三维矩阵对应切片。通过延展存储域的时间维度,避免了同一存储单元因运动轨迹时空重叠导致的运动信息覆盖。另外,在此基础之上,结合人体生理和运动特点,通过程序模拟生成不同身高的行为人,以不同的速度、不同的方向,执行同一样本行为,使所生成的新动作样本是既符合人体骨架生理结构和比例,又符合人体行为规律,并包含新运动信息的“可信”动作样本,以满足深度学习模型对训练样本数量大、质量高的要求。(2)针对人体动作持续时间不固定,动作之间衔接转换无规律可寻,动作在复杂人体行为视频中难以精确定位的问题,开展了面向动作时序定位的多尺度神经网络与算法的研究,提出了一种基于大尺度时间窗口优先的探进定位方法。首先,通过插值拟合以及隔帧抛弃策略,使动作样本在尺度归一化后,能最大程度保留原始样本的运动信息;其次,基于“尺度金字塔池化层”和“全局平均层”组合,实现了深度神经网络模型在多个不同时间尺度样本集上的特征学习。不仅提高了模型的精度,而且能为动作时序定位提供灵活的时间窗口配置;最后,将中文分词领域成熟的“长词逆序分词”算法引入至人体动作时序定位领域并加以改进,通过“大尺度时间窗口优先”和“探进”策略,提升了模型对细微动作的发现能力,提高了动作时序定位效率。(3)针对复杂人体行为因种类不可枚举,导致识别模型通用性差、语义理解准确性差的问题,开展了面向复杂人体行为识别的量化表示与语义学习研究,提出了一种基于语义描述的通用复杂人体行为识别方法。首先,通过语义层定义,以低维度表达方式(文字)对高维度内容信息(视频)进行描述,使复杂人体行为在零样本情况下也可被精确定义;然后,通过词向量与运动特征的时序组合,实现了复杂人体行为的通用量化表示模型。使种类不可枚举、持续时长各异的复杂人体行为能够被量化为尺度相同的三维矩阵;并最终使深度神经网络能够从语义层习得复杂人体行为特征,以及在零样本情况下对复杂人体行为进行准确识别。本文通过对上述三个内容的研究,解决了动作识别、动作时序定位、复杂人体行为识别领域中现存的若干关键技术问题,提出了一系列技术可行且普适性较高的新思路、新模型和新方法。相关研究成果还解决了安全管控领域中人体行为监控及预警的若干工程应用痛点,降低了相关技术在应用和推广过程中的成本,提升了安全管控系统的“智慧化”程度。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.001285
{DOI}: 10.27232/d.cnki.gnchu.2022.001285
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像分割与目标检测在农业场景中的应用研究
{Author}: 金沙沙
{Tertiary Author}: 蒋林华
{Publisher}: 湖州师范学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 芽长检测;根长检测;蔬菜抽薹检测;图像分割;目标检测;切片推理
{Abstract}: 种子是农业科技的芯片。芽长是种子活力的一个重要判定标准。传统的芽长测量和蔬菜生长监测方法采用人工测量的方式,既费时费力、又容易受人为主观因素影响。农产品生长监测是智慧农业的重要一环。蔬菜抽薹是开花的初级阶段,而蔬菜开花会影响蔬菜商品性,因此及时检测到蔬菜发生抽薹现象,有利于及时采摘以及对水肥策略进行调整。随着计算机视觉技术的发展,图像分割与目标检测在农业场景有很高的应用价值。本文研究利用图像分割技术提高种子芽长、根长检测的效率,并通过目标检测的方法对蔬菜进行抽薹检测。本文的主要研究工作如下:(1)提出一种芽长、根长进行自动检测方法,利用芽、根的颜色特征以及种子的形状特征判断芽、根分界线,采用形态学方法对芽、根的边缘轮廓进行处理,然后通过骨架细化方法获取芽根图像的骨架,并提出了一种端点删除剪枝法只保留骨架中芽和主根的部分,最后利用像素点间的欧氏距离计算芽长与根长。通过对玉米、小麦、水稻的芽长和根长进行测量,结果显示,玉米、小麦与水稻芽长的百分误差分别为2.90%、2.05%、2.40%;根长的百分误差分别为1.90%、2.11%、2.02%。(2)为实现蔬菜抽薹检测,本文采集了27段时长为30s到2min的视频,每隔25s抽取一次视频帧,并对抽取出的图像帧分别按照大小为256×256、重叠率为0.2和大小为640×640,重叠率为0.3的标准对整幅蔬菜图像进行有重叠分块处理,然后利用label Img标注工具对分块图像中的菜薹进行标注,生成2300幅包含菜薹的图像块,再通过离线数据增强的方法,对图像分别旋转3°和5°,进行图像融合,将数据集扩充到8710幅。(3)针对YOLOv5s目标检测算法在检测小目标时效果不突出的问题,本文引入了图像切片推理库SAHI(Slicing Aided Hyper Inference)实现大图像切片推理,然后合并推理结果,在一定程度上解决了在大图像中检测小目标的问题;在训练过程中采用Mosaic在线数据增强方法,进一步扩充数据并将NAM(Normalization-based Attention Module,基于归一化的注意力模块)注意力机制加入到YOLOv5s主干网络上,并参考Bi FPN(Bi-directional Feature Pyramid Network,双向特征金字塔)的思想修改YOLOv5s的颈部网络,提高YOLOv5s的特征融合能力。改进后的模型查全率、召回率、m AP(0.5)分别为0.949、0.946、0.955,其中查全率和m AP(0.5)分别较原YOLOv5s提升了1.2%、0.6%。根据文中所提出的方法,可以分别设计搭建芽长、根长检测系统和蔬菜抽薹检测系统,有利于推进农业产业自动化,降低人力成本和时间成本。此外,本文也为其它农业图像的研究提供了参考案例。
{URL}: https://link.cnki.net/doi/10.27946/d.cnki.ghzsf.2022.000228
{DOI}: 10.27946/d.cnki.ghzsf.2022.000228
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLO-V5的矿车桁架铆接孔定位技术研究
{Author}: 程亚彬;张宏伟;王新环;郭子路
{Author Address}: 河南理工大学电气学院;平顶山市安盛机械制造有限公司;
{Journal}: 现代制造工程
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 115-121
{Keywords}: 自动铆接;机器视觉;YOLO-V5算法;最小二乘拟合圆法
{Abstract}: 在矿车车厢自动化生产中，采用机器视觉技术来实现自动铆接工艺。为了对铆接孔进行准确识别与定位，采用深度学习中的YOLO-V5算法对铆接孔进行实时检测，结合最小二乘拟合圆法，在弥补了检测结果缺陷的同时，利用提取的铆接孔边缘坐标，实现了对铆接孔所在位置的准确定位。通过试验，证明了该方法的可行性与鲁棒性。通过对比试验，证明了算法的优越性。
{ISBN/ISSN}: 1671-3133
{Notes}: 11-4659/TH
{URL}: https://link.cnki.net/doi/10.16731/j.cnki.1671-3133.2022.05.018
{DOI}: 10.16731/j.cnki.1671-3133.2022.05.018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的铣刀状态在机监测方法研究
{Author}: 由智超
{Tertiary Author}: 高宏力
{Publisher}: 西南交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 刀具磨损;状态监测;机器视觉;图像处理;轻量化网络
{Abstract}: 刀具作为切削加工的直接执行者,良好的刀具磨损状态是保证加工过程安全性、可靠性和稳定性的关键因素之一。基于机器视觉的刀具磨损状态监测方法不受切削条件和工件材料的影响,在测量刀具磨损实际形状变化方面具有更高的精度和可靠性,并且便于对刀具的磨损形态了解,有助于切削加工参数优化、刀具寿命预测以及加工质量的评估。本文的内容将围绕基于机器视觉的铣刀状态在机监测关键技术展开,深入分析实际加工过程中限制直接法工业应用的影响因素,研究符合实际工程需求的刀具磨损状态识别和评估方法,研究成果对于推动基于机器视觉的刀具状态监测智能化、自动化发展具有重要意义。主要研究工作如下:1.针对小视野高精度的机器视觉系统的安装时间较长以及如何部署刀具状态监测系统以实现高质量刀具图像捕获的问题,进行了宽视场下机器视觉监测系统的硬件选型以及提出基于改进信息熵的多项式回归部署模型。首先,根据刀具磨损检测精度需求与宽视场的协调关系,以及动态检测要求进行机器视觉硬件系统选型。通过工作模式切换的方式保证刀具状态监测系统固定在机床工作台上。此外,考虑背景模型影响的信息熵部署评价指标与工作距离、曝光时间都具有主效应关系,这符合刀具状态监测系统部署参数的客观变化规律。2.针对单张图像无法完备反映刀具磨损特征且捕获单张图像会给机床带来停机时间的问题,提出刀具状态图像序列概念以及自适应捕获方法。基于磨损机理、成像原理和实验验证的方法,首次提出刀具状态图像序列的概念,诠释了在动态图像中哪些图像可以综合反映刀具磨损特征。然后,基于定向梯度直方图、图像编码和逻辑回归分类模型实现刀具图像序列的自适应定位。最后,通过平衡磨损测量要素和磨损测量基准定位刀具状态图像序列中刀具磨损区域,并基于运动模型和局部搜索方法实现后续刀具磨损区域的精确跟踪。3.针对传统高复杂度神经网络模型难以部署应用以及深度学习需要高质量和数量的数据集的问题,提出一种基于数据增强和多重激活函数的轻量级网络模型。首先,分析了工业环境下复杂工况造成的成像质量变化机理。进而,在保证数据质量和丰富度的前提下,采用数据增强来解决数据规模问题。然后,在网络的前端和后端分别引入自适应激活函数和h-swish激活函数,避免信息丢失,降低激活函数成本。最后,构建基于边-云协同的轻量化刀具磨损分类网络模型。该模型在云端迭代优化,并在边缘嵌入式设备上进行推理部署。4.针对在宽视场下高分辨率相机捕获的刀具图像占用大量内存的问题,提出了“定位、分割、测量”层层递进的刀具磨损高精度检测方法。首先,利用同态滤波器和直方图对比度方法实现刀具磨损区域的粗略定位。在此基础之上,改进Grab Cut算法以实现刀具磨损区域的精确分割。最后,通过最小二乘法拟合主切削刃作为刀具磨损测量的基准,以实现后刀面磨损区域的划分和测量。5.针对现有刀具磨损评价指标忽略刀具磨损区结构特征,从而不具备区分不同形式后刀面磨损的问题,提出了一种基于磨损距离离散度的后刀面磨损评估指标。首先,利用先验知识构建正态分布模型,以描述宽视场中刀具-切屑间接接触区内磨损距离的概率分布。通过概率分布阈值计算置信区间,从而实现刀具-切屑直接接触区域的提取选择。然后,提出了一种基于磨损距离离散度的刀具状态监测评价指标,在刀具-切屑直接接触区内表征不同的后刀面磨损形式。在此基础上,构建磨损距离离散度随加工时间的变化率,以准确识别刀具寿命周期内三种后刀面磨损形式转换的时间节点。
{URL}: https://link.cnki.net/doi/10.27414/d.cnki.gxnju.2022.000073
{DOI}: 10.27414/d.cnki.gxnju.2022.000073
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的细粒度图像分类
{Author}: 郑智文
{Tertiary Author}: 甘健侯
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 细粒度图像分类;多尺度多层次;节点级注意;语义级注意;图注意力网络
{Abstract}: 细粒度图像分类任务是计算机视觉领域一项极具挑战的研究课题。近年来,深度学习技术的快速发展极大地推动了细粒度图像分类任务的研究,各种网络模型算法涌现而出。细粒度图像分类任务的关键主要在于如何准确定位具有分辨力的关键区域并从中提取有效特征,但往往由于类间差异小和类内差异大,使得细粒度图像分类任务难以取得更优的分类效果。本文基于Vision Transformer(Vi T)模型和图注意力网络分别研究了两种场景下的细粒度图像分类算法,充分利用图像的多层次、多尺度、多模态和语义特征信息,以达到提升细粒度图像分类任务性能的目的。本文主要研究工作如下:(1)基于Vi T模型的细粒度图像分类。针对无文本的细粒度图像分类任务,本文结合了数据增强、多尺度输入、多层次Vi T以及交叉注意力提出了一种基于Vision Transformer模型的细粒度图像分类算法。首先,图像先经过数据增强获取一种破坏性的增强,之后将增强后的图像以小尺度和大尺度两种尺度的卷积核进行卷积操作,卷积后的两种特征图通过设计好的多层次Vi T,接着把从Vi T中输出的两种张量送入设计的交叉注意力网络,最后采用softmax进行分类。模型在四个细粒度图像分类公共数据集上的实验对比,验证了本文方法与目前主流先进方法相比具有较强的竞争力。(2)基于注意力网络推理图的细粒度图像分类。针对场景文本细粒度图像分类任务,本文结合了多模态语义特征提出了一种基于注意力网络推理图的细粒度图像分类算法。该算法中首先对提取的图像文本特征和局部视觉特征进行位置信息嵌入,并将其作为图节点生成的异构图通过元路径分解分别放入节点级注意和语义级注意的两级注意力网络推理图,接着,将输出的节点特征与提取的全局视觉特征进行融合以获得具有丰富语义的细粒度特征,最后采用softmax进行最终的分类。模型实现了多模态融合与图注意力网络的有效结合,且在两个场景文本细粒度图像数据集上与目前主流先进方法相比具有较强的竞争力。(3)细粒度图像分类系统设计与实现。本文采用C/S结构,MVC的设计模式,设计并开发了一款智能图像识别APP,该软件有效集成了本文提出的两种场景下的细粒度图像分类算法,可进行六大主题569类细粒度图像识别,同时支持用户拍照上传识别、图像文本自动检测、识别结果反馈及相似图像结果展示等功能。该系统识别图像种类多,且具有良好的用户交互和体验性,具有较好的实用价值和广泛的应用前景。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2022.000726
{DOI}: 10.27459/d.cnki.gynfc.2022.000726
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向机器视觉的不锈钢棒材表面螺纹缺陷检测
{Author}: 侯幸林;周培培;赵景波;高照;孙磊
{Author Address}: 常州工学院汽车工程学院;常州工学院电气信息工程学院;
{Journal}: 重庆理工大学学报(自然科学)
{Year}: 2022
{Volume}: 36
{Issue}: 05
{Pages}: 109-114
{Keywords}: 不锈钢棒材;螺纹缺陷;机器视觉;特征提取;数据集
{Abstract}: 不锈钢棒材表面的螺纹是棒材磨制过程产生的一种缺陷，严重影响棒材的验收与后续使用，目前针对该类缺陷多采用双目观察、手指感知等人工方式进行判断，漏检率较高。已有的方法多针对钢材表面的划痕、砂眼、凹坑等缺陷进行检测，鲜少对螺纹缺陷进行研究，据此，设计了一种基于机器视觉的螺纹缺陷检测方法，提出了一种快速有效的螺纹特征提取方法，建立了一个不锈钢棒材图像的螺纹缺陷数据集，通过对图像特征进行训练，得到分类器。实验结果表明：提出的算法有效提升了螺纹缺陷的检测正确率和检测速度。
{ISBN/ISSN}: 1674-8425
{Notes}: 50-1205/T
{URL}: https://link.cnki.net/urlid/50.1205.T.20220512.1012.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于WOA-BPNN的锂电池极片涂布缺陷检测识别
{Author}: 钟健平;费韬
{Author Address}: 华南理工大学自动化科学与工程学院;精密电子制造装备教育部工程研究中心广东省高端芯片智能封测装备工程实验室;
{Journal}: 储能科学与技术
{Year}: 2022
{Volume}: 11
{Issue}: 08
{Pages}: 2537-2545
{Keywords}: 机器视觉;缺陷检测;图像分类;锂电池极片
{Abstract}: 锂电池的正、负极片是锂电池的重要组成部分，极片涂布的质量很大程度上影响着电池的性能和使用寿命，而有缺陷的极片往往是电池安全隐患的根源。为了进一步提高锂电池极片涂布缺陷检测与识别的自动化性能水平，本工作提出了一套基于WOA-BPNN的锂电池极片涂布缺陷检测识别算法。首先，对采集到的锂电池极片涂布图像进行图像预处理操作；接着，将图像中的缺陷目标区域分割出来后，提取其形态、灰度、纹理特征；然后，搭建误差反向传播网络(back propagation neural network,BPNN)，并将串行融合后的融合特征向量作为网络的输入；最后，在训练神经网络分类模型的过程中，使用鲸鱼优化算法(whale optimization algorithm,WOA)用于辅助调参，以进一步提高模型的识别准确率。本工作算法可精确实现对划痕、漏金属、孔洞、裂纹、异污、脱碳等8种常见的锂电池极片涂布缺陷的检测与识别，实验结果证明，当检测的锂电池极片宽度为200 mm，检测精度为0.05 mm，检测速度为60 m/min时，本工作算法的平均漏检率为1.68%，平均误检率为0%，平均分类识别准确率为97.08%。本工作算法能够有效应用于高速高精度的锂电池极片涂布缺陷检测场合，在锂电池智能制造领域具有一定的实用价值。
{ISBN/ISSN}: 2095-4239
{Notes}: 10-1076/TK
{URL}: https://link.cnki.net/doi/10.19799/j.cnki.2095-4239.2022.0226
{DOI}: 10.19799/j.cnki.2095-4239.2022.0226
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 双目视觉下乒乓球的三维重建与轨迹预测研究
{Author}: 尹朵
{Tertiary Author}: 李外云
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 三维重建;轨迹预测;机器视觉;图像处理;目标识别
{Abstract}: 机器人技术由于其涵盖了多学科的内容,众多科研工作均以机器人为研究对象而展开。而乒乓球机器人作为机器人的一种,由于其涵盖了机器视觉、三维重建、轨迹预测、机器人智能控制、嵌入式等众多的核心技术,具有重要研究价值。本文从乒乓球机器人入手,重点研究了乒乓球的三维重建与轨迹预测过程。本文首先研究了高速双目立体视觉系统,为三维重建与轨迹预测算法的研究奠定了基础。(1)在三维重建过程中,通过忽略较小的切向畸变而构建的三维重建算法数学模型,避免了需迭代求解乒乓球三维世界坐标的复杂算法,在提高三维重建算法速度的同时,精度亦满足后续预测要求,重建算法平均误差在15mm内。(2)在轨迹预测中,针对传统UKF(Unscented Kalman Filter)算法预测旋转球轨迹误差会随时间延长而增大的问题,提出了基于SPM-UKF(Simple Physical Model-Unscented Kalman Filter)的乒乓球轨迹预测算法,该算法较好地修正了碰撞后的轨迹预测误差,相较于传统UKF算法碰撞后误差和减小了10mm左右。(3)根据前文提出的三维重建与轨迹预测算法,搭建了乒乓球机器人系统并完成击球实验,乒乓球击回成功率约为71%,验证了文章算法的有效性。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.001066
{DOI}: 10.27149/d.cnki.ghdsu.2022.001066
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 建筑业人工智能研究主题识别及演化分析
{Author}: 韩映雪
{Tertiary Author}: 仲景冰
{Publisher}: 华中科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 建筑业;人工智能;主题演化;LDA主题模型;前沿识别
{Abstract}: 随着近几年人工智能被国家列为产业融合发展和转型升级核心技术,建筑业作为国民支柱产业,利用人工智能作为推进数字化转型的关键技术,是推动建筑行业高质量发展的关键。跟随国家政策指引,国内外对人工智能相关研究数量也在飞速攀升,梳理国内建筑业人工智能研究主题,为前沿研究探明研究方向和路径,是推动建筑业人工智能快速发展重要保障。
本文通过对1985-2021年国内外建筑业人工智能相关研究文献进行梳理,将隐含狄利克雷分布(Latent Dirichlet Allocation,LDA)引入建筑业人工智能前沿分析研究中,挖掘出国内外主题构成。再引入时间变量,划分时间窗口,对主题强度和主题内容进行演化分析,之后综合主题强度和主题内容演化结果对国内外建筑业人工智能研究阶段进行划分,并对国内外主题研究进行对比分析。最后构建多维指标对国内建筑业人工智能主题进行前沿预测,并提出建筑业人工智能发展针对性政策建议。
研究得出国内建筑业人工智能行业发展首先需要加强人工智能底层技术的研究,构建技术人才培养和发展的长效机制。其次促进建筑业人工智能环境优化、数字技术、建筑空间优化等应用和底层技术的深度融合。此外还需推动建筑业人工智能从多个层面与国外开发合作,加强相关理论和关键技术的研究。最后需要持续关注计算机视觉、建筑灾害事故、建筑施工环境优化、建筑业全生命周期信息化和数据信息安全等当前热点主题研究,重点关注以机器学习等前沿趋势主题研究,稳步推进城市空间优化和建筑文化遗产保护正在探索的主题研究,逐步落实建筑三维可视化、行业数字化教育、虚拟现实技术等成熟区主题研究,使研究资源向相关领域倾斜,助力建筑业人工智能研究发展。
{URL}: https://link.cnki.net/doi/10.27157/d.cnki.ghzku.2022.005626
{DOI}: 10.27157/d.cnki.ghzku.2022.005626
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像语义分割方法研究
{Author}: 李鑫
{Tertiary Author}: 张红英;唐定勇
{Publisher}: 西南科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 语义分割;注意力机制;上下文信息;边界优化
{Abstract}: 图像语义分割旨在对图像内所有像素所属类别进行逐一密集预测,推断像素点语义信息和位置信息,完成像素分类任务,是计算机视觉场景理解中不可或缺的关键性技术。随着深度学习的兴起,基于卷积神经网络的图像语义分割成为更行之有效的方式。本文就当前基于深度学习的图像语义分割网络存在的模型分割精度低、图像类内区域误识别、小尺度目标遗失和边界模糊等问题,分别对网络的编码器和解码器部分进行设计,提升网络特征提取、特征融合和全局信息聚合能力,构建两种端到端图像语义分割网络,即融合注意力机制的图像语义分割网络与聚合上下文信息和边界优化的图像语义分割网络。主要研究工作如下:首先,综合国内外语义分割研究现状,深入研究深度学习和图像语义分割关键性技术,分析现有深度学习语义分割网络结构,总结编解码器语义分割网络通用架构和现存问题。其次,针对遮挡物体误识别和大尺度连续物体类内预测结果不一致问题,本文提出融合注意力机制的图像语义分割网络。该网络在特征提取时,设计注意力特征提取模块优化特征图关键性权重;在特征强化时,设计注意力空洞卷积金字塔模块缓解网络棋盘效应,强化特征图像素相关依赖性;在特征融合时,采用迭代注意力融合方式,对特征图进行权重软选择,解决线性聚合映射无法针对特定特征及特定对象和无法克服多尺度特征条件下语义信息不一致问题。实验结果表明,相较于Deeplab V3+网络,提出的融合注意力机制的图像语义分割网络预测结果在PASCAL VOC 2012数据集上MIo U提升2.2%,在Cityscapes数据集上的MIo U提升2.0%。最后,针对小尺度目标丢失和类别边界模糊问题,本文提出聚合上下文信息和边界优化的图像语义分割网络。在解码器中,设计上下文聚合模块对编码器输出特征图进行信息整合,丰富网络全局特征;并设计自适应上采样模块替换双线性插值上采样方式,提高上采样像素特征相似性。针对Re LU激活函数存在的激活死区问题,使用二维视觉激活函数提高非线性建模能力,增强小尺度目标语义信息;并设计类内预测边界分支对物体边界像素进行偏移映射,使预测结果图目标轮廓连贯、边界清晰。实验结果表明,相较于Deeplab V3+网络,本文提出的图像语义分割网络预测结果在PASCAL VOC 2012数据集上MIo U提升3.7%,在Cityscapes数据集上的MIo U提升3.4%,且相较目前先进的图像语义分割网络本文算法能够取得良好的语义分割结果。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2022.000117
{DOI}: 10.27415/d.cnki.gxngc.2022.000117
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度学习型车间巡检机器人目标检测算法研究
{Author}: 丁瑞敏
{Tertiary Author}: 田军委
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 车间巡检机器人;卷积神经网络;轻量化;目标检测;双目测距;ROS
{Abstract}: 随着人工智能与机器人技术的飞速发展,移动机器人目前已广泛应用于车间巡检任务。现有巡检机器人视觉系统多采用激光雷达结合多传感器的检测避障方式,但是成本高、结构设计复杂。以卷积神经网络为基础的深度学习检测方法以其低成本、高精度成为应用在巡检机器人视觉检测系统中的新方向,因深度学习目标检测方法对计算资源要求较高,为了更好的适应在小型计算设备的有限资源下部署,实现机器人的检测测距功能,所以需要解决算法的轻量化问题和障碍物测距问题,从而更好推进巡检机器人的实际应用。(1)改进YOLOv4轻量化目标检测算法。本文以YOLOv4深度学习目标检测算法为基础算法框架,建立轻量化目标检测算法Lightweight YOLO(LYOLO)检测算法。YOLOv4目标检测算法检测性能较好但是复杂的主干网络结构导致模型整体体积过大,难以在移动端或嵌入式端运行。本文通过模型轻量化来实现YOLOv4的改进:首先,通过将Mobile Net V3特征提取网络作为改进模型骨架,从而结构中的深度可分离卷积使得网络参数量大幅下降;其次,本文提出采用位置损失函数(CIo U)作为目标框坐标回归的损失函数,交叉熵函数作为网络分类的损失函数,Focal损失函数作为置信度得损失函数进行复杂样本的挖掘,对整体的损失函数进行优化,从而平衡样本数量分布不均带来的网络误检率,提高样本对复杂样本的检测能力;然后,本文制作了工厂车间环境目标数据集,对数据进行标注,并对数据进行高斯噪声处理,增强了网络的泛化性能及鲁棒性。最后,本文对Mobile Net V3模块部分进行预训练,提高最终模型的训练效果缩短训练时间。实验结果表明经过本文所提出的网络轻量化改进后LYOLO算法模型整体的网络参数量下降至44.74MB,根据混淆矩阵统计数据分布,LYOLO网络平均检测精度达到93.6%,整体参数量为YOLOv4的18%,实验室条件下,单张图片检测耗时为0.01s。同时,经实验随着Io U的增加,模型也仍然具有较高的平均检测精度,其得到的预测框与真实目标框的重合度更高,目标框定位也更准确,说明算法具有较强的泛化能力,算法整体的检测实时性、综合检测定位性能也获得了较大提升。(2)结合目标检测的双目测距方法。本文以轻量化机器人视觉检测方法为基础结合双目测距,获取目标物的距离信息,提供避障信息为巡检机器人重新规划可行路径。通过左右相机共拍摄多组室内目标图片,利用目标检测算法为左相机图片做检测,以左图片检测后的输出目标位置对左图像做裁剪,右相机中图片不做检测。文中主要进行了模板匹配实验,以裁剪后的图像为模板图像对右图像做匹配,获得左右两图中目标物的视差,以此计算得到目标物三维空间位置。本文中的目标检测测距方法直接采用检测方法获得初始模板图像,省去人工截取模板的工序,提高了效率。(3)巡检机器人视觉检测系统模拟仿真实验。本文采用ROS机器人开发平台搭建了巡检机器人的基础构架以及车间基础环境,模拟巡检机器人的实际工作状态。实现单点障碍与多点障碍中的目标物检测,以及检测到目标后的路径重新规划等虚拟仿真实验,验证了本文提出的目标检测和双目测距算法的有效性和可靠性,可以应用于车间巡检机器人的视觉导航。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2022.000483
{DOI}: 10.27391/d.cnki.gxagu.2022.000483
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习GAN网络的缺陷检测研究与实现
{Author}: 杨航
{Tertiary Author}: 蒋学芹
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 无监督学习;缺陷检测;生成对抗网络;自编码器;图像增强
{Abstract}: 在我国经济的高速发展下人民生活水平显著提高,促使了第二产业不断调整升级以满足日益膨胀的市场需求。同时,人们开始注重生活品质的提升,对于日常用品的质量也提出了更高标准的要求。由于第二产业在我国产业结构中占据十分重要的地位,在其日产量巨大的背景下,质量控制成为生产过程中不可或缺的一环,缺陷检测具有十分关键的实践意义。目前大部分企业采用的方式是人工目测,但这种方式存在检测效率低、精度失真、稳定性差、成本高昂等缺点。如何快速准确、节约成本地进行缺陷检测,成为众多企业和学者不断探讨研究的课题。伴随时代的不断进步和技术的深入发展,相较于传统的计算机视觉方法,基于深度学习的缺陷检测方法具有更优良的性能,更适合工业场景的普及和运用。但目前大多数都是有监督学习,即需要对数据进行标注使其有标签再加以训练,实际的生产环境中,缺陷样本数量往往较少,缺陷的种类大多是不可预见的,且人工标注成本较高、效率低下。针对以上问题,本文的主要工作以及创新如下:(1)本文提出了一种基于深度学习GAN网络和自编码器AE模型相融合的图像重构模型。该研究基于图像重构的思想,结合了生成对抗网络GAN和自编码器AE各自的优良特性。将模型相融合时设计合理的网络结构,同时调整损失函数的设计以及训练方法,以实现图像的修复。实验阶段采用真实工业零件数据集,通过设计相应定量评价指标,并与DCGAN网络和自编码器AE的对比实验证明本融合模型的图像重构能力表现得更加突出。(2)基于构建的融合图像重构模型,提出了一种无监督工业零件缺陷检测方法。该方法只需要对无缺陷正常样本进行训练,通过重构模块实现对缺陷样本的修复,通过缺陷检测模块对原始输入图像与修复图像进行图像增强操作,再构建残差图,设计符合工业零件缺陷判定的合理阈值,实现缺陷检测。通过对比实验可以证明,该缺陷检测方法具有较高的准确度,在减少数据标注的同时能适应样本存在的未知的缺陷。因此本研究具有较高的应用价值。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000342
{DOI}: 10.27012/d.cnki.gdhuu.2022.000342
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的铝型材表面缺陷检测技术研究
{Author}: 周博
{Tertiary Author}: 罗维平
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 铝型材;机器视觉;深度学习;缺陷检测
{Abstract}: 铝型材是我们日常生活中最常用的一种型材,广泛应用于航空、建筑、工业、家装门窗等领域,由于其需求量巨大,我国铝型材产销量逐年成递增趋势。在不同的应用领域,对于铝型材的质量要求也不尽相同,在铝型材的生产过程中,由于多种因素诸如机械摩擦、产品工艺、原材料等方面的影响,会导致生产出的铝型材存在不同类型及不同程度的缺陷。目前铝型材厂家对于铝型材产品的缺陷检测普遍采用人工检测的方式,但这种检测方式具有较大的局限性,且具有较强的主观性,无法形成统一的评判准则,无法适应现代化工业生产的要求。近年来,随着机器视觉及深度学习技术的快速发展,基于机器学习与深度学习的表面缺陷检测方法为铝型材产品自动化质检提供了一种新的思路。因此本文将机器视觉与深度学习相结合,提出了一种基于深度学习的铝型材表面缺陷检测系统。首先根据检测任务需求,设计了一种铝型材表面缺陷检测系统,系统主要包括光源模块、图像采集模块、传动模块及分拣模块四部分,实现铝型材表面图像信息的采集及对正常产品及缺陷产品的分拣;其次,在现有公开数据的基础上,构建铝型材表面缺陷检测模型所需数据集。对铝型材表面存在的缺陷类型及缺陷形状进行分析可得其表面缺陷类别主要包含擦花、碰伤、漏底等10类,缺陷具有尺度差异大、形状不规则等特点。根据铝型材表面所存在缺陷的特点,本文提出了一种基于Faster-RCNN的铝型材表面缺陷分类算法,为提升模型特征提取能力,在特征金字塔的基础上,提出一种频率加权噪声过滤金字塔,采用高低频特征加权及噪声抑制方法提升模型提取到特征的表征能力;采用形变卷积提升模型对于不规则特征的提取能力;提出一种多阶段训练方式,充分利用了模型自身所产生的对抗样本,提高了模型对于缺陷的分类精度,通过测试集验证,改进后的模型平均分类精度可达到97.93%,具有较好的缺陷分类效果。针对铝型材表面缺陷区域检测问题,本文提出一种改进级联结构的铝型材表面缺陷区域检测模型,在原始Faster-RCNN的基础上采用改进三级联结构的网络模型,并引入困难样本挖掘,提高了模型对于不同尺寸缺陷区域检测效果;提出一种随机多尺度缩放输入策略,提升了网络对于同一片区域的多缺陷检出效果,经过实验验证,模型整体m AP达到89.29%,检测效果良好。最后,采用QT软件编写铝型材表面缺陷检测系统终端上位机界面,将检测装置与检测算法集成化;通过上位机下发指令可控制检测装置传动,采用Open CV可对检测装置的摄像头进行调用。系统终端实现了图像采集、图像处理、图像检测、结果存储的一体化操作,降低了系统操作难度。经过实验验证,本文的研究达到了预期要求,提高了铝型材表面缺陷检测的自动化程度,满足实际工业生产部署、操作需求。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2022.000140
{DOI}: 10.27698/d.cnki.gwhxj.2022.000140
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的无人机目标检测算法轻量化研究
{Author}: 陈健
{Tertiary Author}: 饶红霞;庞志鹏
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;无人机;轻量化;卷积神经网络;机器视觉
{Abstract}: 伴随着人工智能技术的快速发展,机器视觉结合深度学习在工业领域的识别,检测等方面有了更为广阔的应用前景。在目标检测的任务之中,随着卷积神经网络的不断发展,目标检测的精确度也越来越高,代价就是网络模型也越来越大。卷积神经网络的目标检测精度虽然超过了传统的方法,但是在无人机这类小型嵌入式设备中,却无法同时满足实时性和准确性的要求。如何对卷积神经网络模型进行轻量化改进,这已经成为了新的研究热点。针对机载嵌入式设备运行基于深度学习的目标检测网络,保证其同时满足实时性和准确性的需求,本文的主要研究内容如下:首先,本文论述了无人机和深度学习的目标检测技术发展历程,介绍了深度学习的相关理论基础,分析了常用的卷积神经网络的轻量化策略,为后面的研究奠定了基础。随后,本文深入地研究了SSD目标检测网络。SSD网络可以在多特征尺度上预测不同尺度的目标,对小目标具有较好的检测效果,适合无人机在高空检测地面目标。在分析了SSD网络结构之后,本文在SSD网络模型的基础上进行轻量化改进,为了平衡网络模型的大小和性能,最终选取轻量级网络MobileNetV2替换SSD算法原本的VGG16网络进行深度特征学习。MobileNetV2的深度可分离卷积结构结合SSD网络能够有效地缩小网络模型的大小,然后在PASCAL VOC数据集上验证本文算法的效果,证明了本文算法在检测速度上大幅度地超过了SSD最初的网络模型。最后,本文分析了四旋翼无人机的模型,研究了相机成像原理并且利用张氏标定法对相机进行标定。然后结合机器人操作系统ROS、Gazebo物理仿真平台以及PX4软在环仿真,搭建了无人机的模拟仿真平台进行实验分析。实验实现了本文改进的基于深度学习的轻量级目标检测算法在无人机目标检测任务中的应用。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.002075
{DOI}: 10.27029/d.cnki.ggdgu.2022.002075
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的软包锂电池检测系统的研制
{Author}: 陈灏一
{Tertiary Author}: 陈新;王晗;朱自明
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;深度学习;锂电池;YOLO;缺陷检测;GhostNet;注意力机制
{Abstract}: 随着移动电子设备应用愈发广泛,锂电池凭借其容量大、体积小、密度低的优势,需求量与日俱增,锂电池的生产基本已实现自动化,但在生产过程中因各种因素导致锂电池壳表面会形成划痕、凹坑、凹痕、针眼、露铝等缺陷,这不仅有碍其外观,严重时还会影响锂电池的性能。在工业检测上,人工检测锂电池表面缺陷效果不好,既耗时又耗力。本文基于深度学习针对软包锂电池表面缺陷检测进行研究,并在目标检测算法YOLOv5s的基础上进行优化,进而提出新的网络结构,主要工作内容如下:(1)采集一定数量的软包锂电池表面缺陷图像,然后根据缺陷的几何特征、表现形式对锂电池表面缺陷进行分类。由于数据不足的问题,通过裁剪预处理和数据增强扩充了锂电池缺陷图像,应用数据标注软件Label Img对图像进行标注,最终获得软包锂电池表面缺陷图像的数据集。(2)为了选择最优的软包锂电池缺陷检测算法,分别基于Faster RCNN、YOLOv3、YOLOv5s三种目标检测算法对软包锂电池表面缺陷进行检测。实验结果表明三种算法中YOLOv5s的m AP为93.1%和YOLOv3相比基本持平,与Faster RCNN的m AP相比高了22.13%,同时YOLOv5s的FPS为92,YOLOv3的FPS为56,Faster RCNN的FPS为22,在保证精度的情况下,YOLOv5s的FPS远远高于YOLOv3,因此确定YOLOv5s为软包锂电池表面缺陷检测算法的主要研究对象。(3)首先研究了一种基于G-YOLOv5s的轻量级网络模型并应用于缺陷检测任务。实验证明,该模块在减少大量参数量和计算量的情况下,能够保持一定的检测精度,同时提高了算法的灵活性。但是为了进一步提升轻量化网络的检测精度,紧接着下一步提出GCA-YOLOv5s检测算法,实验结果表明,改进的GCA-YOLOv5s算法的m AP为93.1%,FPS为93,性能略高于YOLOv5s,其Precision和Recall分别为96.1%和87%,均高于YOLOv5s,其参数量仅为2479176,YOLOv5s的参数量为7260488,远小于YOLOv5s的参数量。该方法能够满足高精度、高时效性的实际生产质检要求,同时其网络模型的内存占用较小,更易于嵌入小型设备使用。(4)根据软包锂电池缺陷特征检测需求设计软硬件平台,首先选择合适的相机、光学镜头、光源、数字光源控制器等器件,搭建软包锂电池表面缺陷检测平台。然后对上位机软件进行设计,最后将GCA-YOLOv5s加载到系统中开发了软包锂电池表面缺陷检测系统,以直观展示锂电池表面缺陷检测的功能。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000197
{DOI}: 10.27029/d.cnki.ggdgu.2022.000197
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的PCB锡膏缺陷检测
{Author}: 郑子毅
{Tertiary Author}: 吕文阁;刘俊锋
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;深度学习;锡膏印刷;缺陷检测
{Abstract}: 锡膏缺陷检测是指生产线上锡膏印刷完成后,对印刷质量的检测。通过检测锡膏印刷缺陷,不仅可以及时返修不合格工件,降低损失,还能通过缺陷优化锡膏印刷参数,提升生产效率。本文立足实际生产项目中锡膏印刷的漏涂和多涂缺陷,基于机器视觉技术,使用图像处理和深度学习两种方法来实现对锡膏印刷的缺陷检测。本文的主要工作内容如下:针对锡膏印刷缺陷的特点和检测要求,结合生产现场环境的实际情况,对视觉系统硬件进行选型,选用了Basler的ac A2440-20gm工业相机、视清的MFA230-S25镜头和奥普特的RI9090-W环形光源,并使用以上器材来搭建锡膏检测硬件系统。由于单次拍摄图片中工件数量有六个,需要把工件提取出来进行统一处理,本文通过轮廓模板匹配把六个工件图像单独提取出来,排除背景的干扰,方便后续图像处理方法和深度学习方法的缺陷检测。为了进一步提高轮廓匹配的效率和精度,使用了图像金字塔分层搜索策略提高搜索速度和亚像素精度优化算法提高匹配精度。基于图像处理的锡膏缺陷检测方法中,先使用最大类间方差法来进行图像分割,把锡膏区域从工件背景中提取出来,转化为二值图,然后使用基于游程的二次扫描法对二值图进行连通区块标记。二次扫描法第一次扫描获得图像的游程信息,第二次扫描对游程进行连通区块标号,本文使用等价表的方法处理区块标号的冗余和冲突。标号完成后,计算各个连通区块的中心位置坐标、长宽、面积等参数,通过标定矩阵把像素单位转化为实际单位,再根据生产线上的工艺要求,对锡膏缺陷进行检测,该方法准确率为89%。基于深度学习的锡膏缺陷检测方法中,本文先制作了工件产品合格和不合格图像数据集,然后使用基于自注意力机制的Swin Transformer神经网络模型进行训练,对训练完成的模型进行测试,准确率为99.23%。由于深度学习方法比图像处理方法准确率高,因此使用深度学习方法作为最终方案。根据以上方法,本文在VS2022集成开发环境下,使用C++语言实现图像采集、相机标定、缺陷检测、文件管理和通讯等模块,完成锡膏缺陷检测软件系统。经实验测试,本文设计的检测系统能够准确可靠地检测出PCB锡膏的漏涂、多涂缺陷,有助于提高生产效率,提高生产线的自动化程度。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000446
{DOI}: 10.27029/d.cnki.ggdgu.2022.000446
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的茶叶嫩芽及其采摘点识别
{Author}: 赖小燚
{Tertiary Author}: 许高建;袁媛
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 神经网络;目标检测;图像分割;嫩芽识别;嫩芽分类;采摘点定位
{Abstract}: 机械智能采茶可以同时保证高效率和高芽叶完整率,实现机械智能采茶的关键是使计算机能够“认出”茶叶嫩芽和茶梗。本论文将基于目标检测算法和图像分割算法使用TB-Lai数据集分别建立茶叶嫩芽识别模型、茶叶嫩芽分类模型和茶梗识别模型。本论文的主要研究内容如下:(1)使用在VOC数据集上表现较好的Yolov4、Yolov5、Yolox、Efficient Det、Faster r-cnn和Center Net 6个算法建立茶叶嫩芽识别模型,实验结果表明,6个算法建立的茶叶嫩芽识别模型性能由高到低为Yolox、Yolov4、Efficient Det、Yolov5、Center Net、Faster r-cnn。TB-Lai数据集下Yolox的Precision、Recall、F1 score、m AP分别为89.34%、93.56%、0.91、95.47%。(2)使用经过彩色直方图均衡化处理的TB-Lai-Eq数据集用同样的6个算法建立茶叶嫩芽识别模型,通过和使用TB-Lai数据集建立的茶叶嫩芽识别模型对比之后发现使用彩色直方图均衡化处理茶叶嫩芽图像可以提升模型的精度。(3)使用在茶叶嫩芽识别上表现较优的Yolox和Yolov4算法结合TB-Lai数据集建立了茶叶嫩芽分类模型,通过分析实验结果发现两个算法建立的茶叶嫩芽分类模型均存在误分类的情况,这可能是由于某些品种的嫩芽颜色特征相似导致的,两个模型的m AP分别为79.19%和67.43%,Yolox识别茶叶嫩芽的性能优于Yolov4。(4)基于DeeplabV3+算法用TB-Lai建立嫩芽采摘点识别模型,通过实验结果发现嫩芽采摘点识别模型能够识别茶梗,这证明机械智能采茶是可行的。DeeplabV3+的mIoU、mPA、mPrecision和mRecall分别为78.43%、86.67%、85.89%、56.67%。本论文建立的茶叶嫩芽识别模型、分类模型和茶梗识别模型做到了对茶叶嫩芽的识别、分类以及采摘点识别,证明了机械智能采茶的可行性,为之后机械智能采茶应用于实际中提供了些许理论支持。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2022.000521
{DOI}: 10.26919/d.cnki.gannu.2022.000521
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于强化学习的机器人抓取方法研究
{Author}: 朱英茹
{Tertiary Author}: 史宝军
{Publisher}: 河北工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;抓取模型;DDPG;机器人抓取;实验研究
{Abstract}: 随着“中国制造2025”的推进,我国步入智能化时代,机器人逐渐走出工厂车间深入家庭服务、医疗服务、餐饮等行业,人们对机器人的需求也从单一重复抓取转变为自主决策的智能抓取。强化学习算法作为人工智能的一个分支,已成功应用于机器人控制中。但由于机器人操作模型较为复杂,环境动态多变,强化学习算法在机器人抓取应用中还存在许多问题。因此,本文针对强化学习算法训练时间长、收敛困难的问题提出改进措施,实现机器人由视觉感知到行为决策的控制过程,为机器人灵活作业奠定理论和研究基础,推动机器人智能抓取控制的发展。首先,针对强化学习以图像为输入,信息冗余导致学习效率低的问题,从目标物体的几何形状出发,建立空间抓取模型。针对标准构型物体,提出一种基于YOLO识别的Grab Cut算法自动分割方法。针对非标准构型物体,提出一种基于自适应阈值的Grab Cut算法自动分割方法。基于目标分割结果,利用图像的矩计算目标物体的中心位置和主方向,并根据抓取质量分数规划抓取框。结合深度图像获取物体的深度信息,完成空间抓取模型的建立。其次,根据机械臂的抓取任务要求和操作环境,设置机械臂控制系统的状态信息、动作信息、网络结构和奖励函数。针对深度确定性策略梯度算法(Deep Deterministic Policy Gradient,DDPG)训练时间长、采样效率低等问题,提出一种基于奖励值优先级的经验池采样策略。针对DDPG算法训练过程中,存在前期探索时间长,收敛速度慢的问题,提出一种基于自适应目标探索域的方法。在仿真环境中进行机械臂抓取训练,对比分析本文提出的算法与传统算法的效果。实验结果表明,本文提出的算法在收敛所需时间、收敛所需步数和收敛稳定性等方面均有所提升。最后,搭建机器人抓取系统的仿真实验平台和真实实验平台,完成机器人抓取实验研究。在仿真环境和真实环境中,对基于空间抓取模型的抓取方法进行实验研究,验证本文提出空间抓取模型的可行性。在仿真环境中对基于DDPG算法的机器人抓取进行训练,然后迁移至真实实验平台进行抓取实验研究,验证基于DDPG算法的机器人抓取方法的有效性。
{URL}: https://link.cnki.net/doi/10.27105/d.cnki.ghbgu.2022.000905
{DOI}: 10.27105/d.cnki.ghbgu.2022.000905
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像相似度检索的商品识别系统研究
{Author}: 张才裕
{Tertiary Author}: 陈绪君
{Publisher}: 华中师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 商品识别;商品检测;特征提取网络;相似度检索;自助结算
{Abstract}: 随着国民生活水平的不断提高,城乡居民的线下购物需求持续攀升。与此同时,传统零售业的各种弊端逐渐凸显,人工收银结算效率低、用人成本高昂、消费高峰时段结算体验差等问题尤为突出。近年来,以无人超市为代表的“新零售”开始走进民众生活。无人超市的技术难点之一是自助结算系统中的商品识别技术。寻求一种快速准确的结算方式已成为无人超市亟待解决的问题。目前基于计算机视觉技术实现的商品识别系统主要存在以下问题:1)随着商品类别数目的增加基于深度学习模型的分类准确率出现明显退化;2)算法泛化能力较弱,缺乏在线特征学习机制,不能识别未经训练的样本;3)新添商品类别困难,需重新制作样本进行模型训练;4)特征检索效率低,延迟较高,实时性难以保证。针对以上问题,本文提出了基于图像相似度检索的商品识别算法。本文分别从特征提取网络结构设计与特征检索算法优化两个方面提高商品识别准确率与特征检索效率。其次设计并实现了面向无人超市自助结算的商品识别系统。本文主要研究内容和工作成果如下:(1)实现了基于YOLOX模型的二分类商品检测算法。通过重构RPC数据集结算图标签构建商品检测数据集,并采用图像亮度、对比度调节等数据预处理算法对输入数据进行增强。最后在该数据集上对商品检测算法进行训练与推断,模型检测准确率为99.77%,召回率为99.83%,mAP为99.86%,在GPU上的推理速度达到66.67FPS。(2)优化了基于图像相似度检索的商品分类算法,算法包括特征提取与相似度检索两个步骤。商品图像由特征提取网络映射成特征向量输出,相似度检索算法对特征向量进行余弦相似度计算与排序获得商品识别结果。商品分类算法采用轻量级网络MobileNet-V2的骨干作为特征提取网络,并在构建的商品识别数据集上进行训练。为改进算法的识别精度,在保证其轻量化的前提下将CBAM注意力机制模块嵌入MobileNet-V2网络的BottleNeck中,并加入多尺度特征融合结构,提升了特征提取网络捕获区分性特征的能力。在商品识别数据集上进行实验测试,改进后的MobileNet-V2+CBAM+多尺度特征融合模型识别准确率达到99.51%,相较原模型提升了 1.46%。(3)针对特征检索效率低,延迟较高等问题,本文利用乘积量化对暴力检索算法进行优化,优化后的基于乘积量化的相似度检索算法在含100万个维度为448的向量库上检索耗时2.1ms,为暴力检索算法的1/66。在商品识别数据集上进行分类实验测试,基于乘积量化的相似度检索算法检索耗时为暴力检索算法的5.8%,准确率为99.12%,相较于暴力检索算法准确率损失0.39%。为了进一步减小检索算法的精度损失,本文对基于乘积量化的相似度检索算法进一步优化。针对乘积量化中聚类操作采用的K-Means聚类算法存在聚类效果受初始聚类中心选取影响较大的问题,本文将K-Means聚类算法替换成性能更优的K-Means++算法。改进后的相似度检索算法分类准确率为99.35%,在保证检索耗时不变的前提下,对比基于乘积量化的相似度检索算法提高了 0.23%。(4)设计并实现了基于图像相似度检索的商品识别系统。通过在系统中加入可在线更新的商品特征库,从而能够在无需重新训练网络的前提下实现对新商品的识别。系统主要功能包括自助结算、商品管理、库存管理、已售商品信息统计等。
{URL}: https://link.cnki.net/doi/10.27159/d.cnki.ghzsu.2022.000621
{DOI}: 10.27159/d.cnki.ghzsu.2022.000621
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的建筑固废智能分选研究
{Author}: 刘钢洋
{Tertiary Author}: 窦东阳
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;建筑固废;机器学习;深度学习;图像分类;目标检测
{Abstract}: 近年来,随着我国城镇化建设进程不断加快的同时,建筑固废的产量也在与日俱增,给社会和自然环境带来了巨大压力。然而建筑固废资源化利用领域大多依赖人工分选,导致分选效率低下,处理规模偏小,自动化程度不高。因此本文对建筑固废进行智能化分选研究,以建筑固废为研究对象,通过机器视觉技术代替人眼对建筑固废进行目标检测,通过深度学习技术代替人脑对建筑固废进行识别分类,通过脉冲气流喷枪代替人手对建筑固废进行分选,将机器视觉、机器学习和深度学习等技术方法综合应用于建筑固废的分选处理中,在完成对建筑固废类别信息和位置信息进行自动化获取的基础上,实现对建筑固废的智能化分选。本文主要进行了以下研究工作:(1)通过相机采集、图像分割、数据增强和数据标注等图像处理操作,制备了可用于图像分类和目标检测任务的五种建筑固废图像数据集。此外针对建筑固废图像皮带背景占比过大的问题,使用多种图像分割算法对数据集进行了批量分割实验,并使用形态学处理和统计学原理对相关算法进行了改进。最后通过多种分割性能评价指标确定了针对不同材质建筑固废的最佳批量分割算法。(2)对于建筑固废分类识别问题,首先基于特征提取和机器学习方法,设计并实现了一种建筑固废图像分类算法,并通过消融对比实验和性能评估分析得出了最佳算法设计流程,在对应测试集上达到了72.8%的分类准确率。另外基于深度学习方法,搭建并训练了多种卷积神经网络模型,其中VGGNet和Res Net模型在对应测试集上达到了99.0%的分类准确率。此外根据合并测试集上的性能评估指标选取Res Net模型作为建筑固废图像分类的基线模型,并使用迁移学习和训练超参数调整等优化策略对模型进行优化改进,使其在合并测试集上的分类准确率达到了91.9%,能够更加精确地实现建筑固废智能识别。(3)对于获取建筑固废位置信息的目标检测问题,一方面设计了基于背景建模法和Res Net优化模型的建筑固废目标检测算法;另一方面利用基于深度学习技术的SSD算法实现目标检测,并通过将原始算法中的VGG基础网络结构替换为Res Net结构、使用迁移学习等进行优化改进,使其对建筑固废进行目标检测的@0.5指标达到了0.985。最后通过多维度的目标检测性能对比,选择了改进的SSD算法实现建筑固废的目标检测。(4)完成了对建筑固废智能分选流程的设计,并根据相关需求进行了硬件选型和平台搭建,此外在实验室环境下对建筑固废进行了初步的分选实验,验证了建筑固废智能分选平台的有效性和实用性。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.001685
{DOI}: 10.27623/d.cnki.gzkyu.2022.001685
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的带式输送机异物实时检测与定位研究
{Author}: 孙旭
{Tertiary Author}: 程刚
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 带式输送机;异物检测;低光照图像增强;机器视觉;目标检测;双目相机定位
{Abstract}: 带式输送机是煤炭生产过程中最重要的运输设备,确保带式输送机正常运转是保证煤炭生产效率的关键。带式输送机较为常见的故障主要是跑偏、堆煤和纵向撕裂,跑偏和堆煤有较为成熟的检测方法,而纵向撕裂的检测方法不是很理想。近年来,多层卷积神经网络的应用越来越成熟,尤其是机器视觉领域结合卷积神经网络能够实现对物体的准确检测,而带式输送机的纵向撕裂主要是由于锚杆和大块矸石等异物划伤皮带而引起的,因此如何通过机器视觉的方法检测到皮带上的异物是防止皮带发生纵向撕裂的重要研究方向。本文利用机器视觉的算法针对带式输送机上异物的实时检测与定位进行了研究,构建了一套针对带式输送机上锚杆和矸石等异物实时检测与定位的系统,重点研究了数据集的低光照图像增强、异物实时检测和双目相机定位的算法,并将实时检测与定位算法结合,之后通过实验测试了低光照图像的增强效果、异物检测算法的实时检测效果和检测到异物后的双目相机定位效果,实验表明所采用的算法能够比较理想地实现低光照图像增强、异物实时检测和双目相机定位等功能,最终通过本系统完成了对带式输送机上锚杆和矸石等异物的实时检测与定位的任务。本文主要研究内容如下:1)研究了基于多层卷积神经网络的低光照图像增强算法并进行了实验测试:首先分析传统低光照图像增强算法的缺点引出基于多层卷积神经网络的低光照图像增强算法KinD++,并分析其网络,接着利用数据集对其进行训练,最后对所得到的模型在多种低光照环境中进行实验验证,并对比传统算法和其他深度学习的方法,实验表明KinD++算法能够较为理想地增强多种低光照环境下的图像,并且增强的图像色彩比较保真,能够恢复黑暗区域中物体的细节特征而不引入大量的噪声。2)研究了基于多层卷积神经网络的目标检测算法并进行了实验测试:首先分析了YOLOv4目标检测框架的网络组成,然后针对半掩埋在煤中的锚杆和矸石,提出采用网格掩膜GridMask方法对训练图片中的异物进行部分遮挡,从而扩展数据集,并利用K-means++算法聚类数据集的九种锚定框宽高值,最后对训练得到的模型在测试集上进行精度测试并在运行的带式输送机上进行实时检测异物,实验表明通过网格掩膜的优化能够提高模型对于半掩埋物体的识别精度,模型也能够准确而快速地检测出运行的皮带机上的锚杆和矸石。3)研究了双目相机的定位算法并进行了实验测试:首先构建了相机的成像模型,得到了世界坐标系中的点和像素坐标系中的点的转换矩阵,然后利用张正友标定法对双目相机的内外参数进行了标定,得到转换矩阵中未知的参数值,接着利用SGBM立体匹配算法匹配左右相机的图像获得视差图,利用公式得到视差图中像素点对应的世界坐标系中的三维坐标,将YOLOv4检测到的异物边界框的中心像素坐标送入测距算法最终得到异物距离相机的距离,最后对双目相机的定位算法进行精度测试,实验表明双目相机能够以较高精度完成测距任务。4)设计并搭建带式输送机异物实时检测与定位实验台:首先搭建实验台的硬件系统,然后编写实验台的界面完成双目相机的实时监控、异物检测与定位、自动截取检测到异物的图片并保存、检测到异物发出警报等功能。该论文共有图97幅,表7个,参考文献115篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000237
{DOI}: 10.27623/d.cnki.gzkyu.2022.000237
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的激光焊缝跟踪系统研究
{Author}: 李奉顺
{Tertiary Author}: 张建红
{Publisher}: 南京林业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 焊缝跟踪;深度学习;结构光;卷积神经网络;机器视觉
{Abstract}: 焊接作为工业生产领域中的重要加工技术,被广泛应用于航天、船舶与车辆制造等领域中,提高焊接技术水平对我国从工业大国向工业强国转变具有重要意义。基于工业机器人的自动化焊接技术极大的提高了焊接生产效率,改善了工人的工作环境,但目前机器人焊接仍存在焊接轨迹固定,无法自适应调整焊接轨迹的问题。因此,本文构建了一种基于机器视觉的激光焊缝跟踪系统,利用深度学习与结构光传感技术在工业机器人上实现了焊缝跟踪功能。本文的主要研究内容如下:(1)对焊缝跟踪系统相关研究现状进行归纳总结,构建了基于主控机、六轴工业机器人、焊缝跟踪模块、激光器与送丝机的硬件平台。(2)研究了焊缝特征条纹提取算法,提出一种基于轻量化UNet的V型焊缝特征条纹提取方法。为解决标准卷积神经网络参数量大,实时语义分割网络分割精度不足的问题,引入了深度可分离卷积技术与通道注意力机制对UNet进行轻量化改进。实验结果表明,轻量化UNet在低算力平台上对640×640×3焊缝图像的分割速度可达到84.2fps,MIOU为0.94,相较于ERFNet、DFANet与原UNet具有更高的分割精度、更快的分割速度以及更小的体积。最后,结合动态灰度重心法与最小二乘法实现了对焊缝特征点像素坐标的提取。(3)构建了基于结构光的视觉传感系统,分析了针孔相机的内参模型,结合结构光平面方程建立了像素坐标系与相机坐标系的映射关系。进一步的,通过构建Eye＿in＿hand手眼模型,获得了相机坐标系与机器人工具坐标系变换矩阵。为计算相机内外参数、结构光平面方程与手眼矩阵,设计了传感标定实验,其中相机内外参数与结构光平面方程通过张氏棋盘格标定法计算得到,手眼矩阵通过Tsai两步法求解AX=XB方程获得。实验结果表明,基于手眼矩阵、结构光平面方程、相机内参矩阵与机器人位姿矩阵的视觉传感系统在机器人XYZ轴的平均绝对误差分别为0.35mm、0.2mm、0.57mm。(4)设计了基于MFC框架的焊缝跟踪系统软件平台,该平台集成了Python库、工业相机库与机器人运动控制库,可对跟踪系统进行整体控制。为实现实时焊缝跟踪,对激光三角法跟踪模型与线结构光传感模型的特点进行了分析,采用一种基于PID算法的跟踪补偿方法,实验结果表明,基于深度学习与线结构光传感的焊缝跟踪系统焊接质量良好,系统实时性较高,可以满足V型焊缝焊接需求。
{URL}: https://link.cnki.net/doi/10.27242/d.cnki.gnjlu.2022.000034
{DOI}: 10.27242/d.cnki.gnjlu.2022.000034
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的芯片缺陷检测方法研究
{Author}: 李亚航
{Tertiary Author}: 王书海;孙祎
{Publisher}: 河北科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 芯片缺陷检测;计算机视觉;R3Det;ResNet18;图像处理;YOLOv3
{Abstract}: 半导体芯片的制造工艺复杂且工序繁多,在生产制造的各个环节中都可能会出现缺陷。目前传统的人工缺陷检测效率低、费时费力,因此如何对半导体芯片的缺陷进行有效识别检测,提高检测效率已成为当前制造业的研究热点之一。本文采用计算机视觉的方法分别对半导体芯片的内部空洞缺陷和表面缺陷进行了检测。在内部空洞缺陷检测中,针对X射线获取的芯片内部图像存在背景因素干扰、空洞缺陷占比小和对比度低的问题,提出了一种先提取空洞缺陷所在的中心目标区域,再对中心目标区域进行空洞缺陷检测的方法。首先对中心目标区域进行提取,针对芯片中心目标区域可能发生旋转的情况,选用能够检测旋转目标的R3Det网络模型。该模型可准确计算芯片中心目标区域的边界框,去除多余背景信息带来的干扰。使用ResNet18网络模型对三种芯片进行分类,为接下来阈值分割提供依据。然后对提取出来的中心目标区域进行去噪和指数变换等图像处理操作,增强空洞缺陷的对比度,为后续空洞缺陷分割奠定基础。最后在阈值分割过程中,依据不同芯片类型设定不同阈值进行空洞缺陷分割。该方法有效实现了三种不同类型芯片内部空洞缺陷的检测,一定程度上减少了背景影响和模型的重新设计。在表面缺陷检测中,为了减少预处理和人为因素的影响,采用深度学习的方法,利用YOLOv3网络模型对芯片的表面缺陷进行检测。为提升对芯片表面缺陷的检测精度,在YOLOv3网络结构中加入注意力模块来提高模型选择表面缺陷目标关键信息的能力;同时加入空间金字塔模块利用同一卷积层的不同尺度特征获得更多的信息。实验结果表明改进后的YOLOv3网络缺陷检测精度提高了1.58%。
{URL}: https://link.cnki.net/doi/10.27107/d.cnki.ghbku.2022.000260
{DOI}: 10.27107/d.cnki.ghbku.2022.000260
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的老人跌倒检测系统研究
{Author}: 龚婷婷
{Tertiary Author}: 刘士兴
{Publisher}: 合肥工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视频监控;计算机视觉;运动目标检测;多特征分析;支持向量机
{Abstract}: 随着社会的快速发展,老龄人口人数的不断增加,同时因子女忙于生计而无法陪伴老人,大多数老人只能独居生活,意外跌倒已经成为威胁老人健康的几大危害之一。为了减少老人意外跌倒后没能及时医治所带来的危害,现代家庭对跌倒检测系统有着迫切的需求。随着监控摄像头和计算机视觉的快速发展,利用监控摄像头结合计算机视觉的跌倒检测方法具有智能、便捷以及可靠等优势,它已成为检测跌倒行为的有效方法。因此,本文将结合计算机视觉相关知识,对老人跌倒检测算法进行研究。首先介绍本文系统整体框架和跌倒检测实现流程。其次,通过分析三种常用的运动目标检测方法和几种背景建模算法的各自特点,针对检测系统应用于室内环境的特点,提出一种基于混合高斯模型背景建模的背景差分法提取运动目标,并对检测到的运动区域做二值化处理和形态学腐蚀处理,突出强化运动区域,以得到更为精准的人体目标。然后,为提取有效的跌倒特征保障跌倒检测的准确性,在分析了跌倒行为特征和日常行为特征的基础上,本文提出了采用人体特征与运动特征相结合的特征提取方案,并分别对各特征进行定义与提取,分析了选择的各个特征作为本文跌倒检测系统的特征的可行性。最后,利用滑动窗口法做初步的排除,以减轻SVM分类器的计算量,并利用滑动窗口法对时间序列的人体目标的有关特征进行提取并相融合构建特征向量,导入SVM分类器中,进行分类判断是否属于跌倒行为。为验证本文跌倒检测方法在真实环境下的可靠性,利用外接摄像头采集跌倒、下蹲、行走等行为视频进行实验,实验结果表明,本文跌倒检测方法对跌倒行为的识别率可达90%以上,在真实环境中具有一定的可行性。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000345
{DOI}: 10.27101/d.cnki.ghfgu.2022.000345
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的SAR图像舰船目标检测
{Author}: 陈冬
{Tertiary Author}: 句彦伟
{Publisher}: 中国电子科技集团公司电子科学研究院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 合成孔径雷达;舰船检测;深度学习;卷积神经网络;计算机视觉;轻量化设计
{Abstract}: 计算机视觉(Computer Vision,简称CV)领域的快速发展,促进了合成孔径雷达(Synthetic Aperture Radar,简称SAR)图像的智能化解译进程。而其中的深度学习方法(Deep Learning,简称DL)由于自身充分挖掘数据的先验信息能力而被广泛运用。当前很多深度学习的方法运用于SAR图像舰船目标检测任务中且均能取得不错的效果,但其中缺乏了很多关于深度学习的方法与SAR图像本身特点的结合,使得检测效果有待于进一步提升。针对SAR图像检测任务而言,舰船尺度差异大、小舰船目标居多、相干斑噪声与背景干扰严重等问题使得直接迁移使用深度学习检测方法还有待改进。此外,关于深度学习本身检测方法是否适合于SAR目标检测,涉及到的模型泛化能力、模型解码复杂性等具体问题,同样使其直接运用于SAR目标检测存在可实现的考量。本文针对这两方面存在的问题进行了详细探讨与验证,主要完成内容如下:(1)针对深度学习的检测方法运用于SAR图像舰船目标检测多存在的虚警和漏检等问题进行了改进。以YOLOv3(You Only Look Once v3)模型结构为基础,以重新聚类的锚框为基准,采用多尺度解码结构,融合可变形卷积的思想等,本文获得了一个性能提升的增强型YOLOv3模型,适用于多尺度舰船目标、小舰船目标检测等问题,在不同SAR检测数据集上均获得了比较好的效果。(2)针对深度学习的检测方法运用于SAR图像中泛化能力以及实际运用可行性的考虑。卷积神经网络(Convolutional Neural Network,简称CNN)具有很强的语义信息表达能力,而SAR图像舰船检测涉及到的定位问题反而弱化了语义表达。因此,本文提出了通过全卷积神经网络(Fully Convolutional Network,简称FCN)来实现SAR图像舰船检测分割一体化的方法,在获得检测结果的同时能够获得更加精细化的分割结果,且模型泛化能力极强,适用于其他未见过的SAR舰船检测数据集中。(3)针对实际运用可行性问题的探讨。从轻量化以及泛化能力两方面入手,本文在上述基础上提出了一个轻量化检测与分割一体化模型,该模型效果超过了当前优秀的单阶段检测算法YOLOv4,而模型大小仅为8.4M,是YOLOv4的1/30。
{URL}: https://link.cnki.net/doi/10.27728/d.cnki.gdzkx.2022.000147
{DOI}: 10.27728/d.cnki.gdzkx.2022.000147
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的风力机叶片损伤检测系统
{Author}: 王一博;韩巧丽;张曦文;吴成龙;杨敏
{Author Address}: 内蒙古农业大学机电工程学院;内蒙古农业大学能源与交通工程学院;
{Journal}: 科学技术与工程
{Year}: 2022
{Volume}: 22
{Issue}: 12
{Pages}: 4879-4886
{Keywords}: 风力机叶片;机器视觉;图像识别系统;损伤检测;LabVIEW
{Abstract}: 针对风力机叶片表面出现的磨损等早期损伤特征现象，传统损伤检测方法存在高成本低效率等问题，设计了一种基于机器视觉和图像处理相结合的风力机叶片损伤检测系统。通过搭建机器视觉实验平台完成风力机损伤叶片图像采集和处理，通过使用HSV进行颜色平面提取，卷积运算、高亮显示操作滤波，选用自动阈值分割方法中最小均匀性度量法进行阈值分割处理，最后通过数学形态学去噪处理，腐蚀、膨胀、开运算等操作完成特征提取，设计了基于LabVIEW的风力机叶片智能图像识别系统，通过对图像处理后的损伤特征识别效果调试，完成性能测试。实验结果表明：基于该算法处理后的图像在设计的识别系统内准确识别率达到92.3%,并对裂纹损伤进行目标测量得到实际长度且绝对误差最大为3 mm。该系统满足叶片检损的要求，实现对风力机叶片表面裂纹、轮廓磨损等损伤的图像处理和识别，并对损伤处进行标记、计数和测量，实现无损探伤，为兆瓦级风力机叶片损伤检测提供方法借鉴和图像处理、系统设计的技术支持。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvznPSXLdCi2GPWL-SLDARRLJKRep0wfG-XipK_nyuV814i2FRBioWED5ag7dFzXJo5rSJMHaYsK9gTt_zany8Qgfz_WFFS3Jd_R7HsaUN3WIQdWsyGiQjrlVWMrCt4_Sd2fYawDWn0aqU2x0Dxpr12C22tadQzJ549CXHcPbPHY2eNn5qmVSVZSXImhByCwF8o=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的乳腺超声图像检测
{Author}: 马志杨
{Tertiary Author}: 郑文锋
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;Faster RCNN;ViT;Transformer;区域建议网络
{Abstract}: 根据世界卫生组织的调查显示,乳腺癌已经成为威胁女性健康的很大隐患。医疗诊断乳腺超声图像过程中,医生的医疗经验对于诊断结果有着较为重大的影响。此外,数量庞大的医学影像图片对于医生是巨大的工作量。本研究课题针对乳腺部位的超声图像,将基于深度学习的目标检测技术应用到乳腺超声图像中病灶区域的类别判定和位置定位中。本研究课题不仅能够辅助提高医疗诊断过程中的准确率,同时也大大减轻了医生的负担。目前基于深度学习的目标检测算法主要分为一阶段算法,如YOLO,和两阶段算法,如Faster RCNN。原本用于自然语言处理的Transformer模型被证实在计算机视觉领域用于目标检测时也能取得较好的表现,如DETR模型。本文的研究基于两阶段的目标检测算法Faster RCNN对乳腺超声图像中的病灶进行检测,主要内容如下:第一,提出ViT-Patch病灶分块判别模型,对乳腺超声图像划分出的各块是否包含病灶做出判定。研究中增大原本ViT算法中划分出的乳腺超声图像块的尺寸大小,减少划分出的图像块的数量。各个图像块经过多头注意力机制处理后的输出结合Class Token的信息被单独连接到分类头以完成分类任务。研究中尝试了不同大小的图像块尺寸,并设置了与残差网络的对照实验。研究结果表明ViT模型的输出中不仅新增的Class Token信息可用来整幅图像的分类,其他图像块的输出也可以利用起来实现对于划分出的各块乳腺超声图像的分类并能取得较为理想的实验效果。第二,提出Trans-Faster目标检测模型。基于卷积神经网络模型提取的特征具有归纳偏置的优点。基于Transformer的网络模型提取的特征能够建立起图像不同部分间的空间联系。研究中乳腺超声图像并行地输入到ViT-Patch模型与两阶段目标检测算法Faster RCNN的特征提取模块,然后将两者输出的特征图融合。研究结果表明融合后得到的特征图用于病灶区域的检测时能够实现更好的检测效果。第三,提出Trans-Faster-Patch目标检测模型。将ViT-Patch模型输出的病灶分块分类的结果,与Faster RCNN的区域建议网络中判定锚框区域内部是前景还是背景区域的过程相结合,从而辅助区域建议网络模块生成位置更加精确的建议区域。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.001108
{DOI}: 10.27005/d.cnki.gdzku.2022.001108
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的机械臂抓取位姿估计算法研究
{Author}: 戈婉怡
{Tertiary Author}: 荆树旭
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;深度学习;目标识别;位姿估计;点云配准;直线提取
{Abstract}: 机器人在位置固定,作业对象位姿也确定的情况下,可在装配流水线上非常稳定、可靠地工作。但在机器人位置不固定且作业对象位姿未知的情况下,机器人需要获取作业对象位姿,以及机器人与作业对象之间的相对位置关系才可以实现目标物的抓取。针对以上问题,本文结合深度学习和机器视觉技术对机械臂抓取位姿估计算法展开研究,设计机械臂抓取目标物位姿估计方法,本文的相关工作如下:1.目标识别定位方法。为削弱周围环境对提取抓取目标物特征的干扰,降低场景复杂度,基于深度学习算法设计目标识别定位方法,对抓取物进行识别定位。目标识别定位方法利用自制标注数据集并结合COCO数据集的网络模型对神经网络进行迁移学习训练,在获得目标物位置的同时,提高网络识别精度。目标识别定位方法的基础卷积神经网络为实例分割网络--Mask R-CNN网络。为提高Mask R-CNN网络的识别速度和精度,在对其主干网络结构进行分析后,选用网络层数较少的Res Net50网络为主干网络对图像进行特征提取。为进一步提高网络识别速度,选用轻型高效、计算量小的Mobile Net网络替换原主干网络Res Net50,对Mask R-CNN网络进行改进。目标识别定位方法最终输出的抓取物分割图作为目标位姿估计方法的输入。2.目标位姿估计方法。设计基于线特征的双目数据源目标位姿估计方法,获取抓取物位姿信息。首先对双目相机进行相机标定,获得误差较小的相机内外参数。接着采用结合Canny边缘检测的Hough线变换提取分割图中线特征。针对提取线段重复、间断问题,设计线段合并算法得到完整度较高的线段;针对合并后线段间交点少的问题,设计端点重构算法得到目标物轮廓线段。然后设计二维线段匹配算法对左、右图像的目标物轮廓线段进行匹配,得到左、右图像线段匹配对,依据双目视觉原理获得三维轮廓线段,并将其离散化为抓取物轮廓点云。最后利用SAC-IA粗配准与ICP精配准对抓取物轮廓点云与模板点云进行配准,获得抓取物位姿信息,提高位姿估计精度。通过实验验证,本文设计的机械臂抓取目标物位姿估计方法不仅能提高识别定位的速度和精度,还能获得精度较高的位姿信息,说明本文设计的机械臂抓取目标物位姿估计方法具有高效性和鲁棒性。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2022.000349
{DOI}: 10.26976/d.cnki.gchau.2022.000349
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的疲劳驾驶检测研究
{Author}: 蔡闯闯
{Tertiary Author}: 刘庆华
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 疲劳驾驶检测;AdaBoost;ERT;混合型核函数;SVM
{Abstract}: 近几年,随着国内GDP总值的不断提高,人们的经济收入水平得到了显著的提升,人们对车辆的购买力度也随之提升。但是在车辆走入人们的日常生活中的同时也带来了一个重大安全隐患,那就是道路交通事故频发,国内因为道路交通事故而伤亡的人数每年都在持续的攀升,这给国家造成重大经济损失的同时也时刻威胁着人民的生命安全。通过观察大数据的统计,我们可以从中发现,造成交通事故频频发生的一个重要因素就在于驾驶员出现疲劳驾驶现象,而这一现象是可以通过一些车载设备进行控制的。因此倘若能够研发出一种疲劳预警系统,这对避免疲劳驾驶而导致的交通事故具有非常重大的意义。本文将基于机器视觉处理来对疲劳驾驶进行检测研究,通过对人脸检测、人脸特征点定位、疲劳特征的提取与疲劳判断等进行深入的研究,并在此理论基础上实现了对驾驶员实时检测的疲劳判定系统的构建,实验表明该系统能够准确的检测出驾驶员的疲劳,并及时的发出预警信息。主要工作如下:(1)针对疲劳驾驶检测在时效方面的要求,本文开展了基于图像预处理技术的研究。通过对检测到的视频图像进行预先的处理来降低后续图像处理的计算量,以此来降低疲劳检测的耗时。实验表明在经过图像预处理后大大减少了疲劳检测的耗时。(2)针对疲劳驾驶检测对人脸检测及特征点定位方面的准确率和时效性方面的要求,本文开展了人脸检测及特征点定位算法的研究。通过对比诸多方法,本文采用了基于Ada Boost算法来对人脸进行检测,基于ERT算法实现对人脸特征点的定位。实验表明在经过两种算法的处理下的疲劳驾驶检测在准确率及实时性方面都有了提升。(3)针对疲劳驾驶检测对最终的疲劳判定方面的准确率的要求,本文一方面开展了融合驾驶员面部多个疲劳特征的研究,另一方面开展了基于改进型的支持向量机(support vector machines,SVM)的疲劳判定算法的研究。通过对K型核函数和logistic型核函数组合来得到新的核函数,然后利用基于新的核函数的SVM方法来对输入的多个疲劳特征进行训练,最终进行疲劳检测。实验表明在融合了多个疲劳特征后在通过基于新型的SVM方法来对疲劳驾驶进行检测有着较高的准确度。(4)最终完成对疲劳驾驶检测系统平台的搭建。疲劳驾驶检测系统中包含了驾驶员的各项信息,在经过对该系统平台的实际测试中表明,该检测系统能够对驾驶员的驾驶状态做出实时的、准确的判断,一旦驾驶员产生疲劳现象,该系统平台就会立即发出警示信息。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2022.000226
{DOI}: 10.27171/d.cnki.ghdcc.2022.000226
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于K-means聚类的计算机视觉下杨梅水果图像识别
{Author}: 卢巍
{Author Address}: 昆明文理学院信息工程学院;
{Journal}: 现代计算机
{Year}: 2022
{Volume}: 28
{Issue}: 08
{Pages}: 78-81
{Keywords}: K-means聚类;计算机视觉;图像处理
{Abstract}: 聚类分析是划分数据的一种有用方法，它将数据划分成有用的组。其运用范围非常广泛，在统计学、模式识别、信息检索和数据挖掘等领域得到广泛的运用。本文将K-means聚类运用到杨梅水果照片转换的数据中，尝试运用其对生成数据进行聚类，用以在统计学上对杨梅进行颜色和果实的识别。经过理论和数据实验验证，K-means聚类能够从数据层面上区分果实和背景，为进一步研究当地环境下杨梅果实的机器视觉识别打下基础。
{ISBN/ISSN}: 1007-1423
{Notes}: 44-1415/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxPSwEKWVvUAlyDNUmdOAhpzJ1jyfUHawu140iXD1CknZpOeyUL3GOy2klpN7U_YmDhLmN7MvvSp-lN29Z6pVFgrzy_mSZpwJ-BUeSRhcU9WGwKvaz_pcF7v9OWtmmFTmR5ULWZGaB04iM2PdFgojCDyJWfWBgCBYy38qSd5INKvBrMBodzBIqpM2MGi8U3jJk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的牛反刍行为识别与分析
{Author}: 王月明;陈甜甜
{Author Address}: 内蒙古科技大学信息工程学院;
{Journal}: 中国畜牧杂志
{Year}: 2022
{Volume}: 58
{Issue}: 09
{Pages}: 203-208
{Keywords}: 计算机视觉;YOLOv4;核相关滤波算法;帧间差分法;反刍
{Abstract}: 本试验旨在利用计算机视觉技术实现自动识别牛的反刍行为，并计算反刍时间与咀嚼次数，为牛的健康监控提供参考。在包头市养殖场中采集了7头牛共388 s的视频，人工统计牛反刍的时长为310 s，非反刍行为78 s。利用YOLO(You Only Look Once)目标检测算法和核相关滤波算法（Kernelized Correlation Filter,KCF）跟踪牛的头部，用帧间差分法获取反刍参数，判断牛是否在反刍，通过帧数与帧率的关系计算反刍时间，通过下颚反刍参数变化曲线规律计算反刍的咀嚼次数。试验对比了此算法与人工计数的结果进行反刍识别准确率验证，结果显示，反刍时间的平均误差为4.193%，反刍的咀嚼次数平均误差为4.929%，说明可以用计算机视觉自动识别牛的反刍行为。
{ISBN/ISSN}: 0258-7033
{Notes}: 11-2083/S
{URL}: https://link.cnki.net/doi/10.19556/j.0258-7033.20210825-01
{DOI}: 10.19556/j.0258-7033.20210825-01
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向消化道内镜智能诊断的图像理解多任务模型研究与实践
{Author}: 余涛
{Tertiary Author}: 段会龙;汪小知
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 消化道内窥镜检查;计算机辅助诊断;多任务学习;图像理解;卷积神经网络
{Abstract}: 消化道内窥镜检查是目前筛查胃肠道疾病首选的标准检查方法,检查医生手持细长软管状设备经人体腔道进入并缓慢推送至器官目标区域,并通过光学镜头和图像传感器等装置对器官内部表面进行实时成像,由此依据临床知识和经验对视频图像中消化道黏膜健康状况进行诊断。为辅助临床医生实现对消化道癌症相关病灶的早筛早诊,缓解漏诊误诊情况的发生,研究人员通过开发以图像理解技术为核心的计算机辅助检测和诊断系统,实时帮助临床医生定位病灶和评估风险,辅助提升临床病灶检出能力,规范检查操作流程。目前,以深度学习算法为核心的医学图像理解技术发展迅速,在图像和视频的分类、检测、追踪、分割、配准、生成等任务中表现卓越,在部分病灶识别任务和数据上获得了与临床专家相当的诊断精度。然而,在基于深度学习的消化内镜智能诊断方法的研究和应用部署领域,现有的工作多集中在少数单任务模型的孤立研究上,难以满足复杂的真实临床检查环境对全功能智能辅助诊断的广泛需求,尤其随着孤立任务数量持续增长,临床检查所必须的实时性要求难以得到满足,阻碍了智能辅助诊断在消化道内镜检查领域的推广应用。本文拟采用多任务学习模式,对面向消化道内窥镜智能诊断的端到端图像理解多任务模型进行研究,基于多个临床数据集进行模型的训练和部署,实现多任务推断能力在时间性能和诊断效能上的提升。通过对深度学习的消化道内镜智能诊断中存在的问题与局限进行理论和方法上的研究,本文提出了多任务学习模式下内容和时序解耦合方法以及基于任务相关分析的多任务集成模型设计方案,并对所构建实时消化内镜辅助检测和诊断系统进行了临床实践和验证。具体而言,本文的主要研究内容包括:1)内容解耦合模型方法研究针对单任务模型训练过程中,由于对应任务的特征表示较弱以致模型所关注的特征耦合到别的无关特征上,引起模型可靠性降低的内容耦合问题,本文提出了一种缓解内容耦合问题的模型训练方法。该方法基于耦合任务无关的先验知识,通过在模型训练过程中采用局部拼图法对数据进行增强,并基于类别激活图引入新的损失函数用以提升模型特征的表达准确性,实现了无关任务的内容解耦合,确保了后续进行多任务相关性分析时对应任务关联关系的准确性。以消化道内镜场景下胃癌前病变识别模型为例,本文的内容解耦合模型方法有效克服了癌前病变的识别特征耦合到解剖位置的识别特征上的问题,在癌前病变识别上模型的准确率提高了1.20%和0.84%,同时在可视化类别激活图上模型特征一致性得到了大幅提升。2)时序解耦合模型方法研究针对基于单任务孤立模型的多任务学习中,多个任务在计算流程存在时序上的串行关系,导致系统计算冗余、实时性降低的时序耦合问题,本文提出了一种缓解时序耦合问题的模型构建与训练方法。该方法基于时序耦合任务相关的先验知识,通过对模型结构进行融合调整,并提出改进的三元组度量学习方法用以提升任务特征的特异性,实现了相关任务的时序去耦合,提升了模型的时间性能并确保了后续多任务集成模型并行输出的可行性。以消化道内镜场景下肠镜息肉目标检测与目标追踪任务为例,本文通过对目标检测任务与目标追踪任务进行时序上解耦合,实现在不损失模型检测和追踪精度的情况下模型推理速度提升30%。3)基于任务相关性分析的多任务集成模型方法研究为解决少数单任务模型的孤立研究难以满足复杂的真实临床检查环境下全功能智能辅助诊断的问题,本文综合上述内容和时序解耦合方法,通过对深度学习模型中表征相似性的研究,提出了一种基于任务相关性分析的多任务集成模型方法,该方法基于不同任务的单模型,从模型不同层面量化提取表征多个任务之间相关性的RSA相关系数矩阵,并以该任务相关性为指导,设计和构建逐层递进的端到端多任务集成模型,从而充分实现任务之间的特征共享和信息传递,提升模型的推断性能和时间性能。基于这种方法,本文实现了包含九项任务的面向消化道内镜智能诊断的多任务集成模型,相比多个单任务模型的常规组合模式,模型总体体积减小42%,实时推断速度提升1倍,各项任务的模型准确度上保持了相当的性能甚至略有超越。4)基于任务相关多任务集成模型的辅助检测与诊断系统设计与实践基于上述多任务集成模型的研究成果,本文研发了一套消化道内镜视频辅助检测与诊断系统,并在真实的消化道内镜检查视频数据上进行了评估验证。实验结果表明,该系统达到了临床对多功能智能辅助诊断的实时性要求,并且在病灶检出率和实时性等模型性能上都得到了提升。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001963
{DOI}: 10.27461/d.cnki.gzjdx.2022.001963
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的手机石墨散热片缺陷检测
{Author}: 荀康迪;李兴成;刘凯磊;周豪;梁栋
{Author Address}: 江苏理工学院机械工程学院;
{Journal}: 陕西理工大学学报(自然科学版)
{Year}: 2022
{Volume}: 38
{Issue}: 02
{Pages}: 15-21
{Keywords}: 石墨散热片;机器视觉;图像去噪;缺陷检测;图像匹配
{Abstract}: 针对手机石墨散热片人工缺陷检测存在准确率较低、误检率较高等问题，提出了一种基于机器视觉的手机石墨散热片缺陷检测方法。首先采用基于自适应局部降噪的同态滤波器去除图像噪声、利用仿射变换校正图像等预处理操作；再通过基于形状和灰度的二次匹配法判断图像中是否存在缺陷，有缺陷则采用差分运算和二值化提取图像中的缺陷并显示缺陷。实验结果显示，自适应局部降噪的同态滤波方法可以得到更高对比度和亮度均匀的图像，且二次匹配法准确率达到98%,误检率降到0.8%。采用的滤波方法和二次匹配法适用于手机石墨散热片缺陷检测，能够满足企业品控要求。
{ISBN/ISSN}: 2096-3998
{Notes}: 61-1510/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxrFbZC38x0pJmwiykli7glbagcCQpxoGEMNar9TsY3d8LyB6fcwzsW1zgaj9dfi7ebAs9IML8CwP_--GrUiND0BPlBjllFomGi159dVb6CLcBtrwCRR_ptgwkyaqVPmZ9aDGhu6u1b6UybMXhlRgCvMj2OtSD1KNgey90OFSEa6Ntgs8VLPh5516kA7u5pmMo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV的甘蔗茎秆识别方法
{Author}: 穆协乐;陆静平;郭小龙;吴耀光;张铁异
{Author Address}: 广西大学机械工程学院;
{Journal}: 物联网技术
{Year}: 2022
{Volume}: 12
{Issue}: 04
{Pages}: 9-10+13
{Keywords}: 计算机视觉;OpenCV;图像处理;HSV;甘蔗茎秆;形态学处理
{Abstract}: 人工智能在当今社会具有广阔的发展前景，计算机视觉和图像处理关系密切，良好的图像处理有助于机器识别。为解决对甘蔗收割机、剥叶机喂入量的检测，文中以识别甘蔗茎杆为目的，基于OpenCV对甘蔗图像从RGB空间向HSV空间转换，基于HSV颜色空间下H通道，经阈值分割后对分割后图像做形态学处理，设置相应的迭代次数，最后通过按位逻辑运算实现对甘蔗茎杆的识别。该方法可以防止甘蔗收割机以及剥叶机运行出现堵塞，为甘蔗的收获产量计算提供支持。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2022.04.002
{DOI}: 10.16667/j.issn.2095-1302.2022.04.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于双目深度估计的牛体尺测量方法设计
{Author}: 赵建敏;关晓鹏
{Author Address}: 内蒙古科技大学信息工程学院;
{Journal}: 光电子·激光
{Year}: 2022
{Volume}: 33
{Issue}: 04
{Pages}: 429-435
{Keywords}: 机器视觉;双目;目标检测;深度估计;体尺测量
{Abstract}: 为解决传统人工接触式测量工作量大、测量条件相对艰苦及影响牛正常生活习性的繁琐问题，提出了基于目标检测的双目深度估计牛的体尺测量方法。首先，通过双目相机采集图片，利用YOLOv5(you only look once v5)目标检测算法检测图像中的体尺特征部位，结合边缘检测等算法获取牛体尺测点。其次，利用双目立体匹配算法将双目2维图片转化为空间3维深度信息图，在深度信息图上读取测点3维坐标。最后，在3维坐标系下运用空间欧氏距离进而计算牛的体尺参数。搭建了测试平台进行测量，实验结果表明，该方法的测量精度高于现有相关方法，其中体长的平均相对误差为2.4%、体高的平均相对误差为1.1%、体斜长的平均相对误差为3.3%,为牛体尺测量提供了可行的示范。
{ISBN/ISSN}: 1005-0086
{Notes}: 12-1182/O4
{URL}: https://link.cnki.net/doi/10.16136/j.joel.2022.04.0611
{DOI}: 10.16136/j.joel.2022.04.0611
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在无人机上的应用研究
{Author}: 谢轩
{Author Address}: 娄底职业技术学院电子信息工程学院;
{Journal}: 信息与电脑(理论版)
{Year}: 2022
{Volume}: 34
{Issue}: 07
{Pages}: 19-21
{Keywords}: 计算机视觉技术;无人机;发展背景
{Abstract}: 近年来，随着计算机技术的不断更新迭代，在很大程度上促进计算机视觉技术的进步及发展，无人机由最初的军事领域逐渐向其他领域拓展。笔者以计算机视觉技术类型为切入点，基于无人机的发展背景，进一步对计算机视觉技术在无人机上的具体应用及应用要点进行分析，希望以此全面提升计算机视觉技术的应用价值，并为无人机的发展应用提供有效的技术支撑。
{ISBN/ISSN}: 1003-9767
{Notes}: 11-2697/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy3nGD3vrhOH2JgVjFYa-4ZGCbthbdia9if8xgpN-VxcgHyQEteyhHVLvnGn45W4zKUwJ-qwmIuwle5GGEqegYjsFRpSZtIkgQ3t0CuulU0_rq3q7khnyydJTC_cs0mmtjoygA-hE4CU7PQH2vsMVUwgQxhTVma-eiZTGgZouhbJXBbyNnMZd4uyYU7TPMgC60=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的驾驶员险态驾驶行为检测与预警方法研究
{Author}: 胡超超
{Tertiary Author}: 陈仁祥
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;分心驾驶;目标检测;疲劳驾驶;眼睛状态识别
{Abstract}: 近年来,交通安全事故的频发对我国国民生命和财产造成了巨大的损失,然而大部分交通事故的发生都与驾驶员相关。驾驶员在驾车行驶期间主要会出现两种险态驾驶行为:分心驾驶与疲劳驾驶。为有效降低交通事故的发生以及营造安全有序的道路交通秩序,就需要驾驶员保持注意力集中与精力充沛的驾驶状态,因此,采用准确可行的检测方法来实现对驾驶员当前驾驶行为的实时检测,并及时给予提醒,特别是对“两客一危”车辆驾驶员的实时检测与预警,对维持道路交通安全具有重要意义。目前,对驾驶员险态驾驶行为检测的方法多种多样,主要分为基于生理参数的检测方法、基于车辆行驶状态的检测方法和基于计算机视觉的检测方法。其中,基于计算机视觉的检测方法直观可靠,得到了广泛应用。但由于驾驶员险态驾驶行为复杂多样,在检测过程中仍存在分心驾驶行为检测受限于有限的类别数、检测模型庞大且效率较低等问题。基于此,本文开展了基于计算机视觉的驾驶员险态驾驶行为检测与预警方法研究,主要内容如下:(1)针对采用分类方法进行分心驾驶检测存在只能识别有限分心驾驶行为类别以及忽视时间信息的问题,提出基于改进YOLOv5的驾驶员分心驾驶检测方法。首先,在YOLOv5的基础上引入Ghost模块,采用线性变换代替部分常规卷积进行特征提取以轻量化网络模型,实现快速又准确地检测图像中手机、水瓶、驾驶员双眼和头部区域;其次,在获取目标检测结果的基础上,结合头部姿态估计设计逻辑算法并融入YOLOv5中,从认知分心和视觉分心两个角度检测每帧图像中驾驶员是否存在分心驾驶,避免了分类方法受限分心驾驶类别数的问题;最后,再设置适当的时间阈值,从而实现端到端实时的分心驾驶检测。(2)通过准确且高效地提高疲劳驾驶行为检测中的驾驶员眼睛状态识别,进而提出基于改进卷积神经网络的驾驶员疲劳驾驶检测方法。首先,在Le Net-5网络的基础上采用多个小卷积层堆叠替换一个大卷积层的策略,减少参数量和浮点运算数的同时增强网络对眼睛图像的特征提取能力;其次,在卷积层和池化层之间嵌入高效通道注意力模块,使网络突出眼睛图像中重要通道特征并弱化非重要通道特征,从而准确、高效地自学习图像中有效眼睛状态特征信息;最后,根据驾驶员眼睛状态识别结果计算得到眼睛特征,并结合嘴巴特征,综合检测驾驶员疲劳驾驶行为。(3)根据驾驶员险态驾驶行为检测的特点与需求,设计并开发了集数据采集、样本构建、模型训练、检测预警等功能于一体的驾驶员险态驾驶行为检测与预警系统。将对驾驶员疲劳驾驶行为和分心驾驶行为的检测方法集成,实现在线或离线的驾驶员险态驾驶行为检测与预警。论文最后对所做的驾驶员险态驾驶行为检测与预警方法研究和系统开发进行总结,并针对本文存在的不足之处提出对未来研究的展望。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2022.000165
{DOI}: 10.27671/d.cnki.gcjtc.2022.000165
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的铝镍钴磁性材料外观缺陷检测的研究
{Author}: 虞佳佳;张耀;何勇
{Author Address}: 浙江机电职业技术学院;浙江大学生物系统工程与食品科学学院;
{Journal}: 浙江工业大学学报
{Year}: 2022
{Volume}: 50
{Issue}: 02
{Pages}: 143-148
{Keywords}: 机器视觉;缺陷检测;磁性材料;Canny算法;Blob分析
{Abstract}: 针对镍钴磁棒材料在线分拣中人工端面缺陷检测准确率低、分拣慢的问题，提出一种基于机器视觉的铝镍钴磁棒材料缺陷检测的方法，创新性地提出了一种以轮廓与拟合圆距离差为评价标准的检测边缘崩角和缺角的算法。首先，通过Canny算法获取检测图像的轮廓；然后，基于轮廓最大连通曲线拟合端面圆，轮询计算轮廓点与拟合的端面圆距离，由此精确获取边缘崩角和缺角信息；最后，通过Blob分析法分析端面污点信息。实验测试结果表明：该系统可对产品的两端面外观缺陷进行筛选，实现对表面缺角、崩角和污点等的检测，在设计的铝镍钴磁性材料分拣系统的应用中，检测节拍可达120片/min,检测准确度大于97%,符合企业分拣需求。
{ISBN/ISSN}: 1006-4303
{Notes}: 33-1193/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyLXqQmiLkNtbp6kvmawWsac1tRSxnYv5pWv98vPka4lTD6P8JxGSxgbQIgVn6QwJt6hwEsgxPhIkb0HKfJCsrwAIZBwyxAHm2uAho4cfd7fJcHcZz7isHg62pZIuBsAKrIV4jeezp2R5ucOelEdyqX5N4I1MN2vQo-9UtjlBxjkHUeJGZjarBvAUdouCSfVus=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的目标检测与跟踪技术研究
{Author}: 吕东
{Tertiary Author}: 李庆党
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;低照度图像;目标跟踪;光照感知
{Abstract}: 目标检测与目标跟踪技术能准确、及时地获取实体时空位置属性信息,因此也被誉为计算机领域最具活力和发展潜力的技术之一。近年来,随着深度学习的迅速发展,目标检测、跟踪等技术也向着更加精准、迅速的方向前进。作为自动驾驶、虚拟现实、行为理解等诸多领域的核心技术之一,基于深度学习的目标检测和跟踪技术受到了海内外研究者的普遍重视。本文也将进行基于深度学习的目标检测以及目标跟踪等关键技术的研究。总体而言,检测是跟踪的前序工作,跟踪是检测的时序化过程。常见的目标检测算法多基于日常照度感知场景进行设计,但未充分考虑低照度条件下目标检测任务的特点。低照度场景面临着对比度较弱、噪声较多等多种图像退化现象的叠加问题。因此,提升低照度场景条件下目标检测的准确性与实时性,是当前计算机视觉领域亟待解决的问题。对于目标跟踪任务而言,遮挡所致的跟踪对象丢失问题是制约跟踪任务准确性与实时性的重要因素。虽然相关研究人员对该问题进行了大量的优化,但目前的目标跟踪算法仍未很好的解决跟踪丢失问题。因此,如何结合计算机视觉领域的先进技术,提升遮挡等条件下目标跟踪的准确性与实时性,也是该领域亟待突破与解决的重要问题。本文对上述两个问题进行了针对性研究。首先,结合了图像增强、残差学习、差分融合等先进的计算机视觉方法,设计了针对低照度场景的目标检测算法,提升了低照度场景下目标检测的准确性。随后,结合Deepsort多目标跟踪算法与Res Net-50深度残差神经网络,提升了特征提取能力并构建了更为准确的目标跟踪算法。在Market-1501数据集及测试视频上的实验表明了改进Deepsort目标跟踪算法的有效性。更具体地,本文研究可概括为以下4个方面:(1)理论分析。对现有R-CNN、Faster R-CNN、SSD等目标检测的优劣进行了分析,为后续算法的改进提供了理论支撑。对Sort、Deepsort等的目标跟踪算法进行了解析,并以MOT16数据集为训练源进行对比试验,从而证明了在Deepsort计算中采用了马氏距离替换欧氏距离、添加级联匹配和特征提取网络等方法的有效性。(2)提出了改进的SSD算法。修改原始SSD网络为双层结构,使用残差学习能力强的Res Net-50网络取代原有VGG-16网络;结合Retinex模型的结构图像增强方法,提高浅层特征的利用效率;结合差分模态感知融合模块,挖掘原始图像和增强特征图之间的高维特征融合方式,解决了图像光照度不平衡所致的特征提取效果差的问题。(3)提出了改进的Deepsort算法。在Deepsort多目标跟踪算法结构为基础,结合Res Net-50网络,对Deepsort中的深度特征提取网络进行改进。在Market-1501数据集及测试视频上的实验验证了该改进的有效性,完成了更高效准确的目标跟踪任务。(4)实验验证。改进的SSD算法,在KAIST数据集中平均精度均值达到82.39,较原有SSD目标检测算法精度提升1.71,且运行速度上升为35帧/秒,较原有算法提升10帧/秒,有效解决了低照度环境下目标检测精度低这一问题。改进的Deepsort算法在Market-1501数据集中精度达到84.8,较原有目标跟踪算法精度提升9.0,同时能有效降低跟踪对象由于遮挡导致丢失问题的发生。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2022.000785
{DOI}: 10.27264/d.cnki.gqdhc.2022.000785
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的轨道环境视觉感知算法研究
{Author}: 王银
{Tertiary Author}: 王立德
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 车载视觉系统;轨道环境感知;边缘检测;轨道区域识别;行人入侵检测;低照度增强
{Abstract}: 全自动驾驶列车已成为轨道交通领域新的发展方向,为保障列车安全稳定运行,需要解决的重点问题是对于运行环境的实时智能监控和有效感知。现阶段所采用的手段多聚焦于在轨旁安装视频监控装置或人工定期巡检,这些方法效率低、成本高,无法满足轨道交通长距离、全天候条件下的环境监控需求。研究基于列车车载视觉的环境感知系统,对轨道环境进行实时监测和异常检测是保障列车安全运行的重要手段,也是智能化铁路的发展方向。本文以轨道环境视觉感知系统为研究主体,基于深度学习技术对轨道环境下的多项视觉任务展开研究,在分析了轨道场景特点的基础上,将研究重点聚焦于视觉底层特征提取的共性问题以及轨道场景下高层应用的特异性问题。本文从边缘信息入手探索底层视觉特征的提取方法,在此基础上研究多维视觉特征的高层次应用,从场景和目标的角度建立车载视觉系统对环境的感知能力。更进一步的以提高视觉算法对轨道环境复杂光源的适应性为目的,分析轨道场景下的曝光问题,并基于此研究适用于轨道场景的视觉增强算法。本文主要研究内容及创新点如下:(1)以边缘检测为切入点研究视觉底层特征提取。边缘的检测与识别是众多计算机视觉任务的基础和前提,本文从众多视觉任务之上抽象出边缘特征提取问题用于研究深度神经网络结构、数据以及损失函数等对底层视觉特征提取的影响。提出一种基于编解码结构的多尺度特征融合边缘检测算法,以编解码结构执行特征的提取和高层处理,通过设计特征增强单元和残差上采样单元实现特征在解码网络中的高效利用。另外,本文对类不平衡问题形成的内在原因进行了分析,并针对这一问题提出一种偏置交叉熵损失函数用于降低神经网络在类不平衡数据下的训练风险。实验中设置网络消融研究验证相关模块的功能,在多个数据集上的实验结果证明了本文提出的算法在网络结构设计以及训练方式上的合理性与先进性。(2)从场景分割角度研究轨道区域的精确识别问题。本文舍弃了传统方法以检测两条轨道线确定轨道范围的思路,将轨道范围作为一个封闭的场景模块进行研究。提出一种全卷积轨道场景分割网络Rail Net,通过多尺度特征提取并结合金字塔特征上采样的方式融合骨干网络中不同层次特征。本文针对分割任务设计了一种V型全卷积分割结构用于逐层恢复特征分辨率。为了训练所提出的轨道分割网络,本文建立了一个轨道分割数据集RSDS,并结合网络参数迁移技术对分割网络进行训练。实验结果证明本文提出的算法能够在不同场景下稳定的对轨道区域范围进行精确分割。(3)针对轨道范围内的行人入侵检测问题展开研究。本文基于列车车载视觉检测的要求提出采用长焦和广角摄像机相结合的方式作为视觉硬件平台,在算法层面上分析当前目标检测算法所存在的问题,以及车载视觉对检测算法性能的需求,提出一种单阶段行人检测算法。算法在基础特征提取网络之上建立特征后向融合通道,并基于融合的特征建立卷积检测器执行目标检测。本文针对不同层次特征设计不同的行人先验框策略,这种策略能够有效降低先验框的数量并同时增强小目标行人的检测能力,在网络训练中采用难样本挖掘以及Focal损失策略解决正负样本不平衡问题。通过设计多个验证实验证明所建立的行人检测算法的有效性和先进性。(4)研究列车在多变复杂的光源条件下车载视觉的成像质量问题。本文对轨道交通环境车载视频图像曝光问题进行了分析,基于此提出一种基于自监督学习的轨道低照度环境实时增强算法。算法以密集连接网络结构为骨干网建立特征尺寸不变网络提取图像光照、颜色、边缘等信息输出光照增强率图,基于非线性映射函数对像素进行亮度调整,通过分级结构实现高动态范围的曝光率自适应增强。算法采用自监督的方式训练网络参数,利用低照度图像自身特征和先验知识构建损失函数,从而解决轨道环境下难以获得大量有标签训练数据这一难题。多种场景下的图像增强实验结果显示本文算法能够对输入图片曝光值进行自适应,对低曝光以及高曝光区域动态调整曝光率从而提高低照度图片成像质量。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000061
{DOI}: 10.26944/d.cnki.gbfju.2022.000061
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的药品包装质量检测
{Author}: 薛璨
{Tertiary Author}: 李明
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 药品包装质量;图像显著性;YOLOv5;DBNet;注意力机制
{Abstract}: 药品包装分为内包装与外包装,内包装的作用是保障药品药效,主要包装方式为铝塑泡罩;外包装上的信息用于药品追溯与安全用药,主要方式为药盒。为保障内外包装的完整性以及准确性,目前生产中常采用机器视觉对铝塑板缺粒与药盒三期(生产日期、保质期、批号)进行检测。然而在实际生产中,由于白色药片的颜色特性,机器视觉检测工位只能放在铝塑热封合之前,导致经过检测后的铝塑板仍有缺粒的风险;此外,药盒三期使用压印方式时,通常只能人工抽检,导致三期漏印的情况不能及时发现。本文采用机器视觉对目前存在的问题进行研究,主要工作如下:首先,针对白色药片在二值图中难以与背景区分的问题,提出一种基于显著性的分块阈值分割算法,通过对区域内像素的灰度值进行显著性计算来增大药片区域与背景之间的灰度值差值,实现对药片区域的分割以及是否缺粒的检测;针对分割算法鲁棒性不强、处理速度无法满足产线的要求的问题,将基于深度学习的目标检测算法YOLOv5s与Center Net用于铝塑板缺粒检测。在自制的铝塑板数据集上对上述三种方法进行验证,实验结果表明,YOLOv5s对药片检测的准确率最高,达到99.8%,速度也最快,达到16.7fps。其次,针对压印字符区域由于成像原理与背景区域的像素值相差无几,导致分割出的字符不完整、无法识别的问题,将基于深度学习的文本检测模型DBNet与文本识别模型CNN+RNN+CTC用于药盒三期识别。针对DBNet骨干网络参数较多、不易部署的问题,构建了基于注意力机制的轻量化模型DBNet-MC。首先,将骨干网络替换为轻量化模型Mobile Netv3,减少模型参数、加快推理速度;然后,引入卷积注意力机制模块CBAM,提高模型的特征表达能力;最后,在自制的压印字符数据集上进行验证,实验结果表明,改进后的文本检测模型准确率并未下降,达到98.5%,但推理速度提升26.7%,达到19fps。然后,因产线速度匹配需求,铝塑板缺粒检测速度需大于药盒三期识别速度,同时为了便于模型部署,使用通道剪枝方法对YOLOv5s进行压缩。实验结果表明,压缩后的模型在保持准确率不变的前提下,推理速度提升了33%,达到22fps。最后,根据需求搭建实验平台;基于上述优化的网络模型,使用Py Qt5开发了药品包装质量检测软件,集成铝塑板缺粒检测与药盒三期识别功能。在检测过程中将结果可视化,便于质检人员抽检。同时将结果保存在本地,便于日后追溯。该论文共有图78幅,表12个,参考文献69篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000712
{DOI}: 10.27623/d.cnki.gzkyu.2022.000712
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉和近红外光谱技术的大米外观品质检测研究
{Author}: 陈昊然
{Tertiary Author}: 蒋敏兰
{Publisher}: 浙江师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 大米外观品质检测;机器视觉;近红外光谱;轻量级卷积神经网络;目标检测;垩白米;碎米
{Abstract}: 中国是一个农业生产大国,粮食产量己经处于世界领先水平,人民的温饱问题已经基本解决。当前,我国粮食供求的主要矛盾己从数量的不充足转为质量的不理想。2018年更新的《大米》国家标准GB＿T 1354-2018对大米外观品质中垩白米、垩白度以及碎米率等指标提出了更高要求,这些指标直接影响大米等级的划分。目前,大米外观品质检测主要侧重于大米的形状、大小和颜色差异,但随着技术不断进步及大米种类愈发多样,使得大米外观品质检测仍存在许多挑战:(1)传统垩白米分类取决于大米颜色差异,但颜色分类易受到背景颜色、环境光源及诸多干扰因素的影响,增加垩白米分类的难度;(2)垩白米的垩白区域大小分布不均匀、颜色深浅不一,目前垩白度检测所用的图像分割算法,存在检测精度低及鲁棒性差等问题;(3)大米外观品质自动化检测要求高效、高精度和低硬件成本,但现行的高精度目标检测模型对处理器计算能力、硬件配置有较高的要求,其网络模型复杂性也会造成训练和检测的时间成本过高的情况。为了解决以上问题,本文主要开展了以下3个方面的研究工作:(1)提出基于近红外光谱技术的垩白米分类方法。将近红外光谱技术应用于垩白米分类,该技术可采集不同物质成分的光谱数据,从物质成分这一检测维度可避免环境中颜色信息的干扰,提高垩白米分类的精度。本文构建了正常米和垩白米的近红外光谱数据集,并对数据集进行了显著性分析,确定光谱数据可用于垩白米的分类。建立支持向量机(Support Vector Machine,SVM)垩白米分类模型,并采用主成分分析(Principal Component Analysis,PCA)对分类前数据进行降维处理,提高分类模型的准确率。试验结果表明PCA-SVM分类模型准确率为98.29%,较SVM模型增长了1.71%,可以有效实现对垩白米的分类。(2)提出基于图像特征区域提取的图像分割算法。为提升垩白度检测精度和鲁棒性,本文提出了一种基于图像特征区域提取的垩白度检测算法。利用大米垩白区域像素变化的特点,对图像特征变化的边缘进行提取,计算出边缘像素点个数以及边缘的总像素值,从而计算出边缘像素的平均值作为该区域的阈值。最后,利用计算得到的阈值对垩白区域进行分割,并计算出大米的垩白度。试验结果表明,该算法垩白度检测准确率为96.76%,相较于OTSU算法和改进的OTSU算法,准确率分别提高了26.87%和7.26%。在图像抗干扰性测试中,该算法可有效过滤噪声信号,实现了对垩白度的精准检测。(3)提出基于轻量级卷积神经网络的目标检测模型。为提高米粒目标检测的精度和速度,本文提出了一种基于轻量级卷积神经网络的目标检测模型,Mobilenet+Yolo-V4s网络模型。将Mobilenet轻量级卷积神经网络作为Yolo-V4目标检测模型的特征提取主干网络,采用Mobilenet中深度可分离式卷积操作代替Yolo-V4的特征加强网络的标准卷积操作。构建了垩白米、碎米以及正常米的图像数据集,在该数据集上试验结果表明,Mobilenet+Yolo-V4s相较于Yolo-V4模型参数量降低了81.7%,检测速度提高了2.5倍,并取得了91.69%的总平均精度(m AP)。Mobilenet+Yolo-V4s在保持良好的目标检测能力的同时提供了更快的检测速度,且占用了更少的运行内存,实现了对垩白米、碎米以及正常米的目标检测。
{URL}: https://link.cnki.net/doi/10.27464/d.cnki.gzsfu.2022.000614
{DOI}: 10.27464/d.cnki.gzsfu.2022.000614
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工件几何量测量和表面缺陷检测研究
{Author}: 韩宗旺
{Tertiary Author}: 程祥;张伟
{Publisher}: 山东理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;几何量测量;边缘检测;表面缺陷检测;误差评定模型
{Abstract}: 工件的几何量测量和表面质量检测是机械制造中重要的环节。传统的检测方法多采用接触式测量,存在效率低和人为误差大等问题,难以满足工件快速检测的要求。本文基于机器视觉检测和人工智能检测技术,研制工件几何量测量和表面缺陷综合检测系统,基于关键图像检测算法,提出直线度、圆度、圆柱度评定算法以及螺纹参数检测算法与工件表面缺陷检测算法,实现工件多几何量和表面缺陷的快速检测。主要工作如下:首先,设计机器视觉检测系统的总体方案,对检测系统的图像采集单元、运动控制单元、照明系统等进行分析与设计,建立工件检测流程,编制检测系统控制、几何误差图像处理与缺陷检测图像处理程序和用户界面;进行相机标定,校正镜头畸变,降低测量中图像畸变。其次,研究工件图像处理的关键算法。分析图像清晰度评价函数,提出一种基于自适应阈值的八邻域空心梯度加权的清晰度评价函数,用于检测系统聚焦位置的判定。采用图像滤波方法降低图像噪声,将最大类间方差法与全局阈值处理算法结合对工件图像进行阈值分割,利用形态学去除孤点。提出基于插值—拟合法的亚像素边缘检测算法用于图像目标边缘的精确提取,并与传统边缘检测算子进行对比。再次,研究几何误差评定算法和缺陷检测算法。建立测量工件直线度、圆度、圆柱度的测量模型,提出包容线搜索法和多变异位自适应遗传算法评定工件直线度误差,提出自适应搜索逼近法和基于空间的最小二乘圆心拟合方法评定工件圆度和圆柱度误差。利用图像轮廓坐标点数据拟合方法得到工件的大径和小径,提出阈值分割与LSD算法相结合的牙型角求解算法,建立螺纹图像失真模型,对牙型角测量误差进行补偿。研究螺纹磨损缺陷的检测算法,分析缺陷图像的特征,设计两步分割方法定位缺陷位置,并采用MLP神经网络对螺纹表面缺陷进行分类处理。最后,搭建基于视觉综合检测平台,并进行实验研究。采用标定算法标定相机后,对工件的直线度、圆度、圆柱度误差,螺纹参数和磨损缺陷进行检测,并对检测结果进行分析比较。实验结果表明,所研发的机器视觉综合检测系统可实现工件几何量和表面缺陷的快速检测,为进一步对机器视觉检测系统的深入研究与开发奠定了一定的基础。
{URL}: https://link.cnki.net/doi/10.27276/d.cnki.gsdgc.2022.000347
{DOI}: 10.27276/d.cnki.gsdgc.2022.000347
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 视频图像的长时目标检测跟踪算法研究
{Author}: 王子彦
{Tertiary Author}: 赫熙煦
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;卷积神经网络;目标检测;多目标跟踪;嵌入式
{Abstract}: 近年来,随着大数据时代的到来以及GPU算力的大幅提升,目标检测与跟踪作为计算机视觉中的两个基本问题在众多应用场景中都取得了巨大的发展。目标检测和跟踪算法在一些主流常见的数据集中表现出了强大的性能,但是这些数据集中往往只包含了自然场景下的一些视觉任务。在一些特殊场景下,比如无人机拍摄场景,直接将主流的目标检测跟踪算法应用到任务中,往往难以表现出较好的性能,也不能满足在这些场景下的任务要求。本文针对于目标检测与跟踪算法存在的问题进行深入的研究与分析,在YOLOv5检测算法和DeepSORT跟踪算法的基础上进行改进,主要贡献与创新点总结如下:1.YOLOv5目标检测算法的优化。本文分析了YOLOv5目标检测算法在针对于无人机场景下进行目标检测任务存在的问题,并针对性地进行改进来解决这些问题。首先针对无人机拍摄图像尺度变化剧烈的问题,对YOLOv5原有的特征金字塔PANet进行改进,通过增加跳跃连接的方式,使网络融合了更多的原始特征,并且使用一种加权的特征融合方式解决了特征图融合过程中贡献不平等的问题。然后,在网络检测头输出之前,引入了CA注意力机制模块帮助网络在大范围的图像区域中快速找到感兴趣的目标所在区域。最终,提出了一个基于注意力机制的游走切片检测框架,此框架主要包含全局检测分支和切片检测分支,兼顾了不同尺寸目标的检测精度。在此基础上,提出了一种改进的SWA-YOLOv5网络。最后通过实验模块分别在MS COCO数据集以及Vis Drone2021DET数据集下进行算法对比实验,实验结果表明,本文提出的算法SWA-YOLOv5相比于YOLOv5算法,在Vis Drone2021DET数据集下m AP值提高了3.02%,FPS虽然有所下降,但是仍然可以满足实时性的要求。2.DeepSORT目标跟踪算法的优化。本文首先对DeepSORT算法存在的问题进行了深入的探索与分析,并针对性的对DeepSORT中的三个模块分别做出了改进。在特征提取模块中沿用第三章提出的SWA-YOLOv5网络,并在检测头部分增加外观信息的输出,解决了原有特征提取网络存在的耗时严重以及性能低下的问题;在运动估计模块中对卡尔曼滤波算法中的噪声矩阵实现自适应计算并增加了高斯过程回归模块来对目标检测器失效的情况下的跟踪轨迹做出插值,解决了卡尔曼滤波对于噪声的鲁棒性差的问题;在轨迹关联模块中采用一种基础的线性匹配策略替换掉原有的级联匹配,在此基础上提出了YNGB-DeepSORT网络来实现高效的目标跟踪,并通过实验验证了各个模块的有效性,最后通过算法对比实验将本章的改进算法与几种主流的目标跟踪算法进行对比,验证了算法的有效性。实验结果显示,本文提出的YNGB-DeepSORT目标跟踪算法在MOT16多目标跟踪数据集上相比于DeepSORT算法,MOTA提升了6.5%,IDsw次数下降了527,IDF1提升了10.4%,FPS提升了50%。3.实时目标检测跟踪系统的设计与实现。本文将理论创新应用到实际的工程应用中,针对无人机场景下的目标检测跟踪任务,提出了一种嵌入式平台的实时目标检测跟踪系统,该系统将本文提出的算法移植到嵌入式板卡中,在板卡上利用Tensor RT技术以及多线程技术对其进行工程优化,进而使得系统能得到一个更为流畅与高效的运行。在此基础上设计了地面上位机软件系统来实时的监控系统的整体运行情况。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004137
{DOI}: 10.27005/d.cnki.gdzku.2022.004137
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的样本不平衡问题研究
{Author}: 郑宇
{Tertiary Author}: 徐传运
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;数据不平衡;长尾分布;图像分类;目标检测
{Abstract}: 数据是深度学习不可或缺的因素之一,在各种视觉任务场景中都依赖着相应的数据集。训练分类器的基本假设是:基于所研究数据集不同类别中的样本数量大致平衡。现代深度学习方法在均匀分布上表现良好,然而在长尾的自然世界中样本数量是不平衡的,这种不平衡给基于深度学习的模型训练和实际应用带来了巨大的挑战。对于近年来备受关注的样本不平问题,本文定义了几种常见的不平衡形式,采用相关开源数据集对其进行重构作为研究对象。在计算机视觉中的样本不平衡问题上,利用重加权的思想对深度学习在图像分类和目标检测上展开研究。本文主要研究工作包括:(1)首先在图像分类中研究了现有工业上常用的对于不平衡数据集的处理方法。对现有的重采样,重加权方法进行了详细的比较分析。使用Res Net18模型在CIFAR-10,CIFAR-100,Image Net-Tiny这三个基准数据集上展开相关实验。通过实验发现重加权方法在处理样本不平衡问题上优于更具稳定性。(2)由于重加权方法在样本不平衡问题上的优秀表现,本文针对重加权方法展开了研究。考虑类别数量,样本数量,类别不平衡度这三个因素对重加权结果的影响。在以往的研究中,权重的设置只与类别样本的数量有关,在敏感的加权方法中,仅依靠类样本个数的信息来确定权重的大小是非常粗略地。通过三个数据集自身的属性来改进现有的有效样本计算方法,从而对现有的有效样本损失的优化。实现了自适应的有效样本加权方法。在构造的长尾CIFAR数据集中证明了我们方法的有效性。(3)同时对于在目标检测中的难易样本不平衡问题,本文提出了一种基于Cascade R-CNN的级联优化的策略。逐步优化训练过程中建议区域的质量同时平衡正负样本,并且通过回归损失来对难易样本在边框回归中产生的梯度进行平衡,从而达到平衡检测器训练过程中的难易样本。在SKU-110K和MS-COCO2017数据集上对本文的方法进行了验证,通过实验证明方法有效地提高了检测器的检测精度。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2022.000295
{DOI}: 10.27753/d.cnki.gcqgx.2022.000295
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 低分辨率和非常规类型目标检测的关键技术研究
{Author}: 马霆松
{Tertiary Author}: 田文洪
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 目标检测;低分辨率;非常规目标;知识蒸馏;自适应锚点
{Abstract}: 目标检测算法作为深度学习和计算机视觉领域最重要的研究方向之一,有众多的研究成果被相继提出。但是当这些算法被应用到实际的视频图像中检测时,检测效果往往不太理想。原因主要分为外源性和内源性两种,外源性原因是目标检测模型普遍在遇到低分辨率图像时检测准确度会大幅下降,而内源性原因是不同的目标检测算法本身的缺陷,导致模型在极端尺寸以及相似的密集分布目标等非常规类型检测对象上出现检测准确度大幅下降的情况。这些问题正在成为推动目标检测模型应用的障碍。为了解决上述问题,本文主要开展了如下工作:(1)针对在低分辨率图片上目标检测精度受到显著影响的问题,提出了一种目标检测模型与超分辨率算法有机结合的方法。该方法首先设计了一种能以任意倍率对图像进行放大和缩小的反馈式超分辨率网络。其次,利用超分辨率网络能以任意倍率对图像进行放大和缩小的特点,在超分辨率网络与目标检测网络中间层之间建立信息通信,并进行联合训练,使超分辨率网络结构成为目标检测模型的一部分,从而提高目标检测模型在低分辨率图像上的检测效果。实验结果显示,目标检测模型在结合超分辨率算法前,在4倍及8倍下采样的视频图像上检测精度下降分别为8%以及24%,结合超分辨率算法后该降幅缩小为3%以及9%。(2)在上一个工作基础上,研究了如何在不额外增加网络结构的前提下,提升轻量级目标检测模型在低分辨率图像上的检测精度。本部分工作主要是提出了一种多尺度特征传递的知识蒸馏算法,该方法主要思路是分别在高分辨率和低分辨率图像上训练教师和学生网络模型,学生网络的中间层受到多层教师网络中间层的监督,使得学生网络学习教师网络的目标检测能力。同时设计了一种结合池化与全链接的网络结构,用于判断教师网络在监督时传递的知识哪些重要和冗余,以提高知识蒸馏的效率。实验结果显示,通过使用本文提出的多尺度知识蒸馏算法训练出的轻量级目标检测模型,在4倍和8倍下采样的视频图像数据集上的精度降幅从原来的14%和49%,缩小为了8%以及39%。(3)除了图像分辨率这种导致目标检测模型性能下降的外源性原因外,算法本身的缺陷导致模型在一些特定目标上检测效果下降的情况就是内源性原因了。例如,在极大以及极小等异常尺寸的目标上检测时,采用Anchor-Based路径实现的目标检测模型的检测精度下降明显。针对这一问题,本文提出了一种能够自适应学习Anchor大小的算法。该算法通过动态地为特征图上各个像素位置预测一个任意大小的Anchor的方式来实现目标检测任务。算法整体流程可以分为位置预测、特征过滤以及Anchor大小预测三个步骤,在进行检测时,只需要为有限数量的像素位置预测一个Anchor就能够完成目标检测流程,而不需要像普通Anchor-Based模型一样,为特征图上每一个位置都放置Anchor,大大减少计算负担。实验结果表明,本方法由于预测Anchor大小的不固定性,使得其能够向任意大小的目标进行拟合,使得模型在视频图像数据集上能够获得约3%左右的精度提升。(4)除了Anchor-Based模型的问题之外,部分使用Anchor-Free路径实现的目标检测模型,在实际应用中常常遇到的密集相似目标上也表现出检测效果不佳的问题。为此,本文提出了一种基于预测中心位置划分的关键点匹配算法。与部分Anchor-Free模型采用外观信息来匹配关键点的方法不同,本方法通过将预测关键点组成的框,与真实目标框之间的空间信息进行充分考虑的方法,来完成关键点的匹配和目标检测任务。在检测的过程中,一部分预测框能够找到与之中心距离相近的真实目标框,针对这类目标框设计一种损失函数,从而在这部分预测目标框上进行回归得到定位结果,并对其进行二次分类得到更准确的分类结果。而另一部分的预测目标框与任何真实目标框的中心点距离都较远,为此另外设计了一个损失函数,从而使得这部分预测目标框的数量尽可能少,并且让预测出的这类目标框也应该尽可能远离其他类型的目标框,以免对网络模型产生混淆。实验表明,使用基于预测中心位置划分的关键点匹配方式,能够让使用普通关键点匹配方法的模型提升5%左右的检测精度。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000156
{DOI}: 10.27005/d.cnki.gdzku.2022.000156
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的烤烟自动分级方法研究
{Author}: 陈人杰
{Tertiary Author}: 李迅波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 烟叶分级;卷积神经网络;机器视觉;迁移学习;EfficientNetV2
{Abstract}: 中国是世界上人数最多的一个国家,同时卷烟生产总量和消费总量均位居榜首。但是我国目前烟叶分选完全是由人工进行操作的,人工分选带有很强的主观意识,并且长时间进行这种单调重复的操作会使分选效率和准确率降低,再加上我国颁布的烤烟GB2635-92标准对于烟叶分选的属性描述较为模糊,很多属性没有定量的划分,并且因为人员流动较大,导致复烤公司每年都会对分选人员进行培训增大了花费成本。随着机器视觉技术的发展成熟,许多农产品都实现了有关机器视觉领域的自动化,所以进行烟叶自动化分级的需求越来越急迫。现有的方法大多都是使用颜色特征或者形状特征对烟叶进行分选,但是烟叶分选是类内分选,属于细腻度图像分类,仅仅运用机器视觉进行分选的话,正确率得不到保证。因此为解决烟叶分选人工成本大和准确率低等问题,本文提出一种结合传统特征和深度学习特征的网络模型对烟叶进行分级。本文的主要内容如下:1.构建数据集。由于现有的可用数据集均与烟叶分级任务无关,所以如果想要进行深度学习训练神经网络就需要自己构造数据集。通常来讲,任何深度学习任务普遍都是在一定大小范围内拥有训练数据量愈多,模型愈优秀。所以根据训练集和验证集的自身特点,只在训练集上依靠翻转和旋转操作增加样本数。2.本文设计了一种可以在烟叶图片上卓有成效的最大边缘前景提取算法,并分离出前景图像,减少后续图像操作的干扰因素和提高运行速度。3.本文设计了一种新的形态特征提取算法,结合自定义的灰度化,解决了之前算法提取形态特征不准确和鲁棒性低的缺点;使用HSI颜色空间和颜色矩的方法对烟叶的颜色特征进行提取;选取8个不同方位和3个不同尺度的Gabor滤波器的组合对烟叶图像纹理特征提取,并将每一个输出图像进行求均值和求方差压缩维度。4.本文优化了卷积神经网络Efficient Net V2-S,并将其应用于烟叶分级任务中。使用支持向量机确定困难样本,将困难样本添加到训练集,并运用迁移学习的方法对模型赋予初始值,降低模型过拟合现象的发生和提升了预测准确率。将机器视觉技术得到的传统的特征,如形状特征、颜色特征和纹理特征融合到神经网络模型中,并对Efficient Net V2-S的内部层进行了修改,提高模型分选的准确度,使得准确率达90.0%。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003280
{DOI}: 10.27005/d.cnki.gdzku.2022.003280
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的车站人流量检测研究
{Author}: 张依林
{Tertiary Author}: 王学颖
{Publisher}: 沈阳师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;YOLOX;Deep SORT;多目标跟踪;卷积神经网络;人流计数
{Abstract}: 高铁因为它的高安全性和高时效性,使得其成为几乎每个人首选的出行方式。随着高铁的普及率逐年上升,国内自主研发的新技术不断应用,每个车站的人流量也在逐年递增。本文进行研究与实验的目的是基于深度学习和目标跟踪算法在车站场景下进行人流量检测与统计。卷积神经网络(CNN)和视觉目标跟踪(Visual Object Tracking)也是近年来计算机视觉领域受到广泛关注和研究的方向。其中YOLOX目标检测算法是在YOLO系列的基础上吸收近年来目标检测的最新成果。但进行视觉跟踪的核心目的通常集中在以下两点,一是对物体在后继视频序列中的行动轨迹作出有效估计,二是明确物体在后继视频序列中的活动状态,并以此收集的信息数据为基础来剖析物体语义的深层内容。立足于计算机视觉领域,以该领域中目标检测方向的最新研究成果,即YOLOX为导向,着重探索目标跟踪方向中的多目标跟踪板块,同时在研究过程中以简单的在线和实时深度关联度量跟踪(Deep SORT)为代表的多目标跟踪策略为基础,并将其嵌入到实际的跟踪任务中。本文以传统目标检测算法为研究出发点,详细的介绍并分析了目前主流的二阶段和一阶段目标检测算法,而后又将传统目标跟踪算法以及多目标跟踪算法两大类别进行对比分析,为进行以YOLOX与Deep SORT为基础的人流量统计算法研究做好了充分的理论支持与铺垫。在阐述完YOLOX目标检测算法和Deep SORT目标跟踪算法的基本原则和流程后,对整个系统的最后一步即人流计数算法进行了介绍,最后将人流量统计算法在MOT16数据集上进行了测试,并在沈阳北站进行了视频采样,将人流量统计算法应用于实际的车站场景。本文充分考虑目标检测算法所具备的特性,修改了YOLOX模型,提出了基于CBAM注意力机制的YOLOX-AM目标检测模型。率先在人流计数统计系统中混合应用了以下两种模式,一是YOLOX-AM目标检测算法,二是Deep SORT跟踪器,由于上述两种模式的嵌入,算法跟踪能够因此成功作用到行人多目标跟踪数据集MOT16上,计算了12种评价指标。同时在MOT16数据集上实现了人流计数功能,并应用于车站场景。经过实验验证与分析,基于YOLOX-AM与Deep SORT的人流量统计算法在车站环境的实际应用上取得了良好的效果,体现了本系统较好的鲁棒性,具有实际应用价值并可以推广到诸如机场、学校、商场等应用场景。
{URL}: https://link.cnki.net/doi/10.27328/d.cnki.gshsc.2022.000947
{DOI}: 10.27328/d.cnki.gshsc.2022.000947
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图神经网络的人体姿态估计和动作识别研究
{Author}: 朱怡燃
{Tertiary Author}: 沈复民
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人体姿态估计;骨架动作识别;图卷积网络;多尺度框架;注意力机制
{Abstract}: 人体行为分析一直是计算机视觉领域的关键性问题。而人体姿态估计和骨架动作识别作为人体行为分析的两大基础任务,也得到了研究员们越来越多的关注。不同于基于人体模板来进行关键点特征提取的传统方法,最近基于图神经网络的深度学习方法取得了很好的性能。基于图神经网络的方法将人体关节点作为图的顶点,将基于身体物理连接的两个关节点之间的骨骼作为图的边,以这种方式建立图结构并在该图结构上进行关节点特征融合。尽管这些方法取得了不错的效果,但是它们存在着一些限制。先前的方法往往利用单一关节尺度的信息来提取骨架姿态特征,而忽略了信息量丰富的多尺度信息。同时,它们缺乏包含语义位置信息的全局长范围关系的捕捉。例如,相同坐标的两个关节可能代表着不同的关节类型。另外,在骨架动作识别任务上,在时间维度上常用的标准卷积容易过滤掉关键帧从而导致关键帧信息的损失。为了解决以上问题,本文开创性地提出了面向三维人体姿态估计的图空洞卷积编码器解码器网络。该网络模型由图空洞卷积层和图转换层组成于一个编码器解码器结构中。图空洞卷积层可以增大感受野并学习到多尺度姿态上下文。而图转换层可以方便地捕捉全局长范围关系。在骨架动作识别任务上,本文开创性地提出了图卷积沙漏网络来探索多尺度信息。该模型由多个图卷积沙漏块堆叠而成,图卷积沙漏块主要包含图卷积层、图池化层和图上采样层,主要用来得到不同尺度的骨架拓扑图。为了进一步使多个尺度的特征更灵活的融合,并且保留时序上关键帧的信息,本文进一步提出了选择性超图卷积网络。该模型首先使用超图建模人体骨架来建模骨架关节中更高层次的特征,并引入了一种高级的尺度选择超图卷积来选择不同尺度的信息。另外,该模型中也提出了一种帧选择时间卷积来替换传统步长时间卷积,它能够自适应地选择出关键帧并过滤掉冗余帧。本文在人体姿态估计中的Human3.6M和MPI-INF-3DHP数据集和骨架动作识别中的NTU-RGB+D和Skeleton-Kinetics数据集上对本文提出的网络模型在相关评测指标下分别进行了丰富的实验,实验结果表明本文提出的模型达到了业界先进的水平并且具有灵活的扩展性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004145
{DOI}: 10.27005/d.cnki.gdzku.2022.004145
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的夜间交通流量统计算法研究
{Author}: 王洪昌;王鹏;焦博文;于奕轩;王玉林
{Author Address}: 青岛大学机电工程学院;
{Journal}: 青岛大学学报(工程技术版)
{Year}: 2022
{Volume}: 37
{Issue}: 02
{Pages}: 55-60
{Keywords}: 计算机视觉;交通流量统计;YOLO v5s;DeepSORT;智能交通
{Abstract}: 针对夜晚环境中传统交通流量统计出现的实时性、鲁棒性及准确性不高的问题，提出了一种基于改进的YOLO v5s交通流量统计算法。采用残差网络的连接结构对YOLO v5s算法中的Focus层进行改进。将改进后的YOLO v5s算法与DeepSORT跟踪算法、统计模块搭建高效的交通流量统计框架。采集实际路况的夜间场景视频来对该框架的准确性进行验证。实验结果表明，该算法平均准确率达到92.9%,较改进前提升3.0%,平均检测速度可以达到33.4 Hz,准确率及实时性都能满足交通流量统计要求。该算法框架可有效地提供夜间交通流量数据，为智能交通发展提供一定的技术支持。
{ISBN/ISSN}: 1006-9798
{Notes}: 37-1268/TS
{URL}: https://link.cnki.net/doi/10.13306/j.1006-9798.2022.02.009
{DOI}: 10.13306/j.1006-9798.2022.02.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 农业复杂环境下尺度自适应小目标识别算法——以蜜蜂为研究对象
{Author}: 郭秀明;诸叶平;李世娟;张杰;吕纯阳;刘升平
{Author Address}: 中国农业科学院农业信息研究所/农业农村部农业信息服务技术重点实验室;
{Journal}: 智慧农业(中英文)
{Year}: 2022
{Volume}: 4
{Issue}: 01
{Pages}: 140-149
{Keywords}: 目标检测;机器视觉;小目标;农业环境;蜜蜂;SSD;YOLOv3
{Abstract}: 农业生产环境中的目标识别对象常具有分布密集、体积小、密度大的特点，加之农田环境光照多变、背景复杂，导致已有目标检测模型无法取得令人满意的效果。本研究以提高小目标的识别性能为目标，以蜜蜂识别为例，提出了一种农业复杂环境下尺度自适应小目标识别算法。算法克服了复杂多变的背景环境的影响及目标体积较小导致的特征提取困难，实现目标尺度无关的小目标识别。首先将原图拆分为一些较小尺寸的子图以提高目标尺度，将已标注的目标分配到拆分后的子图中，形成新的数据集，然后采用迁移学习的方法重新训练并生成新的目标识别模型。在模型的使用中，为使子图识别结果能正常还原，拆分的子图之间需具有一定的重叠率。收集所有子图的目标识别结果，采用非极大抑制（Non-Maximum Suppression,NMS）去除由于模型本身产生的冗余框，提出一种交小比非极大抑制（Intersection over Small NMS,IOS-NMS）进一步去除子图重叠区域中的冗余框。在子图像素尺寸分别为300×300、500×500和700×700，子图重叠率分别为0.2和0.05的情况下进行验证试验，结果表明：采用SSD (Single Shot MultiBox Detector)作为框架中的目标检测模型，新提出的尺度自适应算法的召回率和精度普遍高于SSD模型，最高分别提高了3.8%和2.6%，较原尺度的YOLOv3模型也有一定的提升。为进一步验证算法在复杂背景中小目标识别的优越性，从网上爬取了不同尺度、不同场景的农田复杂环境下的蜜蜂图像，并采用本算法和SSD模型进行了对比测试，结果表明：本算法能提高目标识别性能，具有较强的尺度适应性和泛化性。由于本算法对于单张图像需要多次向前推理，时效性不高，不适用于边缘计算。
{ISBN/ISSN}: 2096-8094
{Notes}: 10-1681/S
{URL}: https://link.cnki.net/urlid/10.1681.S.20220314.1915.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 焊接机器人视觉系统标定方法
{Author}: 周江澔;刘子龙;张辰骁;早川真;方治超
{Author Address}: 东南大学机械工程学院;太仓旭莱自动化机械有限公司;
{Journal}: 机械设计与制造工程
{Year}: 2022
{Volume}: 51
{Issue}: 03
{Pages}: 47-52
{Keywords}: 焊接机器人;机器视觉;标定方法;实验验证
{Abstract}: 为保证焊接机器人视觉系统精确运行，综合各标定方法对系统中所涉及坐标系及其之间的关系进行标定。对相机进行标定，确定相机内外参数矩阵；进行机器人手眼标定，用于确定视觉系统中相机坐标系（CC）与机器人末端坐标系（CE）之间的转换关系；进行机器人工具坐标系标定，确定机器人工具坐标系（CT）与机器人基座坐标系（CB）之间的转换关系。最后通过实验验证了各标定方法的可行性。
{ISBN/ISSN}: 2095-509X
{Notes}: 32-1838/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzb2KKfa1brpD4kkpbZfmQCD8NeeR6eyiXB5YhZ0ANHZ5T8yty-LPTwYI6WPLGpgZ0pr9IWRDINj2iRP7_P__p5qyM3zMCakSsFZUwAQPT5IPteHDX_QEC9RiqY-x7ua6Zd9kF846XluaoqWjgqiwNmk5BIFqAByUF8Wcq1XR-NHIH5gQQPxkEQi3oWFOt_4xo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的点云分割技术研究
{Author}: 杨泽宇
{Tertiary Author}: 饶云波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 点云分割;点云分类;注意力机制;深度学习
{Abstract}: 随着人工智能的发展,计算机视觉得到了前所未有的研究和应用。三维点云分割作为计算机三维场景理解的基础,已经成为近年来的研究热点。精准的点云语义预测是自动驾驶、医疗检测、智慧城市等领域的关键技术,有着重要的应用意义。随着点云数据的丰富和点云算法的广泛研究,目前大多数点云网络已解决无序性、非结构化等挑战,但仍然存在语义预测不够精确,场景数据利用不完全等问题。本文围绕上述问题,开展基于融合特征和基于注意力机制的点云语义分割算法研究。研究内容包括融合RGB特征的点云分割算法,基于Transformer的点云学习网络和基于通道自注意力的点云分割网络,主要内容和贡献如下:(1)针对场景数据利用不充分,场景分割的准确率低等问题,提出了融合RGB特征的点云语义分割网络。该算法将图像RGB特征根据空间投影融合到点云数据中。通过点云相对位置信息提取潜在的语义信息,设计新颖的交叉空间注意力模块,搭建分割网络整体架构。算法在Scan Net数据集上达到了68.2%的分割效果,相比于Point Net++提高了13.7%,验证了该算法对场景数据的精准分割。(2)针对点云学习泛化能力差,特征语义无法精准提取的问题,提出了基于Transformer的点云学习网络。该算法利用Transformer中的自注意力机制,设计了适应点云的自注意力结构,并引入特征位置编码,分别对点云的特征内关联性和特征之间关联性进行学习。网络在Shape Net数据集上mIoU值为84.2%,相比于Point Net提高了0.5%。在Model Net40数据集上分类精度达到93.3%,S3DIS数据集上mIoU取得60.6%的成绩,相比于Point Net++分别提高了2.6%和6.1%,证明了本章网络具有较强的点云分类能力和分割能力。(3)针对自注意力机制在点云学习中计算效率低的问题,设计了基于通道自注意力的点云分割网络,优化注意力结构使得网络计算效率得到提高。此外,为进一步有效学习局部区域的点云特征,采用基于余弦距离的K邻近算法对点云特征进行分组,设计了点云局部特征抽象模块,使网络可以掌握更加丰富的特征语义信息。网络在Shape Net数据集上取得了85.9%的成绩,较基于Transformer的点云学习网络和Point Net++高出1.7%和0.8%,证明了本网络在分割任务上具有较强的预测能力和泛化能力。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.002370
{DOI}: 10.27005/d.cnki.gdzku.2022.002370
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的AlexNet网络煤矸石检测系统
{Author}: 何江;张科星
{Author Address}: 太原学院;
{Journal}: 煤炭技术
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 205-208
{Keywords}: 机器视觉;煤矸石;噪声抑制;AlexNet
{Abstract}: 针对传统的煤矸石检测方式成本较高、识别准确率较低、适用性较差等不足，经分析实际检测要求，设计了一种基于机器视觉和AlexNet网络的煤矸石检测系统。该系统通过工业相机来采集传送带上煤矸石图像，利用直方图均衡化和二阶微分线性算子来加强图像对比度与锐化效果，并使用高斯滤波来抑制图像噪声，进而获取更具辨识度的图像，最终运用AlexNet网络实现煤矸石的识别与定位。结果表明，该系统识别准确率达到了95.90%，准确率较高，且实现过程较为简单，适用性良好。
{ISBN/ISSN}: 1008-8725
{Notes}: 23-1393/TD
{URL}: https://link.cnki.net/doi/10.13301/j.cnki.ct.2022.03.049
{DOI}: 10.13301/j.cnki.ct.2022.03.049
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与PLC的零件测量系统设计
{Author}: 刘团结;胡艳丽;贾群;殷杰
{Author Address}: 淮南师范学院机械与电气工程学院;
{Journal}: 蚌埠学院学报
{Year}: 2022
{Volume}: 11
{Issue}: 02
{Pages}: 46-50
{Keywords}: 零件测量;机器视觉;系统设计;图像处理;上位机;可编程控制器
{Abstract}: 针对传统的测量技术在零件尺寸测量方面效率低、精确度不高的问题，设计一种以S7-1200PLC为控制器并与机器视觉相结合的零件测量系统。该系统由机械执行、电气控制、图像处理、上位机软件四部分组成，形成了集零件传送、测量、剔除、回收的一体化智能测量系统模型。最后对实际零件进行检测实验，结果表明该系统运行稳定、测量误差小、效率高，系统抗干扰能力强。
{ISBN/ISSN}: 2095-297X
{Notes}: 34-1321/Z
{URL}: https://link.cnki.net/doi/10.13900/j.cnki.jbc.2022.02.010
{DOI}: 10.13900/j.cnki.jbc.2022.02.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于中值点Hough变换玉米行检测的导航线提取方法
{Author}: 李霞;苏筠皓;岳振超;王思超;周海波
{Author Address}: 天津理工大学天津市先进机电系统设计与智能控制重点实验室;天津理工大学机电工程国家级实验教学示范中心;天津理工大学机械工程学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 05
{Pages}: 167-174
{Keywords}: 机器视觉;特征点提取;作物行检测;导航线提取;Hough变换;导航
{Abstract}: 为解决机器视觉对早期玉米苗带在多环境变量下导航线提取耗时长、准确率低的问题，该研究提出了一种基于中值点Hough变换作物行检测的导航线提取算法。首先，改进了传统的2G-R-B算法，再结合中值滤波、最大类间方差法和形态学操作实现土壤背景与玉米苗带的分割。其次，通过均值法提取玉米苗带特征点，然后采用中值点Hough变换拟合垄间两侧玉米苗列线，最后将检测出的双侧玉米苗列线为导航基准线，利用夹角正切公式提取导航线。试验结果表明：改进的灰度化算法能够正确分割玉米苗带与土壤，处理一幅640×480像素彩色图像平均耗时小于160ms，基于中值点Hough变换检测玉米苗列再提取导航线的最大误差为0.53°，相比于传统Hough变换时间上平均快62.9ms，比最小二乘法平均精确度提高了7.12°，在农田早期玉米苗带多环境变量影响因素下导航线提取准确率均达92%以上，具有较强的可靠性和准确性。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvx8TmA18SkF_M_H3pjX1Yc4YQBUKw4vbxcMMcMc5h9t1Q43bKL2X_irnhGh8Bj__mdupbAYSkkTw7L0ahuF8RoqtMeivQC0uYMjIW6jHUnlxedQlEEKalguZObz6V-paipKK68xkmuMl5ykT1Rg0JSpEpwMA_31wx3XkA687-i6fKsRKSUvJ_8EXaJRGmGVB4g=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的室内机器人环境感知与理解关键技术研究
{Author}: 罗皓楠
{Tertiary Author}: 唐振民
{Publisher}: 南京理工大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 机器视觉;环境理解;语义分割;三维空间感知;注意力机制;噪声滤除
{Abstract}: 近年来,随着我国人均寿命的提升以及生育率的下降,老龄人口的抚养困境已成为不可忽视的社会问题。室内服务机器人可以为解决这一困境提供有效方案,同时还能为正常人的家庭生活带来便利,从而满足人们对于美好生活的追求。室内机器人环境感知与理解任务的核心是感知并解析视觉传感器捕捉到的场景视觉特征,从而使机器人可以有效理解诸如周遭物品的位置与类别、候选的可通行区域等环境信息,并遂行相应基于视觉的推理和导航动作。现今室内服务机器人研究面临的部分关键挑战包括:第一,机器人从环境中直接捕获的底层图像信息与人类可理解的高层语义信息间存在鸿沟,为了更好的完成用户下达的任务,室内机器人环境感知与理解系统应具备场景分割语义信息提取与利用能力。第二,标签噪声在室内服务机器人的实际应用过程中不可避免,在机器人不断运行的过程中,噪声所造成的累计误差将变得难以承受,因此针对于室内机器人环境感知与理解系统的噪声鲁棒算法亟待开发。第三,室内机器人系统运行于三维空间,但考虑到二维平面相机的高效性和廉价性,现有室内机器人系统往往不配备昂贵的三维全景扫描设备。三维场景信息的缺失将导致系统无法具备空间位置判断和避障能力。基于上述挑战,本文拟以提高室内服务机器人遂行任务时的准确度和稳定性为出发点,研究具有多种场景视觉特征处理功能的高智能化室内服务机器人所涉及的若干关键技术。本文将任务分解为视觉推理和机器人导航两部分,通过对环境彩色图像特征、场景语义分割特征、三维空间特征等视觉特征的融合与利用,展开对以上问题的研究。具体的研究内容和成果包括以下几个方面:(1)提出一种可适用于室内机器人环境感知与理解任务的快速场景语义分割框架,用以感知场景内物体的像素级语义标签,从而缩短系统底层视觉输入与所寻求目标之间存在的鸿沟。在构建过程中,为解决语义分割过程耗时过长的问题,提出一种基于子区域分块的双分支算法以最大限度减少非必要的时间损耗。该算法通过将环境输入图像分块的方式,对不同复杂度的子区域采取不同的语义分割策略。首先将当前帧图像与其对应关键帧图像均等分为若干子区域,并将它们进行配对。提取每个子区域对的光流,而后构建决策网络,根据光流信息判断子区域需要采用的分割策略,并将这些子区域送入不同的通道进行处理。最后将各子区域的分割结果拼接起来,完成对当前帧的语义分割。与传统图像语义分割算法相比较,该框架在分割准确率(mIoU)仅降低0.7%的情况下,将分割速度大幅提升到了57FPS。(2)提出一种基于同伴学习的层次式样本选择算法作为系统的预处理环节,通过滤除数据集中含有噪声的标签,使本文其他章节方法免于噪声问题的困扰。首先构建了两个平行的网络分支,每个分支通过交换小误差样本集来达到过滤视觉推理过程中噪声样本的目的。对于机器人导航子算法,设计了一种层次式的鲁棒学习网络,该网络可以在路径和动作两个粒度上进行噪声选择,从而更精细的滤除标签噪声,以最大限度保留有效训练样本。对于系统级联合噪声学习方面,将视觉推理与机器人导航两模型首尾连接起来,以视觉推理的有效样本标签作为输入,同时冻结视觉推理模型参数,使用强化学习的方法在整个室内机器人系统层级上进行鲁棒训练。(3)提出一种基于场景语义分割的视觉注意力机制,该机制利用提取的场景语义分割图作为场景高级语义信息与环境输入特征进行有机融合,使得模型可以将注意力更多的关注于目标语义相关的图像区域。首先通过语义分割掩码的指导将图像分解为多个不同的子区域,而后使用卷积神经网络编码这些子区域的特征,并使用这些子区域特征来构建基于分割的视觉注意力模型。接着在机器人导航子算法中,利用场景语义分割信息辅助机器人导航模型的训练。最后,使用强化学习算法对整个系统的参数进行调整。(4)提出一种基于深度与分割联合注意力的视觉推理和机器人导航算法,该方法将感知到的当前环境语义分割和场景深度信息作为系统辅助输入,在提高局部特征可辨识度的同时增加了三维空间感知能力,使得构建的室内机器人环境感知与理解系统可以更好的在相对复杂的三维环境中进行探索。首先将输入的深度图编码为三通道特征,而后在分割掩码的指导下,深度图特征与彩色图像特征分别被分解为不同的子区域,我们使用这些子区域特征来构建基于深度与分割联合注意力的视觉推理模型。接着在机器人导航子算法中,本文将语义分割信息与场景深度信息进行有机融合,共同指导机器人导航模型的训练过程。最后,一种基于强化学习的联合训练机制被用来在系统级调整模型参数。通过上述研究工作的开展,本文提出基于视觉的室内机器人环境感知与理解任务涉及的若干关键算法,通过详尽的对比实验验证了本文提出各算法的有效性,未来这些算法有望被应用于真实的室内机器人系统中。
{URL}: https://link.cnki.net/doi/10.27241/d.cnki.gnjgu.2022.000039
{DOI}: 10.27241/d.cnki.gnjgu.2022.000039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的多类型工件测量系统研究
{Author}: 刘志毅;杨桂华;唐卫卫
{Author Address}: 桂林理工大学机械与控制工程学院;
{Journal}: 机床与液压
{Year}: 2022
{Volume}: 50
{Issue}: 04
{Pages}: 6-12
{Keywords}: 机器视觉;工件测量;多项式插值;Hough变换
{Abstract}: 综合应用光电技术、数字图像处理技术和计算机技术，以薄片型机械零部件为主要测量对象，开发一套工件尺寸测量系统，主要包括照明系统、图像采集系统、图像处理系统和尺寸测量系统。根据检测要求，采用Canny算法进行边缘检测粗定位和8个方向模板的改进亚像素检测技术获得工件精确轮廓信息，再对轮廓进行分割和选择，采用Hough变换完成工件的二维尺寸测量，并利用Halcon与C++联合编程实现多类型工件二维尺寸测量系统。实验结果表明：直线和圆测量中，Hough变换测量值与千分尺测量值平均误差为0.042 mm;平均耗时32.543 ms。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy1J4oaLWxuGcslFoZCQuexuxg39cqTvWBKVYGpNM9GsmV9lBLN3SYQV6quNiOq2deRWbqC7mzZKkfxJmRI_3bJU6qzQTtnUUM3W8TfWrHMrpJ3pZTvK0vosIkcIo-9Vn_NAOy33v0j6B7owSC8eSP-fXxRU69MtIw0Yy9cuC6DJLkVkmnaQUwkuEQgKGEeGtU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的瞄准镜缺陷检测系统设计
{Author}: 王坚;张义兵;陈双;何义
{Author Address}: 湘潭大学自动化与信息工程学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 02
{Pages}: 36-41
{Keywords}: 机器视觉;缺陷检测;瞄准镜;鸡丝线段定位
{Abstract}: 为实现机器视觉技术在瞄准镜缺陷检测中的应用，开发了一套基于机器视觉的瞄准镜缺陷检测系统。采用局部直方图均衡化和自适应二值化消除图像不同区域的亮度差异，提高图像对比度并找出产品的骨架。针对直接使用累计概率霍夫变换无法找出所有鸡丝线段的问题，提出了一种以累计概率霍夫变换为基础，通过正六边形平移扩散对所有鸡丝线段实现定位的方法。经实验测试，软件系统在离线机上稳定运行，没有出现卡顿现象，也没有抛出异常，检测识别率可达94%，满足了生产要求，目前已应用于实际生产，并取得了良好的效果。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy1J4oaLWxuGcslFoZCQuexuxg39cqTvWChTXZ18klWzU5oN12L0xWwzpTsYdbeGCtLVDuPGxynaBB__kQWlGx9uI8U2TmJ0rHJo2IiHWQTL_6ZTMyqAhHUnwEBJ9DnYGwc4sS2KOJZaA4Wd1O6h7c9GcT3wkkihyHe958wMboi42zPHciOpj5OG3KpBF2jYhM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于多线激光的轮胎花纹深度测量方法研究
{Author}: 徐仕东;毕远伟;孙海卫
{Author Address}: 烟台大学计算机与控制工程学院;
{Journal}: 应用激光
{Year}: 2022
{Volume}: 42
{Issue}: 02
{Pages}: 64-70
{Keywords}: 三维重建;多线激光;机器视觉;图像处理
{Abstract}: 针对轮胎花纹深度测量中存在传统手工方法效率低下及单线激光测量适应性不高的问题，提出一种基于多线激光的轮胎花纹深度测量方法。该方法通过测量装置获取带有多线激光条纹的轮胎花纹图像，再通过三角测量技术得到轮胎表面激光条纹中心点的三维点数据。对获取到的点云数据进行处理，筛选出轮胎凹槽点和轮胎胎面点。将轮胎凹槽点拟合成一个曲面，依次计算胎面点到凹槽曲面的距离，获得每条凹槽的深度，以判断轮胎磨损状况。试验结果表明，该方法简单高效，鲁棒性强，能够准确测量出轮胎花纹的深度，与深度尺测量结果的差值在0.1 mm以内，可以满足轮胎花纹深度测量的要求。
{ISBN/ISSN}: 1000-372X
{Notes}: 31-1375/T
{URL}: https://link.cnki.net/doi/10.14128/j.cnki.al.20224202.064
{DOI}: 10.14128/j.cnki.al.20224202.064
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于无监督域适应的低空海面红外目标检测
{Author}: 宋子壮;杨嘉伟;张东方;王诗强;张越
{Author Address}: 北京遥感设备研究所;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 04
{Pages}: 127-134
{Keywords}: 机器视觉;红外探测器;无监督域适应;梯度反转层;稳定训练;目标检测
{Abstract}: 提出一种基于无监督域适应的低空海面红外目标检测方法。首先利用图像翻译网络将源域图像翻译为目标域图像并共享标签。其次在YOLOv5s目标检测网络中使用梯度反转层优化网络提取特征的域间适应性。此外利用最大均值差异损失进一步缩小从网络中提取的不同红外探测器图像的特征分布。最后采用AdamW异步更新优化算法进一步提高模型在训练过程中的稳定性与检测精度。将所提方法在不同红外探测器采集的低空海面红外船只与无人机数据集中进行实验。实验结果表明，相较于传统有监督学习方法，所提方法有效降低了人工标注成本，且源域检测精度提高6.56个百分点，目标域检测精度提高2.62个百分点，有效提升目标检测模型在不同红外探测器间的泛化能力。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw5FwuFOSATK04MJIxwckOU2fTWCFmUwbwkMxqEfKJPIAAe_WsbtIHkKOhuN242T0kNC5Z0YeoC6OQT6_ETj07H4sz6ow75iGEk9k5v-FDU74abIJ5uUMI3dASHlN84WSqboEHpLSONdSPdZaIJvFF4yKlBjEyd1J0p6AYmNngwLwJYUMKmUsowRx-KC25ftNM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 消毒机器人目标识别定位与包围盒优化
{Author}: 叶雅欣;王佳盛;吴烽云;陈思宇;艾璞晔;邹湘军;李兰云
{Author Address}: 华南农业大学工程学院;佛山市中科农业机器人与智慧农业创新研究院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 04
{Pages}: 346-354
{Keywords}: 机器视觉;视觉定位;点云拼接;Mask R-CNN;主成分分析
{Abstract}: 为实现公共场所定点消毒目标的识别与定位，确定消毒范围，首先采用深度相机获取公共场所的彩色图像和三维点云；其次训练Mask R-CNN深度网络，进行消毒目标的分类、检测与实例分割，进而获取目标点云；然后通过采样一致性初始配准（SAC-IA）和迭代最近邻点（ICP）精配准方法实现不同视角点云的拼接，获取完整的消毒目标点云；最后基于主成分分析（PCA）优化点云的包围盒。实验结果表明，基于Mask R-CNN目标检测的各类别平均精度（mAP）达到0.968，实例分割的平均交并比（IoU）达到0.879，目标包围盒的表面积和体积优化率分别达到了29.2%和28.8%。本研究能有效识别与定位消毒目标，为不同消毒目标采用不同消毒方式提供分类依据，同时能有效减小消毒范围，提高消毒作业效率。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzjD0gc4plV4rK5veB3KURlVfk6QLwyvbXkQekeS7kKKxx7NLSVzSwjuB4FiYRWqO78fJxiKcXGCsrsqMovD8OLXXwjjaaGIIItRIogY3xY6yYwpdgzX1lHGFYW-7E32rh6XmJglmys6_Wift7dEo_0iphzP1VdBw2LoJQCxm9jZelbuD15htQTwcX3jFkdpNs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种基于颜色模型的火灾识别系统
{Author}: 刘洲岐;王雷;刘聪;黄晋;王振
{Author Address}: 山东理工大学计算机科学与技术学院;
{Journal}: 山东理工大学学报(自然科学版)
{Year}: 2022
{Volume}: 36
{Issue}: 03
{Pages}: 1-6
{Keywords}: 视频监控;火焰识别;计算机视觉;特征提取;高斯混合模型
{Abstract}: 相比较传统以温度、烟雾等传感器为主的火灾检测方法,通过对火焰的成像特征进行分析,采用视频检测火灾。针对可见光下的火焰特征,基于计算机视觉技术,设计并实现了一种基于颜色模型的火灾识别系统。本系统以火灾检测算法为核心,设计并实现了简洁、易用的可视化的界面,将多种图像处理算法融入其中,并通过实验数据测试表明该系统的火灾识别平均准确度能够达到96%以上,与传统算法相比具有更低的误报率和更高的识别灵敏度。
{ISBN/ISSN}: 1672-6197
{Notes}: 37-1412/N
{URL}: https://link.cnki.net/doi/10.13367/j.cnki.sdgc.2022.03.013
{DOI}: 10.13367/j.cnki.sdgc.2022.03.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 雷达与视觉特征融合的车辆检测方法
{Author}: 郭熙;胡广地;杨雪艳
{Author Address}: 西南交通大学机械工程学院;
{Journal}: 物联网技术
{Year}: 2022
{Volume}: 12
{Issue}: 02
{Pages}: 7-11+15
{Keywords}: 车辆检测;雷达;机器视觉;梯度方向直方图;数据融合;神经网络
{Abstract}: 当前车辆检测算法仅使用物理特征或几何特征对目标进行分类,特征维度不够丰富导致检测不够准确。基于以上问题,文中提出了一种基于雷达与视觉特征融合的车辆检测方法,同时使用了目标的物理特征与几何特征。雷达特征选用速度、加速度等物理特征,在雷达摄像头数据融合后得到雷达目标点在图像上的感兴趣区域,在感兴趣区域上提取梯度方向直方图特征。计算梯度方向直方图的统计特征作为视觉特征,包括标准差、中位数、平均值。构建输入为雷达与视觉融合特征的神经网络R-V-DenseNet,制作数据集并训练该网络。在测试集上的实验结果证明,R-V-DenseNet相比传统的HOG-SVM方法及单传感器特征检测方法准确率有所提高,检测较为准确。
{ISBN/ISSN}: 2095-1302
{Notes}: 61-1483/TP
{URL}: https://link.cnki.net/doi/10.16667/j.issn.2095-1302.2022.02.002
{DOI}: 10.16667/j.issn.2095-1302.2022.02.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于3D视觉的风电塔筒焊缝检测系统设计
{Author}: 肖苏华;乔明娟;赖南英;罗文斌;刘普京;曹应斌;王志勇
{Author Address}: 广东技术师范大学机电学院;湖南恒岳重钢钢结构工程有限公司;
{Journal}: 电子测量与仪器学报
{Year}: 2022
{Volume}: 36
{Issue}: 02
{Pages}: 122-130
{Keywords}: 机器视觉;风电塔筒;焊缝检测;高精密运动;点云处理
{Abstract}: 为满足风电机组塔筒行业对焊缝外观质量缺陷检测高效性、精确性的需求，采用3D机器视觉技术研制了基于风电塔筒焊缝外观质量缺陷检测系统。首先，通过点云滤波、点云分割、点云精简对采集的点云数据进行预处理，确保后期缺陷评判的准确性；其次，对三维数据进行轮廓切片化处理以及断点拟合处理，得到轮廓特性；再次，采用递归粗提取改进算法提取特征点，进行缺陷评判，获得焊缝外观缺陷检测结果；最后，根据系统焊缝缺陷评判流程及标准，选取典型的焊缝样板进行焊缝宽度、焊缝错边以及焊缝直线度测试，焊缝检测精度可达0.001 mm,速度为当前人工检测速度的3倍，检测结果表明，系统具备高准确性、高速度和高精度特性，能代替人工检测，具有良好的应用前景。
{ISBN/ISSN}: 1000-7105
{Notes}: 11-2488/TN
{URL}: https://link.cnki.net/doi/10.13382/j.jemi.B2104437
{DOI}: 10.13382/j.jemi.B2104437
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于轻量型卷积视觉Transformer的锑浮选工况识别
{Author}: 陈奕霏;蔡耀仪;李诗文
{Author Address}: 湖南师范大学工程与设计学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 06
{Pages}: 259-271
{Keywords}: 机器视觉;锑浮选;工况识别;计算机视觉;轻量型卷积神经网络;视觉Transformer
{Abstract}: 依靠人工观测锑浮选泡沫特征进行锑浮选工况识别，主观性强、误差大，严重制约浮选性能。基于计算机视觉的识别方法成本低、效果好。针对以上问题，提出一种基于轻量型卷积视觉Transformer(L-CVT)的锑浮选工况识别方法。通过Transformer层的堆叠代替标准卷积中矩阵乘法来学习全局信息，将卷积中的局部建模更替为全局建模，同时引入轻量型神经网络MobileNetv2中的子模块，减少计算成本。所提方法解决了卷积神经网络（CNN）忽略浮选图像内部长距离依赖关系的问题，同时也弥补了视觉Transformer(VIT)缺乏归纳偏置的缺点。实验结果表明，基于所提方法的锑浮选工况识别准确率最高可达93.56%，明显高于VGG16、ResNet18、AlexNet等主流网络，为锑浮选数据在工况识别领域提供了重要参考。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220211.1748.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的田间小麦开花期判定方法
{Author}: 刘平;刘立鹏;王春颖;朱衍俊;王宏伟;李祥
{Author Address}: 山东农业大学机械与电子工程学院;山东农业大学生命科学学院;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: 03
{Pages}: 251-258
{Keywords}: 田间环境;小麦;花期判定;图像识别;综合颜色特征;超像素分割
{Abstract}: 针对大量小麦育种材料花期难以精准、快速检测的问题，提出了一种基于综合颜色特征和超像素分割算法的小麦开花期判定方法。首先，根据光照强度及图像清晰度对综合颜色特征的过红颜色分量、HSV颜色空间的S分量和红绿归一化颜色分量自适应调节，增强小花和小穗的差异性。其次，基于中心距离函数和灰度变化函数改进超像素分割算法的聚类规则，获得由同质特征的相邻像素组成的图像区域。随后，优化图像区域路径搜索算法实现各图像区域精确分割，通过灰度和对比度指标完成各图像区域分类，实现小花与小穗的精准、快速分割，并根据小花与小穗的比例完成开花期判定。实验结果表明，本文所提出算法平均计算时间为0.172 s,小花平均识别精度为91%,小穗平均识别精度为90.9%,预测开花率与实际开花率的平均差值仅为1.16%,满足田间小麦开花期判定基本要求。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.S.20220125.1720.039
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆柱形蜂窝陶瓷侧面裂隙检测
{Author}: 毛卫平;高伟;顾寄南;雷文桐;胡君杰;方新领
{Author Address}: 江苏大学机械工程学院;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 02
{Pages}: 117-122
{Keywords}: 机器视觉;圆柱形蜂窝陶瓷;图像处理;侧面裂隙;缺陷检测
{Abstract}: 针对圆柱形蜂窝陶瓷侧面裂隙检测困难问题，提出一种基于机器视觉的检测方法。通过对侧面裂隙检测需求分析，选用COMS相机和LED白色平行光源。对采集的图像进行滤波处理，选择中值滤波去除椒盐噪声。根据图像的特点选择ROI区域，使用全局阈值分割算子threshold进行图像分割，采用膨胀方法连接断裂区域。在提取表面缺陷时，先用connection算子对图像区域分割，再选择面积、长度和宽度3个特征对表面缺陷进行提取。将本检测方法与人工检测方法比较分析，试验结果表明在检测样品均为50个时，本方法检测合格、不合格和混合样品所需时间分别为12.50、6.64和10.58 min,具有更高检测速度，实时性更好；准确率分别为96%、84%和90%,准确率还有待提升，需要进一步的研究。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108082
{DOI}: 10.19651/j.cnki.emt.2108082
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉应用的电力设备识别技术研究
{Author}: 许臻;吴王强;罗雪红;朱大伟;陈相吾
{Author Address}: 陕西省地方电力(集团)有限公司渭南供电分公司;陕西能源研究院有限公司;
{Journal}: 电子制作
{Year}: 2022
{Volume}: 30
{Issue}: 02
{Pages}: 23-25
{Keywords}: 机器视觉;电力设备;识别技术
{Abstract}: 电力行业作为社会与经济建设中的中流砥柱,推动电力行业高质量发展就成为助力社会经济发展的主要因素。电力系统是否能够安全、稳定的运行,直接关系到国民经济的发展。各种电力设备在日常运行的过程中极为容易受到各种因素的干扰,一旦电力设备发生故障,极为容易影响电力系统整体的稳定性。对于当前复杂的电力系统来说,如果仍旧沿用传统人工巡检模式,不仅效率无法满足要求,同时也会造成大量的人力、物力、财力浪费,且极为容易因为人工巡视不到位,导致一些潜在问题没有及时发现的问题。机器视觉技术的应用,能够综合利用图像信息技术针对有关数据进行分析,基于机器视觉进行电力设备识别,能够真正建立智能化、自动化的监测系统。鉴于此,本研究主要围绕基于机器视觉应用的电力设备识别技术进行了阐述,并分析了基于机器视觉应用的电力设备识别系统的构建方法,仅供参考与借鉴。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2022.02.003
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2022.02.003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的新冠肺炎CT图像检测方法研究
{Author}: 王光宇
{Tertiary Author}: 赵曙光
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;医学图像;新冠肺炎;图像分割;图像分类
{Abstract}: 新冠肺炎是一种新型的呼吸道传染病,它的出现对世界的发展和人类的生存造成了严重的威胁。新冠肺炎患者的肺部CT图像具有特异性,若能加以正确判读既可对核酸检测的结果进行补充,又可提高诊断的准确性。但由于该类图像复杂且量大,可胜任的医生相对不足,目前对其进行判读的效率和准确性都还不能满足需要,因此人们迫切需要新的技术和方法用于其辅助诊断。计算机视觉技术的出现使计算机有望能够像人眼、人脑一样识别、理解图像,因而已被广泛和成功地应用于医学图像处理领域。在当前新冠肆虐的危急形势下,研究基于深度学习的新冠肺炎检测、诊断方法和技术,既具有较好基础和可行性,又十分必要和迫切。基于上述情况,本文对基于深度学习的新冠肺炎CT图像的分割、分类方法,进行了较系统、深入的研究。具体工作主要包括:首先,构建了一个由5000张COVID-19患者肺部CT图像及对应四标签掩模图(mask)组成的分割数据集以及一个由10000张正常肺部CT图像、10000张COVID-19肺部CT图像、10000张其它肺炎肺部CT图像构成的分类数据集。其次,构建Lung Seg-Net模型对CT图像数据进行预分割处理,去除数据集图像中除肺部区域外的背景区域,为后续工作奠定基础。之后,在分割数据集上,利用U-Net、U-Net++、U-Net+Res Net101以及Deep Lab V3+模型分别进行分割实验。并在Deep Lab V3+模型中引入卷积注意力模块以及深度可分离卷积模块以提升模型性能。最后,利用Mobile Net V1、VGG16以及Res Net50三种有监督分类模型对分类数据集进行训练和实验。并将基于GAN的SSGAN半监督分类模型引入到肺炎分类任务中,以实现利用少量标签数据完成对图像进行准确分类的目的。本文对所提出的改进方法均进行了实验验证,并与多种同类方法进行了对比,证明了其可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000328
{DOI}: 10.27012/d.cnki.gdhuu.2022.000328
{Database Provider}: CNKI

 