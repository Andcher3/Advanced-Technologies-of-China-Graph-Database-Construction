{Reference Type}: Thesis
{Title}: 基于功能语言学的情感标注研究
{Author}: 郑梅园
{Tertiary Author}: 李学宁
{Publisher}: 广西民族大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 手机产品评论;情感标注;系统功能语言学;评价系统理论;双语情感词词典
{Abstract}: 本研究关注情感语料中形容词性情感词的中英双语对齐问题,将系统功能语言学的理论与情感分析学科结合,设计了一套围绕形容词性情感词,关注情感词的评价对象、评价属性、评价程度等方面的标注方案,旨在解决如何对齐中、英手机产品评论语料中情感词的关键问题。标注方案中将系统功能语言学的归一性、评价系统理论的态度资源系统和级差系统融入标注方案,设置了“评价对象(ENT)”、“评价属性(ATTR)”、“积极评价(POS)”、“消极评价(NEG)”、“中性评价(NEU)”、“鉴赏类评价(APP)”、“情感类评价(AFF)”、“判断类评价(JUD)”、“增强评价程度(HIG)”、“减弱评价程度(LOW)”、“聚焦评价(SHA)”、“虚化评价(SOF)”共12个标签。本研究采集了在东南亚市场占比排名前5的中国手机品牌(华为、小米、vivo、荣耀、OPPO)的中、英文语料。中文从国内的电商平台淘宝和京东采集,英文从东南亚知名电商平台Lazada和Shopee采集。中、英文初步采集语料分别为6993、7141条。经过对语料的清洗、词性标注、“形+名”词组(含形容词性情感词的情感语料,一条语料中可能含多个“形+名”词组)的提取,获得并标注了中、英文含形容词的语料数目为19258,8903。本研究采用人工标注与机器自动标注相结合的方式,完成了对中文2130词、共计99989词频,英文1489词、共计47721词频的标注。标注结果分别命名为中语料情感标注数据集和英文语料情感标注数据集。依据标注数据集分析了中、英双语标注结果的异同;统计了各标签词频;提取出了中、英文手机产品评论语料中的评价对象、评价属性常见词汇分类对齐表;计算了各情感词(评价词)与评价对象、评价属性、评价程度副词之间的共现和搭配强度。统计和分析发现,尽管中文标注的语料数量超过英文的2倍(中文19258:英文8903),标注的总词频方面中文也远超英文的2倍(中文99989:英文47721),但是标注结果中,各标签总词数上中文并没有比英文多出太多(中文2130:英文1489)。英文的“评价对象(ENT)”词数(303)更是反超了中文的“评价对象(ENT)”词数(206),英文的“判断类评价(JUD)”词数(27)也多于中文的“判断类评价(JUD)”词数(11)。研究结论如下,原始语料数量二者并无太大区别,提取获得含形容词的情感语料之后,中文数量远多于英文说明中文语料更长,提取出的情感语料更多;中英文语料最后标注的总词数数量差距,有标注的语料数量的影响,同时也体现了中文在评价用词方面更丰富于英文;英文的“评价对象(ENT)”、“判断类评价(JUD)”词数多于中文,体现了东南亚用户相比于国内的用户更关注手机的整体、部件等具体的表现,也更关注商家、客服人员、物流人员的服务态度。而国内的用户对于手机细节性能,如手机拍照的防抖功能等评价更到位,体现在中文的“评价属性(ATTR)”更多于英文。标注后的数据集和统计结果证明了标注方案的可行性,可用于后续语料库研究和双语情感文本的对齐翻译、双语情感词典的编纂等方面。同时对于国内手机产品拓展东南亚市场也具有重要借鉴意义。本研究的理论意义在于将语言学理论与语料标注实践相结合,是将理论应用于实践的一次有效探索。实践证明了系统功能语言学理论拓展了情感标注的维度和细粒度。研究的现实意义在于促进跨境电商平台产品评论的观点挖掘,便于跨境电商商家更好地了解顾客反馈,进而推动跨境电商的发展。本研究的创新在于将系统功能语言学的理论与情感分析相结合,设计出一套有效可行的情感文本标注方案,对情感标注进行了新的尝试。不仅关注情感词本身,也关注情感词所评价的对象、属性,关注情感词的态度分类,还关注情感词的情感评价程度,多维度地关注情感词,对情感词进行多方位的意义展现。此外,本研究还进行了标注技术自动化的尝试。本研究尝试了使用python编程进行语料处理和语料标注,对语料进行批量处理,使得效率得以提升,且标注一致性和准确率得以保证。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2024.000045
{DOI}: 10.27035/d.cnki.ggxmc.2024.000045
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自然语言生成预训练模型的研究及其在搜索引擎广告中的应用
{Author}: 齐炜祯
{Tertiary Author}: 周明;李厚强
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 预训练;自然语言生成;商用搜索引擎;生成式检索
{Abstract}: 本论文聚焦自然语言生成(NLG)技术在搜索引擎广告生成领域的应用,系统展示了从预训练模型设计到实际部署的完整流程,以及相关的学术创新。自然语言生成作为人工智能和计算语言学的核心分支,致力于将人类语言转化为机器可处理的表示形式,生成符合语义和上下文的目标文本,广泛应用于对话系统、新闻摘要和文章生成等领域。随着计算资源和数据处理能力的提升,基于自监督学习的预训练模型已成为NLG领域的主流方法,其通过大规模数据掌握语言结构,在特定任务中微调进一步提升性能。本研究以搜索引擎的广告关键词生成任务为核心,系统性探索了预训练基础模型优化特定任务的表现。在商用搜索引擎的盈利模型中,广告点击费用是关键来源,因此推荐精准相关的广告关键词对于提升用户体验和广告收益至关重要。本文创新性地提出了一种基于生成式检索与在线实时生成的广告关键词推荐系统,深入分析了预训练模型的设计与实现、推理效率优化以及场景适配等核心挑战,构建了从模型开发到大规模商用部署的完整流程,展示了 NLG技术在商业化应用中的前沿进展。在生成能力提升方面,本研究提出了 ProphetNet模型,通过引入未来信息预测机制显著提升了自然语言生成的效果。ProphetNet模型在跨语言生成、代码生成和对话系统等多个领域进行了充分验证,并在必应广告生成和微软小冰等实际应用中实现了成功部署。此外,ProphetNet为后续生成模型的拓展和信息回溯能力提供了坚实的结构性基础。在推理效率优化方面,本研究针对离线生成与在线生成的不同应用场景提出了专门的优化策略。对于离线生成任务,本研究设计了 EL-Attention机制,通过改进注意力机制实现了对任意Transformer结构的加速,同时确保生成质量。针对在线生成,本文将ProphetNet拓展为非自回归结构的BANG模型,以满足实时生成的低延时需求,大幅提升了非自回归生成的整体表现。在模型的实际应用优化方面,本研究针对离线和在线广告生成任务设计了ProphetNet-Ads与BANG-Ads两种解决方案。ProphetNet-Ads结合信息回溯算法,优化了生成式检索的效果,而BANG-Ads通过反向自步学习与混合蒸馏技术提升了非自回归生成的一致性和表现,在广告任务中接近自回归模型的性能。本论文最终实现了预训练模型在在线部署和离线部署中的性能和延时优化,为预训练模型的设计、优化和实际应用提供了完整的技术框架。研究成果对未来搜索引擎广告生成技术的发展提供了重要的学术参考和应用价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2024.001280
{DOI}: 10.27517/d.cnki.gzkju.2024.001280
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 智能辅助初等数学在线学习平台关键技术研究与实现
{Author}: 丁克玉
{Tertiary Author}: 陈恩红;胡国平
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 辅助学习;大规模语言模型;多模态;自动推理;推荐系统;深度学习
{Abstract}: 人工智能的研究目标是理解人类智能的实质并研发出一种新的能以人类智能相似的方式做出反应的类人智能系统。智能辅助学习技术旨在借助人工智能相关技术为学生和老师提供便捷、高效、个性化的因材施教的教学方式,减轻教与学负担的同时提高学习效率和质量,具有巨大研究价值和应用前景。基础教育是人类自身学习提升智慧的最主要阶段,研发面向数学基础教育的理解、答题、推荐系统是推动类人智能核心技术与系统研究的关键项目,同时也是验证类人智能进展水平的最佳方式。然而在实际场景中,我们仍然面临巨大挑战:深度学习建模需要的大批量数据难以获取;大规模语言模型还存在一定程度的“幻觉”问题;图表类题目推理困难的问题;推理过程使用超纲知识问题;传统的推荐系统往往只能在有限的题库中进行推荐,并且不能进行在线优化。所以说数学科目的形式化表述问题、语义解析问题、可靠的自动推理问题、多模态题目解答以及精准的题目推荐是研究的重点。针对上述问题,本文受到国家重点研发计划(2018YFB1005105)《基于大数据的类人智能关键技术与系统》项目的支持,针对这些问题开展相应的研究工作,具体如下:1)提出了一种基于VCF的表示方法和双编码结构语义解析方案针对基于深度学习相关方法给出的数学题目向量化表示不能进行形式化推理,以及采用传统一阶谓词逻辑表示方法标注成本过高的问题。本文提出了一种基于VCF(verb combination formula)表示方法,该表示方案定义简单容易理解,易于开展大规模标注,使得计算机可以方便的进行自动求解。对于跨越多个句子的语义信息抽取效果不好的问题,本文发现特定的多个句子一起协同理解是正确理解数学题目相关语义的关键。因此,本文提出了双编码语义分析模型(DESP、Double Encoder Semantic Parser),同时引入了词级别选择机制,较好的解决了数学题目的形式化表示问题。2)构建可显式使用数学知识的Neural-Symbolic推理系统针对数学题目的自动推理问题,为了能够显式的使用数学知识,融合符号主义的推理优势与链接主义的学习优势,提出了基于Neural-Symbolic的推理系统,该系统能够显式的使用数学领域的知识,推理系统能够知道自己能不能对当前的题目进行推理,推理是否正确。同时也不会像传统的神经网络模型那样不能给出具体的推理步骤和路径,也可以解决大规模语言模型中出现的“幻觉”问题,对错误的题目和不会解答的题目也会拒绝给出解答。本文提出的Neural—Symbolic推理系统,参数量只有大模型方案的千分之一,在公开的相关数学科目答题集合上取得了 SOTA的效果。3)提出了基于多任务协同学习的多模态解题大模型方案当前的数学教学中存在大量的包含多模态信息的数学题目,为了解决数学题目中包含图像、表格等非文本信息的数学题目以及进一步提升系统的数学解题能力,本文开展了基于多模态大模型的解题技术研究,提出了跨模态的注意力机制和基于多任务协同学习的多模态大模型的构建方案。对比了当前国内和国外的一流大模型如:ChatGPT、GPT4、GPT4-Turbo、文心一言4.0等在初等数学任务的效果,结果显式我们构建的多模态解题大模型在初等数学答题任务上取得了较好的效果,且在小学、初中、高中各学段效果下降幅度较低,稳定性更好。4)提出了基于用户反馈的自进化生成式推荐系统方案针对传统推荐技术在数学试题推荐中存在的不能在理解题目和解答过程的情况下聚焦到对应的关键错误步骤进行推荐,不能满足个性化的推荐,不能自己生成新的题目进行推荐,不能根据用户的反馈在线自进化等问题,提出了基于用户反馈的自进化生成式推荐系统方案。在推荐大模型构建中,引入了类似课程学习的方法,将补全题干与解答步骤、预测题目涉及的知识点,预测解题步骤是否正确,智能推荐等任务协同训练,并结合数学推荐系统的使用场景,首次提出了利用用户反馈信息构建不需要人工标注的奖励模型训练方案,提出了基于排序系统的 query-wise,基于分类系统的 sample-wise、class-wise、contra-wise,batch-wise的多种训练方案。综上所述,本文围绕了辅助教育场景下的初等数学科目的表示、理解、推理、推荐等技术,针对针对实际教学场景中的重难点,分别从数据集合的标注,复杂语义的理解、多模态信息处理、可靠精准推理以及基于用户反馈的生成式推荐等多个层面进行了深入研究,并在数智作业、学习机等产品上成功应用,实现了良好的社会效益和经济效益。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2024.001098
{DOI}: 10.27517/d.cnki.gzkju.2024.001098
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向室内移动服务机器人的人类行为识别与意图预测方法研究
{Author}: 苏学众
{Tertiary Author}: 王雯;颜长锋
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 服务机器人;预训练语言模型;提示学习;知识图谱;意图识别与预测
{Abstract}: 随着人工智能和机器人技术的进步,服务机器人在人类的日常生活中扮演着越来越重要的角色。这些机器人通过准确地理解和识别人类的行为意图,能够避免误解导致的重复对话,从而提升交互效率,同时使得服务机器人可以根据不同环境和语境,动态调整其行为和服务内容,确保提供适当的服务。但目前对于人类行为意图的识别与预测主要是采用基于机器学习以及迁移学习等方法,这些方法通常依赖大量标注数据,并且缺乏解释性。针对这些问题,本文将知识图谱(Knowledge Graph,KG)与预训练大语言模型(Large Language Models,LLM)结合的知识推理方式,应用于人类行为意图的识别与预测,实现了少样本学习下,甚至零样本学习下的意图识别与预测,并使得预测过程具备一定的可解释性。本文不仅在理论上为人类行为意图识别与预测提供了新的见解,而且在实验层面也验证了此方法的有效性。主要研究工作及成果如下:(1)基于提示学习的知识图谱构建。针对室内环境中各种人类日常生活行为场景,通过各种途径收集相关文本语料,并对其进行文本预处理操作,由此构建一个具有3210条语料的文本库。为了构建知识图谱,首先定义了 8种实体类型和11种关系类型的本体模型;其次,为了克服传统的信息抽取方式需要针对不同任务训练不同模型这一局限性,采用提示学习的方式,通过利用预训练大语言模型构建了一个两段式结构化信息抽取框架,对文本库中的实体以及关系进行统一的抽取,其抽取结果中的F1-score分别达到了85.91%和92.70%;然后,对获取到的结构化信息进行知识融合以及质量评估,以获得高质量的三元组信息;最后,将这些三元组存储到Neo4j图数据库中,形成一个以“Person”和“Object”为中心的室内场景离线知识图谱。(2)基于知识图谱和预训练大语言模型的意图识别。针对当前人类行为意图识别方法缺乏可解释性、信息碎片化以及泛化能力不足等问题,本文将一种基于KG结合LLM的知识推理方法应用于人类行为意图识别预测当中,构建了一个包含输入模块、在线推理图谱构建模块、意图推理模块以及输出模块4个部分的人类行为意图识别预测框架,其中,输入模块负责构建提示词,引导LLM执行后续任务;在线图谱构建模块依据输入文本中的关键实体,从离线知识图谱中检索相关路径,构建包含各类推理路径的在线图谱;意图推理模块利用LLM根据提示词的任务指令和在线图谱的场景信息进行当前场景下的意图推理;输出模块则展示LLM的推理结果和过程。通过该方法,可以利用文本信息推理出当前场景下的人类行为意图,并给出推理过程以及结果,表明该方法在进行人类行为意图识别与预测方面具有很好的可解释性。(3)室内环境下人类行为意图识别与预测实验。为了验证基于KG和LLM(如GPT3.5系列模型)相结合的人类行为意图识别与预测方法的有效性和可行性,本文将室内环境中的人类行为意图作为研究对象,以情境感知作为切入点,通过从视频数据中提取关键信息并构建在线推理图谱,设计了一种综合考虑时空行为、目标检测和动态知识图谱的意图推理模型。在WHYACT数据集上,将本文的方法与自然语言推理方法以及LLM等基线模型进行了对比实验。研究首先评估了不同Temperature参数和提示词质量对模型预测多样性和准确性的影响,发现Temperature设为0.7时,模型预测效果最佳,并且高质量的样本提示能进一步提高模型性能。与基线模型相比,本文的模型在F1-score上提高了6.59%,证明了该方法在人类行为意图识别与预测方面的有效性和优越性。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001052
{DOI}: 10.27398/d.cnki.gxalu.2024.001052
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力多特征融合的中文文本纠错算法研究
{Author}: 孙英健
{Tertiary Author}: 郑元林
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 中文文本纠错;预训练模型;对比学习;注意力机制
{Abstract}: 文本纠错是一项利用自然语言处理算法来检测错别字并进行自动纠正的技术,是自然语言处理领域的一项基本任务。近年来随着深度学习的不断发展,文本纠错技术取得了巨大的进步与提升,该项技术也在新闻、公文写作等领域得到了广泛的应用。本文在预训练语言模型的基础上对文本纠错任务展开研究,对当前主流的神经网络模型存在的问题进行了有效的改进。目前中文文本纠错任务存在的主要问题有:(1)网络模型难以学习文本上下文信息,致使检测阶段对错误字符的识别率较低,不利于后续纠错网络对错别字的纠正;(2)文本纠错任务主要面临字音相似性错误,如何有效地将字音信息添加进网络中,也是当下迫切需要解决的问题。针对上述问题,本文对中文文本纠错任务进行了研究,主要内容可以概括为以下三个方面:(1)为了解决网络模型对上下文信息不敏感的问题,提出了一种将检测网络与纠错网络相互结合的基于层次化建模与深度上下文感知的中文文本纠错算法。将Bi-LSTM模型与多头注意力机制相结合作为检测模块,通过多头注意力机制对重要信息进行关注,能够有效地学习文本的上下文信息。同时将RoBERTa预训练模型作为纠错主干网络,提升了模型对于错别字的敏感度与识别精确度,提高了语言模型的鲁棒性。在公开数据集上的对比实验与消融实验结果表明,该方法可以提升模型在上下文信息检测阶段的效果,并增强了模型的纠错性能。(2)针对模型缺失字音信息的问题,提出了一种基于多特征融合与对比学习的中文文本纠错算法,该模型通过添加字音嵌入,提高了模型在检测任务上的灵活性,并使用SimCSE模型来提升模型在纠错任务上的精确率。引入对比学习机制,进一步帮助模型减少了在实际应用时的信息不匹配问题。为了验证本文方法的有效性,在公开的文本纠错基准数据集进行了实验研究,并采用精确率、召回率和F1指标作为模型的评价指标,通过实验结果证明了网络模型的优异性能。(3)构建中文文本纠错系统,主要包含文本传输、文本纠错与文档纠错三大模块。基于Python和Qt环境,将所提出的文本自动纠错模型部署到服务器中,通过系统的文本纠错模块,获得与目标语句高度一致的纠错效果。综上所述,本文针对中文文本纠错存在的主要问题,提出了两种改进算法,并在此基础上构建了文本纠错系统,进行实际的应用。在公开数据集上的实验结果表明,本文提出的方法效果良好,在文本纠错任务中展现出了先进的性能。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001568
{DOI}: 10.27398/d.cnki.gxalu.2024.001568
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人机混合模式下的兵棋推演辅助决策研究
{Author}: 何瑞麟
{Tertiary Author}: 刘伟
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 人机混合;兵棋推演;大语言模型;辅助决策
{Abstract}: 兵棋推演是从战争推演需求中演变而来的一种推演形式,使得指挥人员能在一定规则下对战场状态及走势进行计算和模拟。从古到今,兵棋推演经历了从实体兵棋到计算机兵棋的发展,在逼真性、便捷性、服务型都在不断进步,但操作人员目前在使用兵棋推演系统的过程中还是会有不少问题,包括注意力局限、背景信息学习效率低、操作冗余等。这些问题将导致人类的决策能力无法充分发挥,并将影响人机协作绩效。当前解决兵棋推演领域人机混合问题的关键在于如何提供同时具备辅助决策能力、良好人机交互、以及策略可解释性三项能力的智能体以及如何设计良好的人机混合交互模式。本文将构建具有良好自主决策能力的智能体,搭建兵棋推演人机混合决策实验平台,并基于该平台探究兵棋推演领域人机混合决策这一关键问题。本文的研究主要从以下三个方面开展:第一,为建立具备可交互性与可解释性的兵棋推演智能体,本文使用大语言模型作为基座,结合兵棋推演场景的特点,提出了一个可加入人类经验的兵棋任务分解智能体框架。采用了思维链、格式化输出、函数调用、反馈等方法进行兵棋推演智能体的设计与构建。通过此方法设计的智能体具备一定的自主决策能力,不加入人类经验情况下在多个想定的平均胜率为44.40%,低于主流博弈AI方法能达到的博弈性能。但智能体在加入合理人类经验的情况下,在多个想定中的平均胜率达到73.80%,与主流先进博弈AI胜率(71.54%)相当的情况下支持人在环控制与文本交互。第二,为了提升人机混合模式下操作人员与智能体的交互有效性与交互效率。在智能体设计的基础上,本文通过轻量化微调的方法对人机交互过程中的函数调用(Function Calling)进行了优化。通过构建兵棋推演任务中常见的对话与函数调用数据,提升大语言模型在兵棋推演场景下根据文本指令正确执行函数调用的正确率。实验结果表明,轻量化微调方法能在有限的计算资源下使得模型在函数调用任务中获得大幅度提升,在使用6-7B参数量开源模型的情况下,微调后模型的函数调用准确率超过原生GPT-3.5-turbo模型。第三,为深入研究不同人机混合模式对操作人员绩效、人机信任关系与人员认知负荷之间的关系,本文搭建了具备大语言模型接入能力,且具备多种人机混合模式的兵棋推演实验平台。基于人机混合兵棋推演实验平台,设计了三种不同人机混合模式下的兵棋推演实验。通过该实验探究了不同熟练度操作人员在不同人机混合模式下的绩效、人机信任、认知负荷水平表现,以及定量分析了这些因素相互之间的影响关系。本文对智能体能力的测试结果显示,虽然基于大语言模型实现的智能体表现出较强的理解与推理能力,但在不加入人类经验的情况下与基准AI对抗仅能取得较为一般的成绩,且难以适应非对称环境或需要特殊策略的情形。加入人类经验后,智能体与基准AI博弈胜率具有较大提升。本文针对人机混合兵棋推演中的对话与函数调用数据任务的轻量化微调实验表明,通过构建兵棋推演领域数据并进行参数化微调能够有效提升大语言模型在人机混合兵棋推演模式下执行文本指令的准确率。另外,人机混合推演实验结果表明,人在与智能体协作时,在不同的人机混合模式下会表现出不同的认知负荷、信任水平与绩效,同时人的熟练度也会对结果产生影响。这表明针对不同的任务需求,不同熟练度阶段的个体应当有偏好地选择特定的人机混合模式,以提升绩效或降低认知负荷。本研究不仅为兵棋推演智能体设计了一种新的实现框架,为大语言模型在兵棋推演领域的应用提供了有价值的参考,也为深入理解人机协同决策机制提供了实验依据,有助于推进未来兵棋推演智能体与人机混合智能系统的设计与实现。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.001321
{DOI}: 10.26969/d.cnki.gbydu.2024.001321
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向大语言模型的参数高效微调方法的对比研究
{Author}: 伍洁
{Tertiary Author}: 杜剑峰
{Publisher}: 广东外语外贸大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自然语言处理;参数高效微调;大语言模型
{Abstract}: 近年来涌现了许多参数量巨大的大语言模型,而微调这些模型的全部参数需要非常多的算力,这对于普通用户和研究人员来说非常困难。为此,大量的研究人员开始研究如何在仅微调模型中少部分参数的情况下达到和微调模型中全部参数一样的效果,此类方法被称为参数高效微调方法。自2019年至今已经有超过几十种参数高效微调方法被提出,而这些方法可以分为增加可训练参数的参数高效微调方法、选择模型中部分参数进行微调的方法以及基于参数矩阵分解的方法,并且同类别之间的方法之间存在相互联系而不同类别的方法之间又有很多共同的设计要素。本文首先通过文献研究法将近几年提出的微调方法分为了增加可独立微调参数的方法、部分参数更新的方法以及参数矩阵分解的方法三大类。然后通过对实现原理的详细分析阐明了不同方法之间的联系并为每个类别的代表性方法进行了更加细致的描述。最后在实验中则对应用广泛并且影响力较大的适配器方法中的Adapter方法、直接对模型参数矩阵进行压缩处理的Lora方法和IA3方法、提示微调方法中的Prefix-Tuning方法、P-Tuning方法、P-Tuning V2方法以及仅微调模型中偏置项的Bit Fit方法在ART数据集、SAMSum数据集、Dialog Sum数据集、XSum数据集以及WMT17数据集上进行了详细的实验分析。而参与实验的基座模型则包括了不同参数规模的T5模型、m T0模型以及Bloomz-7.1B模型和Llama2-7B模型。实验结果表明,采用参数高效微调方法微调参数规模较大的模型能够获得比全量微调参数规模较小的模型更好的效果,因此在相同计算资源的情况下应该尽量采用参数高效微调方法微调参数规模更大的模型。而通过双边T检验分析可知,各种参数高效微调方法中Lora方法、Adapter方法以及Prefix-Tuning方法有显著更好的效果,因此在实际的应用中应尽量选择这些方法用于大模型的微调。而在某些特定情况下其他微调方法也能够获得不错的实验效果,在计算资源和时间允许的情况下也可以尝试采用其他微调方法对模型进行微调,通过对比选择最优的微调方法。
{URL}: https://link.cnki.net/doi/10.27032/d.cnki.ggdwu.2024.000460
{DOI}: 10.27032/d.cnki.ggdwu.2024.000460
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 企业社会责任报告特质信息含量与融资约束
{Author}: 田野
{Tertiary Author}: 赵纳晖;严绍业
{Publisher}: 中国财政科学研究院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 企业社会责任报告;融资约束;自然语言处理;信息不对称;信号传递
{Abstract}: 社会责任报告虽未作强制性披露的规定,但是企业却热衷于积极披露,究其原因可能是出于融资需要的考虑对披露信息的补充。目前,已经有大量文献证实了企业社会责任与融资约束的之间的关系,但是对于企业社会责任对融资约束影响的细分领域还不够充分,对于企业社会责任报告信息披露的影响研究还不够深入,因此本文从社会责任报告披露内容上研究其是否可以影响融资约束。随着经济社会的不断发展,人们对社会的发展理念已经不仅局限于经济的增长,对于公益、环保等社会发展因素也越来越重视,人们不再仅仅以一个企业的财务数据高低而评定企业的优劣,积极承担社会责任的企业变得更容易受到消费者和投资者的青睐,作为社会发展的重要经济主体,许多企业也摆脱了利润最大化的固有理念,积极履行社会责任。企业社会责任报告作为企业披露自身履行社会责任的重要信息载体,起着与利益相关者沟通的桥梁作用,报告中披露的企业特质信息可以在一定程度上弥补信息不对称,增加投资者对企业的了解,同时增强投资者对公司的好印象。基于此,本文提出了研究目标,即探究企业社会责任报告特质信息含量与融资约束之间的关系,以更好地促进社会资源的有效配置。
本文在梳理相关文献的基础之上,根据信息不对称理论、信号传递理论、利益相关者理论及公司印象管理理论等相关理论,分析了企业社会责任报告特质信息含量与融资约束之间的关系,并据此提出了本文的研究假设。进而,本文根据研究假设进行了相关模型的设计,并选取2016-2020年披露社会责任报告的全部A股上市公司为研究对象进行实证分析。本文研究的难点是利用自然语言处理的信息抽取技术,通过python软件实现对企业社会责任报告的命名实体词汇抽取,成功实现了本文解释变量的构建。本文通过描述性统计分析、相关性分析、多重共线性检验及多元回归分析的实证研究方法验证了企业社会责任报告特质信息含量与融资约束之间的关系,并且通过多种稳健性检验方法增强了本文研究结果的稳健性和信服力,而且还通过分析不同文本长度下企业社会责任报告特质信息含量与融资约束之间的关系丰富了本文的研究视角。
本文的研究结果表明:(1)企业社会责任报告特质信息含量与融资约束成显著负相关关系,即特质信息含量越高融资约束越少。(2)“短小精悍”的报告比“华而不实”的报告更能缓解企业的融资约束。最后,本文根据得出的研究结论分别对微观企业、准则制定部门和监管机构提出相关建议,并对进一步研究作出展望。本文可能的贡献在于:(1)对于社会责任报告特质信息含量的研究还较少,本文丰富了该领域的研究。(2)本文的研究方法有所创新,将中文命名实体的文本研究方法引入到社会责任报告的研究中。(3)本文在研究视角上借鉴了已有的文献,丰富了研究的角度。
{URL}: https://link.cnki.net/doi/10.26975/d.cnki.gccks.2024.000009
{DOI}: 10.26975/d.cnki.gccks.2024.000009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向电商评论文本的跨领域情感分析研究
{Author}: 高茂娇
{Tertiary Author}: 张顺香
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 跨领域情感分析;电商评论文本;迁移学习;特征映射;胶囊网络
{Abstract}: 跨领域情感分析是自然语言处理的一项重要任务,旨在探索不同领域中情感表达的特点和差异性。电商评论文本跨领域情感分析可以帮助商家更好的把握市场动态和用户需求,为消费者提供个性化推荐服务和更全面的购物体验。针对现有面向电商评论文本的跨领域情感分析任务中,目标领域缺少带标签样本,且同类特征在不同领域情感极性差异较大的问题,本文提出一种面向电商评论文本的跨领域情感分析方法,具体内容如下:(1)针对目标领域缺少带标签样本的问题,提出一种融合特征迁移的跨领域情感分析方法。首先用Tiny BERT模型对源领域和目标领域的样本进行预训练,获取词向量;其次用BiLSTM提取文本特征并进行注意力加权;接着将加权后的特征进行特征映射,生成统一的特征空间,通过最大均值差异的方法来度量源领域和目标领域的分布差异,然后通过最小化MMD,使源领域和目标领域的特征空间更加接近,以进行从源领域到目标领域的知识传输;最后用softmax+全连接层对目标领域样本进行情感极性判断。(2)针对同类特征在不同领域间情感极性差异较大的问题,提出一种基于RBS-CAPSULE的跨领域情感分析模型。首先采用Roch Bert预训练模型对评论文本进行编码,得到词向量表示;接着用BiLSTM对词向量进行序列建模,以获取评论文本的特征向量;然后用Self-Attention对不同位置的特征向量赋予不同的权重,最后用胶囊网络配合EM路由区分领域特征进行领域聚合并分类,以输出评论文本的情感标签。实验结果表明,本文提出的跨领域情感分类方法的各项评估指标均优于对比方法,能有效提高跨领域商品评论文本情感分析的准确率。可以为电商平台优化产品推荐及改善营销策略。图[30]表[14]参[80]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2024.000224
{DOI}: 10.26918/d.cnki.ghngc.2024.000224
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理的气象灾害知识图谱及其应用研究
{Author}: 余正
{Tertiary Author}: 江结林
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;自然语言处理;知识图谱
{Abstract}: 决策气象服务在气象灾害预警和防治领域发挥着至关重要的作用,通过提供一系列针对性建议以协助各相关部门有效应对气象灾害。气象灾害的关键信息通常分散于多种数据源(如预报文档、观测记录)中,在这种情况下,自然语言处理和知识图谱技术显得尤为重要,它们能从复杂类型数据中抽取出关键的实体和关系并进行直观展示与知识发现,从而为决策气象服务的智能迭代、气象灾害预警与防治工作的改进提供有力技术支撑。然而,气象灾害数据的多源异构特征使得语义关系耦合度较高,导致实体及其关系难以被准确提取和判别。因此,气象灾害知识图谱的构建与应用面临如下挑战:1)由于实体边界较为复杂,气象灾害领域的命名实体识别和关系抽取精度较低。2)当前气象决策建议的得出主要基于人工计算与分析,导致决策建议的生成效率与内容质量都有待提高。基于上述分析,本文对基于自然语言处理的气象灾害知识图谱及其应用展开研究,主要研究工作包括:(1)针对基于自然语言处理的气象灾害知识图谱构建,本文就命名实体识别和关系抽取任务分别提出了对应的优化策略。首先,通过预训练模型与全局指针为实体划分边界,提高命名实体识别任务的精确率。其次,基于数据增强策略与头尾实体标注完成标签扩充和特征聚焦,提升关系抽取模型的性能。实验结果表明,本文的信息抽取优化和知识图谱构建策略能够有效提取气象灾害领域的实体及其关系,并以自动化的方式显著提高构建效率。(2)为了提升气象决策建议的生成效率与内容质量,本文提出了一种引入知识图谱语义信息的文本生成模型。首先,将气象灾害知识图谱中相匹配的知识三元组融合进词嵌入层,为文本生成模型提供丰富的主题特征和背景知识。然后,基于指针生成网络和搜索策略的改进提升模型的长文本生成能力。实验结果表明,本文的文本生成模型能够高效生成面向气象灾害预警与防治的高质量决策建议,并具备切实可靠的实际工作指导作用。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2024.001489
{DOI}: 10.27248/d.cnki.gnjqc.2024.001489
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《人与人工智能：AI对生活、工作、世界的意义》（节选）汉译实践报告
{Author}: 高红艳
{Tertiary Author}: 牟彩霞
{Publisher}: 山东建筑大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 科技文本;功能对等;翻译技巧
{Abstract}: 随着科技的迅速发展和互联网数据的爆炸式增长,人工智能成为现代社会不可或缺的一部分,标志着一个崭新时代的到来。如此背景下,人工智能领域的科技文献不断涌现。翻译引进优秀人工智能科技文献进而成为国内译者的责任。本次翻译实践文本选自Artificial Intelligence and You:What AI Means for Your Life,Your Work,and Your World一书的第九和第十章,通过文本分析,确定源文本类型为科技类文本。该类型文本语言特点鲜明,专业性和严谨性要求高,故选用功能对等理论指导翻译实践,并运用适当的翻译方法和技巧,确保译文与原文功能相当。翻译实践报告采用了案例分析法,从词汇、句法和文本三个层面展开。词汇方面,重点关注了专业科技术语和常用词的翻译。句法方面,分析复杂句和被动句的翻译。文本层面,着重译文语段之间的衔接和语义连贯,确保翻译文本的严谨性和逻辑性得以充分体现。分析表明,功能对等理论能有效指导科技文本的翻译,确保译文准确传达原文含义,贴近目标读者的表达习惯,体现翻译文本的严谨性和逻辑性。本次翻译实践报告的经验与方法,可为其他类似文本的翻译提供一些有益的启示和思路。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2024.000100
{DOI}: 10.27273/d.cnki.gsajc.2024.000100
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于细粒度跨模态匹配的视觉语言导航技术研究
{Author}: 崔以博
{Tertiary Author}: 闫野
{Publisher}: 军事科学院
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 视觉语言导航;细粒度跨模态匹配;导航性能;可解释性
{Abstract}: 随着无人系统技术的快速发展,军事等领域对具备高度智能化和自主导航能力的无人平台的需求日益增长。视觉语言导航(Vision-and-Language Navigation,VLN)作为具身智能领域的一项关键技术,因其能够实现智能体与人类有效的自然语言交互并在三维环境中自主导航而备受瞩目。然而,现有的VLN技术在解决跨模态匹配问题上存在局限性,尤其是无法充分挖掘并提升智能体在多模态信息交互中的深层理解能力。当前VLN研究尽管在粗粒度跨模态匹配方面积累了大量的研究工作,但在更深层次的细粒度匹配层面却面临:(1)高精度的细粒度跨模态匹配监督信号稀缺、(2)细粒度跨模态匹配的监督机制缺乏有效性和(3)模型缺乏细粒度可解释性等三大关键挑战。为解决以上挑战,本文针对视觉语言导航任务中存在的细粒度跨模态匹配难题展开系统化研究。本研究分别从“辅助损失”、“自适应预训练”、“多模态文本生成”和“大模型推理”等角度出发提出四个研究内容,通过创新算法设计、扩充高质量数据以及优化模型结构,显著提升智能体在复杂环境下的导航性能,并增强其决策过程的可解释性。具体而言,本文的研究内容和创新点如下:(1)针对当前训练方法在子指令级别跨模态匹配层面监督不足的问题,本文首先采用人工标注的方式对现有VLN数据集中子指令与子路径之间的对应关系进行精细化标注,构建带有高质量子指令子路径匹配标注的数据集。以此为基础,本文提出面向子指令子路径匹配的辅助对齐约束算法,其中包括注意力对齐约束和表示对齐约束。实验结果显示,每项辅助约束均能独立提升智能体的导航性能,而将两者结合后能取得更显著的性能提高,最终结果优于同期解决方案,从而验证了所提出数据集和算法的有效性。(2)针对当前VLN领域在实体级跨模态匹配层面缺乏有效监督的问题,本文首先采用人工标注的方式对现有VLN数据集中的实体地标对应关系进行标注,构建VLN领域第一个高质量的实体地标匹配数据集。以此为基础,本文提出面向实体地标匹配的自适应预训练算法,其中包括三个关键的实体地标匹配自适应预训练任务:实体短语预测、地标边界框预测和实体地标语义对齐。在多个下游任务上的实验结果显示,该算法在已见和未见环境中均取得了同期最佳的导航性能表现,证明了所提出数据集的有效性以及该算法在提升VLN导航性能和泛化性上的优越性。可视化结果表明,该算法促进了模型在实体级跨模态的表示学习,从而增强了智能体的理解和决策能力。(3)针对当前大规模高精度的细粒度跨模态匹配监督信号稀缺的问题,本文提出一种带有细粒度跨模态匹配标注的导航指令生成框架,能够将扩充的导航路径转化为指令路径对,并包含子指令子路径对匹配和实体地标匹配标注。基于该框架,本文构建了富含细粒度跨模态匹配标注的VLN增强数据集,并通过大量实验系统性地评估此增强数据集中指令路径对、子指令子路径对匹配和实体地标匹配的质量及有效性。实验结果显示,使用此数据集训练后,多个VLN智能体的导航性能显著提升,验证了本研究在提高智能体细粒度匹配能力和导航性能方面的有效性。(4)针对当前VLN模型普遍缺乏可解释性的问题,本文提出一种大模型指导下过程可解释的视觉语言导航模型。该模型包括导航指令解析器和联合导航模型两个核心部分。导航指令解析器利用大语言模型强大的推理能力,解析自然语言导航指令并提取实体名词,作为后续导航过程中的关键线索。联合导航模型结合实体预测器和地标预测器,不仅在执行导航动作时选择合适的实体作为依据,还预测实体在环境全景图中的具体位置,以提高智能体决策过程的可解释性。实验结果显示,该模型在多个离散和连续导航任务中均展现出优秀的导航性能和可解释性。可视化分析结果进一步证实该模型在寻找关键实体与环境地标方面的能力,大大增强了智能体行为的可追溯性和信任度。
{URL}: https://link.cnki.net/doi/10.27193/d.cnki.gjsky.2024.000043
{DOI}: 10.27193/d.cnki.gjsky.2024.000043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 诺贝尔奖知识图谱问答系统的设计与实现
{Author}: 宋文
{Tertiary Author}: 杨金翠
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 诺贝尔奖实体识别;问句意图识别;知识图谱;问答系统
{Abstract}: 近年来,随着科技水平和人民文化素养的提高,人们对诺贝尔奖的关注热度也不断提升。然而传统的互联网搜索引擎获取信息的效率较低,不同平台信息内容质量参差不齐,加上无法确保信息的真实性,使用户无法从大量纷杂的网络信息中提取出真实有效的内容。如今智能问答在人们生活的各个方面也逐渐普及,因此本文构建诺贝尔奖知识图谱的智能问答系统,快速帮助用户获取想要了解的真实可靠的诺贝尔奖相关内容。用户在系统中输入相关的问句后,系统调用意图识别和实体识别算法,分别对问句进行分类和问句实体提取,根据分类结果结合提取的实体名称代入模版查询,最后返回正确的答案。本文的具体研究内容如下:(1)构建基于诺贝尔奖的知识图谱。由于当前诺贝尔奖相关的数据较为分散,本文以互联网上公开的诺贝尔奖数据为基础,经过BeautifulSoup等爬虫工具对目标数据筛选过滤,将不同来源的数据处理融合,在构思设计了诺贝尔奖schema后,将诺贝尔奖相关的实体属性关系以三元组的形式存储在Neo4j图数据库中。通过Neo4j的图形界面工具对诺贝尔奖知识图谱进行可视化查询展示,并且把知识图谱作为后续问答系统知识库。(2)诺贝尔奖知识图谱问答系统核心算法实现。诺贝尔奖知识问答主要包括问句意图识别和命名实体识别两个任务。针对问句中诺贝尔奖的命名实体识别本文采用LEBERT-BiLSTM-CRF模型,首先引入LEBERT模型作为预训练模型,结合BiLSTM模型双向提取上下文的特征信息,采用CRF解码获取最优的标注序列完成命名实体识别任务。在问句意图识别任务中,本文采用连接BERT模型不同隐藏层的嵌入提取文本的整体语义信息,再结合TextCNN捕捉文本的局部特征,完成了基于Bert-TextCNN的用户问句分类。经过不同模型实验的对比分析,结果表明本文模型的性能明显有效提升。(3)诺贝尔奖知识图谱问答系统设计与实现。通过对诺贝尔奖问答的需求分析,本文设计实现了基于Flask框架的问答系统,后端对算法模块集成,结合前端CSS和Echarts的可视化界面,展示实现了实体检索、人物关系检索、诺贝尔奖实体识别和诺贝尔奖知识问答等功能。在对系统各个模块功能进行测试后,结果显示本文系统满足用户需求具有一定的实用性。该系统能够对用户提出的问句进行语义理解,识别的问句实体与诺贝尔奖知识图谱中的实体形成对应,从而完成精确查询,提升了大众了解诺贝尔奖知识的便捷性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.002592
{DOI}: 10.26969/d.cnki.gbydu.2024.002592
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多任务学习的社交平台数据情感分析方法研究
{Author}: 杜婉童
{Tertiary Author}: 耿玉水
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 情感分析;神经网络;多任务学习;社交平台
{Abstract}: 网络社交媒体的发展改变了公众的社会习惯,带情感和态度的社会数据为情感分析中的许多任务提供了重要的决策支持。现存多模态情感分析方法主要面临两个问题,一方面,在多模态情感分析对模态间交互作用考虑不足,会导致提取的情感特征所含情感信息有偏差,每种提取的模态特征在融合过程中,对最终情绪分类结果的贡献程度不同也会导致最终分类精度偏差大的问题;另一方面,在进行多模态情感分析时提取的特征中的冗余信息对后续工作也有较大影响,也会引起在进行模态间的交互时过多关注模态间的交互关系,而忽略本身模态所携带的情感信息,最终导致分类精度降低的问题。针对上述问题,本文给出了相应的解决方案,主要贡献如下:
(1)针对跨模态特征提取交互不足的问题,本文提出了基于交互注意融合的对称多模态情绪分析模型(BTR-MTL模型)。首先,为了解决池化时容易导致特征位置信息丢失的问题,提出了BERT结合Text CNN模型生成高阶文本特征。其次,对于特征通道相关性差的问题,利用改进的SE-Res Ne Xt残差网络获取图像特征,提高了模型的性能。然后,针对在双峰情绪融合中过度关注交互信息而忽略各模式独立性的问题,通过对称的模态交互机制和门控机制,将模态内部自身信息与模态间的交互信息相结合。最后,利用多任务学习的优点通过部分参数共享添加额外的关联任务,从而提高情感分类的准确性和模型的泛化性。在两个已发布的MVSA情感数据集上,与传统的多模态融合情感分析方法相比分类精度和F1值均有提高,证明了该模型的有效性。
(2)针对特征中的冗余问题,提出一个基于元启发算法的特征提取方法(HGB-HFN方法)。首先利用元启发式算法优化技术对提取的特征进行优化,以较低的计算成本获得精度较高的最优特征数据集。然后,针对忽略模态独立信息的问题,通过混合融合的方法,以视觉特征为主导,从文本内容在提取出准确的语义和情感信息,并训练多个基分类器来学习独立和多样化的判别信息。在流数据集MOSI和MOEI上进行了比较实验表明,该方法在精度和效率上都优于现有的计算方法。
综上所述,本文提出的两种解决方案在解决多模态情感分析中的挑战方面取得了一定的成果,并在实验中展现了较好的性能表现。这些成果为多模态情感分析领域的进一步研究和应用提供了有益的参考和启示。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000176
{DOI}: 10.27278/d.cnki.gsdqc.2024.000176
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于开放信息提取的网络安全知识图谱构建研究
{Author}: 刘洋
{Tertiary Author}: 韩晓晖
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 网络安全;知识图谱;网络威胁情报;开放信息抽取;联合抽取
{Abstract}: 随着信息化的不断扩大以及网络技术的持续发展,网络攻击的方式日趋成熟,高级持续性威胁(Advanced Persistent Threat,APT)的出现对企业和组织的安全构成了日益严峻的挑战,入侵检测等传统防御手段在面对高级可持续威胁和零日攻击时略显不足。网络威胁情报(Cyber Threat Intelligence,CTI)包含了大量威胁知识,为企业和组织的决策提供了有效手段。网络威胁情报具有海量化、碎片化的特点,这使得网络安全人员很难快速从威胁情报中获取有效的信息,如何利用海量的网络威胁情报,成为安全领域的挑战之一。网络安全知识图谱可以关联多源异构数据,为网络威胁情报的有效利用提供了解决方案,它由实体和关系组成大规模的安全语义网络,将多源异构的威胁情报整合在一起,为网络防御提供强有力的支持。目前网络安全知识图谱的构建面临着一些问题,传统的网络安全信息抽取采用流水线方式进行抽取,存在误差传播且实体和关系之间信息交互不紧密的问题。传统网络安全知识图谱基于本体模式进行构建,难以完全提取文本中的威胁知识。因此,本文从联合抽取和开放信息抽取两个方面开展网络安全知识图谱构建研究,本文主要工作包括:
(1)针对流水线式实体和关系抽取存在误差传播、传统联合抽取模型两个子任务之间缺少信息交互等问题,提出一种基于多粒度膨胀卷积的威胁情报实体关系联合抽取方法。该方法将实体关系联合抽取建模为表格填充任务,使用网络安全领域预训练模型Sec BERT和双向长短期记忆网络生成威胁情报文本词的嵌入表示,能够更好的提取网络安全领域句子特征。为了防止命名实体识别和关系分类任务特征混淆,为每个子任务单独学习不同表示。构建共享特征来增强两个子任务之间的信息交互。提出了多粒度膨胀卷积和通道注意力机制来捕获远近词之间的交互关系与特征。最终使用双仿射分类器与多层感知机结合进行实体和关系的预测。最后,在收集的数据集上进行实验和分析证明了所提方法的有效性。
(2)针对网络安全领域缺乏通用数据集、传统的网络安全知识图的谱构建都是基于本体模型难以完全提取威胁情报的问题,提出基于开放信息提取的网络安全知识图谱构建方法。该方法使用开放信息抽取对非结构化网络威胁情报进行提取。首先利用Sec BERT预训练模型生成具有上下文语义信息的嵌入向量,然后将文本句法依赖图和句子成分图分别输入到两个图卷积神经网络中提取句子的语义特征,最后采用多视图学习损失对模型进行微调,得到句子中的开放三元组。为了标记网络安全领域中重要的三元组,提出了网络安全实体识别模型。最后使用Neo4j图数据库将三元组构建为知识图谱。在公开数据集上进行实验,证明所提的方法的有效性。
(3)设计并实现了一个网络安全知识图谱管理系统。该系统能对上传的非结构化威胁情报进行分析,自动抽取实体和关系并将其存储到Neo4j图数据库中。基于B/S架构编写前端页面用于可视化展示,实现了实体检索、关系检索、节点路径查找等功能。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000269
{DOI}: 10.27278/d.cnki.gsdqc.2024.000269
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的医疗报告生成关键技术研究
{Author}: 刘勇
{Tertiary Author}: 王俊峰
{Publisher}: 四川大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 医疗报告生成;大语言模型;多模态特征对齐;多模态特征融合;深度学习
{Abstract}: 在医疗领域中,临床数据的管理和利用是提高医疗质量和效率的关键。从病人的基本信息到复杂的影像学资料,这些数据每时每刻都在生成,为医疗决策提供了数据支撑。然而,如何能有效管理和利用这些复杂且具参考和研究价值的数据,对于医务工作者来说是一个巨大的挑战。随着人工智能技术的快速发展,基于深度学习的医疗报告生成技术应运而生。这项技术旨在通过模型和算法自动分析医疗数据,并生成准确而清晰的医疗报告,这对于医务人员显得尤为重要。首先,自动化医疗报告生成技术可以快速分析大量医疗数据,提高诊断速度与准确性,减少漏诊和误诊的风险,加速诊断流程。其次,自动生成的医疗报告具有更高的一致性,有助于医生基于可靠数据做出精确决策,确保治疗效果和患者安全。此外,自动化医疗报告生成技术还促进了医疗知识的发展与研究,为科学研究提供了丰富的数据支持,有助于探索新的诊断方法和治疗方案。最后,这项技术提升了患者护理质量与体验,帮助医生更好地理解患者病情,制定更科学的治疗方案,提高了患者的治疗效果和生活质量,同时提高了医疗服务的可及性和透明度,提升了患者对医疗服务的信任和满意度。尽管相关研究获得了一定的进展,其仍然面临以下挑战:(1)现有模型难以应对缺乏高质量训练数据和临床端到端医疗报告生成整体解决方案的问题,这些问题限制了基于文本的医疗报告生成技术研究和应用的开展。(2)现有模型在多模态特征对齐上多采用对比学习和联合嵌入策略,容易出现模型偏差和通用性较差问题。此外,现有研究很少考虑对报告文本中相似文本特征表示和处理,限制了模型对于未见文本的理解能力。(3)现有模型大多是基于全局图像和文本特征融合的研究,有少部分研究虽然考虑到了局部图像特征的重要性,但一般也仅限于将图像分成若干小的图像块进行处理,模型缺乏对局部解剖级别的图像和文本特征表达与融合,导致生成的报告出现准确性和可解释性不足的问题。本文主要针对以上问题开展研究,主要内容包括以下几个方面:第一,针对文本医疗报告生成任务中,现有模型规模和能力难以解决缺乏高质量训练数据和临床端到端医疗报告生成整体解决方案的问题,提出基于提示学习的整体解决框架(PMRG)。该框架通过结合领域专家知识的人工提示学习和加权随机抽样策略的自动提示学习,充分利用Chat GPT模型的强大样本学习和推理能力,灵活高效地应对高质量训练数据缺乏的情况,满足了临床端到端自动化医疗报告生成的迫切需求。实验结果表明,PMRG框架在复杂的医患对话数据集上性能优于对比模型,无论是在自动化评价标准,还是人类医学专家评价标准方面,都取得了较高的评价,为临床的自动化文本医疗报告生成需求提供了新的解决方案。第二,针对放射医疗报告生成任务中,现有模型一方面使用对比学习或联合嵌入策略进行多模态图像和文本特征对齐,面临因负样本选择策略和复杂模型结构,而导致的模型偏差和通用性较差的问题。另一方面,现有模型很少考虑对报告文本中相似文本特征表示和处理,限制了模型对于未见文本的理解能力。提出基于专家网络和原型句的特征对齐模型(Moe PS),具体采用原型句策略,根据相似文本特征,提取报告文本中具有代表性的句子特征表达,帮助模型理解文本和图像特征之间的语义关系,有利于文本特征和图像特征的进一步对齐。此外,采用注意力机制和多个感知机网络组成的专家网络引导模型选择与文本特征语义相似度高的图像特征,强化了模型对于图像特征的语义理解。通过专家网络和原型句,有助于提高模型的图像和文本特征的多模态对齐能力,从而提升放射医疗报告生成的质量。实验结果显示,Moe PS模型在OPENI和MIMIC-CXR数据集上取得了最优的结果,证明了基于专家网络和原型句的特征对齐策略的有效性和可行性。第三,针对放射医疗报告生成任务中,现有模型缺乏对局部解剖级别的图像和文本特征表达与融合,导致生成的报告出现准确性和可解释性不足的问题,提出了一种整体与局部解剖区域的特征融合模型(GLFF),具体通过提示学习识别与标注放射报告文本描述中的句子级解剖区域,提升了模型对解剖区域文本特征语义上下文的理解,有助于文本与图像特征的对齐和融合。此外,通过引入图像解剖区域的特征识别和分割技术,使模型能够精细化地捕捉到图像局部解剖区域特征与文本特征的关联。最后,通过注意力机制,结合对比学习和权重学习动态特征融合算法将整体与局部图像和文本特征进行有效融合,提升放射医疗报告的生成质量。实验结果显示,在OPENI和MIMIC-CXR数据集上,GLFF模型取得了最优的结果,证明了所提出的整体与局部解剖区域的特征表达与融合策略在提高医疗报告生成准确性和可解释性方面的有效性和可行性。综上所述,在医疗领域,临床数据的管理和利用是提高医疗质量和效率的关键。基于深度学习的医疗报告生成技术可以自动分析数据,生成准确的报告,减轻医生负担并提高治疗效果。
{URL}: https://link.cnki.net/doi/10.27342/d.cnki.gscdu.2024.000019
{DOI}: 10.27342/d.cnki.gscdu.2024.000019
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 大语言模型环境下的后门攻击研究
{Author}: 王思达
{Tertiary Author}: 秦素娟
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自然语言处理;大语言模型;后门攻击;大模型微调
{Abstract}: 随着人工智能的迅速发展,大语言模型成为该领域的研究热点。大语言模型的安全性也逐渐引起学界和工业界的重视。对大语言模型通常会使用“预训练+微调”的应用方式,但是使用了存在后门的数据集对预训练模型进行了微调,就会导致整体模型的不安全。而目前的大语言模型环境后门攻击方法单一,使用的触发器简单切突兀。基于此,本文针对将以大语言模型为环境下微调阶段进行的后门攻击开展研究。本文的主要内容如下:(1)提出了一种基于隐秘字符的大语言模型后门攻击方法。本文通过分析目前大语言模型环境中的后门攻击,发现攻击使用的触发器为突兀单一的字符。因此,本文将UNICODE编码中零宽度字符作为后门触发器,将触发器通过从源文本的三个不同位置检索并插入。实验结果表明,该后门攻击在大语言模型环境中可以实现良好的攻击效率,实验证明其能够达到95%以上的攻击成功率,使目标模型保证有不变的干净准确度,同时可以在一定程度上躲避人工检查。(2)提出了一种基于句法结构的大语言模型后门攻击方法。针对目前存在的后门攻击方法使用的后门触发器仅考虑表征空间中实现的,而没有考虑特征空间的角度,本文将通过使用相同句法结构特征生成的训练数据作为后门触发器。在后门训练中,通过使用句法控制的释义模型将正常样本释义为具有预先指定语法的句子来生成中毒样本并优化保留更多的训练样本,使攻击更适应大语言模型环境。在推理过程中,受害者模型的后门将通过以相同的方式解释测试样本来激活。在与目前的大模型环境的后门攻击进行对比后,结果显示本方法的攻击方式在大语言模型环境中能够比直接迁移的攻击方法有着5%攻击成功率的提高,同时保持原本模型的干净准确度。(3)针对上述两种攻击方法,提出了一种大模型后门攻击的防御方法。方法通过大模型训练语料库中的多语言特征对模型的训练集与测试集进行反向翻译,并对测试集的句法结构进行改变,使相应后门攻击的后门触发器被消除。考虑到目前还没有成型的特征空间的后门防御策略,本文提出了一种针对大模型环境中基于反向翻译的防御方法。试验结果表明,本方法能够在多种数据集上针对两种后门攻击进行有效的防御,使表征空间的攻击成功率降低一半以上,使特征空间的后门攻击成功率降低30%以上,同时保证其干净准确度。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.000477
{DOI}: 10.26969/d.cnki.gbydu.2024.000477
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 检索增强的智能问答神经网络方法
{Author}: 张航
{Tertiary Author}: 吕建成
{Publisher}: 四川大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 自然语言处理;检索增强的问答;智能问答系统;开放域问答;密集检索
{Abstract}: 随着人工智能和自然语言处理技术的飞速发展,智能问答系统已成为连接人与机器通信的桥梁,其目标是赋予机器以自然语言形式理解并回应人类查询的能力。近年来,基于深度神经网络模型的智能问答技术,特别是大型预训练模型如GPT-4、BARD、通义千问等的出现,极大地推动了该领域的进步。这些模型凭借在海量数据上的预训练,有效地捕获了语言的复杂性和丰富的上下文信息,从而显著提升了智能问答系统处理多样化查询和跨领域问题的能力。尽管取得了令人瞩目的成绩,现有的智能问答技术仍面临诸多挑战,其中之一便是模型在训练后难以进行知识的实时更新,导致无法处理含有最新信息的查询。此外,当面对稀有专业领域的问题时,由于缺乏特定领域的知识背景,仅靠问答模型可能无法提供准确和全面的回答。因此,检索增强的智能问答技术应运而生,旨在通过动态地从外部知识源检索信息,解决智能问答系统在实时信息获取、知识更新及缺乏领域知识的局限性。综上所述,检索增强的智能问答具有极其重要的研究价值和实用意义。检索增强的智能问答在针对特定应用场景仍面临诸多的挑战,如:1)目前高效的检索依赖于双塔神经网络模型,然而该模型缺乏行词汇级别的细粒度匹配能力,且严重依赖负文档采样技术,这些限制影响了检索性能;2)现有的检索模型的学习算法高度依赖于高质量标注的查询-知识匹配数据对,但这一假设在实际应用场景中难以实现,噪声匹配的数据对会对训练造成严重干扰;3)在小语种场景下,外部知识源和用户查询之间往往存在语言差异且缺乏训练数据,如何在资源稀缺情况下训练有效的跨语言知识检索器是一个难点;4)检索到的相关知识序列通常为较长文本,如维基百科或百度百科页面,而传统问答阅读模型对输入长度进行限制,难以处理这些长文本信息以更好相应用户需求。针对以上挑战,本文基于神经网络方法,围绕检索增强的智能问答方向提出了一系列检索模块与阅读模块的学习算法和理论,旨在推进问答领域的技术进步。本文的主要创新点总结如下:1.针对现有密集检索器中的缺乏词汇层面细粒度交互以及假阴性负样本问题,提出了召回重排对抗优化神经网络。该方法通过对抗思想协同训练密集检索模型和重排序模型,显著提升了文本检索性能,并在多个文本检索基准上实现了当时最先进结果,为精准高效的检索模块提供了新的训练视角。2.针对检索训练数据中的误匹配噪声数据对会影响检索精度的问题,提出了迭代检测纠正神经网络方法,该方法利用模型对数据对的困惑度鉴别噪声,并使用指数滑动平均模型对误匹配噪声进行标签修正,实现了鲁棒抗噪的知识检索。该策略在多种噪声场景下都展现出了卓越的数据净化能力及性能提升效果,为构建噪声匹配鲁棒的文本检索奠定了理论和方法基础。3.针对跨语言知识检索的挑战,提出了知识增强的跨语言检索预训练神经网络方法。该方法有效利用了知识的语言无关性,进行了创新性的同语言和跨语言匹配预训练数据对构建。这一方法不仅成本低廉、效率高,而且在低资源的跨语言检索场景中展现了卓越的检索性能,为跨语言智能问答检索领域带来了新的方法论和实践途径。4.针对基于Transformer神经网络架构的阅读器难以进行长文本建模的问题,提出了基于池化注意力机制的长文本阅读神经网络方法。该方法能在相同硬件资源条件下将原始预训练模型的支持长度拓展数倍,在检索增强的长文本阅读场景下展示优异性能,并在当时两个全球公开竞赛中名列前茅,为长文本阅读理解的发展提供了有效的解决方案和新的研究思路。
{URL}: https://link.cnki.net/doi/10.27342/d.cnki.gscdu.2024.000002
{DOI}: 10.27342/d.cnki.gscdu.2024.000002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人机交互场景下的机械臂抓取关键技术研究
{Author}: 王韶晨
{Tertiary Author}: 阚震
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 机械臂抓取;人机交互;意图理解;自注意力模型;灵巧操作
{Abstract}: 机器人被誉为“制造业皇冠顶端的明珠”,是衡量一个国家科技创新和高端制造业水平的重要标志之一。机械臂抓取作为机器人中最常见且通用的技术,随着社会的发展,其在制造业、医疗、教育等领域的需求不断增长,人与机械臂交互的频率和范围也日益增加。其中,人机交互场景下的机械臂抓取是指人和机械臂在共享的工作环境中,机械臂根据人的意图、指令或动作反馈,自动地执行物体的抓取、操作等任务。此外,在深海探测、太空操作,火灾救援等危险或人类难以直接作业的环境下,研究人机交互场景下的机械臂抓取技术变得更加迫切和必要。当前,机械臂抓取技术在实现人机共融方面仍存在不足,难以满足日益增长的需求。主要问题可以归纳为以下几个方面:首先,机械臂系统在场景感知能力上面临更大的挑战,要求其能够准确理解所处环境并迅速做出响应;其次,传统交互场景中机械臂交互模式较为被动,通常依赖操纵杆等直接命令或触发信号启动任务,限制了人机交互的体验;再次,交互模态单一,不仅束缚了用户与机械臂的互动方式,也影响了机器人对用户意图的理解和响应效率;最后,随着交互任务的日益多样化,对机械臂操作的灵巧性提出了更高的要求。本文围绕上述问题与挑战展开研究,主要工作如下:针对机械臂在复杂场景下的感知挑战,提出了一种面向机械臂抓取任务的自注意力模型,TF-Grasp。与传统基于卷积神经网络的方法相比,TF-Grasp展示了在处理和理解环境信息、捕捉全局依赖关系、学习特征表示以及指导机械臂完成抓取动作方面的优势。同时为机械臂后续的操作和人机交互环节奠定了坚实的基础。在康奈尔抓取数据集和贾卡尔抓取数据集上,所提出模型分别取得了97.99%和94.6%的抓取检测成功率,同时在真实场景中,所搭建的抓取系统取得了 92.1%的抓取成功率。针对传统交互场景下机械臂服务模式被动的问题,提出了一种基于人类视线的主动机械臂抓取技术。该方法利用头戴式近眼追踪设备实时监测用户的眼球运动,能够在不断变化的动态环境中高精度地追踪用户视线并确定其焦点位置。它还能区分用户无意识的视线移动与实际的操作意图,从而使机械臂能够根据人类意图精确执行包括抓取、移动和放置物体在内的多种操作任务。此外,该方法强调实时反馈与控制的重要性,能够提供即时反馈并实现快速准确的控制响应,从而不仅提升了用户的交互体验,也增强了机械臂适应用户操作需求的灵活性,提高了任务执行的效率和准确性。针对传统交互场景下机械臂交互模态信息单一(例如仅限于程序指令)、不自然、直观且不够人性化的问题,提出了一种基于自然语言的视觉-语言抓取模型。该模型将机器人建模为一个能同时处理视觉与语言模态的智能体,使机械臂能够在交互过程中解读用户的自然语言指令,并结合视觉感知来规划出合理的抓取策略。通过采用Cross-attention机制,该模型有效融合了不同模态信息,增强了机械臂对自然语言指令的理解能力,并实现了对指定物体的精准抓取。此外,通过实物系统验证了基于自然语言指令的机械臂抓取系统在更广泛交互场景中理解用户意图和有效促进人机协作的能力。针对传统交互场景下机械臂(例如使用二指夹爪)操作能力受限的问题,提出了一种交互式灵巧技能传递策略。该方法通过人类视频示教的交互方式,将人类的操作技能传递给灵巧手,从而实现了机械臂操作方式从简单的双指夹具到灵巧手的转型和能力提升。针对交互过程中人手与物体可能出现的遮挡问题,引入了手-物注意力机制,通过分析人手与物体间的互动并重构人手姿态,有效地捕捉手部动作信息,实现技能的高效迁移。同时,考虑到人手与灵巧手在构型上存在的结构差异,将灵巧手建模为多体机械系统,确保灵巧手在工作空间内的目标姿态可以被精准重构。该方法不仅为机械臂应对多元化场景开辟了新途径,还提升了其执行灵巧操作任务的能力。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2024.001063
{DOI}: 10.27517/d.cnki.gzkju.2024.001063
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理构建分子筛合成数据库
{Author}: 王弘扬
{Tertiary Author}: 李乙
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 自然语言处理;材料数据库;分子筛水热合成;数据挖掘
{Abstract}: 分子筛材料具有独特的孔道结构,使其具有卓越的催化性能。此外,分子筛还具有优异的热稳定性和出色的可调变性,是一种重要的工业材料,在原油裂解,气体吸附,离子交换等领域都有着广泛的应用。然而,由于分子筛合成原料的多样性、合成过程的复杂性以及合成过程中难以监测等特性,分子筛合成机理尚未达到共识,传统的合成方法几乎完全依赖科学家的化学直觉,试错成本较大。
信息时代的到来,为材料数据库领域被注入了新的活力。大量的科技文献蕴含着丰富的非结构化信息,传统的人工提取无法保证准确度,且效率很低,自然语言处理充当了这些论文中的非结构信息与规整结构化的数据库信息之间的桥梁。整理已有的非结构化实验数据,构建规整的材料合成数据库,利用海量的结构化数据来探究人工不易察觉的规律,是众多科学工作者努力的方向。但是,由于文本复杂程度高,写作表达手法多样,从海量数据中高效、准确地提取分子筛合成信息是十分困难的。因此,分子筛领域目前尚未出现文本挖掘合成数据库,搭建一个用于自动构建分子筛合成数据库的工作流有助于促进新型分子筛材料探索。
对表达方式不同的分子筛合成段落进行分类及针对性的提取,降低文本的信息熵,最后将高度结构化的分子筛合成数据进行提炼整合,可以实现对材料数据库的构建。将高度结构化的数据库信息作为输入进行数据挖掘等工作,通过机器学习的手段探索合成规律,可辅助实验人员,为相关实验提供经验和指导。
本论文聚焦于自动提取分子筛合成信息的方法开发以及分子筛合成数据库的构建,通过基于规则的自然语言处理技术,解构科技论文中关于分子筛合成的文本信息,搭建分子筛合成数据库的自动构建流程。采用基于机器学习的数据挖掘技术对数据信息进行深入分析,探究分子筛合成规律,为实验合成提供理论指导。具体包括以下三个方面的工作:
1.搭建了分子筛合成数据库的自动构建流程,实现了从论文到合成数据库的信息自动提取。先收集文献并进行统一命名,经过预处理,将分子筛合成文本进行拆解分类。之后,建立词典辅助信息标注,对分子筛合成过程中可能用到的化合物进行词典归类,同时建设更新模块以识别未分类原料,并对段落进行标签化以便于提取识别。在此基础上解构分子筛合成段落信息,针对文献中明确原料用量、明确摩尔比、含有变量的不同表达方式建立了针对性的策略,均实现了有效的信息提取,完成了合成条件、产物名称及性质的收集并形成数据库。最终对数据库进行评估和自校准,查找可能遗漏的数据并自动补充,对由于原文献数据不全导致空缺的情况进行备注。基于以上自动化流程,可随时对新发表的文献进行信息提取并更新数据库,实现了数据的自动化处理。
2.基于文本挖掘方法提取论文信息,构建了分子筛合成数据库。该数据库包含从2015年1月至2023年12月收集到的分子筛合成文献提取的5031条合成条件,涵盖了96种分子筛。数据库包含大量数据,具有统一的格式,可供实验人员查阅、检索。进行了骨架元素的占比及对应的分子筛种类占比的分析,对数据库中硅铝分子筛,硅磷铝分子筛和纯硅分子筛,进行了分子筛种类、拓扑类型、杂原子类型和常用的有机结构导向剂的数据分析。并针对最常见的五种分子筛进行深入探讨,对其合成方式的开发具有指导意义。填补了文本挖掘方法提取论文信息构建分子筛合成数据库的空白。
3.应用机器学习技术探究了合成参数与产物性质的关系。探究了无模板合成不同种类分子筛在三元相图中的分布情况,比较了无模板合成的不同硅铝分子筛在反应元素占比、晶化条件之间的区别,为实验提供了理论指导,指引了探索方向。对ZSM-5分子筛、SAPO-34分子筛进行了反应参数与产物性质之间的关联性探究,并使用机器学习模型进行数据分析,为实验上合成不同产物性质的ZSM-5分子筛、SAPO-34分子筛提供理论指导。将三元相图与决策树模型结合,顺利预测了无模板合成ZSM-5分子筛不同硅铝比对应的合成区域,区域内其他点对应的投料元素比例可作为合成特定范围硅铝比的另一项尝试,为实验人员提供新的合成思路。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.000158
{DOI}: 10.27162/d.cnki.gjlin.2024.000158
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于关系相关性的实体关系抽取方法研究
{Author}: 韩日东
{Tertiary Author}: 彭涛
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 实体关系抽取;长尾问题;多标签问题;关系相关性;关系层级结构
{Abstract}: 在互联网数据量激增的背景下,如何获取和利用海量非结构化文本中的知识信息成为了亟待解决的问题。实体关系抽取,作为获取知识的有效手段,旨在从文本中自动识别出实体间的语义关系,是知识图谱、搜索引擎等一系列应用服务的基石,受到了学术界和产业界的广泛关注。目前,虽然深度学习和预训练语言模型的蓬勃发展极大地提高了实体关系抽取任务的性能表现,但是它仍然受到长尾问题和多标签问题的巨大影响,在长尾关系类别和多标签实体对上的性能依旧差强人意。
本文针对实体关系抽取任务面临的长尾问题和多标签问题,提出了基于关系相关性构建关系抽取模型的解决方案。具体动机分为两个方面:(1)对于长尾问题,大量的关系类别虽然分布在数据量曲线的尾部,样本量不足,但是它们可能与分布在数据量曲线头部的某些关系存在高度相关性。通过这种相关性,在训练过程中可以实现从头部关系类别向尾部关系类别的知识传递,从而为尾部关系的样本学习到更有效的特征,提升尾部关系类别的训练效果;(2)对于多标签问题,同一实体对在特定上下文中可能同时表达多种语义关系,这说明被同时表达的关系类别间存在语义上的部分重叠。关系相关性能够度量出关系类别间的语义距离,从而帮助分类器为多标签实体对更准确地识别出语义上接近的关系类别,有利于分类过程中决策边界的划定。具体地,本文围绕“如何建模关系相关性”展开,针对关系类别间存在层级结构和不存在层级结构两种情况,提出了以下四种方法:
1.基于关系层级交互注意力机制的关系抽取。该方法针对关系类别间存在层级结构的情况,重点建模关系层级间的相关性,即父子关系类别间的相关性,提出了一种递归式的关系层级交互注意力网络。该网络的核心思想在于,沿着关系层级结构自上而下,让高层级的关系分类结果指导低层级的关系分类过程。具体来说,每个层级在进行关系分类时,会同时利用来自上一层级的历史知识和当前层级的输入信息,从而形成了递归式层级间交互的网络结构。实验结果表明,该网络结构有效地捕捉了关系层级间的相关性,不仅提升了关系抽取的整体性能,而且在长尾关系类别上显著优于基线模型。
2.基于全局层级嵌入和局部概率约束的关系抽取。该方法同样针对关系类别间存在层级结构的情况,同时建模关系层级间和关系层级内的相关性,即父子关系类别间与兄弟关系类别间的相关性,并从全局和局部双重视角构建了模型。从全局视角出发,将关系层级结构视作无向连通图,利用图神经网络进行编码,从而得到了蕴含相关性信息的关系嵌入表示,即全局层级嵌入。从局部视角来看,沿着关系层级结构自上而下逐层进行关系分类时,相邻层级的分类结果应该彼此依赖,以反映关系层级间的相关性。为此,设计了一个基于KL散度的局部概率约束函数,以保证相邻层级分类概率的关联性与一致性。实验结果证实了全局层级嵌入和局部概率约束的确捕捉到了大量相关性信息,在关系抽取整体性能和长尾关系性能上取得了显著提升。
3.基于关系共现相关性的关系抽取。该方法针对关系类别间不存在层级结构的情况,借助关系类别的共现现象来建模关系间的共现相关性。具体来说,该方法在多任务学习框架下,引入了粗粒度和细粒度两个关系共现预测任务,用于判断特定关系类别是否与一组其他关系类别在同一段文本中共现。这两个任务可以学习到所有关系类别的嵌入表示,而这些嵌入表示被用于构造额外特征并指导分类器利用关系共现相关性完成关系分类过程。实验结果表明,该方法在长尾关系类别和多标签实体对上的性能表现显著优于基线模型。
4.基于实体类型约束的关系抽取。该方法同样针对关系类别间不存在层级结构的情况,借助实体类型约束来建模关系相关性。所谓实体类型约束,是指特定关系类别所允许的主客实体类型是预先定义且固定的,即实体类型与关系类别间的约束关系。本方法从全局和局部两个层面利用实体类型约束,在全局层面,通过对训练集的统计构建实体类型约束图,并应用图神经网络得到各关系类别的嵌入表示。该约束图为每个关系类别限定了允许的主客实体类型,揭示了拥有相同主客实体类型的关系类别间的约束相关性。在局部层面,对于每个待分类的实体对,与其实体类型匹配的关系类别应受到分类器的更多关注,换言之,与实体类型匹配的关系类别的分类概率应高于不匹配的关系类别。基于此,设计了一种基于排序机制的类型约束损失。实验结果证实,关系类别间的类型约束相关性能够显著提高长尾关系类别和多标签实体对上的性能表现。
综上所述,本文针对实体关系抽取任务面临的长尾问题和多标签问题,从关系类别间存在层级结构和不存在层级结构两个角度,围绕如何建模关系相关性展开研究,证实了关系相关性在解决长尾问题和多标签问题上的有效性和巨大潜力,并为实体关系抽取任务提供了全新的视角。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.000057
{DOI}: 10.27162/d.cnki.gjlin.2024.000057
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的智能驾驶专利研究
{Author}: 张帅杰
{Tertiary Author}: 支凤稳
{Publisher}: 河北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 智能驾驶专利;专利计量分析;知识图谱;实体抽取;问答系统
{Abstract}: 随着经济与科技的发展,智能驾驶领域的研究借助物联网、区块链、云计算、人工智能等得到了飞速的发展以及广泛的应用。尽管相关领域的专利不断飞速涌现,但是对于用户来说,如何快速、便捷地查询智能驾驶领域的专利仍然是一个较为困难的问题。因此将知识图谱的便捷性与智能驾驶专利进行结合,通过以图形表达的形式来直观地展示和描述各类数据信息及其之间的关系,可以提高信息查询的准确性。本文首先对文献进行了计量分析,然后基于Neo4j知识图谱对智能驾驶专利的相关知识进行构建,同时在应用层选取了问答系统进行应用展示,提供了一种快捷查询的办法,为智能驾驶专利领域图谱的构建以及应用做了探索。首先对智能驾驶相关专利数据进行收集,通过定义检索关键词以及构建关系检索式的形式从专利数据库进行收集数据,并进行数据筛选以保证可以进行后续的实体标注以及实体和实体关系的抽取;在数据筛选完成后,借助专利文献计量的方法对现状以及发展趋势进行研究;然后通过阅读相关文献以及查阅资料对专利数据的实体类型以及实体关系进行归类,为后续的实体标注做准备;归类完成后借助在线文本标注平台Easy DL进行文本的标注,通过手工标注以及智能标注相结合的办法,并进行迭代优化,以保证后续的实体抽取过程可以顺利进行;在实体的抽取和关系抽取阶段,通过预先编码的方式在Py Charm中进行预训练,并借助联合抽取模型GPlinker对实体以及实体之间的关系进行抽取;最后将抽取的结果导入到Neo4j构建知识图谱。在应用阶段本文选择了问答系统对应用层进行展示,通过架构设计以及后台代码设计,实现了知识查询和建议的问答功能的构建,基于智能驾驶专利知识图谱的构建,实现了对智能驾驶专利的应用,利用关键词以及Cypher查询在Neo4j数据库中查询到相关的专利信息给予答案,并且提供了一种个性化推荐作答的方式。知识图谱与智能驾驶专利的结合,能够有效地提高用户对于相关专利的了解并提高利用效率,对未来的专利展示以及查询提供了新的方案,更好地推动智能驾驶专利的应用。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2024.000318
{DOI}: 10.27103/d.cnki.ghebu.2024.000318
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于强化学习和变换神经网络的无信号交叉口自动驾驶决策研究
{Author}: 于晏浩
{Tertiary Author}: 吴坚
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自动驾驶决策;无信号交叉口;深度强化学习;生成式预训练变换神经网络;仿真试验
{Abstract}: 随着自动驾驶技术的快速发展,确保自动驾驶车辆在复杂城市环境下的安全与效率成为研究的热点。特别是在无信号交叉口场景,车辆需做出快速准确的决策以避免潜在碰撞,挑战尤为显著。本文提出一种结合深度强化学习(Deep Reinforcement Learning,DRL)与生成式预训练变换神经网络(Generative Pretrained Transformer,GPT)的创新方法,旨在提升自动驾驶车辆在此类场景下的决策性能。面对无信号交叉口车辆交汇繁多的复杂情况,本文将该场景下自动驾驶车辆的决策任务抽象成序列建模任务,利用GPT的特点对序列数据深层次理解后,生成最佳策略。为了提高GPT模型对于驾驶决策任务的适应性,改进DRL算法并生成决策数据集对GPT微调;为了降低DRL训练难度同时提高决策数据集的质量,将复杂的无信号交叉口驾驶环境分解成了5个单任务场景进行仿真试验。全文具体内容如下。首先介绍了仿真环境的搭建,包括无信号交叉口场景的特点分析、路径优化以及任务场景分解与测试场景的定义。通过使用CARLA模拟器结合深度学习的Gym框架,构建了模拟实际场景中面对多种复杂的交通状况的无信号交叉口仿真环境。研究中,首先针对无信号交叉口的场景特点设计DRL决策算法。本文分析了强化学习的核心概念、原理与方法分类,进一步的阐述了深度强化学习算法及其在自动驾驶中的应用。通过分析深度强化学习算法中TD3算法的优缺点,针对较大的低估偏差的问题引入softmax函数,并使用PID引导策略初期加快探索。之后设计策略网络与价值网络,并在策略网络中引入了自注意力机制,用于捕捉多交互场景中智能体与环境的长期依赖关系,使策略网络生成动作更精准。最后根据无信号交叉口场景特点设计合适的状态空间、动作空间和奖励函数。然后,本文详细分析了基于变换神经网络的模型,尤其是其在理解复杂场景和增强决策过程中的潜力,提出通过结合这两种技术的优点,探索自动驾驶车辆在无信号交叉口的优化决策方法,并分析了自注意力机制的原理与架构,设计结合到DRL策略网络中。引入Transformer架构,并根据架构中各模块功能与本文的研究任务,选择使用以Transformer解码器为核心的GPT-2作为驾驶决策模型。通过对改进TD3算法的决策采样生成决策数据集,然后对GPT模型进行离线训练以生成最佳策略,提高在研究场景决策任务中的准确性和适用性。最后,通过在仿真环境中进行广泛的试验,本文验证了所提方法的有效性。结果表明,相比DRL方法,基于GPT模型的驾驶决策在无信号交叉口的性能和泛化能力显著提高。此外,基于GPT的自动驾驶决策系统的透明度和可解释性对比DRL算法也有了增强。本文的贡献在于提出了一个有效地结合深度强化学习与生成式预训练变换神经网络的自动驾驶决策框架,为解决自动驾驶车辆在无信号交叉口的决策问题提供了新的视角和技术路径。未来的研究将进一步探讨这一框架在更广泛自动驾驶场景下的应用及优化。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.003241
{DOI}: 10.27162/d.cnki.gjlin.2024.003241
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《ChatGPT对比人类》日汉翻译实践报告
{Author}: 郭嘉颖
{Tertiary Author}: 曾婷婷
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: ChatGPT;省略;标题翻译;同形异义词
{Abstract}: 在ChatGPT横空问世的背景下,本次翻译实践选取了日本朝日新闻记者平和博所撰写的《チャットGPTvs.人類》,该书籍共分为13个章节,此次翻译实践的内容为前7章节。本文旨在为译者提供该类型文本翻译的案例分析,并希望通过译文使国内读者了解国际上ChatGPT的发展态势。本文由四个主要部分构成。第一部分为文本介绍,明确文本内容与该文本语言风格,说明对此文本进行翻译的背景与意义。第二部分为翻译实践过程,分为译前准备、正式翻译和译后审校,其内容为笔者在进行翻译时对于标题、词语、句子的处理,以及译后的审校过程。第三部分为案例分析,遵循目的论三原则的指导,使用意译、词性转换、拆译、语序转换等翻译方法对标题、词语和句子进行了翻译。第四部分为翻译实践总结,总结笔者此次翻译实践过程中的收获与不足,以及对未来学习的展望。经过本次翻译实践,笔者深刻认识到“原文意思传达准确”与“译文通顺流畅”的重要性,即在准确传达原文意思的基础上,使译文符合中国人的表达习惯。笔者意识到这需要译员具备高超的中日文水平,因此,译者今后愿不断提升自身双语能力,提高翻译水平。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.006340
{DOI}: 10.27162/d.cnki.gjlin.2024.006340
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 翻译逻辑视角下《生成式AI：现代人的必修课》（节选）的翻译实践报告
{Author}: 孙小婷
{Tertiary Author}: 宋欣
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 逻辑翻译理论;翻译逻辑;科普文本
{Abstract}: 本次翻译实践报告所选取的文本为清水亮所写的科普书『教養としての生成AI』(《生成式AI:现代人的必修课》)。该书从AI的发展史、生成式AI的实际应用、以及在AI时代中人类应培养的能力等多方面进行了讲解,向读者传达了生成式AI的魅力和可能性,同时提供有助于正确使用AI技术的信息和知识。笔者选取该书的第五章与第六章作为翻译素材。该素材文本中含有大量需要进行逻辑梳理的语句、段落,应选取合乎逻辑的译法通俗易懂地传达给读者,从而达到科普目的。因此,笔者基于阎德胜的“翻译活动中的决定因素是思维活动”的视角,从逻辑翻译理论的翻译逻辑层面出发指导本次翻译实践活动,并从该层面探讨逻辑翻译理论对于科普文本翻译实践的指导意义。本翻译实践报告的主要内容由四个部分组成。第一部分是翻译任务的简介,内容包括作者及文本介绍、选题目的及意义以及翻译原则简介。第二部分是翻译的具体过程,包括译前准备活动、正式翻译过程以及译后审校工作。第三部分是在逻辑翻译理论的翻译逻辑层次下,从词语的翻译逻辑、句子的翻译逻辑以及段落的翻译逻辑三个方面列举原文中具有逻辑性的的典型词句案例以及分析过程。最后的部分是对本次翻译实践活动的经验总结,包括本次翻译实践过程中所遇到的困难、采取的对策以及不足之处等。本次翻译实践为笔者带来了许多收获。总体来说,当从翻译逻辑视角探讨科普文本的翻译时,首先要在保证科学相关术语严谨对译的基础上,仔细分析含有逻辑性的词语,根据原文语境推理深层含义;其次从语句结构、句间关系等入手,选择符合句子逻辑的翻译方法;最后注重从整体性与连贯性两方面来梳理段落。循序渐进地对原文进行处理,以不断优化译文的逻辑框架。同时,笔者针对本次翻译活动的待改进之处进行了自我反思,希望能够成为今后的借鉴,并为翻译同类型文本的翻译工作者提供一份可供参考的经验。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.002987
{DOI}: 10.27162/d.cnki.gjlin.2024.002987
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 司法人工智能问题研究
{Author}: 王梦婷
{Tertiary Author}: 杜宴林
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 司法人工智能;司法裁判;法律推理;自动化决策
{Abstract}: 在2017年发布的《最高人民法院关于加快建设智慧法院的意见》中,最高人民法院明确指出了要利用大数据、审判动态分析和智能研判技术,以优化司法决策过程,并提升司法预测的精准性。而在2022年发布的《最高人民法院关于规范和加强人工智能司法应用的意见》中,进一步强调了人工智能在司法工作中应发挥全方位辅助作用,在数据采集、语义认知、裁判推定逻辑等环节都应当具备可解释性,但是以算法模型预测案件判决结果的人工智能却有可能产生溢出效果,判决偏离度预警功能会对法官自由裁量权产生部分影响。因此,需要进一步探讨司法人工智能的运作逻辑,并对司法人工智能规制路径进行优化。以推理模式为区分,司法人工智能可分为代表演绎推理的代码驱动型人工智能,以及代表类比推理、归纳推理的数据驱动型人工智能,甚至在数据驱动型人工智能结合了深度学习、人工神经网络技术等后出现的新型人工智能。在实践运用领域,我国司法人工智能大致具备电子卷宗移送、全案证据审查、判决文书自动化制作、类案推送、量刑参考、裁决偏离预警等项功能。例如北京“睿法官”依托海量历史审判数据资源库,对裁判文书提取当事人信息、案情、判决结果形成裁判模型,在法官审理待决案件时自动推送历史类案以供参考。上海206系统对办案过程中的历史判例进行“法定刑、基准刑、宣告刑”三维度数据标注,形成神经网络自主学习,为待决案件提供量刑依据。相较于国内各地法院的自动化应用形态,外国司法人工智能的建设样态更为激进。爱沙尼亚的“机器人法官”甚至能够独立用于裁决少于7000欧元的小额索赔案件。就其内部运作逻辑而言,司法人工智能贴合莱布尼茨所提出的法律公理化体系理念:法律被分解为演绎科学,法律推理从严密的逻辑体系中即可得到唯一性结论。这种以逻辑和抽象法律概念、同案相关性决定案件裁判的司法人工智能则因过分注重形式合理性,因而有倒向机械法理学的风险,这在代码驱动型人工智能中尤为严重。数据驱动型人工智能代表类比推理,但字符相关性又难以代替逻辑推理中的因果性,导致案件裁决都是或然性裁决。此外,当前自然语言技术也难以应对呈动态性变化、注重上下文语境、存有语义模糊的法律语言。结合各种司法人工智能的特征以及运作逻辑,可以说数据驱动型人工智能的黑箱效应致使裁判理由的缺失,内部算法对裁判结论直接影响、审判主体复数化等现象更是损害法律的权威性。省略去陈述申辩、举证质证、法庭辩论等环节也导致程序正义的受损,而司法人工智能内部缺乏价值判断、前瞻性、经验性的性质又使得实质正义面临冲击。在优化路径上,尽管司法人工智能已可运用于简单案件,但在复杂案件领域其仍应保持辅助性地位。对于代码驱动型人工智能而言,需要搭建法律渊源框架,尤其注意明确习惯、指导性案例的效力,对于数据驱动型人工智能而言,需要进一步保证类案筛查的准确性。在算法形成、运转的各大环节内,为有效破解司法人工智能黑箱效应,可事前预先确定人工智能内部的参数标准,通过不断训练致使输出贴合期望值,当人工智能处理数据生成决策方案后,相应地给予当事人事后质疑以及要求算法解释的权利。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.006962
{DOI}: 10.27162/d.cnki.gjlin.2024.006962
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的中医穴位自动问答系统
{Author}: 刘泽迪
{Tertiary Author}: 邱桃荣;杨词平
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 知识图谱;中医穴位;自动问答;命名实体识别
{Abstract}: 人工智能与中医结合为中医发展带来新机遇。针对中医穴位知识体系复杂和知识散乱,公众对中医穴位知识的需求日益增长这一问题,研究构建中医穴位知识图谱和中医穴位知识自动问答系统,提出利用深度学习模型实现中医穴位知识图谱自动构建和识别自然语言问句意图,设计实现基于知识图谱的中医穴位自动问答系统。主要研究内容与阶段性成果如下。(1)研究中医穴位知识图谱的构建。以自顶而下策略研究适合中医领域的穴位知识图谱构建方法,借鉴现有中医穴位相关资料设计并定义了中医穴位知识图谱模式层。在知识抽取方面,面向中医穴位数据特点,提出了基于BIO标注方法和结合Soft Lexicon与对抗训练对Ro BERTa-WWM-Bi GRU-CRF模型改进的中医命名实体识别模型,实现知识的三元组表示。所改进的命名实体识别模型以Ro BERTa-WWM模型捕捉文本的深层语义,以Bi GRU模型理解序列的上下文,以CRF模型确保序列标注准确实现实体识别。针对中医穴位数据集较少、错别字较多导致识别准确性和鲁棒性差的问题,对Ro BERTa-WWMBi GRU-CRF进行改进,即在模型中引入对抗训练FGM,通过对字向量施加微小扰动生成对抗样本,增强模型泛化能力和鲁棒性。针对中医领域文本富含专业术语、古文词汇和表达方式独特导致实体边界提取困难的问题,在上述改进模型的基础上引入Soft Lexicon,融合词典信息至字符级表示,提升模型对中医穴位领域实体边界识别。在收集的中医穴位数据集上,与Lattice-LSTM、BERT-CRF、BERT-Bi LSTM-CRF等先进的模型进行对比实验,在F1值上分别提高了18.4%、11.26%、9.56%,达到了93.48%,并通过消融实验验证改进模型的有效性。(2)研究基于知识图谱的中医穴位自动问答方法。在问句意图识别方面,提出结合自注意力的Ro BERTa-WWM-Text CNN意图识别模型。该模型用Ro BERTa-WWM预训练模型将问句文本转化为特征向量,利用Text CNN捕捉文本语义信息,最后运用Softmax函数实现问句意图识别。为提升Ro BERTaWWM-Text CNN模型在处理中医穴位复杂信息时的筛选能力,通过引入自注意力机制使模型能聚焦于对中医穴位问答任务关键信息。在自制数据集上,结合自注意力的Ro BERTa-WWM-Text CNN模型的F1达到92.42%。在实体链接和知识检索方面,利用同义词库和实体相似度计算方法将识别出的问句候选实体链接为知识图谱实体,最后依据问句三元组检索图数据库得到答句三元组,并转换成自然语言形式的答句。最后设计与实现基于知识图谱的中医穴位自动问答系统。实现了以Flask和Spring Boot为核心的混合后端架构,分别负责核心算法逻辑和支撑业务功能的实现。前端采用Vue框架,为用户提供了直观友好的交互体验。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2024.002261
{DOI}: 10.27232/d.cnki.gnchu.2024.002261
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的中文新闻标题文本分类算法研究
{Author}: 桂国涛
{Tertiary Author}: 任燕;何煊
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;新闻文本分类;特征拓展;注意力机制
{Abstract}: 在当今互联网飞速发展、网民数量急剧攀升的背景下,新闻仍然是人们获取社会信息、了解时代变化的主要途径。尽管新闻的传播形式正在向图片、视频等多媒体方向发展,但新闻标题作为信息的主要概括仍然是以文字形式存在。面对互联网上大量涌现的新闻标题短文本,读者要找到感兴趣的新闻类别变得更加困难。因此,发展短文本分类技术具有重要意义。由于中文短文本的数据稀疏性问题,其分类效果往往不理想。目前,现有的中文短文本分类深度学习模型主要基于词或字符等模式特征提取。由于单模式特征提取难以解决短文本的数据稀疏性问题,因此分类效果并不理想。为解决上述问题,本文做出了以下的工作:(1)提出了一种名为N-Radical的中文特征拓展算法,其核心思想是结合偏旁部首和N-gram特征,以更全面地理解文本内容。该算法通过将偏旁部首和N-gram特征结合,不仅提高了对汉字构成和含义的理解能力,还有效捕捉了词语间的局部关系和语境信息,从而提高了模型对文本的语义理解和结构理解能力。并在传统Text CNN和GRU上进行了对比试验和消融实验,实验结果表明,加入N-Radical算法后在中文新闻标题分类任务上能显著提高传统Text CNN和GRU的性能,为中文文本处理领域的进一步研究和应用提供了有益参考。(2)提出了基于双向GRU、Attention、CNN构建多通道短文本分类模型,结合上面提出的N-Radical的特征拓展算法对原始文本进行处理。通过设计5个基线模型在THUCNews、Toutiao新闻数据集、微博热搜数据集3个数据集上进行对比实验。实验结果显示,相较于评价指标最好的基线模型,NR-GAC在准确率和F1得分在三个数据集上分别高出了3.59%、2.78%、3.94%和3.17%、2.88%、5.08%。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2024.002565
{DOI}: 10.27232/d.cnki.gnchu.2024.002565
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 功能对等理论指导下《即将到来的浪潮》（节选）汉译实践报告
{Author}: 陈秋美
{Tertiary Author}: 赖祎华
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 《即将到来的浪潮》;功能对等理论;科技翻译
{Abstract}: 2024年《政府工作报告》首次提出要以“AI+”打造新质生产力,突出AI在科技创新领域的战略地位。值此AI发展的重要时间节点,AI相关书籍的翻译显得更加重要。《即将到来的浪潮:技术、权力和21世纪最大的困境》是英国人工智能先驱之一穆斯塔法·苏莱曼和美国作家迈克尔·巴斯卡尔共同撰写的一本科技类书籍,出版于2023年9月。作者在书中简单回顾了人工智能技术的发展历程,深度解读了人工智能、合成生物等高端技术即将带来的机遇和威胁,并提出了他的建议。本书属于科技主题的信息型文本,要求译文既要忠实严谨又要通顺易懂,语义准确和逻辑合理比结构和形式上的对等更加重要。这与功能对等理论的翻译原则有契合之处。尤金·A·奈达的功能对等理论强调好的译文需要让译入语读者获得和源语读者相似的反应,努力做到最大程度的对等。在翻译时,奈达认为译者需要在语义对等的基础上尽可能满足形式对等,而在两者冲突时,则遵循“意义第一,形式第二”的原则。译者在认真学习功能对等理论的相关原则和翻译策略后,在该理论的指导下进行了翻译实践,并从词汇、句法和语篇三个视角进行了具体翻译案例的分析。译者灵活运用词性转换、语序转换、顺译法、分译法等翻译方法,力求准确传达原文的语义,让译入语读者尽可能获得和源语读者相似的体验,并在语义准确的基础上努力实现形式上的对等。本实践报告有助于功能对等理论与科技类文本翻译的结合,丰富该理论在科技文本翻译方面的应用实践,为探索科技类文本翻译的高效路径提供经验参考。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2024.001887
{DOI}: 10.27232/d.cnki.gnchu.2024.001887
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多模态情绪识别方法研究
{Author}: 冀硕
{Tertiary Author}: 王欢;王程
{Publisher}: 石家庄铁道大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 多模态情绪识别;CLIP;特征提取;决策级融合
{Abstract}: 近年来,随着人工智能和计算机算力的迅猛发展,多模态情绪识别成为研究热点。通过整合文本、图像、音频、等多种模态的信息,并利用不同模态间的互补性来增强情感特征的表达能力,使得多模态情绪识别获得了比单模态情绪识别更高的准确率。针对多模态情绪识别模型可迁移能力不佳的问题,通过引入CLIP模型(Contrastive Language-Image Pre-Training),提出了一种基于文本、语音、图像的决策级融合多模态情绪分析模型CLIP-Decision,主要工作如下:(1)为了提高语音单模态情绪识别的准确率,对比分析了Log-Mel谱图特征和MFCC特征在语音情绪识别中的表现,由于Log-Mel谱图特征对不同性别声音能量区分能力更强,使其在不同算法和数据集中均表现出了更佳的识别性能,其中以Log-Mel谱图为特征的3D CNN-LSTM算法以71.75%的识别率成为最佳算法,因此将其作为语音单模态情绪识别模型,为对其优化并进行多模态融合做准备。(2)针对CLIP模型在图像-文本情绪识别任务中识别性能不佳的问题,提出了一种基于CLIP的CLIPRT模型(CLIP-Res Net-Transformer),该模型分别使用Res Net图像编码器和Transformer文本编码器,并针对Res Net编码器的计算速度较慢的问题,将半精度浮点数用于训练深度神经网络,结合使用网格搜索、随机搜索和手动调整来设置初始超参数等方法来提升CLIPRT模型的识别速度。(3)针对多模态情绪识别模型迁移能力弱的问题,本文提出一种基于CLIP的决策级多模态融合模型CLIP-Decision,该模型以3D CNN-LSTM算法和CLIPRT模型为基础,将时空注意力机制引入Res Net编码器作为视频编码器提取图像特征,并与Transformer文本编码器提取的文本特征进行匹配从而实现情绪识别。还提出了一种基于规则的决策级融合机制,通过调整混淆阈值降低单模态混淆对CLIP-Decision模型情绪识别性能的影响。CLIP-Decision模型较6种常用的多模态情绪分析模型,不仅识别准确率有所提升,且在IEMOCAP、CMU-MOSEI等四个数据集上的识别准确率均达到了75%以上。
{URL}: https://link.cnki.net/doi/10.27334/d.cnki.gstdy.2024.000691
{DOI}: 10.27334/d.cnki.gstdy.2024.000691
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《GPT-4人工智能现状》视频模拟口译实践报告
{Author}: 辛冠霖
{Tertiary Author}: 赵真
{Publisher}: 内蒙古师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 人工智能;模拟口译;听辨理解;译语表达
{Abstract}: 人工智能是近年来科技领域的关键发展方向之一,其在各个领域的迅速应用引发了广泛的关注和探讨。ChatGPT作为OpenAI公司开发的人工智能技术的一种具体应用,利用深度学习和自然语言处理技术模拟人类对话,展现了人工智能在语言理解和生成方面的卓越表现。本次口译实践选取了源自俄罗斯视频网站“Дзен”下“PRO роботов”频道的视频作为语料来源,该视频囊括了对当前ChatGPT等人工智能技术的全面分析。报告通过回顾本次模拟口译实践过程,分析所遇到的问题,并进行反思和经验总结,普及该领域知识、提升译员专业素养的同时,为今后从事该方向的译员提供思路与启发。本篇模拟口译报告分为引言和正文四个部分。引言部分对人工智能的概念和论文整体结构安排进行介绍;第一部分对口译任务背景信息进行简单介绍,包括语料的选题背景、来源、特点和意义,使读者了解口译任务的基本情况;第二部分详细描述模拟口译过程中的步骤,涉及到译前、译中和译后三个环节;第三部分从“听辨、理解、表达”三个角度出发,对口译过程中遇到的各种问题选取代表性案例进行分析,通过探讨问题的成因并提出解决方案,以便更好地应对类似的情况,是整篇报告的核心内容;第四部分总结口译实践的经验教训和收获,包括在这个过程中学到的知识、技能和对口译工作的反思,并对未来口译实践提出展望。
{URL}: https://link.cnki.net/doi/10.27230/d.cnki.gnmsu.2024.001189
{DOI}: 10.27230/d.cnki.gnmsu.2024.001189
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能文学创作的交互主体性研究
{Author}: 王雨涵
{Tertiary Author}: 郭昭第
{Publisher}: 天水师范学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 文学创作;人工智能;交互主体性
{Abstract}: 人工智能文学创作的兴起,标志着文学创作领域的一次重大转变,并为文学理论研究提供了全新的视角与思考空间。文学创作不再是人类独有的活动,人工智能的参与重新定义了创作过程和创作主体。在这一背景下,人工智能如何处理并解码语言、情感与文化背景,以及如何通过这一过程评估人工智能生成的文学作品的价值就成为了亟待探讨的问题。随着人工智能技术在文学创作中的应用逐渐增多,人们开始有机会深入分析人机之间的互动实践。这些实践不仅提供了丰富的案例,也让交互主体性概念拓展至新的维度。在人机交互创作文学作品的过程中,人工智能并不是简单地替代人类作者,而是通过与人类的共同合作从而拓宽文学创作的视野与范围,揭示出人类作者和机器之间的互补性以及创作过程中的新的可能性。人类作者与人工智能系统的合作超越了简单的技术互助,它们之间的互动成为了一种具有创意思维和审美价值的共享过程。这种互动不仅停留在技术层面,还涵盖了更加复杂的情感交流、文化理解以及新型人机交互方式。此外,交互主体性概念也从传统的人类主体扩展到了包括人工智能系统在内的数字化主体,为文学与技术的融合提供了新的理论支撑,促进二者之间的深度对话。通过探索人工智能技术在文学创作中的作用与意义,有助于人类主体能够更好地理解人类创作活动的本质并探索文学创作与技术发展的未来趋势。尽管人工智能技术与文学的融合带来了新的机遇,可一旦过度依赖技术,就有可能会导致文学创作失去其最为核心的人文精神与情感深度,甚至导致人类主体被异化与仿象所支配。因此,在对人机交互关系的思考中,应当积极应对这一融合可能带来的风险与挑战,构建出人类与人工智能能够和谐共生的环境。
{URL}: https://link.cnki.net/doi/10.27868/d.cnki.gtsxx.2024.000072
{DOI}: 10.27868/d.cnki.gtsxx.2024.000072
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向儿科常见疾病的智能问答技术研究与应用
{Author}: 李佳丽
{Tertiary Author}: 李晖
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 大语言模型;儿科医疗轻问诊模型;基于RAG的问答优化;结构化剪枝;LLM-Pruner
{Abstract}: 近年来,以Chat GPT和GPT-4为代表的大语言模型,增强了人工智能的泛化性、通用性,开启了人工智能问答发展的新范式。大语言模型技术的突破,也为医疗人工智能发展注入了新动力。因此,基于大语言模型的医疗智能问答技术有望满足用户对医疗轻问诊的需求,是医疗智能问答领域未来发展的趋势。然而,将通用大语言模型应用于医疗领域,仍面临一系列挑战。因此,本文开展面向儿科常见疾病的智能问答技术研究工作,工作内容如下:(1)针对医疗人工智能应用重度依赖高质量海量数据的问题,本文基于《儿科疾病诊疗规范》丛书和近千篇《儿科临床指南》等专业医疗文献资料,构建了目前国内少有的中文儿科常见疾病医学知识库。基于此知识库,对通用大语言模型Baichuan2-13B-Chat进行指令微调,成功构建了面向儿科常见疾病的儿科医疗轻问诊模型,并将其命名为“Xiao Bao”。(2)针对医疗大语言模型在处理医疗问题时由于缺乏充分的上下文信息,导致模型产生不准确的预测或诊断的问题,本文基于检索增强生成(RetrievalAugmented Generation,RAG)方法进行问答优化,通过整合非参数化的外部数据库中的相关儿科医疗知识,增强儿科医疗轻问诊模型性能。基于RAG的问答优化采用了一种协同的方式,结合信息检索机制和上下文学习方法在增强儿科医疗轻问诊模型的性能的同时,也提高模型响应的准确性和专业性。(3)针对医疗大语言模型的日常运营和模型迭代需要消耗大量算力的问题,本文基于结构化剪枝框架LLM-Pruner对儿科医疗轻问诊模型进行剪枝。LLMPruner通过移除模型结构中的冗余部分,同时采用低秩近似算法对剪枝后的模型进行恢复训练,在保证模型性能的前提下可显著减少模型的参数量和计算复杂度。通过剪枝和恢复训练处理,儿科医疗轻问诊模型在保持原有的高精度、高效能的同时,极大地降低对算力的需求。这对于在资源有限的医疗环境中推广和应用儿科医疗轻问诊模型Xiao Bao具有重要意义。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2024.003079
{DOI}: 10.27047/d.cnki.ggudu.2024.003079
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 生成式人工智能的社会性风险及行政法规制研究
{Author}: 林金宝
{Tertiary Author}: 王孟嘉
{Publisher}: 河南大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 生成式人工智能;行政法规制;社会性风险;回应性监管
{Abstract}: 在第四次工业革命的浪潮中,人工智能技术依托于人工神经网络与深度学习理论方面的显著突破,借助于海量互联网数据资源及强大的计算处理能力,实现了重大进展。这一技术的革新,为人类的多个领域注入了新的活力,开辟了人工智能应用的新篇章。2023年3月由Open AI公司推出的依托于大语言模型的生成式人工智能Chat GPT-4.0横空出世,凭借卓越的自然语言处理和深度学习能力,其将与各行业的生产经营和管理实践实现深度融合,为国家产业发展与创新转型提供了契机,但也隐含着一定的风险。人们突然发现智能工具已经超越了人类认知的极限并可以在特定领域与人类主体比拟,社会成员在享受智能技术发展所带来的便利之时,也对于其在价值观念和社会秩序等方面带来的挑战展开了思考。发展与风险是事物演进的一体两面。Chat GPT类生成式人工智能在资本的扶持下,沿着“自我进化”的路径不断成熟,但反噬技术发展的力量也在潜滋暗长。生成式人工智能的社会性风险不断外溢,在监管滞后和技术扩张的联合作用下,技术的内生性漏洞可能外化为内容生成的虚假、伦理观念的偏差、个人隐私的侵犯等,技术的发展过度崇尚“工具理性”,忽视了“价值理性”要素,引发人的主体性、公私法益受损的广泛风险迭代问题,进而给个体、社会带来更大的不确定性风险。生成式人工智能还改变了数字社会的生产架构,向传统的治理范式提出挑战。由于民事、刑事规制对于新兴技术的治理有着天然的劣势,所以需转向具有较大适应性和灵活性的行政法视域。但传统的行政法规制模式也存有一定的局限,面临规制迟滞和专业资源匮乏、市场主体自治动力缺失与协调性不足的困境,以往分散式的治理模式难以统筹生成式人工智能生命周期的治理全局、基于法律规范的硬性治理难以提升治理实效、基于强制措施的命令模式弱化了主体关系,作为一种具有前瞻性的动态治理范式,行政法中的回应性治理恰好贴合当下技术快速迭代与技术普适性的发展环境,给我国的新兴技术行政法规制提供了新的视角。行政法的本质在于对既有利益分配机制的调和,其根本目的仍是促进社会主体“人”的发展。在数字经济发展的视域下,行政法的治理既要把握好技术的创新,也要注重社会主体利益的衡量。在现阶段,我国应集中针对生成式人工智能的风险源头,由行政机关承担掌舵者的治理职责,坚持创新发展与风险治理平衡总体思路,基于回应性治理的全局性、适应性与灵活性,秉持前瞻的风险预防理念,遵循包容审慎的监管策略;以此搭建回应性的全过程、全生命周期的监管模式;在具体应对路径上,应完善框架性的软硬法结合规范体系,依据生成式人工智能的风险特性来进行分级分类治理,发挥多元主体的资源和能力优势。从而,谋划全面性的行政法治理格局,实现生成式人工智能治理范式革新,促进科技向上向善发展。
{URL}: https://link.cnki.net/doi/10.27114/d.cnki.ghnau.2024.002142
{DOI}: 10.27114/d.cnki.ghnau.2024.002142
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能环境下企业招聘管理的优化设计
{Author}: 邢岩
{Tertiary Author}: 张苏串
{Publisher}: 山西大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 中国邮政;人力资源管理;人工智能;招聘管理;优化设计
{Abstract}: 在全球化和信息化的背景下,企业竞争的关键在于人才争夺。中国邮政集团作为全球最大的邮政服务提供商之一,面临激烈的市场竞争,需要不断优化招聘管理以适应市场和战略需求。传统招聘管理存在效率低、成本高、信息不对称等问题,无法满足企业对人才招聘的迫切需求。随着技术进步,企业开始采用数字化和自动化工具提升招聘效率,但这些工具的应用场景仍存在一定局限性。人工智能(AI)技术的应用,通过深入分析简历、评估候选人的非语言行为等手段,可以显著提升招聘的准确性和效率。此外,中国政府的政策支持为AI技术在招聘管理领域的应用提供了坚实的基础,为企业的人才招聘工作带来了新的机遇。本研究聚焦于中国邮政集团有限公司L分公司,旨在探讨在人工智能技术的推动下,如何优企业的招聘管理策略。研究首先通过对人力资源招聘管理及人工智能领域相关文献的广泛梳理,为文章构建了扎实的理论基础。为深入了解企业在招聘管理方面的实际情况,研究采用了问卷调查的方法。本次调查覆盖了L分公司内的各类员工,目的是收集员工对于企业当前招聘管理的了解程度、满意度以及个人看法。通过对问卷数据的详细分析,本研究成功识别了企业在运用传统招聘管理中存在的关键问题,特别是员工普遍反映的招聘的效率、公正性和合理性方面的关切。基于L邮政的实际情况和问卷分析结果,本文设计了一种运用人工智能相关技术的企业招聘管理的方案。从人员需求分析、简历收集与筛选、人员面试评估三阶段进行了分析,基于这些分析与每个阶段的任务特性,结合人工智能中的自然语言处理技术、计算机视觉技术、语音分析技术以及机器学习技术提出了对应的解决方案。该方案可极大程度的降低企业招聘管理中所需的人力成本,为企业管理的数字化升级改革提供了新的视角。本文以中国邮政集团L分公司为研究对象,针对其招聘管理中出现的效率、准确度和公平性等挑战,提出了基于人工智能技术的创新解决方案。值得注意的是,这些招聘管理问题并非仅存在于L分公司,在一些传统国有企业中也有出现。本文的研究希望为有类似困境的企业提供新的视角和策略参考,通过应用人工智能技术优化招聘流程,进而提升招聘效率、降低成本,为企业的人力资源管理和长期发展奠定坚实基础。
{URL}: https://link.cnki.net/doi/10.27284/d.cnki.gsxiu.2024.002227
{DOI}: 10.27284/d.cnki.gsxiu.2024.002227
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的网络评论方面级情感分析研究
{Author}: 卢瑞杰
{Tertiary Author}: 廖汗成
{Publisher}: 江西财经大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 网络评论;方面级情感分析;方面识别;方面级情感分类;茂名市旅游业
{Abstract}: 随着网络的普及和互联网技术的飞速发展,网络评论数量迅猛增加,成为了包含丰富情感信息的宝贵资源。深入分析网络评论可带来巨大的经济和社会效益。细粒度的方面级情感分析能够判断网络评论中各个方面的情感倾向,受到广泛关注。因此,本研究专注于方面级情感分析中的两个关键子任务:方面词识别和方面级情感分类。针对现有模型的局限,分别提出了基于BERT-AEW-BiGRU-CRF的方面识别模型和基于IA-RelationGCN的方面级情感分类模型。此外,本研究将验证后的模型运用于构建的茂名市旅客评论数据集,评估旅客对茂名市旅游业各方面的评价。基于BERT-AEW-BiGRU-CRF的方面识别模型,通过引入自适应元素加权(AEW)方法调整词向量编码表示,缓解文本中词汇分布不均匀导致的词向量偏移问题。该模型利用BERT对文本数据进行结构化。通过AEW方法增强模型对关键词汇的关注,实现对词向量的优化,使模型能够更准确地理解上下文信息。通过BiGRU捕获上下文信息。利用CRF层学习标签间依赖,以识别方面词。将构建的BERT-AEW-BiGRU-CRF模型与选定的基线模型进行对比实验。实验结果证明了所提模型在方面识别任务中的优势。同时,消融实验结果证明了 AEW方法的有效性。在方面级情感分类任务中,针对现有研究往往忽略了方面词关系、上下文中方面词自身语义,以及其他关键词汇的影响。本文设计并构建了基于IA-RelationGCN(Interactive Attention-Relational Graph Convolutional Neural Network,IA-RelationGCN)的方面级情感分类模型。该模型利用BERT对文本进行结构化,并使用BiLSTM对上下文进行建模。通过构建包含句法关系的图结构,并利用图卷积网络提取句法信息。为增强模型对重要词汇的关注,引入位置编码到图卷积网络中,提出了一种融合位置编码的图卷积网络。构建包含方面词关系的图结构,并利用改进的图卷积网络提取方面关系。通过对图卷积网络的输出进行掩码处理,提取方面词语意特征。最后,利用交互式注意力机制对上下文特征与方面词语义建模,判断方面词的情感极性。在相关数据集上,将此模型与选定的基线模型进行对比试验。实验结果显示了所提模型的有效性。通过消融实验,证明了 IA-RelationGCN模型各组成部分对性能提升均有贡献。本研究通过自然语言处理技术筛选收集的茂名市旅游评论和游记,并进行数据标注,构建了一个适用于方面级情感分析的数据集。为提升数据预处理质量,构建了一个适用于旅游领域的停用词典。在此基础上,应用所构建的模型对茂名市旅客评论进行细粒度的情感分析。通过对结果进行统计和解析,评估了茂名市旅游业现状。
{URL}: https://link.cnki.net/doi/10.27175/d.cnki.gjxcu.2024.001324
{DOI}: 10.27175/d.cnki.gjxcu.2024.001324
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向汽车故障知识图谱构建的实体关系抽取算法研究
{Author}: 文雯
{Tertiary Author}: 徐飞;郑宇哲
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 命名实体识别;MacBERT;关系抽取;知识图谱
{Abstract}: 随着汽车行业不断迈入智能、互联、电动、自动驾驶的新时代,车辆故障率激增,检修难度大幅提高。车辆故障检修机构积累了大量维修数据,但因分析手段匮乏,这些数据未能充分利用。这导致在进行领域信息自动化时面临着诸多难点,其中以实体识别及关系抽取这两类基础任务最为典型。例如,车辆故障数据的多样性和复杂性使得实体间的关系难以准确捕捉。同时,现有数据往往记录方式不统一、描述模糊不清,这给实体关系抽取也带来了许多挑战。因此,如何有效地处理和利用这些数据,提高实体关系抽取的准确性和效率,构建领域知识图谱,是当前汽车故障领域亟待解决的重要问题。
针对当前汽车故障检修现状,本文聚焦于汽车故障检修领域非结构化文本数据,旨在深入探讨故障文本的核心要素并分析其关联性,最终达成汽车故障检修知识抽取与图谱建立的目标。本文研究的成果希望能为汽车故障检修相关人员提供必要的辅助支持,以应对不断增多且多样化的故障事件,提高故障处置效率。具体工作如下:
(1)在知识抽取的命名实体识别任务中,为提高故障文本实体识别准确率及效率,本文提出一种中文命名实体识别模型MCIC(Mac BERT-Char-IDCNN-CRF,MCIC)模型。为避免分词维度单一和重要词汇信息丢失的问题,模型使用不同分词策略下的词汇信息复合Mac BERT预训练模型作为输入,通过混合膨胀卷积神经网络对输入的文本进行特征提取,最后使用条件随机场进行标签预测得到实体识别结果。实验证明,本文提出的MCIC模型相较于传统实体识别模型有3.77%的F1值提升。
(2)在知识抽取的关系抽取任务中,提出一种融合对抗训练与实体信息嵌入的端到端关系抽取模型。针对关系抽取任务无法很好的利用实体类型及边界信息,导致抽取精度不高问题做出改进。首先在关系分类前明确实体类型,确定实体边界范围,在模型输入部分引入实体信息标识符,以增强其对特定领域的适应性。其次加入FGM(Fast Gradient Method,FGM)对抗训练,将字向量与扰动相加生成对抗样本,增强模型的泛化能力及鲁棒性。实验显示,与基线关系抽取模型进行比较,本文模型在准确率、召回率以及F1值三项评价指标上均有一定提高。最后,本文将抽取出的候选三元组存储在Neo4j图数据库中,搭建一个简单的汽车故障检修领域知识图谱,用于查询关系和展示节点等功能。
实验结果表明,本文提出的模型在知识抽取任务中取得了良好的效果。在文本结构化程度不高及数据样本小的情况下,采用深度学习手段获取更深层的语义信息,对增强模型识别效率及泛化能力上取得了一定优势。基于知识抽取算法构建的领域知识图谱为处理复杂的汽车故障检修信息提供了一种结构化的手段,也为用户提供了搜索引擎外的另一种简单可靠的信息检索途径。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000570
{DOI}: 10.27391/d.cnki.gxagu.2024.000570
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 大语言模型差分隐私保护关键技术研究
{Author}: 张玉姗
{Tertiary Author}: 梁晓艳
{Publisher}: 河北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 差分隐私;大语言模型;生成对抗网络;自然语言处理;隐私保护;深度学习
{Abstract}: 大语言模型是指具有大量参数的语言模型,经过预训练任务来理解和处理人类语言,然后通过对来自大量文本数据的上下文化的文本语义进行建模。第三方、研究人员和从业者越来越多地采用这些预先训练好的模型,并对其私人数据进行微调,以完成下游的人工智能任务。然而,已经表明,攻击者可以从这些大语言模型中提取/重建精确的训练样本,这可能导致暴露个人可识别信息。这一问题引起了人们对大语言模型隐私的深切关注。差分隐私是一种可以在理论上保证训练数据的隐私的方法。它起源于统计数据库领域,是定义处理隐私和防止披露的最重要标准之一。差分隐私提供了一个严格的框架,该框架允许在训练或微调大语言模型的过程中添加噪声,使得提取训练数据变得不可行。
如何利用差分隐私这一关键技术实现安全高效用的大语言模型成为大语言模型广泛应用的瓶颈,其中,更准确的差分隐私评估和更高可用性的差分隐私保护方案构建是两个关键技术。本文将围绕这两个关键技术展开深入研究。
(1)针对差分隐私评估中分类器仍无法找到强大攻击的问题,提出基于生成对抗网络自动检测给定差分隐私的评估工具DP-Discriminator。基于数学定义,首先提出了一种新的ξ-DD攻击概念。此外,利用生成对抗网络零和博弈的思想优化生成器和判别器,使得生成器能够生成近似真样本的伪样本,判别器学习复杂数据的真实分布,从而提高分类能力。所提出的DP-Discriminator根据生成对抗网络捕获潜在数据特征的能力,学习样本间特征的整体分布。由于强大的分类器,DP-Discriminator能够以最小的时间消耗自动准确评估差分隐私。实验结果表明了所提方法在估计各种差分隐私算法的ξ-DD中的有效性。在最新工作中,检测算法RAPPOR(0.4-DP)的ξ-DD的值为0.301,而所提工具检测到ξ-DD=0.369,误差降低了一个数量级。
(2)针对大语言模型差分隐私方案中依赖第三方且无差别保护训练数据的问题,提出基于本地差分隐私的大语言模型隐私保护效用方案。为解决大语言模型中隐私效用平衡这一问题,分析现有LLM隐私保护工作大都集中在中心化差分隐私上的局限性,。针对当前本地差分隐私机制将所有数据视为同等敏感这一特点,该方案首先在本地私有化文本,通过敏感检测器检测训练数据中可能影响下游任务的敏感令牌,对敏感令牌引入效用优化本地差分隐私,将其提交给大语言模型微调以完成下游任务。实验表明,与以前的基线相比,该方案在四个具有代表性的公共数据集上都具有很强的实用性。最后评估了嵌入反转和成员推理攻击场景下的隐私保护水平。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2024.000955
{DOI}: 10.27103/d.cnki.ghebu.2024.000955
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT的中文电子病历实体关系抽取方法研究
{Author}: 张劲松
{Tertiary Author}: 于晓梅
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 电子病历;医疗数据处理;命名实体识别;实体关系抽取;BERT
{Abstract}: 随着计算机及相关技术的进步,医疗领域正迈向大数据时代。医院产生大量电子化的医疗数据,尤其是电子病历(Electronic Health Record,EHR),记录了患者信息、检查结果等重要数据。然而,电子病历的结构和完整性存在差异,使得其中信息难以直接利用,需要进一步挖掘。因此,将电子病历转化为结构化格式成为了当前计算机和医学交叉领域的研究热点。
实体关系抽取是自然语言处理领域的基础性任务,也是许多其他相关任务的实现基础。在医学领域,医疗实体关系抽取旨在从电子病历文本中提取医学实体并识别它们之间的关系,这对于构建医学知识图谱、辅助诊疗等应用至关重要。近年来,深度神经网络和基于转换器的双向编码器表示(Bidirectional Encoder Representations from Transformers,BERT)等预训练模型的兴起推动了中文电子病历的自然语言处理任务的发展,但同时也面临着数据集缺失、数据隐私与安全、文本规范性等问题。
针对电子病历的特殊性,如语言风格多样性和医学术语的复杂性,需要设计更精细化的模型和算法。本文深入研究了实体关系抽取的任务需求,提出了一种命名实体识别方法和两种关系抽取方法,以解决现有模型的不足,主要内容如下:
(1)针对中文词语组成复杂,现有中文医疗命名实体识别方法没有考虑汉字字形特征和词语边界信息的问题,提出了基于汉字字形和词语边界特征的中文医疗命名实体识别方法。该方法在使用BERT获取字向量的同时,引入了汉字字形特征和词语边界特征。同时利用不同维度的语义特征,提高了实体识别的准确率。在不同数据集上的实验证实本方法能更加准确地识别出中文电子病历领域中的实体。
(2)针对中文电子病历中广泛存在的单实体重叠(Single Entity Overlap,SEO),以及现有方法未充分考虑不同实体间联系和约束的问题,提出了基于BERT的融合实体间约束中文电子病历关系抽取方法。该方法引入了“unrelated”关系类别,加入了实体组合模块。这些机制共同作用,使得该方法能够应对SEO问题,并学习到不同实体间的约束信息,在不同数据集上的实验验证了该方法的有效性。
(3)针对现有实体关系联合抽取模型编码器、解码器复杂导致的标签稀疏、收敛速度低和关系冗余问题,提出了融合BERT和平移嵌入模型(Translating Embeddings for Modeling Multi-relational Data,Trans E)关系运算的中文电子病历联合式实体关系抽取方法。本方法使用BERT生成包含上下文信息的动态语义向量,并引入了Trans E中对关系的运算,基于关系三元组中的头实体和尾实体对关系进行建模,并映射各关系类别的全局表示向量,从而有效缓解了现有联合抽取模型中标签稀疏和收敛速度低的问题。在两个公开数据集上的一系列实验中,本方法均取得了较好的实验结果,证明了本方法的有效性。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2024.000773
{DOI}: 10.27280/d.cnki.gsdsu.2024.000773
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本相似度的科研项目查重算法研究及应用
{Author}: 吕云峰
{Tertiary Author}: 王茂发;单维锋
{Publisher}: 防灾科技学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 文本相似度;科研项目查重;Word2vec;BERT;DSSM
{Abstract}: 近年来,国家对科研项目的扶持力度越来越大,逐渐形成了多层次的科技计划资助体系。然而,随着各类科研项目的数量不断增加,科研项目“抄袭剽窃”与“重复立项”的问题日益突出,对科研项目进行查重以检测申报过程中的这些学术不端行为已成为科研项目管理的一个重要的技术环节。
文本相似度计算是自然语言处理技术中非常重要的一部分,旨在对两个给定的文本进行比较,进而得出它们之间的相似程度。本文应用三种基于字符串的文本相似度计算方法和三种基于语义的文本相似度计算方法分别计算科研项目标题相似度和科研项目摘要相似度,结合权重得出科研项目相似度。基于上述算法,开发了一款科研项目查重系统,旨在实现快速、准确地对科研项进行查重,辅助科研管理人员发现科研项目申请中的学术不端行为。
本文的主要研究工作及成果如下:
(1)对中国地震局地震科技星火计划项目和中国地震局重大政策理论与实践问题研究课题进行整理,并进行文本预处理,形成科研项目查重数据库。
(2)基于编辑距离、Jaccard和余弦相似度三种相似度算法提出了基于字符串的科研项目标题文本相似度计算方法。
(3)基于Word2vec、BERT和DSSM三种相似度算法提出了基于语义的科研项目摘要文本相似度计算方法。
(4)通过集成科研项目标题和摘要文本相似度计算方法,设计并实现了一款科研项目查重系统,辅助科研项目管理人员高效准确地检测出科研项目中存在的学术不端行为。
{URL}: https://link.cnki.net/doi/10.27899/d.cnki.gfzkj.2024.000048
{DOI}: 10.27899/d.cnki.gfzkj.2024.000048
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 社会技术系统视角下高校学生ChatGPT类产品使用意愿研究
{Author}: 王艺洁
{Tertiary Author}: 李华锋
{Publisher}: 山西财经大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: ChatGPT;高校学生;使用意愿;扎根理论
{Abstract}: 自计算机器出现以来,人工智能(AI)一直是科学家、工程师和思想家研究和兴趣的主题。近年来,人工智能被广泛应用于医疗、金融、交通、娱乐等各个领域。人工智能研究中最实质性的突破之一是出现了基于生成式预训练Transformer的大规模语言模型,如ChatGPT(聊天生成预训练Transformer;Open AI)。这类应用在教育领域的影响尤为显现,因为它能够产生与上下文相关的反应,并且似乎模仿人类语言,这增加了学者和从业者对ChatGPT对学生学习的潜在影响的关注。然而,关于高等教育学生采用ChatGPT的研究仍然很少,在学生群体作为ChatGPT类产品主要用户的背景下,需要更深入地了解高校学生对于ChatGPT类产品的需求、偏好和感受,进一步推动ChatGPT类产品纵向发展。本文以ChatGPT类产品为研究对象,对高校学生ChatGPT类产品使用意愿的影响因素进行研究。首先,在文献梳理和综述的基础上引入扎根理论研究方法,利用三级编码过程,明确高校学生ChatGPT类产品使用意愿的影响机制。其次,以选择编码结果为基础,构建高校学生ChatGPT类产品使用意向的理论模型,提出研究假设。最后,通过调查问卷获取数据来源,并通过使用AMOS22.0软件对前文提出的理论模型和假设进行实证研究,研究结果显示:(1)高校学生ChatGPT类产品使用意愿的影响因素主要包括社会影响、信息质量、绩效期望、努力期望、新颖性价值、信任6个变量。(2)高校学生对ChatGPT类产品的信息质量、努力期望、新颖性价值、信任均显著正向影响其对系统的行为意向;(3)信任在“绩效预期→使用意愿”、“努力期望→使用意愿”、“社会影响→使用意愿”、“信息质量→使用意愿”的关系中发挥中介作用。针对以上研究结论,立足高校学生需求,从ChatGPT类产品服务质量的角度出发提出针对性对策建议。(1)优化工具性力,提高用户的绩效期望。(2)进行充分市场调研,关注用户关键需求。(3)抓住关键要素,提升资源利用效率。
{URL}: https://link.cnki.net/doi/10.27283/d.cnki.gsxcc.2024.000994
{DOI}: 10.27283/d.cnki.gsxcc.2024.000994
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像文本跨模态检索方法研究
{Author}: 李政
{Tertiary Author}: 郭彩丽
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 图像文本跨模态检索;特征表示;特征匹配;损失函数
{Abstract}: 随着移动互联网和多媒体应用的蓬勃发展,文本、图像、视频等多媒体数据呈现出爆炸式增长的趋势。为了突破媒体类型的限制,高效管理多媒体数据,图像文本跨模态检索已成为学术界和产业界关注的焦点。该检索模式允许用户输入一张查询图像来检索与其主题或特征语义相关的文本描述,或者输入一句查询文本来检索与其主题或特征语义相关的图像。图像文本跨模态检索的核心任务是实现图像和文本间的跨模态语义相似度计算。图像文本数据的多模态异构特性为跨模态检索的实现带来了巨大挑战。首先,当前跨模态检索模型的实现依赖复杂的深度学习模型和有判别性的损失函数,会对模型训练带来收敛性挑战。其次,图像文本数据中广泛存在类内差异,抑制类内差异会降低模型的泛化能力。再次,跨模态检索数据集的构造方式会引入数据噪声,降低模型的鲁棒性。最后,在当前跨模态检索任务定义中,图像和文本间的语义关联被定义为粗粒度的二元关系,缺失细粒度的语义关联。本论文选题来源于先进信息网络北京实验室项目:“动态视频检索研究”。针对上述挑战,本论文对图像文本跨模态检索方法进行了深入研究,旨在优化模型训练收敛性、保持数据类内差异、提升模型噪声鲁棒性以及建模细粒度语义关联,分别提出了相应的研究方法,本论文的主要工作和研究内容总结如下:(1)针对图像文本跨模态检索模型在训练过程中存在的梯度难以反向传播、训练收敛困难的问题,研究基于训练收敛性优化的跨模态检索,提出基于训练梯度优化的跨模态检索方法。构建高效全局特征表示与匹配模型,以确保训练梯度的有效回传,并具备高效的训练与推理效率。针对梯度消失问题,推导出梯度消失发生的条件,并设计具有选择性困难负样本挖掘的三元组损失函数,以缓解模型训练过程中的梯度消失问题,保证训练快速收敛。实验结果表明,相比基准方法,本方法仅需要一半的迭代次数即可完成训练,并在召回率总和指标上实现了 11%的性能提升。(2)针对图像文本数据中存在的类内差异问题,研究基于类内差异保持的跨模态检索,提出基于多视角类内差异建模的跨模态检索方法。引入多视角全局特征匹配模型,通过多个视觉特征聚合器分别学习同一图像多个视角的视觉特征表示,以显式地建模类内差异。为了实现多个视角的联合优化,设计多视角跨模态检索损失函数。本方法可以即插即用地应用于当前的图像文本跨模态检索模型,并且仅引入了少量的计算开销。实验结果表明,相比基准方法,本方法在召回率总和指标上实现了 4%的性能提升。(3)针对跨模态检索数据集中存在的噪声数据问题,研究基于噪声鲁棒性学习的跨模态检索,提出基于数据噪声修正的跨模态检索方法。基于语言预训练模型计算文本之间的语义相似度,以此有效识别潜在的噪声数据。为了修正噪声数据,设计噪声数据修正跨模态检索损失函数,该损失函数能够自适应地调整噪声数据在特征空间中的位置。本方法充分考虑了对图像文本跨模态检索模型原始架构的兼容性,可以即插即用地集成到现有的跨模态检索模型中。实验结果表明,相比基准方法,本方法在召回率总和指标上实现了 12%的性能提升,并能显著提高对相关样本的召回率。(4)针对跨模态检索任务定义中存在的细粒度语义关联缺失的问题,研究基于语义关联建模的跨模态检索,提出基于列表排序学习的跨模态检索方法。利用语义关联度计算模块来计算整个检索排序列表的语义关联度。将不可微分的排序评价指标NDCG转化为可微分的列表排序学习损失函数,实现对整个排序列表的优化。本方法充分考虑了对图像文本跨模态检索模型原始架构的兼容性,可以即插即用地集成到现有的跨模态检索模型中。实验结果表明,相比基准方法,本方法在召回率总和指标上实现了 9%的性能提升,并能提供更加用户友好的检索结果。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.000052
{DOI}: 10.26969/d.cnki.gbydu.2024.000052
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向专业领域的问答系统研究
{Author}: 雷浩
{Tertiary Author}: 徐蔚然
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 阅读理解;问答系统;提示学习;文本匹配
{Abstract}: 随着智能技术的发展,人们对问答系统的要求越来越高。本文研究如何面向某一专业领域而设计问答系统,并确保问答系统的回答更准确和更安全。虽然以ChatGPT为代表的大语言模型技术已经显著提高了问答系统的性能,但是如果仅简单使用通用大模型来构建专业领域的问答系统,很容易存在以下问题,如生成的答案不够准确,生成的答案不可控,有安全性问题,大模型训练成本高等。本文结合国内外研究现状,研究了基于多种形式知识库相结合的专业领域问答系统。论文的主要研究内容和贡献如下:第一、本文提出了基于多种形式知识库相结合的专业领域问答系统总体框架。在该框架下知识保存在多种形式的数据库中,从而确保了知识的准确性和安全性。可信知识库的构建成本高,但答案相对准确;开放知识库的内容全面,但答案不一定准确。在检索增强的方法下不同数据库的知识能够有机融合在一起,并生成答案。该技术路线兼顾了精度和广度,同时生成的答案更加可控,可解释性高,成本更低。第二、为了提高答案的准确性,针对可信知识库提出了基于表示学习的多路召回语义匹配算法。假定问题的准确答案存在于一个可信知识库中,关键问题是设计一种语义匹配算法来精确地找到答案。本文将语义分为句子级向量表示、词级向量表示和token级向量表示三个层次;多路召回模型同时学习三个层次的语义信息和文本关系,提高语义相似度匹配任务的精度;最后利用多路召回语义匹配算法找到准确的答案。在七个语义文本相似度基准数据集上进行实验,多路召回语义匹配模型在六个数据集上都超过了基线模型,并且平均提升1%,证明了所提出算法的有效性,另外通过消融实验,证明了每一路召回对算法的提升。第三、为了提高生成答案的安全性和可控性,针对开放域知识库提出了基于提示学习的检索增强问答系统算法。该算法分为两个阶段,首先,在预训练阶段设计了两个任务:随机句子掩盖任务和句子顺序预测任务,这两个任务使得模型获得对长文本的基本理解能力和对多个句子的信息整合能力;然后在第二阶段通过提示学习引入外部知识,来指导模型生成答案,提高模型的阅读理解性能。本文在PAR数据集上进行了实验,该算法超过了对比的基线模型,在EM指标和F1分数都有所提高,另外通过消融实验验证了算法的有效性。第四、结合实际需求设计并实现了面向专业领域的问答系统。本文进行了需求分析和系统流程设计,并结合前两个算法,完成了问答系统的开发和实现,最后对系统进行测试,证明了该问答系统的性能。本文结合实际需求,设计了基于多种形式知识库相结合的专业领域问答系统,实验证明了所提出算法的有效性,开发的问答系统达到了项目方的要求。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.001397
{DOI}: 10.26969/d.cnki.gbydu.2024.001397
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向大语言模型的有害文本检测技术的研究与实现
{Author}: 朱昊
{Tertiary Author}: 王玉龙
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 大语言模型;有害文本;提示学习;红队测试
{Abstract}: 随着GPT-4,Llama等大语言模型的迅速发展与广泛应用,其在自动问答、文本生成、情感分析等多个领域的应用潜力受到了极大关注。然而,这些模型生成的文本可能包含有害文本内容,对个人和社会造成不良影响。鉴于此,目前迫切需要开展大语言模型的有害性研究,确保模型输出健康、积极的内容。为了有效地评估大语言模型生成的有害文本,本文首先提出了一种基于自我推理的有害文本检测方法,该方法通过将自我推理和困难样本LoRA训练相结合,实现了对有害文本的有效检测。该方法不依赖大量训练数据,具有训练成本低、泛化性强和可解释性高的特点。为了验证该方法的有效性,本文展示了在ToxiGen、HateXplain、HateCheck、ImplicitHate、SocialBiasFrames、DiaSafety和ContextToxicity等多个数据集上的实验结果,基于自我推理的有害文本检测方法在准确率、召回率、F1值等多个指标上都超越了HateBERT、GPT-4、Prompt Tuning等方法。此外,本文对样本数量、基座模型选择等参数分别进行了实验分析,验证了该检测方法的泛用性。针对大语言模型潜在的有害内容,本文提出了一种基于提示优化的有害提示生成方法,通过结合提示优化器和波束搜索两种算法,无需大量人工干预即可有效生成诱导模型输出有害文本的提示。本文展示了在多个场景下的实验结果,基于提示优化的有害提示生成方法,在无需增加训练成本的情况下,其生成效果能够超越采用监督学习的红队测试方法。此外,为了验证红队分类器对有害提示生成效果的影响,本文展示了使用不同有害文本检测的实验,结果表明与目标模型基座相同的红队分类模型能够有效发掘目标模型潜在的有害内容。最后基于上述研究工作,本文设计并实现了一个大语言模型有害输出检测系统,该系统包括有害文本检测、有害提示生成和大语言模型有害性检测模块,能够满足实际的功能和性能需求。本文针对大语言模型有害输出检测系统设计并实施了系统测试方案,验证了系统的实用性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.002249
{DOI}: 10.26969/d.cnki.gbydu.2024.002249
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习特征融合提取的文本分类模型研究
{Author}: 刘师宇
{Tertiary Author}: 刘其成
{Publisher}: 烟台大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 文本分类;BERT;词性特征;内卷积;深度学习
{Abstract}: 日常生活中存在着大量的文本数据,有效地对这些文本进行分类和情感分析,对于人们理解用户观点、市场趋势以及舆情分析等应用具有重要意义。文本分类作为自然语言处理任务中的核心任务之一,仍然存在许多挑战和问题,例如数据稀疏性、文本间关联性等。基于传统机器学习的文本分类方法,在处理复杂的文本语义和情感表达时存在一些限制,虽难以充分捕捉文本的语义信息,但为基于深度学习的文本分类研究提供了有价值的起点。然而,基于深度学习的文本分类模型在实际应用中也面临一些挑战,例如如何更好地处理长距离依赖、解决分类偏差和错误模式等方面的问题,但深度学习的引入为解决自然语言处理任务带来了新的可能性。因此,本研究围绕基于深度学习特征融合提取的文本分类模型展开研究,旨在充分发掘深度学习的优势,进一步提升文本分类的效果和性能。具体的研究内容如下:
1.针对中文网络中短文本篇幅过小导致特征稀疏分类效果欠缺等问题,并且充分考虑丰富特征在文本表达过程中的重要性,本文提出一种融合词性信息的文本分类模型PB-DPCNN(Part-of-speech based BERT-DPCNN)。该模型首先通过词性标注引入文本词性特征,构建具有词性属性的词性向量。同时,基于BERT模型对词向量进行动态调整获得融合特征,来表达词间的复杂关系,解决文本数据中一词多义、特征稀疏的问题。将得到的融合动态词向量作为输入层信息以改善文本表示,经过嵌入层固定词向量格式,通过等长的双层卷积捕获长距离模式提高词位嵌入的丰富性;输出层结合残差池化进一步提升词位感知空间,并获得最终文本特征表示,压缩序列长度的同时抽取长距离的文本依赖关系并进行分类。实验结果表明,与现有模型相比,PB-DPCNN模型丰富了输入数据的特征表示,抽取长距离依赖关系,减少文本中重要信息的丢失,具有良好的文本语义识别能力,有效提升了分类指标。
2.针对传统神经网络难以充分抽取局部特征信息的问题,为了从文本数据中提取更多局部结构,增强文本中情感特征的表达,同时解决过深堆叠网络带来的网络退化等问题,本文进一步提出了基于动态预训练和堆叠内卷积的文本分类模型BERTInvos(BERT-based stacked involutions)。该模型首先使用动态预训练进行文本编码,以获得丰富的语义特征和上下文理解能力。利用内卷积算子代替普通卷积和注意力机制,按不同维度进行堆叠设计深层网络结构,实现特征提取和局部感知,逐渐学习到输入文本的不同尺度和层次的特征表示。在训练过程中,为了增强模型的表达和泛化能力,本文引入了批处理降低分类偏差。同时,通过改进的激活函数H-Swish调整分类层的非线性输出,保持训练过程的稳定性并进行精准分类。实验结果表明,该模型取得了良好的性能表现,能够提高文本分类的准确性,降低损失率,有助于更好地捕捉文本中的局部模式和增强情感特征表达能力。
{URL}: https://link.cnki.net/doi/10.27437/d.cnki.gytdu.2024.000425
{DOI}: 10.27437/d.cnki.gytdu.2024.000425
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 桑叶提取物对花鲈生长、免疫及肝肠功能的影响
{Author}: 周思顺
{Tertiary Author}: 黎中宝
{Publisher}: 集美大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 桑叶提取物;花鲈;生长;抗氧化;非特异性免疫;转录组
{Abstract}: 随着水产养殖业的高速发展,在养殖过程中出现了许多问题,因此功能性饲料添加剂的开发变得尤为重要。本研究评估了桑叶提取物作为天然饲料添加剂对花鲈(Lateolabrax maculatus)生长性能、免疫和肝肠功能的影响。试验方法如下:将试验花鲈暂养两周后,选择体质健康(平均体重为9.00±0.02 g)的花鲈360尾,将其随机分为6个处理组,3次重复,并分别放入18个200 L的试验缸中,每个试验缸放置20尾。每天分别饱食投喂粗蛋白含量为48%,粗脂肪含量为8.6%的不同添加浓度(0、3、6、9、12、15 g/kg)的试验饲料,并在水温为25-28℃,盐度为0.5-1的条件下进行52天的养殖试验。养殖结束后,随机选取9尾鱼采集其头肾、肝脏、肠道和血清用于生理生化指标检测、组织切片制备与观察以及转录组学分析。试验结果如下:
(1)桑叶提取物对花鲈生长、免疫和抗氧化能力的影响
试验结果显示,与对照组相比,日粮中添加9 g/kg桑叶提取物能够显著增加花鲈的增重率、特定生长率(P<0.05)。当桑叶提取物添加量为3、6、9 g/kg时,花鲈日摄食量显著增加(P<0.05)。与对照组相比,桑叶提取物显著提高了血清中的Ig M含量,且在桑叶提取物添加量为6g/kg时达到最高(P<0.05)。桑叶提取物对血清ACP、AKP、LZM、补体C3、TP无显著影响(P>0.05)。与对照组相比饲料中添加桑叶提取物对花鲈头肾ACP和AKP活性无显著影响(P>0.05)。与对照组相比,桑叶提取物显著提高了血清中CAT、SOD活性和GSH水平,并显著降低了血清中MDA的含量(P<0.05)。桑叶提取物对花鲈血清中T-AOC无显著影响(P>0.05)。与对照组相比,桑叶提取物对花鲈头肾SOD活性、T-AOC和MDA含量也均无显著影响(P>0.05)。通过转录分析发现,桑叶提取物主要通过直接或间接影响色氨酸代谢来调控花鲈头肾的免疫机能。然而,桑叶提取物对花鲈头肾中3-羟基邻氨基苯甲酸3,4-双加氧、β-1,4-N-乙酰氨基半乳糖转移酶3、鞘磷脂磷酸二酯酶、MHC I类抗原和免疫球蛋白重链等基因的表达量无显著性影响。以上结果表明,桑叶提取能够。以上结果表明,桑提取物能够提高花鲈的生长性能,且在其添加量为9 g/kg时效果最佳,且在一定程度上提高花鲈血清和头肾抗氧化能力和非特异性免。
(2)桑叶提取物对花鲈肝脏功能的影响
试验结果表明,与对照组相比,桑叶提取物显著增加了花鲈肝脏LPS、TRS活性,且在桑叶提取物添加量为6 g/kg时达到最高(P<0.05)。桑叶提取物显著提高了肝脏组织中参与代谢过程的LDH、GOT活性,且在桑叶提取物添加量为9 g/kg时GOT活性达到最高,桑叶提取物添加量为15 g/kg时LDH活性达到最高(P<0.05)。桑叶提取物对肝脏抗氧化酶无显著影响(P>0.05),但肝脏中MDA的含量显著降低(P<0.05)。与对照组相比,桑叶提取物显著增加了花鲈肝脏中AKP和ACP活性,且当桑叶提取物添加量为3 g/kg时AKP活性达到最高,9 g/kg时ACP活性达到最高(P<0.05)。桑叶提取物对花鲈血清中GPT和GOT活性无显著影响,但具有一定降低趋势(P>0.05)。通过比较转录组学分析发现,桑叶提取物能够通过提高参与代谢过程的磷脂酸磷酸酶、葡萄糖醛酸转移酶、肌醇加氧酶、碳酸酐酶、细胞色素c氧化酶亚单位2等基因的表达量来增强花鲈肝脏的脂肪和碳水化物代谢能力。桑叶提取物也能够通过提高参与机体免疫过程的信号转导子和转录激活子1、ATP依赖性RNA解旋酶DHX58和C-X-C基序趋化因子9的表达量来影响花鲈肝脏的免疫能力。以上结果表明,桑叶提取物能够通过提高花鲈肝脏中消化酶活性、代谢酶活性以及肝脏代谢和免疫调控基因表达量来增强花鲈肝脏消化、代谢、免疫能力。但桑叶提取物对花鲈肝脏抗氧化能力和肝脏损伤影响不明显。
(3)桑叶提取物对花鲈肠道功能的影响
试验结果表明,日粮中添加9 g/kg桑叶提取物可提高肠道TRS、AMS和LPS活性(P<0.05)。与对照组相比,桑叶提取物对花鲈肠道LDH、GPT、GOT活性无显著影响,但均具有一定增加趋势(P>0.05)。添加3 g/kg桑叶提取物可提高肠道CAT活性(P<0.05),但对肠道SOD活性和GSH、MDA的含量影响不显著(P>0.05)。桑叶提取物还能够改善花鲈肠道组织形态,表现为肠绒毛长度的显著增加,从而增加了肠道消化吸收面积(P<0.05)。与对照组相比,饲粮中添加桑叶提取物显著提高了花鲈肠道微生物ACE、Chao1和Shannon指数(P<0.05)。桑叶提取物还提高了花鲈肠道中优势菌群丰度,从而改善肠道微生物组成。通过比较转录组学分析发现,桑叶提取物能够通过上调花鲈肠道中参与机体代谢过程的醚脂质代谢通路中外核苷酸焦磷酸酶/磷酸二酯酶家族成员6的表达量对花鲈肠道代谢产生影响。桑叶提取物也能够通过上调了参与机体免疫过程中的嘌呤核苷磷酸化酶、γ-谷氨酰水解酶、转录因子AP-1、C-C基趋化因子24、含有caspase募集结构域的蛋白质8的表达量和参与机体抗氧化过程中过氧化物-5的表达量来影响花鲈肠道免疫和抗氧化过程。由以上结果可见,日粮中添加的桑叶提取物可改善花鲈肠道抗氧化能力、肠道组织形态和微生物组成,并能够通过提高花鲈肠道中有关代谢和免疫相关基因的表达量,从而改善花鲈的肠道功能。
{URL}: https://link.cnki.net/doi/10.27720/d.cnki.gjmdx.2024.000152
{DOI}: 10.27720/d.cnki.gjmdx.2024.000152
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的加密恶意流量检测算法研究
{Author}: 王统亮
{Tertiary Author}: 臧小东
{Publisher}: 曲阜师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 网络安全;深度学习;域生成算法;未知加密流量检测;恶意流量分析
{Abstract}: 隐私保护导致大量加密网络流量增加。攻击者经常利用流量加密来掩盖恶意行为,以规避网络安全设备或监控系统的检测。加密恶意流量和正常加密流量之间几乎没有区别,因此很难确定其中是否存在恶意行为。研究人员已经提出了几种基于启发式的检测方法,但它们要么需要提高泛化能力,要么需要增强检测性能。另一方面,随着未知协议的广泛应用,网络流量的未知性不断加深。这使得在缺乏先验知识的情况下,监督学习方法难以获得有效模型。分析未标记数据在入侵检测领域备受关注,因为攻击模式不断演变,而系统对此毫无了解。许多研究已经探讨了各种技术,如聚类来解决这一问题。然而,这些方法可能会出现聚类模糊的情况,导致某些数据点可能被错误地分配到不正确的类别中。本文旨在针对上述问题展开以下研究工作:
(1)本文提出了一种具有自适应域泛化的深度学习方法来解决加密恶意流量检测泛化能力差和时耗长的问题,通过数据包头字段以及构建句子的底层语法规则构建特征集,使用自然语言处理技术来提取加权特征向量。首先,本文将原始数据包视为文本,设计了一个具有自然语言处理和深度学习的检测模型。通过捕捉关键词作为流量的特征表示,采用一种自适应域泛化算法和新的损失函数对数据集的恶意样本进行泛化,将增加的恶意样本来平衡数据。同时,本文设计了一种高效的特征选择算法,可以获得最佳的特征子集,并将特征维度降低了75.3%,在效率和鲁棒性上优于其他最先进的检测方案。
(2)本文提出了一种具有轻量化特征融合的聚类方法来解决未知加密恶意流量检测准确率低和时耗长的问题,通过协议有关和协议无关的特征构成两组特征集合,使用交叉项特征融合技术学习特征之间的潜在联系。首先,本文将提取的所有特征分为数值特征和非数值特征。针对数值特征,采用转换成热度图的方式,并使用卷积神经网络来捕捉热度图中特征的潜联系,将其转换为特征向量。对于非数值特征,本文则采用TF-IDF方法将其转换为向量表示。本文采用了交叉项的特征融合算法,减少了32%的维度。通过实验验证,本文发现这种模型在检测出未知加密流量的同时提高了聚类的准确率,具有较好的性能表现。
{URL}: https://link.cnki.net/doi/10.27267/d.cnki.gqfsu.2024.000809
{DOI}: 10.27267/d.cnki.gqfsu.2024.000809
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于大规模预训练模型的建筑领域知识图谱的研究
{Author}: 刘怡晴
{Tertiary Author}: 丁松阳
{Publisher}: 河南财经政法大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: GPT-prompt;命名实体识别;关系抽取;建筑规范;自一致性判断
{Abstract}: 在当前全球经济背景下,房地产市场波动显著影响行业。受政治、经济不确定性和环境可持续性发展的限制,房地产开发受限,导致整个建筑产业以及相关原材料的供应链受到不同程度的影响。近年来大数据和人工智能的发展,成为推动行业转型的关键,也为建筑设计、项目管理等带来创新方法和工具。人工智能在建筑设计领域的发展,从最初使用基于逻辑推理的专家系统来回答设计方面的问题,到目前使用以“数据驱动型”的算法优化设计方案或生成新的设计。但“数据驱动型”的模型依赖于数据质量,无法直接学习和理解建筑规范,因此需融合建筑规范以提高设计精确性。
建筑规范文本通常为非结构化文本,知识图谱是一种知识的表示技术,它通过实体和关系构建而成,因此知识图谱为非结构化文本的转化提供了一种有效途径。本研究探讨通过知识图谱构建,将建筑设计规范转化为模型可理解的知识,其中重点是命名实体识别和关系抽取技术,在分析建筑规范的基础上,识别出关键实体和关系类别,为构建图谱并指导图的生成奠定基础。
本研究提出了一种基于GPT-prompt架构的方法,方法核心依赖于利用大规模预训练语言模型GPT,向模型提供角色信息和任务指示,并结合少样本学习(Few-Shot Learning)策略,其次在命名实体识别任务中,引入了自判断的策略提高实体抽取的精度;在关系抽取任务中,引入“思维链”和“自一致性判断”机制来提高模型抽取关系的性能。实验表明,在命名实体识别任务中,引入了自判断的策略的架构方法在该任务中表现良好,取得了0.80的F1分数,已经超越基于BERT模型的最优成绩(0.72)。在关系抽取任务中,通过“思维链”和“自一致性判断”机制的模型,其F1值最高达到了0.88,证明了GPT-prompt架构在处理复杂任务时的有效性。在完成实体与关系的抽取后,选用Neo4j数据库作为主要技术工具,以三元组形式高效存储、管理和展示,为后续知识图谱融入图的生成的研究做铺垫。
{URL}: https://link.cnki.net/doi/10.27113/d.cnki.ghncc.2024.000113
{DOI}: 10.27113/d.cnki.ghncc.2024.000113
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: ChatGPT智能传播的伦理风险与治理研究
{Author}: 汪成灿
{Tertiary Author}: 刘宝珍
{Publisher}: 湖北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: ChatGPT;智能传播;伦理风险;治理
{Abstract}: 2022年11月30日美国人工智能研究公司Open AI发布了一款聊天机器人程序ChatGPT,该模型的推出代表着人工智能生成技术的重大突破,从单模态到多模态的大模型迭代,其使用范围被极大拓展。作为生成式预训练机器人,其激发的生态性变革将重塑智能传播行业。但是,以ChatGPT为代表的生成式AI技术,在发挥技术理性的同时,也不可避免地丧失其价值理性,在各个领域触发了一系列潜在的风险议题,而这些议题本质上均与伦理考量紧密交织,亟需在理论与实践层面上予以深度解析和妥善应对。本文遵循“提出问题—分析问题—解决问题”的研究思路,将ChatGPT作为研究对象,综合运用使用与满足理论及善治理论,建构了针对ChatGPT伦理风险问题的探索框架。研究框架主要围绕伦理风险的表现形式、成因溯源以及治理路径三个维度展开。通过网络文本分析法和问卷调查法,对ChatGPT引发的多种伦理风险进行了系统分类,归纳为技术风险、社会风险、法律风险以及思想风险四个方面。从上述风险出发,接着论证了ChatGPT技术伦理风险产生的技术成因主要是:ChatGPT生产技术的局限性以及技术的不确定性;主体成因是:制度上难以确立的权责边界和伦理机制、平台风险监管的把关缺位、智能机器对人类的裹挟;社会成因是:系统性偏见带来数据霸权、文化差异带来意识形态窄化。这也反映了完善技术措施和伦理主体性责任。最后,通过前文的样本数据分析进行总结,形成多元有效的治理策略,主要从主体、客体和环境三个层面出发,主体层面主要阐述构建以人为本的治理结构与机制,建构综合监管模式和多元有序的规制策略。客体层面聚焦于ChatGPT技术本身,要求要实现创新驱动与伦理内嵌的技术优化。环境层面从ChatGPT治理的国际环境、社会环境出发,建立多元共治的治理生态,同时也要注意培育公众的数字素养,提升风险防范能力。以期为ChatGPT的伦理风险问题提出可行性的解决之道,为推动科学合理使用ChatGPT等人工智能新技术提出逻辑进路,助力社会生态的良性健康发展。
{URL}: https://link.cnki.net/doi/10.27130/d.cnki.ghubu.2024.001210
{DOI}: 10.27130/d.cnki.ghubu.2024.001210
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向文本、图像、语音的多模态情感分析研究
{Author}: 杨杨
{Tertiary Author}: 赵海兴
{Publisher}: 青海师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 多模态情感分析;深度学习;自然语言处理;图像处理;音频处理
{Abstract}: 情感分析的出现,使机器产生理解人类行为的途径,为人工智能、自然语言处理、图像处理、音频处理等研究方向提供了新的思路。然而随着世界的发展和大数据时代的到来,世界变得越来越复杂,单一模态的数据信息在情感分析任务中存在局限性,利用单模态数据信息已经不能理解这些复杂的情感。多模态情感分析的出现刚好解决了这一问题,多模态情感分析同时从两个或两个以上的模态数据中分析其情感,拥有更高准确度的同时,又从多角度对数据进行分析,为情感分析任务提供更多应用场景。本文主要研究对象是面向文本、图像、语言的多模态情感分析,基于现有多模态情感分析模型的理论与方法,结合现有研究中还未解决的问题,提出了多模态情感分析中面临的几个问题。1.融合后的特征往往导致重要信息遗失;2.融合后的每个特征的隶属度是没有精确定义和计算;3.多模态情感分析模型复杂度往往太大,难以用于实际问题的应用;4.模型往往不会考虑各模态间的联系与影响。对于上述问题,本文分别提出了两个模型(BLR-双重融合模型与M-S主、副双通道融合模型)解决。首先采用BLR-双重融合模型利用Transformer融合机制对文本及图像模态的信息进行融合,其主要目的为:1.将送入模型的特征两两融合,最大限度保证特征不缺失;2.对融合后的每个特征根据其重要程度赋予权值。此模型很好的解决了上述问题1与问题2,并且在2个数据集上对比5个基线模型,准确度均有提升,说明本文提出的融合方法在理论上是可行的。其次采用M-S主、副双通道融合模型可以同时对文本、图像和音频模态的信息进行特征提取并对数据情感分析,其主要目的为:1.采用轻量化模型,减小模型规模,加快模型运行时间,使得模型更加方便应用;2.考虑三个不同模态之间的关系,引入跨模态注意力机制,多角度充分利用多模态信息,方便解决实际问题。此模型在BLR-双重融合模型的基础上进行升级,解决了问题3、问题4,在1个数据集中对比6个基线模型都有所提升,表明本文提出的模型在准确度、适用场景、处理效率均有提升。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2024.000406
{DOI}: 10.27778/d.cnki.gqhzy.2024.000406
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于PBL的高中人工智能实验教学模式与资源平台构建研究
{Author}: 张辉凤
{Tertiary Author}: 解敏
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 项目式学习;实验教学模式;评价指标体系;资源集成;高中人工智能实验
{Abstract}: 作为核心驱动力的人工智能技术已经深入到生产生活的各个领域中,各国机构确立了“人工智能+教育”为未来教育的发展方向之一。我国高中人工智能课程的开设也得到了越来越多的大学和中学的关注和支持。然而,在高中人工智能实验课程中存在缺乏优质实验教学资源、实验课内容与实际应用难以对接、教师不适应新教材、教学模式不够完善等问题。针对这些问题,本研究构建了基于PBL的高中人工智能实验教学模式、建立PBL过程性评价指标体系、设计实现实验资源平台并在实际教学中应用检验,以期为高中人工智能实验教学提供支持和参考。首先,采用文献研究法梳理了国内外人工智能教育、项目式学习等相关文献。以建构主义、布鲁姆教育目标分类、项目式学习为理论基础,结合人工智能的实验类型,构建了三种实验的项目式教学模式。实验教学模式由实验教学目标、实验教学内容、实验教学方法、教学过程和教学评价五部分组成。其次,为了科学评估PBL实验教学效果,利用德尔菲法建立评价指标体系,综合考量理解人工智能技术原理、制定解决人工智能应用问题的方案并实现目标和学习体验三个一级指标。然后,为了更好地支持实验教学,构建了实验资源平台。该平台根据实验模式的要求集成了多种来源的人工智能实验资源与评价资源,为师生集成了丰富的教学资源。最后,在实际教学中对该实验教学模式进行了检验。结果表明,基于PBL的高中人工智能实验教学模式不仅培养了学生的人工智能课程实践动手能力,还能够激发学生的学习热情,增强团队协作意识。本研究的成果是:(1)构建了涵盖三种实验类型的PBL实验教学模式,能对接一线教学实践,为师生开展高中人工智能实验教学提供了易理解、易操作的指导。(2)设计构建了高中人工智能实验项目式学习的过程性评价指标体系,可以结合PBL实验教学模式评价实验教学效果。(3)集成设计和开发了实验资源平台,为实施基于PBL的高中人工智能实验教学提供融实验资源、过程、评价为一体的实验环境。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2024.000217
{DOI}: 10.27459/d.cnki.gynfc.2024.000217
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: The Digital Humanities and Literary Studies（Chapter 1）英汉翻译实践报告
{Author}: 周雨欣
{Tertiary Author}: 姜涛
{Publisher}: 黑龙江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 学术翻译;双破折号;复合句翻译;词义引申;变序译法
{Abstract}: 本次翻译实践报告文本节选自学术专著《数字人文与文学研究》(The Digital Humanities and Literary Studies)的第一章“作者与计算机写作”。该章主要介绍了运用数字人文手段研究作者身份识别及其发展历史,计算机写作及其带来的问题。结合该文本特点,首先,本报告选用词性转换法、加注法、增加范畴词、词义引申法对名词进行翻译;其次,在处理原文双破折号时选择将其转化为括号、删除后增译以及删除后调整句子结构;最后,针对大量复合句提出了变序译法、拆分译法和合译法三种方案。本次实践报告希望能够为从事数字人文研究的国内学者们提供学习资料,并为未来从事数字人文学术专著翻译工作的人员提供参考和借鉴。
{URL}: https://link.cnki.net/doi/10.27123/d.cnki.ghlju.2024.000069
{DOI}: 10.27123/d.cnki.ghlju.2024.000069
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 评价理论视角下美国媒体关于ChatGPT社论语篇的立场分析
{Author}: 杨露
{Tertiary Author}: 刘丹
{Publisher}: 黑龙江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 英语社论语篇;评价理论;立场研究;ChatGPT
{Abstract}: 随着人工智能技术的飞速发展,大型语言模型ChatGPT已成为科技领域的新星。其高度的通用性和智能化表现引发了社会各界的广泛关注,并逐渐从单纯的技术革命演变为深刻的社会革命。本文选取了《纽约时报》和《华盛顿邮报》中45篇关于ChatGPT的社论作为分析语料。以评价理论为基础,通过定量和定性分析,探讨社论中的态度系统、介入系统和级差系统,以揭示两家媒体对于ChatGPT的立场和态度。研究表明,在态度系统中,鉴赏资源是主要的表征手段,特别是消极鉴赏资源,它们被用来描绘ChatGPT生成文本的平庸与虚假特质;情感资源中,安全和倾向是主要的情感要素,两家媒体均对ChatGPT的安全性持不信任态度。在介入系统中,两家媒体倾向于使用推测性的容纳资源与读者构建互相对话的充足空间,然而,在面对ChatGPT文本可信度以及政府监管力度不足等敏感议题时,它们则选择直接否认、排斥或不予采纳某些观点,以此来缩小对话空间,凸显自身立场。最后,两家媒体通过级差系统中的强化和量化手段,进一步调整了对于ChatGPT的态度和对话空间。其中,孤立式和重复式的强化资源被用来深化社论作者对ChatGPT鉴赏价值的探讨,而量化资源的极化现象则揭示了ChatGPT的出现对社会各方面产生的巨大冲击。本研究不仅丰富了评价理论在新闻领域的实践应用,还进一步明确了评价资源在社论语篇中的功能和作用。此外,本研究引导了对前沿新兴科技有关社论的国际关注,能够深化我们对媒体在科技报道中扮演的角色和所持立场的理解,也为未来科技发展的社会影响提供了参考和启示,同时能够引导读者对科技发展可能带来的机遇和风险进行正确的理解和诠释,从而确立正确的价值观念和提高思辨能力。
{URL}: https://link.cnki.net/doi/10.27123/d.cnki.ghlju.2024.000274
{DOI}: 10.27123/d.cnki.ghlju.2024.000274
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于异质图和大语言模型的篇章级事件抽取方法研究
{Author}: 赵一斐
{Tertiary Author}: 袁洪芳;韩众和
{Publisher}: 北京化工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 篇章级事件抽取;异质图;大语言模型;低资源;深度学习
{Abstract}: 随着互联网和数字化信息的迅速发展,文本数据的规模和复杂性不断增加,因此有效地抽取和理解其中蕴含的丰富事件信息对于信息检索、情报分析、舆情监控等应用具有重要意义。作为自然语言处理研究中的关键领域,篇章级事件抽取旨在从文本文档中抽取出结构化且完整的多种类型事件信息。不同于传统的句子级事件抽取,篇章级事件抽取的应用场景更加复杂。一方面,一篇文档可能存在多个不同类型的事件,这使得不同事件之间的关系建模难度增加。另一方面,事件的不同论元在多个句子中分散出现,这导致捕捉论元之间的长距离依赖充满挑战。除此之外,篇章级事件抽取数据集相对稀缺,并且事件类型分布不均匀,进一步增加了抽取的难度。本文针对篇章级事件抽取任务存在的多事件和事件论元分散挑战,提出了一种基于改进异质图的篇章级事件抽取方法。首先,该方法支持以解耦实体抽取部分的方式精简模型的参数;其次,构建以触发词为中心的篇章级异质交互图从而更全面地对语义进行建模;最后,支持使用基于动态筛选的树形事件论元抽取方式获得事件论元结果。实验结果表明,该方法能够获得较好的效果并减少模型的计算资源。为进一步解决篇章级事件抽取面临的低资源问题,本文提出了一种面向篇章级事件抽取的大语言模型数据增强方法。首先,该方法构造面向特定任务的提示模板引导大语言模型结果;其次,利用融入事件关键信息的三元组进行多样化数据生成;最后,根据自评价筛选机制获得高质量数据。实验结果表示,该方法能够有效解决篇章级事件抽取的数据标注不足问题并降低人工成本。
{URL}: https://link.cnki.net/doi/10.26939/d.cnki.gbhgu.2024.001106
{DOI}: 10.26939/d.cnki.gbhgu.2024.001106
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合媒体情绪的玉米期货价格预测
{Author}: 宁坡
{Tertiary Author}: 宋玉平
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 玉米期货价格预测;媒体情绪;深度学习模型
{Abstract}: 玉米是重要的粮食和饲料作物,生产潜力大、经济效益高,具有食用、饲用以及多种工业用途,在保障粮食安全方面具有重要战略地位。玉米期货作为重要的金融工具,其价格的不确定性不利于投资者利用其进行避险和投资。而玉米期货价格的预测,使投资者有一定心理预期,在一定程度上能够降低价格波动风险。然而,现阶段玉米期货预测存在一些问题,如因子考虑不够全面、文本信息内容利用率不够高以及长期预测的效果有待提高等,导致预测结果的可靠性潜力有待挖掘。因此,本文通过技术手段将媒体情绪量化,提高因子的利用率,改进当前的玉米期货预测方法,提高长期预测准确性和有效性,以更好地帮助农业生产者和消费者管理价格风险,促进玉米的流通和贸易,推动玉米产业的健康发展。为了提高玉米期货预测的准确性,本文提出了一种基于文本的玉米期货预测框架Chat GPT-Autoformer。因子方面,引入玉米、小麦、大豆以及原油四大方面媒体情绪因子,结合众多结构化指标。其中,媒体情绪通过农产品网站获取新闻标题文本,并利用Chat GPT自动进行文本情绪识别得到;结构化因子则利用Light GBM与Pearson进行特征筛选。模型方面,本文采取具有自注意力机制的Autoformer模型,比较引入媒体情绪前后对于玉米期货价格的预测精度以及比较Chat GPT与Bert处理媒体情绪对于玉米期货价格的预测精度差异。此外,与基准模型LSTM、RF以及ARIMA模型在玉米期货价格的短期、中期以及长期预测方面进行比较,探究不同模型在不同时期预测精度与稳定性。然后,通过最优模型构建因子效率指标量化因子重要性。最后,选取回测区间进行回测,对比本文的Autoformer模型的策略绩效,进一步论证本文研究的合理性。本文实证表明:(1)Autoformer模型与随机森林模型(RF)、长短期记忆模型(LSTM)以及ARIMA模型相比,具有更好的预测精度及稳定性,在长期预测方面这种优势更加突出。具体表现为:Autoformer相比于LSTM模型,平均MAPE降低82.9%,平均RMSE降低52.8%;Autoformer相比于RF模型,平均MAPE降低84.2%,平均RMSE降低61.5%;Autoformer相比于ARIMA模型,平均MAPE降低81.1%,平均RMSE降低69.2%。(2)通过新闻媒体文本的引入所构建的媒体情绪指标对玉米期货价格的预测带来了积极的影响。玉米、大豆、小麦以及原油四个情绪指标的引入,使得测试集RMSE平均下降了27.7%,MAPE平均下降了18.5%。(3)Chat GPT进行新闻媒体文本情绪评分在长期预测方面更有效率。使用Chat GPT相较于BERT,通过Autoformer模型预测准确度的对比,测试集MAPE平均下降了18.9%,RMSE平均下降了4.2%,而在长期预测(滞后240天),测试集MAPE与RMSE下降幅度更大,分别为23.2%和4.4%。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2024.002383
{DOI}: 10.27312/d.cnki.gshsu.2024.002383
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于大语言模型的个性化试题生成与精准评测研究
{Author}: 陈云
{Tertiary Author}: 吴笛
{Publisher}: 湖北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 大语言模型;ChatGPT;自动化试题生成;提示词学习;认知诊断
{Abstract}: 近年来,随着互联网技术和人工智能技术的飞速发展,教师和学生能够轻易地在互联网上获取各式各样且种类繁多的教育信息,也需要更多的时间对这类教育信息不断进行筛选消化和处理。本研究以ChatGPT为代表的大语言模型为基础,结合提示词学习技术,使得大语言模型能够满足人们快速获取与采集教育信息的需求。随着人工智能的发展,提示学习技术逐渐成为大语言模型技术中一个关键的研究方向。本研究发现大语言模型对于教育领域的改革和应用研究具有重大意义。本研究将当前大语言模型融入教育环境,基于大语言模型生成个性化试题的方法以及其在教育中的应用场景。针对生成提示中存在的偏差、上下文理解缺失、格式不规范以及教育评估中的道德问题,文章进行了详尽的分析,并提出了创新性的解决策略。本文旨在推动大语言模型在教育领域学习资源生成的应用,并促进基于大语言模型的教学实践研究。基于前人的研究成果,本研究首先构建了含有知识点关系的知识图谱,并将知识图谱作为知识库输入到经过预训练的大语言模型中,并将传统的大语言模型改进为基于知识增强的大语言模型,并将改进后的大语言模型和认知诊断相结合,提出了基于增强知识的大语言模型试题生成和学习者精准评测方法,进一步缩小了大语言模型与教育领域的应用之间的“时空”。本研究对武汉市某大学学生的学习效果进行实验,验证了大语言模型生成试题方法的有效性,并利用认知诊断模型对学生的学习能力和学习效果进行了深入分析,为利用大语言模型在教育领域的实践提供了范例,还分析了大语言模型生成试题的具体效果,并帮助学生更好的认识到自身存在的知识漏洞。此外,本研究在帮助学习者了解自身知识结构存在问题的同时,也为他们提供了更多样化、个性化的试题选择。研究结果能够帮助教师更好地调整教学策略,从而进行更有针对性的教学。
{URL}: https://link.cnki.net/doi/10.27130/d.cnki.ghubu.2024.002443
{DOI}: 10.27130/d.cnki.ghubu.2024.002443
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态思维链推理的视觉问答方法研究
{Author}: 胡钇
{Tertiary Author}: 沈复民
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自然语言处理;大型语言模型;上下文学习;思维链推理;强化学习
{Abstract}: 近年来,大型语言模型(Large Language Models,LLMs)技术蓬勃发展,以Chat GPT为首的LLMs在多个自然语言处理任务上表现出了杰出的性能。LLMs的出现,让自然语言处理的研究和应用越来越以预训练模型为中心,并且随着预训练模型的参数量越来越大,许多科研人员已经无法承担微调预训练模型的成本。因此,人们开始使用上下文学习的方式使LLMs输出下游任务的结果。在模型参数量足够大的情况下,使用零样本或少样本的上下文学习也能够取得与微调模型相当的结果。在使用LLMs的过程中,为了能让LLMs解决逻辑较为复杂的问题,可以使用思维链(Chain-of-Thought,CoT)推理来提示LLMs分步骤回答问题,提高LLMs的逻辑能力。最近的研究开始探索多模态复杂场景的思维链推理,比如科学问答任务,这是通过使用高质量的人工标注思维链推理作为监督信号微调多模态模型实现的。然而,人工标注的思维链推理可能会遗漏了必要的外部信息,导致LLMs产生错误的结果。为了解决这些问题,本文首先提出了第一个解决方法T-SciQ(Teaching for Science Question Answering)。该方法使用LLMs生成的思维链推理作为监督信号来训练较小的多模态模型解决科学问答任务。具体来说,T-SciQ首先通过少样本上下文学习使LLMs生成两种思维链监督信号QA-CoT和QA-PCoT。QA-CoT是通过常规提示生成的思维链,能够赋予多模态模型解决简单科学问题的能力。QA-PCoT生成的过程中需要显式提示LLMs分步骤生成结果,它可以赋予多模态模型解决困难科学问题的能力。为了使训练模型的两种监督信号不会产出冲突,每种类型的问题只能保留其中一种信号,T-SciQ直接根据验证集上对应类型的问题的准确率筛选信号。T-SciQ筛选信号的方法比较简陋,因此本文提出了第二个解决方法T-SciQ-PG(Teaching for Science Question Answering by Policy Gradient)作为其改进。T-SciQ-PG利用强化学习,使用额外的代理网络实现两种监督信号的混合。大量的实验结果表明,本文提出的T-SciQ-PG方法在三个数据集上达到了新的最先进的性能,证明了该方法的有效性和优越性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.005114
{DOI}: 10.27005/d.cnki.gdzku.2024.005114
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人机信任视角下高校学生ChatGPT使用意愿影响因素研究
{Author}: 刘思婕
{Tertiary Author}: 黄琦翔
{Publisher}: 广东外语外贸大学
{Type of Work}: 硕士
{Year}: 2024
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzuZ-qy6aKEE4QR4DrMB2lV_DiTCIcxzvxalWwMZr6fsr95v-bNZqX2xi4RnvViEdeoQWD4BEeqmWuvg5brqF1pnMN54XAxnW3D_cWSbMf5b0yI0mS8vKrksPTqatAZU4ViyD9YUXn1JTwp1bWX7x5QJ8ty3DL4RNC1ldAUV1Ztc7kc98PD28Crqsq1ssqjSww=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图书知识图谱的智能问答系统研究与应用
{Author}: 陈婷婷
{Tertiary Author}: 徐天伟
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 知识图谱;智能问答;实体抽取;意图识别
{Abstract}: 近年来,深度学习技术在图情领域得到广泛应用,传统图书馆向智慧图书馆转型是必然趋势。大数据与人工智能技术为领域知识体系构建以及智慧图书馆创新服务指明方向,然而受高质量大规模领域数据集缺乏的困扰,提供满足用户个性化、多元化、精准化的高效资源服务成为当前亟待解决的关键问题之一。本文旨在研究基于图书知识图谱的智能问答系统,重点关注低资源场景下智能问答模型的设计和优化。通过在实体抽取和意图识别任务中分别引入对话式生成大模型和多任务学习技术,缓解系统在实际应用过程中对数据的高度依赖,从而实现图书资源的高效便捷管理和智能问答服务。主要工作如下:(1)面向智能问答系统的图书领域知识图谱构建。为了加强问答模型的可解释性,构建图书知识图谱为问答服务提供数据支撑。首先通过网络爬取并收集图书相关数据,本体构建定义实体与属性关系,再经过相似度计算进行实体对齐构建应用于问答系统的图书知识图谱,存储在Neo4j图数据库中,包括34542个实体节点,40364条属性值,76674条实体关系,能很好满足智能问答系统的应用需求。(2)基于对话式生成大模型的实体抽取模型。针对传统监督学习模型对图情领域高质量大规模数据集的依赖问题,本文充分利用对话生成大模型在少样本学习和推理能力方面的优势,提出一种基于Chat GLM的图书实体抽取模型。该模型采用P-Tuning v2方法对模型进行微调,并在Prompt提示中融入图书知识图谱信息,增强大模型生成文本时的思维链,实现通用型对话式生成大模型的领域化应用。通过多组对比实验表明该方法在低资源场景下可以有效提升领域实体抽取的效率,与BERT类模型相比具有显著优势。(3)基于多任务学习的意图识别模型。针对现有监督模型在低资源状态下容易产生过拟合问题,文本根据特定应用需求和知识图谱特点,提出一种基于多任务学习的意图识别模型。通过多任务学习模型将意图关系分类和意图对象分类结合起来,并采用梯度归一算法Grad Norm平衡多任务学习的损失,实现模型在低资源场景下对用户提问意图的精准识别,利用意图关系和意图对象实现知识图谱多跳查询,以提高问答系统的性能。实验结果表明基于多任务学习的意图识别模型具有良好的泛化能力,能提升模型在低资源场景中的表现。(4)基于图书知识图谱的智能问答模型设计及系统开发。基于提出的核心算法模型,本文设计了基于图书知识图谱的智能问答模型。首先通过基于编辑距离的实体链接方法将经过实体抽取模型抽取到的实体映射到本文构建的图书知识图谱中,再根据意图识别模型识别的意图类别构造Cypher语句查询知识图谱中的答案,经过答案排序选择最优答案,最后生成自然语言回答,并返回给用户准确的答案。在此问答流程基础上,本文采用MVC+Flask+Vue的技术架构,开发了基于图书知识图谱的问答系统,实现了智能问答服务。该系统可同时提供知识管理、知识图谱可视化等功能,能够较好地满足高校师生对图书知识问答和管理的智能化需求。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2024.001571
{DOI}: 10.27459/d.cnki.gynfc.2024.001571
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 差分隐私机器学习算法的设计与优化
{Author}: 于达
{Tertiary Author}: 印鉴
{Publisher}: 中山大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 可信机器学习;训练数据隐私保护;差分隐私;差分隐私深度学习;数据脱敏
{Abstract}: 数据是深度学习和人工智能领域的基石。近年来,大量的高质量训练数据已经推动了这两个领域的快速发展,催生出众多创新应用,如人脸识别、语音助手和聊天机器人等,极大地提升了人们生活的便利性,同时也促进了社会生产力的进步。因此,获取高质量的训练数据显得至关重要。然而,数据泄露的潜在风险,如训练模型在推理过程中可能泄露训练数据,使得在私人助理、金融、医疗等敏感领域的大量数据还无法用于模型的开发和训练。为此,设计能够保护数据隐私的学习算法显得尤为重要。相关算法可以增强敏感数据的可用性,从而进一步推动深度学习在相关领域的应用与发展,对不同应用场景具有广泛而重要的社会价值。
差分隐私(Differential Privacy)作为一种理论上严格的隐私保护定义,在传统数据库领域已成为保护数据隐私的黄金标准。近年来,开发能够为训练数据提供差分隐私保护的机器学习算法是一个重要的新兴研究方向。这一方向面临着三个主要问题:1)相关优化算法的理论分析工具还不够完善;2)将这些优化算法应用于深度学习的挑战亟待解决;3)新兴的大语言模型的指令调优过程需要人类标注员,而这引入了传统差分隐私优化算法无法解决的新的隐私风险。
具体来说,相关优化算法的经验风险最小化(Empirical Risk Minimization)的理论上界的分析还有很大提升空间。此外,当这些优化算法被应用于深度学习实践时,存在两大主要挑战:一是相比于传统的深度学习算法,它们的计算开销的大幅增加;二是,相较于未采用隐私保护措施的基线模型,满足差分隐私的模型在准确度上有所降低。最后,现有的研究主要关注在模型部署阶段对训练数据泄露的问题。然而,随着基于人类反馈的强化学习(Reinforcement Learning from Human Feedback)等算法的流行,在模型训练数据的创建阶段出现了新的隐私风险。这是因为基于人类反馈的强化学习需要使用人类标注员进行数据注解,而将敏感数据暴露给人类标注员引入了新的风险。为了解决这些问题,本文进行了以下四个方面的工作:
1.针对经验风险最小化理论上界不是最优的问题,本文分析了用来保证差分隐私的噪声对目标函数优化性质的影响,并基于此分析显著提升了先前研究中的理论结果。具体来说,我们展示了在带噪声的梯度下降过程中,效用保证是由目标函数的海森矩阵(Hessian Matrix)的“期望曲率”决定的,而不是像传统优化分析那样仅基于全局最小曲率。这里提出的“期望曲率”概念,代表了整个优化路径上的平均曲率,并且显著优于全局最小曲率。因此,通过采用“期望曲率”进行分析,本文显著提升了经验风险最小化的理论上界。
2.针对差分隐私深度学习算法的计算开销大的问题,本文首先分析了导致额外计算开销的原因。这种额外开销源于该类学习算法需实例化并存储每个训练样本的梯度。不同于传统学习算法仅需存储批次样本的平均梯度,这显著增加了算法的内存开销,从而减缓了训练速度。为解决此问题,本文提出了一种重参数化神经网络前向传播过程的方法。通过采用这种重新参数化的方法,本文能够在反向传播过程中以极小的内存开销存储每个样本的梯度投影。实验表明,本文提出的重参数化方法大幅降低了此类学习算法的内存占用,并显著提高了训练速度。
3.针对差分隐私深度模型准确度显著降低的问题,本文提出了一种使用预训练模型来大幅提升模型性能的方法。预训练模型首先在公开且非敏感数据上进行学习,然后再被应用于下游任务。在传统深度学习任务中,预训练模型已被证实可以显著提高模型性能。然而,如何在需要保护下游训练数据隐私的场景中应用预训练模型还是开放性问题。本文首次尝试将预训练模型应用于这一场景,并提出了一个既简单又高效的元框架。通过详尽的实验,我们证明了该框架能显著提升提供差分隐私的学习算法的性能。
4.针对人类标注员引入的隐私风险,本文提出了一种在标注过程中使用合成数据替代真实数据的方法。在许多模型的开发过程中,模型服务提供商会首先部署一个初始模型,然后收集用户在使用过程中提供的指令。为了对模型进行迭代优化,服务提供商会雇佣标注员对用户指令进行分类和回复。本文首先分析了现实世界中的用户指令数据集,发现它们包含大量敏感信息,进而引出了一个关键问题:将用户指令交给人类标注员处理可能会导致隐私泄露。为了解决这一问题,本文提出使用具有差分隐私保证的合成指令来对真实数据进行脱敏,并开发了一套生成高质量合成指令的框架。实验结果表明,使用合成指令能有效地防止训练过程中的隐私泄露,同时确保对话模型的性能与使用真实用户指令训练出的模型相媲美。
{URL}: https://link.cnki.net/doi/10.27664/d.cnki.gzsdu.2024.000015
{DOI}: 10.27664/d.cnki.gzsdu.2024.000015
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向机器学习的高效数据隐私保护方法研究
{Author}: 刘建奇
{Tertiary Author}: 李会勇
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 集中式机器学习;非独立同分布数据;联邦学习;高效数据隐私保护
{Abstract}: 近年来,在大数据和大算力的推动下,机器学习技术已在各领域得到了广泛的应用。根据机器学习模型训练方式的不同,机器学习模型的训练场景可分为集中式机器学习场景和以联邦学习为代表的分布式机器学习场景。然而,越来越多的研究表明集中式机器学习场景和联邦学习场景中存在不同的数据隐私泄露问题。具体包括:1)集中式机器学习场景中,用户的原始数据被上传到云端服务器用于机器学习模型推理或训练。然而,这些上传的原始数据往往包含大量的隐私信息,尤其涉及人脸数据时,存在极高的数据隐私泄露风险;2)联邦学习场景中,为了提高机器学习模型训练的收敛速度(即提高通信效率)和模型测试精度,部分联邦学习算法共享全局数据的策略,存在泄露参与设备原始数据隐私的风险;3)联邦学习场景中,尽管参与设备的原始数据不离开本地,但在协同训练过程中,参与设备共享的模型更新仍然存在泄露原始数据隐私的风险。虽然目前已有许多保护数据隐私的相关工作,然而这些工作存在计算开销大和通信效率低的问题。为此,本文面向集中式机器学习场景和联邦学习场景展开了研究,旨在保护数据隐私的前提下,提出相应的高效数据隐私保护方法。本文的主要研究内容和创新成果如下:
(1)面向集中式机器学习场景,针对上传人脸数据的隐私保护问题,本文提出了一种基于嵌入式自编码器的高效人脸去识别框架,有效保护了人脸身份隐私。具体而言,该人脸去识别框架由隐私去除网络、特征提取网络、隐私评估网络三部分构成。为了减少人脸数据去识别时的计算开销,本文着重设计了隐私去除网络的结构,其由两个不同结构的自动编码器嵌套构成。此外,为了使隐私去除网络可以有效移除人脸图片中的身份信息,同时保留需要的人脸属性信息,本文使用了对抗训练的方法。实验结果表明,与现有方法相比,所提框架能够节省最高达99.30%的计算开销。此外,所提框架在数据实用性方面超越现有方法最高达26.22%。
(2)面向非独立同分布数据的联邦学习场景,针对全局数据共享的隐私保护问题,本文提出了一种基于选择性数据收集的高效隐私保护联邦学习算法,实现了隐私保护的全局数据共享。具体而言,为了防止全局数据共享泄露参与设备原始数据的隐私,本文在中央服务器端利用目前最为先进的生成模型(稳定扩散模型和大语言模型)生成了用于训练生成对抗网络的候选训练数据,从而避免收集参与设备的原始数据。同时,为了确保候选训练数据与参与设备的原始数据具有相似的领域知识,本文提出了一种选择性数据收集算法,该算法可以挑选出代表参与设备并要求它们共享特定的本地类原型,随后利用这些本地类原型从候选训练数据中选择合格的训练样本。此外,为了提高模型训练的收敛速度和模型测试精度,本文在参与设备端提出了一种隐私保护的模型双重校准方法,其有效减少了参与设备本地模型与全局模型之间的偏差。实验结果表明,与现有方法相比,所提算法在保护参与设备原始数据隐私的前提下,实现相同模型测试精度的同时可以减少最高达52.49%的通信开销。
(3)面向非独立同分布数据的联邦学习场景,针对模型更新共享的隐私保护问题,本文提出了一种基于变分自编码器的高效隐私保护联邦学习算法,有效防止了模型更新中的梯度信息泄露参与设备原始数据的隐私。具体而言,为了防止梯度泄露原始数据的隐私,本文在参与设备端设计了一个数据混合模块,该模块具备对参与设备的原始数据加入噪声扰动的功能。在本地模型训练期间,参与设备的原始数据首先会被送入到数据混合模块以得到去隐私的混合数据,然后再使用此混合数据进行模型训练。因此,攻击者无法利用梯度信息恢复出参与设备的原始数据。此外,为了提高模型训练的收敛速度和模型测试精度,本文在中央服务器端提出了一种隐私保护的全局数据集蒸馏方法,蒸馏得到的全局数据集可以用于补偿由数据混合模块带来的性能损失。实验结果表明,与现有方法相比,所提算法在保护参与设备原始数据隐私的前提下,实现相同模型测试精度的同时可以减少最高达87.41%的通信开销。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.000195
{DOI}: 10.27005/d.cnki.gdzku.2024.000195
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向移动应用UI设计与实现的数据驱动方法研究
{Author}: 王一惠
{Tertiary Author}: 刘华虓
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 移动应用;UI设计;UI实现;评论分析;API推荐
{Abstract}: 在信息化时代,移动应用程序(mobile application,简称app)已经渗透到人们生活与工作的方方面面。用户界面(user interface,简称UI)作为连接移动应用与用户的桥梁,直接影响着用户对于应用的交互体验。一个精心设计的UI界面能够提升用户的满意度和忠诚度。清晰简洁的布局、易于理解的导航结构和令人愉悦的视觉效果可以帮助用户更加快捷地完成任务,提升对应用的信任感。
移动应用程序的UI开发包括两个重要任务,即UI设计和UI实现。在完成这两个任务的过程中,产品开发人员面临着以下问题。
在UI的设计中,开发人员需要对产品UI进行持续的改进和优化。为此,他们需要不断地收集用户关于UI的建议信息,并结合用户的建议对UI界面进行调整和优化。因此,如何高效地获取用户关于UI的建议以提升应用产品的UI设计是开发人员面临的第一个问题。此外,开发人员在追求UI创新和独特性的同时需要保证其功能布局符合用户的使用习惯,过于个性化或特别的功能布局设计会给用户的使用带来困难,进而引起用户的困惑和抗拒。因此,如何分析产品UI的功能布局是否符合常规设计惯例,是开发人员面临的第二个问题。
在UI的实现中,开发人员面临的一个重要任务是编写代码实现UI中的动画。UI动画是在移动应用UI上有意构造的视觉变化,可以让应用更加赏心悦目,同时还能提高产品的可用性。在UI动画的实现过程中,绝大部分编程任务都可以利用动画API来完成,由此避免重复“造轮子”。然而,动画相关的API数量众多,如何根据当前动画任务选择相应的API是开发人员面临的一个重要问题。
针对上述问题,本文基于深度学习、自然语言处理等领域中的流行技术提出相应的数据驱动方法,从海量评论和应用商店的APK文件中挖掘关于UI设计与实现的可重用知识,帮助移动应用开发人员获取用户关于UI的建议、评估产品UI的功能布局以及使用动画API资源。
本文的主要研究内容如下:
(1)针对用户评论的UI建议挖掘方法
UI设计是一个需要持续改进和优化的过程。开发人员需要不断收集并分析用户的建议信息,从而对UI进行调整和优化。为了帮助开发人员高效地获取用户关于UI的建议信息,本文提出了UISMiner(UI Suggestion Miner),一种从评论中自动挖掘UI设计建议并定位UI建议位置的方法。UISMiner的实现依赖于自然语言处理和机器学习技术,主要包括三个步骤:1)通过训练分类器获得与UI建议相关的评论;2)通过定义规则,从获得的评论中提取UI建议。3)基于语义相似度分析方法将UI建议与UI中的相应部分关联。实验结果表明,UISMiner可以有效地获取与UI建议相关的评论,并从获得的评论中提取相关信息。人工评估实验表明了UISMiner的实用价值。
(2)基于产品设计经验的UI功能布局检测方法
UI的功能布局有许多非官方但被广泛接受的设计惯例,包括功能的位置和功能之间的位置关系。如果产品UI未能遵循这些设计惯例,用户在使用app时则可能会感到困惑。为了帮助开发人员分析产品的UI是否在功能布局方面具有违反设计惯例的风险,本文提出了一种功能布局分析方法Ui Analyzer。该方法将UI的功能布局与相似UI的功能布局进行比较,从而对被分析UI的功能布局进行评估。Ui Analyzer首先根据功能布局为被分析的UI和相似的UI生成语义线框图。随后,利用卷积神经网络从语义线框图中提取视觉特征,并应用异常检测算法对得到的视觉特征进行处理,判断所分析UI对应的视觉特征是否存在异常。实验结果表明,Ui Analyzer能够有效评估应用UI的功能布局是否存在违反设计惯例的风险。
(3)针对安卓动画实现的API列表推荐方法
在UI动画实现的过程中,开发人员很难从大量的API中识别出适合的API实现当前动画。应用市场包含了数以百万计的应用,它们可以为解决这个问题提供宝贵的数据资源。通过总结应用中相似动画的API使用情况,可以为推荐工作提供可重用的知识。本文提出了Animation2API,从现有的app中挖掘API知识,并为UI动画推荐API。与现有基于文本的API推荐方法不同,Animation2API采用GIF/video格式的UI动画作为查询输入。首先,通过分析大量的app,构建了一个包含UI动画和API映射关系的数据库。然后,构建了一个UI动画特征提取器,用于获取UI动画的时空特征向量。通过比较UI动画之间的时空特征向量,从数据库中识别出与查询动画相似的动画。最后,总结相似动画所用的API,为开发人员推荐API候选列表。实验结果表明,与基于文本的API推荐方法相比,Animation2API能够更准确地为动画实现推荐候选API。用户实验表明,Animation2API能够提高开发人员的动画开发效率。
(4)基于多模态信息的安卓动画API实时推荐方法
动画的实现通常需要调用多个API。为了在开发人员编程过程中实时提供帮助,本文提出了U-A2A,一个根据编程上文和动画任务的多模态信息实时推荐动画API的推荐模型。该模型基于3D-CNN和GRU分别提取动画任务和API上文的信息,并基于线性模型预测下一个待使用API。本文利用UI探索和代码分析技术获取动画与API序列的关联关系,并基于这些关联关系对模型U-A2A进行训练。实验结果表明,U-A2A能够有效地根据API上文和动画任务推荐下一个待使用API。
综上所述,本文面向移动应用的UI设计和UI实现过程,基于自然语言处理,数据挖掘,逆向工程和深度学习等技术,围绕UI建议获取,UI功能布局检测,UI动画API推荐这三个问题开展研究,旨在为app开发人员提供帮助。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.000384
{DOI}: 10.27162/d.cnki.gjlin.2024.000384
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的超高清视频质量评估方法研究
{Author}: 邢凤闯
{Tertiary Author}: 王捍贫
{Publisher}: 广州大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 无参考视频质量评估;Transformer;对比语言-图像预训练;多模态融合
{Abstract}: 视频作为一种信息载体,因其丰富且生动的内容使其在日常生活中得到广泛应用。然而,随着视频数量的急剧增长,许多低质量的视频也不断涌入人们的视野,大大降低了用户的观看体验。视频质量评估(Video Quality Assessment,VQA)系统能有效估计视频的质量,并通过质量信息来优化视频传输、存储和编码等,提高用户的观看体验。随着5G通信技术和计算机技术的蓬勃发展,超高清(Ultra High Definition,UHD)视频逐渐成为各类视频平台的主流内容。UHD视频凭借其超高分辨率和极高帧率的特点,大幅提升了用户的视觉体验。然而,这种超高分辨率和帧率也给基于卷积神经网络的VQA方法带来了新的挑战,尤其是计算复杂度的增加和长期依赖特征的增长,使得UHD视频质量评估变得更加困难。
Transformer架构在自然语言处理和计算机视觉任务中展现出了出色的性能。UHD视频数据具有与自然语言相似的长期依赖特性,并且视频帧还具有与图像相似的空间结构。因此,本文主要研究基于Transformer的无参考视频质量评估方法,探索该方法在处理UHD视频数据时的性能表现。本文的主要工作涵盖以下三个方面:
(1)由于缺乏UHD视频质量评估数据集,本文构造了一个全新的4K超高清视频质量评价数据集DVL2021,用于4K超高清视频质量评估的研究。该数据集一共包括206个(后期扩展为643个)野生4K超高清视频样本。每个序列以每秒50帧(fps)的速度捕获,并以原始的10位4:2:0 YUV格式存储,持续时间为10秒。根据ITU-RBT.500-13提供的电视图像质量主观评价方法,招募了32名评估者参与了主观质量测试的过程,年龄从十八岁到六十四岁不等(平均年龄为32.7岁)。DVL2021具有以下优点:1)视频内容丰富多样,2)拍摄相机类型繁多,3)真实失真类型复杂,4)时空信息广泛分布,5)主观评分(Mean Opinion Score,MOS)广泛分布。此外,本文通过DVL2021评估五种主流VQA方法来进行基准实验。这些方法的基线结果的SROCC系数(Spearman Rank Order Correlation Coefficient,SROCC)全部高于0.75,说明了DVL2021达到了较高的可靠度。
(2)针对UHD视频具有超大分辨率(4K的分辨率)和长时间依赖特性(50fps的帧率)的困难,本文尝试使用Transformer架构来执行视频质量评估任务,提出了一种新颖的用于VQA任务的时空注意力网络,命名为Star VQA。Star VQA通过交替级联的时空注意力构建了一个基于Transformer的网络模型。为了适应Transformer架构的训练,在Star VQA中,设计了一个矢量化回归损失函数,它将主观评分(MOS)编码为概率向量,并嵌入一个特定的向量化标记作为可学习变量。为了捕捉视频序列的长时空依赖关系,Star VQA将每个补丁的时空位置信息编码为Transformer的输入,从而获取视频的空时质量特征。另外针对视频质量评估样本量较少,且Transformer的训练需要大量数据的问题,本文设计了协同训练的范式,基于Star VQA提出了一种针对VQA任务的协同训练的时空注意力网络,称为Star VQA+,它使用图像分类数据集Image Net和VQA视频数据集协同训练空间和时间注意力权重的方法。在包括LIVE-Qualcomm、LIVE-VQC、Ko NVi D-1k、You Tobe-UGC、LSVQ、LSVQ-1080p和DVL2021在内的野生视频数据集设计了多个实验。实验结果表明,本文提出的Star VQA+优于之前最先进的方法。
(3)针对预训练的过程中源域(图像分类任务)和目标域(VQA任务)不一致的困难,本文尝试利用对比语言-图像预训练(Contrastive Language-Image Pretraining,CLIP)方式处理VQA任务。在从大规模网络数据中学习视觉-语言表示时,CLIP在广泛的视觉任务中展现出了出色的泛化能力。然而,将其应用于广泛研究的VQA任务仍然是一个未解决的问题。本文提出了一种基于CLIP的方法用于解决VQA问题,命名为CLIPVQA。具体而言,首先设计了一种有效的视频帧感知范式,旨在提取视频帧之间丰富的时空质量和内容信息。然后,利用自注意力机制充分整合时空质量特征,得到视频级的质量表示。为了利用视频的质量语言描述进行监督,开发了一个基于CLIP的语言嵌入编码器,然后通过交叉注意力模块将其与生成的内容信息完全聚合,以产生视频-语言表示。最后,将视频级质量和视频-语言表示融合在一起进行最终的视频质量预测,并采用矢量化回归损失进行高效的端到端优化。在九个野生视频数据集上进行了全面的实验,实验结果表明,所提出的CLIPVQA获得了最优的VQA性能,并且比现有基准VQA方法超越高达37%的泛化能力。此外,还进行了一系列消融研究,以验证CLIPVQA中每个模块的有效性。
通过广泛实验,本文提出的基于Transformer的超高清视频质量评估算法,包括Star VQA+和CLIPVQA,获得了令人鼓舞的结果。这些算法在多个视频质量评价数据集上(包括UHD视频质量评估数据集DVL2021)展现出卓越的性能,在客观质量评价指标上都取得了显著的成绩。随着计算机视觉和人工智能技术的不断发展,本文开发的视频质量评估算法将在视频处理和视频通信领域中扮演更重要的角色,并为未来的VQA研究和应用提供有力支持。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2024.000015
{DOI}: 10.27040/d.cnki.ggzdu.2024.000015
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言刺激下反刍特质的多质融合心理测量研究
{Author}: 李宇龙
{Tertiary Author}: 苗丹民;刘治
{Publisher}: 中国人民解放军空军军医大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 反刍特质;自然语言;多模态数据;眼动;面部AUs;面部血流;极限梯度提升
{Abstract}: 研究背景:
在现代军事环境中,士兵的心理状态直接关联到他们的任务执行效能,其中反刍作为一种持续专注于负面思维的心理特质,对心理健康和军事表现产生重大影响。反刍特质,现已被证实与包括抑郁症和焦虑症在内的多种心理疾病紧密相关。其过度活动损害个体的心理健康,并显著影响了士兵的日常功能和职业表现。在高压的军事环境下,反刍的负面效应直接削弱了个体及团队的战斗力。
尽管识别反刍特质在心理健康评估中至关重要,但现有方法主要依赖自评量表等主观工具,容易受到虚假回答、社会期望偏差和个体自我认知误差的影响,这限制了它们在精确筛查和早期预警中的效果。反刍特质在语言表达、视觉注意及面部和生理响应上具有独特表现,源于其本质上的持续和反复的负性思考与沉溺。这种思维模式不仅在语言表达中会留下显著痕迹,也体现在无意识的行为表现中。此外,高反刍者在面对刺激时,其视觉注意模式与低反刍者不同,显示出对负面信息的过度关注。反刍过程中的情绪波动及其对身体的影响——包括面部表情和血流动力学的变化——提供了特殊物理和生理证据。
鉴于此,本研究旨在探索更加客观、科学的反刍特质识别方法。随着自然语言处理(Natural Language Processing,NLP)和人工智能技术的快速发展,采用自然语言结合眼动、面部运动单元(Action Units,AUs)和面部血流的多质融合方法研究反刍特质,可以从多维度捕捉个体的情感、认知和注意力等信息,克服传统方法的局限,并提供更精确、更客观的诊断信息。通过这些技术的多模态数据分析,不仅可以提高反刍特质的识别精度,还能深化对反刍与心理健康复杂关系的理解,为军事心理健康的筛查、管理和干预提供科学依据。研究对象和方法:
本研究共分为五个部分,涉及六项具体实验,研究对象均为基层部队士兵。
第一部分:基于自然语言编制反刍刺激材料及效果验证。实验一,通过《反刍思维量表》(Ruminative Response Scale,RRS)对4591名士兵进行初筛,根据设定的入组和排除标准,选出609名被试进行一对一的半结构化访谈。访谈内容被录音并转录为文本,经过校对与去噪处理,保留607份有效文本;接下来,结合运用NLP技术与情景沉浸理论,制定出更具反刍启动针对性的刺激材料。实验二,选取40名高反刍者和38名低反刍者,对反刍刺激材料中的7个不同维度进行5点评分。通过评分统计检验及实验前后心理状态的对比,评估刺激材料的有效性和可靠性。
第二、三、四部分:基于单模态数据的反刍自然语言的识别及模型构建。对3373名士兵进行RRS调查,筛选出478名目标群体(高反刍组271人,低反刍组207人)接受反刍刺激实验。实验三,通过眼动追踪技术分析被试的视觉注意模式,构建了针对整套题目及单独题目的反刍识别模型;实验四,利用面部AUs数据分析两组人群在情绪启动下的面部表情差异,构建反刍识别模型;实验五,通过分析面部血流数据,探索了两组人群在情绪反应和生理激活方面的差异,建立第三套单模态识别模型。最后,对三种单模态数据互补性进行分析,探究眼动、面部AUs和面部血流数据在反刍特质识别中的相互补充作用。
第五部分:基于多源同步多模态数据融合的反刍识别。实验六,整合眼动追踪、面部AUs和面部血流的单模态数据分析成果,采用层级融合策略,结合XGBoost算法,构建多数据源的反刍自然语言识别模型。
研究结果:
第一部分:实验一,构建了一组由607份高反刍者访谈文本组成的反刍语料库。并基于此编制了一套包含37个语段,17种反刍情景的反刍自然语言刺激材料;实验二,在对刺激材料进行评分验证,通过混合设计方差分析发现,材料类型和人员类别之间存在显著的交互作用。具体而言,在所有七个维度上,高反刍组对反刍材料的评分显著高于对照组(反复度:t=3.058,P<0.01;持续度:t=3.099,P<0.01;联想度:t=3.189,P<0.01;生动度:t=3.336,P<0.01;失控度:t=3.043,P<0.01;假设度:t=3.413,P<0.01;代表性:t=2.674,P<0.01),而两组在中性材料评分上无显著差异。
第二、三、四部分:实验三,对两组人群在接受自编反刍刺激材料时的六种眼动指标进行比较,显示所有指标均存在显著差异。采用随机森林(RF)分类器构建的识别模型,准确率达到73.22%,逐题分析的平均准确率为69.60%;实验四,分析了两组人群在接受刺激材料时的面部AUs特征,发现在活跃度、强度及变化方面存在显著差异。最终模型的分类准确率为62.75%,逐题分析后的平均准确率提升至63.21%;实验五,对两组人群的面部血流数据进行比较,发现在额头、鼻子、左右脸等多个面部区域存在显著差异。采用RF构建的模型准确率为60.64%,逐题分析的平均准确率为58.03%。此外,人群类型与情景类型之间的交互作用显著,特定情景类型下的血流差异尤为明显。最后,互补性分析强调了眼动数据在高反刍者识别上的高真阳性率(True Positive Rate,TPR)为0.79以及面部血流数据与面部AUs数据在提高整体分类效果方面的显著互补性。
第五部分:实验六,通过多模态数据的层级融合分析,采用XGBoost算法对多模态数据进行融合分析,实现了87.03%的分类准确率,显著高于单模态方法(眼动70.08%,面部AUs 64.85%和面部血流61.09%)及其他比较算法(RF 85.98%、KNN85.35%、NB 71.54%和SVM 56.07%),证明了多模态融合在提高识别精度方面的有效性。
研究结论:
(1)本研究成功验证了刺激材料能够有效启动并测量目标群体的反刍水平。结果表明,自编刺激材料在引发和评估反刍特质方面具有良好的效果,证实了这种方法在识别心理特质中的应用潜力。
(2)通过眼动追踪、面部AUs分析以及面部血流动力学的深入研究,本研究揭示了这些非侵入式技术在区分高反刍者与低反刍者中的应用价值。这些单一模态数据在区分高反刍者与低反刍者方面表现出一定的有效性。通过对这些数据的互补性分析,证实了采用多模态数据融合可以显著提高识别的准确率,弥补了单一模态方法的不足,支持了多模态融合策略在提升心理健康评估精度方面的重要性。
(3)多模态数据融合显著提高了反刍特质的识别准确率。通过对多种单模态数据的综合分析,本研究证实了多模态数据融合在提高诊断精度方面的有效性,并强调了综合不同数据类型在心理健康评估中的重要性。
(4)特定情景显著影响了个体的心理和生理反应,为理解反刍特质的复杂性提供了新的视角。本研究通过分析不同情景下的刺激材料效用,进一步揭示了环境因素如何影响心理特质的表达。
(5)通过层级融合方法和XGBoost算法,本研究显著提高了反刍特质识别的效率和准确性。这种方法有效整合了多种数据类型的信息,优化了识别流程,并在心理健康评估中实现了较高的准确率。
{URL}: https://link.cnki.net/doi/10.27002/d.cnki.gsjyu.2024.000057
{DOI}: 10.27002/d.cnki.gsjyu.2024.000057
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成式预训练模型的关系抽取算法研究
{Author}: 蔡睿祺
{Tertiary Author}: 张永刚
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 关系抽取;自注意力机制;预训练模型;指令微调;上下文学习
{Abstract}: 关系抽取是自然语言处理领域中一项关键的下游任务,旨在识别文本中实体间的语义关系或连接。它主要包括两个步骤:实体识别和关系分类。实体识别涉及从文本中准确找出实体的起始和结束位置,而关系分类则涉及对识别的实体对进行分类,以明确它们的具体关系类型。关系抽取在信息提取、问答系统、知识图谱构建以及当下流行的大型模型等多个领域中都有广泛应用。通过从大量文本中自动提取关系信息,这一任务有助于理解文本内容、构建语义网络,并为后续的自然语言处理任务提供宝贵的背景知识。目前基于预训练语言模型的关系抽取方法主要分为两类。第一类是基于编码器结构的序列标注方法,通过对原始文本进行编码,再添加额外的神经网络结构作为序列标注框架,这种方法专注于从编码信息中提取实体和关系信息,引入了特定的模型组件和标记策略。虽然这种方法曾是关系抽取的主流方法,但它往往需要在预训练模型的基础上增加复杂的网络结构和序列标注策略,且在处理不同语言或领域时缺乏灵活性,通常还需要较长时间的新数据微调训练。第二类是基于编码器-解码器结构的生成式建模方法。这种方法通过在模型输入中增强实体或关系信息,使模型能够生成期望的文本格式,然后通过解码这些生成的文本来获取所需的实体和关系信息。尽管生成式建模方法在训练成本上有优势,并可应用于其他信息抽取任务,但现有方法通常采用复杂的标签增强操作或线性处理,这在模型微调前需要大量的预处理时间。为了解决上述问题,本文对基于生成式预训练模型的关系抽取算法进行了新方法的探索,本文的主要工作包括以下两个部分:(1)本文提出了约束指令微调方法(CITER),在生成式预训练模型的基础上引入指令微调方法,并对指令添加约束模块,提示模型生成清晰、明确的高质量输出文本。为了验证CITER的效果,本文在三个不同规模的预训练模型上,对7个命名实体识别和5个关系抽取任务的开源数据集进行多任务学习训练,实验结果显示CITER在整体实验效果上优于所有主流的对比方法。通过对CITER对应模型框架下不同子模块的消融实验,证明了CITER的有效性。(2)为了进一步提高现有方法的效果,本文提出了一种上下文学习增强的基于生成式预训练模型的微调方法(ICLER),在本文已有工作的基础上,引入是上下文学习方法,设计了上下文示例模块在训练数据集中基于句向量相似度的上下文示例选取方法。ICLER在12个开源数据集上进行多任务学习训练,实验结果表明,总体效果相比于CITER均取得了有效的提升。通过对上下文示例模块的消融实验,本文在现有实验条件下,确定了上下文示例选择个数的超参数数值k,并验证了上下文示例选取方法的有效性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.003820
{DOI}: 10.27162/d.cnki.gjlin.2024.003820
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的知识图谱问答模型研究
{Author}: 化青远
{Tertiary Author}: 彭涛
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自然语言处理;知识图谱;知识图谱问答;深度学习
{Abstract}: 随着知识图谱技术的进步和深度学习算法的发展,知识图谱问答系统在各个领域逐渐成为研究热点。这种系统能够分析用户的自然语言问题,并基于知识图谱进行信息推理和检索。尽管传统的知识图谱问答技术已经得到广泛应用并取得良好效果,但目前仍存在一些挑战和问题。首先,随着知识图谱中知识量的增长,知识图谱问答模型面临着庞大的数据库信息量的问题,在实体链接步骤中,大量无关实体会带来干扰。其次,用户对模型智能推理的需求越来越高,常针对一个主题进行连续的多轮提问,其中的缺省词和指代词为传统模型带来了挑战。因此,本文分别对知识图谱单轮问答模型和知识图谱多轮问答模型进行研究。针对知识图谱单轮问答任务,本文提出了一种基于深度学习的方法,并构建问答模型。具体而言,在检索空间生成步骤,本文将问题和知识图谱相关信息整合为推理路径节点,将问答任务转换为推理路径预测任务;答案匹配步骤对候选节点信息进行匹配度计算,提出使用预训练模型分层微调的方法特征提取;最终根据匹配度生成答案。为了验证模型性能,本文在常用知识图谱单轮问答数据集中进行实验,并改变模型设置进行了消融实验。实验结果表明,使用深度学习进行良好的特征提取能够提高模型性能,证明了本文模型和方法的有效性。基于知识图谱单轮问答模型,本文对知识图谱多轮问答模型进行了进一步研究。首先需要预测多轮问答中缺省词和指代词的历史位置,其次拼接整合当前问题,转换为单轮问答,从而得到答案。具体而言,首先对实体间关系进行抽取从而弱化实体名称带来的干扰,生成推理路径节点;其次,构建图结构神经网络模型对推理路径图进行预测,将缺省词定位任务转换为预测依赖问题任务;最后,根据预测节点生成答案检索空间,根据检索空间做单轮知识图谱问答,生成最终答案。为了提高特征提取的性能和模型的泛化能力,本文提出对话扩展的方法,自主生成正负样本,从而根据图结构使节点融合更多信息。在知识图谱多轮问答数据集中的实验结果表明,本文提出的推理路径节点图提高了问答的准确率。为了进一步证明推理路径节点的信息整合和特征提取的效果,本文进行消融实验,并研究训练过程中验证集效果变化。实验结果证明对推理路径节点进行特征学习的有效性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.007396
{DOI}: 10.27162/d.cnki.gjlin.2024.007396
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能技术驱动下档案馆智慧服务策略研究
{Author}: 董雨欣
{Tertiary Author}: 李捷;任建伟
{Publisher}: 郑州航空工业管理学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 档案馆;人工智能;智慧服务;大语言模型
{Abstract}: 现阶段,我国各行各业正在以万物互联为导向,迅速朝着智慧化发展,经历着前所未有的革新。档案馆作为公共文化服务机构,不仅承担着社会教育和信息服务的功能,也亟需融入到智慧化的潮流与趋势当中。随着时代的发展,传统的以“馆藏为中心”、被动服务为主的档案服务已不适用且满足公众的档案服务需求,公众期盼档案馆可以进一步提供便捷化、智慧化、个性化的服务。因此,本文将人工智能技术引入到档案馆智慧服务建设当中,促进了档案馆顺应新时代的可持续发展,构建了档案事业全新格局,推动了档案事业的高质量发展。本文紧密围绕“人工智能技术驱动下档案馆智慧服务策略研究”,将文章分为七个章节进行展开。第一章论述了本文的研究背景与意义、国内外研究现状、研究思路与方法还有研究创新与不足。第二章对档案馆智慧服务、人工智能进行了概念界定,依托档案双重价值论、新公共服务理论和技术嵌入论作为本研究的理论基础。第三章是本研究的机理分析,说明了在人工智能技术驱动下档案馆智慧服务的构成要素以及技术体系,并通过搭建档案馆智慧服务平台分析了人工智能技术到底是如何应用进档案馆智慧服务的。第四章总结归纳了人工智能技术驱动下档案馆智慧服务的主要功能及典型的应用场景。第五章是通过网络调查对档案馆近年来人工智能技术的应用现状进行调研,针对调研结果分析了人工智能技术应用于档案馆智慧服务中的现实问题。第六章是针对人工智能技术驱动下档案馆智慧服务的现存问题提出解决策略,并将大语言模型的使用作为档案馆智慧服务未来发展的趋势,以期为档案馆智慧服务的建设提供一些借鉴和参考。第七章则是本文的总结与展望。
{URL}: https://link.cnki.net/doi/10.27898/d.cnki.gzhgl.2024.000172
{DOI}: 10.27898/d.cnki.gzhgl.2024.000172
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于OpenAI的主观题自动评分方法的研究与应用
{Author}: 袁园
{Tertiary Author}: 李文华
{Publisher}: 长江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: GPT微调模;主观题自动阅卷;教育评估;自然语言处理;数据库原理与应用
{Abstract}: 随着人工智能技术的飞速发展,自然语言处理(NLP)领域取得了显著的进步,特别是大型语言模型如Open AI的GPT系列在文本生成和理解方面展现出了强大的能力。本文提出了一种基于Open AI的GPT微调模型的主观题自动阅卷方法,并针对“数据库原理与应用”课程中的多选题、填空题和简答题进行了自动评分研究。该方法旨在提高阅卷的效率和准确性。本文首先介绍了研究的背景和意义,指出传统的人工阅卷方式存在效率低下、评分主观性强等问题,而自动化阅卷技术的引入则能有效解决这些问题。随后,文章详细阐述了研究的内容和方法。在数据准备阶段,本文收集并整理了“数据库原理与应用”课程的考题和答案对,构建了一个较为丰富的题库和答案库。接下来对数据库原理与应用的不同题型做简要分析,包括多选题、填空题、简答题、设计题、编程题和综合题,最后重点落在多选题、填空题和简答题的评分方法研究与模型构建。本文采用了Open AI的GPT微调模型,通过对模型进行微调,使其能够更好地理解和评估学生的答案。针对多选题、填空题和简答题的不同特点,本文设计了相应的评分策略。对于多选题,模型会分析学生答案与标准答案的匹配程度,给出准确的评分。对于填空题,本文考虑了答案的精确性和语义相似性,以确保评分的公正性。而对于简答题,则结合了自然语言理解和关键点提取之后,用学生答案和标准答案之间的最高相似度给出得分。接下来是系统评分的功能模块。在实验部分,本文使用了大量的真实考试数据来验证模型的准确性和可靠性。实验结果表明,基于GPT微调模型的自动阅卷方法在评分准确性和效率上都表现优异,与传统的人工阅卷方式相比,具有优势。此外,本文还将本系统和市面上已经存在的其他系统做出对比,指出了本系统的优势与不足。本文的贡献不仅在于提出了一种新颖的自动阅卷方法,还在于通过实证研究验证了该方法的可行性和有效性。该方法在实际应用中可以提高阅卷的效率和准确性,减轻教师的工作负担,同时为教育评估的客观性提供了新的解决方案。最后,文章总结了研究的主要发现和贡献,并指出了未来可能的研究方向。随着技术的不断进步,本文期待基于GPT微调模型的自动阅卷方法能够在更广泛的范围内得到应用,并为教育评估的革新贡献更多的力量。同时,本文也意识到自动化阅卷技术仍然存在一定的局限性和挑战,如对于复杂题目的理解和评分准确性仍需进一步提高。因此,未来的研究将致力于优化模型性能,提高评分的精确度和可靠性,以推动自动化阅卷技术的持续发展。
{URL}: https://link.cnki.net/doi/10.26981/d.cnki.gjhsc.2024.000116
{DOI}: 10.26981/d.cnki.gjhsc.2024.000116
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 生成式人工智能的风险及其规制
{Author}: 单羽豪
{Tertiary Author}: 岳瑞凤;刘远东
{Publisher}: 中原工学院
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 生成式人工智能;风险;风险规制
{Abstract}: 生成式人工智能(Generative artificial intelligence)是利用复杂的算法、模型和规则,从大规模数据集中学习,以创造新的原创内容的人工智能技术。生成式人工智能通过“准备-运算-生成”的运行模式为人们提供了创造性和高效的内容生成工具,深刻改变了创作、沟通和信息传播方式。但其在给人们带来便利的同时也带来了一系列的风险,如在准备阶段出现了数据安全和算法偏见风险等问题,在运算阶段存在隐私泄露和网络侵权、欺诈风险等问题,在生成阶段引发了版权及版权归属不明和商业秘密泄露及其导致的不正当竞争等问题,在应用阶段其生成内容产生的意识形态、法律、伦理、环境等问题。对于以上风险问题,首先分析了当前欧盟、美国、中国对于风险规制的相关法律法规,同时列举了目前国内外的相关政策,讲述了生成式人工智能风险规制所存在的不足之处。最后需要以安全负责和科技向善为着眼点,明确以监管的核心理念与原则,采纳风险预防的核心态度,主动采取措施应对生成式人工智能可能产生的法律与社会风险。避免过度干预,在生成式技术发展与维护公共利益之间找到动态的平衡点。选择适合中国的规制路径,实现“事前-事中-事后”全链条监管,增加算法运行的透明程度,推动优化与完善知识产权相关法律生成式人工智能生成的多样化内容。这有助于平衡技术创新与社会稳定之间的关系,保障公众权益。
{URL}: https://link.cnki.net/doi/10.27774/d.cnki.gzygx.2024.000414
{DOI}: 10.27774/d.cnki.gzygx.2024.000414
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于专利知识图谱的集成电路领域自动问答系统设计与实现
{Author}: 汪志强
{Tertiary Author}: 谷俊
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 问答系统;知识图谱;命名实体识别;专利文献;大语言模型
{Abstract}: 随着大数据时代的到来,传统的信息获取方式无法满足人们从海量数据中快速、准确地获取信息的需求。在科研领域,情报工作占据了研究人员大量的时间和精力,伴随人工智能技术的发展,自动问答系统可以替代研究人员完成情报分析工作,显著提高信息分析的效率。此外,自动问答系统的应用可以深入分析特定市场的竞争格局,通过整合和评估企业业绩数据、专利信息及市场趋势报告等数据,系统可以回答行业的发展情况,提供全面的企业情报。结合大语言模型的问答能力与知识图谱的推理能力,本文以集成电路领域专利文献为例,研究如何有效构建专利知识图谱,并为专利问答系统提供数据支撑,设计并实现了基于专利知识图谱的自动问答系统。本文主要研究内容如下:(1)专利知识图谱的构建。利用网络爬虫从知网的中国专利全文数据库中采集集成电路领域的专利数据,对数据进行预处理并保存。然后构建并训练基于BERT-Bi LSTM-CRF的模型,对集成电路专利摘要数据进行命名实体识别,并且定义各个实体的分类标签及其之间的关系。最后,完成专利知识图谱的构建,将知识图谱存储到Neo4j图数据库中,为专利问答系统的实现提供数据支撑。(2)问答系统算法的设计。首先,对本地文档进行加载和拆分,利用编码模型对其进行向量化处理后存入数据库。再将用户问句编码,与数据库中已有文档片段的向量进行相似度匹配,提取出相似度最高的结果并将其加载进提示模板,作为发送给大语言模型的模板,最终生成回答。最后,利用已经训练完成的BERTBi LSTM-CRF模型,对系统生成的答案进行命名实体识别,并将识别出来的实体作为节点,利用Cypher查询语句进行查询关联知识图谱,将相关结果返回给用户。(3)专利问答系统的实现。基于上述研究成果,设计并实现基于专利知识图谱的自动问答系统。利用Flask框架对系统进行包装,通过浏览器访问的方式请求服务,最终实现自动问答、知识图谱可视化以及相关专利信息展示功能。最后,对系统进行功能测试,以验证系统的稳定性。通过自然语言交互,专利问答系统可以生成答案并直接返回给用户,提供了一种更为高效的信息获取方式。同时,知识图谱可以将实体之间的关系可视化展示,使数据关系更加直观易懂,显著提升了专利知识的获取和应用效率。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2024.002071
{DOI}: 10.27312/d.cnki.gshsu.2024.002071
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 生成式人工智能辅助论文写作的用户满意度影响因素研究
{Author}: 李玉东
{Tertiary Author}: 陈静
{Publisher}: 华中师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 生成式人工智能;用户满意度;信息系统持续使用拓展模型;信息系统成功模型
{Abstract}: 随着信息技术的发展,生成式人工智能技术因其能够根据用户需求自动生成优质的文本、图像等内容而得到了广泛应用,而其中2022年11月Open AI公司发布ChatGPT-3.5因其在个性化回应、内容多样性及对话连贯性方面出色的表现,短时间内引起了广泛关注和追捧,成为了生成式人工智能的代表作品。随后,学术界普遍关注了ChatGPT-3.5的应用和带来的风险,但针对用户体验的研究相对有限,难以从用户角度出发为生成式人工智能服务优化提供科学依据。鉴于此,本文选择辅助论文写作这一应用场景,探究该场景下用户满意度影响因素,并据此提出建议。本文以ChatGPT-3.5为研究对象,在对相关文献进行深入分析的基础上,采用信息系统持续使用的拓展模型,并引入信息系统成功模型中系统性能的测量变量(包括系统质量、信息质量和服务质量),构建了生成式人工智能辅助论文写作的用户满意度影响因素模型,旨在全面探讨用户在使用生成式人工智能辅助论文写作过程中的满意度影响因素。随后通过问卷调查对样本数据进行收集,使用SPSS软件进行描述性统计分析、信效度分析,同时使用AMOS软件进行验证性因子分析并构建结构方程分析模型进行路径分析以及假设研究,以实证生成式人工智能辅助论文写作的用户满意度影响因素模型。研究结果表明,期望确认、感知有用性以及信息质量对用户满意度具有显著影响;然而,系统质量、感知易用性和服务质量并未显著影响用户满意度。此外,期望确认对感知易用性和感知有用性也存在显著影响。本研究可为ChatGPT-3.5的APP设计和改进提供依据,有助于ChatGPT-3.5的信息服务提供商更深入地理解用户的信息需求,从而优化APP设计,改善用户体验,进一步提升用户满意度。
{URL}: https://link.cnki.net/doi/10.27159/d.cnki.ghzsu.2024.001425
{DOI}: 10.27159/d.cnki.ghzsu.2024.001425
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的医学领域问答方法研究
{Author}: 姜冉
{Tertiary Author}: 时小虎
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度学习;自然语言处理;提示学习;医学领域问答;预训练语言模型
{Abstract}: 近年来医学领域问答在科研领域和实际应用方面均取得了快速发展。良好的医疗问答系统不仅可以为消费者提供即时的信息和支持,也能够极大缓解医护人员的负担,对于提高医疗服务的质量和效率,减少误诊、漏诊等问题起到积极的帮助作用,是医疗信息化的一项重要内容。
自然语言处理领域中许多传统的文本处理模型可以直接应用于医学领域问答系统中,而近年来各种大型预训练语言模型的提出,为医学领域问答任务带来了新的希望。大型预训练语言模型不仅效果远超传统的经典模型,还可以通过微调等形式应用于不同的下游任务。但是,预训练语言模型存在参数多,训练时间长,耗时耗力等无法改变的现实问题。往往预训练语言模型在训练时使用庞大的数据库,针对下游任务小数据集微调时,一方面因为数据集过小容易出现过拟合,另一方面小数据集与预训练数据集通常存在明显的数据分布差异,容易导致模型微调后不如预期效果。针对以上问题,本文使用提示学习的方法,以预训练语言模型为基础,冻结大模型的参数,只训练少量的提示参数,大大节约时间与算力的同时使得模型对相对单一领域的数据集有更好的适应性。
本文在预训练语言模型的基础上,加入提示学习的方法,分别进行意图识别,文本问答和摘要三项任务,并应用于医学领域。本文的具体研究工作主要包括如下两方面:
1.设计了医学领域的意图识别模型,以BERT模型为基础框架,使用硬提示的方法构建新的输入,对输入文本进行意图识别。使用MATINF数据集,将所提出的意图识别模型与其他八种基准模型做了对比实验,在精确率,召回率和F1分数三种指标上,本文模型均高于其他模型,并有3.6%～14.79%不同程度的提升。
2.针对于医学领域不同消费者的几类共性问题,在BART模型的基础上分别设计了五种不同的提示学习的方法,即全局提示、个性化提示、混合提示、已知类别提示和未知类别提示。在这五种模型上分别进行了文本摘要与问答两项任务。为了训练模型生成更符合人类预期的文本,具体实现了一种针对医学领域的强化学习损失函数。为了验证算法的有效性,五种不同的问答模型分别做了对比实验与消融实验,并应用于不同任务以验证模型的泛化性,最后针对冻结和微调方式都加上提示学习的部分进行实验。与seq2seq+attention基线模型相比,无论是冻结还是微调方式,五种方法在BLEU、METEOR和ROUGE-L三种六项指标上都有7%～30%不同程度的提升。而与BART等大模型微调或冻结参数相比,在六项指标上也有1～5个百分点不同程度的提升。
总体而言,本文所做工作丰富了语言大模型在医学问答领域的应用,与已有方法相比在性能上有了一定程度的提高,具有潜在的实际应用价值,对于医疗信息化具有积极的促进作用。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.001584
{DOI}: 10.27162/d.cnki.gjlin.2024.001584
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 花生病虫害知识图谱问答系统的研究与构建
{Author}: 杨淑敏
{Tertiary Author}: 张慧
{Publisher}: 河南农业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 花生病虫害;命名实体识别;三元组抽取;知识图谱;问答系统
{Abstract}: 花生是我国重要的经济作物,在种植过程中却常常受到病虫害的侵袭。常见的花生病虫害包括花生叶斑病、花生蚜虫、花生菌核病等,不仅影响花生的正常生长,更会导致花生减产、品质下降,给农民带来经济损失。为有效管理和防控花生病虫害,科研人员和农业专家投入大量精力,探索各种防治方法,包括病虫害监测、生物防治、化学防治等,以期降低病虫害对花生生产的危害。然而,由于花生病虫害知识涉及多个学科领域,如昆虫学、植物病理学等,这些领域中的知识分散且复杂,病害和虫害之间还存在诸多关系和互动,这给防治工作带来了极大挑战。此外,农业专家培育的优良品种信息难以有效整合和应用,进一步制约了花生病虫害的防治效果。随着大数据技术的蓬勃发展,农业信息正以前所未有的速度迅猛增长,农业信息化已然成为推动现代农业发展的重要基石。本文聚焦于花生病虫害这一核心主题,通过深入的数据挖掘、分析与处理,构建了花生病虫害数据集。在数据集的基础上,进一步实现花生病虫害命名实体识别和三元组抽取,有效提取了关键信息。随后,将这些处理后的数据存储在Neo4j图数据库中,成功构建了花生病虫害知识图谱,基于知识图谱,实现了花生病虫害知识问答。本文的主要工作包括:
花生病虫害本体与数据集的构建,本文利用七步建模法构建花生本体,实现了花生病虫害分类、实体、关系和属性定义,形成了清晰、逻辑严密的知识结构。基于本体建模,通过收集、整理和清洗花生病虫害相关数据,形成了完整、高质量的数据集合,涵盖了花生病害、虫害、品种、病虫害特征、防治措施等,为后续知识挖掘和数据分析提供基础。
花生病虫害命名实体识别。针对花生病虫害命名实体识别中特殊实体识别困难、实体识别不准确等问题,提出了一种半自动化数据标注方法,对数据集进行BIO实体标注,确保数据的一致性和准确性。在模型选择方面,对比了三种不同模型的命名实体识别效果,融合了条件随机场和长短期记忆网络模型,采用精准率、召回率、F1值作为模型评价指标。通过实验测试,自标注语料的花生病虫害数据集在实体识别任务上表现出较高的性能,各项评价指标均稳定在99%以上。
花生病虫害三元组抽取与知识图谱构建。利用专业的标注工具对数据集数据进行详尽的实体、关系、客体标注。在三元组抽取环节,采用了两种方法,一是利用Cas Rel模型进行三元组抽取,二是根据标注数据的SPO角色语义,设计了一种基于句法规则的方法进行三元组抽取。在知识图谱构建方面采用自顶向下和自底向上相结合的策略。自顶向下的方式确保了知识图谱的整体框架和结构,自底向上方式可以逐步丰富和完善图谱的细节。通过两种方式的有机结合,清晰地展示了花生病虫害领域的知识结构和关联。
花生病虫害问句分类与问答系统的构建。基于Django框架,设计并实现了一个花生病虫害知识图谱问答系统。该系统利用实体属性链接技术自动提取前端用户输入的关键词,并在知识图谱中进行相关信息查询,若找到匹配的信息,系统会迅速将答案返回到用户端,为用户提供便捷、高效的知识查询服务。
实验结果表明,以上各项任务在准确性和速度方面表现出了良好的性能,能够正确高效的实现既定任务。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2024.000422
{DOI}: 10.27117/d.cnki.ghenu.2024.000422
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向医疗健康文本的文档级关系抽取研究与应用
{Author}: 李博博
{Tertiary Author}: 荆心;韩召宁
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 医疗健康文本关系抽取;深度学习;证据检索;知识图谱;大模型
{Abstract}: 医疗行业是一个典型的知识和技术密集型行业,其发展水平直接关系到国民健康和生命质量。面向医疗健康文本的实体关系抽取任务,作为人工智能自然语言处理领域的一个分支,该任务能够在海量的医学文献或电子文档中提取出有价值的医疗健康相关的知识,对于智能医疗的下游产业发展具有重要作用。虽然目前针对医疗文档关系抽取任务进行了一些研究,但是仍然存在一些亟待解决的问题:大量医疗文档中实体关系过于复杂且实体对距离较长而相互依赖过多导致模型准确率较低;医疗文档中缺乏明确的证据使得模型无法使用证据进行推理;部分模型在训练时内存效率过低,训练和推理成本过高,从而无法实现模型迁移。针对上述问题,本文主要研究内容和工作如下所述:
(1)针对实体对距离较长且相互依赖的问题,本文提出基于迭代推理和图像重建的关系抽取模型MHDoc RE。该模型主要包含三个模块:基础模块、推理模块和重建模块。首先,利用基础模块对实体对的关系进行初步预测。其次,通过迭代推理模块逐步确定基础模块的预测,有效地处理医疗文档中出现多提及且难以预测的实体对。最后,将迭代推理后的实体关系矩阵预测任务表述为掩码图像重建问题,使用推理多头自注意力模块来恢复被遮蔽“像素点”,极大地提高了模型的推理能力,使得模型能够在复杂的医疗文本中捕获多粒度语义信息来完成关系预测。模型在公开数据集Doc RED、CDR和GDA上进行实验,结果显示优于目前所有基线,消融实验证明了该方法的合理性和有效性。该研究点的研究成果极大地促进了复杂医疗文本关系抽取的准确度和完备度,进而促进医学健康知识的挖掘与整合。
(2)针对医疗文档证据使用和训练效率问题,本文提出融合有效证据和推理的医疗健康文档级关系抽取模型Doc ERRE,充分提高关系抽取过程中证据检索的利用率。该模型通过引入证据信息作为监督信号,指导医疗文档关系抽取模型的注意力模块为关系证据分配较高的权重,从而使模型在训练和推理时重点学习对应实体关系的证据语义信息。此外,还提出一种自监督训练策略,使模型能够在大量无证据标注的数据上学习证据检索。由于模型直接引导注意力将证据信息融合到关系抽取系统中,因此降低了参数计算成本和显存消耗,故而可以在消费级硬件上实现模型迁移和推理。最后,在Doc RED数据集上训练教师模型实现对远程数据的证据预测,然后利用标注好的数据训练学生模型。实验结果表明,无论是教师模型还是学生模型,相比于现有基线性能均达到了最好水平,特别是学生模型,性能提升显著。该研究点的研究成果不但解决了医疗健康知识抽取中的难点问题,进一步提升文档知识抽取的准确率,同时极大地降低了解决该任务的硬件经济成本。
(3)本文设计并实现了一个基于大语言模型和知识图谱的问答应用系统。首先通过提出的医疗知识抽取模型抽取医疗知识三元组来构建知识图谱,然后使用AI应用开发框架Lang Chain并加入医疗知识图谱作为知识库来构建问答系统,极大地提升了大模型的问答水平。最后对系统的问答效果进行了对比测试,发现加入知识图谱后系统的回答结果更加准确合理,专业性更强,符合预期要求。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000235
{DOI}: 10.27391/d.cnki.gxagu.2024.000235
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的常见病问答系统研究
{Author}: 王超
{Tertiary Author}: 孙喁喁;卢俊峰
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 问答系统;知识图谱;意图识别;实体链接;实体消歧
{Abstract}: 随着互联网普及,用户身体不适更倾向于在线自查症状,但网络信息庞杂,含有大量广告和不可信内容,难以做出准确的自我诊断,基于知识图谱的常见病问答系统解决了这一问题。该系统利用自然语言理解功能解析患者输入的问题,通过知识图谱找到对应的答案反馈用户,做到实时、准确解决患者常见病症相关问题。然而,用户输入的问题大多是内容短的口语,这给自然语言理解的意图识别和实体链接环节带来了极大的挑战。本文分析了口语化短文本语料对现有流行的意图识别和实体链接算法的影响,并在此基础上改进了自然语言理解模块,提升问答系统的整体性能。主要工作如下:
1.针对常见Text CNN模型无法利用全文特征来处理口语化短文本语料的问题,本文提出结合Text CNN和Bi GRU-Att的双通道短文本意图识别算法。该模型旨在通过整合两种不同神经网络结构的优势来提高意图识别的性能,模型首先以ALBERT词向量作为输入,使用Text CNN模型并改进它的池化操作从输入文本中提取局部特征,然后利用Bi G RU处理整个句子,连接注意力层关注文本中的关键信息,得到全局特征。两种特征合并后,通过全连接层、dropout层和softmax层输出概率值进行意图分类。本文在CMID数据集和KUAKE-QIC数据集上通过对比其它常用模型,验证了所提出的模型性能更优。
2.由于短文本语料形式和信息不完整性的限制,导致现流行针对短文本语料的实体链接算法效果不佳,本文提出基于Ro BERTa的实体链接算法,该算法包括实体提及识别、候选实体生成和消歧三个模块,在候选实体消歧模型中,通过对医疗文本的分析,在候选实体关联度得分的基础上,加入了相似度得分作为辅助得分,计算最后分数作为消歧依据得到链接实体。本文在CCKS2020中文短文本实体链接数据集上进行实验,对比其它常用算法验证了本文提出算法具有一定优越性。
3.结合文章提出的算法,构建了基于知识图谱的常见病问答系统,展示了问答系统整体流程,并详细介绍了自然语言理解模块中意图识别和实体链接的工作原理。通过展示实际问句的处理流程,对问答系统中的这两个关键模块进行了详细阐述。最后结合前端技术完成系统整体开发,展示各个功能的实际使用界面。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2024.000876
{DOI}: 10.27391/d.cnki.gxagu.2024.000876
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《探究ChatGPT的威力：应用、技术及影响》（节选）汉译实践报告
{Author}: 宋靖轩
{Tertiary Author}: 黄天娥
{Publisher}: 河北经贸大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 信息型文本;交际翻译理论;翻译策略;ChatGPT
{Abstract}: 随着科技快速发展,人工智能发展逐步成熟,渐渐成为国家数字经济发展中不可或缺的新兴力量,ChatGPT的出现也标志着人工智能发展进入新阶段。我国也开始在此领域进行探索。ChatGPT正在全国掀起一股潮流,阿里巴巴、百度、腾讯、华为等企业都相继推出了自己的ChatGPT模型。
本次翻译实践源文本节选自埃里克·萨里翁(Eric Sarrion)的《探究ChatGPT的威力:应用、技术及影响》(Exploring the Power of ChatGPT:Applications,Techniques,and Implications)。本书探讨了ChatGPT的各个方面,包括其工作原理,在计算机程序中的应用,对就业、社会、法律及伦理的影响。书中还论述了ChatGPT的长期发展前景,包括未来可能取得的进展、使用时可能面临的挑战,以及如何合理使用这项技术。笔者选取了一至三章、七至九章以及十八、十九章进行翻译实践并撰写翻译实践报告,这几章介绍了ChatGPT的发展背景、工作原理、应用领域、相关规章制度以及未来发展前景,目的是让大众尤其是ChatGPT爱好者对其使用进行最基本的了解。
源文本为信息型文本,语言简洁凝练,逻辑性较强。本次翻译实践报告以纽马克“交际翻译”理论为指导,对此次翻译实践进行分析。本篇翻译报告中,笔者结合“交际翻译”理论,以及在翻译实践中遇到的问题,从词汇、句子、篇章三方面对译例进行分析。根据笔者在翻译过程中遇到的难题,笔者也列出翻译实践中所用的其他翻译策略,例如专有名词的翻译,词类转换技巧,增译减译等。
从这次翻译实践中,笔者收获了更多的翻译方法和技巧,同时对纽马克的交际翻译理论有了更深入的了解。笔者也从此次翻译实践中吸取很多经验,以期在未来的翻译实践中尽量避免翻译错误。同时,在修改译文的过程中,笔者不断更换并应用更广泛的词汇,这也提高了自身的母语能力。最后,笔者也希望此次翻译实践能为其他译者翻译的同类型文本提供相关经验和参考。
{URL}: https://link.cnki.net/doi/10.27106/d.cnki.ghbju.2024.000803
{DOI}: 10.27106/d.cnki.ghbju.2024.000803
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向图像重构的语义通信系统设计与实现
{Author}: 王煦皓
{Tertiary Author}: 卓永宁
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 语义通信;卷积神经网络;自编码器;Transformer;语义等价语义熵
{Abstract}: 随着信息技术与计算机科学的不断发展,万物互联的智能通信逐渐成为研究热点。以人工智能技术为主导的语义通信,不仅是人与物体,物体与物体互联的核心,同时也是第六代移动通信的关键技术之一。语义通信技术是在传统信息论基础上提出的以语用为目的的达意通信,其具有信息压缩程度高,抗噪性能强等特点,但同时其抽象程度高,目前还不具备良好的量化性,因此理论研究都需要以面向任务为前提,目前主流的语义信息理论有基于知识库,基于模糊逻辑,基于语义等价等,然而现有理论都不具备普适性和良好的可计算性,都需要在面向具体任务的限定条件下来探讨。在工程实现方面,基于得益于人工智能技术的深度信息挖掘能力,以卷积神经网络为主导的图像语义通信技术和以Transformer为基本框架的自然语言处理技术已成为语义通信系统实现的关键。语义通信的关键技术中,计算机视觉主要挖掘图像的空间特征信息,自然语言处理主要针对具有时序强相关性的语言序列语义通信,将二者相结合的大型语义图像模型研究是当今语义通信系统设计实现的热点课题。在通信传输方面,图像作为一种关键的信息模态,其具有直观性强,信息丰富等特点,因此在万物互联的智能通信场景中扮演着重要的角色。本文探讨了一种面向图像重构任务的语义传输系统,具体工作概括如下:1.分析了问题研究意义及研究现状,从理论和实践两方面介绍了语义通信的理论和框架,介绍了本文的理论参考模型以及实现参考框架。2.设计实现基于残差卷积自编码器的模型,设计基于PSNR和SSIM的综合损失函数,实现图像特征的压缩提取,并分析参数化与可视化结果。3.设计实现基于Transformer的图像语义传输模型,提升信息传输过程中对抗噪声的性能,结合图像数据的特性实现编解码器,分析基于Transformer系统的鲁棒性,并结合残差自编码器结构,搭建图像语义通信系统,通过迁移学习对其进行微调。4.借助基于语义等价的语义信息论理论,语义相对熵,PSNR,SSIM以及可视化任务,在面向图像重构任务的限定条件下对本文所实现的模型进行性能分析。本文最终实现的面向图像重构的语义通信模型在传统图像相似度度量,可视化度量以及基于语义等价的语义信息论层面度量下,都取得良好效果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.004648
{DOI}: 10.27005/d.cnki.gdzku.2024.004648
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的视觉语言多模态推理方法研究
{Author}: 姚俊豪
{Tertiary Author}: 沈复民
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 视觉语言推理;提示学习;思维链提示;文档视觉问答
{Abstract}: 随着数字化时代的快速发展,大量的文档资料被电子化存储,这为自动提取信息和知识提供了可能。然而简单的文本识别和数据提取已经无法满足日益增长的信息处理需求。因此,文档视觉问答任务应运而生,它不仅要求机器识别和理解图像中的文字内容,还要求它能够根据问题的上下文来链接视觉信息与文本信息,进行推理和分析,最终给出准确的答案。文档视觉问答任务具有巨大的潜力和价值,研究人员正在探索各种先进的算法和技术,以推动文档视觉问答系统的发展。虽然这些方法在文档视觉问答任务上取得了一定的进展,但仍然存在一些问题:(1)使用预训练-微调范式来进行文档视觉问答任务,在少样本或零样本学习条件下,未能充分挖掘和利用文档图像信息,进而影响了它们在处理文档视觉问答任务时的性能表现。(2)简单地使用大语言模型在处理少样本时的上下文学习能力,很难有效地掌握文档数据的视觉信息,且不同的演示示例也会导致推理效果变化。(3)大语言模型在处理复杂的推理任务时,不透明度的决策过程有时会引发一些细微的错误,最终可能导致不正确的推理结果。针对当前文档视觉语言问答任务中存在的推理方法局限性,本文展开了深入研究,并提出了两种基于提示学习的推理方法。首先,本文通过引入布局感知提示方法,利用OCR算法处理后的文档图像数据,结合文本与位置信息的映射,保证了文档视觉语言数据能够被大语言模型更好地理解,可以从少样本学习中提取出有效的信息,从而提升了推理结果的准确性。紧接着,为了解决大语言模型在复杂推理任务中不可见的思考过程以及可能导致的推理错误,本文提出了一种基于思维链提示的零样本方法。该方法通过引导模型生成推理计划与执行结果,再整合推理过程得出答案,这样的方法能够提供更为细致的指导,从而确保大语言模型在零样本学习条件下进行文档视觉问答任务时,能够准确地进行逻辑推理。这一过程显著地提高了大型语言模型在文档视觉问答任务中的逻辑推理精确度。本文提出的方法通过实验和对比证明了有效性与可靠性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.001846
{DOI}: 10.27005/d.cnki.gdzku.2024.001846
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CLIP轻量级Transformer模型图像字幕生成研究
{Author}: 郭金雨
{Tertiary Author}: 程光辉
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 图像字幕;束波搜索算法;注意力机制;基于CLIP的早期融合Transformer(BCEFT)模型;多模态融合注意力(MFA)模块
{Abstract}: 图像字幕任务位于计算机视觉和自然语言处理这两大模态的交叉点上,旨在为输入的图像生成相应的文本描述。近期,CLIP模型因其在文本上下文中训练的丰富语义特征而备受瞩目,表现出对视觉-文本任务的高度适应性。同时,采用图像编码器与文本解码器的传统Transformer架构也在图像描述领域显示出了令人鼓舞的成果。尽管如此,模型的庞大参数量和对额外数据预处理的需求仍旧是亟待解决的挑战。首先提出了多模态融合注意力模块(MFA),旨在替代传统多模态融合模型中的核心组件。MFA模块成功将参数量和计算复杂度降低了超过一半,并且通过理论推导验证了其效率。基于此,进一步提出了基于CLIP的早期融合Transformer(BCEFT)模型,以解决上述提到的问题,并通过对比实验验证了BCEFT模型在降低参数量和计算需求的同时,仍保持优异的评价指标得分。其次验证了束波搜索算法存在一定的缺陷,即更偏向于生成较短的字幕。通过改进序列修改累计得分计算公式对序列长度进行了奖励,从而促进长序列的生成,并通过理论推导和实验验证了改进的有效性。最后通过将强化学习与改进的束波搜索算法相结合来进一步训练BCEFT模型,该方法仅需要非常短的训练时间就能产生一个高质量的图像字幕模型,无需额外的注释或预训练,它就能有效地为大规模和多样化的数据集生成有意义的描述。在MSCOCO数据集上的测试结果验证了BCEFT模型不仅实现了显著的效率提升,还将模型参数减少近50%以及将运行时间加速8倍。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.003692
{DOI}: 10.27005/d.cnki.gdzku.2024.003692
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向农作物病虫害的知识图谱智能问答系统研究与实现
{Author}: 刘瑞麟
{Tertiary Author}: 王鲁;封文杰
{Publisher}: 山东农业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 农作物病虫害;自然语言处理;知识图谱;智能问答系统
{Abstract}: 农作物病虫害是严重威胁农业生产的最重要因素之一。病虫害的识别和预防,可以有效减少其造成的经济损失。目前通过线上查阅资料来解决实际生活的农业问题已成为趋势,然而在信息化时代中,数据多源化,分散化使得农户难以快速、全面地查询与利用各种农作物病虫害的信息资源。问答系统能够提供智能检索的功能,通过检索存储在知识库中数据来自动回答自然语言问题。知识图谱的诞生和迅速发展为智能问答系统提供了全面的知识储备。本文以农作物病虫害知识文本为研究对象,结合知识图谱构建高质量知识库,通过自然语言处理技术,深度学习等方法开展命名实体识别模型与问答算法研究,设计并实现面向农作物病虫害的知识图谱问答系统。主要开展的工作如下:（1）为解决大部分农业文本无分隔符导致的潜在分词错误的问题,本文构建文本-语音多模态农作物病虫害命名实体识别模型CDP-MCNER。该方法利用语音中的天然停顿辅助中文分词,以跨模态注意力模块为主要架构、数据增强方法提高多模态输入的多样性、最后多模态语义表示输入到CRF/CTC项目层以预测标签。该模型在自构建的农作物病虫害数据集上准确率、召回率和F1值,分别为91.32%、93.05%和92.18%,均优于经典纯文本NER模型、词汇增强类NER模型和多模态NER模型,表明了该模型在面向农作物病虫害的命名实体识别方面的有效性,能够为该领域的命名实体识别研究提供方法支撑。（2）通过对农作物病虫害领域内数据进行处理与分析,自顶而下构建农作物病虫害知识图谱。首先,通过网络数据采集技术获取农作物病虫害知识,再对此数据进行预处理与清洗。其次,根据农作物文本内容的特征确定实体的类别和实体之间的关系并对数据集进行标注。然后,通过CDP-MCNER对文本数据提取实体和基于规则的方法提取融合农作物病虫害三元组。最后,使用Neo4j图数据库将三元组数据进行存储,以方便后续的知识图谱的展示。（3）为了更好地理解知识问答中的所提问题,本文提出一种基于CNN-Transformer的农作物病虫害意图与槽位联合抽取模型。该方法以BERT作为词嵌入、利用CNN网络强调相邻词的含义、利用窗口特征序列来保证词的原始顺序、最后在Transformer中引入对齐,以保持输入与输出之间的一对一关系进一步提升模型的能力。实验结果表明,CDPCT-IDSF模型在自建语料库CDPIS上的槽位填充F1值为94.36%,意图识别精度为92.99%,整体识别精度为87.23%,优于其他对比模型,表明所提模型在农作物病虫害意图识别与槽位填充任务上的有效性以及将其应用到智能问答系统问答功能的可行性。（4）将农作物病虫害知识图谱作为数据源储存在Neo4j图数据库中,设计与实现了面向农作物病虫害的知识图谱智能问答系统,完成了农作物病虫害知识问答模块与知识图谱可视化模块功能的搭建与交互,使得农户能够便捷的查阅农作物病虫害相关知识,方便农户进行农作物的防治。
{URL}: https://link.cnki.net/doi/10.27277/d.cnki.gsdnu.2024.000156
{DOI}: 10.27277/d.cnki.gsdnu.2024.000156
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向慢性糖脂代谢疾病诊疗的医学大数据挖掘与人工智能分析研究
{Author}: 何丽云
{Tertiary Author}: 张化冰
{Publisher}: 北京协和医学院
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 慢性糖脂代谢疾病;药物不良反应;医学大数据挖掘;自然语言处理;人工智能分析
{Abstract}: 【研究背景】全球慢性糖脂代谢疾病患病率持续上升,患者多药物长期使用增加了药物不良反应风险,生活方式等是影响这类疾病的重要因素。随着信息技术和医学数据库的发展,医学大数据和人工智能分析的应用为预防和管理这些疾病提供了新的可能。[研究目的]本研究旨在利用现有的医学大数据挖掘技术和人工智能分析方法,深入探索慢性糖脂代谢疾病的药物不良反应及相关影响因素,以提高治疗的安全性和管理的有效性,优化慢性代谢疾病诊疗管理方案。【研究方法】研究利用自然语言处理技术挖掘海量的中文电子病历非结构化数据,采用深度学习的大语言模型融入医学知识增强的方法,利用现有大语言模型资源,构建在中文电子病历非结构化文本数据中抽取常用降糖药物不良反应信息的抽取技术体系。研究也挖掘医学文献中的随机对照试验(Randomized controlled clinical trial,RCT)研究数据和药物警戒数据库(FAERS数据库)的真实世界数据,检测新型降糖药物肠促胰素类药物(GLP-1受体激动剂和DPP-4抑制剂)的不良反应。挖掘和分析美国哈佛医学院的电子病历及中国健康与营养调查(China Health and Nutrition Survey,CHNS)数据库,探究慢性糖脂代谢疾病相关影响因素。【研究结果】研究成功构建了用于中文电子病历非结构化数据的基于医学知识增强的大语言模型药物不良反应信息抽取系统,研究中二甲双胍药物不良反应抽取效能的F1值达0.8698。在挖掘RCT研究数据中,结果显示GLP-1受体激动剂和DPP-4抑制剂会增加胆囊或胆道疾病发生风险,但绝对风险值较小;挖掘真实世界数据所得到结果与之一致。哈佛医学院的电子病历数据分析显示减肥手术讨论可能是患者心血管事件、糖尿病的保护因素;基于CHNS数据库的中国人群数据,研究发现较长睡眠时长与炎症因子升高相关,而皮下脂肪、工作活动量分别可能是全因死亡率、糖尿病的保护因素。【研究结论】基于医学知识增强的大语言模型能够相对有效地抽取非结构化中文电子病历中的药物不良反应信息,有助于实现药物不良反应的主动监测,增强药物治疗的个体化和安全性。结合大型RCT研究数据和上市后的真实世界数据有利于检测慢性代谢性疾病新上市药物的未知的不良反应。充分挖掘电子病历数据和大规模人群的医学公共数据库,能有效识别慢性代谢性疾病关键生活方式因素,有助于优化和提高慢性糖脂代谢疾病患者的生活方式干预的管理方案。
{URL}: https://link.cnki.net/doi/10.27648/d.cnki.gzxhu.2024.000488
{DOI}: 10.27648/d.cnki.gzxhu.2024.000488
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合元认知的自适应导学设计及应用研究
{Author}: 刘桐
{Tertiary Author}: 顾小清
{Publisher}: 华东师范大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 自适应导学;元认知;领域模型;学生模型;导学策略
{Abstract}: 在数字化时代的浪潮之下,教育的数字化转型不仅是实现科教兴国和人才强国战略的必由之路,而且激发了教育领域新一轮的革命性变革。随着数字化学习环境的普及,学习形式的变化,对学习者调控学习过程的能力提出了更高的要求。然而,研究表明,许多学习者并不是优秀的学习调节者,调控能力的差距导致了学习成效的差异。元认知,作为一种高阶的思维监控和控制能力,被认为是影响学习成效的关键因素。它涉及到个体对自我学习过程的认知和调控。因此,发展适应学习者元认知需要的学习环境,成为提高学习成效的重要途径之一。
近年来,人工智能技术再次登台,为在大规模学习群体中实现自适应学习提供了新的可能性。尽管学者们围绕“教育人工智能”开展了诸多科学研究,但如何精确识别、捕捉和追踪学习者元认知状态,如何设计适应元认知状态的导学策略等问题仍然亟待解决。由此,本研究聚焦于三个核心问题:(1)如何从过程视角有效追踪学习者的元认知状态;(2)基于元认知状态,研究设计融合元认知的自适应导学机制;(3)评估融合元认知的自适应导学对学习效果的影响。
首先,本研究从理论驱动角度出发,探究元认知外显化和表征问题。从静态表征、过程表征和动态表征三个维度,建立融合元认知的领域模型表征框架,为具体表征领域模型提供理论原型。进一步,从数据驱动的角度,以本研究开发的Code Tutor学习环境为载体,结合文本分析、行为分析等技术,基于多维度的学习过程数据,表征融合元认知的领域模型。
其次,本研究遵循“问题-逻辑-机制”的路径,设计融合元认知的自适应导学机制。在自适应导学中的“两个循环”和“三个基本问题”的前提下,本研究构建了融合元认知的自适应导学的基本逻辑。并从中观视角,设计了元认知状态感知机制、自适应导学干预机制和导学内容生成机制。进一步,通过运用代码结构分析、自然语言生成等技术,实现了融合元认知的自适应导学机制。
最后,本研究基于导学系统实践,考察融合元认知的自适应导学成效。运用多维度学习过程数据,从三个方面开展实践效果分析工作:(1)基于前后测成绩比较,考察学习者知识掌握的学习收益情况;(2)从问题解决过程的视角,考察自适应导学干预对于问题解决的影响。由此,前两项分析工作回应导学“是否有效”的问题;(3)挖掘学习行为模式,分析学习者个案,回应导学“为何有效”的问题。基于以上工作,本研究得到以下结果:
首先,依托于“学习者中心”理论,本研究构建了融合元认知的领域模型。其中包括,静态语义关联表示的领域知识网络;以抽象语法树形式表达的结构化任务解决过程;涵盖三类元认知状态的动态表征。其次,本研究基于导学目标,构建了四项融合元认知的自适应导学基本逻辑和三项导学机制。运用人工智能技术,实现了融合元认知的自适应导学,并开展实践应用。
最后,本研究发现:在自适应导学系统的支持下,学习者后测成绩分布呈现出较高的一致性,尤其是在高分区间的成绩增长。在任务解决过程中,适应性学习提示发挥了正向促进作用。绝大多数学习者在接收到学习提示后能够有效地推进任务进展。通过采用贝叶斯网络分析方法,我们发现学习者在接收学习提示后,任务向前推进的概率为0.757。这说明了自适应学习提示的有效性。进一步,我们发现,自适应学习提示能够引起学习者注意,引发学习策略的调整,从而推进任务进展。学习者在理解任务要求的基础上,呈现出迭代循环的行为模式。然而,有些学习者在接收学习提示后,仍然“固守”现有学习策略,降低了任务解决效率。
本研究的创新和贡献体现在:首先,过程化表征元认知状态创新,基于“以学习者为中心”的理念,建立动态的表征方法,从过程视角表征学习者的元认知状态。其次,融合元认知的自适应导学机制创新,建立过程化的自适应导学感知机制、结构化的学习提示干预机制和具体化的学习提示生成机制。最后,本研究经历了构建理论模型,发现元认知状态,设计自适应导学机制,实现融合元认知的自适应导学功能的过程。建立从理论到实践的逻辑通链,为理论到实践的跨尺度研究提供实践思路。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2024.000426
{DOI}: 10.27149/d.cnki.ghdsu.2024.000426
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: ChatGPT模型下人工智能版权问题分析
{Author}: 彭慧莹
{Tertiary Author}: 杨振宏
{Publisher}: 黑龙江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: ChatGPT;人工智能;版权
{Abstract}: 人工智能技术作为影响人类社会的重要技术之一,依托于大数据和算法技术的更新而蓬勃发展。以Chat GPT为代表的生成式人工智能一经诞生便引发了前所未有的震动,在给用户带来便利的同时,也带来了潜在的版权侵权隐患。人工智能技术的发展标志着人工智能已经从弱人工智能开始向强人工智能过渡,新情况对当前的法律体系提出了新挑战。本文试图以Chat GPT模型的运行原理为入手点,结合我国最新的AI生成图片案例,对当前人工智能生成内容的可版权性和版权权利归属问题进行分析。在肯定人工智能生成内容可版权性的基础上,进而提出以下问题解决构想:肯定以著作权方式保护Chat GPT生成内容,设立生成内容备案登记制度和人工智能数据合理使用制度,从法律角度对可版权保护的内容进行限定;明确较短的权利保护期限和较低的侵权赔偿范围,减轻人工智能生成内容涌入文化创作市场给自然人创作者带来的冲击;赋予模型使用者Chat GPT生成内容的版权权利,构建以使用者为核心的版权权利归属体系,对内容生成付出实质贡献的权利主体给予肯定。对特定主体增设作品署名义务,帮助公众和司法机关从来源上区分辨别人工智能生成内容。
{URL}: https://link.cnki.net/doi/10.27123/d.cnki.ghlju.2024.001862
{DOI}: 10.27123/d.cnki.ghlju.2024.001862
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CLIP预训练模型的图像描述算法研究
{Author}: 陈玲
{Tertiary Author}: 向南
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 图像描述;CLIP预训练模型;跨模态融合;风格化描述;语义增强模型
{Abstract}: 图像描述是结合计算机视觉与自然语言处理的多模态任务,其主要目标是让计算机自动生成准确的文本来描述图像内容,该技术在遥感图像,视觉辅助和人机交互等领域应用非常广泛。目前图像描述模型通常采用监督学习方法,但这些方法受限于高昂的人工成本。如今,大规模预训练模型的应用为图像描述提供了新的方向。本文利用CLIP预训练模型,融合深度学习相关技术对图像描述任务进行研究,主要工作如下:
1)针对图像描述技术中的模态鸿沟和图像-文本不匹配导致的生成文本退化问题,本文提出了基于CLIP预训练模型的语义增强跨模态融合模型。该模型首先使用文本语义增强网络来提取文本增强语义表示,然后,使用对比学习,优化文本之间的相似度度量和特征表达的一致性,最后,用图像增强解码策略来生成准确且多样性的描述结果。为了评估提出的模型有效性,本项目在两个广泛使用的图像描述数据集上进行了实验,包括MS-COCO数据集和Flickr30k数据集。实验结果表明,本文提出的模型在生成描述任务中取得了显著改进。与基准模型相比,该模型在CIDEr指标和BLEU-4指标上分别提升了3.6%和3.2%。此外,本文还进行了可视化分析,展示了模型对不同隐特征之间差异性的增强效果,以及在跨域图像描述任务中的表现。
2)针对图像描述中缺乏风格化知识和不能有效融合图像客观信息与风格知识的问题,本文提出了基于预训练模型的风格强化图像描述模型。该模型通过风格增强网络,细致地捕捉和表达图像描述中的风格化元素,然后采用风格化训练策略,根据不同风格化需求调整模型的学习过程。该策略有效地平衡了描述的准确性和风格的一致性;最后,通过基于CLIP模型的风格化解码策略,确保生成的图像描述不仅在内容上准确无误,同时在风格上丰富多彩。本文在多个广泛使用的图像描述数据集上进行了实验,实验结果显示,模型在风格化描述的生成上表现更加出色,不仅提升了描述的风格化质量,也在维持内容准确性的同时增加了文本的丰富性和吸引力。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2024.000371
{DOI}: 10.27753/d.cnki.gcqgx.2024.000371
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于科学思维的ChatGPT在高中物理课堂教学中的应用研究
{Author}: 曹龙辉
{Tertiary Author}: 张欣
{Publisher}: 湖北大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 高中物理;课堂教学;科学思维;生成式人工智能;ChatGPT
{Abstract}: 《普通高中物理课程标准(2017年版)》指出高中物理课程旨在促进学生物理学科核心素养的养成和发展。物理学科核心素养包含了物理观念、科学思维、科学探究、科学态度与责任四个方面,其中“科学思维”是发展中学生核心素养的关键因素。目前有很多种培养学生科学思维的教学方法,如论证式教学、PBL教学模式、HPS教学模式,但都有无法因材施教的困难,这一困难阻碍了对学生科学思维的培养。2022年问世的生成式人工智能ChatGPT,凭借其强大的问题回答能力、启发性内容生成能力、对话情境理解能力等,能为学生提供多样化的学习资源、个性化的学习支持和及时的反馈等,为实现因材施教从而更有效地培养学生科学思维提供了可能性。因此,有必要将ChatGPT应用于高中物理课堂教学,以弥补其他培养科学思维的教学方法的不足。本论文将基于对学生科学思维的培养探讨ChatGPT应用于高中物理课堂教学的原则与策略,主要研究内容如下:第一,培养科学思维的方法及分析。本章阐述了三种培养科学思维的重要教学方法——论证式教学、PBL教学模式、HPS教学模式。分析三种教学方法培养学生科学思维的模式和途径及其优缺点。三种教学方法都具有激发学生的学习兴趣、培养学生的批判性思维等优点,其中PBL教学模式能将理论和实际结合,HPS教学模式能够培养学生的综合性思维,促进学科交叉。但这三种甚至更多的培养科学思维的教学方法都存在无法因材施教等缺点,这一缺点可以由ChatGPT来弥补。第二,高中物理科学思维培养现状以及ChatGPT在高中物理教学中的应用现状。本文通过问卷调查和访谈,以高中物理教师为调查对象,对高中物理科学思维培养现状以及ChatGPT应用现状展开调查研究,调查显示:目前高中物理教师对学生科学思维的培养效果不佳,其中一大原因是在课堂教学中无法因材施教;大多数高中物理教师对ChatGPT较为了解,但对其教育潜能认知不够,在教学中使用不多;高中物理教师对ChatGPT融入课堂教学普遍持认同态度,但缺乏相应的应用方法。第三,挖掘ChatGPT在高中物理课堂教学中的应用策略。为弥补培养科学思维的教学方法无法因材施教等缺点,根据调查ChatGPT在高中物理课堂教学中应用的困难和建议,探讨将ChatGPT应用于高中物理课堂教学中应遵循的原则,包括学生主体性、理论联系实际、因材施教、安全性原则、自主判断原则和补充不替代原则。在上述原则的基础上,挖掘将ChatGPT应用于高中物理课堂教学培养学生科学思维的策略,包括辅助学生进行推理和探究、评估学生的论证观点、辅助学生探索物理学史、辅助学生设计实验思路和引导学生质疑ChatGPT。最后总结出ChatGPT对比传统教学方法应用于课堂教学的优势,包括为学生提供个性化的学习体验、增强课堂的互动性以及培养质疑习惯,发展批判性思维。第四,以前文探讨的ChatGPT在高中物理课堂教学中的应用原则和应用策略为基础,设计基于科学思维的ChatGPT课堂教学案例,将《牛顿第一定律》作为规律课教学的案例;将《实验:电池电动势和内阻的测量》作为实验课教学的案例,进行了具体案例设计并对教学设计中的各个环节进行意图说明。
{URL}: https://link.cnki.net/doi/10.27130/d.cnki.ghubu.2024.002417
{DOI}: 10.27130/d.cnki.ghubu.2024.002417
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于逻辑关系与提示学习的推理问答技术研究
{Author}: 郑裕川
{Tertiary Author}: 秦科
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 逻辑推理;预训练语言模型;提示学习;生成式大语言模型;问答系统
{Abstract}: 随着自然语言处理技术的持续发展,推理问答技术备受关注,并在多个领域得到广泛应用。通过问答形式向机器提出问题,为用户提供了直观、便捷的人机交互方式。然而,随着研究的不断深入,机器模型在推理能力方面的不足逐渐显现。尤其是逻辑推理问题,其要求模型能够深入理解文本所蕴含的语义和逻辑信息,并进行有效推理,这对模型的阅读理解能力和逻辑推理能力提出了挑战。针对当前逻辑推理方法普遍存在的对关键问题要素的关注不足、推理能力不足、答案缺乏可解释性等问题,本论文面向多项选择式复杂逻辑推理问答问题,研究了基于逻辑关系与提示学习的推理问答关键技术,并基于上述推理问答技术的研究实现了私域数据下的推理问答系统。具体而言,本文的研究工作如下:(1)本文提出了一种基于预训练模型的问题驱动表示增强方法,并结合逻辑关联词和句子成分解析语篇结构。该方法研究了逻辑推理问题中“问题文本”对于增强题干和选项的嵌入表示中所蕴含信息的重要性;并通过逻辑关联词和句子成分将文本建模为不同层次的语义单元,进而构建图结构,利用神经网络进行信息交互与答案推理。最终,基于上述方法设计了基于精调预训练语言模型的逻辑问答问题推理模型。实验结果表明,该方法能够有效提高神经网络模型在逻辑推理问题回答准确率上的表现。(2)本文针对复杂逻辑推理问答领域中的提示学习技术展开探究,从提示学习与生成式大语言模型的角度出发,提出了多个提示学习函数设计思路,并设计了多角度的逻辑推理问题提示函数模板,以挖掘大语言模型的逻辑推理潜能。通过实验验证这些方法对生成式语言模型回答的影响,分析了大语言模型在不同提示下的整体表现。实验结果显示,合适的提示学习方法能够有效改进大语言模型在逻辑推理任务上的性能,并为答案本身提供了可解释性。对实验结果的深入分析对于未来在生成式大语言模型上开展后续研究工作具有重要的参考价值。(3)针对实际生产中的推理问答需求,本文设计并实现了基于私域数据的推理问答系统。系统基于预训练语言模型嵌入表征和提示学习技术,利用生成式大语言模型,实现了私域数据下的推理问答功能。用户可以根据需要自定义私域知识库,系统在用户提出问题时能够检索相关知识,并生成高质量、高可信的答复。通过系统功能测试验证了其在推理问答领域的潜力,系统达到了实际应用标准。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.000969
{DOI}: 10.27005/d.cnki.gdzku.2024.000969
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人工智能的数据库系统参数调优技术研究
{Author}: 陈思芹
{Tertiary Author}: 侯孟书
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 数据库管理系统;参数调优;深度强化学习;大语言模型;知识嵌入
{Abstract}: 在当今数据驱动时代,优化数据库管理系统(DBMS)的性能对于支撑广泛的商业、科研和技术应用变得越来越重要。随着技术的发展和应用场景的多样化,现代DBMS变得日益复杂,配置参数的适当设置对于确保数据库系统高效运行至关重要。然而,传统手动参数调优不仅耗时且依赖专家经验,不足以应对复杂和动态的工作负载。近年来,随着人工智能技术的发展,特别是机器学习和深度强化学习,为自动化数据库参数调优提供了新的可能性,但现有方法大多采用黑盒模型,仅考虑了数据库性能反馈作为调优依据,效率和效果受限于试验次数和范围。本论文结合最新的大语言模型(LLM)等人工智能技术,探索基于知识的数据库系统参数调优新途径。论文贡献点如下:1.设计了一个基于大模型的数据库调优知识提取算法,利用RAG流程和LLM的语言理解能力和专家知识,自动提取数据库调优文档和手册中的知识,并且通过提示工程方法提升知识提取的准确性。2.提出了一种名为Ke Tune的支持知识嵌入的深度强化学习(DRL)数据库参数调优方法,结合提取的知识与DDPG模型,设计了支持知识嵌入的调优模型架构。同时还提出基于知识的参数推荐算法初始化、基于过滤等级的奖励值优化策略等方法实现知识的有效嵌入,以提升调优效率和效果。3.基于以上算法设计并实现基于知识的数据库参数调优原型系统。以Llama Index和GPT-4-Turbo实现了从数据库手册和调优文档中提取知识的RAG过程,并在Postgre SQL数据库上验证了知识嵌入的参数调优算法的有效性。实验结果显示,KeTune在TPC-H和TPC-C两组工作负载下的调优效果均优于传统DDPG模型。在TPC-H工作负载下,当调参旋钮数量为40个时,Ke Tune模型相比DDPG模型降低延迟约21.9%;在TPC-C工作负载下,提升吞吐量约5.7%。实验结果表明,Ke Tune能够有效地利用提取的知识指导调优过程,显著提高数据库性能,同时保证了系统的稳定性和安全性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2024.001664
{DOI}: 10.27005/d.cnki.gdzku.2024.001664
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向中医文化传播的中医古籍机器翻译研究
{Author}: 刘文静
{Tertiary Author}: 钱爱兵
{Publisher}: 南京中医药大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 中医文化传播;中医古籍;机器翻译;预训练模型;数据增强
{Abstract}: 目的为了推动中医文化“走出去”,深入研究公众对中医古籍翻译的认知,并运用机器翻译方法实现中医古籍的自动翻译。以期打破中医知识传播的传统模式,帮助公众阅读和理解中医古籍中蕴含的知识和文化内涵,促进中华文化的传承和传播。
方法首先,通过文献分析法系统梳理古籍机器翻译和中医古籍翻译的研究现状及发展趋势,关注语料匮乏时可采用的数据增强方法。然后,采集社交媒体用户关于中医古籍翻译的讨论文本,利用LDA主题模型和百度AI情感倾向分析进行主题识别和情感分析,深入分析用户对中医古籍翻译认知的现状和对翻译工作的主要关注点。其次,运用比较研究法,对比分析mT5、mBART和mRASP等多个预训练模型在中医古籍的古英、古现和现英三种翻译场景下的翻译性能。最后,运用回译的数据增强方法,进一步提升模型的翻译性能。
结果(1)社交媒体用户对中医古籍翻译的讨论可归纳出5个主题,分别是:中医文化与理论表达、中医知识的跨文化传播、中医古籍翻译准则与策略、中医古籍翻译全球化和中医临床实践与研究成果。情感分析结果显示:社交媒体中有56%的用户讨论对中医古籍翻译工作持积极情感,有43%的用户讨论表现为消极情感,仅有1%的用户讨论是对中医古籍翻译持中性情感。综合主题识别和情感分析结果,用户对中医古籍翻译工作的主要关注体现在四个方面:①中医古籍翻译可以促进中华文化传承和传播;②现有翻译方式难以准确传达文化内涵;③缺乏统一的翻译标准;④缺少有效的翻译工具。
(2)构建中医古籍古现英平行语料,在多语言预训练模型的基础上进行微调训练,可以在古英(lzh-en)、现英(zh-en)和古现(lzh-zh)的翻译场景中展现优异性能。对比分析发现:在古英和现英的翻译场景中,多语言预训练模型的微调性能呈现的层次性排序结果完全一致:mBART-large-cc25<mRASP<mT5-large<mBART-large-50。mBART-large-50模型在古英翻译的BLEU值达29.23,在现英翻译场景中的BLEU值达32.06。在古现的翻译场景中,各模型的性能表现顺序为:mBART-large-cc25<mBART-large-50<mT5-large<mRASP。mRASP模型在古现翻译场景中的BLEU值达23.65。
(3)运用并对比三种回译的数据增强方法,进一步提升基于mBART-large-50和mRASP预训练模型微调得到的模型在三种翻译场景中的性能。在古英(lzh-en)的翻译实验中,在基于反向翻译模型的回译策略下BLEU值提高了 1.53%,运用火山翻译的回译使得BLEU值降低了 0.1%,基于ChatGPT-4的回译策略实现BLEU值0.61%的提升。在现英(zh-en)的翻译实验中,基于反向翻译模型的回译策略使BLEU值增加1.03%,基于火山翻译的回译策略实现0.53%的BLEU值提升,基于ChatGPT-4的回译策略使BLEU值提高0.9%。在古现(lzh-zh)翻译场景下的回译实验中,基于反向翻译模型的回译策略使BLEU值提升1.1%,基于火山翻译的回译策略使BLEU值下降1.02%,基于ChatGPT-4的回译策略实现BLEU评分增加0.52%。
结论(1)中医古籍翻译的工作进展迅速,但尚存在一定不足:在国家大力发展中医药和积极推进新时代古籍翻译工作的背景下,中医古籍翻译工作向全球化发展,很多经典古籍被翻译为多种国家的语言。然而,依然存在着中医术语翻译标准不一、译名不统一的问题,使得译本的翻译质量参差不齐,严重制约了中医在国际上的传播和使用。
(2)预训练模型在中医古籍翻译中具有较高的有效性:构建高性能的机器翻译模型是实现中医古籍自动翻译的核心,研究表明以mBART-large-50和mRASP预训练模型为基础微调训练得到的mBART-lzh-en、mBART-zh-en和mRASP-lzh-zh模型分别在中医古籍的古英、现英和古现翻译场景中表现优异,与市场上的在线翻译平台相比也有一定优越性。
(3)基于反向翻译模型回译的数据增强方法领域适应性较强:基于反向翻译模型回译的数据增强方法在三种翻译场景中均实现BLEU值1.0%以上的提升,表明这一回译策略更适用于中医古籍平行语料的生成,具有更高的领域适应性。此外,利用ChatGPT-4回译的数据增强方法在提升机器翻译性能上也有一定的有效性。
{URL}: https://link.cnki.net/doi/10.27253/d.cnki.gnjzu.2024.000073
{DOI}: 10.27253/d.cnki.gnjzu.2024.000073
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于神经网络的中文命名实体识别方法研究及应用
{Author}: 刘锦彤
{Tertiary Author}: 李卫军;王生国
{Publisher}: 北方民族大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 实体识别;深度学习;自然语言处理;机器学习
{Abstract}: 命名实体识别是一项重要的自然语言处理技术,主要任务是识别文本中人名、地名和机构名等实体的信息,是信息检索、推荐系统、链接预测和知识补全等众多自然语言处理任务的一项重要任务。目前,命名实体识别存在两个问题。第一,粗粒度类别无法满足深层次的自然语言处理的需求,需要细粒度的实体类别识别来更好地理解文本的深层含义;第二,自然文本中实体之间存在嵌套关系和层次关系,当实体边界较模糊时存在边界识别错位的问题,识别这些嵌套实体可以更深层次的理解和分析自然语言。本文结合神经网络模型研究细粒度的命名实体识别和嵌套命名实体识别,主要的工作如下:
1)基于BILTAR的细粒度实体识别研究构建了中文细粒度实体识别模型ABILTAR,该模型包含BERT、特征提取模块BILTAR和旋转位置编码Ro PE等技术。选用CLUENER2020、Weibo和Resume三个中文细粒度实体识别数据集作为实验数据集。与多个前沿模型做了对比实验,实验结果表明ABILTAR模型比当前流行的实体识别模型表现更优。针对ABILTAR的子模块在CLUENER2020和Weibo数据集上做了18组消融实验,实验结果表明ABILTAR的各个子模块对模型性能都有提升效果。该项研究解决了粗粒度类别的信息缺陷问题,提出了更优的特征提取层。
2)基于IDCNNLR的嵌套实体识别研究构建了中文嵌套实体识别模型AIDA。AIDA包含IDCNNLR特征提取模块、多位置自注意力机制和全局指针模块。选用CMe EE和ACRE2005嵌套实体识别数据集来评估AIDA的嵌套实体识别能力,并在CMe EE和CLUENER2020数据集做了对比实验和消融实验。对比实验结果表明AIDA比当前流行的实体识别模型有更优的性能。指定删去一个或多项技术做了20组消融实验,消融实验结果表明AIDA的各个子模块均能提升模型性能。该项研究提高了实体识别模型的嵌套实体识别能力,通过多个技术优化来改善模型性能,消除了实体边界模糊问题。
3)设计并实现了一个实体识别系统。基于上面两个实体识别模型,构建了电子病历实体识别系统,主要功能用于患者信息查询、电子病历识别和模型重训练。医护人员可以通过患者ID直接检索到患者个人信息和就诊信息,加快了病人就诊速度。用户可以选择需要的模型做病历实体识别。该系统通过多个模块来实现病历的查阅和分析功能,能够根据新的医疗信息优化系统,提高了医护人员的病历处理速度,加快了医疗机构的工作效率。
{URL}: https://link.cnki.net/doi/10.27754/d.cnki.gbfmz.2024.000080
{DOI}: 10.27754/d.cnki.gbfmz.2024.000080
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于大模型的逻辑编排应用与测试用例生成技术研究
{Author}: 江伟维
{Tertiary Author}: 夏莹杰;蒋萌青
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 大模型;自然语言需求描述;逻辑编排;测试用例
{Abstract}: 随着社会智能化和数字化的快速发展,对软件开发的需求不断增加。为满足这一需求,越来越多的低代码平台推出了可视化逻辑编排工具,使得通过拖拽组件即可快速搭建前端页面和后端接口服务成为可能。然而,尽管可视化编排降低了开发门槛,仍需要使用者具备一定的开发技能,尤其是在处理复杂的业务逻辑和应对个性化需求时。开发者通常需具备编程的基础知识,比如理解诸如变量、条件语句、循环等基本编程概念,这些要求进一步提高了该工具的使用门槛。基于这一现状,本文做了如下的工程实践,并取得了一定的成果:(1)设计了基于零样本三阶段(Zero Shot Three Stage Prompt,ZSTS)的逻辑编排应用生成方法。为更好发挥大型语言模型(Large Language Model,LLM)的理解与生成能力,本文采用逻辑节点提取、参数提取和应用生成三个阶段的方法,使得在缺乏大量样本的情况下,能够智能地将自然语言功能需求描述准确转化为具体的逻辑编排应用(Logic Flow Application,LFA)。(2)提出了基于语义模型与K均值聚类的逻辑编排应用数据优化方案。为了提高生成应用的准确率,通过反复输入相同的需求,本文获取了多组各异的输出数据。根据逻辑编排的结构特异性选取初始数据点,然后通过K聚类算法对应用数据进行聚合,提取最准确的应用数据。(3)提出了基于多路径有向图的逻辑编排测试用例自动生成方法。为了对逻辑编排应用更好地进行测试,通过进行工程化分析,本文识别了所有与逻辑有关的执行路径,针对每个路径,本文构造了合理的prompt利用LLM生成全面而合理的测试用例。最后,组合所有的路径的测试用例,作为完整而实用的LFA测试用例集。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2024.000499
{DOI}: 10.27461/d.cnki.gzjdx.2024.000499
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 使用深度神经网络对自然语言文本进行因果关系挖掘
{Author}: Wajid Ali
{Tertiary Author}: 左万利
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 因果关系;因果关系挖掘;多层次关系网络;因果关系分类;BERT;关系分类
{Abstract}: 因果关系挖掘是自然语言理解中一项极具挑战性但又非常关键的任务。它在一些日常生活应用中发挥着重要作用,如决策、药物不良反应、商业风险管理、问题解答、未来事件预测、情景生成、信息检索、医学文本挖掘、文本蕴含和话语理解等。为了在正式数据集(来自书籍、期刊、故事和报纸的数据)和非正式数据集(网络语料库)中处理这项任务,已经开展了许多研究,从传统的基于特征的机器学习(ML)方法开始,到目前的深度学习(DL)方法。大多数机器学习方法都使用自动化技术,通过使用带有标签数据集的大型语料库进行复杂的特征工程来创建特征。这样就能自动挖掘显性因果关系,而忽略复杂的隐性和模糊因果关系。利用自动特征工程技术,深度学习已成功应用于因果关系挖掘,并在展示源句中隐藏的因果知识方面表现出色。然而,以往的研究大多依赖于传统的机器技术,这些技术通常成本低、性能差。尽管取得了重大进展和成就,但由于以下问题,目前的方法效果不佳。首先,大多数机器学习和深度学习尝试都是自动化的,并且只关注显性因果关系,忽略了隐性和模糊因果关系,而这种因果关系通常存在于网络语料库中。其次,它们旨在确定句子是否存在因果关系,而很少关注提取因果关系及其方向。第三,大多数方法都是针对特定领域的,依赖于小型数据集,而忽略了非正式的网络语料库。第四,大多数方法缺乏多层次的特征网络,而这正是有效的关系推理所必需的。因此,这些方法可能会导致性能下降。为了解决从独立于领域的大型网络语料库中提取隐含和模糊因果关系的难题,本论文采用了复杂的方法,利用高效的多层次深度神经网络、上下文词扩展方法和多通道知识导向深度神经网络学习隐含因果关系的丰富上下文和语义信息。本论文的主要目标是解决从网络语料库中提取大量隐含的、模糊的、与领域无关的因果关系的问题。网络语料库可以包含各种数据源,如在线司机、传感器、在线交易、电话、数据存储、社交媒体平台和云计算服务。本论文的主要工作和贡献如下:为了解决简单的传统方法、机器学习方法和单层次深度神经方法无法挖掘网络语料中大量隐含的、模糊的、与领域无关的因果关系的问题。我们提出了一种新颖的深度多特征BERT+MFN(来自变换器的双向编码器表示+多层次特征网络模型,无需特征工程即可解决标记(词)和事件(段)级别的隐含因果关系问题。为了克服标记级特征工程的局限性,我们使用BERT来整合基本特征,以捕捉文本中的长程依赖关系和局部语境。这就产生了词级语义表征。为了处理分段级特征,我们使用独特的MFN(TC-KN、bi-LSTM和RN)来收集分段级基本特征,并采用一种新颖的方法从知识库中自动构建新颖的卷积词过滤器,而不是训练有素的典型卷积过滤器。BERT+MFN具有识别因果关系的高效推理能力。在公开数据集上的实验结果表明,所提出的模型在各种评估指标上都优于基线方法。对于许多传统的ML和DL方法来说,因果关系挖掘一直是一项具有挑战性的任务,因为在没有任何明确信号的情况下,因果关系通常以非正式、隐含和模糊的方式表达。要挖掘这种因果关系,需要多层次的DL网络。在本文中,我们提出了一种名为CMCE+BK(通过候选事件扩展和先验背景知识进行因果关系挖掘)的独特方法,它结合了两个模块来进行高效的因果关系挖掘。我们的模块主要用于挖掘源句中的扩展句段/事件和连接词级元素,其中扩展句段和连接词可以通过使用从上下文词库中提取的因果术语来描述候选句段和连接词的扩展性质。先验BK(背景知识)模块的使用进一步强化了句段和连接词层面因果关系的关键特征,从而提高了模型感知句子中因果联系BK的能力。在可公开访问的AltLexes语料库中进行的实验和消解研究表明,CMCE+BK需要一定程度的上下文词和多层次背景知识扩展,才能实现优于前沿因果关系和文本挖掘技术的性能。为了解决网络语料库中的隐含因果关系问题,我们提出了一种创新的MCKN(多列知识导向神经网络)模型。所提出的MCKN的独特之处在于,它首次使用了多个KC(知识导向通道)和一种新颖的词语过滤技术,从而大大降低了模型的维度。这是首次尝试使用卷积"wf",而不是预定义的卷积滤波器,来锁定目标句子中的分段和连接层次特征。这项工作的独特之处在于,它利用网络语料库来定位句子中的因果关系,其中包括噪声数据和与领域无关的数据。在AltLexes(另类词法化)数据集上的实验结果表明,MCKN在不同指标上都取得了最佳性能。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.007740
{DOI}: 10.27162/d.cnki.gjlin.2023.007740
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于司法案件要素信息处理的类案检索技术研究
{Author}: 胡伟凤
{Tertiary Author}: 赵佳;李玉军
{Publisher}: 山东大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 关键信息提取;命名实体识别;关系分类;类案检索
{Abstract}: 在我国的司法体制中,法官基于判案经验及知识体系具有一定的自由裁量权,由此产生了裁判尺度不统一、类案不同判、量刑不规范等问题。为总结审判经验、统一裁判尺度,最高人民法院先后确立了类案检索的案例指导制度,要求各级法院对类似案件类似审判。此外,随着信息技术的发展,视频监控已成为社会公安安全的重要组成部分,在司法案件处理过程中,视频监控信息可以最真实地记录案情经过及矛盾点,是司法案件审理人员做出司法裁决的重要支撑。针对我国最高人民法院提出的类案检索要求,司法工作人员在实际工作中面临以下问题:(1)需要快速熟悉权威性的案例数据库,例如裁判文书网等;(2)现有检索工具操作复杂,检索维度少;(3)针对海量的检索案件库,大部分现有检索工具缺少类案相似度展示,司法工作人员需花费大量人工时来确定案例的相似性;(4)案件处理过程中的视听资料往往时长较长且场景复杂,如何从中筛选出可以作为案件支撑的证据信息成为一个难题。类案检索技术是实现智能司法类案检索系统的重要核心技术,其以实现司法过程中类案类判为目标,通过发现与案情相类似的裁判文书为法官判案提供参考,对推动司法领域智能化建设有着极其重要的作用。同时,查询式视频摘要技术可支撑个性化摘要检索功能,通过设定检索条件、缩小排查范围,可大大降低案件审判支撑数据的排查时间。本文围绕司法领域类案检索任务,结合自然语言处理技术、信息检索技术、深度学习方法,研究了司法案件要素提取技术、类案检索技术,并构建了司法类案检索系统,对司法审判具有重要的实际应用价值。本文主要研究内容总结如下:(1)针对现有基于词汇增强的命名实体识别模型中,仅考虑实体边界识别能力的增强,忽略了词语间的关联关系对实体类别的影响,本文设计了融合字级句法特征的命名实体识别模型PasLEBERT。在加强实体边界识别能力的基础上,补充词语间带有方向信息的句法结构关系信息;通过基于张量的特征融合方法挖掘字级、词语级、句子级特征间的关联关系,实现信息互补的同时减少冗余信息带来的噪声影响,进而提升司法案件要素信息提取的准确率。在四个通用中文命名实体识别数据集和一个自定义数据集对该方法进行了实验验证,结果表明,该方法与ACL发布的词汇增强模型LEBERT相比,F1值提高0.43%～2%,与字形结构增强模型MECT相比,F1值提高0.89%～8.86%。(2)针对中文文本表述中,不同的实体类别因为同属于相同语义关系因而表述相似,进而导致实体关系类别易混淆的问题,提出了一种融合词性区分度信息的关系分类方法Dic-Transformer,设计了基于词性加强的区分度信息来提高模型对统一语义实体对下的两个不同方向的实体关系的区分能力;采用更高效的Transformer模型对输入语句的语法语义信息进行编码,增强语义编码模块的上下文感知能力;设计了基于注意力机制的特征融合模块来融合语义信息与关系区分信息,使得模型既保留融合特征的个性信息又捕获融合特征的交互联系;采用结合交叉熵函数与Max-Margin函数的模型优化方法,使模型训练过程中既获得标准类别信息,又最大化正确预测概率,从而加强模型对网络状态的学习感知能力,增加关系分类的准确率。基于经典关系分类数据集SemEval-2010 Task 8进行了实验验证,F1值达到86.2%。(3)针对司法案件裁判文书特殊的文本结构及长文本特征,提出了基于司法案件要素信息的类案检索模型BERT-LF。通过聚合段落级语义交互来推断整个法律案例的相似性,并基于BERT的文本编码方法对查询和候选段落进行语义编码,保证模型语义学习能力的同时解决司法案件的长文本问题;将对案件判决具有重要影响的司法案件要素进行识别、扩展,通过案件事实要素、文档主题和基础文本语义信息的深度融合使得文档表示更适合法律场景;基于卷积神经网络和注意机制,不仅对段落中具有法律语义的位置信息进行编码,而且对段落之间的司法案件要素进行逻辑判断和强化,进而提升类案检索的准确率。在中国法律体系案件检索数据集LeCaRD上对该方法进行了实验验证,与IJCAI发布的先进类案检索模型BERT-PLI相比,在准确性指标P@5、P@10、MAP上分别高出17%、9%和15.6%。在匹配度排名指标NDCG@10、NDCG@20、NDCG@30 上分别高出 7.3%、5.7%和 2.8%。(4)针对司法工作人员在类案检索过程中因海量司法案件数据导致案件检索及类案评判效率低下的的问题,采用MVT软件架构设计思想及B/S架构模式,基于Django web开发框架及开源solr搜索引擎框架,对本研究提出的类案检索算法进行集成,设计并实现了类案检索系统。倒排索引技术、分页检索机制及离线、在线相结合的计算策略,为系统的响应时间性能指标提供了保证,使得系统在百万级长文本数据检索任务上响应时间达到ms级,类案检索响应时间为<6s。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.007439
{DOI}: 10.27272/d.cnki.gshdu.2023.007439
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 中文纠错文本的测试用例生成方法研究
{Author}: 冯程皓
{Tertiary Author}: 谢振平
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 中文文本纠错;测试用例生成;测试用例优化;用户选择;多用户需求
{Abstract}: 随着最新自然语言处理技术的发展,智能化文本写作与纠错润色技术正在进入可实用阶段,但如何完整地评价文本特别是中文文本的纠错性能,目前的相关研究还非常不成熟。本论文尝试从中文纠错文本测试用例构建的角度展开研究,进一步发展更为智能化的中文纠错文本测试用例生成方法。具体地,以生成更为全面的、重要的测试用例文本为目标,研究提出了基于需求选择的、面向多用户个性化要求的中文纠错文本测试用例生成方法,相应地,本论文主要工作内容及创新点如下:
1、针对中文文本纠错软件在回归测试中的性能测试任务,通过对中文纠错文本测试用例独特性的分析,以面向多用户和自动化为研究重心,设计了一种基于需求选择的、面向多用户个性化的中文纠错文本测试用例自动化生成方法。为了实现面向多用户个性化需求的目标,避免因重复生成字词表而造成资源浪费的情况,新方法中的字词表将在生成后实现永久存储,并且用户可以在使用新方法时自定义错误最小间隔和测试用例集的大小。进一步,新方法会根据用户自定义的数据生成两种测试用例:存在错误文本、无错误文本,最后对存在错误文本进行错误数量的随机生成、错误种类的随机选择、错误位置的随机指定,实现测试用例集的自动化生成。实验结果表明:新方法能够快速生成万级甚至百万级的测试用例集,不同中文文本纠错软件对于测试用例集的纠错精度均小于官方公布水平、均处于较低水平,测试用例集能够在性能测试中更大程度上揭露软件缺陷,新方法具备有效性和通用性。
2、随着中文文本纠错技术的进步,为了实现对测试用例的进一步优化,以应对中文文本纠错软件快速迭代而导致的中文纠错文本测试用例膨胀的情况,设计了一种基于需求选择的、面向多用户个性化需求的中文纠错文本测试用例优化生成方法。新方法包括三种以不同角度实现降低测试成本目标的优化策略,包括测试用例选择、测试用例优先级排序、测试用例最小化。此外,新方法中还提出了两种可供用户选择的测试用例评判标准,包括错误数量密度、错误种类密度。实验结果表明:测试用例选择方法面对不同需求都能满足用户的期望值;不同测试用例通过优先级排序后,相比于其自身排序之前,在不同测试用例评判标准下的各个相同时间段内均能有效提高测试效率;测试用例最小化方法能够保证在性能测试效果不变的情况下生成最小的测试用例子集,且测试用例集的缩减效果明显。
综合地,基于需求选择的、面向多用户个性化需求的中文纠错文本测试用例生成方法对中文文本纠错软件的测试领域具有积极意义:(1)新方法是一种有效的生成方法,一定程度上填补了中文纠错文本测试用例生成方法的空白。(2)新方法是一套完整的测试用例生成及优化方法,不仅考虑到了测试用例从无到有的初始生成方面,也考虑到了测试用例后续的多角度优化,更进一步考虑到了测试用例的不同需求场景,增加了该方法的多用户需求满足性,更具实用价值。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2024.000027
{DOI}: 10.27169/d.cnki.gwqgu.2024.000027
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《伤寒杂病论》知识抽取及知识图谱构建研究
{Author}: 闻沫言
{Tertiary Author}: 马月坤
{Publisher}: 华北理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;联合抽取;实体嵌套;关系重叠;伤寒杂病论
{Abstract}: 《伤寒杂病论》是中国古代医学的重要代表之一,它不仅是中医学的宝库,也是中华文化的重要组成部分,对中医学研究、学习和应用都有着重要的意义。通过应用知识图谱技术来构建《伤寒杂病论》的知识图谱,可以更好地挖掘和整合其中的知识信息,提高中医诊疗的精准性和效果。在对《伤寒杂病论》研究过程中发现文本中包含大量的实体嵌套和关系重叠问题,为了解决上述问题并完成知识图谱构建,论文做了以下两方面的研究:
1)针对《伤寒杂病论》文本中大量关系重叠和实体嵌套问题,提出了一种新的实体关系联合抽取模型框架Cas Rel-Bert-Bilstm-Attention,该模型框架是基于Cas Rel方法、深度学习、指针标注方法相结合的,包括头实体识别模块、关系和尾实体识别模块。头实体识别模块利用Bert-Bilstm-Attention模型和指针级联标注相结合,确定头实体的起始位置和终止位置以及头实体的类别,解决实体嵌套问题。关系和尾实体识别模块Bilstm-Attention模型和指针级联标注相结合,确定关系和尾实体的起始位置和终止位置以及对应的类别,解决关系重叠问题。得到包含头实体-关系-尾实体的三元组,为后续知识图谱构建提供数据。实验结果表明,在准确率、召回率以及F1值上分别为80.7%、78.8%、79.4%,验证了模型在《伤寒杂病论》的实体关系联合抽取上有较好的效果。
2)针对《伤寒杂病论》文本中包含的知识内容,构建了一个知识体系,其中包括:病名、方剂、药物、证候、症状、脉象,以及这些知识点同知识点之间的关系。依据此体系填充实体及实体间的关系,存入Neo4j图数据库,完成《伤寒杂病论》的知识图谱构建。该知识图谱中包含2154个实体以及4584条关系。实现《伤寒杂病论》的知识图谱的结构化和可视化。
图35幅;表10个;参55篇。
{URL}: https://link.cnki.net/doi/10.27108/d.cnki.ghelu.2023.000070
{DOI}: 10.27108/d.cnki.ghelu.2023.000070
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的情感分类研究
{Author}: 李波
{Tertiary Author}: 李胜旺;丁保忠
{Publisher}: 河北科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;情感分类;方面级情感分类;深度学习;图卷积网络
{Abstract}: 近年来,情感分类在自然语言处理领域中备受关注。作为一种细粒度的情感分析子任务,方面级情感分类在社交评论分析、预警监控等领域得到了广泛应用。方面级情感分类的目标是给定方面词来预测其情感信息。已有的深度学习方法如卷积神经网络(CNN)和长短时记忆网络(LSTM),已经对此进行了探索。之后,引入图神经网络为方面级情感分类提供了新的可能性。方面级情感分类需要更精细化的建模,但现有的方法往往无法很好地提取面向方面的特征。为此,本文基于深度学习方法,设计了两个新的情感分类模型。主要的贡献如下:
针对传统的神经网络结构往往不能充分突显方面词重要性的不足,本文提出了一种基于多头注意力和图卷积的模型MHGCN。该模型能够独立地抽取方面词,并对句子上下文和方面词分别建模。通过引入注意力机制,能够有效地融合上下文与方面词的表示,从而为情感分类提供更为丰富的特征。实验结果显示,在Sem Eval2014的Lap14、Rest14和Twitter数据集上,该模型相对于现有的最高基准模型,准确率分别提高了0.31%、0.63%和1.01%。
然而,MHGCN模型中对上下文和方面词的独立建模可能会增加计算复杂度,从而降低模型效率。为改善这一状况,本文进一步提出了一种基于交互注意力和图注意力方法的IHGCN模型。该模型利用多头注意力构建多通道的图卷积,以更好地突显上下文和方面之间的联系。随后,通过掩码层获得方面词的特征,再与上下文表示进行交互式的注意力计算,以识别情感极性。实验结果显示,在Sem Eval2014的Lap14、Rest14和Twitter数据集上,该模型与最优的模型对比,准确率分别提高了1.91%、2.92%和1.47%。
最后,实现情感分类系统的可视化,对系统整体加以分析,并展示系统执行的流程。
{URL}: https://link.cnki.net/doi/10.27107/d.cnki.ghbku.2023.000847
{DOI}: 10.27107/d.cnki.ghbku.2023.000847
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向计算思维培养的高中信息技术分层教学模式研究
{Author}: 姜焰姣
{Tertiary Author}: 邓晖;张罗丹
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算思维;分层教学;高中信息技术
{Abstract}: 计算思维作为当代信息化社会人类必不可少的一种思维能力之一,其重要程度甚至能上升到影响一个国家未来的创造力与竞争力水平。所以近几年来,学生计算思维的培养和提升方面的研究成为各国教育界的研究热点,上至国家发布的一系列教育改革策略,下至个人的理论实践研究。早在2018年,我国就颁布了《高中信息技术课程标准(2017版)》,将计算思维列为高中信息技术学科四大核心素养之一,且在《高中信息技术课程标准(2020修订版)》中再次对计算思维的培养进行强调,我国的这一系列举动更加说明了计算思维的重要性和必要性。而由于每个学生之间的思维能力有所差异,分层教学模式也是多年来教育学者们老生常谈的议题,并且该模式基本趋近成熟。因此,本研究将借助分层教学模式,以培养学生计算思维能力为核心,对分层教学模式进行再思考与创新,构建面向计算思维能力为培养目标的分层教学模式,为相关的教学研究与实践提供一定的理论价值与实践意义。
本研究主要采用文献研究法,准实验研究法和调查研究法。首先,通过文献研究法了解常见的分层教学、计算思维及以计算思维能力培养为目标的分层教学模式的概念和研究现状,然后重新理解分层教学、计算思维两大核心概念,明确计算思维的三种思维能力和两种意识态度两大方面的培养目标。其次分析面向计算思维培养的分层教学模式的构建依据,可行性以及构建原则,将分层教学过程与计算思维的活动过程相结合,构建以计算思维五个思维能力和两个意识态度的提升为目标的分层教学模式。第三,采用准实验研究法将构建好的面向计算思维培养的分层教学模式应用于教学实践,即以《算法与程序实现》部分内容为例,结合本研究的模式,进行教学设计,然后选取某校高一年级两个班进行实验。在实验前,先发放程序设计测试题,计算思维能力和态度量表对学生进行前测,随后开展教学,实验结束后再次进行相关的测试。最后,采用调查研究法,搜集分析实验前后的数据,为面向计算思维培养的分层教学模式是否能有效提升计算思维能力和创新合作意识提供实验依据。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.004324
{DOI}: 10.27684/d.cnki.gxndx.2023.004324
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于统一视觉与语言表征学习的多模态智能研究
{Author}: 黄羽盼
{Tertiary Author}: 卢宇彤
{Publisher}: 中山大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 视觉-语言表征学习;多模态智能;预训练模型;掩码视觉建模;图文生成
{Abstract}: 随着智能设备、社交媒体和电子商务的蓬勃发展,图像和文本数据的快速增长带来了对多模态智能技术的新需求。在计算机视觉与自然语言处理交叉领域,多模态智能技术致力于协同处理视觉与语言信息,以实现信息的高效理解、创造与应用。这项技术不仅提高了生产效率,也激发了创造力,并对社会产生了广泛的价值。利用多源数据和任务的通用技术,能够挖掘多模态数据间的内在联系,从而提升模型在各种任务中的性能和通用性。
本文聚焦于视觉-语言表征学习,旨在提升多模态智能模型的性能与通用性。然而,在这一领域中,视觉与语言信息间的结构和属性差异带来了显著的挑战。在多模态预训练领域,现有模型在图像表征提取与跨模态表征学习阶段分离,同时也缺乏有效的掩码视觉建模方法,或是图像和文本的掩码建模方式差异较大。这些问题导致视觉表征的学习有限,跨模态对齐的学习难度加大,从而影响模型在下游任务中的性能。此外,多模态应用领域中的图文双向生成模型往往采用特定任务的设计框架并进行独立训练,而多模态对话模型则通常无法支持多图文交互,这限制了模型的应用场景,降低了多模态智能技术的通用性。为应对这些挑战,本研究基于统一的视觉与语言表征学习,从以下四个方面展开,旨在缩小模态间的差异并提升多模态智能模型的性能和通用性:
1、针对预训练模型图像表征提取与视觉-语言表征学习阶段分离和缺乏有效地掩码视觉建模的问题,本文提出了一种基于视觉语义标记的端到端预训练方法。该方法联合抽取基于网格的卷积视觉特征,并优化视觉-语言表征。通过将图片转换为视觉语义标记进行掩码视觉建模,直接从自然图像和文本数据中提取视觉与语言的联合表征,有效捕捉两者间的复杂关联性,从而提升模型性能。
2、针对预训练模型中视觉与语言表征及优化目标不统一引起的图像和文本的掩码建模方式差异较大的问题,本文提出了统一视觉与语言掩码建模的预训练方法。该方法基于离散掩码标记统一视觉-语言预训练目标,并采用自注意力机制的表征方式。这一方法不仅减少了跨模态表征学习的差异,提升了模型性能,还适应于以文本或图像为主的多种文档任务,并被有效拓展到了中文数据集应用于中文任务。
3、针对图文双向生成模型的结构不统一的问题,本文提出了一种统一的图文双向生成模型。该模型基于Transformer架构,将图像和文本统一表示为标记序列,实现跨模态双向生成。此外,引入了两级粒度表征和序列级别训练方法,旨在提升双向通用模型的性能。这一方法简化了任务特定模型的设计,优化了存储利用率,并显著提升了模型通用性。该统一图文双向生成模型还被拓展为一个能够生成多样化图像描述和丰富图像内容的双向图像-文本统一框架,显著提升了生成的多样性。
4、针对图文交互方式单一和数据集形式局限的问题,本文提出了拓展图文交互方式和构建新型数据集的方法。这种方法旨在训练支持多种图文交互的对话模型,提升了模型在处理图文输入时的交互灵活性和通用性。本文构建了一个结合细粒度图像和文本交互的对话数据集,并基于此数据集训练了一个多模态开放式对话指令跟随模型。此外,本文还构建了一个由GPT-4协助的基准测试集,用以定量评估模型在处理多轮图文对话的能力。这一方法不仅适应于复杂的图文交互场景,还具备高度的灵活性和可扩展性。
本文的四个部分相互关联,旨在统一视觉与语言的表征学习,共同推进了多模态智能领域的发展和创新。本文工作不仅增强了多模态模型理解自然图像和文档图像相关任务的性能,也扩展了模型在图文生成和多模态对话应用中的通用性。本文研究成果均已开源,为后续研究和实际应用提供了参考和支持。
{URL}: https://link.cnki.net/doi/10.27664/d.cnki.gzsdu.2023.000017
{DOI}: 10.27664/d.cnki.gzsdu.2023.000017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于小样本学习的关系分类研究
{Author}: 李宜兵
{Tertiary Author}: 马祖长
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 小样本学习;关系分类;迁移学习;编码器;深度学习;知识图谱;意图识别;自然语言处理
{Abstract}: 关系分类是自然语言处理领域中的重要任务,是文本结构化的基础。有监督的关系分类需要大量的标注数据,然而在很多领域,标注数据稀少,使得有监督的分类变得困难。近年来,为了解决标注数据稀少的分类问题,小样本学习方法被提出,并且成为研究热点。小样本学习关系分类主要目标是在学习一定关系的数据后,在新的关系上只需要少量的标注数据,从而实现分类任务。然而,现有的模型泛化能力仍然有待于进一步提高。因此,找出影响模型泛化能力的重要因素,提升分类的准确率具有重要意义。本文针对小样本学习关系分类进行了研究,提出了一系列新方法。第三章提出了强化实体对权重的句子编码器、动态生成类原型及混淆损失函数方法。第四章提出了强化实体及依从词权重的句子编码器,自适应生成类原型和查询句子表示方法,以及一种新的网络结构。第五章提出了融合关系描述词及其自注意力方法。实验结果表明这些方法提升了模型分类的准确率。第六章基于中文医疗信息处理领域应用场景,设计了小样本学习的意图识别模型。实验结果表明所提理论方法在实际应用场景的有效性。本文主要贡献如下:
1.第三章提出了 HACLF小样本关系分类模型。首先,模型设计了一种强化实体对权重的句子编码器。原型网络的小样本学习关系分类模型没有考虑到实体对的重要性,本文认为小样本学习关系分类中实体具有重要作用。为此,基于BERT模型进行了改进,设计了一个词级注意力机制,强化了实体词语在句子编码中的权重,提出了一个新的句子编码器BERTFE。其次,模型中使用了动态生成类原型的方法。原型网络中需要生成一个类原型,它是根据支持集句子静态生成了类原型,支持集句子的权重是一样。类原型的表示准确与否,直接关系到模型分类的准确率。本文认为并非支持集中的所有句子贡献相等,与查询句子相似的句子应该分配更多的权重。因此,设计了一个句子级别注意力机制,动态的生成类原型。第三,模型设计了一个混淆损失函数。一个句子中的实体之间可能存在一个混淆的关系。混淆关系和真实的关系很相似,导致模型很难区分它们。为了区别真实关系和混淆关系,基于KL散度理论设计了一个损失函数,帮助模型在训练过程中尽可能区分这两种关系,从而提升模型的准确率。实验结果和消融研究证明所提方法是有效的。
2.第四章提出HAFN小样本关系分类模型。首先,模型设计了一种强化实体及依存词权重的句子编码器。小样本学习一个主要问题是数据不足,数据增强是常见的方法。然而,在引入外部数据源进行数据增强的同时也可能会引入噪音。如何在不引入外部数据源情况下,充分挖掘已有的样本信息,对提高模型的泛化性具有重要意义。实体在关系分类中具有重要的作用,那么实体的依存词也可能具有一定的作用。为了充分挖掘句子的语义特征,对句子进行句法依存分析,找出实体的依存词,基于BERT模型进行改进,设计了词级注意力机制,强化了实体词及其依存词在句子编码中的权重,构造了一个新的句子编码器FDBERT。其次,模型使用一种自适应的类原型和查询句子表示方法。查询句子与真实的类原型距离越近,与其他类原型距离越远,越有利于模型对关系的分类。为此,设计了混合注意力机制,根据查询句子与支持集句子相似性,动态生成类原型,再根据查询句子与类原型相似性生成新的查询句子表示。第三,模型设计了新的融合网络,提高模型收敛速度。原型网络中采用欧式距离的方式判断查询句子的类别,由于句子维度高,导致计算量大,模型收敛速度慢。设计了一个融合网络替代欧式距离方法,在确保模型精度不减的情况下,模型训练的收敛速度得到了很大提升。在两个公开数据集上分别进行了实验,结果表明了所提的HAFN模型分类准确率较高,模型训练的收敛速度大大加快。
3.第五章提出FRLA小样本关系分类模型。首先,模型融合关系描述词方法。小样本学习关系分类中的N-way-1-shot任务,支持集句子只有一个,语义信息不足,导致类原型不能准确的表示。通过融合的实体及其依存词语的信息后仍然有限,模型准确率仍然有提高的空间。为此,提出了融合关系描述词语与支持集中的句子组成新的句子方法,通过关系描述词和支持集中的句子联合生成了一个新的句子代替原有的支持集中的句子。其次,模型使用了自注意力机制方法。为了更加突出关系描述词的作用,提出了自注意力机制,提高了类原型表示的准确性。实验结果证明了所提方法的有效性。其中在HuffPost数据集上的两个任务达到了最好的水平。
4.第六章设计了一个小样本学习的用户意图识别模型。为了验证本文提出的相关小样本学习理论实际应用效果,将其应用在中文医疗信息处理领域。首先,根据CBLUE发布的医疗搜索检索词意图数据集,使用本文所提的相关小样本学习理论,训练了一个小样本学习关系分类模型FSLRCQIC,用于用户意图识别。其次,构建了一个骨科医疗的知识图谱问答系统,FSLRCQIC模型迁移到人工标注的少量意图数据上,实现了用户问句的意图识别功能。其中,每个意图类别人工只标注了 5个样本。实验结果验证了所提小样本学习方法在实际应用中的有效性。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.002180
{DOI}: 10.27517/d.cnki.gzkju.2023.002180
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向不同场景的文件级软件缺陷定位研究
{Author}: 祝子烨
{Tertiary Author}: 李云
{Publisher}: 南京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 软件工程;软件缺陷定位;缺陷报告;深度学习;表示学习
{Abstract}: 随着信息化时代的发展,大量的智能化软件已出现在人类社会的各个领域。这些智能化软件不断渗入并改善人们的日常生活,但软件中的缺陷也会给人们造成难以预料的危害,轻则影响用户体验,重则造成重大经济损失甚至人员伤亡。为了更高效地修复处理这些软件缺陷,从复杂的软件程序中快速定位到引发缺陷的源代码文件是关键且重要的一步,文件级的软件缺陷定位任务为此目标而诞生。本文主要研究基于缺陷报告的文件级软件缺陷定位任务,该任务旨在依据缺陷报告中表述的缺陷内容来寻找与该缺陷相关的源代码文件。目前,基于缺陷报告的文件级软件缺陷定位方法通常更适用于缺陷修复记录充足的场景,即目标项目有大量已定位并完成修复的缺陷报告。在该场景下,传统方法主要为有监督的分类模型,但仍存在两个核心问题待解决:其一,是自然语言文本和编程语言文本之间的差异;其二,是现有“缺陷报告-源代码”表示学习能力不足的问题。除此之外,软件缺陷定位任务也需要考虑在缺陷修复记录不足场景下的问题。新发布或者不成熟的软件项目中通常存在着大量未修复的缺陷报告,但有限的历史开发数据导致收集到的缺陷修复记录严重不足。在该场景下,传统有监督缺陷定位模型的性能会大大降低。如何利用成熟项目的缺陷修复记录辅助目标项目缺陷定位的问题以及如何利用目标项目中大量未修复的缺陷报告的问题都是研究人员需要解决的难题。根据基于缺陷报告的文件级软件缺陷定位的研究现状,本文从缺陷修复记录充足和缺陷修复记录不足这两个缺陷定位场景出发,进行了深度分析和探索,并取得了一些成果。具体来说,本文的主要贡献有:1)针对自然语言和编程语言之间的差异,本文提出了基于深度多模态的文件级软件缺陷定位模型。该模型将缺陷报告和源代码文件视为两种模态的数据,并利用多模态表示学习将缺陷报告和源代码文件在各自独立语言空间中的表示进一步投射到协同空间中。在协同空间中,我们通过一定的相关性约束以鼓励相关源代码文件的表示尽可能接近给定缺陷报告的表示。本文提出的方法结构简单并适用于大规模数据,在多个开源大规模软件项目上的表现明显优于多个基线模型。2)针对现有“缺陷报告-源代码”表示学习能力不足的问题,本文提出了基于缺陷报告分解和程序中间表示的文件级软件缺陷定位模型。具体来说,本文采用缺陷报告分解策略以学习缺陷报告的多样性特征。此外,本文设计了具有层次结构的图中间表示以有效捕获源代码的多行为特征。该模型在多个软件项目上的实验结果证明了其在缺陷修复记录充足的缺陷定位场景下的有效性。3)针对如何利用成熟项目辅助目标项目缺陷定位的问题,本文提出了基于对抗迁移学习的跨项目文件级软件缺陷定位方法。此外,为了降低知识迁移对源项目的苛刻要求,本文提出的模型利用对抗学习从缺陷修复记录充分的源项目中仅抽取适用于目标项目的通用特征,从而有效过滤影响目标项目定位性能的源项目私有特征。同时,为了学习自然语言的语义特征,模型以全迁移方式学习源项目和目标项目的缺陷报告。在多个源-目标项目数据上的实验充分证明了所提出模型的优势。4)针对如何利用目标项目中大量未修复的缺陷报告的问题,本文提出了基于生成对抗网络的半监督文件级软件缺陷定位模型。该模型的核心思想是采用生成对抗网络来捕获缺陷报告及其对应源代码文件之间的潜在相关性分布,通过模拟样本生成提升文件级软件缺陷定位性能。在多个自构建的数据集上的实验结果证明了所提出模型在缺陷修复记录不足场景中的有效性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001789
{DOI}: 10.27251/d.cnki.gnjdc.2022.001789
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多级别语义表示的命名实体识别关键技术研究
{Author}: 王宇
{Tertiary Author}: 李云
{Publisher}: 南京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 命名实体识别;边界检测;对抗迁移学习;注意力机制网络;多标签分类
{Abstract}: 随着大数据时代的到来,自然语言文本数据作为重要的信息载体之一,大量出现在人们的日常生活中。自然语言文本是人们认识和理解世界上万千事物的重要渠道,也方便人们更有效地表达观点和记录历史等。近年来,人工智能技术的飞速发展不断提升了机器分析和理解自然语言文本的能力。为了实现文本的智能化处理,自然语言处理基础任务的构建及其性能显得尤为关键。命名实体识别、词性标注、句法分析等多项基础性任务应运而生。其中,命名实体识别任务旨在识别出语句中所有的实体词并判断其类型,是知识图谱构建、智能问答系统、机器翻译等高级别自然语言处理应用的关键基础。本文通过引入深度学习领域中的迁移学习、注意力机制网络和多标签分类学习方法,结合自然语言文本中的词级别、词块级别、语句级别等多级别语义表示,对命名实体识别任务领域中若干关键问题展开研究,并取得了一些成果。论文主要工作集中在以下几个方面:(1)针对命名实体识别模型隐式特征抽取问题,本文提出了一种基于对抗迁移学习和自适应多表示融合的命名实体识别方法。该方法基于经典的序列标注模型,通过引入迁移学习思想实现了多任务词级别表示的知识迁移,同时采用对抗训练策略来避免知识迁移过程中的噪声干扰。为了更好地融合学习到的多个表示,该方法还引入注意力机制网络实现了基于任务的自适应表示融合。本文提出的模型联合了命名实体识别、词性标注、组块分析等多个标注任务,有效提升了模型词级别特征抽取的全面性。(2)针对语句中命名实体词存在复杂嵌套结构的挑战,本文提出了一种基于边界头尾检测和词间交互标注的命名实体识别方法。本项工作设计了一个词块级别的分类方法,其建模策略来自于命名实体词的两个关键特性,包括(i)实体边界词具有明确性和(ii)边界内部词具有紧密交互性。该方法采用基于自注意机制和双仿射函数的边界头尾检测器来检测实体词的边界信息,并采用基于序列标注模型的词间交互标注器来学习边界内的词间关系。本文提出的模型从实体边界和边界内部两个角度加强了词块级别表示,提升了语句中相似词块表示的差异性,有利于处理命名实体的复杂嵌套结构。(3)针对命名实体词自身类型多样性问题,本文提出了一种基于语句级多标签分类和束搜索算法的命名实体识别方法。该工作将序列生成模型成功应用于命名实体识别任务。由于命名实体词的类型同时取决于自身以及上下文,该工作在编码器和解码器之间加入了以类型为导向的语句级多标签分类模块以进一步学习语句中包含的实体词类型信息;解码器基于编码器和多标签分类模块得到的信息生成语句中命名实体词的标签序列;同时该工作还设计了受限束搜索算法来保证序列生成模型在测试阶段输出的多样性和合法性。(4)针对命名实体识别模型中的条件式错误传播问题,本文提出了一种基于实体边界和类型信息并行化处理的命名实体识别方法。该工作提出了并行处理策略,并围绕着识别命名实体词的两个关键子目标设计了并行化实体识别模型。该模型从实体词边界和类型出发构建了相应学习模块,克服了传统模型需要按照一定的顺序策略完成目标任务的局限性;同时,为了更好地融合并行化处理的结果,该模型还引入了基于双仿射函数的匹配模块来预测上述模块学习得到的词块级边界表示和语句级类型表示间的关联性。此外,该工作首次采用并行策略完成命名实体识别任务,且相较于传统模型更适用于识别复杂命名实体场景。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001809
{DOI}: 10.27251/d.cnki.gnjdc.2022.001809
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 呼叫中心智能化发展策略研究
{Author}: 何树颖
{Tertiary Author}: 姜娟
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人工智能;呼叫中心;发展策略;扎根理论;智能化
{Abstract}: 现代智能呼叫中心作为现代企业不可或缺的一部分,它集成了人工智能技术,通过机器学习、自然语言处理、语音识别等技术帮助企业管理和处理客户联系中心的任务。与智能呼叫中心相比,传统呼叫中心面临运营和人力成本居高不下,以及全球疫情的常态化趋势等压力。2017年7月20日,由国务院颁发的标题为《国务院关于印发新一代人工智能发展规划的通知》这一文件可以看出,国家高度重视人工智能在中国的发展与规划。因此,多种因素都促使传统呼叫中心纷纷寻求智能化发展道路,探究呼叫中心智能化发展策略迫在眉睫。在理论层面上,本文采用扎根理论进行案例研究,丰富了扎根理论在中国本土化的理论应用场景,并通过严谨科学的编码过程得出有价值的理论结果。在实践层面上,从宏观角度看,呼叫中心的智能化发展符合科技驱动发展战略,可以推动社会经济稳健发展和国家经济增长。从中观角度看,呼叫中心需要转型为智能化发展策略以应对高人力成本等问题。从微观角度看,本文以Q公司为研究对象,为其提供呼叫中心智能化发展的指导方针。研究方法上,本文采用了扎根理论研究方法,通过与Q公司相关人员的深度访谈收集一手数据,并运用扎根理论和MAXQDA编码工具对数据进行分析,识别关键概念的表现维度,梳理概念之间的逻辑链条,最终得出七个核心范畴,包括公司对智能化技术的研发、公司对员工智能化应用能力的提升、公司使全员对智能化发展统一认可、公司收益受智能化发展的积极影响、员工对智能化的清晰认知、员工对智能化的思想转变、员工对智能化的行为调整。结合Q公司的实际情况进一步分析,得出影响呼叫中心智能化发展的核心因素模型。基于这些核心范畴和核心因素模型,本文提出了四条呼叫中心智能化发展优化路径建议,包括贯彻智能化发展战略、推动员工认知、思想和行为的转变、搭建适应智能化发展的培训体系,以及强化智能化技术的研发。对于那些能够更好贯彻呼叫中心智能化发展策略的企业来说,加快从传统呼叫中心向智能化发展的步伐对企业和整个服务行业的发展都具有重大推动意义。综上所述,本文通过探究呼叫中心智能化发展策略,在理论和实践层面上提供了重要的研究结果和指导方针,对服务行业乃至国家的发展具有重要推助意义。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.002053
{DOI}: 10.27251/d.cnki.gnjdc.2023.002053
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度学习在中文命名实体识别算法中的应用
{Author}: 毛新涛
{Tertiary Author}: 于舒娟
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中文命名实体识别;部首级嵌入网络;门卷积网络;注意力机制;预训练模型
{Abstract}: 随着计算机技术和互联网技术的飞速发展,网络中的数据信息呈几何倍增长形式,为有效减轻人工处理数据的负担,人工智能技术成为了当前研究的热点。自然语言处理技术是高效获取数据的关键技术,也是人工智能领域的重要研究方向。命名实体识别作为自然语言处理的一项基础性任务,不仅自身具备很高的研究价值,而且在很多下游任务中同样扮演着重要的角色,例如信息检索、机器翻译、知识图谱构建等。命名实体识别算法有较强的语言针对性,和大多数拉丁语系语言相比,中文语句中没有明显的词边界信息,使得中文命名实体识别技术面临极大的挑战,如何提升模型实体识别的准确率成为目前的主要难题之一。本文从汉字特征、词分割技术、注意力模型和预训练语言模型四个方面对中文命名实体识别算法做出了改进和优化,旨在更进一步提升模型的识别性能。本文的创新工作如下:(1)针对中文语句中因词边界模糊和语义信息匮乏导致分词错误传播的问题,本文提出一种基于词典和字形特征的多元嵌入算法模型MNSR(Multi-embedding Network based on Soft Lexcion and Radical-feature,MNSR)。该模型的优点是:着眼于汉字字形信息和中文词汇信息,通过融合部首级嵌入方法和Soft Lexicon方法增强语义信息,减少分词错误现象;利用门卷积网络强化潜在词语特征提取能力,并缓解训练过程中产生的梯度消失问题。实验结果表明,MNSR模型在中文命名实体识别任务中有着良好的表现效果,在公开数据集Onto Notes4.0、Weibo和Resume上的F1值分别达到76.40%、64.30%和96.16%,MNSR模型相较于传统模型和文献相关的最新模型都有不同程度的识别性能提升。(2)针对卷积池化过程中各个通道所占重要性不同造成的信息损失问题,多元嵌入表示信息之间细粒度相关性特征不足的问题,本文通过引入SE注意力机制和Cross-Lattice注意力机制,提出了SECL-MNSR模型(Incorpoating SE and Cross-Lattice Attention into MNSR,SECLMNSR)。其中SE模块用于部首级嵌入模型的特征提取网络中,利用两个全连接层实现权重参数的训练,对通道间的相互依赖关系进行显式建模;Cross-Lattice模块作用于不同输入表示之间,捕捉各个特征空间上的细粒度相关性特征。实验结果表明,两个注意力机制模块的引入有效强化了模型对中文实体信息的捕获能力,相较于MNSR模型,SECL-MNSR在数据集Onto Notes4.0、Weibo和Resume上的F1值分别提升了0.83%、0.87%和0.28%,进一步优化了对实体名词的识别准确率。(3)针对SECL-MNSR模型在文本上下文信息方面的特征提取能力较弱和训练数据量不足的问题,本文通过结合BERT预训练网络,提出了B-SECL-MNSR模型(Incorpoating BERT into SECL-MNSR,B-SECL-MNSR)。该模型利用BERT获取长距离语义依赖关系,并将结果融入到字符表示信息之中以增强数据信息可用性。实验结果表明,对比文献相关的模型,B-SECL-MNSR拥有更好的识别性能,在Onto Notes4.0、Weibo和Resume数据集上的F1值分别达到83.38%、72.21%和96.69%;相较于SECL-MNSR模型,B-SECL-MNSR模型在推理效率允许降低的范围内实现了识别性能的显著优化,其F1值分别获得6.15%、0.25%、7.04%的提升。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000708
{DOI}: 10.27251/d.cnki.gnjdc.2023.000708
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型BERT的阅读理解去偏算法研究
{Author}: 吴梦洁
{Tertiary Author}: 于舒娟
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;机器阅读理解;预训练语言模型;词嵌入
{Abstract}: 近年来,互联网技术的飞速发展使得各类数据信息呈现指数级增长,与此同时人们的信息获取方式也呈现出多元化、便捷化的转变趋势。在此背景下,基于信息检索以及智能问答等现实场景的应用需求逐步扩大,如何促进问答系统更高效地服务于多方领域成为了当下的研究热点,机器阅读理解技术作为主流实现方式因此具有十分重要的研究价值。目前深度学习算法中的预训练语言模型基于出色的文本表示能力,在一些公开阅读理解数据集上取得优异的表现。尽管如此,现有文献模型在面对对抗性偏差样本的干扰时,文本推理能力极易受损,从而影响应有的预测性能。针对该问题,本文研究基于预训练模型的阅读理解去偏算法,旨在优化模型面对真实场景中非定向数据偏差时的性能表现。论文的主要工作如下:(1)传统预训练模型在面对训练数据偏差时,容易根据答案位置信息进行捷径性预测,导致文本推理能力的下降,针对这一问题,本文结合BERT模型具体结构,提出一种基于泛化性位置编码的阅读理解去偏算法R-PD(Regularized Positional Dropout,R-PD)。该算法的思想是:首先对模型初始化词嵌入表征引入正则化技术,泛化模型在训练过程中对答案位置信息的过度依赖;接着通过在损失函数中引入KL散度分布项,约束正则化随机性对模型训练稳定性的影响,从而进一步维护模型的预测性能。实验结果表明,R-PD算法的引入能够有效强化模型的语义推理能力,提升模型在存偏数据集上的预测准确率。(2)针对预训练模型编码模块层级堆叠,容易丢失低层级短语特征的问题,本文提出一种基于组合层次级编码模块语义信息的改进算法R-PD-HC(Regularized Positional Dropout and Hierarchical Combination,R-PD-HC)。该算法的思想是:充分利用不同编码层所学特征,引入池化模块与Sigmoid激活函数分配层级特征权重,并通过加权组合的方式获取融合不同层级文本特征的分类输出,从而综合考虑表层位置特征与深层语义特征。实验结果表明,R-PD-HC算法的引入促进了模型对多样性语义特征的学习,进一步提升了预测准确率。(3)为了进一步优化模型的预测性能,本文考虑基于数据要素出发,丰富模型的多样性特征提取,提出基于数据增强的R-PD-HC去偏算法。其中,基于阅读理解样本的格式特殊性,本文针对问题文本引入两种适应性样本扩充策略:第一种方法是基于样本进行替换、删除、交换、插入变换的EDA数据增强算法,第二种方法是基于语言训练的BERT-QG问题生成算法。实验结果表明,引入数据增强后的去偏模型能够更好地捕获位置偏差,从而进一步优化R-PD-HC算法的去偏表现,最终相对初始模型具有更优的预测性能。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001501
{DOI}: 10.27251/d.cnki.gnjdc.2023.001501
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT和外部知识的答案选择模型研究
{Author}: 罗亮
{Tertiary Author}: 程春玲
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 答案选择;BERT;多层感知机;上下文感知;外部知识;微调
{Abstract}: 答案选择任务是自然语言处理中一项重要的任务,它可以有效地帮助机器理解自然语言,为问答系统和智能对话系统等人工智能应用提供基础支持。BERT(Bidirectional Encoder Representations from Transformers)的出现对答案选择任务的研究产生了深远影响,其强大的通用语言能力为答案选择模型的构建提供了有力支持。本文旨在研究和解决在应用BERT构建答案选择模型时所遇到的特征缺失、背景知识缺失和高成本等问题,并实现高性能的答案选择模型。本文主要从文本特征挖掘和知识增强两方面入手,以改进答案选择模型,并探索BERT在下游任务中应用的高效微调方法。具体主要工作如下:(1)为解决参数冻结的BERT生成的文本特征向量缺乏句子级别语义特征和问答对交互特征的问题,本文提出了一个基于多层感知机和语义矩阵的特征增强答案选择模型。该模型包含两个用于挖掘不同特征的网络模块,即语义理解模块和语义交互模块。其中,语义理解模块采用全连接层获取语义理解矩阵,并将其嵌入多层感知机中,用于提取文本的句子级别的语义特征;而语义交互模块则采用双向注意力机制计算语义交互矩阵,并嵌入多层感知机中,以捕捉问答对之间的交互特征。经过实验验证,该答案选择模型具有轻量级的特点。相比其他基于文本特征提取的同类模型,该模型在准确率方面表现出色,并有所提升。(2)为解决使用外部知识增强模型语义理解能力时,知识库中关联的部分知识对某些具体的问答对实例并不适用,以及知识的特征表示与上下文信息相互隔离的问题,本文提出了一个基于上下文感知的知识增强答案选择模型。该模型由两个重要组件构成,分别为知识筛选层和知识表示层。知识筛选层根据知识的置信度以及知识与上下文信息的匹配程度,对知识进行动态筛选,缓解无效知识对模型产生的干扰;知识表示层采用注意力机制使得知识特征和所应用的上下文语境相适应,以增强上下文信息在知识表示中的作用,并利用卷积网络对知识特征进行压缩表示。实验结果表明,与其他知识增强模型相比,该模型的准确率更高。(3)为解决BERT微调方法在实际应用时训练和存储成本过高的问题,本文提出了一种基于提示向量的BERT高效微调方法。该方法具体实现为,在BERT的每个Transformer编码层中添加提示向量,引导模型产生特定的输出。同时,在针对下游任务进行训练时,只需调整这些提示向量和BERT中的偏差项参数,就可以适应下游任务的需求。实验结果显示,该方法相较于微调方法,能够大幅降低BERT在训练和部署时特定于答案选择任务的参数数量,而且在准确率和泛化能力方面也具有较大优势。与其他高效微调方法相比,该方法准确率表现更佳,展现出更优异的综合性能。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000989
{DOI}: 10.27251/d.cnki.gnjdc.2023.000989
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向视觉问答的多模态信息增强方法研究
{Author}: 蒋钰玲
{Tertiary Author}: 鲍秉坤
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视觉问答;数据增强;知识增强;预训练模型
{Abstract}: 视觉问答需要计算机根据图片和问题给出对应回答,是跨模态智能研究的重要分支。随着研究的不断深入,视觉问答朝着多元化和复杂化的方向发展,出现了两个全新的任务场景:涉及多幅图像的问答任务和涉及外部知识的问答任务。在涉及多幅图像的问答任务中,模型需要准确理解图片内容与文本问题的语义,并将二者进行合理关联,以保证模型在相同场景下应对不同问题的鲁棒性。而在涉及外部知识的问答任务中,模型需要将理解到的图片和问题的语义与外部知识进行关联以得到准确的答案。应对上述新任务需要大量的有标注多模态信息,一方面,任务一需要大量与问题对应图片相似的图片,以强化模型对问题相关的图片内容的理解;另一方面,任务二需要利用外部知识库丰富模型对图片内容相关知识的储备。然而当前以人工标注为主的数据获取方式难以满足上述数据需求,使得现有模型存在多图片视觉问答鲁棒性差,涉及外部知识的视觉问答准确率低等短板。为此,本文将研究在不依赖人工标注的情况下进行多模态信息增强的方法,并对文本和图片内容进行视觉及语义的多角度特征互补,以期提升视觉问答模型在特定场景上的性能表现。主要的两个工作如下:(1)针对在涉及多幅图像的视觉问答任务中模型鲁棒性差的问题,提出了一种基于样本重组的视觉问答方法。为了解决有限标注数据产生的伪相关问题,该方法将原有样本中在同一场景下的图片和文本进行重组,生成大量未标记的新样本,并基于熵最小化损失为这些未标记数据生成具有较高可信度的伪标签,以用于模型的训练。此外,该方法还计算模型训练前后一致性损失,以防止模型在训练过程中出现过拟合。在NLVR2、NLVR1和SNLI-VE数据集上的实验结果表明,该方法可以有效提高模型在相同场景下应对不同问题的鲁棒性,并且改善模型的推理能力。(2)针对在涉及外部知识的视觉问答任务中模型答案正确率低的问题,提出了一种基于知识增强的视觉问答方法。该方法借助图文检索模型,利用图片从Wikidata知识库中检索相关文本知识。然后使用GPT-3生成的候选答案对文本知识进行二次筛选,进一步增加了文本知识与答案的相关性,减少干扰。此外,为了将大规模语言模型的推理和理解能力应用到视觉问答任务中,该方法设计了可学习的提示词,引导模型挖掘外部知识和问题的关联,从而在理解相关外部知识的基础上推理问题的答案。在OK-VQA数据集上的实验结果表明,该方法可以有效提高模型在涉及外部知识问题时结果的准确率。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000460
{DOI}: 10.27251/d.cnki.gnjdc.2023.000460
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多标签学习的中医辨证分析研究
{Author}: 陈诗琪
{Tertiary Author}: 龚乐君
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中医辨证;多标签学习;知识图谱;自然语言处理
{Abstract}: 随着医疗信息技术的快速发展,中医领域的智能医学发展已被纳入国家鼓励发展的项目当中。辨证论治是中医识别病症和治疗疾病的基本法则,建立科学规范的智能化辨证方法,对中医领域的智能医学发展具有重要意义。目前,中医辨证智能化存在的难点在于,中医临床辨证时存在多证候相兼问题,这使得中医辨证本质上成为多标签学习任务。同时,由于中医数据采集规范标准的缺失以及数据隐私保护等多方面原因,中医领域难以形成大规模的标准数据集,这使得中医医疗文本数据集规模小且信息分布密度稀疏。针对上述所存在的问题,论文深入研究了基于中医医疗数据的数据挖掘与辨证分析方法。主要工作内容如下:(1)提出了一种基于改进ML-Relief F和多标签深度森林(Multi-Label Deep Forest,MLDF)的中医辨证分析模型。论文通过改进的ML-Relief F特征选择算法,对医疗文本表示生成的稀疏特征矩阵进行筛选,得到最优特征子集。同时,论文首次将MLDF算法引入中医辨证分析任务,利用其强大的表征学习能力,在小规模医疗文本数据集的训练下得到证候预测结果。实验结果证明了使用改进ML-Relief F特征选择算法的必要性与所提出模型的可行性。(2)提出了一套基于Neo4j的多源异构中医领域知识图谱构建流程。由于全科知识图谱的数据准确性存在缺陷,使其临床应用受到限制。因此,论文以中医防治慢性肾功能衰竭医案数据为基础,结合外部多源异构医疗数据,自顶向下构建了基于中医防治慢性肾功能衰竭的单病种知识图谱。在模式层使用Protégé构建知识图谱本体结构,在数据层处理并融合多源异构数据生成三元组,存储于Neo4j图数据库。通过医疗信息可视化展示与分析,证实了该知识图谱可用于对知识准确性要求高的医疗场景。(3)提出了一种基于知识图谱嵌入的多标签中医辨证分析模型。为了更好地对中医医疗文本进行表示,论文利用外部知识图谱的嵌入式向量提供额外的隐藏信息,将表示学习过程分为知识图谱嵌入模块与文本表示模块。为了合理有效地对两种特征表示进行融合,论文提出了KT-Fusion特征融合方法。最后,模型将MLDF算法作为分类器得到证候预测结果。通过对比实验证明,论文选用的知识图谱嵌入模型在所用数据集中具有最好的嵌入性能,并且所提出的模型在中医辨证分析任务的多标签分类性能上有明显提升。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001807
{DOI}: 10.27251/d.cnki.gnjdc.2023.001807
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本与视觉的时空关联型多模态情感识别
{Author}: 季铭辉
{Tertiary Author}: 刘天亮
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 情感分析;时空特征融合;注意力机制;通道融合;多模态融合
{Abstract}: 短视频作为当前最受欢迎的信息传播方式,其数据组成复杂多样,不仅包括视频图像信息,还包括音频、文本标注等多种形式的数据,如何有效利用这些多模态数据进行情感分析已成为研究者们的热门话题。针对上述问题,本文提出一种融合视频与文本标注的多模态情感分析模型。具体工作如下:(1)针对视频数据中时间与空间维度特征难以融合的问题,本文提出一种基于多头自注意力与时空特征融合的视觉情感分析方法,使用改进型Transformer结构融合浅层特征图像序列中的深层时空间特征。首先使用卷积神经网络提取图像帧序列中的浅层视觉特征;然后使用多头自注意力机制提取深层空间特征;之后据此提取其时序特征,并拼接融合时空间特征,以提取视觉模态中的深层情感特征信息;最后使用分类网络预测视频样本的情感类别。实验结果表明,与传统的视频情感特征提取方法相比,该模型在识别视频情感方面能够获得更加优异的性能提升。(2)针对文本数据中无法高效提取语义情感特征的问题,本文提出一种基于Bi-LSTM和双通道信息增强的文本情感分析方法。首先对文本词向量进行表示并采用情感词典与位置编码增强其情感词性与位置信息;然后使用两个相互独立的Bi-LSTM网络实现通道特征提取;采用Transformer网络学习双通道特征间的语义关联;最后使用分类网络预测文本语料的情感类别。实验结果表明,相较于传统文本情感特征提取方法,该模型能够有效提取文本数据中的深层语义情感特征,实现更加精准的模型预测。(3)针对视觉与文本模态间结构差异较大情况下数据特征难以融合的问题,本文提出一种基于多层权值矩阵的多模态情感决策分析方法。利用局部权重优化矩阵和后验概率矩阵,分配各模态决策权重,构建视觉与文本模态的决策融合模型,通过分析数据样本的情感分值矩阵,判别样本的情感类别。实验结果表明,相较于单模态情感分析模型以及多模态特征融合模型,该决策融合模型能够有效利用多模态数据的信息差异,提升模型的分析性能。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001072
{DOI}: 10.27251/d.cnki.gnjdc.2023.001072
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制语义匹配的问答系统研究与应用
{Author}: 成会乔
{Tertiary Author}: 章韵
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 问答系统;注意力机制;问句分类;答案选择
{Abstract}: 在互联网蓬勃发展和数字化进程加速的时代背景下,人们可以通过互联网获取各种知识,但是如何在海量数据中高效地筛选出有价值的信息,成为了一项亟待解决的难题。问答系统通过采用语义分析等技术,能够深入理解用户的搜索意图从而提供快速准确的答案,满足了用户精准定位答案的需求。论文针对FAQ问答系统,深入研究其中的问句分类和答案选择任务,利用深度学习技术提高中文语境下问答系统的智能化水平。针对问句分类任务中问句语义特征信息难以提取与表示的问题,论文提出了基于融合字词特征注意力机制的问句分类模型(CW-Bi GRU-MA模型)。该模型进行字词双粒度嵌入输入,结合双向门控循环单元Bi GRU进行特征提取,丰富问句文本的语义特征,同时引入多头注意力机制强化重要特征的表达,提高了问句分类效果。针对答案选择任务中问句和答案语义匹配不充分的问题,设计了面向答案选择的多角度注意力问答匹配模型(BERT-MPAM模型),采用比较聚合网络结构以较大程度地避免语义信息缺失,利用预训练语言模型BERT进行词嵌入,弥补传统词向量技术的缺陷。同时,采用多角度注意力机制,全面提取问句和答案的局部和交互语义特征,并对这两种注意力网络进行有效聚合,提高了模型的匹配性能。论文将CW-Bi GRU-MA模型和BERT-MPAM模型在各自的公开数据集上与多个模型进行了对比实验,验证了这两个模型有着较好的性能。最后集成上述两种模型,搭建基于语义匹配的金融知识问答系统,对其进行详细的分析与设计,该系统能够深入解析用户问句,查询问答库并返回答案,帮助人们快速、准确的获取金融知识,具有一定的实用性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000574
{DOI}: 10.27251/d.cnki.gnjdc.2023.000574
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向教育知识图谱的小样本关系抽取技术研究及应用
{Author}: 张旺
{Tertiary Author}: 陈国良
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 关系抽取;小样本学习;图神经网络;注意力机制
{Abstract}: 教育知识图谱是一种以各个学科知识点为节点,以知识点之间的关系(如包含、依赖、关联等)为边的结构化数据表示。它可以用于支持教育领域的多种应用,如智能推荐、个性化学习、知识管理等。然而,由于教育领域涉及到多个学科和层次,构建完整且高质量的教育知识图谱需要大量的人工标注和维护工作,这是一个非常耗时、耗力的过程。因此,如何利用较少的监督数据进行有效的关系抽取成为了一个重要且具有挑战性的研究点。论文以教育知识图谱中的小样本关系抽取技术为研究对象,针对现有方法中由于数据稀疏带来的鲁棒性不足、特征表示不充分以及泛化能力差等问题进行了探索,主要包括以下三点研究内容:(1)针对现有方法中存在的噪声问题,提出了一种基于How Net的双重注意力机制小样本关系抽取方法。该方法对文本序列中的实体进行语义分解,并使用双重注意力机制分别计算实体与实例的语义权重,从而改善模型的鲁棒性。具体来说,该方法利用How Net语义网络将实体划分为多个义原,通过第一层注意力机制选择与上下文语境最匹配的义原,缓解实体在不同上下文中存在的一词多义问题。第二层注意力机制是在提取不同关系类别的原型特征时,对不同的实例编码进行特征融合,以降低噪声数据的影响。该方法在中文数据集Fin Re上,与其他方法对比在不同难度的小样本关系预测任务中均取得了较好的性能。(2)针对现有方法中存在的特征表示不充分以及泛化能力差的问题,提出了一种基于多视角图注意力网络的小样本关系抽取方法。该方法能够从文本中挖掘出隐含的图结构特征,并充分利用这些特征来提高关系预测的准确性。具体来说,该方法以文本序列中的每个字为节点,利用高斯图生成器从多个视角构建节点之间的边,以表示文本之间的隐藏关系。在不同的视角下,模型分别使用不同的图注意力网络学习每个节点之间的关系权重,让其具备自动选择正确关系的能力。随后,将权重信息和特征信息输入到图卷积网络中进行特征融合,以获取更多的上下文信息,提高泛化能力。该方法在FewRel1.0和FewRel2.0两个数据集上进行了性能评估,均取得了不错的效果。(3)论文设计并实现了一个面向教育知识图谱的知识抽取可视化系统,用户可以上传自己的数据并进行少量的标注,从而训练出自己的专属知识抽取模型。该系统提供了上述两种不同的算法用于知识抽取模型构建,用户可以根据不同学科领域的需求选择合适的算法进行知识抽取。另外,本系统添加了针对抽取结果的质量评价模块。用户可以利用该模块的对抽取结果的准确性进行评估,并选择质量较高的结果重新训练模型,以提高模型的准确性。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001056
{DOI}: 10.27251/d.cnki.gnjdc.2023.001056
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于众包标注和深度主动学习的电力知识图谱构建方法
{Author}: 李前亮
{Tertiary Author}: 邓松
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 众包标注;文本分类;主动学习;知识图谱;自然语言处理
{Abstract}: 随着电力系统规模日益扩大,新知识不断涌入,系统中的知识总量呈现爆炸式的增长。现有的电力知识组织和管理方式不能满足日益增长的电力系统知识应用需求。知识图谱是一种新颖、高效知识组织管理技术手段。将知识图谱应用在电力领域,可以串联组织复杂电力知识网络,提升电网信息检索能力。构建电力知识图谱需要利用知识抽取技术。知识抽取模型构建需要大量人工标注数据,同时模型的训练依赖大量计算资源。为了解决上述技术难点,本文面向电力场景,总结影响电力知识图谱构建的因素,提出基于深度学习和机器学习低成本构建电力知识图谱方法。本文主要工作如下:(1)知识图谱作为一种新颖高效的知识信息组织、管理技术手段通过三元组等核心要素将电力系统信息串联组织。构建知识图谱需依赖大量数据众包标注,然而众包标注数据质量参差不齐并缺乏有效质量评价方法。本章节提出基于KF-Bert(Bidirectional Encoder Representation from Transformers with K Fold Test)和Cart-DT(Classification and Regression Decision Tree)的众包数据质量评价算法。受K折验证思想启发,实现对不同标注数据有效融合。基于决策树分类模型完成对不同标注员标注数据质量评价。减少专家系统在数据标注环节的参与,降低的数据预处理成本,为后续文本分类工作提供高质量的数据基础。(2)知识图的构建有利于电网生产、电气安全防护、故障诊断和可观测性。高精度的文本分类算法是构建电力系统专业知识图的关键。然而电力业务系统中存在大量描述不佳和专业化的文本,这些文本中包含有效标签的数据量较低。这将给文本分类模型精度的提高带来很大的挑战。为了弥补差距,本章节提出了一种基于CCTP-DAL电力文本分类算法(Classification algorithm for Chinese Text in the Electric Power Industry based on deep active learning)。发挥Transformer多头自注意力机制在高维数据处理和自动提取特征方面的优势,结合层次置信度主动学习机制在有效降低模型训练数据需求的巨大潜力。以较少的数据标注成本和极低的计算资源获得高精度电力文本分类模型,为电力知识图谱的构建做好基础工作。(3)基于上述主要工作,本文设计实现面向电力领域信息安全知识图谱。首先介绍图谱构建过程中知识表示与知识存储环节,包括梳理概括安全领域知识本体、信息安全本体描述语言和电力信息安全知识批量存储,然后以“输电网”为关键词展示知识图谱的动态化搜索展示与可视化展示功能,最后介绍电力知识图谱路径查询功能,帮助运维人员了解电力复杂耦合业务。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.002097
{DOI}: 10.27251/d.cnki.gnjdc.2023.002097
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识表示学习的实体对齐算法研究与实现
{Author}: 邱晨阳
{Tertiary Author}: 季一木
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;实体对齐;知识表示学习;预训练语言模型;迭代策略
{Abstract}: 随着信息时代的飞速发展,网络数据总量也呈爆发式增长,2022年网络数据总量据估测已经达到了61ZB的规模。为了有效处理和利用这些数据,研究者们提出了以结构化的形式描述客观世界中概念、实体及其关系的知识图谱。知识图谱能把互联网中的信息表达成便于人类理解的形式,辅助人类更好的利用这些信息。但是使用单一的知识图谱作为信息源,仍会面临信息缺失、错误等问题。针对该问题,研究者提出了知识图谱融合的解决方法,通过不同知识图谱的融合来提升知识图谱的质量。实体对齐是知识图谱融合中最基础和关键的技术,旨在寻找不同知识图谱中对应同一现实事物的实体,以此辅助知识图谱内其他信息的融合。过去常见的基于知识表示学习的实体对齐模型基于关系三元组和预对齐种子对进行训练,将实体结构向量表示投影在统一的向量空间中,再通过计算向量间距离来衡量对应实体之间相似度,从而实现实体对齐。这类方法需要大量人工筛选预对齐种子对,且没能利用知识图谱中各实体的属性三元组。针对以上的问题,本文对实体对齐方法进行了深入研究,主要工作包括以下三部分:(1)针对基于知识表示学习的实体对齐方法无法利用属性信息的问题,本文提出了一种基于Sim CSE和Trans E的实体对齐算法,该算法联合知识表示学习模型和预训练语言模型进行实体对齐任务,通过Trans E模型生成实体结构的向量表示,同时通过Sim CSE模型生成实体属性的向量表示,然后再联合两种向量表示进行实体对齐。这样更充分的利用知识图谱内信息,可以提升实体对齐效果。经过实验证明,该算法能有效提高实体对齐的准确率。(2)针对大规模人工筛选种子实体对成本过高的问题,本文提出了一种基于半监督学习的迭代实体对齐算法,该算法依靠少量人工对齐的种子实体对进行迭代实体对齐,并基于双向对齐策略和课程学习策略筛选出向量间距离小于阈值的对齐实体作为新的种子实体对,从而逐步扩展种子实体对规模,以此在降低实体对齐人工成本的同时有效提高实体对齐的效果。经过实验证明,该算法能在减少人工筛选种子实体对规模的情况下,提升实体对齐效果。(3)基于本文上述提出的实体对齐算法和迭代实体对齐算法,本文构建了面向开源知识图谱的实体对齐网络系统平台,本文采用微服务的思想设计了整个系统的总体架构,保障了系统的高可用性和低耦合性。该系统支持用户上传知识图谱数据,并根据需求设定参数进行实体对齐任务,从而帮助用户更好的进行各类知识图谱研究。经过实际使用操作验证,该系统能稳定实现本文设计的各项功能。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001894
{DOI}: 10.27251/d.cnki.gnjdc.2023.001894
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态数据的轨道交通事故分析与预防策略研究
{Author}: 闫冬阳
{Tertiary Author}: 李克平
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 轨道交通;事故预测;致因分析;深度学习;强化学习;自然语言处理
{Abstract}: 随着我国轨道交通事业的快速发展,先进设备和技术在轨道交通系统中得到了广泛应用,在大幅度提高运营效率和服务水平的同时,也造成了其复杂程度不断增加,给轨道交通安全带来了前所未有的挑战。为了稳步实现“十四五”规划对轨道交通发展的更高要求,保证轨道交通安全可靠高质量发展,迫切需要提升轨道交通事故分析和事故预防的能力。轨道交通的事故分析和事故预防需要充分利用历史事故数据,挖掘事故发生的规律和演化机理,把握系统运行状态的变化与事故风险之间的潜在关联关系。由于轨道交通系统的构成复杂,系统运行数据和事故数据由多种模态的数据组成,具有数据规模大、格式多、信息维度高且难以提取等特点,对数据处理和信息提取技术有更高的要求。目前,轨道交通的事故分析和事故预防对事故数据的利用仍然较多地局限在结构化数值数据上,对文本等非结构化数据的利用率不高,无法综合利用多源多模态信息实现对轨道交通系统状态和安全态势的准确把握。为了提高轨道交通系统事故分析和事故预防的能力,本研究从数据处理、方法改进和新技术应用等多方面着手,探索了事故分析和事故预防与数据驱动、深度学习、强化学习等新兴技术的结合方式,提出了新的基于深度学习和强化学习的事故分析和事故预防方法。本研究的主要工作如下:(1)基于复杂网络理论,改进了文本数据的特征提取和表示方法,并提出了包含数值、分类、文本等格式的多模态数据融合表示方法,提高了事故数据的表示和特征提取质量。针对轨道交通多模态数据的特征表示问题,本文提出了基于文本复杂网络的特征表示方法,对文本非结构化数据的词袋模型表示方法进行改进。该方法利用了复杂网络在复杂系统建模中的优势,借助度、可达性和中心性等网络节点特征,对文本非结构化数据进行了更为准确的量化处理。为进一步提高多模态数据关键特征的表示和提取能力,将提取出的关键信息与结构化数值数据进行了融合。实验中首先通过与多种既有方法对比,验证了所提方法在文本分类任务中的优势,并发现了复杂网络类型和特征对方法性能具有较为重要的影响。进一步引入轨道交通的多模态事故数据,通过事故致因分类任务分析了本文方法在多模态数据上的表现。最后,对比了多模态数据中不同数据特征结合方式对分类结果的影响,发现结构化数据和非结构化数据的融合表示可以为分类准确度带来进一步的提升,但应当考虑维度不平衡等问题的影响。(2)针对事故数据存在的数据不平衡问题,利用随机游走机制,融合深度学习算法,提出了文本非结构化数据的数据增强方法,减少了信息损失,提高了分类任务的性能,并分析了事故多模态数据增强的不同方式和性能表现。考虑轨道交通多模态数据中结构化数据和非结构化数据共存的特点,研究了非结构化数据进行数据增强时的信息损失问题,并提出了一种新的解决方案:引入复杂网络随机游走方法,直接对非结构化数据进行网络建模,并使用随机游走路径进行数据增强。利用卷积神经网络提升了对随机游走路径的特征提取效率,并设计了融合深度学习过采样的结果选举策略,提高了数据增强方法在分类任务上的稳定性。基于轨道交通多模态不平衡事故数据,分析了对多模态不平衡数据进行数据增强的多种方式,并对比了不同方式的事故致因分类结果的表现。结果显示多模态数据相较于单一模态的数据能够带来更好的分类效果提升,与此同时,也显示出对数值和文本同时进行数据增强会最大程度改善轨道交通多模态事故数据的不平衡问题,为如何最大限度处理和利用轨道交通事故数据指明了方向。(3)提出了考虑多致因复杂作用关系的事故致因分析方法,利用数据隐含信息提取致因之间的潜在作用机制,分析事故多致因路径,并提出了提取关键多致因路径的方法。充分利用事故数据中文本数据对事故致因作用描述的关键信息,提取关键词建立致因要素网络,拓展致因网络的组成,形成了事故双层致因网络。通过深度学习方法学习下层致因网络节点作用与上层网络致因要素节点的关联关系,用于预测下层致因节点失效状态的传递方向。进一步使用深度学习方法进行了事故多致因路径的提取,并分析了多致因节点对下层致因网络中致因节点关系的影响,依据致因网络风险评价指标判断多致因在事故风险形成中的重要性,为事故预防环节中关键多致因的确定提供依据。基于轨道交通事故数据进行了实例分析,提取了出现频次较高的前30个致因对应的事故多致因路径,并进行了分析。从多致因分析的角度,发现了需要重点防控的致因节点并得到了最有效降低致因网络风险的事故多致因路径。(4)引入强化学习算法,提出了多模态数据驱动的轨道交通事故预防策略和新的事故预防效果评价指标。研究中分析了事故影响因素在不同时间点上被获取的可能性,并以提前发现事故风险并主动预防为目标,考虑影响因素的时间可达性进行预测变量的选择,形成包括数值、类别和文本数据在内的多模态事故数据作为事故预防参考信息。引入了深度强化学习算法,将事故预防定义为复杂风险环境下的决策问题,提出了基于强化学习的事故预防策略,并考虑了人为操作对实际中事故预防成功率的影响,设计了考虑事故预防准确性、人为因素以及部署成本在内的事故预防效果综合评价指标。基于新的评价指标,验证了所提出方法在事故预防准确性以及事故预防的效率上取得了最佳的平衡。同时,实验分析中发现了实际应用中的随机性会给所提方法的性能造成一定的影响,提高相关工作人员的技能水平是保证事故预防方法取得最好表现的关键。通过进一步分析实验结果,对工作人员接受事故预防技能培训的周期和不同时段的培训重点给出了针对性的建议。图65幅,表34个,参考文献165篇。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2023.003738
{DOI}: 10.26944/d.cnki.gbfju.2023.003738
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地铁基坑工程施工风险评价研究
{Author}: 黄奕鹏
{Tertiary Author}: 李林;颜春明
{Publisher}: 广西大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 地铁;基坑;风险评价;网络层次分析法;云模型
{Abstract}: 随着我国城市化进程的不断推进,城市交通压力日益加剧。为了缓解交通拥堵,越来越多的城市选择修建地铁。然而,地铁基坑工程具有施工周期长、影响范围广、涉及因素多、复杂程度高以及隐蔽性强等特点,使得地铁基坑工程在施工所面临的施工风险很大。在此背景下,本论文以施工企业的角度出发,对地铁基坑工程的施工风险评价进行研究,分析地铁基坑施工风险评价的工作流程,并提出风险应对的措施。本文首先对地铁基坑施工风险评价的现状进行分析,并简要分析风险评价指标体系构建和权重计算存在的问题。在此基础上,运用工作-风险分解耦合矩阵法,将工作和风险单元分解后,利用人工智能模型对风险原因进行分析。然后,对风险因素进行归纳和整理,得到了包含围护结构施工风险、基坑降水风险、地基处理风险、基坑开挖风险、主体结构施工风险、自然风险、地质风险、环境风险共8个一级指标以及59个二级指标的风险评价指标体系。之后,进一步分析风险因素间的相互作用关系,运用网络层次分析法进行权重计算,并构建了基于云理论的风险评价模型,形成了风险评价的工作程序。最后,对广州市轨道交通地铁三号线东延段东城西站项目进行风险分析,计算得到项目的施工风险等级为“一般风险”,并通过对比分析,验证结果的准确性,进而根据施工风险评价结果以及现场实际情况,为降低该项目的施工风险提出应对建议。通过本文的分析与研究,形成了较为完整的风险评价流程,可以为地铁施工企业提供科学性较强、客观性较强、准确度较高的施工风险评价方法以供参考和借鉴。
{URL}: https://link.cnki.net/doi/10.27034/d.cnki.ggxiu.2023.002723
{DOI}: 10.27034/d.cnki.ggxiu.2023.002723
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 藏文摘要生成关键技术研究
{Author}: 李芬芳
{Tertiary Author}: 周庆国;多拉
{Publisher}: 兰州大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 藏文信息处理;句子边界消歧;注意力机制;预训练语言模型;文本摘要;多元集束搜索
{Abstract}: 藏语是藏族人民沟通和交流的语言,藏文是藏语的文字书写系统,有其独特的构字规则和语法结构。随着自然语言处理(Natural Language Processing,NLP)技术的发展,越来越多的NLP技术被应用到藏文信息处理领域,这些研究能够促进民族之间的交流,帮助人们更多地了解语言的特性。随着互联网技术和智能终端的快速发展,藏文信息呈现出快速增长的趋势,这为藏文信息处理的各项任务语料库的构建和研究提供了契机,也为数据的存储和管理带来了挑战,如何有效地组织这些数据并快速地提炼出关键信息就显得尤为重要。文本摘要任务能够将一篇长文本自动地压缩成一个主题性强、信息量大的摘要,这为藏文信息压缩提供了思路。近年来,藏文信息处理技术受到了研究人员关注,但是摘要生成技术发展缓慢,主要表现在:第一,NLP技术中,下游任务的研究对基础任务的依赖较大,藏文电子资源有限,分句和分词等任务研究进展缓慢,大多研究基于规则方法展开,这对研究人员的语言基础要求较高,且每一种方法的数据和评价规则不统一,限制了摘要技术的发展;第二,藏文字的结构及语法有其特殊性,在藏文信息处理过程中,需要研究人员探究出适合藏文语言特点的方法,而不能直接采用其他语言的研究方法。在深度学习的快速发展过程中,研究人员开始探索基于深度学习技术的藏文信息处理,这有利于提高藏文信息处理的效率和准确性,促进藏文的信息化和数字化发展。针对藏文摘要任务,本文从藏文句子边界消歧(Sentence Boundary Disambiguation,SBD)、摘要语料库构建、摘要生成技术三方面展开了研究。首先,研究了基于深度学习方法的藏文SBD,用于对藏文语料分句;然后,基于分句结果用成熟的分词方法对语料进行分词,参照Text Rank算法从篇章中抽取关键句,构建藏文摘要数据集并优化,基于BERT抽取式摘要模型证明了数据集的可用性;最后,引入多元集束搜索算法(Diverse Beam Search,DBS),研究了基于BERT预训练语言模型的多元集束搜索藏文生成式文本摘要方法BERT-DBS,降低生成摘要内容的冗余性。本文主要研究工作如下:(1)研究了基于注意力机制的音节级别藏文SBD。藏文中的标点符号功能特殊,存在歧义,无法直接通过标点符号判断句子结尾。基于规则的句子边界识别方法标准不统一,且规则的覆盖能力有限,无法很好地处理大规模语料。循环神经网络(Recurrent Neural Network,RNN)以序列数据为输入,能够按照序列方式进行递归,注意力机制(Attention Mechanism)具有自适应学习输入序列中不同位置重要性的优势,本文研究了结合RNN和注意力机制的藏文SBD方法RNN＿Att。该方法以音节为训练单元,首先,通过Word2vec模型训练生成藏文的音节向量;其次,设置训练数据的窗口,在模型中进行训练;最后,在英文、德文、泰文三种语言的数据集上进行了泛化性实验。实验结果表明,该方法有效克服了基于规则的SBD方法对分词和词性标注技术的依赖,与序列标注方法相比,在SBD任务上,F1值高出了1.55%～10.53%,同时,基于不同语言的实验有效证明了本文模型在SBD任务中的泛化能力。(2)研究了基于双向长短期记忆网络(Bi-directional Long Short-Term Memory,Bi LSTM)的构件级别的藏文SBD。藏文字既有横向书写规则,又有纵向书写规则,其组字规则要比中文和英文等语言复杂。针对上一研究中,构件级别藏文SBD方法不稳定的问题,本研究同时考虑了标点符号的“上文”和“下文”信息。在实验过程中,引入了窗口的概念,只选择标点符号前后窗口数量的构件(字符)参与训练。对比了单纯考虑左侧、右侧文本和同时考虑两侧文本信息的藏文SBD;其次,在英文、德文、土耳其文、罗马尼亚文四种语言上进行了SBD实验。实验结果表明,基于标点符号两侧文本信息的构件级别SBD方法F1值保持在96%左右,较大规模数据集和多种语言上的实验,证明了模型的泛化能力。(3)基于Text Rank算法构建藏文摘要数据集并验证其质量。本文在上述关于藏文SBD研究的基础上,参照Text Rank抽取式摘要的算法,构建了一个面向藏文新闻领域的长文本摘要数据集;根据Lead-3思想,构建了一个藏文短文本摘要数据集。为了验证数据集的性能,研究了基于Sentencepiece和BPE两种切词方式的BERT和公开的Ti BERT预训练语言模型上的藏文抽取式文本摘要。实验结果表明,基于Text Rank算法构建的摘要数据集性能优于Lead-3思想生成的数据;Sentencepiece比BPE更适合藏文BERT预训练语言模型中的切词。BERTclassifier、BERT-Transformer和BERT-RNN模型的ROUGE-1和ROUGE-L比Transformer分别提高了将近10%,ROUGE-2提高了8%。(4)研究了基于BERT多元集束搜索的藏文生成式文本摘要方法BERT-DBS。对于藏语等低资源语言,其训练数据有限,训练过程中较难提取到词的语义信息,容易出现生成的摘要不能充分表达原始文档含义的现象。BERT-DBS方法采用BERT预训练语言模型进行编码,采用Transformer进行解码,在摘要生成的过程中,引入多元集束搜索算法,通过多样性因子生成多种候选序列,选择最佳的候选序列作为输出。在构建的藏文摘要数据集上将该方法在Sentencepiece和BPE两种切词方式的BERT和公开的Ti BERT预训练语言模型上进行了实验。实验结果表明,BERT-DBS方法生成的摘要能够充分捕获原始文本含义,有效避免了生成摘要的高复制比,提高了藏文摘要生成的性能。BERT-DBS在长文本摘要上的ROUGE-1、ROUGE-2和ROUGE-L与BERT相比,分别提升了6.58%、3.85%、3.77%,BERT-DBS在短文本摘要的ROUGE-1、ROUGE-2、ROUGE-L与BERT相比,分别提升了2.97%、0.63%、1.24%。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2023.003772
{DOI}: 10.27204/d.cnki.glzhu.2023.003772
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CRF和深度学习的数学试题知识点自动标注算法研究
{Author}: 孟婉颖
{Tertiary Author}: 葛志昊;杨文娣
{Publisher}: 河南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识点自动标注;命名实体识别;深度学习;高中数学;自然语言处理
{Abstract}: 在互联网信息时代,教育不断朝着智能化趋势发展.智能题库是教育智能化的重要组成部分,对于教育质量和效率的提升有着重要的作用.而准确的试题知识点自动标注是完成诸如个性化认知诊断、个性化试题推荐等智能题库任务的基础.因此,如何准确、自动的进行试题知识点标注具有重要的研究意义.目前,对于试题知识点自动标注的研究,主要集中在文史科目,而对于数学等理科科目的研究还较少.由于数学试题中含有大量公式,直接使用通用领域的文本分类技术,难以保证知识点标注的精度.因此,本文以高中数学试题作为研究对象,首先,针对数学题目的特殊性,研究了数学公式的抽取与表示;其次,对比分析TextCNN模型、Transformer模型和本文构建的TextCNN-Transformer组合模型在高中数学试题多知识点自动标注任务中的分类效果,具体研究内容如下:(1)公式的抽取与表示.本文将试题中出现的公式总结为17种实体类别;经过对比分析后,选择利用条件随机场(Conditional Random Fields,CRF)模型,将试题中的公式映射为实体类别,然后使用相应的实体类别对公式做出替换,在去除噪声的同时,尽可能的保留了原始题目中存在的信息.(2)基于深度学习的试题知识点的自动标注.本文融合TextCNN模型和Transformer模型,构建了TextCNN-Transformer组合模型.此模型通过结合TextCNN层提取的文本局部特征和Transformer层提取的文本长期依赖关系,优化了特征抽取工作.实验结果表明,在高中数学实体替换后的数据集中,使用TextCNN-Transformer组合模型进行知识点自动标注,取得了94%的精准率和85.48%的召回率.与TextCNN模型和Transformer模型相比,本文构建的模型在各项评估指标中均有不同程度的提升.研究结果表明,本文所构建的方法对试题知识点自动标注有良好的效果,在学生个性化认知诊断、个性化试题推荐等方面具有一定的实用价值.
{URL}: https://link.cnki.net/doi/10.27114/d.cnki.ghnau.2023.001682
{DOI}: 10.27114/d.cnki.ghnau.2023.001682
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义完备性的Transformer语言模型研究及应用
{Author}: 李育璠
{Tertiary Author}: 黑新宏;朱磊;陈志颖
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: Transformer;语义完备性;命名实体识别;关系抽取;预训练;语义表示
{Abstract}: 近些年,自然语言处理已成为人工智能重要的研究方向,其中以Transformer为基础的预训练语言模型更是吸引了大量学者的关注。Transformer通过自注意力机制表示单个词元与其余词元之间一对多的关联性,并且通过训练得到词嵌入,从而更好地描述文本的语义。但是,现有基于Transformer的语言模型着重于词级别的表征,未能深挖句子、段落、篇章等层级上进行语义表示。针对这一问题,本文提出了语义完备性(Semantic Completeness,SC)特征,并将该特征应用到命名实体识别和关系抽取中进行特征增强,从而提升下游任务的性能。本文具体研究内容如下:(1)提出基于语义完备性的命名实体识别方法。在解析现存语言模型中语义相似度的基础上,提出了语义完备性以表示句子间的关联信息。并且,以语义完备性理论为基础,使用Transformer框架,改进基于片段排列的命名实体识别模型,提出了优化的SCM-E(Semantic Completeness Model-Entity)模型。该模型中,一方面利用遮盖-对比的方法构造语义完备性表示向量,另一方面在BERT的基础上提出了一种新的预训练任务Sim-WWM(Similarity-Whole Word Mask),提升模型对实体的理解能力。实验表明,基于语义完备性的SCM-E模型在多个数据集上均有显著提升,特别是在ADE数据集上相较于基线模型提高了 3.15%。(2)提出了基于语义完备性的关系抽取方法。针对关系分类中的文本依赖问题,提出了一种新的分析方法,将关系分类所依赖的文本划分为了Si和So。在此基础上,利用语义完备性理论分析Si和So对关系分类的贡献,提出了优化的SCM-R(Semantic Completeness Model-Relation)模型。该模型使用Transformer框架,通过语义完备性向量对Si和So进行结合,构造关系依赖向量辅助关系分类。实验结果表明,SCM-R模型在多个数据集上均表现出色,最高相较基线模型提升了 5.40%。(3)搭建多任务自然语言处理平台。结合之前的研究,将命名实体识别任务、遮盖预测任务、语义相似度计算任务整合至统一平台,并保留扩展空间用于增加更多任务。平台对不同任务的结果均进行了可视化,使用户的交互过程更加友好。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000475
{DOI}: 10.27398/d.cnki.gxalu.2023.000475
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 暗网多平台用户身份对齐方法研究
{Author}: 杨燕燕
{Tertiary Author}: 杜彦辉
{Publisher}: 中国人民公安大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 匿名空间;信息抽取;数据增强;注意力机制;用户对齐
{Abstract}: 网络攻击、非法交易和网络谣言等网络公害严重影响社会稳定和国家安全。随着国家管控力度加大,其生存空间逐渐由明网向深暗网等匿名空间转移。网络公害匿名化给执法人员的侦察和取证工作带来挑战,是网络空间管控领域一大难题。对网络用户身份进行侦察和识别是网络公害治理案件中线索发现和侦办的主要内容,是打击网络犯罪工作的基础。当前网络用户身份的侦察主要依靠网络地址和网络身份特征等传统侦察手段,由于匿名空间中无法获取真实的网络地址和有效的网络身份特征,传统侦察手段在匿名空间中难以产生效果,亟需研究针对匿名空间网络用户身份侦察的新方法。论文针对警务实战中匿名空间用户身份侦察困难,缺乏有效的用户对齐方法开展研究,提出了基于暗网文本写作风格的用户对齐新方法,解决了匿名化带来的网络管控问题。针对网络空间匿名化用户身份侦察困难的问题,论文以网络犯罪行为频发的暗网为研究背景,通过研究基于文本写作风格的暗网用户身份识别方法,重点解决暗网多平台用户身份线索挖掘和关联、暗网文本样本稀疏、暗网文本特征提取和暗网用户身份对齐建模等方面问题,采用基于启发式规则的多类别身份线索挖掘方法、基于信息抽取的用户身份线索关联方法、基于原型网络的用户文本内容增强方法,从用户级和内容级两方面进行数据扩充。同时结合自注意力增强卷积的文本特征提取和用户与网络交互的过程,从文本的写作内容和用户的网络行为两方面融合进行建模开展多任务学习,提出了暗网多平台用户身份对齐的新方法,显著提升了匿名网络用户身份侦察的准确性。论文主要创新工作如下:(1)针对暗网中多平台的同一用户的多个身份信息难获取的问题,提出了少样本的跨平台用户身份线索关联方法。该方法通过启发式规则对暗网网页中的用户身份线索进行挖掘;通过信息抽取技术构建有监督的共指关系抽取模型CRE(Coreference Relation Extraction)达到跨平台自动化关联同一用户的多个账户信息;通过多任务低资源条件下构建面向少量标注的用户身份线索关联方法,有效降低了模型对大规模标注样本的依赖,实现获取更为丰富的用于用户身份对齐训练数据的目的。通过该方法,构建了暗网用户身份信息数据集DID(Darknet User Identity Information Dataset),论文所提方法与多种经典的关系抽取模型在DID数据集上相比表现出更好的性能。(2)针对暗网用户发帖量不足难以确定写作风格的问题,提出了一种基于原型网络的用户文本内容增强方法。该方法通过设计可保持语义一致的中文文本变换策略、构建原型网络的对抗样本生成模型AEGP(Adversarial Example Generation with Prototypical)进行变换片段选择,实现在内容层增强写作风格同一认定数据的目的。论文所提出的对抗样本方式的数据增强方法,既具有多样化也在通用性上有所提升。(3)针对面向短文本的身份对齐方法处理全局和长序列信息欠缺的问题,提出了一种融合写作风格与网络行为的用户身份对齐方法。该方法采用自注意机制增强卷积,利用全局信息和长序列信息获取写作风格;同时引入元路径信息对用户在暗网的网络行为进行建模,结合文本嵌入、时间嵌入和上下文嵌入多个维度,构建融合文本特征和网络行为的多任务学习模型FTNB(A Multi-task Learning Model that Fuses Text Features and Network Behavior),实现了面向暗网多平台用户对齐任务,并提升了对齐效率。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2023.000004
{DOI}: 10.27634/d.cnki.gzrgu.2023.000004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的任务导向型对话系统算法研究与应用
{Author}: 格桑汪姆
{Tertiary Author}: 胡铮
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 任务导向型对话系统;智能问答;深度学习;自然语言处理
{Abstract}: 随着人机对话系统在客服、智能家居等领域得到广泛应用,以应用范围广、服务效能高为特点的任务导向型多轮对话技术备受关注。任务导向型对话系统通常采用基于流水线的框架进行开发,即包含自然语言理解(Natural Language Understanding,NLU)、对话状态追踪(Dialogue Sate Tracking,DST)、策略学习(Policy Learning,PL)和自然语言生成(Natural Language Generation,NLG)四个模块。其中,DST模块是基于流水线结构的任务导向型多轮对话系统的核心模块,目前在跨领域小样本场景下,存在追踪能力不足的问题;此外,新领域任务导向型多轮对话系统的开发框架仍值得探索。针对跨领域小样本场景下,对话状态追踪模块的识别准确性较低的问题,本文提出了一种将可见模版与连续可学习模版相结合的基于提示学习的编码器-解码器对话状态追踪模型(Fusion Prompting Dialogue State Tracking,FP-DST)。FP-DST 模型利用可见模版来引导连续可学习模版对槽位描述进行初始化,然后通过连续可学习模版进一步优化槽位描述的表征,从而能有效利用大规模预训练语言模型积累的先验知识,以在小样本场景下获得更高的追踪识别准确性。围绕联合准确率的指标,通过实验验证了其可行性。面向新领域任务导向型多轮对话系统的开发需求,本文设计了基于流水线的可支持多领域的任务导向型多轮对话开发框架。其中,在NLU和NLG模块均使用基于BERT编码器-软门控复制增强的GRU解码器的结构,以提升框架在跨领域场景的上下文理解力和生成回复的多样性。通过在中文多领域多轮对话数据集CrossWOZ上的实验表明,该框架在不同领域对话内的意图识别准确率为80.72%,回复生成与标签数据的BLEU相似度为32.17%,从而验证了该框架的实用性。最后,面向冬奥主题旅游应用场景,本文开发了一套面向冬奥主题旅游应用场景的中文任务导向型多轮对话原型服务。构建了北京、张家口的冬奥主题旅游对话语料数据集,以及两地酒店、景点、餐厅等本体数据。本文运用提出的开发框架对冬奥对话原型服务进行开发,包括算法模块的训练、微调及系统的部署。接着,完成了单领域、跨领域的测试用例上的功能性测试。该对话系统在自建冬奥对话语料数据集上的意图识别准确性测试中,取得了 99.7%的F1准确率。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000823
{DOI}: 10.26969/d.cnki.gbydu.2023.000823
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本及图文匹配算法研究
{Author}: 陈启岗
{Tertiary Author}: 杨春霞
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本匹配;图文匹配;依存句法;注意力机制;图注意力网络
{Abstract}: 在多媒体大数据的时代背景下,全球数据规模呈爆炸式增长,数据类型也呈现出多样化的趋势,其中文本和图像这类数据最为常见。文本及图文匹配技术能够帮助用户从海量的数据中快捷精准地查询到有价值的信息,故研究数据匹配具有十分重要的意义。本文将基于深度学习的方法研究文本及图文匹配任务中细粒度对应的问题,主要工作与创新如下:(1)针对现有的文本匹配方法未同时融合单词、短语和句子等多粒度信息的问题,本文提出了基于多粒度信息交互的文本匹配模型(MGII)。该模型首先通过双向长短期记忆网络生成具有上下文信息的单词表示,采用卷积神经网络生成具有局部信息的短语表示,采用自注意力机制和最大池化生成具有全局语义信息的句子表示。其次通过交互注意力机制将文本中的每个单词与另一个文本的三种粒度的信息进行交互,并对三种交互结果进行聚合生成两个文本的最终表示。实验结果表明,与使用单一粒度或结合两种粒度的模型对比,MGII在两个文本匹配数据集上取得了较好的性能。(2)虽然MGII模型融合了单词、短语和句子多个粒度的交互信息来生成文本表示,获得了较好的匹配结果,但是它忽略了文本的句法结构信息,故本文提出了一种基于依存句法和图注意力网络的文本匹配模型。具体地,该模型先通过依存句法分析获取单词之间的依存关系,并设计两种图构建策略将句法依存关系编排到语义图中。其次使用图注意力网络对语义图编码,生成具有句法结构信息的文本表示。实验结果表明,考虑依存句法关系可以帮助模型捕获文本的深层次语义关系,从而进一步提高文本匹配任务的准确率。(3)现有的图文匹配方法存在属性词和视觉对象难以对应,以及区域关系和关系词难以对齐的问题,对此本文提出了基于视觉语义跨模态注意力网络的图文匹配模型。该模型首先使用视觉对象的外观特征及其空间关系构建视觉图,使用语言特征及句法依存关系构建语义图。其次利用图卷积网络对视觉图和语义图进行编码,分别得到包含空间关系和语法结构关系的节点表示。然后通过跨模态注意力机制建模区域和单词的细粒度对应关系,生成视觉节点和语义节点的最终表示。实验结果表明,由文本检索图像时,本章所提模型与性能最好的基线模型对比,在R@1、R@5、R@10三个指标上分别提高1.1%、0.7%、1.4%。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2023.000868
{DOI}: 10.27248/d.cnki.gnjqc.2023.000868
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向中文的混合嵌入文本表征方法研究
{Author}: 范晓明
{Tertiary Author}: 王斌君
{Publisher}: 中国人民公安大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 自然语言处理;深度学习;文本表征;汉字编码;亚字嵌入
{Abstract}: 近年来,基于深度学习的文本表征技术取得显著进步,在自然语言处理领域发挥着重要作用。英文环境下,以神经网络为核心的表征方法已相对成熟,以“character、subword、word”为令牌的多粒度表征体系已基本完善。通过不同粒度令牌的独立或混合嵌入,表征模型有效实现了对文本特征的自动抽象与提炼。其中,以character和subword为令牌的表征模型不仅解决了未登录词问题,还具有明显的性能优势,是学术和工业界的主流方法,也是目前的研究热点。由于语言的差异性以及象形文字的特点,中文表征技术还存在字符和子词粒度令牌体系不完整、未登录词问题未有效解决等短板。针对这些问题,本文围绕中文字词内蕴特征挖掘及其深度融合展开中文文本表征研究,提出小字符集约束下的中文亚字粒度表征模型,并据此构建了“爻、字、词”为令牌的中文分层嵌入体系以及相应的字词混合嵌入方案,主要研究内容和创新点如下:1.针对中文令牌体系的不足,提出了“辞帽”模型(CHARM),实现了小字符集约束下的中文亚字粒度表征。模型为汉字提供由拉丁字母表示的助记缩略符,也称作相码,通过爻辞结构实现了音形特征的显性融合和可逆映射。基于相码构建的“爻、字、词”三层令牌体系,为中文亚字(爻级)嵌入提供了一种更加简洁、高效的方案,也降低了中英文嵌入模型间的迁移成本。2.针对未登录词问题,以字嵌入为突破点,提出基于相码的爻特征融合机制,也称“合步”机制。结合卷积神经网络、循环神经网络、自注意力机制等深度学习技术,设计了适应不同任务的“爻-字”混合嵌入模型,并在文本分类、命名实体识别、通用预训练任务中进行了实验验证。对比实验表明,基于合步机制改进的字嵌入模型,能有效解决未登录词问题,性能也有不小的提升。其中,用于通用预训练任务的“承步”模型(CHARMNBERT),在多项测试中拥有最佳表现,可为下游任务提供质量更好的字嵌入。3.立足多粒度混合嵌入质量的提升,将合步机制延伸至词嵌入模型中。发挥相码的亚字嵌入优势,将爻、字、词多粒度特征进行有效融合,实现了基于混合词嵌入的预训练模型Charm2Vec(辞串模型)、Wo Ch BERT(沃步模型),并在文本分类任务上验证了以上模型的有效性和实用性。在公开数据集和专用数据集上的验证结果表明,经合步机制改进的模型,性能上均有不错的增幅。特别是沃步模型,在同一级别的任务中表现出色,具有很强的适应性、实用性。以上工作,弥补了中文文本表征体系中字符和子词嵌入表示的不足,有效解决了中文未登录词问题,降低了中英文模型间的迁移成本。对文本分类、情感分析、舆情分析、命名实体识别等下游任务,本文所提方法均能提供更有竞争力的底层支持。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2023.000384
{DOI}: 10.27634/d.cnki.gzrgu.2023.000384
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Albert和多头自注意力机制的图神经网络文本分类的研究
{Author}: 潘鹏程
{Tertiary Author}: 殷丽凤;李波
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本分类;图神经网络;预训练模型;Albert;多头自注意力机制
{Abstract}: 自然语言处理是计算机科学领域中的一个重要的方向,而文本分类是其众多实际应用之一,经历了由浅层学习模型到深度学习模型的转变。在研究过程中,有学者提出利用图神经网络来进行文本分类,图神经网络能够更好的捕捉句子间语义的关系,但还是存在对同一词向量在不同的上下文中所代表的含义会有所不同以及容易忽视词语之间更深层次的语义交互的问题。因此,为了克服这些问题,本文进行了以下研究:
首先,本文提出了一种基于Albert和多头自注意力机制的图神经网络文本分类模型(Albert＿MSA＿GNN)并应用于文本分类任务。Bert是一种预训练语言模型,本文引入了一种基于Bert的轻量级模型Albert来获得输入文本的预训练词向量,经过预训练模型处理之后的词向量具有更丰富的上下文语义信息以及句子间更长距离的语义关系。此外,将输入的文本做数据预处理,并且引入预训练词向量模型Albert对预处理后的数据进行特征提取,生成文本的词向量表示并将文本数据转化为文本图结构。
其次,将Albert输出的词向量通过多头自注意力机制进行特征提取得到特征向量,使得Albert模型生成的词向量具有更深层次的语义交互,之后在原有图神经网络的基础上,本文提出了基于分配词权重的消息传播方法,并将生成的文本图传入图神经网络并生成一组经分类器训练后的标签向量。然后将多头自注意力机制提取到的特征向量与图神经网络生成的标签向量整合连接线性层FC和softmax层做文本多分类概率输出。
最后,通过与七种不同的基线神经网络文本分类模型在新闻、医药以及电影三种不同领域的四个公开的数据集上进行对比实验,结果表明,本文提出的Albert＿MSA＿GNN模型相较其他对比文本分类模型在不同领域的数据集上的分类效果具有更高的准确率以及F1值,另外本文通过一系列相关对比实验也可多方面验证本文所提模型的有效性。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000185
{DOI}: 10.26990/d.cnki.gsltc.2023.000185
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合多级别特征的医学命名实体识别研究
{Author}: 甘晨阳
{Tertiary Author}: 李明
{Publisher}: 重庆工商大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学命名实体识别;多级别特征融合;GlobalPointer;嵌套实体;BERT
{Abstract}: 随着互联网技术的快速发展,计算机技术在医疗领域的应用越来越受到学术界的重视。作为人口大国,我国拥有丰富的医疗资源,同时也产生了大量的医学文本数据。如何将这些医学文本数据与先进的计算机技术相结合,以提高医疗领域信息化水平和提升医学知识查询效率成为研究的重点。因此将自然语言处理中的命名实体识别任务应用到医学领域,显得顺理成章。通过利用命名实体识别技术提取医疗文本实体,可以建立医疗相关知识图谱,从而可以更快速的梳理复杂医学知识的脉络。为了进一步提高医学实体识别的准确率,本文开展了命名实体识别方法的研究,并从提升医学领域实体识别的精确率、缩短模型的训练时间、提升医学嵌套实体识别的精确率这三个方面进行了研究,具体研究内容为:(1)针对医学领域命名实体识别的准确率较低的问题,本文提出一种新的词嵌入表示方法。首先,通过简单循环神经网络训练医学文本得到字符级向量表示。然后使用GloVe模型获取医学文本的词级向量表示;最后,使用预训练模型BERT动态生成医学文本的向量表示,并将三种向量表示拼接起来。实验结果表明,相比传统的Word2vec词向量表示,本文提出的融合多级别特征的词嵌入模型在GENIA和NCBI-disease两个数据集上精确率、召回率和F1值均得到了提升。(2)针对命名实体识别模型训练时间过长的问题,提出一种新的门控循环单元结合GlobalPointer的医学命名实体识别模型。相比LSTM,门控循环网络在单个神经元上优化了内部门控结构。相比于条件随机场,GlobalPointer对上下文更加具有全局观,避免了条件随机场的复杂递归运算。这两处改进从整体上缩短了命名实体识别模型的训练时间。在GENIA数据集和NCBI-disease上,本文方法将模型的训练时间缩短了22%到30%。同时也研究了ROPE位置编码对GlobalPointer模型的影响,实验结果表明,加入ROPE位置编码后可以将GlobalPointer模型的性能平均提升9.41%。(3)针对医学命名实体识别中嵌套实体识别难度大,识别精度低的问题,提出了一种基于分层双向门控循环单元网络和文本卷积神经网络的模型。首先,使用文本卷积神经网络获取文本的局部特征,以弥补门控循环网络对于局部特征的提取能力不足。其次,使用门控循环网络进行分层叠加,每一层网络对应处理一层嵌套关系,以提高嵌套实体的识别精度。实验结果表明,在GENIA数据集、ACE2005数据集和BC2GM数据集上本文提出的模型均取得了较高的精度。
{URL}: https://link.cnki.net/doi/10.27713/d.cnki.gcqgs.2023.000691
{DOI}: 10.27713/d.cnki.gcqgs.2023.000691
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱嵌入的多跳问答方法研究
{Author}: 牛园园
{Tertiary Author}: 江赟
{Publisher}: 重庆工商大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 问答系统;知识图谱;知识图谱嵌入;时序知识图谱
{Abstract}: 知识图谱是一种知识库,目前在很多现实场景任务都得到了广泛应用,如推荐系统、问答系统以及信息检索等领域。基于知识图谱的问答方法是人工智能领域和信息检索领域的重要研究热点。根据问题在知识图谱上推理路径的长度,知识图谱问答方法可以分为单跳问答和多跳问答,其中多跳问题还可能带有时间约束或者隐式等信息。在实际应用中,一方面,用户倾向于表达复杂的多跳推理的自然语言问题,这就需要具有较强的长路径建模能力。知识图谱都是不完整的,会缺失很多信息,这就给知识图谱多跳问答带来更大的挑战。另一方面,传统的知识图谱没有考虑时间信息,在面对带有时间约束的问题时,基于知识图谱的问答方法不能有很好的表现,因此,研究者们提出了时序知识图谱。时序知识图谱虽然包含了时间信息,但针对时间知识图谱问答开发的方法很少。而且现有的时间知识图谱问答方法侧重于语义或时间级匹配,缺乏推理时间约束的能力。为了解决上述问题,本文主要研究了以下两方面内容:(1)本文提出一种基于关系路径的知识图谱嵌入多跳问答模型,使用知识图谱嵌入解决了知识图谱稀疏导致的链路缺失的问题,使用知识图谱中实体之间的丰富语义提升模型问答准确率,并对问题和关系的进行表示增强。本文提出了复杂问题的语义提取模块和关系检测模块,其中语义提取模块用自注意力机制对问题进行增强表示,能够更加准确地获得复杂问题的多重语义。关系检测模块是将主题实体和候选实体的关系路径提取出来,最后与问题进行语义匹配。将本文提出的模型在完整的Meta QA数据集以及不完整的Meta QA数据集上进行实验,实验表明,本文提出的方法的准确率较高。(2)本文提出一种基于时序知识图谱嵌入的多跳问答模型,由四个模块组成:知识图谱嵌入聚合模块,问题处理模块,路径推理模块,答案预测模块。知识图谱嵌入聚合模块对实体和关系进行语义增强表示,首先使用图注意力网络,融合了当前结点信息和邻居结点的信息去增强实体表示,丰富了实体的语义关系,增加了邻居信息。其次使用神经网络将时间信息聚合到关系信息中去,丰富了关系中的时间演化信息。问题处理模块获得了时间约束信息和时间约束关系,并得到融合了上下文信息、时间信息和实体信息的问题特征表示。通过路径推理模块可以提取出与问题主题实体相关的子图,并用时间约束进行剪枝,得到满足时间约束的关系路径。最后在答案预测模块得到最终答案。在Cron Questions和Complex-Cron Questions数据集上评估模型,证明本文提出的方法准确率较高。
{URL}: https://link.cnki.net/doi/10.27713/d.cnki.gcqgs.2023.000693
{DOI}: 10.27713/d.cnki.gcqgs.2023.000693
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向高速铁路道岔故障维修领域的知识图谱研究与应用
{Author}: 卢冉
{Tertiary Author}: 林海香;马腾云
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 高速铁路道岔;故障文本数据;深度学习;知识图谱;自动问答系统
{Abstract}: 高速铁路道岔作为高速列车运营过程中的关键地面信号设备,在高速列车实际运行的过程中,其一旦发生故障会对高速铁路运行的效率和安全产生极大影响。因此,高速铁路道岔的故障维修需要充分发挥技术优势,依托大数据研究高速铁路道岔故障维修方法,辅助高速铁路道岔维护人员进行故障维修,以提高维修效率。高速铁路多年来的运营积累,产生了大量以自然语言方式记录的高速铁路道岔故障文本数据。但当前针对道岔故障维修领域非结构化文本数据的研究,未能充分挖掘出数据中蕴含着丰富的故障知识,仅仅是根据故障诊断结果进行粗略定位,并不能表示出道岔故障时各要素之间的复杂联系。为解决上述问题,本文将知识图谱技术应用至道岔故障维修领域,以高速铁路道岔故障文本数据集为基础,通过知识图谱技术挖掘出道岔故障各要素之间的内部联系,提高维修效率。论文的主要研究内容如下:（1）构建高速铁路道岔故障实体识别语料库。在命名实体识别的初期,需要具有标注好的数据集,但当前高速道岔故障维修领域并没有公开的标注好的数据集,因此本文首要任务就是构建高速铁路道岔故障语料库。首先定义了8种故障实体类型,后续采用“精灵标注助手”软件对高速道岔故障数据集进行文本序列标注,最后将数据处理成实体识别模型允许输入的BIO格式,从而实现高速铁路道岔故障实体识别语料库的构建。（2）建立高速铁路道岔故障维修领域实体识别模型。利用构建完成的高速铁路道岔故障语料库作为实验数据集,建立BERT-Bi LSTM-CRF命名实体识别模型,模型首先通过基于Transformer的预训练语言模型（Bi-directional Encoder Representations from Transformers,BERT）获取上下文语义信息的高质量词向量表示,其次将BERT获取到的词向量输入至双向长短时记忆神经网络（Bi-direction Long Short Term Memory,Bi LSTM）,从而学习上下文语义特征,并为各类标签打分,最后将得分标签序列通过条件随机场（Conditional Random Field,CRF）模型增加约束,输出最优标签序列。通过实验分析,本文建立的实体识别模型的精确率、召回率、F1值分别达到93.41%、92.93%和93.17%。并且通过对比实验显示,本文模型在以上三种指标上均优于其他实体识别模型。（3）提出基于规则的高铁道岔故障实体关系抽取方法。为提升领域知识图谱的质量,采用基于规则的关系抽取方法,在道岔维修领域专家的指导下,根据故障数据集的特点制定关系抽取的规则模板,最后再请领域内的不同专家按照制定的规则利用置信度打分的方式进行实体间的关系判断。该方法虽然是人工进行关系抽取,但是抽取规则以及关系判断均由领域专家指导,抽取的关系正确性高,能显著提高知识图谱知识质量。（4）构建高速铁路道岔故障维修领域知识图谱。构建的领域知识图谱分为命名实体识别、关系抽取、知识融合和知识存储四个步骤,在知识融合部分,运用了知识融合的关键技术——实体对齐,利用基于文本相似度与语义相似度算法分别实现了结构相似的同义故障实体与结构相似但语义不同的故障实体的对齐。根据实体识别、关系抽取以及知识融合得到三元组数据结果,构建高速铁路道岔故障维修领域知识图谱,利用Neo4j图数据库实现知识储存和图谱可视化呈现。最后设计基于高速铁路道岔故障维修领域知识图谱的自动问答系统。该系统基于Fast API的web框架下开发,实现了问题解析功能、查询语句生成功能、数据库连接功能、答案转化功能、界面显示功能。用户可以使用此系统完成故障类型的识别、找到故障间的内在联系和隐含知识、提供维修措施的建议。系统有效的辅助了工作人员对高铁道岔故障的维护,推动现场工作更加高效地运转。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2023.001012
{DOI}: 10.27205/d.cnki.gltec.2023.001012
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT模型的新闻文本自动摘要研究
{Author}: 董文超
{Tertiary Author}: 陈鑫影
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 抽取式文本摘要;预训练语言模型;DistilBERT;BERTSUM
{Abstract}: 近年来,互联网技术的飞速发展为人们的日常生活带来了巨大的便利,但也不可避免地导致了信息的迅猛增长,如何在这种情况下快速、高效地获取所需的资讯变得尤为重要。自动文本摘要技术的出现可以有效缓解该问题,其作为自然语言处理和人工智能领域的重要研究内容之一,利用计算机自动地从长文本或文本集合中提炼出一段能准确反映源文中心内容的简洁连贯的短文,算法包括特征评分、分类算法、线性规划、次模函数、图排序、序列标注、启发式算法、深度学习等。本文通过深入探讨数据集和评估指标等相关知识,提出了轻量化的自动文本摘要模型,并预测了未来可能出现的挑战及发展趋势。任务可以分为抽取式和生成式两种方法:在抽取式摘要方法中,模型通过从源文本中选择有意义的句子来生成摘要;在生成式摘要方法中,模型通过对源文本进行编码,利用机器学习生成摘要。上述两种方法在文本摘要任务上,已进行了多种形式的研究并取得较为优异的结果,其中包括基于图、基于深度学习等方法。大规模预训练语言模型在自然语言处理任务中的使用变得越来越普遍,但面对算力不足、运算资源有限等问题,运行这些体量大的模型仍然具有挑战性。本文的主要创新点有3条:(1)针对传统的文本摘要模型参数多、运算耗时长等问题,本文基于改进BERTSUM模型,探索了BERT模型的蒸馏变体DistilBERT在CNN/DM数据集上所表现出的摘要性能,并由此提出了一种轻量化抽取式摘要模型——DistilSum。(2)针对模型轻量化的工作,本文依托知识迁移,使用教师-学生网络,提出了另一种轻量化抽取式摘要模型——MobileSum。此模型更适合应用于手机等低资源设备上,相较于DistilSum模型,它的模型参数更少,训练速度更快。(3)为了提升模型性能,本文在模型中改进并引入了结构化注意力,与模型的摘要判断层联合使用,为备选句子进行打分,最终帮助模型选择出最优top-n个句子作为文档摘要。经过实验对比分析,DistilSum模型保证了原模型99.9%的性能,同时缩减了约36%的训练参数,大幅减少了训练时间。MobileSum模型保证了原模型94%的性能,同时缩减了79%的模型参数,成功实现了模型的轻量化。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000051
{DOI}: 10.26990/d.cnki.gsltc.2023.000051
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向边缘端智能芯片的神经网络训练算法研究
{Author}: 周扬帆
{Tertiary Author}: 刘欣
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 边缘计算;人工智能芯片;深度学习;训练算法;在线学习;凸优化
{Abstract}: 边缘计算是有效解决隐私保护、带宽限制、通信延迟等问题的重要手段,也是实现万物智联的重要技术。在边缘计算的应用场景中,人工神经网络算法是端侧实现智能决策的重要方法。在当前人工智能芯片体积和功耗严格受限、边缘计算应用场景高度动态的背景下,如何高效、低成本地训练人工神经网络模型参数这一问题已经受到了各国政府、大型企业和研究机构的高度关注。为了应对上述问题,当前的研究主要通过云端训练-端侧部署的方式实现神经网络在边缘端的推理应用。然而,在高速变化的边缘计算应用场景中,不仅需要在云端完成对神经网络模型的预训练,从而获得一个较高精度的初始模型,而且要在边缘端人工智能芯片的推理过程中实现模型的在线训练,从而不断提升模型精度。一方面,在云端完成的预训练任务受到硬件算力限制的影响较小,因此为了获得高精度的初始化模型,需要解决训练算法收敛速度慢、泛化能力弱的重要问题;另一方面,在边缘端进行的在线训练任务受到人工智能芯片体积和功耗的严重影响,因此为了实现在边缘计算场景下模型精度的不断提升,需要解决训练算法计算成本高昂的关键问题。针对上述重大挑战,本文分别在神经网络预训练阶段和边缘端在线训练阶段提出了系统的快速收敛、高泛化、低计算成本的训练算法,为在人工智能芯片上实现可持续提升精度的神经网络模型提供了可行的解决方案。本文的主要研究内容如下:1.面向预训练阶段的快速收敛、高泛化的训练算法强凸条件下的自适应在线优化算法。针对凸优化算法收敛速度慢的问题,本文提出一种快速收敛的自适应在线优化算法。首先,重新设计了自适应算法中二阶动量的形式,分析了算法在该形式下的步长选择更加贴近理想步长;其次,通过理论证明得出,所提算法在在线理论框架下的后悔界可以达到O(logT),其中T表示迭代次数,比传统自适应凸优化算法的收敛速度(O((?)))更快;最后,在公开数据集上完成了充分的仿真实验,且结果表明所提算法具有更快的收敛速度和更好的泛化能力。基于Bandit抽样的快速自适应优化算法。针对无效样本对模型训练的干扰问题,本文利用Bandit抽样方法在每轮迭代时选择有效的训练样本,不仅提升了算法的收敛速度,而且提高了算法的泛化能力。当损失函数为凸时,提出了一种基于Bandit抽样的自适应在线优化算法AdaBeliefBS,通过理论证明得出该算法的具有确定的上界,并且当特征向量服从双重尾分布式,该算法的后悔界为O(d(?))+O((?)),比原始优化算法的后悔界更紧;当损失函数为强凸时,提出了一种基于Bandit抽样的强凸优化算法SAdamBS,并证明了其收敛性,且当特征向量服从双重尾分布时,所提算法的后悔界可以更紧,为O(d log(Tlog2N/KN2logd))。仿真实验结果表明所提出的两种改进算法均比其原始版本的收敛速度更快、泛化能力更强。2.面向人工智能芯片端在线训练的低计算成本训练算法无投影自适应在线凸优化算法。针对优化算法计算高阶投影算子的问题,本文利用Frank-Wolfe优化技术将高阶投影算子替换为一维线性搜索步骤,从而大大降低了算法的迭代成本,提出了一种新的无投影自适应训练算法LigthtAdam。该算法迭代成本低,可以帮助边缘端智能芯片实现深度模型的在线训练。经过理论证明,该算法的后悔界为O(T3/4),并且该理论结果得到了多组仿真实验的验证。最后,为了保持该算法的泛化能力,对算法的动量形式进行了重新设计,并分别从理论和仿真实验上论证了该算法的泛化性能得到提升。在凸条件下,LigthtAdam的计算成本比其他主流算法降低15%以上。该算法的计算成本完全满足边缘端人工智能芯片的功耗要求。非凸条件下的随机坐标块自适应优化算法。针对高维特征向量梯度计算成本高昂的问题,本文提出一种随机坐标块自适应优化算法RAda。该算法利用随机坐标块优化技术在迭代时随机选取高维特征向量的一个坐标块进行梯度计算,从而解决了高维特征向量运算的高昂计算成本问题,并为在边缘端智能芯片上实现在线训练提供了另一种选择。经过理论证明得出,该算法在损失函数为非凸的条件下收敛,且算法的一阶随机复杂度为O(1/δ2),可实现δ精确解。仿真实验表明,在非凸条件下所提训练算法的计算成本比其他主流非凸训练算法降低24%以上。RAda为在功耗严重受限的边缘端实现模型在线训练提供了有效的解决方案。总的来说,针对边缘端人工智能芯片体积功耗和成本资源严格受限的难点问题,本论文通过模型预训练和在线训练,以及芯片端仿真实验,开展面向边缘端智能芯片的高效、低成本神经网络训练算法研究,具有重要的理论意义和实用价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.000290
{DOI}: 10.27517/d.cnki.gzkju.2023.000290
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的网络图片敏感文字检测技术研究
{Author}: 张惠民
{Tertiary Author}: 杨飚
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 敏感图片检测;DRRG;ABINet;BERT
{Abstract}: 随着互联网络的普及,人们越来越习惯从网络上获取信息,网络给人们带来便利的同时也给犯罪分子提供了机会。近些年来,很多嵌入敏感文字信息的图片传播广泛,由于不法人员把敏感文字信息颜色调成和图片背景相似的文字,或者隐藏在含有丰富自然场景信息的图片中,使网络平台的自动审核系统误认为是合格图片而流入互联网,并且通过一些近义词含蓄表达不良信息,逃过检测系统的审核。基于此背景下本文设计了一套敏感图片检测方法,提高包含敏感信息图片的检测准确率,保证网络环境的相对安全,主要研究内容如下:1)针对目前网络图片上文字形状存在多样性的特点,本文选取用于任意形状文本检测的深度关系推理图(Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection)算法作为基础方法,该算法对形状多样的文本有较好的检测效果。同时,本文在该算法的基础上,为了解决训练过程中网络参数量庞大,模型占用内存过多以及训练时间过长导致调参难度大的问题将VGG16网络换为Res Net50网络,并且引入ECA(Efficient Channel Attention)轻量级通道注意力机制,在Res Net50网络的第2、3、4、5阶段分别加入了ECANet模块,构建了ECA-Res Net50的特征提取网络,提升模型对文本特征的关注度;针对原算法中特征融合不充分导致小感受野目标检测不充分问题引入了特征融合模块,将不同感受野特征进行融合,提取更丰富的图像特征;同时受CTPN(Connection Text Proposal Network)算法的启发,在特征融合后加入BLSTM(Bi-directional Long Short-Term Memory)网络,学习文本序列特征,更好地定位长文本。最后通过实验验证,改进的算法在自制中文数据集和CTW1500数据集上综合指标分别达到了83.28%和86.71%,较原算法性能有所提升。2)为了解决由于二次制作导致敏感图像中模糊文本识别错误问题本文采用ABINet(Autonomous Bidirectional and Iterative Language Network)文字识别算法对文本进行识别,将视觉模型识别出的结果在输入到基于Transformer模型的语言模型中再次训练,通过内置BERT(Bidirectional Enoceder Representations from Transformers)模型中的MLM(Masked Language Modeling)掩码预测预训练对根据上下文语境对模糊文字进行预测,经过3次迭代调整预测结果,最后在5个英文验证数据集和中文数据集上进行验证,发现较仅仅基于视觉方法的文字识别算法性能有所提升。3)收集了敏感词的数据集,并进行了数据预处理,然后将敏感词数据集和中文新闻标题数据集进行融合,制作了一个16分类的短文本数据集,其中敏感文本为第16类文本,然后使用预训练模型BERT对健康文本和敏感文本分类,从而可以检测出敏感文本,通过实验验证,模型的综合指标达到了91.32%。最后使用部分中文图片进行测试,通过三个部分的检测,对图片的敏感性进行判别,验证了整体方法的有效性。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2023.000660
{DOI}: 10.26926/d.cnki.gbfgu.2023.000660
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 文化数字化视域下的文物知识图谱构建研究与系统实现
{Author}: 崔鑫
{Tertiary Author}: 王晶
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 词汇增强;命名实体识别;关系抽取;知识图谱
{Abstract}: 文化数字化是通过人工智能算法、数字版权、影音编码等数字技术对于文化内容进行再造,进行数字形式的修复、保存、关联、传播。在文化数字化视域下,选取了石刻、陶瓷、青铜器三类文物,通过领域词库构建、命名实体识别、关系抽取等技术构建文物知识图谱;设计并实现了文物知识图谱系统,通过命名实体识别以及关系抽取模块减轻博物馆工作人员人工标注的压力,通过可视化展示模块促进文物信息的传播。本文的主要研究内容和创新点如下:(1)构建了文物数据集以及文物领域词库。文物数据集包含文物命名实体识别数据集和文物关系抽取数据集,主要数据来源于博物馆官网,可信度高。通过构建种子领域词库以及使用新词发现算法扩充领域词库,构建了初始的文物领域词库,并在后续的命名实体识别部分当作词典进行使用。(2)提出了一种基于词汇增强的文物命名实体识别算法。在输入表示层跟上下文编码层都引入词汇信息,缓解了文物数据中词边界判断错误的问题,在文物命名实体识别数据集上有较好的实验效果。(3)提出了一种基于BERT的文物关系抽取算法。在基于BERT的关系抽取基线算法的基础上,引入实体类型信息以及优化了之前多实体情况下实体两两配对的情况,弥补了基线算法的不足,并在文物关系抽取数据集上取得了较好的实验效果。(4)设计并实现了文物知识图谱系统。系统包括关键词检索、命名实体识别算法展示、关系抽取算法展示以及可视化展示等功能,为博物馆工作人员减轻了人工标注的压力,有利于更好地挖掘文物内涵,促进文物信息的展呈与传播。综上所述,本文提出了一套面向文物的知识图谱构建方法,设计并实现了文物知识图谱系统,为挖掘文物文化内涵,促进文物信息传播提供了帮助。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.001771
{DOI}: 10.26969/d.cnki.gbydu.2023.001771
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于投资者情绪的高频股票预测研究
{Author}: 岳松涛
{Tertiary Author}: 张帆
{Publisher}: 山东工商学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 投资者情绪;机器学习;深度学习;高频股票数据;文本情感分类
{Abstract}: 股票市场预测是经济领域中一个非常重要的实际问题,而对高频股票市场的研究,可以更精准的规避风险,获得回报。许多专家学者都将投资者情绪引入股票市场预测中,但是很少有人在高频股票市场预测中使用投资者情绪。以财经新闻,相关经济变量等数据构建的投资者情绪指数均为低频数据,无法应用到高频股票数据的预测中。并且由于高频投资者情绪对股票的非线性影响、滞后性以及长期依赖性,传统的经济模型很难利用其进行预测。因此,本文利用股民股票评论构建高频投资者情绪指数,并提出了一种基于投资者情感的高频股市序列预测模型AEformer。本文爬取了东方财富网上证指数股吧的所有股票评论,选取了BERT模型对股票评论数据进行分类,构建出分钟级高频投资者情绪指数,并对其使用了格兰杰因果检验验证。通过非对称嵌入层将BERT模型与Autoformer结合起来,提出了基于投资者情绪和非对称嵌入层的多模态股票预测模型AEformer。通过消融实验,分析了非对称嵌入层中各个部分在利用投资者情绪进行股价预测的效果。最后,分析了非对称嵌入层在其他Transformer类模型的作用。实验结果表明,BERT模型在本次文本多分类任务中的分类效果优于其他模型,其准确度、精确度等指标均提高了4%以上。在高频股票预测中,加入投资者情绪要比不加入投资者情绪预测的预测精度平均提高了10%。而在所有使用投资者情绪进行预测的任务中,AEformer模型在短期与其他模型优势不明显,但是在中长期预测中相比于其他模型更为优秀。非对称嵌入层不仅提升了AEformer模型的预测精度,同时在其他Transformer类模型中也起到了积极作用。
{URL}: https://link.cnki.net/doi/10.27903/d.cnki.gsdsg.2023.000156
{DOI}: 10.27903/d.cnki.gsdsg.2023.000156
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态机器学习的谣言检测系统设计与实现
{Author}: 高露露
{Tertiary Author}: 李小勇
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 谣言检测;自然语言处理;计算机视觉;特征融合
{Abstract}: 信息技术的革新带动了社交网络的快速发展,人们足不出户就可以获取到来自全球各地的万千信息。然而信息传输的便捷性同样导致谣言的大肆传播,这不仅影响人们的正常生活,甚至会扰乱社会治安,所以对于谣言必须尽快发现并澄清来降低其危害性。但是人工识别谣言效率低下,鉴别工作往往具有滞后性,因此自动化的谣言检测研究具有重要意义。本文在总结现有工作不足的基础上提出了 一种基于多模态信息的谣言检测模型,并通过实验验证了其有效性和优越性,同时根据该模型建立了谣言检测系统。本文主要工作如下:1)提出了一种基于多模态信息的谣言检测模型。模型从文本内容、图像信息和社交上下文三个角度出发,利用深度学习的方法对文本和图像进行特征提取,同时将容易忽略的隐藏状态也作为谣言检测的依据,然后将这些特征与手动提取的社交特征进行多层次的融合,最终将融合的特征用于谣言检测。模型在特征提取过程中使用到注意力机制从而可以聚焦于关键特征,同时使用了多层次的特征融合方法可以更充分地利用多个模态之间信息的联系。此外,在公开的谣言数据集上进行了实验,实验结果表明,基于多模态信息的谣言检测模型具有更高的识别准确率。2)设计并实现了谣言检测系统。系统的主要工作模块包括爬虫模块、数据预处理、算法模块、用户等级策略和数据存储。爬虫模块负责根据微博账号爬取该用户的个人信息和历史微博数据;数据预处理模块负责手动提取社交特征;算法模块负责切换和提供算法模型服务;用户等级策略负责发现并特殊管理那些发布谣言可能性高的低信任度微博用户;数据存储负责对系统运行过程中产生的必要数据进行持久化。系统不仅可以对一则信息进行谣言判断,还可以通过监视低信任度用户的微博来提前发现谣言,从而可以起到较好的辅助作用。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.002978
{DOI}: 10.26969/d.cnki.gbydu.2023.002978
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 跨领域电商文本评论细粒度情感分析方法研究
{Author}: 谢云熙
{Tertiary Author}: 张艳荣
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 电商文本评论;情感分析;跨领域;预训练;联合模型
{Abstract}: 随着电子商务技术的不断成熟和网上购物规模的持续扩大,越来越多的消费者使用网上购物取代线下实体商店购物。在网上购物的环境下,消费者无法完全相信商家提供的商品信息,进而会把电商文本评论作为评判该商品好坏的标准。电商文本评论中包含着大量的主观情感,依据情感极性将其划分为积极,消极和中立。同时电商文本评论中包含的主观情感会涉及多个方面,为了得到商品中某个方面的情感倾向,则需要更细粒度的情感分析技术。因此本文在国内外研究的基础上,以电商文本评论为研究对象,分析不同方面的情感极性,并且解决领域数据稀缺问题,最终实现跨领域电商文本评论细粒度情感分析。研究内容主要有以下几个方面:（1）针对跨领域电商文本评论细粒度情感分析问题,该任务的目标是将电商文本评论的不同方面进行情感分类,以获得不同方面的情感极性。本文采用ERNIE-Gram预训练模型提取电商文本评论的特征,将其输入到改进后的DPCNN神经网络中,构建ERNIEGram-DPCNN联合模型,再对预训练模型进行微调,实现跨领域电商文本评论细粒度情感分析任务。最后通过实验对比,验证了 ERNIEGram-DPCNN模型的精确率高于其他模型。（2）针对跨领域电商文本评论数据稀缺问题,提出基于生成式对抗网络的跨领域电商文本评论细粒度情感分类SKEPGram-CDNN模型,该模型以生成式对抗网络为框架,通过将SKEP模型预训练得到的情感知识与ERNIE-Gram-DPCNN模型提取出的电商文本特征互相融合作为生成式对抗网络的生成器,并且根据胶囊网络在跨领域迁移任务的优越表现,将其作为生成式对抗网络的判别器应用于跨领域细粒度情感分类任务中。通过把源领域知识迁移到目标领域,有效解决了某些电商领域数据稀缺问题,满足实际应用中多样化的需求,促进了学科交叉融合。最后通过对比实验,证明了SKEP-Gram-CDNN模型的有效性。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2023.000315
{DOI}: 10.27787/d.cnki.ghrbs.2023.000315
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向电网设备的知识图谱设计与实现
{Author}: 程卓然
{Tertiary Author}: 闫丹凤
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱构建;知识图谱补全;文本推荐;微服务
{Abstract}: 电网设备是电力系统的核心组件,对电网设备的状态评估、运维、试验和检修工作是确保电力系统可靠运行的关键环节,这些环节统称为电网设备运检过程。随着电力技术的发展,电网设备的种类越来越多,设备构造越来越复杂,使得电网设备的运检难度逐渐提高。由于运检工作高度依赖工作人员的专业技能和工作经验,上述问题将会导致电网工作人员的学习成本不断提升,严重影响运检工作效率。与此同时,随着数据采集技术的发展和电网信息化过程的推进,电网设备领域文本数据量激增,这些文本中包含了大量宝贵的领域专业知识,可以用于构建知识库,进而为电网设备运检工作提供辅助支持功能,降低运检人员的学习成本。但由于其大多为非结构化文本,其中的专业知识无法被直接利用。为解决此问题,本论文基于知识图谱相关技术设计并实现了一个面向电网设备的知识图谱系统,该系统能够以知识图谱的形式存储海量电网设备领域文本中的专业知识,并基于知识图谱提供知识分析和推理能力。首先,本论文对领域知识图谱构建方法进行研究,基于文本数据采集、命名实体识与实体关系抽取技术构建了一个大规模的电网设备领域的知识图谱数据集。本论文基于97687篇多种来源、结构各异的电网设备领域的文本数据进行了知识提取,提取了 14类共计33512个实体与12类共计85412条关系,构建了一个电网设备领域的知识图谱,与领域内的其他知识图谱相比,本文所构建知识图谱具有规模大、覆盖面广、领域特色强的特点。其次,本论文提出了一种知识图谱动态更新方法。此方法通过六种升级执行器对知识图谱中的数据进行动态更新,以不断补充新的领域知识。基于此方法可以实现对知识图谱数据版本的管理,每一次数据变更都被视为一次数据版本升级,升级的详细信息都会被记录在日志系统中,并基于日志提供数据回滚机制。此外,知识图谱动态更新方法还具有高扩展性,当知识图谱数据变更的方式增加时,只需增加对应的升级执行器即可完成升级,对其他升级器和图谱数据不产生影响。再次,本论文提出了一种开放域零样本知识图谱补全模型。此模型基于知识图谱自身的推理能力与生成对抗思想设计,可以在缺少大规模训练数据集的情况下从新关系的自然语言文本描述中学习关系特征,并在知识图谱低维向量空间中完成关系补全,解决了电网设备领域知识图谱中的链接缺失问题。最后,本论文设计并实现了面向电网设备的知识图谱系统,该系统以电网设备领域的文本数据与知识图谱数据为基础,提供领域数据管理、全文检索、相似文本推荐和数据可视化等功能。基于针对系统设计的功能测试与性能测试,验证了本系统在功能上与性能上均符合设计预期,对电网设备的运检工作可以发挥强大的辅助支持作用。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.001568
{DOI}: 10.26969/d.cnki.gbydu.2023.001568
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 增强语义表示的文本匹配技术研究与实现
{Author}: 杜嘉
{Tertiary Author}: 周延泉
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小样本学习;文本匹配;提示学习;门控机制;动态提示
{Abstract}: 在自然语言领域中,文本匹配任务是一项非常重要的任务,其是许多下游任务所必需的核心能力,可以广泛应用于信息检索、问答系统、对话系统等多个领域。在这些应用中,文本匹配任务的准确性和效率直接影响着系统的性能。随着人工智能发展,为适应各行各业的专业场景,并充分利用大规模语言模型的能力,小样本场景下的文本匹配任务正在变得越来越重要。因此,研究如何高效、准确地完成小样本文本匹配任务是非常有必要的。近年来深度学习技术和大规模预训练语言模型的引入推动了小样本文本匹配技术的研究,小样本文本匹配技术已经取得了不错的进展。但是由于语言模型的预训练任务和文本匹配任务之间存在差距,大规模预训练语言模型的能力并没有得到充分挖掘。基于提示学习的方法可以一定程度上增强语言表示,缓解这个问题。然而,当前基于提示学习的文本匹配方法主要采用任务级别模板,隐式地引入任务信息,忽略了实例存在差异性的问题,没有使用显式的任务信息,并且任务级别的模板是静态的,存在局限性。针对这两个问题,本文提出了两种方法来增强文本匹配的提示学习方法:(1)本文提出了一种基于门控提示学习的文本匹配方法,通过引入门控机制增强了提示模板对实例的适应性。(2)本文提出了一种基于动态提示学习的文本匹配方法,通过融合实例的语义信息和显式的任务信息将静态提示模板转化为动态模板。这两种方法均利用提示学习方法进一步增强了文本的语义表示。为了证明本文提出的方法的有效性,本文在小样本场景下对五个文本对数据集(MRPC、QQP、SNLI、QNLI和RTE)进行了详细的实验。实验结果表明,本文提出的改进方法在这五个数据集上的表现都优于当前最优模型。最后,本文将下游任务中所需的文本匹配能力服务化,设计并实现了一个小样本文本匹配系统,以本文提出的改进模型为核心,集用户管理、模型训练和服务部署等功能为一体,并通过Web界面和API服务两种方式提供稳定可靠的服务。本文进行了系统测试以验证该系统的稳定性和实用性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000005
{DOI}: 10.26969/d.cnki.gbydu.2023.000005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的网络新闻自动摘要
{Author}: 郝帅
{Tertiary Author}: 尹四清;王志宏
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自动摘要;Transformer网络;门控过滤;关键字融合;相对位置编
{Abstract}: 目前,互联网信息技术飞速发展,尤其是文本信息呈现指数型增长,每天都有海量的信息不断涌入,如今出现的越来越多的“标题党”新闻给读者带来了巨大的挑战,因此,迫切需要提供一种易于理解的摘要的工具来缓解信息过载的问题。文本自动摘要技术旨在从各类网络新闻文本中产生简洁的,概括性强的文本信息的方法,目前已成为国内外研究的重点。然而现有的摘要模型普遍存在内容不准确,生成摘要语句不通顺,无法解决中文一词多义问题等缺点,且生成式摘要模型对于文本中蕴含的重点主题信息没有细致良好的把控。生成摘要没有包含原文主要信息,不能作为原文信息的概括。针对目前存在的问题,本文进行了两方面的研究。(1)针对目前网络模型难以从宏观的角度得到文本所涵盖的主旨信息,导致模型生成内容不准确的问题。本文提出了一种融合主题信息的Transformer网络,采用关键词抽取算法挖掘文本的主题信息,将其融入模型进行计算。使模型在文本关键词的指导下,生成面向主题的摘要,针对一词多义问题,本文通过预训练模型来训练词向量得到词语在不同语义下的特征编码,在此基础上生成摘要,并在真实数据集上进行验证,证明本文模型的效果。(2)本文考虑到对于长序列来说,某些无关噪声的注意力计算会降低模型的精确度,因此基于上述网络我们提出一种门控网络,对某些噪声进行过滤,过滤掉低关注度的噪声,在提高模型生成摘要的准确性的同时,使模型更高效的处理任务。对于模型无法判断中文词序的问题,在此基础上我们采用相对位置编码对词向量的顺序和结构进行增强,使得模型更好的认识词语之间的位置关系,增强生成摘要语句的通顺性。同时我们采用改进的解码策略来拉近生成摘要与人工标准摘要的相似性。该模型通过实验数据集的结果表明,该模型在LCSTS数据集下的ROUGE-1,ROUGE-2以及ROUGE-L三个指标上均取得了明显的提升。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000288
{DOI}: 10.27470/d.cnki.ghbgc.2023.000288
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于在线评论的卡车用户需求挖掘研究
{Author}: 尹红雨
{Tertiary Author}: 郑枫
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 在线评论;自然语言处理;文本分类;需求排序
{Abstract}: 在新一代信息技术背景下,得益于社交网络的普及与发展,在线评论成为表达用户需求的新型载体,同时又是获取产品缺陷信息的有效途经。通过对产品在线评论的深入分析,可以更加准确地识别和理解用户的需求,并且可以更好地把握用户需求随时间变化的趋势,这对于企业的产品定位具有极其重要的意义。本研究的主要内容是将用户的在线评论应用于卡车的辅助优化设计过程中,通过对现有研究理论的梳理,出了一种基于社交媒体在线评论文本的卡车用户需求挖掘方法,即从在线评论中取卡车设计属性及与之对应的评价,然后对评论文本进行情感分析和量化,最后基于用户对设计属性的关注度和满意度构建需求优先级排序模型。简要流程如下:广泛收集卡车领域的文献资料和用户在线评论作为原始数据集,人工筛选出有效评论后利用自然语言处理技术进行文本预处理以构建专业词库——属性词汇库、情感词汇库、否定词词汇库和程度副词词汇库,使用六个有监督的分类模型进行词汇取与文本分类,利用K折交叉验证法计算分类模型的各项指标,选择最优的文本分类结果,分别对显性句式和隐性句式进行情感分析与量化,最终基于用户关注度和满意度构建需求优先级排序模型。针对目前基于评论文本的用户需求挖掘研究存在的短板、不足之处,本研究为具有复杂属性层次的产品供了一种新的用户需求挖掘的思路和方法,而且主要从以下四个方面高需求挖掘的全面性和准确率:一是在人工筛选出有效评论文本后,以标点符号为基准将长句截断成短句,再进行人工标注;二是在文本分类与词汇取阶段利用K折交叉验证法从六个有监督的基于机器学习和深度学习的文本分类模型中选择F1值最高的文本分类结果进行后续研究;三是在情感分析与量化阶段将有效评论文本划分为三种句式——同时包含属性词汇和情感词汇的显性句式、只包含属性词汇的隐性句式以及只包含情感词汇的隐性句式,建立有效的隐性需求取方法,对上述三种句式分别进行情感分析与量化研究;四是本研究出受环境因素影响的加权系数,以弱化自然条件因素影响卡车用户对部分设计属性的满意度评价。最后以用户关注度和情感值为指标对卡车属性的重要程度和需改进程度进行排序,建立一种融合多种模型优势的需求优先级排序方法。综上所述,本研究基于在线评论对卡车用户的多元需求进行挖掘,结合定性与定量的分析方法,将用户的自然语言转化为产品的设计指标,可以为企业或相关部门的设计决策者供高效的产品开发规划。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000249
{DOI}: 10.27278/d.cnki.gsdqc.2023.000249
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于电子病历的知识图谱构建方法研究
{Author}: 贾奕文
{Tertiary Author}: 邵虹
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 电子病历;深度学习;命名实体识别;实体关系抽取;知识图谱
{Abstract}: 电子病历记录了患者诊疗过程的详细信息,其中蕴含丰富的医疗知识,但其多为非结构化数据且病历文本词汇专业性强,传统的自然语言处理技术难以自动化的从中提取医疗信息。随着电子病历数量的急剧增加,利用自然语言处理技术获取电子病历中的医疗知识意义重大。知识图谱作为一种语义网络技术,将真实世界的事物之间的关系转换为图数据结构存储,为充分利用病历中的医疗知识提供了解决方案。针对以上分析,以电子病历文本为研究对象,使用自然语言处理技术构建电子病历知识图谱。
针对病历文本中的嵌套、非连续长实体带来的边界信息模糊、实体内部联系弱的问题,给出一种基于多特征融合的实体识别模型。使用Soft-Lexicon模型融入医疗词汇信息;通过多头注意力机制增强字符向量的边界信息,采用Biaffine注意力机制获得实体边界表示;使用CLN获取实体内部字符信息交互,线性注意力机制获取实体内部表示,增强长实体内部的依赖信息;采用门控机制融合实体边界表示和实体内部表示作为实体跨度表示;通过多尺度空洞卷积进一步提取不同跨度间的上下文信息。实验表明,模型在测试集上F1值达到了87.42%,相较于Bi LSTM-CRF模型,长实体识别F1值提高了7.14%。
针对医学文本中的三元组重叠现象,给出一种基于跨度的实体和关系联合抽取模型。使用基于多特征融合的实体识别模型作为实体识别模块;针对跨度分类模型在关系种类较多的情况下会产生大量冗余关系的问题,引入关系过滤模块,减少关系抽取模块的关系冗余和噪音;在关系抽取模块中,使用CLN融合实体对和上下文信息,增强模型对重叠三元组的识别能力。实验表明,相较Sp ERT模型F1值提高了1.54%。
使用实体和关系联合抽取模型,在电子病历数据集上抽取三元组信息,采用Neo4j数据库实现了病历知识图谱构建。在病历知识图谱的基础上,利用第三章实体识别模型和基于关键字匹配的意图识别,设计并实现医疗问答系统。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2023.000867
{DOI}: 10.27322/d.cnki.gsgyu.2023.000867
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 视觉与语言的跨模态融合方法研究
{Author}: 张立赛
{Tertiary Author}: 陈清财
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 多模态表示;视觉语言预训练;跨模态检索;跨模态生成
{Abstract}: 视觉和语言机能的结合作为人类大脑的重要功能,是人工智能领域长期以来关注的重要问题,也是当前工业与信息化行业所需要的重要技术。认知科学对人类思维的研究表明,人脑的工作机制具有跨模态联动的特点。相比单独地处理视觉或图像,视觉和语言的融合能够大幅提升智能系统感知的信息量,实现更加准确的决策。随着深度神经网络对视觉和语言模型在自注意力的结构上完成统一,人工智能系统的跨模态融合时代已经呼之欲出。由于文本和图像在数据形式上具有异构性,跨模态融合的智能系统需要首先对二者建立语义层面的关联,然后通过有效的方法结合两种模态的信息,来实现具体任务上的性能提升。仿照人类的思维模式,本文首先围绕多模态关联问题建立了表示学习的基础,然后基于多模态表示进行了跨模态融合及应用的探索。研究内容主要包含四个方面:(1)针对视觉语言预训练模型的弱监督的细粒度表示问题,提出了一种视觉语言的替换式细粒度自监督任务。该方法首先从真实对齐语句中替换一个词语,然后通过替换语言建模的任务来根据图像预测每个单词是否被替换,从而学习词汇级的细粒度对齐能力。本文为单模态和多模态阶段都设置了替换任务。此外,本文提出了一种同位词语句改写策略,以提高替换语言建模任务的难度。在多个多模态下游任务的实验中证明了所提出方法的有效性。(2)针对视觉语言的单塔模型和双塔的性能-效率折中问题,提出了一种视觉语言解耦方法。它可以在保持单塔模型的高精度的同时,实现双塔模型的高效检索。该方法将跨模态嵌入的构建分成两个阶段:其中早交互融合阶段采用单塔模型结构,负责充分融合视觉语言信息,学习高质量跨模态表示;而解耦阶段则将模型分解为双塔结构,实现高效灵活的推理。在公开数据集上的实验证明,视觉语言解耦方法大幅领先双塔模型的检索精度;而对比单塔模型,可以在保留高精度的情况下大幅提升检索速度。(3)针对多模态语言模型对图文对齐语料的依赖问题,提出了将视觉信息集成到语言模型的半监督视觉联想方法。该框架使用跨模态检索模拟人类的视觉想象力,能够以可插拔的方式集成到纯文本的下游任务中,改善语言模型的性能。在自然语言推理和阅读理解任务上的实验结果表明,本文的框架可以对广泛应用的强基线模型带来提升。(4)针对图像修复任务的病态定义问题,提出了文本引导的图像修复方法。该方法通过一种对偶多模态注意力机制来提取关于损坏区域的语义信息,并通过应用图像-文本匹配损失保证生成图像和文本语义的相似度。在公开数据集上的实验结果表明,该模型在定量和定性指标上都达到了图像修复方法的先进水平。通过在图像编辑功能上的额外扩展,证实模型修复的图像与引导文本的语义是一致的,并且可以首次实现语言控制的图像擦除修改。综上所述,本文依照“先建立多模态关联表示基础,再将多模态知识融入单模态任务”的框架。首先研究了单塔与双塔结构的视觉语言表示模型,在跨模态检索等任务上达到了先进的性能;然后基于多模态表示,分别研究了类比人类想象力的视觉集成语言模型,以及首个文本指导的图像修复模型。本文将所提出的方法在多个国际公开数据集上进行验证,最终均取得优异的性能。其中首度提出的文本引导的图像修复任务已经多个国际知名AI创作项目支持,对于细粒度预训练和跨模态检索的研究已经在工业化场景落地并申请专利。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2023.000344
{DOI}: 10.27061/d.cnki.ghgdu.2023.000344
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 社交聊天机器人性别偏向建构研究
{Author}: 吴熙倡
{Tertiary Author}: 马中红
{Publisher}: 苏州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 社交聊天机器人;性别刻板印象;人机交互;调查-实验法
{Abstract}: 由人工智能技术带来的智能助手设备、聊天机器人等产品,已经被广泛应用于人类日常生活的各个方面。然而,这些产品在大多数情况下都被赋予了女性化的声音特征、命名和虚拟形象。通过梳理人机交互、聊天机器人等领域的研究,发现基于对话系统技术的社交聊天机器人产品具有明显的性别偏向,但目前国内对于社交聊天机器人性别偏向的建构问题研究较少,也缺乏一定的研究模型。本文通过一项启动效应调查-实验,将用户对机器人的性别偏向认知程度和用户的性别作为自变量,探讨了用户对社交聊天机器人性别偏向的感知和建构作用。实验的结果验证了用户会使用人类的社会规范与机器人进行交流,用户能够感知机器人的性别、以及它们身上存在的性别偏向问题,但是用户对机器人性别偏向的判断,却存在潜意识与主观上的矛盾。本文还对微软“小冰”系列的3名社交聊天机器人进行了性别偏向的对话测试,对收集到的交互文本进行了质性编码与分析,以了解机器人的性别偏向程度和性别偏向建构的因素。质性分析结果表明:社交聊天机器人的交互文本中,具有性别偏向的内容达到30%-50%,它们在某种程度上都复制与强化了人类的部分社会性别观念与性别刻板印象。本文的调查-实验和对话测试,组成了一套用于研究用户人机交互行为、衡量社交聊天机器人性别偏向程度的研究模型。最终研究发现:社交聊天机器人的性别偏向受到了用户、技术、开发者,以及社会文化的建构。首先,从人机交互的视角,用户与社交聊天机器人互动,开发者设计程序、创作脚本的过程都是一种构建“人-机心智”的过程,他们都在有意或无意识的情况下向机器人灌输了具有性别偏向的内容或观念;其次,聊天机器人的技术逻辑是一种“编码-解码-再编码”的过程,AI技术在这一过程中将完成对人类性别意识形态的学习与再造;从社会文化对性别的建构来看,聊天机器人的性别偏向,来源于机器人被赋予的性别符号、人类社会具有性别歧视意味的语言实践、男权文化培育下的大众传媒不断再现的社会性别刻板,以及被重构的社会性别意义;最后,从技术女性主义的视角,技术与性别具有相互交融的关系,技术的生产与消费制造了性别鸿沟,使得女性在性别分工中处于科学技术等领域的边缘,因此,机器人即使作为技术也摆脱不了男权文化的“性别-权力”结构约束。
{URL}: https://link.cnki.net/doi/10.27351/d.cnki.gszhu.2023.003999
{DOI}: 10.27351/d.cnki.gszhu.2023.003999
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于检索式与生成式融合的问答技术研究与实现
{Author}: 王文
{Tertiary Author}: 何月顺;何勇
{Publisher}: 东华理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 问答模型;检索式模型;生成式模型;答案精排
{Abstract}: 随着人工智能技术不断发展,深度学习得以运用在各行各业中,Bert、Erine、GPT等预训练模型也成为自然语言处理应用中的热点话题。在问答系统中,这些模型拥有着广泛的应用场景。目前,问答系统的解决方案主要有检索式问答与生成式问答。生成式问答的优点是没有标准答案,答案自由度较大,但这也导致了答案评估的困难,回答容易偏离主题。检索式问答的优点是答案准确,易于评估,但是它的回答仅限于数据库中已有的类似问题。因此,为了充分结合两者模型的优点并避免其缺点,本文基于检索式与生成式问答,结合预训练模型展开研究工作,主要工作成果如下:
(1)本文提出了一种基于孪生神经网络的检索模型,用于检索式问答,该模型由四层结构组成,分别为Bert、双向长短期记忆神经网络(Bi-LSTM)、池化层以及相似度计算层,问句通过Bert输出问题特征向量,结合Bi-LSTM和池化策略优化输出语义向量,从问答库中获取相似度最高的问题,经实验对比论证,该模型准确率高于传统问答检索模型。
(2)针对生成式问答质量评估困难,回答主题不一致等问题,本文构建金融领域数据集针对Erine进行训练微调,以满足金融业务问答需求,采用网格搜索确定最佳训练参数,使用Embedding Average与Perplexity指标评价模型效果。针对检索式与问答式输出的答案,提出了一种基于Bert和BP神经网络设计的评分模型,采用语义推理数据集进行训练,对于问答模型召回的答案候选项打上具体的分数从而进行精确排序。构建答案精排方案,设计完全匹配阈值参数α和评分校正参数β用于修正输出最佳答案,经实验数据论证,参数设计有效。
(3)基于检索式、生成式和评分模型支撑,本文实现智能金融问答系统。针对问答系统操作繁琐、用户满意度低、客服工作量大等问题,该系统基于微信平台作为用户端,Web端作为客服端。微信端能够自动回复用户金融业务问题,Web端实现智能转人工功能,提供候选集回答辅助人工客服,操作方便快捷。
{URL}: https://link.cnki.net/doi/10.27145/d.cnki.ghddc.2023.000747
{DOI}: 10.27145/d.cnki.ghddc.2023.000747
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: Flask应用的XSS和CSRF漏洞检测方法研究
{Author}: 李朝杨
{Tertiary Author}: 王希胤
{Publisher}: 华北理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 漏洞检测;源代码;深度学习;Flask应用程序
{Abstract}: 基于深度学习的源代码漏洞检测已成为应用安全领域的一个研究热点。有很多学者提出了基于深度学习的源代码漏洞检测方法,然而这些研究主要集中于以PHP、C/C++、Java为编程语言开发的软件应用上,很少涉及Python应用程序(例如基于Flask框架开发的应用)的漏洞检测。基于此背景,将基于深度学习的漏洞检测方法应用于Python源代码漏洞检测研究中,构建了Flask应用的XSS(Cross Site Scripting)和CSRF(Cross Site Request Forgery)漏洞数据集,提出了两种结合不同深度学习技术对Flask应用进行源代码漏洞检测的方法。主要完成了以下工作:
1)收集创建了Flask应用的XSS和CSRF漏洞数据集。针对目前没有公开可用的Flask应用漏洞数据集的问题,制定了一套从大型开源代码库Git Hub中收集Flask应用漏洞数据的策略。
2)提出了基于Attention-Bi LSTM模型的Python源代码漏洞检测方法。Bi LSTM模型可以学习源代码的序列特征,注意力机制可以为源代码的不同特征赋予不同的权重以突出影响漏洞检测的重要特征,结合两者的特性可以有效学习Flask源码中XSS和CSRF两种漏洞的代码模式和特征。利用该方法生成的漏洞检测模型在两种漏洞数据集上的准确率分别达到了98.66%和98.90%,F1Score分别达到了90.50%和91.93%。
3)提出了基于Code BERT模型微调的Python源代码漏洞检测方法。Code BERT是在大量不同类型的代码语料库上经过预训练的模型,它省去了收集大量代码语料库来训练词嵌入模型的步骤,相比于传统模型具有更强的代码语义理解能力。因此,利用它可以有效学习Flask源码中XSS和CSRF两种漏洞的代码模式和特征。利用该方法生成的漏洞检测模型在两种漏洞数据集上的准确率分别达到了94.22%和97.97%,F1Score分别达到了85.08%和91.77%。
实验结果表明,上述两种方法可以有效的检测Flask应用中潜在的XSS和CSRF漏洞。
图34幅;表16个;参45篇。
{URL}: https://link.cnki.net/doi/10.27108/d.cnki.ghelu.2023.000465
{DOI}: 10.27108/d.cnki.ghelu.2023.000465
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像字幕生成研究
{Author}: 张孝良
{Tertiary Author}: 李业丽;蒋艳平
{Publisher}: 北京印刷学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;计算机视觉;图像字幕生成;Yolov5;LSTM
{Abstract}: 随着科技的发展,越来越多人们之前不敢想象的事情现在变成了现实。在大数据时代,深度卷积神经网络具有比之前神经网络更复杂的网络结构,因为它含有更多的隐藏层,与之前传统的机器学习的各种方法相比具有更加强大的特征学习能力和特征表达能力,这使得卷积神经网络在计算机视觉领域拥有更加广泛的应用,在近些年的计算机视觉任务中展现出了非常令人瞩目的成绩。本文研究的是计算机视觉中讨论火热的Image Caption即图像字幕生成领域,属于自然语言处理与计算机视觉的结合应用。其目的是将输入的图片经过模型训练输出为对这张图片的自然语言描述。各色各样的图像在生活中随处可见,人类理解图片中的内容当然是非常简单,但随着科学技术的发展,随着深度学习的发展,我们也在不断探索、研究如何让机器通过认识一张张图片感知这个世界,如何知道图片中是什么,如何描述它,如何知道世界里有什么。这项研究显然是对人工智能和人类未来的发展有正向意义的,目前正在尝试的应用场景也有很多,比如盲人辅助、溺水、火灾自动识别警报,比如图片检索,比如未来和人类真实交流的机器人等,都离不开图像字幕生成任务。针对目前的图像字幕生成方法对图片中的物体识别不精确、模型运算时间较长、生成的文本句子不连贯缺乏上下文语义的缺点,本文在编码器算法和解码器算法上进行了一系列改进,经过实验证明新提出的方法可以有效提升模型的执行速度和生成文本的准确度,本文所做的主要工作包括以下四个方面:(1)建立一种基于Yolov5图像特征提取的图像字幕生成框架。在目标检测和物体识别领域Yolov5取得了十分傲人的成绩,本文将其优秀的特征提取和图片编码能力运用到图像字幕生成领域,得到了比以往模型运行速度更快、更加细节而且优秀的图像编码结果。经过实验对比,在一定程度上提高了实验模型的运算速度和模型评分。(2)提出一种复合信息交互的BiLSTM算法,并融入注意力机制。长短期记忆递归神经网络可以利用时间序列对输入进行分析,但目前的算法仍存在输出的文本预测不通顺上下问不连贯的问题,因此本文引入双向LSTM即BiLSTM作为字幕生成器,并将自注意力机制融入到其中,通过建立Yolov5-Soft Attention-BiLSTM模型对数据集进行特征提取并编码,实验证明BiLSTM结合注意力机制的引入使得模型能够更好的识别当前描述目标,使描述更加通顺且贴合图片,得到了更高的评分。(3)建立了COCO数据集预处理模型,如丢弃低频词、停用词过滤等。实验证明该方法有效提高了模型准确率和模型运算速度,得到了比以往更好的提升。(4)对Yolov5和BiLSTM模型进行了的结构局部调整优化,经过实验证明这些改进对图像字幕生成算法的准确率和运行速度提升具有一定成效。实验证明,本文提出的算法在识别准确率和模型运算速度上都优于传统的图像字幕生成算法,在不同的程度上提升了图像字幕生成任务的分析速度和模型准确率。
{URL}: https://link.cnki.net/doi/10.26968/d.cnki.gbjyc.2023.000242
{DOI}: 10.26968/d.cnki.gbjyc.2023.000242
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本匹配技术
{Author}: 杨志
{Tertiary Author}: 赵庶旭;孙琦龙
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 注意力机制;对比学习;图神经网络;文本匹配
{Abstract}: 文本匹配是自然语言处理技术中的一项关键性任务,用于确定两个文本之间的相似度或匹配程度。其有着广泛的应用场景,如语义推理、文本分类、信息检索、问答系统等。目前文本匹配存在着以下的问题:一是预训练模型对文本语义的表示能力不足(表示退化),预训练模型生成的词向量存在各向异性的问题,而各向异性被认为是导致预训练模型在各下游任务中只能达到次优性能的一个重要因素;二是对文本上下文语义信息提取能力不足,目前通常做法是,直接使用预训练模型编码,未考虑构成当前句子的词之间的上下文关系;三是忽略了文本句法结构信息,语义、句法和结构,构成了文本的三要素,而目前通常做法是基于文本的语义信息进行匹配,忽略了文本的句法依存结构信息。论文针对文本匹配任务现有研究工作的不足,提出了改进的文本匹配模型。首先是针对文本预训练模型在句子的语义表示上存在的“坍缩”现象,提出了基于对比学习的文本表示优化迁移模型,借鉴Sim CSE模型的思路,采用dropout机制,进行正负样本采样。考虑到在一个Batch内扩增,会导致假负样本和表示向量的“坍塌”问题。提出了一种新的对比学习框架BSim CSE来缓解采样偏差的影响。使用样本匹配权重来消除假负样本的影响;其次采用混合数据增强方法,来尽可能扩充样本数据集。通过在目标领域的无监督语料上Fine-tune,使模型生成的文本表示与下游任务的数据分布更加适配,提升文本的语义表示能力。通过两组实验结果证明,在句子语义匹配(STS)任务上,同等设置下,BSim CSE相比其他模型,性能上有较大的提升。其次针对文本匹配模型只考虑文本语义匹配,忽略上下文及句法结构特性的问题,提出了基于多头自注意力机制和图卷积神经网络的混合文本匹配模型DSSGM。在文本语义编码上,基于多头自注意力机制,充分提取构成文本的词之间上下文信息。在文本句法依存编码上,基于图神经网络来获取文本句法依存结构的信息。在特征融合上,为合理并有效地综合应用语义特征及句法依存特征信息,论文设计了一种前向网络,并联合残差连接及层归一化高效地对语义特征及句法依存特征进行融合。本文提出的模型分别跑在三种数据集上进行评测,在准确率、F1值等评测指标上都取得了较好的结果。消融实验中,评估了DSSGM模型各个模块对于最终结果的影响,验证了多头自注意力机制模块和图卷积神经网络模块对于文本匹配的有效性。最后在性能分析实验中,DSSGM模型同样达到了较为理想的效果。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2023.001032
{DOI}: 10.27205/d.cnki.gltec.2023.001032
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文档级实体关系抽取方法研究
{Author}: 耿艳芳
{Tertiary Author}: 丁艳辉
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;文档级实体关系抽取;图神经网络
{Abstract}: 关系抽取是信息提取的重要子任务之一,旨在从文本中提取实体之间的语义关系。近年来,随着知识图谱的快速发展和大数据时代对知识图谱的迫切需求,关系抽取作为构建知识图谱的必要任务之一,其重要性也越来越被人们重视。早期实体关系抽取的研究聚焦于从单个句子中提取实体间的关系,即句子级实体关系抽取。近年来,随着大数据的蓬勃发展和深度学习的进步,推动了文档级实体关系抽取的发展。相比句子级实体关系抽取,文档级实体关系抽取需要从多个不同句子中提取实体间的关系,需要考虑更多的实体,因此需要更强的信息收集能力。在语境复杂的文档中,实体之间的隐含含义也需要被考虑。因此,模型需要获取更准确的全局信息并具备强大的推理能力,这使得从文档中抽取实体之间的关系更具挑战性和难度,导致目前文档级实体关系抽取工作进展缓慢。为了应对这些挑战,本文对基于深度学习的文档级实体关系抽取方法进行了系统的研究,主要研究内容包含以下几点:(1)为了解决现有方法获取实体间局部信息和全局信息不充分的问题,本文提出一种基于E-R图的文档级实体关系抽取方法(E-R图模型)。该方法通过构建一个新的实体关系图(E-R图)来探究实体间的相互作用,使用图卷积网络来捕获并更新实体之间的信息。在E-R图中明确定义两种类型的节点和三种类型的边,通过相关节点之间的相互作用,获得足够的局部信息,通过实体间有效的边连接,收集足够的全局信息以加强全局推理。实验表明,该模型在大规模公开文档级实体关系抽取数据集Doc RED上表现出色,性能超过了对比模型。(2)为了进一步增强节点表示,解决输入冗余问题,本文提出一种融合注意力机制和改进输入的文档级实体关系抽取方法(IN＿E-R＿AT模型)。该方法在E-R图模型的基础上对输入的文档进行改进,既能减少信息冗余带来的消极影响,又能保证有足够的关键信息以预测实体之间的关系。除此之外,通过融合注意力机制,按照实体间信息的重要性赋予邻接实体不同的权重,以获取和实体相关性大的信息特征,增强节点的表示,从而更精准地实现文档级实体关系抽取。在数据集Doc RED上的实验结果表明,相较于E-R图模型,IN＿E-R＿AT模型有了显著的性能提升。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2023.001713
{DOI}: 10.27280/d.cnki.gsdsu.2023.001713
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于关键词提取的评论分析系统研究
{Author}: 杜新宇
{Tertiary Author}: 吴俊杰
{Publisher}: 太原师范学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 电商评论;LSTM;神经网络;关键词提取
{Abstract}: 伴随着电子商务的高速发展,评论的数量达到一个新量级后,不论是对商家还是用户,都很难再进行有效的分析。对于商家来说,巨大的数据量导致处理起来很艰难。对于用户来说,评论内容冗杂,导致浏览评论费时费力。同时,这也会影响平台的用户体验,增加平台的用户流失风险。因此针对评论内容的关键词提取,对于评论的分析有重大的意义。针对上述存在的问题,本项目针对电商评论数据的特征提取问题,建立了基于关键词提取的评论分析系统,设计并创新了一种基于LSTM的关键词提取算法Mix Extra。首先,引入一层神经网络LSTM到输入层,通过选择N个具有隐态特征的属性词和观点词,来指导下一阶段的算法模型进行训练,从而改善训练效果。其次,将两个神经网络LSTM用作下一阶段的算法训练,该层网络用于主要的属性词抽取和辅助的观点词抽取,并对相关的顺序信息进行了记录。最后,演算最后的候选属性词和候选观点词来获取关键词。实验结果表明,该模型是有效的,并在由不同产品类型组成的数据集上实现了较优的性能,包括相机、手机、书籍、口罩共四个商品类别。通过与CRF、LSTM、CMLA和RNCRF进行比较,综合F-score增益率为1%至4%不等。完成关键词提取和分析后,结果被图表化呈现,使商家和用户能够更直观地了解数据。商家可以根据不同的用户群体制定相应的策略,而用户可以轻松分析该产品是否符合其需求。这体现出了本文算法的应用价值。最后,开发并实现基于关键词提取的评论分析系统,通过阐述系统的设计与实现并进行相关的仿真实验,对系统进行测试,完成系统架构的实现。
{URL}: https://link.cnki.net/doi/10.27844/d.cnki.gtysf.2023.000092
{DOI}: 10.27844/d.cnki.gtysf.2023.000092
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识增强的方面级情感分析研究及应用
{Author}: 杜一帆
{Tertiary Author}: 李睿凡
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 方面级情感分析;方面词情感分析;方面类别情感分析;图卷积神经网络;知识增强
{Abstract}: 方面级情感分析,旨在以“方面”为分析粒度,预测出文本中每个方面的情感极性,是自然语言处理领域中的前沿研究之一。其中,方面词情感分析和方面类别情感分析是最重要的两个子任务,两者的主要区别在于预测对象是否显式地存在于句子之中。近年来图神经网络在方面级情感分析领域取得了较优效果。然而,大多数方法的性能提升有限,主要原因在于对外部知识利用不充分,对句中概念词与方面类别关系构造不合理,以及对句法结构和语义关系互补性的建模缺失。针对以上问题,本文开展了如下工作:1.针对方面词情感分析任务,提出一种情感感知的双通道图卷积神经网络模型,其中双通道分别为语法通道和语义通道。在语法通道中,本文首先利用依存句法分析方法捕获句子的语法结构,得到原始的句法依存树矩阵,然后利用SenticNet中词的情感数值构建句子的情感值矩阵,以对原始矩阵增强情感知识,另外使用词性知识构建词性知识矩阵,对句法依存树矩阵进一步增强;在语义通道中,本文将基于ConceptNet知识库训练的词向量与经过Bi-LSTM编码的隐向量融合,对词语进行知识语义增强。最终解决了语法、语义通道对外部知识利用不足的问题。2.针对方面类别情感分析任务,提出一种知识增强的多通道图卷积神经网络模型,其中多通道分别为知识通道、语法通道和语义通道。在知识通道中,本文利用基于WordNet的相似度函数计算方面类别与句子上下文之间的语义相似度,进而得到与方面类别相关的相似度矩阵,解决了方面类别与句中相关概念词关系的捕获和利用不合理的问题;在语法和语义通道中,本文分别使用句法依存分析和自注意力机制构建对应的邻接矩阵,设计基于注意力的特征融合模块,融合语法和语义通道的特征,解决了模型对句法结构和语义关系互补性的建模缺失问题。3.设计并实现了面向评论的方面级情感分析系统,该系统由用户信息管理模块、模型管理模块和情感分析与可视化模块组成。该系统平台无关、用户友好,允许用户在进行可视化参数配置、模型训练以及对文本进行方面级情感分析。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000203
{DOI}: 10.26969/d.cnki.gbydu.2023.000203
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 大数据时代主流融媒体信息组织管理机制研究
{Author}: 李晨雨
{Tertiary Author}: 崔金栋
{Publisher}: 东北电力大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 主流融媒体;信息组织;管理机制;大数据
{Abstract}: 2019年1月,为适应新时代发展的需要,习近平总书记做出重要指示,明确主流融媒体承担着主流舆论引导和意识形态建设的重要使命,“推进媒体深度融合,做强新型主流融媒体”成为国家发展战略中的一环,主流融媒体中心与平台建设成为大势所趋。信息经济形态下信息资源成为产业发展的关键要素,大数据时代主流融媒体的特性使其在享受着丰饶的媒体资源的同时还面临着信息过载和信息过剩的风险,从而导致其效能无法得到充分发挥。如何对主流融媒体信息资源进行高效组织与管理成为主流融媒体建设与价值创造的重要基石。论文从主流融媒体信息资源组织管理需求入手,综合利用大数据技术、自然语言处理技术和语义网技术,探索构建主流融媒体信息组织管理机制,对其中所涉及的信息获取、提取、描述与归集等关键问题进行研究,着力实现主流融媒体信息资源的高效组织,为资源利用与价值提升奠定基础。首先,基于主流融媒体的内容建设特点与面临的资源环境特性明确主流融媒体信息组织管理需求;其次,通过爬虫与大数据技术实现多源异构信息资源的分布式增量获取和分布式并行存储与处理,为信息组织管理打造坚实的数据底座;再次,基于信息资源兼容性处理理念将主流融媒体多模态信息资源处理简化为文本数据挖掘,并利用自然语言处理技术通过深度学习和文本聚类对资源的语义特征和主题特征进行提取与聚合;然后,构建主流融媒体信息单元,以封装结构屏蔽资源表达的差异性,并基于来源信息与主题事件实现信息单元间的关联;最后,结合仿真结果和主流融媒体信息组织管理中存在的关键问题,从信息组织全链条出发提出了相应的管理建议与对策。研究结果表明,论文所提出的主流融媒体信息组织管理机制能够较好的适应大数据时代背景下主流融媒体信息组织管理的需要,并为信息的深度利用提供了依据。相较传统方法,论文所提方法在信息采集效率、信息处理能力、信息提取精度和信息关联效果等方面均有明显提升。
{URL}: https://link.cnki.net/doi/10.27008/d.cnki.gdbdc.2023.000202
{DOI}: 10.27008/d.cnki.gdbdc.2023.000202
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的图像描述算法研究
{Author}: 柯杰
{Tertiary Author}: 曾上游
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像描述;自然语言处理;卷积神经网络;长短期记忆网络;注意力机制
{Abstract}: 深度学习图像描述是一项计算机视觉任务,涉及使用深度学习算法生成图像的自然语言描述。它在图像搜索,字幕和自动图像注释等字段中具有许多应用价值。近年来,随着注意机制,变压器模型和其他深度学习技术的发展,该领域取得了许多进步。这些模型已在基准数据集(例如MSCOCO和Flickr30k)上实现了最先进的结果。然而该领域还是存在巨大挑战,例如需要改善生成语言的多样性和连贯性,处理稀有和新颖的语音概念以及提高模型的效率。总体而言,深度学习图像描述是一个令人兴奋的迅速发展的领域,并具有许多实际的应用和研究机会。在现阶段的研究中大多是基于编码器-解码器结构进行的,为提升图像描述的精确度还可以引入注意力机制,本研究主要设计在编码器部分采用VGG19和Res Net101对图片进行特征提取,解码器使用长短期记忆网络,并提出了一种新的改进注意力机制来增强图片与词之间的相关性,最后输出自然语言。本研究在Flickr8k和MSCOCO两个公共数据集上进行了对比实验,并使用BLEU、METEOR和CIDEr等多种评价指标对模型进行了全面评估。实验结果表明,基于改进注意力机制的图像描述生成模型在图像描述任务中表现更优,相比传统的注意力机制模型,其准确性有了明显提升,有显著的优越性。为了进一步提升图像描述的准确性和评价指标,在编码器部-解码器架构的研究基础上,提出了一种采用双重注意力机制的模型DAA-Net(Dual Attention-Aware Network),即编码部分采用深度残差网络Res Net101,能更好的提取图片特征,在训练过程中,为缓解训练和测试过程中可能出现的输入不一致问题,本研究还提出一种采样策略,即将实际标注的单词和模型生成的单词按一定比例进行采样,并将其作为解码器的输入。实验结果表明,该采样策略在一定程度上有效缓解了输入不一致问题。同时采用了多层卷积神经网络(CNN)对图像进行自动特征提取,以提高图像描述的质量,并使评价指标达到人类识别水平。为了有效地处理自然语言句子中的语义信息,循环神经网络(RNN)被引入解码器中,从而提高了图像描述的准确性。解码部分使用长短期记忆网络,在DAA模块的处理下,通过减少模型参数的改进的注意力机制,能够更好的处理建模图像中不同目标之间的关系,使得解码器得到更准确的注意力区域,引入层归一化方法减少模型训练的时间,获得图像的语言描述,提升了图像描述生成模型的评价指标。使用编码器架构和注意机制的使用导致了图像描述领域的显着改善,从而可以使用深度学习技术对图像进行更准确、多样化和连贯的描述。使注意力机制轻量化的同时将注意力结果和查询结果的相关性进行确定,来增强图片与词之间的相关性,最后输出自然语言。在进行图像描述时使用的改进注意力机制模型,结合公共数据集MSCOCO和Flickr30k的对比验证结果,表明该模型在加速模型收敛速率、提高相关评价指标以及增强模型性能方面都表现出显著的优越性,相较于传统的一般注意力机制模型,更好地处理了建模图像中不同目标之间的关系,使得解码器获得更准确的注意力区域,提高了相关评价指标并增强了模型性能,有显著的优越性的同时实现更准确的图像描述生成。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2023.002048
{DOI}: 10.27036/d.cnki.ggxsu.2023.002048
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度图神经网络的文本分类研究
{Author}: 刘永皓
{Tertiary Author}: 管仁初
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图神经网络;文本分类;论文发表场所预测
{Abstract}: 随着迈入信息时代,在现实世界中,我们的周围充斥着大量文本。如何有效地处理这些文本并提取所需要的信息,这是一个有挑战性的问题。得益于文本挖掘领域的快速发展,文本分类吸引了来自学术界和工业界的广泛关注,并取得了十分显著的发展。文本分类是自然语言处理一项十分经典和基础的任务,它的目的是为给定的文本赋予正确的标签,已经被广泛用于各种实际应用中,比如,问答系统、主题分类和论文发表地点预测等。与早期的基于规则的文本分类方法相比较,基于统计的文本分类方法有更好的准确率和稳定性。但是它们仍然严重依赖手工特征工程,这一个过程需要严谨的处理或者专业的领域知识,可能会消耗大量的时间并且费用高昂。同时,这些模型并没有充分利用大量的训练数据,因为相关的特征已经被提前定义。最近,深度学习的出现极大地改变了人工智能领域。这些深度学习方法能够自动地对复杂的特征进行建模并产生有语义和语境的文本表征,从而消除了繁琐复杂的手工特征设计过程,已经成为了包括文本分类在内的自然语言处理任务的主流范式。虽然之前基于序列的深度学习模型可以很好地捕捉局部连续词序列中的语义和句法信息,在文本分类任务中已经取得了令人印象深刻的进步,但是它们仍然有一些限制。首先,它们不能很好地捕获长距离的单词之间的交互,从而忽略了这些单词的全局共现信息。其次,它们忽略了文本中蕴含的语法或者句法结构,而这对正确理解文本是有帮助的。最近,图神经网络逐渐变成一个研究热点,因为其在处理复杂结构数据和关系的强大表现能力。在文本分类任务中,一系列基于图神经网络的模型也取得了令人瞩目的表现。本文基于图神经网络首先研究了文本分类的一个具体应用场景,即论文发表场所预测。针对这个应用场景,之前提出的模型忽略了论文内部的结构信息,同时使用手工制作的特征来表示论文,而忽略了那些涉及高级语义的特征。为了解决以上问题,本文提出为每个论文摘要构建语义图,并执行双重注意力消息传递神经网络以得到它们的辨别性论文摘要表征。在相关数据集上的大量实验结果表明,所提出的模型性能非常出色,显著优于现有的基线方法。接下来,本文分析了之前提出的基于图神经网络的文本分类模型存在的缺陷。首先,这些模型仅仅考虑了文本内单词的一阶邻居,同时如果堆叠一定数量图神经网络层之后会出现过平滑问题。针对这些缺陷,本文提出一种深度图注意力扩散模型用于文本分类任务。具体来说,该模型首先使用注意力扩散技术来扩大文本中单词的感受野,这样做能够在每一层中捕获长距离的单词交互。此外,为了训练更深的神经网络以提取单词的隐藏语义,该模型将图神经网络的特征转换和特征传播过程解耦,这样也能缓解过平滑问题。在一系列基准数据集上的表现证明了本文提出的模型的优越性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.005028
{DOI}: 10.27162/d.cnki.gjlin.2023.005028
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向开源数据的网络安全威胁情报挖掘关键技术研究
{Author}: 程顺航
{Tertiary Author}: 李志华;林其光
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 威胁情报;实体识别;关系抽取;数据投毒;虚假情报挖掘
{Abstract}: 网络安全威胁情报作为一种全面、准确、结构化网络安全信息,通过信息共享提供安全预警和决策支持,是开展安全防御工作的基础和前提。目前,网络安全威胁情报广泛存在于APT报告、安全博客等开源非结构化数据中,其中包含的威胁实体和关系等重要信息难以被直接使用,并且存在着许多虚假的内容。对此,本文重点研究面向开源数据的网络安全威胁情报挖掘技术,主要工作概况如下:(1)针对网络安全威胁情报文本中非结构化信息难以充分利用且训练样本稀少问题,提出一种面向少样本的威胁情报实体关系抽取(Threat Intelligence Entity Relation Extraction,TIERE)方法。首先,根据开源网络安全分析报告复杂度高、专业性强的特点,研究并提出了一种数据预处理方法,用于提高文本的可分析性;然后,提出了基于改进自举法的命名实体识别(Name Entity Recognition based on Improved Bootstrapping,NER-IBS)算法,以及基于语义角色标注的关系抽取(Relationship Extraction based on Semantic Role Labeling,RE-SRL)算法,所提算法利用少量样本和规则构建初始种子,经过多次迭代挖掘威胁实体,并通过构建语义角色的策略抽取实体间的关系;最后,使用STIX2格式规范对提取的实体和关系进行标准化表示。实验结果表明,TIERE方法能够在少样本环境下有效地挖掘威胁情报实体及其关系。(2)针对网络安全威胁情报实体中存在分类模糊、语境相似以及分布不均匀的不足,提出一种威胁情报实体识别(Threat Intelligence Entity Identification,TIEI)方法。首先,对网络安全威胁情报文本进行预处理,将冗余信息较多的长文本转化为精简的词序列;然后,研究并提出融合专业知识的机器阅读理解(Machine Reading Comprehension with Specialized Knowledge,MRC-SK)模型,该模型使用注意力机制学习额外的专业知识,并通过指针网络预测问题在原始文本中对应答案的开始索引和结尾索引;最后,为缓解实体分布不均匀对识别结果的影响,在模型训练阶段,使用Dice损失函数代替交叉熵损失函数。实验结果表明,TIEI方法能够有效地挖掘具有分类模糊和语境相似的威胁情报实体。(3)为了有效地识别开源网络安全威胁情报中的虚假信息,针对现存的数据投毒攻击手段,提出了一种虚假威胁情报挖掘(Fake Threat Intelligence Mining,FTIM)方法。首先,研究并提出基于GPT-2的虚假威胁情报生成(Generation of Fake Threat Intelligence Based on GPT-2,GFTI-GPT)模型,该模型利用通用数据预训练,使用网络安全威胁情报文本进行微调,并通过Top-P采样随机生成虚假情报;然后,模拟数据投毒攻击方式,分析虚假情报对真实网络安全数据源所造成的影响,并对真实情报和虚假情报进行标注,以此构建样本数据集;最后,结合BERT预训练模型,研究并提出基于Text CNN的虚假威胁情报分类(Classification of Fake Threat Intelligence Based on Text CNN,CFTI-TC)模型,该模型可有效地识别虚假的网络安全威胁情报。实验结果表明,FTIM方法能够有效地识别开源数据中的虚假信息。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.001808
{DOI}: 10.27169/d.cnki.gwqgu.2023.001808
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的图像语义分割方法研究
{Author}: 张鑫
{Tertiary Author}: 姚庆安
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像语义分割;卷积神经网络;Transformer;轻量级网络;编-解码结构
{Abstract}: 图像语义分割一直是计算机领域具有挑战性的课题研究,但随着卷积神经网络在图像语义分割领域的研究逐渐趋于饱和,目前的语义分割精度难以提升是一个急需解决的问题。因此,研究人员开始把目光转向自然语言处理领域大火的Transformer,该网络基于自注意力机制不受局部相互作用的影响,既能挖掘长距离的依赖关系又能并行计算,取得与卷积神经网络相当的实验结果。然而图像局部关联性缺失、复杂计算量等一直是Transformer网络研究的痛点。本文在基于Transformer的基础上展开研究,保留图片局部相关性,设计轻量级图像编-解码分割网络。具体的研究内容如下:(1)本文提出基于Transformer的图像语义分割框架。主要结合图像金字塔的分割思想来分割不同层图像的语义信息,从而获取不同维度的语义特征图,采用计算机视觉常用的编-解码结构,设计更加符合下游分割任务的模型结构,进一步完善Transformer用于图像分割任务。(2)编码部分。提出重叠图像切割模块,保留图片中相邻位置的语义关联性。不同于自然语言处理,该模块保留图片本身的局部相关性,保持高分辨率的分割特征图,提高语义分割精度。对于本文中间阶段的网络,同样输入重叠后的切割图片,保证不同层次图片的高分辨率。(3)解码部分。本文采用更加简易有效的解码结构,不同于以往的复杂设计,而是消减模型的计算量。本文提出的轻量级解码部分适用于主干网络Transformer,不仅大大减少冗余的参数量,而且精度也大大提高。基于以上内容研究,与传统卷积神经网络模型相比,本文模型在ADE20K、Cityscapes和VOC 2012数据集上取得40.18%、77.61%和64.64%的精度。进一步验证模型的有效性,为进一步实际应用奠定基础。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000728
{DOI}: 10.27805/d.cnki.gccgy.2023.000728
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的命名实体识别研究
{Author}: 庞海婷
{Tertiary Author}: 赵辉;刘乐
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;中文预训练模型;多层感知机;虚拟对抗训练;循环膨胀;卷积神经网络
{Abstract}: 在智能科技和互联网快速发展的今天,高效提取文本中有价值的信息、利用这些文本数据已经成为研究的关键。命名实体识别(Named Entity Recognitio n,NER)主要用来处理文本数据,识别非结构化文本中指代性强的实体。但是研究发现中文实体识别过程中受实体边界模糊、多义字、多音字等因素影响,且非实体较多容易造成噪声影响,单个神经网络模型提取的特征信息局部不稳定,以上因素均影响了中文实体的识别效果。因此,本文提出了两个中文细粒度实体识别模型,工作内容主要围绕以下两个部分进行:(1)针对在实体识别过程中存在实体边界模糊、多义字、多音字等现象,导致无法很好的表征字词信息的问题,且非实体导致的噪声影响,本文提出基于中文预训练和虚拟对抗训练的细粒度实体识别模型(CBERT+VAT+(MLP+Bi LSTM)+CRF模型,CBV-MBC模型)。首先通过中文预训练模型Chinese BERT生成融合拼音向量、字形向量、字向量、位置向量的丰富语义向量,在语义向量表示上输入相同大小的对抗扰动生成对抗样本,分别计算对抗样本和原始样本的损失,加和后输入到多层感知机MLP和双向长短时记忆网络Bi LSTM中,将生成的全局向量输入到条件随机场CRF中进行解码,获得全局优化预测标签序列,实现了中文细粒度命名实体识别任务,得到了准确率较高的识别效果。(2)为了充分提取文本的特征信息,本文提出基于循环膨胀卷积和融合神经网络的细粒度实体识别模型(CBERT+VAT+(Bi LSTM+MLP)+IDCNN+CRF模型,CBV-IDCMBC模型)。将循环膨胀卷积神经网络IDCNN融入到基于中文预训练和虚拟对抗训练的中文细粒度命名实体识别模型中,凭借IDCNN提取文本局部特征的优势,结合多层感知机MLP和双向长短时记忆网络Bi LSTM提取融合后的全局特征,将融合全局特征和局部特征的特征信息输入到条件随机场CR F中解码并标注结果,CRF能有效捕捉到标签之间的依赖关系,得到全面的标签序列。本文提出的命名实体识别模型分别在CLUENER 2020数据集、Weibo NER数据集和Resume数据集上进行了对比实验和消融实验,实验结果表明本文提出的两个模型均能够有效提升命名实体识别的效果,验证了模型的有效性。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.001005
{DOI}: 10.27805/d.cnki.gccgy.2023.001005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 《发展汉语》口语教材课文语言的自然性研究
{Author}: 揣舒冰
{Tertiary Author}: 王倩
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 课文语言材料;自然性;《发展汉语》口语教材;词语选择;招呼语
{Abstract}: 在国际中文教育的过程中,教材是教学过程中的重要一环。教材中课文承担了大部分语言输入的功能与作用,是供学习者学习和模范的范本。对话不自然、语言生硬刻板的教材课文,会对学习者的语言模仿和习得效果带来消极影响。国内学界这方面的计量实证研究较少,因此对汉语教材中课文语言的自然性进行研究考察十分必要。本文从语言本体论出发,在辩证分析“自然性”概念的基础上,理论上构建考察口语教学材料语言自然性的评估模型,并选取《发展汉语》口语教材为研究对象,主要以词语及句子为考察单位,采用定性定量结合的方法,以整体分析与个案分析结合的方式,考察该教材课文语言的自然性。从词语选择和招呼语使用两个层面对课文语言的自然性进行考察,选择招呼语以及招呼语“你好”,从交际对象、交际场景分布、语用功能等角度详细分析了课文语言自然性的实际呈现情况。就提高课文语言自然性问题从编写教材和教师如何更好利用已出版教材进行教学两方面提出针对性建议。在词语选择自然性方面,通过问卷调查了解母语者的心理倾向,结合大型稳定的语料库证实该心理倾向的普遍性,以此作为词语选择自然性考察的依据。教材中多数课文的选词自然性较高,但韵律结构的搭配、词语的时空限制、语用搭配以及语篇回指方面可以更加完善。在招呼语使用自然性方面,首先,从招呼语类型、交际场景、交际对象、语用功能四个角度对教材中的招呼语进行总体考察。交际实际中常见的招呼类型在教材中均得到了相应的体现,但在类型设置的全面性方面仍可完善;对交际场景和交际对象的呈现由初级到中级逐渐丰富;在语用功能方面,初、中、高级阶段教材招呼语设置以“整体介绍-常见类型-高频类型强调”的方式进行展示,符合了口语交际自然性实际,同时也符合学生的学习规律。其次,从交际场景和交际对象两方面进行对特定招呼语“你好”进行自然性考察。将教材中出现的场景分为正式、半正式、非正式三类,非正式场景占比最高;将教材中出现的交际对象分为陌生、熟悉两类,与陌生交际对象交际时使用“你好”的情况占比最高。教材中“你好”在交际对象的使用自然性较高,在交际场景上则没有体现出母语者很少在非正式场景中使用你好的语用限制。通过上述工作以点带面地考察《发展汉语》口语教材课文语言的自然性问题,在此基础上,我们提出了教材编写要贴近真实的交际过程、对教材做及时更新、在教材课文中加强语用文化的渗透、汉语教学中对低自然度的表达进行替换和更新、为学习者创设真实的交际环境、多体裁多渠道选取真实交际语料纳入汉语教学等针对性建议。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.002569
{DOI}: 10.27162/d.cnki.gjlin.2023.002569
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本生成图像方法研究
{Author}: 张佳
{Tertiary Author}: 张丽红
{Publisher}: 山西大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;文本生成图像;生成对抗网络;Transformer;注意力机制
{Abstract}: 深度学习是通过卷积神经网络、自编码神经网络等深度网络模拟人脑神经系统结构和功能的一种机器学习方法。深度学习及相关算法的不断进步使得文本生成图像成为人工智能和计算机视觉领域倍受关注的研究热点之一。文本生成图像旨在将文字描述通过神经网络模型生成相匹配的图像,该任务融合了文本、噪声与图像等多种模态的信息。在传统图像生成方法研究中,生成图像往往存在着畸形、分辨率较低及与文本描述不匹配等问题。为了解决这些问题,本文构建了两种基于深度学习的文本生成图像网络。设计了更高效的文本编码器对文本处理网络进行改进;分别在生成网络中设计注意力机制、Transfomer多头注意力机制等模型,以提高生成图像的质量和文本匹配度。论文构建了基于条件增强和注意力机制的文本生成图像网络模型,该模型由文本处理网络和生成对抗网络两部分组成。文本处理网络采用双向长短期记忆网络对文本特征进行提取与处理,通过条件增强模块增加文本词语对应的特征数据,丰富文本语义特征。在生成对抗网络中文本特征与视觉特征进行融合,通过使用注意力机制从通道和空间两个维度对输出特征进行调整,使生成网络关注文本描述的重要特征,最终得到生成图像。通过判别器对生成图像与真实图像进行判别,并设计对抗损失函数对网络模型进行优化。通过在MSCOCO和CUB birds 200两个数据集上进行实验,评估相应的指标,与其他方法相比该方法具有明显优势。论文构建了预训练模型CLIP与Transformer网络的文本生成图像模型,该模型同样也由文本处理网络和生成对抗网络两部分组成。文本处理网络采用CLIP模型进行文本特征提取与处理。对于生成对抗网络,在生成器中,通过多层感知机实现了特征的非线性映射;依次输入Transformer编码器、上采样网络中进行特征提取,Transformer编码器中的多头注意力机制显著提高了模型处理长文本序列、建立文本与图像之间的关联、并行计算等方面的效率;通过线性逆摊平层重构图像。在判别器中,将生成图像输入Transformer编码器与线性摊平层进行特征提取,对生成图像与真实图像进行判别。针对网络各个部分设计对抗损失函数。采用Multi-ModalCeleb A-HQ数据集和CUB birds 200数据集进行实验,对相应的指标进行评估,证明了该方法良好的生成效果。
{URL}: https://link.cnki.net/doi/10.27284/d.cnki.gsxiu.2023.000908
{DOI}: 10.27284/d.cnki.gsxiu.2023.000908
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能的意向性问题研究
{Author}: 郭玲君
{Tertiary Author}: 董佳蓉
{Publisher}: 山西大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人工智能;意向性;语义;符号
{Abstract}: 意向性是心智哲学研究中的重要问题,它也被视作判断人工智能是否拥有智能的关键。塞尔是人工智能领域中意向性问题的发起者,他在中文屋论证中提出:意向性是人类特有的,而计算机系统无法获取该能力。由此引发了人工智能领域专家学者对于意向性的激烈讨论。由于科学技术以及人类自身认知的局限性,人工智能中的意向性问题还未能给出满意的解决方案。本文第一章首要简述了该论文选题的意义、目前国内外的研究现状以及研究的内容与思路。第二章介绍了人工智能技术在符号主义与联结主义两种范式下发展迅速,学界对人工智能的未来十分乐观,并提出了强人工智能的目标。在众多批判者中,塞尔以中文屋论证指出了强人工智能的目标根本无法实现、语义的缺失导致人工智能不具有理解力,无法获得人类意向性的人工智能始终不是真正的智能。笔者将现存的意向性问题划分成了两类,分别是人工智能能否获得意向性以及人工智能能获得哪种意向性。第三章对内在主义的意向性理论进行了系统的分析。塞尔坚持意向性是内在的,同时强调只有生物意义下的大脑才能获得这种内在的意向。对此福多提出了建立思想语言假说来表明大脑认知与语词之间的联系,但这并不符合意向性的先验的特性;计算主义则尝试了语义表征的方式,但是语义表征的实现需要依赖科学技术水平进一步提升;目前最前沿的大规模预训练语言模型,虽然能够实现零样本的数据处理,但依旧无法获得语义使得结果经常出现虚假的情况。第四章中讲述了这种内在的人工智能意向性受到外在主义者的反对。首先以丹尼特为代表的实用主义,他们反对意向性来源于生物自身,主张意向性来源于人脑意识的赋予。以哈那德为代表的功能主义不认可塞尔内在的意向性观点建立在计算机系统之上,他主张将两者分开认识,认为计算机系统只能获得派生的意向性。面对计算系统如何获得理解能力而获得意向性,专家们提出了自己的解决方案:分别是哈那德的拥有外部感觉运动系统的机器人、维戈托等人的猜谜游戏、弗洛里迪零语义的解决方案,但是这些理论都呈现出了行为主义或者目的缺失的弊端。在第五章中本文提出了人工智能智能目前只能获得意向性特征,而这种派生的意向性可能以还原论、目的论、具身化的三种方向达成。最后阐述了研究人工智能意向性问题给认知哲学以及人工智能的自然语言处理技术带来了积极的影响。
{URL}: https://link.cnki.net/doi/10.27284/d.cnki.gsxiu.2023.001175
{DOI}: 10.27284/d.cnki.gsxiu.2023.001175
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 我国产业政策知识图谱构建与应用
{Author}: 于小涵
{Tertiary Author}: 蔡永明
{Publisher}: 济南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;产业政策;电子政务;Neo4j图数据库
{Abstract}: 目前国家重视产业改革,政府出台大量相关政策推动产业结构升级,促进经济高质量发展。相关企业需要及时获取政策态势,提前做好战略调整。但是产业政策条目繁杂,海量内容分散在各个政府及媒体网站,既不利于政府高效管理政策文本,也不利于公众及时获取政策动向。而知识图谱能够以有效的方式提取知识,形成紧密的知识网络,使得信息高度凝练、便于掌握。因此,本文将知识图谱与产业政策结合,使用知识图谱构建产业政策知识网络,实现产业政策的知识融合与集成。本文通过梳理已有文献,总结了知识图谱的相关基本概念、构建流程和关键技术,结合产业政策知识图谱的特点选择了自顶向下的构建方法,即先构建知识图谱的逻辑层架构,再构建知识图谱的数据层实例。逻辑层以设计产业政策的本体模型为主,本文提出的本体模型包括政策、省份、年份、关键词、行业、战略性新兴产业六类实体,涉及政策代码、政策名称、主要内容等十项属性,涵盖颁布政策、关键词包含、引用、政策相似等七种关系。数据层利用Python实现政策文本的批量处理,采用正则表达式抽取文本中的引文,BERT-Text CNN模型抽取每篇政策所涉及的行业,TF-IDF算法抽取每篇政策中的关键词,Text Rank算法抽取每篇政策的摘要作为主要内容,Jaccard系数计算不同政策文本的相似度。然后选用Neo4j图数据库对抽取的知识单元进行存储,将绘制的知识图谱进行可视化展示,并通过多种查询方式综合验证了本文构建产业政策知识图谱流程的可行性以及最终结果的可靠性。最后以问答系统为例,将构建好的产业政策知识图谱作为数据库,另用Python编写了包含识别问句实体和意图、识别问句类型、构造查询语句、返回拼接答案四个模块的后端逻辑层,并借助Streamlit框架完成前端开发,探究了产业政策知识图谱在政策服务中的应用。本文提出了一种新的产业政策本体模型,并利用我国2009到2021年内与产业政策相关的文本数据构建了产业政策知识图谱和基于该知识图谱的问答系统,为知识图谱在政策信息领域的构建和应用提供了参考,具有一定的理论和实际意义。
{URL}: https://link.cnki.net/doi/10.27166/d.cnki.gsdcc.2023.000279
{DOI}: 10.27166/d.cnki.gsdcc.2023.000279
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向纺织行业的多模态知识图谱构建方法及应用
{Author}: 王欢
{Tertiary Author}: 宋丽娟;杜方
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 纺织行业;多模态知识图谱;表单知识抽取;跨模态实体对齐;知识库
{Abstract}: 多模态数据间交互式任务的涌现对综合利用不同模态的知识提出了高要求,所以多模态知识图谱应运而生,其通过融合不同模态知识来满足这类任务的需求。然而,面向纺织行业的多模态知识图谱构建仍然面临着一些挑战。首先,表单文档中包含大量可复用知识,而当前图谱构建却很少利用自动化方法抽取表单文档的结构化数据,导致图谱的内容相对不足。其次,现有实体对齐方法大多针对传统知识图谱设计,未充分考虑图像信息且需要大量人工标注数据,因此如何对跨模态实体进行对齐成为主要难点。最后,构建纺织行业的本体层和数据层,并且实现多模态知识图谱的可视化,是一个是亟待解决的问题。为了解决以上问题,本文提出了一系列面向纺织行业的多模态知识图谱构建及应用方法。主要研究工作如下:(1)提出了一种基于改进的LayoutXLM表单知识抽取模型(Table Document Knowledge Extraction,TDKE)。现有的表单知识抽取模型受OCR识别影响,存在文本边界框行错位问题,导致实体关系建模不准确。本文所提出的TDKE针对此问题设计了表单文本边界框BBox行对齐算法,通过计算并校正边界框位置实现表单行之间的对齐,从而避免文本边界框行错位。接着利用LayoutXLM表单预训练模型对行对齐后的表单进行键值对抽取。实验结果表明,该方法可以有效提升表单中实体及关系抽取的精度,抽取的结构化数据可以为领域多模态知识图谱的构建提供可靠数据来源。(2)提出了 一种中文跨模态实体对齐预训练语言模型(Chinese Cross-Modal Entity Alignment,CCMEA)。该模型基于无监督学习方法,首先利用视觉和文本双流编码器分别提取不同的单模态特征。然后针对不同模态特征难以交互的问题,设计了一种交叉编码器以引导跨模态特征间的学习,使得单一模态特征更精细化。最后为突出跨模态实体间的联系和差异,采用对比学习方法增强图像实体和文本实体的匹配度和差异性。实验结果表明,该方法不需要进行复杂的多模态数据标注工作,即可在下游小样本数据集上有良好泛化能力,实现了领域多模态知识图谱的跨模态实体对齐任务。(3)构建了面向纺织行业的多模态知识图谱。依据设计的纺织行业知识本体,综合应用本文提出的表单知识抽取、中文跨模态实体对齐方法以及BERT-BiLSTM-CRF命名实体识别、爬虫等技术完成纺织行业多模态知识图谱数据层的构建。最后使用KGBuilder工具完成纺织行业多模态图谱的构建及可视化,为下游应用提供了数据支持。(4)开发了面向纺织行业的多模态知识库管理系统。综合应用SpringBoot、Vue等技术方法,构建面向纺织行业的多模态知识库管理系统,为用户提供知识检索、知识导入、专家审核等功能。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2023.001054
{DOI}: 10.27257/d.cnki.gnxhc.2023.001054
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT预训练模型的中医医案命名实体识别研究
{Author}: 刘彬
{Tertiary Author}: 肖晓霞;李科威
{Publisher}: 湖南中医药大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 实体识别;部首特征;BERT模型;双向长短期记忆模型;条件随机场
{Abstract}: 目的:中医医案是中医师辨证论治、察明证素的记录,是中医临床经验传承的资料。从用自然语言描述的医案中抽取有效的命名实体、结构化医案,是利用机器学习、深度学习等技术深挖中医知识的基础。中医历经2000多年的发展,其医案中有大量的古文,且存在书写自由、术语表达丰富、结构复杂等特点,这给医案中命名实体的提取带来挑战。本研究旨在运用命名实体识别技术提取出医案中的症状、处方、证候等关键信息,结构化医案,为后期利用数据挖掘、知识图谱等技术提供结构化临床数据。方法:本研究团队从电子版中医医案《中国现代名中医医案精粹丛书》中提取了部分术语、构建了术语词典,用于自动标注医案文本。本研究提出了一种基于词典的双向最大匹配法的语料标注法,对400份医案中的身体部位、症状、疾病、药物等采用BIO方式进行标注,将标注好的文本再做人工核查确保标注的正确,最终获得了一个有五万余字的标注好的文本。医案中身体部位、药物、症状、疾病按双向最大匹配法进行标注,其它的内容标注为O。为了提高命名实体识别率,分析中医命名实体发现所需识别术语的部首极具特点,采用静态爬虫技术收集了偏旁部首,构建了部首词典。最后采用以BERT为基础模型,分别结合LSTM、CRF和部首特征构建基于深度学习的命名实体识别模型。其中BERT-LSTM-CRF-部首特征模型需要在BERT词向量中嵌入汉字部首并进行训练,且采用BiLSTM提取特征,使用CRF进行序列预测。结果:使用标注后的医案数据进行实验,本文模型的精确率为85.72%,召回率为86.62%,F1值为86.17%,与模型BERT、BERT-CRF、BERT-BiLSTM-CRF相比,其F1值分别提升了2.68%、2.47%、1.48%,表明本文模型在医案实体识别中效果最佳。结论:实验结果表明,在嵌入部首特征之后,模型的P值、R值、F1值均得到了提升。说明部首特征与医案中的实体联系紧密,嵌入之后使得模型对于实体的识别更具有针对性,能够用于中医医案命名实体的识别。同时,与其它方法相比,本文的方法具有更好的实体识别效果,为中医医案知识发现提供新的思路。
{URL}: https://link.cnki.net/doi/10.27138/d.cnki.ghuzc.2023.000574
{DOI}: 10.27138/d.cnki.ghuzc.2023.000574
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的实体关系联合抽取和COVID19领域问答系统构建研究
{Author}: 文瀚冬
{Tertiary Author}: 刘晓勇
{Publisher}: 广东技术师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;提示学习;信息抽取;知识图谱;问答系统
{Abstract}: 大数据时代下的互联网上产生了海量且冗杂的文本信息,提取关键信息以洞察价值变得尤为关键。同时,知识图谱和问答系统作为实现数据价值的有效工具,支撑其实现的实体识别和关系抽取任务受到了越来越多的关注。近年来出现的GPT-3等生成式预训练语言模型为信息抽取任务的做法提供了新思路。目前预训练-微调的做法会导致模型与下游任务之间存在差距并且信息抽取任务中会出现实体交叠等问题,导致抽取信息不够精确和全面。同时面对随时爆发的流行疾病,缺少一种针对疾病和药物方面的解决方案。针对上述问题,本文基于提示学习方法对信息抽取任务展开研究,设计并使用信息抽取模型参与知识图谱和问答系统的实现。1.基于提示学习的实体关系联合抽取方法研究。根据信息抽取任务抽取三元组的特点。由人工对模板进行设计,提示模板由标识符、插槽和用于连接上下文的自然语言组成,目标模板则设计为三元组形式用于引导模型生成期望输出。考虑到由人工构建的模板可能会因长度和内容不同导致模板起到的效果存在差异,通过调整关系在三元组中所处的位置设计了三种类型的提示模板。针对数据中部分实体会出现交叠的情况,分别设计了针对有交叠和无交叠情况下的目标模板。为了进一步丰富模板的提示内容,根据数据的标注信息将实体关系信息插入模板插槽中。为了加强模板在模型中的提示效果,为模板设计了对应编码层。另一方面。考虑到由人工构建的模板使模型学习效果差等问题,通过引入通配符取代提示模板中用于连接上下文的自然语言文本,进一步简化模板。同时,通过设计提示模板优化层,使模型仅对通配符部分的参数进行优化,使模型能够通过训练参数变化找到效果较好的模板形式。实验结果表明,所提出的方法通过引入提示模板缩小了预训练模型与下游任务之间的差距,同时基于模板的方法能够有效解决实体交叠问题,从而得到较好的抽取结果。2.基于COVID-19疾病和药物的知识图谱构建研究。首先,以百科名医网站的网页知识作为数据源,并通过爬虫技术完成对数据的采集。其次,使用信息抽取模型对采集数据进行知识抽取。最后,通过使用neo4j图数据库实现知识图谱的数据存储和的可视化。3.基于COVID-19疾病和药物的问答系统构建研究。首先,对系统进行需求分析,将系统自顶向下设计为应用层、处理层和数据层三层。其次,采用Django框架对系统架构设计为MVT模式。接着,对系统中应用模块的业务逻辑进行设计和实现。最后,将设计好的系统进行展示和测试。
{URL}: https://link.cnki.net/doi/10.27729/d.cnki.ggdjs.2023.000405
{DOI}: 10.27729/d.cnki.ggdjs.2023.000405
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算思维培养的小学高段信息科技课堂游戏活动设计与实践
{Author}: 盛密
{Tertiary Author}: 马晓玲
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算思维;小学科技课堂;课堂游戏活动;游戏设计
{Abstract}: 计算思维是21世纪创新型人才的核心素养,也是义务教育阶段信息科技学科的核心素养之一,体现着信息科技学科的重要育人价值。计算思维能力的培养越来越受各界关注,近年来,教学游戏逐渐成为一种探索新型教学模式的工具,游戏化教学也相继在各个学科得到实践和应用。但计算思维是新生事物,人们对计算思维培养的研究处于探索阶段,只有小范围的实证研究和应用,未形成系统化、标准化和科学性的培养方案以及策略。因此,结合现有研究成果与教学实际问题、以及新课标的理论指导,针对学生共同参与游戏活动与游戏设计以达到计算思维技能训练的探究十分有必要。本研究包括以下三部分内容:首先,采用文献研究法对计算思维与游戏化教学的相关文献进行梳理和分析,厘清计算思维的内涵及培养策略、游戏化教学现状。通过文献研究发现,计算思维是一种运用计算机科学领域的思想方法来解决问题的思维方式,计算思维的培养集中在课程教育中,主要通过机器人技术、游戏设计、程序设计语言等计算工具开展。因此,基于游戏活动的编程教学有利于提升学生的计算思维素养。其次,在相关理论基础的支撑下,基于大量的文献梳理和分析,结合教学现状构建出基于计算思维培养的小学高段信息科技课堂游戏活动设计方案,并进行教学实践。该方案包括教学分析、教学目标设计、教学内容设计、教学策略设计、游戏活动评价设计六个方面。为检验该方案的实践效果,在宁夏银川选取X小学进行为期两轮的教学实践,通过行动研究法将该方案运用于实际教学情境中,并分析其实践效果。最后,通过综合性评价方式分析教学实践效果。在教学实践前后,采用问卷、访谈、量表等对教学实践过程进行数据收集和分析,得出结论:在信息科技课中融入游戏活动能够提高学生的学习主动性,基于编程语言的游戏设计可以有效提升学生的计算思维能力。综上所述,在信息科技课堂中融入教学游戏活动,紧密结合游戏活动主题与教学目标,依托编程设计实现游戏功能,不仅能够启发学生的思维方式、提高学生的学习积极性,也能够锻炼学生的算法思维、评估迭代、纠错等思维素养;而问题解决方案设计是解决一个问题的过程性描述,能够很好地锻炼学生的评估思维和算法思维,从而训练学生的计算思维技能。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2023.000043
{DOI}: 10.27257/d.cnki.gnxhc.2023.000043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的中文文本摘要方法研究
{Author}: 徐尔卓
{Tertiary Author}: 秦董洪
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本摘要;指针生成网络;LSTM;BERT;空洞卷积
{Abstract}: 随着大数据、人工智能、云计算等技术的发展,互联网上累积了海量文本数据,为了提取其中的关键信息,文本摘要技术应运而生。一般而言,生成文本的简短摘要必须满足信息量充分、能够体现原文的主要内容、冗余度低等要求。但目前生成式文本摘要技术存在生成质量不高、语句不流畅等问题。因此,针对于目前文本摘要生成存在的不足,提出了一种改进的指针生成网络(PGN,Pointer-Generator Networks)模型来提升生成式文本摘要的质量,所展开的研究内容与创新性工作如下:(1)针对PGN容易出现生成错词、漏词和重复词等问题,提出了一种基于BERT模型改进的预提取器模块,并将该模块引入PGN。改进的模型通过加入BERT模块来提高文本信息之间的依存关系,可有效缓解局部信息偏好的缺陷。(2)针对自回归式模型对于生成类任务容易产生梯度消失和梯度爆炸的问题,设计了一种双通道预提取的编码模式。使用基于BERT改进的自编码方法结合空洞卷积组成双通道预提取器,并行处理输入数据,减少误差累积影响同时增强文本信息提取能力,最终达到优化PGN模型性能的目的。实验结果表明:基于PGN改进的模型在Rouge 1、Rouge 2、Rouge L值上均优于原始的PGN模型,同时与直接加入预训练BERT的PGN模型相比,训练时间缩短了约24%。(3)针对原始PGN模型解码能力不足的问题,在指针生成网络的解码阶段将LSTM模型替换成ON-LSTM模型用于提取句中层次信息。并在解码阶段融合多头注意力机制,进一步加强对于文本信息解码能力。最后在损失函数中使用Flooding技术,使模型可以跳出局部最优点,从而寻找到更好的模型参数。实验结果表明:经过改进的PGN生成的文本摘要错词漏词明显减少,Rouge 1值可达34.6。综上所述,本文对生成式文本摘要技术进行了一系列的探索,为指针生成网络容易出现错词和漏词的问题提供了一条有效的技术途径,对于生成式文本摘要的实用化方面具有一定的潜在价值。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000362
{DOI}: 10.27035/d.cnki.ggxmc.2023.000362
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于混合神经网络的文本情感分析研究
{Author}: 徐志展
{Tertiary Author}: 廖义奎
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;情感分析;BERT;XLNet;融合情感词
{Abstract}: 随着社交媒体的普及,人们在日常生活中越来越多地使用网络表达自己的情感和观点,这些情感信息可以帮助企业、政府或组织更好地了解和响应公众的情感需求和反馈,以及对舆情进行监测和管理。为了缓解文本情感分析任务中部分情感词关注度不高且难以捕捉句子间长距离依赖问题,本文主要从以下方面开展工作和研究:1.数据集的收集和整理。基于开源的情感分析数据集作为基础,开发并实现了一个分布式、高可用的爬虫程序,对淘宝、大众点评和外卖等平台的评论文本进行提取和优化处理,共获得了2.2万的中文情感数据集。同时,还收集整理得到了40258个包含情感极性的中文情感词典。2.提出了一种基于BERT和门控注意力优化的DBGA情感分析模型,以解决传统基于神经网络的情感分析方法难以捕捉句子间长距离依赖和部分情感词关注度不高的问题。该模型首先利用了BERT的双向表示获取更丰富的语义特征,然后结合了门控注意力进一步提取上下文的语义,还提出了一种兼容BERT结构的融合情感词的分词选择算法(BDSS)能更进一步地提升模型性能。实验结果显示,DBGA模型比基线BERT模型的准确率提高了2.07%。3.提出了基于XLNet与混合网络优化的DXMR情感分析模型。为了进一步提高模型的性能,首先利用了优于BERT的XLNet模型作向量化处理,然后利用混合神经网络(DBGA已验证有效性的门控注意力和多通道文本卷积网络)来获取更为丰富的文本特征,更进一步地提高了情感分析的准确性和泛化能力。同时,还提出一种基于XLNet的融合情感词的分词选择算法(X DSS),使网络模型更加关注情感词并提高了模型的性能。通过对比和消融实验的验证,DXMR优化模型的准确率比基线提高了3.67%,比DBGA模型还提升了1.6%,说明了其有效性和优越性。4.设计并实现了一个情感分析原型系统。为了将本文提出的方法得到实际应用,以第四章提出的DBGA优化模型和第五章提出的DXMR优化模型为情感分析技术的核心,加载最优模型并封装成接口,最后,展示了各模型的情感分析效果对比,并证明了提出模型的可行性。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000525
{DOI}: 10.27035/d.cnki.ggxmc.2023.000525
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的方面情感分析算法研究
{Author}: 李锦
{Tertiary Author}: 夏鸿斌;周丹平
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;情感分析;深度学习;注意力机制;图卷积
{Abstract}: 文本情感分析主要研究人们在文本中表达的情感、观点、态度。基于方面的情感分析是其中的一个细分领域,相比于研究文本整体情感的情感分析,基于方面情感分析直接对文本中的实体进行分析,具备更多的实用价值。方面情感分析的研究常常以文本特征表示为基础,再针对方面项和上下文进行深层次的特征抽取。目前主流的方法是基于注意力机制对文本中出现的实体进行建模。但基于深度学习和注意力机制的方面情感分析方法仍然存在问题:其一,目前情感分类模型在使用注意力机制计算表征之间的依赖关系以及抽取特征时,未能充分利用局部特征和全局特征的优势来提取文本特征,同时,融合局部特征和全局特征的过程中,使用拼接或相加等方式容易导致特征损失和特征覆盖的问题。其二,现有方法在方面词注意力的研究中缺乏引导机制,经常导致方面词注意力错误的集中于在与方面词在句法上不相关的词上。同时,方面词注意力针对单个词进行建模,难以有效理解带有否定前缀的观点项所蕴含的整体语义信息。针对目前基于深度学习的方面情感分析算法中存在的问题,本文主要的研究内容如下:(1)针对模型对方面项重视程度不够导致抽取方面词特征不充分的问题,本文提出了基于双特征融合注意力的方面情感分析模型。分别设计了局部与全局的特征抽取模块,充分捕捉方面词和上下文的语义关联。并将一种改进的“准”注意力添加到模型的全局特征抽取器中,使模型学习在注意力的融合中使用减性注意力以削弱本文噪声产生的负面影响。基于条件层规范化设计了局部特征和全局特征的特征融合结构来更好地融合局部和全局特征。在Senti Hood和Sem Eval2014 Task4数据集上进行的实验结果表明,该模型在融入了上下文语境特征后取得了较明显的性能提升。(2)针对现有模型关于方面词注意力的研究缺乏引导机制的问题,本文提出一种基于图卷积和注意力机制的胶囊网络模型,将胶囊网络和图卷积相结合,通过句法依存树和否定前缀等外部语法知识聚焦注意力机制实现了胶囊网路的动态路由过程,并将预训练好的BERT词向量运用其中,能够显著增强文本和方面词的特征表示。在ACL-14 Twitter社交评论数据集以及4个来源于Sem Eval竞赛的基准数据集上的实验表明,本文提出的方法性能较优。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.000472
{DOI}: 10.27169/d.cnki.gwqgu.2023.000472
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的情感分析模型研究
{Author}: 王郅翔
{Tertiary Author}: 刘渊;周丹平
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 情感分析;注意力机制;图卷积网络;Prompt;BERT
{Abstract}: 随着社会的快速发展,我国经济迎来了高质量发展阶段,企业越发注重用户对自身产品效果的体验反馈,文本能最直观的反映用户喜好,因此把文本内容研究好,对于一个企业的可持续发展具有重大意义。本文致力于研究自然语言处理领域中的情感分析方向,采用深度学习技术,分别对传统文本分类模型、方面级情感分析和小样本数据分析模型进行改进,解决现有模型的限制,并提高在实际应用中的效果。总的来说,本文的主要工作如下:(1)针对传统文本分类模型存在识别能力受限、训练时间随着输入长度倍增的问题,提出了一种基于文本摘要提取的粗粒度情感分析模型BLAT(Bi-LSTM with Additive Attention and Text CNN)。BLAT模型引入Fastformer的加性注意力机制代替Transformer的自注意力机制,使得模型能够在不损失精度的情况下,面对长文本训练能够有较为出色的训练速度。其次,模型通过对原始文本数据做摘要提取处理形成双路特征,融入长短期记忆网络与卷积神经网络组成多尺度特征提取网络,通过实验在中文电商评论数据集上进行验证,准确率可以达到92.26%,相较当下主流模型能够达到较好的效果。(2)针对方面级情感分析模型容易出现位置信息缺失,特征提取尺度单一的问题,提出了一种面向方面级的基于句法依存树和图卷积网络的情感模型SEPGCN(Syntactic-Embedding Position and GCN)。模型通过句法依存树的绝对距离和方面级词组与属性之间的相对距离构建位置特征,采用注意力机制增强语义关联,并将位置特征与之融合,最终转化到图卷积网络中寻找关联节点并做分类输出,通过在Sem Eval-2014中的Res-14和Laptop-14数据集上进行实验,最终结果相较于对比模型具有一定的优越性。(3)针对当前深度学习网络模型在小样本数据集上表现不佳,容易出现过拟合等问题,提出了一个基于模板提示学习的小样本情感分类模型PBFT(Prompt-BERT-Fine-Tune)。本章节使用Prompt方法对原始文本进行处理,并生成类似于完形填空的模板,通过预测其内容最终建立上下文语义的强关联。模型使用BERT词向量作为模型的特征提取方法,同时在模型的情感映射层中建立情感词表进而提升模型识别效率。选取方面级中的小样本数据集进行验证,其结果表明,Prompt模板学习的方法能够增强上下文语义关联,对分类任务具有借鉴意义。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.001756
{DOI}: 10.27169/d.cnki.gwqgu.2023.001756
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的医药领域语义分析研究
{Author}: 周胜
{Tertiary Author}: 汤卫东
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 在线医疗;语义网络;知识图谱;Neo4j图数据库;Bert
{Abstract}: 随着互联网时代的到来,医疗服务进入了互联网+医疗的新时代,这种服务利用信息技术,包括移动通信技术、云计算、物联网和大数据等,与传统医疗服务进行深度融合。但是,互联网带来的大量复杂数据也增加了人们信息检索和学习的难度。在医疗领域,医疗知识图谱是实现医疗人工智能的基础,构建完善的医疗知识图谱可以为人们提供更高效、更精准的医疗服务。本文医药领域语义分析的研究内容主要包括以下几个方面:(1)研究如何基于知识图谱技术构建高质量且有效的医药领域问答系统的知识库,主要步骤分为知识获取、数据预处理、实体识别、关系抽取和知识存储。(2)研究如何基于语义网络进行语义分析,本文通过GBDT+LR多模型融合算法和Bert+TextCNN多意图分类算法进行二次意图识别。此外,本文还采用基于BiLSTM-CRF的命名实体识别模型,以实现对文本中实体的准确抽取,并结合AC自动机进行进一步的修正。这一模型结合了 BiLSTM和CRF的优势,能够有效地识别出医药领域文本中的命名实体。(3)基于Uniapp构建前端界面,基于Sanic搭建后端服务,以在线问答的方式为就医者提供准确的答案。本文的研究目的是通过结合知识图谱技术和自然语言处理技术,实现对医药领域文本信息的有效语义分析。研究结果表明,该方法能够有效提取医药领域文本中的有价值的信息,为医药领域的知识管理和决策支持提供有力工具。本文通过上述方法,成功构建了以Neo4j图数据库呈现的中文医疗知识图谱。同时,通过深度学习方法提高了基于医疗知识图谱的智能问答系统对用户自然语言问题和意图的理解能力。最终,实现了一个满足用户需求的在线医疗平台。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.001341
{DOI}: 10.27035/d.cnki.ggxmc.2023.001341
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理的口腔医学问诊培训系统的研究
{Author}: 唐彪
{Tertiary Author}: 周卫
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;RoBERTa;问诊培训系统;口腔医学
{Abstract}: 随着人们生活水平的不断提高,越来越多的人开始重视口腔健康问题。此外,口腔医疗行业正面临医师不足的问题。一方面,培养一名合格的口腔医师过程漫长、复杂且成本高;另一方面,现存的口腔医师问诊培训系统交互性弱,难以有效地训练医师的问诊能力。为了解决上述问题,本文基于自然语言处理技术实现了口腔医学问诊培训系统,该系统能有效训练医师问诊能力。在模型上,本文采用RoBERTa-BiLSTM模型提取相关特征,并判断两个文本之间是否相似;在系统上,本文以常见的临床病例为数据基础,利用训练好的匹配模型实现问诊功能,主要研究工作如下:(1)收集60种常见口腔临床病例,将其构建成口腔医学病例库并存储在数据库中。从病例库中提取医师提问的问句,并制作成口腔医学问句数据集,用于训练文本匹配模型。针对问句数据集训练语料不足问题,本文采取数据增强的方式扩充数据,为预训练模型提供充足的训练语料。(2)本文提出了基于RoBERTa-BiLSTM预训练模型实现文本匹配任务,分别在开放领域数据集LCQMC、医疗领域数据集cMedQQ以及自制口腔医学问句数据集中进行对比实验。其中,在自制口腔医学问句数据集中,训练集、验证集、测试集的比例为8:1:1,正负样本比例接近1:1,模型准确率较ABCNN、BIMPM、BERT、AlBERT以及RoBERTa分别提高了10.82%、5.41%、1.46%、2.63%以及0.73%,最终达92.25%。(3)为了设计并实现口腔医学问诊培训系统,本文主要从系统总体设计、数据库设计以及功能模块实现等方面,详细介绍了该系统的设计与实现过程,并对系统进行了功能性和非功能性测试,之后将系统采用容器化方式部署上线,最后让用户完成调查问卷,为完善系统提供宝贵意见。系统的核心功能是问诊培训功能,该功能是通过训练好的文本匹配模型,从病例库中找到和用户输入相似的问句,并将问句对应的病人回答返回到用户界面,从而实现模拟问诊,提高医师的问诊能力。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000306
{DOI}: 10.27035/d.cnki.ggxmc.2023.000306
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合交互注意力网络的旅游知识图谱构建与应用研究
{Author}: 郝小芳
{Tertiary Author}: 张超群
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 实体和关系联合提取;交互注意力网络;注意力机制;知识图谱;问答系统;旅游
{Abstract}: 随着旅游需求的增加和旅游产业的发展,相关网站数量剧增,旅游数据不断增长,用户面临信息过载问题。传统搜索引擎仅根据关键字检索并返回与之相关页面,最终结果仍需人工筛选。但是,基于知识图谱的问答系统能语义解析,准确识别用户意图,并返回精准简洁答案,有效提高了检索效率。为此,本论文旨在从用户需求出发,实现融合交互注意力网络的旅游知识图谱构建与应用研究,主要工作如下:(1)针对目前网络上无公开旅游数据集的问题,构建一个旅游数据集TDDS。首先,用Python爬取多个网站的景点数据,共计20000条;经过数据清洗后采用基于地址属性相似度匹配算法和景点名称相似度计算来实现数据融合;最后采用基于远程监督的方法标注数据,得到旅游数据集TDDS,共计9062条数据,用于知识图谱的构建。(2)针对目前实体和关系抽取存在实体冗余和三元组重叠问题,提出一个融合交互注意力网络的实体和关系联合抽取模型RSIAN。该模型通过交互注意力网络来学习句子级别和关系级别的高阶语义关联,增强句子和关系之间的交互,辅助模型进行抽取决策。在TDDS、NYT、Webnlg三个中英文数据集上进行对比实验、消融实验和重叠三元组分析实验,最后实验结果表明RSIAN在准确率、召回率和F1值上的整体性能均优于所有对比模型,且性能更稳定,具有较好的泛化能力,能有效解决旅游实体冗余和关系重叠问题。(3)针对旅游数据集的复杂性,基于新建的旅游景点本体和RSIAN模型相结合得到更高质量的三元组,再用Neo4j进行持久化存储,并基于所构建的旅游知识图谱实现问答系统。该系统先对输入的问题进行预处理,再用BiLSTM-CRF模型进行命名实体识别,为了提高答案的匹配度,采用基于问题模板特征词匹配和相似度计算相结合的方法进行分类,提高分类的准确性,再根据匹配类别生成Cypher查询语句,并依据模板进行回答,最终答案通过文本和图谱进行展示,能较好地提高用户满意度。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000347
{DOI}: 10.27035/d.cnki.ggxmc.2023.000347
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本挖掘的协作学习会话分析与应用研究
{Author}: 田玉
{Tertiary Author}: 王萌
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本挖掘;协作学习;会话分析;框架设计
{Abstract}: 近年来,协作学习已被广泛应用于教育教学,以激励学生创造共享性知识。交互对话是协作学习的基础,可以说协作学习的过程即会话的过程,协作学习过程中生成的会话文本承载了协作学习的主要内容,对会话文本进行分析可以明晰协作学习的规律和实质,是掌握协作学习过程变化的关键所在。然而,通过对相关研究的文献综述进行梳理发现,当前协作学习会话分析研究尚未形成健全体系,仍存在会话分析理论不完善、会话分析框架欠缺和缺少自动化分析工具的现状。在此背景下,本研究对协作学习会话分析展开探究,以“框架设计——模型构建——应用分析”为研究主线,尝试结合文本挖掘分析协作学习会话,构建一个多维的会话分析框架,以深入探究如何利用文本挖掘技术自动化分析协作学习会话并衡量协作学习效果。通过将会话分析从理论探索层面落地到实践应用层面,以提升协作学习过程性分析效率,为协作学习提供过程性评价依据,从而推动协作学习实践应用的革新。在框架设计阶段,以协作学习小组为研究单位,从协作学习会话的文本组织结构出发,明确以词汇和句子为协作学习会话的分析层级,并确定两个层级的具体分析要素。词汇层级包括词频统计、相关度计算、主题抽取、纵深度分布,通过Wordcloud、Bert、LDA、Matplotlib等技术实现,以分析会话关键词、知识相关度、会话主题以及概念层级分布;句子层级包括句子总数、平均句长和会话文本分类,通过Python统计和机器学习实现,以分析会话的有效输出、会话丰富度以及交互程度。本阶段主要明确了各分析要素的技术实现路径以及与协作学习效果的对应关系,为协作学习效果评价提供明确的客观依据。在模型构建阶段,利用机器学习算法对会话文本进行分类,建模步骤包括确定分类标准、文本收集及标注、文本预处理、文本向量化、模型构建与选择。首先确定了认知交互、情感交互和社会交互三个分析维度的具体分类依据;经过文本采集、标注和预处理后,利用Word2Vec实现了会话文本的向量化;最后借助Decision Tree、Random Forest、Naive Bayes、SVM算法进行了模型构建,依据评价标准进行选择获得了文本分类性能表现最佳的分类模型,包括基于Random Forest的认知交互会话文本分类模型、基于SVM的情感交互会话文本分类模型、基于Random Forest的社会交互会话文本分类模型,三个分类模型为会话文本的自动分类奠定了技术基础。在应用分析阶段,首先通过将本研究提出的会话分析框架应用于实际协作学习会话过程,依据得出的会话分析数据对比了组内和组间的协作学习效果变化和差异,说明基于文本挖掘的协作学习会话分析框架在实际协作学习会话分析应用中具有一定的价值和实用性,能够为衡量协作学习效果提供分析依据。然后基于数据分析结果得出了协作学习会话过程性反馈与评价启示。最后基于该框架提出了协作学习智能会话分析工具的功能设计和架构设计,旨在为后续协作学习会话分析提供客观、有力的支持。综上所述,基于文本挖掘的协作学习会话分析与应用研究设计了自动化的多维度会话分析框架,连接了文本挖掘数据与协作学习效果间的关系,希望该框架为后续协作学习会话分析提供一种新思路和分析方式,为协作学习智能会话分析工具的开发提供框架支撑,进一步丰富协作学习会话智能化分析的路径。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.001329
{DOI}: 10.27169/d.cnki.gwqgu.2023.001329
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 南水北调中线工程风险防控智能问答及应急方案智能生成
{Author}: 卢汉康
{Tertiary Author}: 刘雪梅
{Publisher}: 华北水利水电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;应急方案;智能问答;南水北调
{Abstract}: 由于工程线路长,沿途环境复杂多变,工程运行过程中存在诸多风险,传统应急方案存在数字化程度低、内容关联性差、智能辅助决策不足等问题。为便捷地管理沿线各类工程,预防工程运行过程中风险事件发生,确保险情突发后应急抢险和救助工作能够快速有效地开展,本文提出知识驱动的南水北调中线工程风险防控智能问答及应急方案智能生成方法,设计并实现风险防控系统,提升沿线工程管理和应急抢险的智慧化水平。本文主要工作如下:(1)风险防控知识图谱构建。基于风险防控手册、险情抢险方案等资料,提出应急方案知识图谱本体模型,通过知识抽取、知识融合、知识存储构建风险防控知识图谱,实现风险防控领域文本中非结构信息的结构化表达。(2)应急方案智能生成方法设计。基于水利工程巡检文本,构建实体识别模型,自动抽取巡检文本中的工程、风险事件等实体;设计应急方案智能生成模板,提出多特征融合的实体对齐技术、利用知识检索与推理技术,实现应急方案的生成与推送。通过模型准确性分析与“渠道渗漏”等实例验证,本文提出的实体识别模型F1值高达96.21%,设计的实体对齐算法准确率达90.33%,生成应急方案可靠,能够有效辅助专业人员进行应急处置决策。(3)风险防控智能问答方法设计。基于用户输入的自然语言问句,利用实体抽取模型抽取实体列表,提出基于迁移学习的意图识别模型抽取问句意图,设计答案生成模板,采用知识图谱检索推理技术生成问句答案。通过模型性能分析,本文提出的意图识别模型F1值高达88.67%,通过实例验证,该方法生成答案可靠,能够有效辅助工作人员管理沿线各类工程。(4)风险防控系统实现。基于Django和ECharts开发框架和图谱可视化工具,利用计算机技术,集成上述3项研究内容,设计并实现南水北调中线工程风险防控系统。系统测试与验证结果表明,本文研究构建的风险防控系统具有稳定性与可靠性,能够提供险情知识问答服务以及应急方案辅助决策服务。
{URL}: https://link.cnki.net/doi/10.27144/d.cnki.ghbsc.2023.000465
{DOI}: 10.27144/d.cnki.ghbsc.2023.000465
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的中文智能问答方法研究
{Author}: 方雨桐
{Tertiary Author}: 邓健志
{Publisher}: 桂林理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱问答;深度学习;知识蒸馏;智能问答;图神经网络
{Abstract}: 知识图谱以结构化三元组的方式组织现实世界中的事实,具备高度灵活的语义建模和表达能力,并被广泛应用于各种开放领域和特定领域。基于知识图谱的智能问答方法(Knowledge Based Question Answering,KBQA),能够自动解析用户提出的自然语言问题,理解用户意图,并在知识图谱中定位三元组信息(即知识),返回答案给用户。这种方法能够弥补传统搜索引擎的不足,极大地提高了效率,提供了直接的人机交互方式。因此,本文主要围绕KBQA的关键技术和实际应用进行改进与创新,具体的研究工作如下:(1)针对中文字形复杂、语义信息复杂的问题,提出基于中文预训练语言模型Chinese BERT的知识图谱单跳问答方法(Chinese BERT-KBQA)。该方法采用中文预训练语言模型Chinese BERT,将其作为文本的语义嵌入层,其融合了字形和拼音信息,提升了传统语义解析方法在实体提及识别与关系预测子任务上的性能。具体而言,分别提出基于Chinese BERT-CRF的实体提及识别模型和基于Chinese BERT-Text CNNSoftmax的关系预测模型,以综合提高对中文文本的语义理解能力。最后结合子任务间的相关信息,进行最终的答案预测。在教育问答数据集MOOC Q&A和开放域问答数据集NLPCC2018上的实验结果表明了该方法的有效性。(2)针对Chinese BERT-KBQA方法只处理简单问题,无法对复杂问题进行多跳推理的缺陷,提出一种基于双线性图神经网络和双教师蒸馏的多跳问答方法(BGNNTT),并在此基础上开发了教育知识Web应用。传统的多阶段语义解析方法在面对需要多次推理的复杂问题时,多步间的误差累积会导致问答方法的准确度降低。图神经网络的引入可以捕获图谱结构的邻域信息并生成实体的向量表示,把答案预测问题转化为向量间的语义相似度计算问题。基于这一思想,本文结合双线性图神经网络进行推理,引入一种双线性聚合器,通过结合线性聚合和双线性聚合,可以捕获知识图谱中图节点之间的上下文信息,并获得更全面的实体表示,有效提高多跳问答推理能力。此外,为了缓解虚假路径推理现象,添加了双教师学习,即结合双向推理构建两个教师网络,融合两个教师网络的中间监督信号来指导问答推理的中间过程。与现有的多跳问答方法相比,在MOOC Q&A和NLPCC-MH多跳问答数据集上取得了更好的效果。通过实验结果表明,本文提出的知识图谱单跳和多跳问答方法在一定程度上实现了良好的问答性能,并优于其他问答方法,提升了机器对中文文本的语义理解能力。
{URL}: https://link.cnki.net/doi/10.27050/d.cnki.gglgc.2023.000433
{DOI}: 10.27050/d.cnki.gglgc.2023.000433
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于5E教学模式的教学活动设计研究
{Author}: 季婕
{Tertiary Author}: 袁庆飞;胡新颖
{Publisher}: 西北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 信息技术课程;5E教学模式;计算思维
{Abstract}: 随着《普通高中信息技术课程标准(2017年版2020年修订)》的颁布,我国越发重视创新人才的培养。高中信息技术课程开始从提高学生的“信息技术意识(Literacy)”变成面向培养学生的“学科核心素养(Competence)”的教育。尤其是数字化时代的来临,计算思维的发展更是顺应了国家对于培养创新型人才的需要,是解决问题和创新作品中的重要思维方式,因此,要重点培养学习者的计算思维。根据《普通高中信息技术课程标准(2017年版2020年修订)》的要求,教科书也逐渐把其他编程类语言换成了Python语言,从重视语法过渡到重视问题求解,来实现对高中生计算思维的培养。通过文献的搜索,发现目前高中编程教学仍存在一些问题:第一,教学目标尚未全面实现,教师对学生思维与创新能力的培养不够重视;第二,教学模式匮乏,限制了学生创造性的发挥;第三,教学评价缺乏多维度,学生无法得到及时的反馈。“5E”则是以“探究”为主线,以“问题”为导向的教学模式,注重过程性与表现性评价,符合新时代培育要求。由上,本研究尝试将5E教学模式融入到高中信息技术的编程课中。本论文的具体研究内容和结论有以下几点:(1)设计了基于5E教学模式的教学活动流程。本研究通过文献研究法梳理了国内外5E教学模式与编程教学的研究现状,以活动理论、心流体验理论与反馈干预理论作为本研究的理论支撑。结合5E教学模式与“编程计算”单元的契合性、5E教学模式的启示、设计原则与要素的基础上,以教科版高中信息技术必修一中的“编程计算”单元为例,设计出基于5E教学模式的教学活动流程。(2)开展了基于5E教学模式的教学活动实施。本研究通过准实验研究的方法,依托J省M中学的高一两个班级共81人展开教学实施。教学前,教师要明确实验的目的、假设、变量、方案等。其次要做好实验前测的准备工作,确保教学过程顺利实施。利用设计的教学活动流程进行具体案例的创设,其中包括课标分析、教材分析、学情分析、教学目标、教学过程与教学反思等。利用“编程计算”单元中四个具体的教学案例体现整个教学的实施过程。(3)验证了基于5E教学模式的教学活动实施效果。在教学实施结束后,通过对学生作品评价、学生访谈、计算思维的前后测等进行数据分析,发现基于5E教学模式的教学活动流程可以提高学生对于编程知识掌握情况,有效促进学生的计算思维能力。
{URL}: https://link.cnki.net/doi/10.27410/d.cnki.gxbfu.2023.001433
{DOI}: 10.27410/d.cnki.gxbfu.2023.001433
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 高糖饲料中添加丙酸钠对鲤生长、代谢和肠道健康的影响
{Author}: 郑海玲
{Tertiary Author}: 程镇燕
{Publisher}: 天津农学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 鲤;丙酸钠;生长性能;理化指标;代谢;肠道健康
{Abstract}: 本文主要研究丙酸钠对高糖饲料鲤(Cyprinus carpio)生长、生理生化、糖代谢和肠道健康等方面的影响,为鲤制订合理的饲料配方提供参考。正式开始试验选取378尾规格一致、体格健壮的鲤(初体质量为26.48±0.94g)随机放到循环水养殖系统中,每个缸21尾鱼,分成6组,每组设3个重复,试验设对照组(D0)、高糖组(12%玉米淀粉,D1)、高糖+0.25%丙酸钠组(D2)、高糖+0.5%丙酸钠组(D3)、高糖+1%丙酸钠组(D4)、高糖+2%丙酸钠组(D5),每天投喂2次(9:00,18:00)养殖周期56 d。主要研究内容和结果如下:1.高糖饲料中添加丙酸钠对鲤生长性能、体成分和生理生化指标的影响与对照组及高糖组相比,添加0.5%丙酸钠后,鱼体末体质量、增重率及特定生长率均有明显提高(P<0.05)。高糖组及添加丙酸钠各组鱼体粗灰分都显著低于对照组(P<0.05);高糖组鱼体粗脂肪含量显著高于对照组(P<0.05),添加丙酸钠后鱼体的粗脂肪含量显著降低(P<0.05)。高糖组鲤血清ACP、AKP活性低于对照组(P>0.05),添加丙酸钠后,鱼体血清的非特异性免疫指标发生了不同程度的变化,0.5%丙酸钠组血清ACP、AKP活性最高;添加0.5%丙酸钠组HDL-C显著高于其他各组(P<0.05);高糖组LDL-C含量相比对照组有所上升,但添加丙酸钠后,随着添加量的增加而下降(P>0.05)。在血清中,高糖组的CAT活性比对照组有较大的提高(P<0.05),在加入丙酸钠后,各组间没有明显的差别(P>0.05);高糖组的SOD、GSH活性与对照组相比有所降低(P>0.05),添加丙酸钠后,鱼体血清理化指标发生了不同程度的变化,0.5%丙酸钠组SOD活性最高。肝胰脏中,添加0.5%丙酸钠组CAT活性略高于对照组(P>0.05);高糖组的SOD活性较对照组有所降低(P<0.05),在添加丙酸钠后,SOD活性得到了改善。日粮中的丙酸钠对GOT,GPT活性及肝胰脏GPT活性有明显的影响(P<0.05)。血清中加入丙酸钠后,GOT、GPT活性有所降低。肝胰脏中的GPT活性在高糖组明显低于对照组(P<0.05),加入丙酸钠之后,GPT的活力呈现上升的趋势,在加入0.5%的丙酸钠时,其活性达到峰值。综上,高糖饲料中添加丙酸钠可以改善鲤的生长性能和生理生化指标且在添加量为0.5%时,生长性能达到最佳。2.高糖饲料中添加丙酸钠对鲤糖代谢和肠道健康的影响与对照组相比,高糖组GPR43的表达量明显降低(P<0.05),但是,在丙酸钠升高时,GPR43基因的表达量出现了一个先上升后降低的趋势;加入丙酸钠后,AMPK的基因在不同组间的表达量无显著差异,除了加入0.5%的丙酸钠组之外(P>0.05);与对照组相比,高糖组糖异生通路中的PEPCK,G-6-Pase,GS酶活性明显升高(P<0.05),添加丙酸钠后,PEPCK、G-6-Pase活性有所降低;与其它组相比,高糖状态下的PK,PFK酶活性较高(P<0.05),在加入丙酸钠之后,PK活性呈现出了先下降后上升的趋势,添加0.5%丙酸钠组显著低于其余三个丙酸钠处理组(P<0.05);PFK活性升高,但各组间无显著性差异(P>0.05)。Nrf2,NF-κB在高糖组与对照组间表达无显著差异(P>0.05),加入丙酸钠后,与对照组及高糖组相比,添加0.5%丙酸钠组Nrf2的含量较高且达到峰值(P<0.05);加入丙酸钠对NF-κB的无显著性差异(P>0.05),在0.5%的丙酸钠组中,其表达量最低;与对照组相比,高糖组TNF-α的表达量明显升高(P<0.05),在加入丙酸钠之后,添加0.5%丙酸钠组比对照和高糖组有明显的降低,其它各组间没有明显的差异(P>0.05)。丙酸钠增加了肠道前、中肠绒毛高度和绒毛宽度,加入0.5%丙酸钠组的中肠肌层厚度较其他各组明显增加,后肠肌层厚度均高于高糖组。综上,高糖饲料中添加丙酸钠对肝胰脏糖代谢和维持肠道健康都有积极影响。
{URL}: https://link.cnki.net/doi/10.27717/d.cnki.gtjnx.2023.000031
{DOI}: 10.27717/d.cnki.gtjnx.2023.000031
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 白头翁皂苷B4对沙门氏菌诱导的肠道炎症的影响及机制初探
{Author}: 覃兰迁
{Tertiary Author}: 何家康
{Publisher}: 广西大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: AB4;沙门氏菌;巨噬细胞;NF-κB信号通路;肠道菌群
{Abstract}: 沙门氏菌(Salmonella)是生活中常见的一种致病性肠杆菌,是养殖业中常见的病原体之一。沙门氏菌主要经消化道感染,可引起人和动物局部或全身性感染,感染后出现一系列严重的炎症反应,严重危害养殖业健康发展和公共卫生安全。越来越多的研究表明,抗生素在经济动物中的不合理使用,使沙门氏菌对抗生素的耐药性日益增加,抗生素治疗作用下降。中草药具有抑菌、抗炎、不易产生耐药性和低残留等优点,成为人们关注的焦点。白头翁皂苷B4(Anemoside B4,AB4)是从中药白头翁中提取出来的天然药物,具有抗炎、免疫调节和抗肿瘤等多种生物活性。本研究通过体外和体内实验探究AB4对沙门氏菌性肠炎的保护作用及其机制。首先,本研究建立沙门氏菌感染RAW264.7巨噬细胞模型,利用RT-q PCR检测沙门氏菌感染巨噬细胞TNF-α、IL-6、IL-1β和NF-κB m RNA相对表达量,确定最佳感染时间和感染复数。然后,进一步探究AB4对沙门氏菌感染RAW264.7巨噬细胞的保护作用:测定AB4对沙门氏菌的最小抑菌浓度(MIC);采用CCK-8法检测2-64μg/m L AB4对RAW264.7细胞活力的影响;通过RT-q PCR检测不同剂量的AB4作用不同时间后对沙门氏菌感染RAW264.7细胞TNF-α、IL-6、IL-1β和NF-κB m RNA相对表达量的影响,确定药物最佳孵育浓度和时间;利用NF-κB抑制剂JSH-23,Western Blot检测NF-κB信号通路相关蛋白的表达水平,确定AB4对沙门氏菌诱导的炎症作用机制。最后,建立沙门氏菌感染小鼠模型,探究AB4对沙门氏菌感染小鼠的预防作用及其机制:将50只雄性BALB/c小鼠随机分5组,即空白组、沙门氏菌模型组、AB4(5、10、20 mg/kg)预处理组。AB4预处理组连续7天口服AB4(5、10、20 mg/kg),空白组和模型组口服等剂量生理盐水,每天记录体重变化。试验第8天除空白组外,其余组别腹腔注射0.2 m L 10～7 CFU/m L沙门氏菌。12 h后,称重、取血,检测血清GOT、GPT、TNF-α、IL-1β、IL-6含量;取肝脏、脾脏和肾脏,计算脏器指数和脏器菌载量;取十二指肠制作病理切片;RT-q PCR法检测肠组织中TNF-α、IL-6、IL-1β和NF-κB m RNA相对表达量;考察AB4对沙门氏菌感染小鼠生存率的影响;16S r DNA测序检测空白组、模型组和20mg/kg AB4组肠道菌群的变化。通过以上研究,本研究发现:(1)AB4抑制沙门氏菌感染巨噬细胞的炎症反应。本研究成功建立了沙门氏菌感染RAW264.7细胞模型,条件为:MOI=100,孵育2 h;2～64μg/m L AB4对RAW264.7细胞没有毒性;20μg/m L AB4孵育4 h极显著抑制TNF-α、IL-6、IL-1β和NF-κB m RNA的表达;NF-κB抑制剂显著抑制TNF-α、IL-6、IL-1β和NF-κB m RNA和p65、IκBα蛋白的磷酸化,AB4与其有相似作用。(2)AB4对沙门氏菌感染小鼠有保护作用。与模型组相比,AB4缓解沙门氏菌引起的体重下降,脏器指数降低,肾脏和脾脏载菌量降低;小鼠血清中GOT、GPT、TNF-α、IL-1β、IL-6含量降低;病理切片结果显示AB4缓解沙门氏菌导致的肠道损伤,肠组织中TNF-α、IL-6、IL-1β和NF-κB m RNA相对表达量降低。此外,20 mg/m L AB4通过改善小鼠肠道菌群群落结构和多样性,维持肠道菌群平衡。结论:AB4可抑制沙门氏菌感染巨噬细胞的炎症反应,能显著延长沙门氏菌感染小鼠的生存期、降低组织中的细菌载量、改善肠道黏膜损伤,提高肠道菌群多样性,有效防治沙门氏菌感染。
{URL}: https://link.cnki.net/doi/10.27034/d.cnki.ggxiu.2023.002273
{DOI}: 10.27034/d.cnki.ggxiu.2023.002273
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图卷积神经网络和ERNIE-gram的乡村旅游评价文本分类研究
{Author}: 杨森淇
{Tertiary Author}: 段旭良
{Publisher}: 四川农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图卷积神经网络;BERT;深度学习;自然语言处理;文本分类
{Abstract}: 随着社会经济的发展和人民生活水平的提高,人们对旅游的需求也达到了空前的阶段,在每次出行前,游客往往将网络上对景点的评价作为一项重要参考,悄然的将大众点评与景点联系在了一起。大多数网民在对景点进行评价时认为表情符号能够弥补文字表达的不足,能够更好地表达情绪,因此表情符号已然成为移动互联网时代全民接受的线上交流方式,也逐渐成为不可或缺的沟通要素。本文构建了融合表情符号的中文景点评价文本数据集,数据集的数量为44671条。数据集处理的主要流程为:首先对数据进行收集,随后进行清洗,去除停用词和无意义的表情,并且人为增加了一些融合表情的数据,最后进行公开发布。融合表情的中文情感分类数据集解决了中文景点评价文本没有公开数据集这一问题。本文提出E2G模型对数据集进行高精度分类。E2G模型首先对文本进行预处理,随后分别送入ERNIE-gram和Text GCN,ERTNI-gram利用其独有的mask机制进行训练,得到最终的概率。Text GCN利用数据集构建异构图,将文档和词作为节点,最终得到节点的表示,输出概率,将两个概率进行计算,得到最终结果。为了证明E2G模型的有效性,本文与几组先进模型和经典模型进行了对比,经过试验表明,E2G对中文景点评价有很好的分类效果,分类的准确率高达97.37%,和ERNIE-gram,Text GCN相比,E2G准确率分别领先了1.37%和1.35%。同时为了验证GCN与GAT在数据集上的表现,进行了两组对比实验,最终结果表明,ERNIE和ERNIE-gram分别结合GCN和GAT,GCN的表现要领先1.6%和2.15%。最后,为了测试八种激活函数在GCN第二层上的效果,进行了实验对比,得到了效果最好的激活函数RELU6。
{URL}: https://link.cnki.net/doi/10.27345/d.cnki.gsnyu.2023.000691
{DOI}: 10.27345/d.cnki.gsnyu.2023.000691
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器学习的猪育种表型预测及基因芯片位点筛选研究
{Author}: 栗涛
{Tertiary Author}: 王佳
{Publisher}: 华中农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器学习;基因组预测;特征选择;深度学习;猪育种
{Abstract}: 生猪育种是农业领域的一个重要分支,它的发展对于提高猪肉的生产效率、改善品质和保障供应有着至关重要的作用。基于求解线性混合模型方程的基因组预测是目前预测家畜经济性状的育种值或表型表现的最常用方法。随着进一步提高基因组预测性能的需要,非线性方法被认为是一种能够替代线性方法的潜力巨大的方法。快速发展的机器学习方法已经在畜牧业育种中显露出出色的表型预测能力。本文围绕基因组预测的线性和非线性方法展开了如下几个方面的工作:(1)使用来自全球领先的种猪繁育公司PIC公开数据集和华北赤峰国家猪核心群数据集,共计8个生猪养殖中重要的生产性状来比较线性模型与非线性模型的预测精度。为了研究使用非线性模型实施基因组预测的可行性和可靠性,我们基于猪基因芯片数据构建了不同的非线性机器学习模型用于生猪表型的预测,包括随机森林、支持向量机、极端梯度提升树和深度学习卷积神经网络。结果显示,对于PIC数据集中的性状T1、T2、T3和T5以及赤峰数据集中的平均日增重,使用支持向量机模型预测的准确性高于线性混合方法。而对于PIC数据集中的性状T4、赤峰数据集中出生仔猪总数和腰肌深度,支持向量机模型的准确性略低于线性混合方法。非线性机器学习模型在60%的数据集上表现出的预测精度都超过了线性混合方法,这表明支持向量机模型在生猪育种中使用是非常有帮助的。(2)使用四种特征选择方法:递归特征消除、极端梯度提升机、随机森林和全基因组关联研究对高维的猪基因组标记位点进行筛选降维以降低猪基因芯片成本。基于预测效果最佳的支持向量机模型,选用几种特征选择方法所选择的少量特征用于预测,探索被选择的特征对预测效果以及计算性能的影响。结果表明,极端梯度提升机模型可以将基因组标记的数量减少到二十分之一,并且其选择的少量特征的预测精度在四个模型中是最优的。在常见的特征选择方法中,极端梯度提升机方法更适合对基因数据进行特征筛选。(3)整合了极端梯度提升机与支持向量机模型,并且将其开发为一种新工具SNPkey。能够实现基因组位点筛选和表型预测功能,使得基因组预测表型工作可以更加省时、便捷。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2023.001651
{DOI}: 10.27158/d.cnki.ghznu.2023.001651
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 小学生计算思维学习进阶的构建研究
{Author}: 张茜
{Tertiary Author}: 刘向永
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算思维;学习进阶;小学生
{Abstract}: 人工智能时代背景下,计算思维已成为学生必备的基本技能,我国义教新课标也将计算思维列为信息科技学科核心素养之一。当前关于计算思维的研究多为计算思维的培养或评价,对计算思维的发展过程或内部结构关注度不高。而学习进阶作为国际教育领域的重要课题,致力于描述一段时间内学生的思维是如何发展的,基于此设计的课程可以使学生的核心素养随着年级的增长而持续加深。因此,本研究尝试构建小学生计算思维学习进阶,刻画出小学生计算思维发展过程,厘清计算思维结构,进而为教学实施、课程设计和学生评价提供参考,促使课程与教学关注学生的计算思维发展过程,基于此设计的课程可以使学生的计算思维能力随着年级的增长而持续加强。基于上述研究背景,本研究主要运用文献分析法、德尔菲法、访谈法和测验法等研究方法,研究过程包括三个阶段:第一,小学生计算思维学习进阶的构建。本研究通过对国内外文献和国内外课标的梳理,根据学习进阶的构成要素,从进阶维度、成就水平和进阶终点三个方面构建了计算思维学习进阶,主要包括五个进阶维度(分解、抽象、算法、概括、评估),每个进阶维度分别包含三个成就水平。第二,小学生计算思维学习进阶的修正。首先,在初步构建的小学生计算思维学习进阶基础上对计算思维研究领域专家与一线教师进行两轮征询,根据反馈结果修正计算思维学习进阶,最终得到专家普遍认可的一致性意见。再对一线信息技术教师和教研员进行访谈,对访谈文本资料进行三级编码,根据结果修正完善计算思维学习进阶。第三,小学生计算思维学习进阶的检验。首先,基于计算思维学习进阶和Rasch模型的基本要求,在较为权威的国际计算思维挑战赛测试题(Bebras)的基础上编制测评工具。接着选取W市90名小学生进行试测,运用Winsteps软件分析测评工具的信度、拟合度和分离度等参数,验证了测评工具的科学性,并对工具进行修正。最后,运用修正后的工具对W市四、五、六年级的240名学生正式施测,基于Rasch模型,运用Winsteps软件对数据进行分析,验证了计算思维学习进阶的科学性,同时掌握学生的计算思维实际发展水平。研究得到以下结论:(1)小学生计算思维学习进阶的进阶维度包括分解维度、抽象维度、算法维度、概括维度和评估维度,每个进阶维度下分别有三个成就水平。(2)小学生计算思维学习进阶的成就水平是合理的。通过对小学生的测评分析,验证了计算思维学习进阶的合理性,学习进阶的成就水平基本符合学生实际发展规律。(3)小学生计算思维水平呈现逐渐完善的趋势。根据测试结果,大部分学生的计算思维能力处于水平二层次,并且随着年级的增长,学生的能力依次递增。最后,根据研究成果,本研究尝试为计算思维教学、课程和评价提出建议:在教学方面,抓住学习进阶起点与关键点,助力学生思维进阶;在课程方面,关注学生思维发展过程,开发连贯课程;在评价方面,采用过程性评价,分析学生计算思维具体水平。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.001482
{DOI}: 10.27169/d.cnki.gwqgu.2023.001482
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 国家利益认知的测量
{Author}: 张俊杰
{Tertiary Author}: 王凯
{Publisher}: 上海外国语大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 战略环境;国际制度;国家偏好;深度学习;自然语言处理
{Abstract}: 国家利益是国际关系中最为基础且难以把握的概念,基于客观资料对国家利益进行系统性的测量显然对于国际关系研究具有不言而喻的价值。本文运用了深度学习模型,从公开的信息来源对具体国家的特定利益进行测量。通过自然语言处理的方法,对来自报纸和政府的信息进行解析,以辨别国家是否确认具体议题为国家利益,并测量和追踪国家随着时间变化在具体利益中类别与程度的变化。国家在制定和执行国际关系政策时,其偏好和策略会相互影响。国家偏好涉及对不同利益的排序,可以看作是国家对利益的认知。本文认为,国家对具体利益的认知实际上是属于一种偏好。本研究采用词袋模型和BP神经网络模型,将国家利益测量分为识别、分类和判断三个维度。结果显示:国家利益识别准确率93%最高;政治利益分类94%高于经济84%和安全74%;重要性判断准确率82%。本研究发现,对越南南海利益有两条解释路径:一是战略环境压力下降和国际制度有利时,利益诉求上升;二是战略环境压力和国内政治压力都很大时,即使国际制度不利,利益诉求也上升。战略环境压力和国内政治压力是影响越南立场的两个最关键因素,而国际制度对越南影响较小。对越南来说,维护国内政权稳定和应对外部威胁是在南海问题上考量的两大重点。国际制度虽也有影响,但作用次之。越南政策取决于如何在这三方面达成平衡,但国内因素处于首要位置。
{URL}: https://link.cnki.net/doi/10.27316/d.cnki.gswyu.2023.000850
{DOI}: 10.27316/d.cnki.gswyu.2023.000850
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT和标签注意力机制的多标签文本分类
{Author}: 陈星宏
{Tertiary Author}: 尹祎
{Publisher}: 武汉科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多标签文本分类;BERT;标签注意力;标签语义
{Abstract}: 近年来,人工智能技术的不断发展,自然语言处理领域也在不断进步。文本分类作为自然语言处理领域的一个分支,被广泛应用。随着人们对文本数据分类要求的精确度越来越高,传统的单标签分类方法其结果的单一性已经不能满足人们的需求,而多标签文本分类方法中的所有标签因不具有排他性的优势逐渐成为研究的热点。在多标签文本分类领域的众多训练模型中,BERT模型的双向Transformer架构可以捕捉文本上下文的语义关系,该模型对不同场景的文本分类任务做出动态性的调整,以此处理多标签文本分类问题。然而,这样的架构也存在着明显的缺点,它忽视了标签的自身语义信息和标签之间的依赖关系,导致产生标签存在遗漏或语义重复的问题。基于此,本文采用BERT结合标签注意力机制的方法对文本进行多标签分类。主要内容包括:(1)面对上下文语义信息理解问题,本文提出BERT结合多标签语义理解模型的方法,该方法改进了BERT子结构的方式,以达到更好的提取到文本的特征的目的,同时改进下游深度学习模型捕捉标签的相关性。具体地,该方法通过设计BERT与不同的下游分类任务模型结合实现了三种模型,分别对文本的特征表示、提取文本的局部表征和标签相关性提取方面进行改进。通过实验验证了三种模型分别在上下文语义理解、局部特征提取、标签时序性预测的有效性上展现了结合多标签语义理解的优势。(2)面对标签语义信息准确性问题,本文提出一种基于标签注意力机制的文本分类方法。该方法通过BERT学习到输入文本以及标签语义的上下文向量表示,进而利用注意力机制捕捉标签语义和文本信息之间的语义相关性,突出与标签信息相关的文本特征,提升模型的分类能力。实验结果表明,该方法在多标签文本分类任务中展现了比较好的性能。
{URL}: https://link.cnki.net/doi/10.27380/d.cnki.gwkju.2023.000761
{DOI}: 10.27380/d.cnki.gwkju.2023.000761
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自然语言处理技术在建筑工程投资管理中的应用
{Author}: 姚凯卿
{Tertiary Author}: 尚春静;张立杰
{Publisher}: 防灾科技学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 投资管理;工程量清单;命名实体识别;智能查询;自然语言处理
{Abstract}: 21世纪以来,人工智能技术逐渐开始在建筑工程领域得到应用,如二维码在建筑制品的质量跟踪应用,工程质量缺陷的图像识别等。这些技术的应用提高了建筑工程建造管理效率。为进一步推进新技术迭代升级和产业快速增长,科技部等六部门印发了《关于加快场景创新以人工智能高水平应用促进经济高质量发展的指导意见(国科发规[2022]199号)》。工程投资造价估算是项目决策的关键内容,但因其在人工智能数据特征识别研究的不足,使得现阶段投资造价人工智能应用场景缺少实现的基础。本文基于自然语言处理技术对建筑工程工程量清单特征进行数据分类,构建了工程量清单特征名称和特征词库,并基于Text CNN算法实现工程量清单项目特征的命名实体识别模型,开发了一套基于命名实体识别模型的工程量清单识别和清单查询平台,为建筑工程投资造价领域发展和应用人工智能提供了场景,促进投资造价管理新技术升级。具体研究内容如下:
(1)应用数据对比分析、分类方法,对深圳市建设工程造价为例的近万个历史工程量清单数据,按照工程量清单九位编码的分部分项工程数据特征,建立了工程量清单数据库标准的项目特征名称及特征值数据库。
(2)建立了工程量清单项目特征命名实体识别(NER)模型体系,将TF-IDF文本相似度算法和Text CNN算法结合,实现了工程量清单特征识别的平均准确率超过93%。
(3)开发了工程量清单项目特征识别和查询接口软件,将工程量清单识别模型集成到建筑工程造价估算软件中,实现清单项目特征识别和特征关联清单及定额信息查询应用。
{URL}: https://link.cnki.net/doi/10.27899/d.cnki.gfzkj.2023.000069
{DOI}: 10.27899/d.cnki.gfzkj.2023.000069
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于对比学习的关系抽取研究
{Author}: 王树森
{Tertiary Author}: 徐雅静
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 关系抽取;对比学习;零样本;开放域关系抽取
{Abstract}: 随着深度学习技术的高速发展,关系抽取技术取得了巨大的进步,但其性能表现依赖标注数据的质量和数量,对实际的应用落地造成了一定程度的困扰。零样本关系抽取旨在通过对已知关系训练,实现对未知关系抽取,能够从一定程度缓解模型对标注数据的依赖问题。尽管零样本关系抽取能够处理未知关系,但无法处理非预定义关系。对于非预定义关系,需要通过开放域关系抽取来解决。针对未知关系和非预定义关系,本文基于对比学习思想对关系抽取下的零样本和开放域关系抽取场景进行深入探索和研究。具体研究内容和贡献如下:一、本文对零样本和开放域关系抽取的相关理论知识和研究现状进行调研和梳理,并介绍对比学习的原理、数据增强以及损失函数。二、针对零样本关系抽取中现有方法受限于相似问题,本文基于对比学习提出了一种新型的关系对比学习框架(Relation Contrastive Leaning,RCL)。在多任务学习的设置下,本文引入关系对比学习,并通过关系对比学习和关系表示学习在已知关系数据上训练,使得模型能够学习到关系本身的特性、关系与关系之间的差异和实例与实例之间的不同,从而把这种能力泛化到对未知关系的抽取上。经过实验验证,RCL能够有效的解决相似问题。三、针对开放域关系抽取中现有方法受限于数据集的伪相关问题,本文提出了一种基于对比学习的开放域关系抽取模型。在多任务学习的设置下,通过实例排序和标签校准使得模型能够在不同空间对正样本、困难负样本和半困难负样本进行相对关系约束建模,学到一种更具有鉴别力的关系表示,提高下游聚类的性能。经过实验验证,本文提出的模型优于所有对比的基线模型,验证了方法的有效性。最后,本文对研究内容进行了总结,并对未来零样本和开放域关系抽取的发展进行展望,给出多个未来研究方向。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000035
{DOI}: 10.26969/d.cnki.gbydu.2023.000035
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT模型的方面级情感分析研究
{Author}: 陈叶楠
{Tertiary Author}: 刘天时
{Publisher}: 西安石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: BERT模型;方面级情感分析;对比学习算法;依赖解析树;关联性图注意网络
{Abstract}: 情感分析属于自然语言处理领域的一个重要分支,在指导生产、市场营销、掌握社会舆情等方面发挥着重要的作用。传统的粗粒度情感分析已无法满足当今的生产需要,使细粒度的方面级情感分析应运而生。针对短文本中方面级情感分析准确率低的问题,本文从影响方面级情感分析任务性能的因素出发,改进了预训练BERT模型。在此基础上,融合关联性图注意网络与改进的BERT模型构建了方面级情感分析RGAT-CLBERT模型,有效提升了方面级情感分析任务的性能。本文的主要工作包括:(1)分析预训练BERT模型存在的词向量表示各向异性问题。从预训练BERT模型的源头注意力机制出发,逐步探究其各个组件功能,总结出该模型存在的词向量表示各向异性问题,即词嵌入矩阵在向量表示空间分布不均匀的状态。针对所研究的问题产生的原因从几何性质层面进行具体分析,给出了相关的理论支撑依据,为后续扩充该模型的应用场景做理论铺垫。(2)结合对比学习算法,获得了改进BERT的CLBERT模型。由于预训练BERT模型存在的各向异性问题,导致模型对上下文语义信息的提取不够充分,影响了方面级情感分析任务性能的提升。为此,通过引入对比学习算法,优化了预训练BERT模型的词向量表示,得到了CLBERT模型。测试结果表明,该模型在多任务通用语言理解评估基准数据集中相比BERT基本模型的准确率和F1(F-score)值都有不同程度的提升,其中,在SST-2数据集上准确率提升了1%,在MRPC数据集上F1值达到了3.4%的提升。(3)构建了融合关联性图注意网络与CLBERT的方面级情感分析RGAT-CLBERT模型。由于现有的方面级情感分析模型忽略了单句中存在多个方面词的句式表达,这种句式表达使用传统的方面级情感分析模型进行分类时会错误的关注距离方面词最近的情感词。同时,预训练BERT模型对语句中上下文语义信息提取不充分,在一定程度上共同影响了情感倾向的判断。为此,利用句法结构信息与上下文语义信息的相互结合,构建了方面级情感分析RGAT-CLBERT模型。所构建的模型在三个公开数据集上(Twitter数据集、Rest14数据集、Laptop14数据集)进行了实验验证。结果表明,RGAT-CLBERT模型在方面级情感分析中准确率和F1值均有一定提升,其中,在Rest14与Laptop14数据集上的F1值分别提升了1.9%与1.6%。本文所构建的RGAT-CLBERT模型在一定程度上提升了方面级情感分析任务的性能,为自然语言处理的研究提供了参考,具有较广的应用前景。
{URL}: https://link.cnki.net/doi/10.27400/d.cnki.gxasc.2023.000376
{DOI}: 10.27400/d.cnki.gxasc.2023.000376
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 肿瘤靶向pH/还原响应型非抗凝肝素化ES2-紫杉醇纳米递送系统的构建及抗肿瘤作用研究
{Author}: 卢鲁
{Tertiary Author}: 谭海宁
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 非抗凝肝素;肿瘤靶向;化学修饰;紫杉醇;抗肿瘤
{Abstract}: 新生血管的生成对肿瘤的生长和转移至关重要,可以为肿瘤的发生和发展提供营养物质。课题组在前期研究中筛选了一段多肽序列(ES2,IVRRADRAAVP),研究发现,该序列可显著抑制肿瘤新生血管的生成。基于前期研究结果,本课题将ES2作为研究对象,采用无抗凝活性的肝素(non-anticoagulant heparin,GSHP)对其进行化学修饰改善其存在的半衰期短、稳定性差等问题。为增加肿瘤靶向作用,首先采用与肿瘤细胞表面高表达的唾液酸具有高度亲和的苯硼酸作为靶向基团,利用3-氨基苯硼酸(3-aminophenylboronic acid,PBA)上的氨基与GSHP上羧基间的缩合反应将苯硼酸分子连接到糖链上,得到样品GSHP-PBA(GP)。其次,为增加纳米粒的成球能力,将维生素E琥珀酸酯(D-α-tocopherol succinate,TOS)以酯键的方式连接到GSHP上,得到样品GSHP-PBA～TOS(GPT)。最后,通过胱胺(cystamine,Cys)作为连接臂将GSHP与ES2进行连接,得到样品ES2-GSHP-PBA～TOS(EGPT)。此外,为增加纳米粒的抗肿瘤活性,将广谱抗肿瘤药物紫杉醇(paclitaxel,PTX)包载在纳米粒内部,得到最终纳米粒PTX/EGPT NPs。PTX/EGPT NPs纳米粒具有“一药双靶”的作用,即在PBA的作用下,药物到达肿瘤部位,在肿瘤微环境(低pH、高GSH)刺激下,纳米粒解体,释放ES2和PTX,从而在抑制内皮细胞增殖的同时杀伤肿瘤细胞,达到抑瘤效果。本论文主要内容和取得结果如下:(1)PTX/EGPT NPs的合成与表征首先,采用高碘酸钠氧化和硼氢化钠还原的方法制备无抗凝活性的GSHP,采用EDCI和NHS作为催化剂将PBA通过酰胺键连接到糖链GSHP上,随后采用EDCI、NHS和DMAP作为催化剂将TOS通过酯键连接在糖链上。然后,以Cys为link将ES2连接到糖链上得到EGPT。每一步聚合物的结构通过1H NMR进行表征,最终表征结果显示成功制备了 EGPT。最后通过物理包载的方法将PTX包裹在纳米粒内部,得到PTX/EGPTNPs,采用高效液相色谱法(highperformance liquidchromatography,HPLC)研究PTX的载药量和包封率。采用动态光散射仪对纳米粒的粒径进行考察,通过透射电子显微观察纳米粒的形态,最后模拟肿瘤微环境对纳米粒的释药行为进行研究。结果表明PTX的载药量和包封率分别为4.39%±0.56%和70.11%±8.66%,纳米粒在水溶液中呈球形,粒径为202.32±4.32 nm。此外,PTX和ES2分别能在弱酸性环境和高谷胱甘肽环境下实现快速释放,表明纳米粒具有肿瘤微环境敏感的特性。(2)PTX/EGPTNPs的体外生物学评价以EAhy926细胞和B16F10细胞为研究对象,采用CCK-8、迁移、侵袭、管腔和凋亡实验评价PTX/EGPTNPs的体外抗新生血管生成和抗肿瘤能力,通过激光共聚焦和流式细胞仪研究PTX/EGPTNPs的体外肿瘤靶向性。结果表明,PTX/EGPTNPs能够显著性抑制两种细胞的增殖,抑制两种细胞的迁移和侵袭,并因有ES2的存在纳米粒能显著抑制内皮细胞的管腔形成。此外,结果发现PTX/EGPT NPs可以诱导内皮细胞和黑色素瘤细胞的调亡。通过靶向性实验研究发现,PTX/EGPTNPs与ES2相比,对黑色素瘤细胞具有更强的靶向性。(3)PTX/EGPTNPs的体内生物学评价采用小动物活体成像仪对PTX/EGPT NPs在小鼠体内的组织分布情况进行考察,采用荷瘤小鼠模型对纳米粒的体内抗肿瘤能力进行评价,且通过免疫组化实验研究了小鼠肿瘤组织中细胞凋亡因子和血管生长因子的表达。体内分布结果表明,纳米粒具有明显的肿瘤靶向性且能在肿瘤部位滞留更长时间。体内抗肿瘤实验结果表明,纳米粒在体内对实体瘤具有较强的抑制作用,抑制率能达到76.56%,且对小鼠并无明显的毒副作用。此外,免疫组化结果显示,纳米粒能够显著抑制Bcl-2、COX-2、MMP2/9、VEGF和TGF-β等因子的表达,显著促进Cyt-C和Caspases-3的表达。综上所述,PTX/EGPTNPs表现出良好的抗新生血管生成活性和抗肿瘤活性。此外,本课题成功将肿瘤靶向剂、抗新生血管生成药物、抗肿瘤转移药物和化疗药物应用在同一药物递送系统中,具有较好的应用前景。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.003737
{DOI}: 10.27272/d.cnki.gshdu.2023.003737
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的网络谣言识别
{Author}: 茅新
{Tertiary Author}: 吕英杰
{Publisher}: 北京化工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 健康类谣言;谣言识别;内容特征;深度学习;文本分类
{Abstract}: 随着移动互联网的发展和社交平台的崛起,信息的传播速度、传播范围得到空前的发展。尤其在健康信息领域,大量的健康类信息在社交平台上产生和传播。与此同时,健康领域也成了谣言的泛滥之地。健康类谣言与其他主题谣言相比,更具有敏感性和危险性,因为健康类谣言涉及人们的生命健康,谣言的传播过程中受众极易受到伤害,稍有不慎还可能引发公共安全危机。同时,随着碎片化阅读的普及,健康类谣言的传播形式也开始转变,往往使用简短、肯定的结论,让人在碎片化的阅读中快速记住结论,使得健康类谣言更具隐蔽性和影响力。因此尽早发现并识别谣言是减少谣言危害的重要方式,目前各大网络平台主要依靠网民举报,人工筛选的方式进行判定,但这种方法既增加了平台的工作量,又无法对谣言的源头进行识别,从而降低谣言传播的影响。为了解决这一问题,本文提出了一种针对短文本健康类谣言的检测模型,通过挖掘短文本谣言的内容特征,包括词语特征、情感倾向特征、话题类型特征、情感差异特征、对象情感特征,来摆脱传统网络谣言识别对用户特征和传播特征的依赖,实现对谣言的早期识别。实验证明,该模型在识别健康类谣言方面具有较高的准确率和召回率,有效地缓解了社交平台上健康类谣言传播带来的危害。主要包括以下两个部分:(1)短文本健康类谣言内容特征分析。基于已有研究对网络谣言和健康类谣言内容特征的总结,本文结合自然语言处理技术如词性标注,情感倾向分析等,从短文本健康类谣言文本内容中提取出词语特征、情感倾向特征、话题类型特征、情感差异特征、对象情感特征五个内容特征,其中为构建对象情感特征,获取了大量科普类文本构建了对象情感知识库。为了验证本章提出的内容特征对于谣言识别的效果,使用爬虫技术,从微信小程序爬取了大量短文本健康类谣言数据,并利用支持向量机分类算法,设置了不同的实验模板,对各模板特征集进行分类训练。实验结果表明,新提出的话题类型特征、情感差异特征和对象情感特征对谣言识别有较好的效果。(2)基于深度学习的谣言识别模型构建。本文针对健康类谣言短文本的特点,改良了文本分类模型Text CNN、Text RNN和Text RCNN,将提取出的内容特征融合进深度学习网络模型进行谣言识别,并通过融合不同的内容特征设置不同的参照组进行实验。实验结果表明,融合内容特征的改良模型比原文本分类模型和基于特征的分类方法效果要好,其中最佳识别模型是融合话题类型特征、情感差异特征和对象情感特征的Text CNN模型。本文还通过对对象情感特征的对象知识库大小进行对比实验,发现知识库大小对模型效果有明显影响,为后期模型的优化提供了参考。本文提出的模型专注于短文本健康类谣言的识别,可以实现谣言的早期检测,在谣言源头就可以识别,避免了谣言传播带来的风险,有效帮助网络平台自动识别谣言。
{URL}: https://link.cnki.net/doi/10.26939/d.cnki.gbhgu.2023.000897
{DOI}: 10.26939/d.cnki.gbhgu.2023.000897
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的军事信息系统设计与实现
{Author}: 程霄
{Tertiary Author}: 刘勇
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 军事知识图谱;深度学习;知识抽取;实体推荐;自然语言处理
{Abstract}: 在互联网和大数据快速发展的当今,如何对互联网上的信息进行有效地挖掘和使用是目前研究的主要方向,而知识图谱技术就是一种可以有效地从大量零散的文字中提取出结构化知识的方法,并且能够挖掘信息间的关联性,有利于满足领域信息系统的需求,具有十分广泛的应用前景。本文基于知识图谱实现了以军事领域为核心的信息系统,具体工作内容如下:1、提出了基于军事领域知识图谱的构建方案。针对军事领域缺乏公开数据集等问题,本文对军事领域知识图谱的构建技术进行了深入的研究,在此基础上给出了军事领域知识图谱构建的总体设计方案。通过爬虫技术和基于深度学习的知识抽取技术,从互联网中获取了结构化、半结构化、非结构化数据,根据军事相关知识进行本体层设计,利用Neo4j技术完成了数据的存储,并完成了军事领域知识图谱的搭建。2、研究了针对军事领域信息的知识抽取算法和知识表示模型。本文采用BERT+CRF抽取模型用于知识抽取,有效解决了军事数据不完整、专业名词较多、实体关系重叠等问题。同时针对军事信息三元组的特点,对TransE翻译模型进行训练和改进,学习图谱中实体的语义信息、实体与实体间的关系信息,并对其进行向量化表示,通过计算实体之间的相似性,实现对实体的推荐。3、设计并实现了基于知识图谱的军事领域信息系统。在已构建的军事领域知识图谱的基础上,搭建出系统的各个功能模块,包括图谱可视化、实体查询、图谱维护、关系抽取、实体推荐等功能,最后对系统进行了测试工作,验证了系统功能的可行性。总体而言,本文提出了军事领域知识图谱的构建方案,以及针对军事信息的知识抽取和知识表示算法,实现了系统的搭建和系统功能的开发,在系统中为用户提供了多种信息获取功能,提升了用户体验。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.002273
{DOI}: 10.26969/d.cnki.gbydu.2023.002273
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的中文图书自动分类研究
{Author}: 欧阳涛
{Tertiary Author}: 徐天伟
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本分类;图书分类;预训练模型;深度学习;智慧图书馆
{Abstract}: 作为高校的学习资源中心,图书馆在其学科发展中扮演着至关重要的角色。随着高校“双一流”学科建设的不断推进,图书馆资源建设与服务能力愈发受到重视,可以说高校图书馆承担着推动高校学科发展的重要使命。近年来,新一代人工智能技术的发展,为高度自动化的图书馆资源管理提供了可能,如何利用人工智能技术实现中文图书的科学编目和自动分类成为开展智慧图书馆研究的重要内容。然而由于缺乏高质量领域数据集、技术手段运用不够深入等问题,基于人工智能技术的中文图书分类研究目前仍处于探索起步阶段。因此,本文重点开展高校图书馆中文图书自动化学科分类的应用研究,构建了中文图书学科分类数据集,采用先进的自然语言处理技术实现中文图书的自动分类,为未来智慧图书馆的自动化管理和智能化、精准化的知识服务提供技术支撑。本文研究工作主要包括:(1)中文图书学科分类数据集构建。针对传统中图分类法在高校学科知识服务方面的不足,基于学科目录建立了中图分类法到学科分类的映射方法,采用了 Python编程实现对高校图书馆的馆藏、流通和订购数据进行数据清洗和补全,构建了包含五种标签的中文图书学科分类数据集,其中完整的二级学科条目包含109类、52773条数据。(2)基于预训练模型的中文图书自动分类。利用自然语言处理领域前沿的预训练语言模型构建了中文图书分类模型,并与深度学习传统的神经网络模型进行性能对比,通过在公开数据集和自建数据集的多组对比实验,验证了基于多头自注意力机制的预训练语言模型在文本表示和特征提取能力方面的优势,同时也证明了基于预训练模型的中文图书分类模型的有效性。(3)基于预训练模型与特征融合的细粒度中文图书分类。针对中文图书学科分类任务,对BERT类预训练模型的参数进行了优化,并在此基础上提出了一种基于特征融合思想的预训练模型特征增强方法PLM-LCN,充分利用不同类型网络的特性增强预训练模型的特征表示能力。通过与多种基准模型的消融和对比实验,验证了 PLM-LCN提升分类性能的有效性及良好的模型泛化能力。(4)高校中文图书自动分类系统设计与开发。依据高校图书馆实际需求,基于提出的中文图书分类模型算法,设计开发了高校中文图书自动分类系统。该系统实现了通过图书相关内容自行进行学科分类,同时支持基于学科分类的图书管理、图书检索和图书推荐,为高校图书馆的精准化学科知识服务提供技术支撑。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2023.002035
{DOI}: 10.27459/d.cnki.gynfc.2023.002035
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 物联网恶意软件分类模型的优化技术研究
{Author}: 孙建鹍
{Tertiary Author}: 罗熊
{Publisher}: 北京科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 恶意软件分类;深度强化学习;混淆攻击;噪声标签;演化算法
{Abstract}: 随着边缘设备的增多,物联网中信息传输密度的增加对通信网络中的信息处理时延和边缘设备能耗提出了更高的要求,这些要求也对物联网中的恶意软件识别提出了新的挑战。首先,目前的恶意软件识别方法主要关注于桌面端和移动端恶意软件,难以有效防范物联网平台的恶意攻击,也无法满足物联网边缘计算设备低内存占用和检测时间的要求。其次,针对新兴的机器学习恶意软件识别方法,规避攻击技术使用伪装策略降低了模型的识别能力。尤其是其中的对抗混淆攻击,通过在机器学习模型的原始输入序列中插入简单的混淆指令欺骗恶意软件识别系统,降低了模型的识别能力。然后,恶意代码混淆技术、恶意软件识别系统过时等因素可能导致机器学习的训练数据集出现噪声标签,严重降低了机器学习识别系统的学习能力。最后,恶意软件识别系统中超参数的不同配置也会影响系统的性能,虽然高级演化算法可以在一定程度上缓解超参数组合多、最优组合探索困难的问题,但是这些算法未考虑基于演化计算方法的模型优化在不同时期的种群差异性现象,导致了时间和资源的浪费。针对上述问题,本文开展了如下四个方面的研究:(1)针对物联网场景下恶意软件识别模型的内存和用时限制,本文设计了一种基于自然语言处理技术的物联网恶意软件分类模式,并结合时序卷积网络实现了一种恶意软件分类模型,其分类性能优于先进模型。在恶意软件族分类和恶意软件检测两个任务上的实验结果验证了本文模型的低内存和低耗时优势。(2)针对恶意软件识别中的对抗混淆攻击,本文基于自适应的强化学习方法,研究了输入序列中冗余信息的自动移除。该方法通过基分类器和序列抽取模块的联合学习,对混淆样本的冗余信息进行移除,提高了识别混淆恶意软件操作码序列的能力。(3)针对恶意软件混淆攻击等因素导致的不可靠样本标签问题,本文提出了一种鲁棒的混合损失函数,并设计了一种两阶段的鲁棒恶意软件识别模式,提高了模型的学习能力。在人工噪声标签数据集和真实数据集上的实验验证了本文模型在噪声标签问题上的良好性能。(4)针对恶意软件识别模型超参数选择困难问题,本文提出了一种改进的自适应种群规模调整方案,通过在不同阶段采用不同的种群规模提高了识别模型超参数搜索的效率。同其他四种先进演化算法的对比验证了本方法在减少训练用时方面的优势。本文通过以上分类模式设计、输入序列优化、输出噪声标签拟合和超参数优化四个方面的研究,实现了物联网恶意软件识别模型从数据到模型的优化方案,提高了模型在物联网环境中边缘设备上的恶意软件识别能力。
{URL}: https://link.cnki.net/doi/10.26945/d.cnki.gbjku.2023.000474
{DOI}: 10.26945/d.cnki.gbjku.2023.000474
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的DGA域名检测与生成方法研究
{Author}: 赵科军
{Tertiary Author}: 王新军
{Publisher}: 山东大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 网络安全;僵尸网络;域名生成算法;n元语法模型;深度学习;卷积神经网络;循环网络;自注意力机制;生成对抗网络;数据增强
{Abstract}: 僵尸网络(botnet)是当前社会面临的主要网络安全威胁之一。僵尸网络可以通过控制的计算机终端主动利用安全漏洞感染网络中的其他计算机终端,而被感染的网络规模通常非常庞大。僵尸网络具有较强的计算、存储能力和网络带宽优势,可以发起各类大规模网络安全攻击,如分布式拒绝攻击、虚拟货币“挖矿”、垃圾邮件分发、数据盗取及勒索攻击等。僵尸网络已经成为当前主要的网络安全风险之一,僵尸网络检测也就成为了网络安全领域重要且具有实际应用价值的研究课题。典型的僵尸网络通过命令与控制服务器建立与被控终端的通信信道,用于恶意代码更新及指令下发,僵尸网络检测研究的主要目标是发现命令与控制服务器,然后可以采取下线、黑名单处理等方式瓦解整个僵尸网络。为了防止命令与控制服务器的IP地址被直接暴露,僵尸网络通常使用域名的方式访问命令与控制服务器。当前僵尸网络广泛采用域名生成算法(Domain Generation Algorithm,DGA)生成恶意域名,将命令与控制服务器所使用的真实域名隐藏在大量的伪随机域名中,增强了僵尸网络隐蔽性,也提高了僵尸网络域名的检测难度。DGA域名检测是当前一种流行且重要的DGA僵尸网络检测技术,通过检测出DGA域名可以直接定位到僵尸网络的命令与控制服务器。基于域名的检测方法只需要关注域名字符本身,无需其他额外信息,可以方便地部署在各级终端和网络出口位置上。为了减少被发现的可能,越来越多的DGA算法生成可拼读域名,该类DGA域名与合法域名字符分布相似,而传统的基于人工提取特征的域名检测方法较难获取两者之间的差异性,DGA域名检测研究面临新的挑战。近年来深度学习在计算视觉、自然语言处理等众多领域取得了显著的成果,利用深度学习的分类模型实现DGA域名检测已成为当前主流的研究方向。本文充分了解和比较了当前主要的DGA域名检测方法,面向DGA域名检测三个关键挑战性问题:1)域名特征提取;2)可拼读DGA域名与合法域名字符分布相似性;3)部分DGA家族域名样本稀缺性,基于深度学习开展DGA域名检测与生成方法研究。首先,传统的检测方法主要使用人工提取特征的方式,对于不同的DGA家族域名可能需要挖掘不同的特征,并且对于可拼读DGA域名检测能力也较弱。针对DGA域名特征提取问题,本文分析了合法域名和多种DGA域名中n元语法(n-gram)模型元组的差异性,提出了一种基于n-gram模型的DGA域名检测方法。相比传统人工提取特征的检测方法,该模型的输入只需要域名字符,使用n-gram元组避免了人工选取特征的过程,并减少了获取其他特征信息的难度,同时元组信息包含了域名相近字符间的前后联系,能够更好地表达域名字符间的关系。实验结果表明,在公开数据集上基于n-gram的DGA域名分类检测方法F1值达到97.21%,准确率和召回率分别为97.23%和96.7%,均较使用人工选取特征的对比算法更高,验证了该算法在无需手工选取特征的情况下,能取得更好的检测结果。然后,针对可拼读DGA域名与合法域名字符分布相似的问题,本文着重从域名字符及神经网络同层特征长依赖关系入手,分别基于长短期记忆(Long short-termmemory,LSTM)和多头自注意力机制,结合一维卷积神经网络实现DGA域名检测。为了克服LSTM多序列无法并行计算的问题,本文提出将LSTM输入序列向量拼接为单个向量,解决了多序列前后计算依赖的限制,提高了检测速度。该方法充分利用了卷积神经网络高效隐藏特征信息提取和LSTM网络长距离依赖关系获取的能力,能够更加有效地检测出可拼读DGA域名。本文提出的基于多头自注意力的卷积神经网络检测模型,为了获得更多子空间的信息,模型使用了多输入的多头自注意力,即并行作多次自注意力计算,自注意力可以直接获得特征与同层特征的关系,将特征提取和上下文关系获取过程进行统一处理,能够获取远距离特征间的依赖关系。通过实验验证,本文提出的基于LSTM模型在公开数据集上分类检测的F1值可以达到98.32%,基于多头注意力的模型F1值达到98.63%,在保证对伪随机DGA域名检测准确基础上,增强了对可拼读DGA域名的检测能力,较对比研究方法有较大提升。并且相关研究成果在大学校园网运行环境进行了部署,能够实时在线检测已知和未知的恶意DGA家族域名,并可进一步确认感染主机。具有较高实际应用价值。最后,针对部分DGA家族域名样本稀缺性问题,本文提出了两种DGA域名的生成方法应用于小样本DGA域名数据增强。部分DGA家族域名如新发现的DGA家族通常样本数量较少,而基于深度学习的分类任务需要大量的训练数据才能更好地发挥模型大容量的优势。本文提出了一种域名增强生成对抗网络技术,基于自注意力机制和WGAN(Wasserstein Generative Adversarial Network)的利普希茨(Lipschitz)归一化方法保证生成模型能够稳定收敛生成与目标相似的域名,生成的域名与原始域名混合可以增强小样本DGA家族域名训练集质量。本文还提出一种轻量级的基于双向集束搜索的域名生成模型,通过目标域名或单词拼接,然后对其中n-gram元组进行微调,尽量减少生成域名字符分布变化。实验表明提出的两种生成算法生成的域名与目标域名具有较强相似性,用于小样本家族数据增强能够提升检测模型的训练质量,提高检测模型对数据增强家族域名的检测率。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.000111
{DOI}: 10.27272/d.cnki.gshdu.2023.000111
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多源数据融合的金融时间序列预测研究
{Author}: 张晨
{Tertiary Author}: 刘卫国
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;金融时间序列;多源数据融合;机器学习;神经网络
{Abstract}: 对金融市场进行投资是为了获得更高的利益。通过预测金融时间序列变化趋势,投资者可以更好地制定投资策略,控制风险,提高投资收益。但是,金融市场受到大量事件的影响,其未来变化具有动态性。因此,金融时间序列的预测具有极大挑战性。然而,传统的方法通常利用金融时间序列的历史数据来预测其未来发展趋势。历史数据本质上是随机变量,仅通过其来预测未来市场变化无法直观地体现其他影响因素,还会忽略影响因素之间的相关性,不足以获得可靠的预测结果。随着互联网时代信息的高速增长以及自然语言处理技术的发展,使得从海量新闻文本数据中量化投资者情绪,进一步的挖掘金融市场趋势及其波动性成为可能。尽管如此,对金融文本进行舆情分析仍存在以下挑战:第一,基于深度神经网络进行情感分析需要大规模的标记数据,而标记金融文本片段代价昂贵;第二,金融文本具有其独特的专业用语并且倾向于使用模糊表达,然而,目前为止大多数金融文本分析方法基于“单词计数”的手动特征选择,无法理解金融文本更深层次的语义信息;第三是由于自然语言处理模型对文本输入长度的限制,导致大多数金融文本的舆情分析任务仅仅利用了新闻的标题而忽略新闻文本内容,难以关注到真正能够体现投资者情绪的主观数据,缺乏对新闻的文本内容正确的处理和分析。本文主要基于深度学习算法,对金融时间序列预测的相关任务进行了研究,主要贡献如下:(1)搭建基于迁移学习的金融长文本舆情分析网络(Rank-LayeredFinbert-LSTM,Rank-LFLSTM)本文使用面向金融领域的预训练语言模型Finbert解决标签数据稀缺问题,同时利用Finbert从语言建模任务中学习到的权重以初始化下游的舆情分析模型;基于迁移学习在特定金融领域语料库上进行预训练,从而学习到金融文本深层次的语义信息;基于Textrank算法对长文本按照语义特征进行动态划分,深层次挖掘文本的上下文特征,从而精准捕获市场情绪变化。实验表明该舆情分析网络在提取金融文本深层次语义特征方面取得了明显的进步,并且分类准确性远超一般模型。(2)搭建基于多源数据融合的金融时间序列预测模型(BILSTM-Attention)在金融文本舆情分析任务的基础上,提出了结合金融时间序列的历史数据,金融新闻情感分数,金融相关技术指标三者的多源融合数据,从而解决了数据特征单一问题;提出结合了注意力机制的双向LSTM模型,基于注意力机制研究不同维度特征之间的相互作用以及他们对市场趋势变动的共同影响。实验结果表BILISTM-Attention模型能够很好的分析处理金融时间序列相关问题,在预测金融市场变化趋势上具有很好的前景。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.004841
{DOI}: 10.27272/d.cnki.gshdu.2023.004841
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于情感分析的物流服务质量评价算法研究
{Author}: 李乐
{Tertiary Author}: 韩家新
{Publisher}: 西安石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 情感分析;深度学习;物流工程;自然语言处理
{Abstract}: 文本情感分析属于自然语言处理领域的一个重要分支,而目前关于情感分析算法的研究仍然存在一些不足。基于传统机器学习的情感分析算法需要训练大量数据,导致其执行速率缓慢,存在大量冗余工作,因此深度学习算法被提出,其可以解决高维空间的数据稀疏等问题,同时也可以进行更充分的特征提取。但单一的深度学习算法仍无法很好的解决文本中存在的一词多义,获取文本重点信息不精准等问题。针对上述问题,本文提出了一种改进的基于多层协同卷积神经网络LSTM-TTT的情感分析算法,解决了传统情感分析算法的模型训练效率低下以及存在大量冗余数据的问题;同时对比单一深度学习算法,基于LSTM-TTT的情感分析算法可以完整提取上下文语义信息,并且能够精准识别出文本中存在的同义词、近义词等易混淆情感极性词汇,具有特征提取快,分类精度高等优点。本文主要工作围绕以下几个方面展开:(1)研究基于深度学习的情感分析算法原理,探究分析Transformer、LSTM、Text-CNN、TF-IDF算法,通过对多层神经网络进行协同学习与动态全连接集成基于多层协同卷积神经网络LSTM-TTT的情感分析算法,并且设计了LSTM-TTT算法参数训练策略对比实验将算法各项性能指标训练至最优状态。(2)提出天猫商品在线物流服务质量评价文本数据集,通过爬虫技术方法获取了天猫超市不同类型商品的物流服务质量评价数据,并按比例划分训练集、验证集以及测试集。同时分析了电商平台物流服务质量评价文体特点,有针对性的对其进行文本预处理工作。(3)设计LSTM-TTT算法与随机森林、XGBoost、LSTM和Transformer四个机器学习算法的对比试验,实验结果表明,LSTM-TTT算法经过训练后的精度与F1值为95.5%,取得了非常优秀的结果,其相较于LSTM算法在准确率上提高了6%;相较于Transformer算法在准确率上提高了8%,证明了LSTM-TTT算法的有效性与可行性。LSTM-TTT情感分析算法是一种改进的深度学习算法,丰富了情感分析在自然语言处理领域的相关研究。同时将LSTM-TTT情感分析算法运用到在线物流服务质量评价文本数据集上进行训练分析,是在电子商务行业物流服务质量监控领域的一种应用创新。
{URL}: https://link.cnki.net/doi/10.27400/d.cnki.gxasc.2023.000296
{DOI}: 10.27400/d.cnki.gxasc.2023.000296
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Prompt的文本生成技术研究与实现
{Author}: 郭新浩
{Tertiary Author}: 肖达
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;文本生成;Prompting技术;预训练模型
{Abstract}: 文本生成任务是根据给定的输入,自动生成输出内容,典型的文本生成任务包括机器翻译、文本摘要、对话任务等。目前实行这些任务很成熟的方案是在预训练模型上进行下游任务的微调,已经取得了很好的效果,在这些任务上也有了很成熟的应用。但是随着目前预训练模型参数量越来越多,这种微调方法存在着资源消耗量大的问题。这种微调方法的另一个问题是预训练任务和微调任务不能对齐,不能充分利用模型在预训练阶段学习到的知识,甚至可能导致模型的灾难性遗忘。基于prompt的学习方法可以很好的解决上述问题。基于prompt的微调方法在减少了训练参数和训练数据量的同时,还能取得良好的效果,逐渐成为新的微调范式。本文主要探索prompt技术在文本生成领域的研究。本文的主要工作内容有,提出了一种基于prompt的参数初始化方法,解决了少样本场景下prefix-tuning任务中模型收敛慢或者不能收敛的问题;提出了将离散prompt和连续prompt相结合的prompt架构;提出了基于强化学习的prompt调优方法;针对强化学习中打分模型容易为与原文重复度高的摘要打高分的问题,提出了一种数据构建方法。实验结果表明,在少样本场景下,上述提出的方法都能够有效的提升模型性能。最后对上述技术进行了整合,设计了一个基于prompt的文本生成系统,系统实现了内容安全生成和文本摘要功能,系统中还加入了敏感文本检测模块,对异常文本进行检测,过滤不安全的文本内容。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.002814
{DOI}: 10.26969/d.cnki.gbydu.2023.002814
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 低资源场景下关系抽取关键技术研究
{Author}: 韩佳乐
{Tertiary Author}: 程渤
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 关系抽取;少样本学习;对比学习;原型网络;提示微调
{Abstract}: 关系抽取任务是自然语言处理领域的一个关键任务,旨在自动捕获非结构化文本中的结构化关系,是一系列任务的重要基石,包括知识图谱构建、问答系统、推荐系统等。随着人工智能技术和硬件计算能力的飞速发展,基于深度学习的关系抽取技术得到了广泛的研究,通过具有丰富类别的大规模高质量的标注数据训练神经网络,使得模型获取辨别这些关系的能力。尽管这些方法取得了令人印象深刻的表现,但它们过分依赖于大量优质的带标签数据进行学习,很难适用于训练过程中从未见过的新关系。然而,在现实场景中,由于标注数据的昂贵人力物力成本和特定领域数据的稀缺性,获取大规模高质量的标注数据十分困难,这极大地限制了深度学习模型的实际应用。因此,开展低资源场景下的关系抽取关键技术研究,探索如何采用少量标注样例辨别新关系是一个极具研究价值且迫切需要解决的问题。近年来,少样本关系抽取任务吸引了国内外学者的最新关注。然而,目前的研究在如何学习更好的具有辨别力且无偏差的表示、解决更困难的少样本关系抽取任务、以及挖掘预训练语言模型中的知识这三个方向上依然存在一些重要的问题需要解决。因此,本文针对基于低资源场景下的关系抽取任务进行了研究,并做出了如下贡献:1.针对基于迁移的少样本关系抽取方法存在的监督不足和虚假关联问题,本文提出了一个基于对比学习和原型网络的两阶段多分支网络,旨在学习更具有辨别力和无偏性的表示。具体地说,预训练阶段采用了一种有监督对比预训练策略,充分挖掘全局训练数据的丰富关系类别,利用对比学习方法获得更具有辨别力的表示。在元训练阶段,本文设计了一个基于句子分支和实体分支的原型网络,辅助的实体分支促使句子分支学习无偏性的表示。实验结果表明,该模型能够有效地缓解现有方法中存在的监督不足和虚假关联问题,提升少样本关系抽取任务的性能。2.现有少样本关系抽取方法不能很好解决困难少样本任务,忽略了区分混淆类别的关键信息,并且在训练过程中对不同难度任务一视同仁。为了填补这一空白,本研究引入关系标签语义信息,介绍了一种新颖的基于混合原型和关系的对比学习方法,捕获更细粒度的原型类别表示,以更好地建模困难任务。同时,本文提出了两个训练策略,即困难负原型生成策略和任务自适应焦点损失。通过增加训练任务的难度和迫使模型更关注难度更高的任务,这些策略提升了模型的鲁棒性和有效性。上述方法在三个流行的少样本关系抽取数据集上取得了最优的表现,并大幅提升了困难任务的性能。3.面向广义少样本关系抽取任务,为了消除原始提示微调技术模板的严格限制,本文提出了基于生成的提示微调方法,创新性地将关系抽取转换为文本填充任务,采用预训练生成模型联合生成实体类型和关系标签序列,更充分地挖掘预训练语言模型的知识,从而实现高效的关系识别。在预测阶段,一种简单但有效的实体导向的解码和关系评分机制被提出,通过注入实体信息来隐式地约束生成的关系类型,并高效地将生成的序列与标签集对齐。本文在完全监督和低资源两种场景下,基于三个预训练模型,在四个关系抽取数据集上,有力地证明了提出的方法的有效性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000277
{DOI}: 10.26969/d.cnki.gbydu.2023.000277
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 工程造价信息采集及数据挖掘研究
{Author}: 巴文豪
{Tertiary Author}: 郭婧娟
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 工程造价;数据挖掘处理;信息采集;机器学习
{Abstract}: 现如今互联网和大数据快速发展发展的背景下,信息技术和数据处理技术正在逐渐渗透到众多领域。反观工程造价领域每天都在产生这大量的造价信息和数据,而工程造价信息的获取、积累和传递仍然依赖于传统的方法,其及时性和准确性已经不能满足当今工程管理领域的需要。住建部和国家有关部门颁布多项政策,大力号召进行工程造价市场化改革和推进工程造价信息化建设,加强造价资料和信息数据的积累,提高服务水平,提高信息价的准确性和及时性。
本文通过立足工程造价咨询企业在信息化背景下转型升级,对其获取造价信息数据的难点和问题进行分析,梳理开展业务对信息数据的具体需求,提出了运用自然语言处理技术的Ro BERTa预训练模型,实现对工程量清单智能采集,并智能归类汇总成造价指标,并通过项目特征筛选数据中的类似样本数据构建小样本数据集,构建了基于高斯过程回归的工程造价预测模型,解决了信息价与实际价之间的偏差问题。本研究可以为工程造价咨询企业业务开展提供支撑,推进工程造价信息化进程,提高行业竞争力和创新能力,提高造价管理的水平。本研究重点研究了以下四点内容:
(1)通过文献研究对国内外工程造价信息化建设状况和发展趋势进行了梳理,确立了工程造价领域进行信息化改革和数字化转型,需要结合自然语言处理技术、机器学习和数据挖掘等前沿技术的观点,基于此确定了本文的研究目的和研究路线。
(2)为了明确工程造价咨询企业在数据化转型中的具体需求,对工程造价咨询企业的业务范围及全过程造价咨询业务中的关键工作进行分析,确定了不同阶段造价工作所需要依据的计价文件资料。分析了信息化背景下工程造价咨询企业存在的问题。在此基础上分析了工程造价咨询企业对数据信息的需求,面对信息化浪潮企业需要准确可靠的信息和数据以及已完工程造价资料。明确后续研究对信息采集的方向。
(3)构建了对工程造价信息采集的具体方法,利用自然语言处理有关技术,基于Ro BERTa预训练模型,构建了工程量清单分类模型,实现数据的智能化采集和积累。该模型在采集到的样本训练和学习之后,分析确定了各个模型的最优参数,并对预训练模型在此任务中的性能进行了分析和评估。结果表明该模型对工程量清单的分类准确路达到了90%以上,模型性能表现较为优异。
(4)工程造价信息数据经过采集和整理后,本文对基于机器学习的工程造价预测模型展开了研究,采用高斯过程回归算法搭建了工程造价预测模型。根据拟建工程项目技术等指标,筛选出类似工程造价样本数据集,通过对样本数据的学习和训练,确定预测模型的最佳核函数,以使对工程造价的预测误差最小化,经过实验,该模型在样本数据集上对工程造价预测误差低于1.5%,满足了工程造价估算和概算的精度要求,可为工程项目造价管理提供可靠的依据。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2023.002112
{DOI}: 10.26944/d.cnki.gbfju.2023.002112
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于增强BERT的食品安全案事件知识图谱构建研究
{Author}: 王琦
{Tertiary Author}: 孙德辉
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 增强BERT;食品安全;知识图谱;命名实体识别;关系抽取
{Abstract}: 知识图谱作为一种新型的知识表示和推理手段,为食品安全领域的研究提供了新的思路。知识图谱将食品安全案事件中的实体、属性和关系等信息进行高效的表示和存储,提高食品安全知识的表达和交流效率。同时,通过基于知识图谱的智能推理和分析,可以快速发现案件中的潜在风险因素,预测可能发生的食品安全事件,并及时采取相应的措施,提高食品安全保障水平。因此,建立食品安全知识图谱具有重要的理论和应用价值。本文针对食品安全领域的案事件知识图谱构建进行了研究。知识图谱的构建主要通过两步进行,首先是命名实体识别,提取文本中具有特定意义的实体,然后根据文本建立实体间的关系。本文的具体研究内容如下:(1)针对食品安全领域的实体类型较多且专业性较强的问题,提出融合食品安全专业词汇的命名实体识别模型,可以有效识别食品安全领域专业词汇,并结合双向长短期记忆网络模型学习食品安全文本的上下文特征以及条件随机场模型进行识别结果进行约束,来提高模型的识别准确率。依据模型特点构建食品安全命名实体识别数据集,对模型进行训练与验证。实验结果表明,本模型有效提高了食品安全领域命名实体识别准确率。(2)根据食品安全文本的特点,提出能够融入已有食品安全专业知识图谱数据的实体关系抽取模型,同样使用双向长短期记忆网络模型结合条件随机场进行模型的优化。构建食品安全实体关系抽取数据集,在该数据集上与其他模型进行对比,验证了该模型的有效性。(3)根据以上模型将裁判文书构建为食品安全案件知识图谱,将食品抽检记录数据构建为食品安全事件知识图谱,共同组合为食品安全案事件知识图谱。并设计食品安全专家研讨系统,本系统可以实现对专家发言的检测,将专家发言内容中涉及食品安全的关键字自动提取,在食品安全案事件知识图谱中寻找相关实体及关系,进行实时展示。通过构建食品安全知识图谱,为有效地食品安全研判与推理打下了基础。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2023.000515
{DOI}: 10.26926/d.cnki.gbfgu.2023.000515
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识交互的家庭服务机器人任务解析与序列规划研究
{Author}: 周昭旭
{Tertiary Author}: 田国会
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 服务机器人;指令解析;序列规划;知识库;人机交互
{Abstract}: 随着生活水平的提高,家庭服务机器人越来越多地迈进了人们的生活。目前在家庭服务任务中,机器人执行任务大多基于简单任务的预设指令,不具备对复杂任务与未知任务的理解与完成能力,表现为无法规划出任务执行的步骤,导致其泛用性不足。而面临多变的家庭环境和个性化的用户交互需求,如何理解用户口述风格各异的任务指令,并能够生成出符合特定家庭环境的复杂服务任务的动作序列,是服务机器人智能化的关键所在。因此,本文针对家庭服务任务的智能指令解析、动作序列生成和知识交互优化三个关键点进行研究,并进行实验验证,本文的具体工作如下:(1)针对家庭服务机器人在面对用户口述服务请求时,对任务指令内容理解能力不足的问题,提出了基于门控机制与先验知识的任务类型识别与关键词提取方法,提高了指令解析的准确度和泛用性。对于用户口述的服务任务请求指令,首先通过语音识别转化为自然语言文本格式,并使用FastText词嵌入方式将指令文本转化为词向量序列。然后,在BiGRU的基础上融合注意力机制,提出基于门控机制与先验知识的任务类型识别与关键词提取联合模型,解析出指令的任务类型与包含的物品、属性等关键词,同时基于关系判断与主客体对齐的关系匹配模型进行多物品属性的匹配,得到指令中物品与对应属性的配对结果。最后对指令解析方法进行对比实验,验证了该方法在指令解析中的智能性与准确性。(2)针对家庭服务机器人在执行复杂服务任务时,难以规划出合理动作序列的问题,提出了基于服务策略的动作序列生成方法,降低了任务的复杂度,可有效指导动作序列的规划。首先,由于对复杂或未知任务直接规划动作序列难度较大,故使用一个文本表示的服务步骤作为中间状态,命名为服务策略,进而提出了基于知识增强的服务策略生成模型,通过指令解析出的任务类型与关键词经扩展输入到该模型中,作为引导文本与控制文本约束服务策略生成的主题,使其更符合家庭服务任务的逻辑。然后将生成的服务策略经优化后,令其每个步骤都作为子任务用于动作序列规划,定义了基于PDDL的家庭领域描述,提出了针对子任务的问题描述自主生成方法,利用任务规划器进行求解得到机器人可执行的动作序列。最后对基于关键词引导的知识增强服务策略生成方法进行对比实验,并将基于服务策略的动作序列生成结果进行验证实验,验证了该方法在复杂任务规划中的完成度与可靠性。(3)针对家庭环境复杂多变而导致生成的服务策略环境适应性较差的问题,提出了基于知识库的人-机-知识交互问答优化方法,结合当前环境与知识库的信息对服务策略进行补全消歧等优化,提高其环境适应性。从个性化家庭服务任务的需求入手,建立了包含家庭物品、属性和序列等知识的家庭服务知识库,并基于该知识库搭建了人机交互问答模块,同时结合视觉检测,对服务策略与环境中不匹配的部分进行问答消歧,从而对服务策略进行适应性优化,提高其泛用性。最后对该优化方法进行实验,在搭建的家庭环境仿真平台上展示整个任务规划的流程。实验表明,本文方法能够有效解析出用户指令包含的关键信息,并提高完成复杂任务的能力。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.002903
{DOI}: 10.27272/d.cnki.gshdu.2023.002903
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多模态信号分析与理解关键技术及应用研究
{Author}: 雷陈奕
{Tertiary Author}: 李厚强;华先胜
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 多模态信号分析;多模态数据集;预训练技术;视觉问答;个性化推荐系统;对比学习;表征学习
{Abstract}: 随着移动设备和移动互联网的不断普及,人们的工作和生活方方面面都已经进入了一个在线服务交互的时代。在线服务包括日常信息沟通、网购、视频娱乐、专业咨询等各种场景。在爆炸式增长和普及的在线服务中,用户和服务商之间的交互方式也呈现多元化趋势。与传统的线下服务和早期的互联网服务不同,当前这些在线交互模式的信息载体是多媒体数据,同时涵盖了不同模态的复杂信号,包括文本信号、视觉信号、语音信号和用户信号等。因此,对这些复杂多模态信号的语义理解和解析已成为在线服务能够良好开展的一个基石。只有对这些多模态信号进行良好的语义抽象,包括融合、转化、对齐、迁移和表征等,才能让用户更加高效地获取信息和服务,让服务商更加明确地理解用户的需求,让平台更好地进行数据结构化存储和产品改进。因此,多模态信号分析与理解的关键技术及应用探索是一个兼具学术与工程应用价值的重要课题。针对上述背景,首要就是针对多模态信号进行深入分析与理解建模。本论文以移动互联网上的海量多模态数据为基础,基于自监督学习、预训练-微调等先进技术和研究范式,探索实践了多模态预训练大模型的建模方案,从而能够对多模态信号进行高层语义理解和关联表征,为基于多模态信号分析与理解的关键应用提供了底层技术基础。进一步的,为了更好衡量与验证所学习到的多模态预训练大模型的语义理解与表征能力,本论文选取了基于多模态信号理解的问答系统和个性化推荐系统作为代表性关键应用进行实践。这两个应用需要模型具备极高的多模态信号理解与推理能力,同时还涉及用户的结构信息和结构化输入等复杂信号,因此能够对多模态信号分析与理解模型进行很好的应用与评估。同时,本研究工作依托科技部国家重点研发计划重点专项课题《基于Q-A问答的在线咨询与服务》(课题编号:2020YFC0832505)进行,基于预训练技术的多模态信号建模、基于多模态信号理解的问答系统和个性化推荐系统也是该课题的关键技术与关键应用。总体而言,本论文的主要研究工作、创新成果和核心贡献包括:(1)本论文提出了一种基于大规模预训练技术的中文多模态信号分析与理解算法。通过真实的互联网线上数据,本论文构建了一个超大规模的中文多模态视频数据集,其中包含超过1000万个带有人工撰写文本描述的完整视频。该数据集极大地丰富了中文多模态数据语料。基于该数据集,本论文提出了一种新颖的、基于预训练范式的视频-文本学习框架。本论文创新性地设计了多种预训练任务和学习机制,不仅可以让多模态预训练模型更加鲁棒,而且还能够从不同角度捕捉更复杂的多模态语义信号和结构关系。同时,本论文探索了多模态预训练模型的压缩技术,使得模型在保障高质量性能的同时,参数量得到极大压缩,从而便于线上部署。本论文在包括通用领域和专业领域多个数据集上,与业内先进算法进行了各种不同的下游任务的验证和评估。相关结果证明了本论文所提算法的有效性。(2)本论文提出了一种基于多问题联合学习的视觉问答算法。由于在线对话和问答服务的多轮交互特性,往往在问答过程中可能同时存在多个问题。这些问题之间往往具有强的语义相关性,这些关联性能够更好地辅助和定位提问者的意图,帮助问答系统更好地进行回复。因此,本论文提出了一种新颖有效的基于注意力机制的多模态多问题联合训练框架,从而有效提升了视觉问答系统的准确度。在多个公开数据集上的实验结果表明,本论文提出的算法为提问者提供了更加准确的回答,表现出了很好的性能。(3)本论文提出了一种基于多模态信号迁移学习的个性化视频推荐算法。首先,通过一种新颖的基于对比学习范式的预训练技术,结合多模态信号的语义泛化能力,将用户在不同场景下的行为兴趣映射到同一个兴趣参数空间,从而为用户在不同场景下的兴趣提供迁移学习和联合学习的可能性。接着,结合上层设计的多场景迁移学习算法,更好地捕捉了用户在不同场景下的兴趣意图,从而提供更好的用户体验和个性化推荐服务。本论文在真实的互联网用户行为数据集上进行了实验,并与近年来的多个经典算法进行了比较分析,从而验证了本文提出的算法的有效性。(4)本论文所提出的算法和系统,经过针对性调优,在多个司法领域的任务上进行了验证。一方面进一步验证本文方法的泛化能力与在重要场景的实用意义,另一方面验证本文对于所依托重大项目的理论、技术与系统实践的支撑作用。具体而言,包括非法内容识别和司法对话生成,涵盖了司法领域的判别任务和生成任务。实验结果和分析验证了本文研究内容对于司法场景相关技术和应用的支持。同时,本文还在其他真实应用场景进行了系统部署验证,并对实际应用中的系统搭建和实现进行了相关的研究和分析。总之,本论文的研究成果有助于推动多模态信号语义理解、下游应用以及多媒体领域相关课题的实践和创新。此外,在真实的在线系统中部署和实践进一步表明,本研究具有重要的应用价值和实际意义,可以提升下游关键应用的用户体验和服务水平。最后,本论文的研究成果也有助于科技部国家重点研发计划重点专项课题《基于Q-A问答的在线咨询与服务》(课题编号:2020YFC0832505)中多模态信号理解、问答技术和个性化业务相关需求的技术攻关和应用推进。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.000214
{DOI}: 10.27517/d.cnki.gzkju.2023.000214
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向无标注长文本和低资源场景的抽取式文本摘要
{Author}: 唐莫鸣
{Tertiary Author}: 钱卫宁;陈岑
{Publisher}: 华东师范大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 抽取式文本摘要;层级编码器;强化学习;对比学习;迁移学习
{Abstract}: 文本摘要是自然语言处理领域的一项重要任务,旨在压缩文档篇幅并提炼主旨信息以便读者快速掌握文档核心内容。文本摘要方法主要分为抽取式摘要和生成式摘要。相较于生成式摘要,抽取式摘要通过选择文档的重要文本片段构建摘要,构建的摘要严格忠于原文档。因此,对于信息准确性要求较高的工业应用场景,更偏好使用简洁高效的抽取式摘要。目前,学术界已经对抽取式文本摘要进行了详尽研究,大多要聚焦于有监督摘要方法和基于强化学习的摘要方法。然而,当前的抽取式摘要方法仍然存在以下缺陷:i)文本编码长度受限以及文档缺乏高质量参考摘要的问题。受限于语言模型的编码长度,基于预训练语言模型的摘要方法难以直接应用于长文档摘要。此外,这类方法需要使用具备大规模参考摘要的文本摘要数据集才能获得出色性能。然而,现实应用场景中文档普遍缺乏高质量人工摘要。因此,现有的基于预训练语言模型的摘要方法难以应用于现实场景的长文档摘要任务。ii)错误传递以及摘要合理评估问题。基于强化学习的抽取式摘要方法难以解决自回归摘要的“曝光偏置”问题。强化学习通常用于长序列决策的自然语言生成任务,当与自回归摘要结合时会面临“教师指导”(teacher forcing)训练范式造成的“错误传递”问题。此外,当前基于强化学习的摘要方法使用的奖励信号机制难以充分发挥强化学习动态评估抽取摘要的优势缓解“曝光偏置”问题。iii)小规模训练数据集造成的监督信号匮乏问题。当前的抽取式文本摘要方法主要应用于具备大规模“文档-参考摘要”的开源据集,在训练阶段需要充足的监督信号才能获得出色性能。然而,现实中大部分应用场景仅具备极小规模的文本摘要数据集,例如仅具备200篇文档-参考摘要对。因此,当前的抽取式摘要方法难以在低资源应用场景取得满意结果。本文旨在解决上述抽取式文本摘要方法存在的问题,具体研究内容如下:·研究基于BERT的层级编码器以及基于自然语言理解任务的奖励函数,通过抽取式强化摘要方法实现参考摘要匮乏场景的长文档摘要任务。本文旨在解决基于预训练语言模型的文本编码器难以编码长文档的问题。为此,本文提出基于BERT的“句-段落-文档”层级编码器。文档的每个段落聚焦于自身的语义观点并与文档主旨相呼应。层级编码器中的段落级编码器利用BERT编码文档段落的丰富语义信息获得句子的局部段落级表征向量,文档级编码器进一步编码不同段落句子间的语义关联关系获得文档句子的全局表征向量。此外,为了将抽取式摘要应用于缺乏参考摘要的现实场景,本文将抽取式摘要与强化学习结合,利用文本摘要在现实应用场景的相关下游任务设计奖励函数,引导摘要模型抽取语义显著且可靠的摘要。实验结果表明,本文方法在多个长文档摘要数据集上都取得了更好的表现。·研究面向强化自回归摘要的对比学习范式和基于采样的奖励信号机制,缓解自回归摘要的“曝光偏置”问题。针对“曝光偏置”造成的自回归摘要“错误传递”问题,本文提出了面向强化自回归摘要的对比学习训练范式。通过构建文档的候选摘要并按照语义质量排序,利用比学习范式编码候选摘要的排序信息,使模型具备判断摘要语义质量的能力。即使摘要模型在推理阶段偏离目标摘要,也能够从后续解码过程可能构建的候选摘要中选择最佳摘要作为输出,避免“错误传递”。此外,本文针对当前抽取式强化摘要方法采用的奖励信号机制无法合理评估抽取摘要的问题,设计基于采样的密集奖励信号机制,更好地优化摘要抽取策略。实验结果表明,本文的方法在短摘要和长摘要数据集均有效提升了自回归摘要方法的结果。·受提示学习和迁移学习的启发,研究面向低资源场景的抽取式文本摘要方法。针对仅具备小规模摘要数据集的应用场景,本文将抽取式文本摘要转化为文档和候选摘要之间的文本释义任务,旨在缩小文本摘要任务和预训练语言模型的训练差距,更好地检索预训练语言模型的相关知识辅助摘要任务。此外,本文通过迁移学习将文本释义任务的知识迁移到文本摘要任务,引导摘要模型识别语义显著的高质量候选摘要,降低摘要方法对训练数据规模的要求。实验结果表明,本文提出的低资源抽取式文本摘要方法在中英文数据集的各项低资源设置中均显著优于当前领先的抽取式摘要方法。综上所述,本文设计基于BERT的“句-段落-文档”层级编码器,利用全局注意力机制预训练语言模型提升摘要模型的文本表征能力;同时,针对现实应用场景中文档普遍缺乏高质量参考摘要的问题,本文根据文本摘要的下游任务设计奖励函数为模型训练提供间接监督信号。此外,本文还提出面向强化自回归摘要的对比学习范式和基于采样的奖励信号机制,缓解自回归摘要的“曝光偏置”问题。同时,本文还提出面向低资源应用场景的抽取式文本摘要方法。通过上述研究,本文尝试扩展抽取式文本摘要方法的适用范围。在未来的工作中,本文将尝试将抽取式文本摘要与预训练生成式摘要模型结合,在保证摘要忠于文档核心语义的情况下改善摘要的可读性。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.004090
{DOI}: 10.27149/d.cnki.ghdsu.2023.004090
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态预训练模型的文档图像问答技术研究与应用
{Author}: 吴欣雅
{Tertiary Author}: 王小捷
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多模态预训练模型;视觉文档问答;注意力机制
{Abstract}: 文档视觉问答(Document Visual Question Answer,DocVQA)是指基于视觉文档回答问题的任务,该任务需要有效利用图像中的语言信息来回答问题。DocVQA在实际生活中有广泛的应用,得到了不少研究。但是,现有研究主要集中于“in-line”问题,即答案位于关键词所在的同一行、同一列或同一句子,具有简单的线性关系。而在实际应用中,存在大量更具挑战性的情况需要解决。为此,本文在系统综述和分析相关工作的基础上展开研究,主要工作包括:提出了一类新的DocVQA问题,称为“in-region”DocVQA问题。不同于现有的“in-line”问题,“in-region”问题中,问题和答案存在于某个区域中,不具有简单的线性位置关系。要解决这类问题,需要在定位正确区域的基础上,进一步理解区域中的文本。继而,本文构建了一个面向“in-region”问题的全新的文档视觉问答数据集:RDVQA,其包含8582张图像和针对于图像的8814个问题。提出了一个基于区域推理的DocVQA模型ReIQ。其包含两个关键模块:基于区域推理的预训练模块STPM和基于注意力机制的状态追踪模块DocST。在STPM模块中设计了两个全新的预训练任务,MTBR和STR,在DocST模块中,我们采用注意力机制通过多轮迭代的方式,对问题和视觉文档进行多轮推理。ReIQ模型在RDVQA数据集上的实验结果优于StructuralLM,表明了其在解决此类文档视觉问答问题方面的有效性。最后,基于ReIQ模型和RDVQA数据集开发了面向电子商务零售领域的DocVQA演示系统。用户可以方便地上传文档图片、提交问题并获得答案。在前端,该系统提供了一个用户友好的图形用户界面。在后端,调用ReIQ模型对用户的问题和文档进行处理,最终输出精准的答案。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000114
{DOI}: 10.26969/d.cnki.gbydu.2023.000114
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的伪代码到代码生成方法研究
{Author}: 于倩倩
{Tertiary Author}: 顾乃杰
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 伪代码;代码生成;程序修复;注意力机制;数据处理
{Abstract}: 计算机已经普遍应用在医疗、商务、旅游等各个领域。人们的学习、生活和工作越来越离不开计算机,对于计算机的需求越来越多样化。为满足日益增长的需求,自动代码生成技术逐步进入人们的视野,用来提高软件开发的效率和降低专业化操作的技术门槛。早期的代码生成方法虽然可靠性比较高,但是其往往需要创造形式化规范。形式化规范的创建过程十分具有挑战性。近年来,人工智能领域发展迅速,并在数据挖掘、计算机视觉等领域大放异彩。因此,将人工智能技术与代码生成技术相结合来探索新的自动代码生成方法逐步得到关注。本文围绕伪代码到代码的生成任务,一方面针对伪代码到代码生成模型展开研究,另一方面探索如何获得高质量的伪代码到代码数据集,具体工作内容如下:(1)针对如何提升伪代码到代码生成任务的成功率问题,设计实现一种基于全局与局部信息自适应的伪代码到代码生成模型。首先将每行伪代码通过多尺度金字塔特征提取器多方位地进行特征提取,获得对应的带有权重的预测代码。然后进行搜索合成阶段,将带权重的预测代码按照预设的搜索组合规则进行搜索组合从而合成一个候选程序,并通过给定的测试用例对候选程序进行验证。与此同时,设计基于全局和局部信息自适应的代码修复模型,合理地利用编译器的反馈信息以找到真正的报错行和修复报错代码,以提升伪代码到代码的成功率。(2)针对现有的开源的伪代码到代码数据集的质量问题,提出一种全自动化的数据筛选与数据修正模型。该模型通过代码到伪代码修复器和伪代码到代码生成器逐步迭代的方式对有问题的伪代码数据进行自动化的筛选和修复,从而获得优化后的数据集。具体来说,先通过伪代码到代码生成器将数据进行初始分类,分成正确伪代码数据和错误伪代码数据。然后代码到伪代码修复器利用正确的代码将错误的伪代码数据进行改写,从而获得正确的伪代码数据。综上所述,在开源的SPoC数据集的测试集TestP和TestW上,基于全局与局部信息自适应的伪代码到代码生成模型分别取得了 46.1%和63.5%的优良精度。实验结果表明该模型能够提升代码生成任务的成功率。此外,在现有的伪代码到代码生成模型上对优化后的数据集进行验证,分别取得了 63.1%和82.4%的优秀精度。实验结果反映全自动化的数据筛选与数据修正模型能够获得高质量数据。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001420
{DOI}: 10.27517/d.cnki.gzkju.2023.001420
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 古诗词知识图谱构建及在预训练模型中的应用研究
{Author}: 赵嘉琪
{Tertiary Author}: 吴斌
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中国古诗词;自然语言处理;知识图谱;预训练模型;深度学习
{Abstract}: 中国诗词传承了几千年的中华文明,也是世界文化的宝贵组成部分。在古代,诗词不仅是诗人抒发情感的载体,还映射出当时的社会风气与文化面貌。对古诗词领域的深入研究,可以帮助我们了解中国古代文人的思想,弘扬中国传统文化。随着数字人文的发展,利用人工智能技术对古诗词进行数据挖掘和分析也逐渐成为研究热点。然而互联网上存在的大量分散的古诗词相关信息,对人们有效获取信息和知识提出了重要挑战。知识图谱可以将不同形式的碎片化信息联系起来,形成结构化知识库。另一方面,现有的关于古诗词的研究往往依赖于大量标注语料做有监督训练,而古诗词的标注数据集通常需要大量的专家参与进行人工构建,这会耗费大量的人力和时间。预训练语言模型能从大量的无监督语料库中学习到良好的语言表征,并有助于后续完成其他下游任务。因此,本文研究基于古诗词知识图谱的预训练模型的构建及应用算法,具体包括以下几个方面:(1)提出了一种基于义原预测的古诗词知识图谱构建方法。通过预测古诗词中词语义原的方式,分析词语的语义信息,将古诗词中的词语和现代汉语之间建立语义联系。通过此方法我们构建了一个包含91,152个节点,203,395条边的古诗词语义知识图谱。(2)提出了一种将古诗词知识图谱融合到预训练模型中的方法,并基于古诗词语料库及古诗词知识图谱训练了一个古诗词领域的预训练模型。模型不仅学习了诗词的词法句法特征,还学习了古诗词知识图谱中的词语语义特征,为后续任务提供了更好的初始化向量,加快了下游任务训练时的收敛速度。实验证明,该预训练模型在诗词主题分类和诗词翻译任务上都展现出了比基线模型更优的效果。(3)构建了基于知识图谱的古诗词大数据分析可视化平台。主要功能包括,古诗词古文原始语料的展示,基于字词的古诗词分析,古诗词知识图谱的展示,对诗词情感题材的分析以及诗词的翻译。分析结果以可视化图表的形式为用户展示。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.001630
{DOI}: 10.26969/d.cnki.gbydu.2023.001630
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的中文食谱智能问答系统设计与实现
{Author}: 兰传浩
{Tertiary Author}: 祝永志
{Publisher}: 曲阜师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;关系抽取;命名实体识别;中文食谱;问答系统
{Abstract}: 随着社会的不断进步,饮食相关信息成为了人们在日常生活中关注的重点。虽然互联网技术的发展使得人们更容易获取与食谱相关的信息,但是这些信息往往是简单的聚合在一起,没有经过筛选,难以满足人们对信息精细化的要求。知识图谱的兴起和发展为智能问答系统和高质量数据库的建设提供了坚实的基础,基于此,本文以中文食谱知识图谱为基础,设计并开发了基于知识图谱的中文食谱智能问答系统。本文的研究工作主要包括以下内容:(1)中文食谱知识图谱构建方法研究。针对中文食谱多源异构的特点,采用自顶向下的方式构建中文食谱知识图谱。首先设计中文食谱知识图谱的本体概念层,然后根据概念层的本体规范将抽取到的三元组添加到数据层中。针对原始数据中存在多三元组和重叠三元组的问题,本文提出了一种基于对抗训练和指针级联标注的实体关系联合抽取模型BERTAdvCasLSTM。该模型采用BERT来训练字向量,通过指针级联标注的方法来抽取三元组中的头实体和特定关系下的尾实体,解决了多三元组和重叠三元组的提取问题,使用对抗训练来提升模型的泛化能力。为了更好的提取尾实体,本文使用Bi-LSTM将头实体特征和句子特征进行融合。实验结果显示,本文构建的模型与CasRel模型相比在DuIE1.0和Recipe＿Chinese数据集中F1值分别提升了2.7%和1.9%,证明了模型的有效性。(2)基于知识图谱的中文食谱智能问答方法研究。针对中文食谱数据的标注特点,设计了一种基于GlobalPointer和对抗训练的问句实体识别模型,识别问句中的实体,解决了嵌套实体的识别问题。针对用户自然语言问句长度较短、表达形式多样等问题,采用了基于BERT-TextCNN的问句意图理解模型,理解用户问句的意图。根据获取到的信息构建Cyhper查询语句,完成答案查询。实验结果显示,与BERT-CRF模型相比,问句命名实体识别模型在Recipe＿NER数据集上的F1值提高了1.77%。与BERT模型相比,问句意图识别模型在中文食谱问句意图识别数据集上的F1值提高了1.08%。(3)基于知识图谱的中文食谱智能问答系统的设计与实现。本文以中文食谱知识图谱为基础,使用Django开发框架,将基于知识图谱的中文食谱问答方法作为技术路线,使用Echarts可视化图表工具对知识图谱进行可视化展示,构建了基于知识图谱的中文食谱智能问答系统。该系统可以帮助用户高效准确地获取中文食谱知识,促进中文食谱知识的数字化和智能化发展。
{URL}: https://link.cnki.net/doi/10.27267/d.cnki.gqfsu.2023.001248
{DOI}: 10.27267/d.cnki.gqfsu.2023.001248
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多源异构数据源的冬奥知识图谱构建研究
{Author}: 曹原
{Tertiary Author}: 刘平山
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;多源异构数据;实体关系抽取;知识融合
{Abstract}: 知识图谱是结构化的语义知识库,用于描述现实世界中的概念(实体)及其相互关系,可通过聚合大量知识,实现知识的快速响应和推理。随着2022年北京冬奥会的举办,互联网上有关冬奥会的信息日益增多,公众对冬奥相关知识的需求也呈增长趋势。然而冬奥会领域的互联网信息存在信息相互独立、关联性不强和展现方式单一的严重问题,并且来自不同数据源的数据相互独立存在且结构复杂各异,无法实现信息的交互与共享。知识图谱的出现为这些问题的解决提供了新思路。目前关于冬奥会领域的知识图谱的研究比较匮乏,本文以冬奥会领域为背景,在现有知识图谱构建研究的基础上,研究从多种来源、结构不一的数据源中抽取知识构建冬奥领域知识图谱。主要研究内容如下:(1)为了构建出一个高质量的冬奥知识图谱,首先对冬奥领域进行了深度调研,基于本体论构建了冬奥领域本体模型。然后对互联网中的各类多源异构的数据进行分析,确定了知识抽取的数据源。在领域本体的框架下,分别设计并且实现了基于百科类网站和国际奥林匹克委员会官方网站的半结构化数据知识抽取与冬奥赛事资讯的非结构化文本数据知识抽取。最后将抽取的三元组知识经知识融合后转存入Neo4j图数据库完成冬奥知识图谱的构建。(2)对于数据量最大蕴含信息最丰富的非结构化文本数据,研究如何从大规模赛事资讯文本数据中抽取冬奥知识图谱构建所需要的实体与关系。基于深度学习,在面向特定领域并预先给定关系类型情况下,提出一种考虑到句中重叠关系与实体抽取的标注方式和三元组抽取规则。该标注方式可实现对实体和关系的同步标注,将实体关系联合抽取任务转换为序列标注问题。然后在此基础上结合多任务分类思想构建了共享Ro BERTa-wwm编码层的多层CRF实体关系联合抽取模型(Ro BERTa-wwm-Multilayer-CRF,RMC)。该模型用单个模型同时执行多个联合的序列识别任务,解决了实体关系重叠问题,为冬奥知识图谱构建提供大量知识表示。(3)基于多源数据的特点制定知识融合策略。对半结构化网页中抽取的三元组与非结构化资讯文本中抽取的三元组采用同义词表判断法和无监督学习下的文本相似度计算相结合的方法,进行知识三元组的融合,避免和减少知识图谱中三元组重复出现或信息不完整等情况。最后,为确保存入Neo4j图数据库中的知识符合预先构建的本体模型,本文采用了自定义映射规则和手动编写映射语句的方式,将My SQL数据库中的数据转存至Neo4j图数据库,完成知识图谱的存储与可视化。通过以上研究能将多源异构、碎片化的冬奥知识用知识图谱这种知识组织形式有效组织起来,方便了管理者对于冬奥数据的合理利用。同时也方便了用户快速准确地筛选有用信息,及时做出精准决策,为后续冬奥会领域知识的智能化服务提供了数据支撑。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2023.000756
{DOI}: 10.27049/d.cnki.ggldc.2023.000756
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的文本到图像合成算法研究
{Author}: 李祥羽
{Tertiary Author}: 王行甫
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本到图像合成;生成对抗网络;多尺度特征融合;通道-空间注意力机制;视觉Transformer;提示微调
{Abstract}: 移动互联网时代,图像已经成为人类社会信息传播的主要媒介,但图像创作复杂、低效,文本到图像合成任务旨在根据自然语言文本描述合成与之语义一致的目标图像,使图像创作更加高效。因其广泛的现实价值,文本到图像合成研究成为多模态机器学习领域的重要课题。生成对抗网络在文本到图像合成任务中取得了良好的效果,但也存在很多问题。首先,传统的多阶段堆叠式模型各阶段网络之间存在参数纠缠,训练难度较大,且效果受限于初始阶段合成图像的质量。其次,最近的单阶段模型避免了前述问题,但对细粒度文本特征的利用不充分。再次,当前模型对多模态特征间相互信息的利用不足。最后,受限于特征编码器的跨模态特征提取能力,基于生成对抗网络的模型与大型自回归、扩散模型相比竞争力不足。针对上述挑战,本论文对基于生成对抗网络的文本到图像合成进行了研究,主要工作总结如下:(1)针对当前单阶段模型对细粒度文本特征利用不充分的问题,提出了一种基于多尺度特征融合机制的文本到图像合成模型。本模型提供了一种多尺度特征融合机制,包含仿射融合块、属性词和单词联合块和属性词增强块等组件,在合成图像的过程中,利用仿射变换与混合注意力机制深度融合图像特征和句子、属性词、单词等不同细粒度的文本特征。针对当前模型对多模态特征间相互信息利用不足的问题,基于对比学习思想设计了对比损失函数充分利用正负样本对的相互信息。此外,本文还使用注意力机制来增强判别器中图文特征的连接效果。实验表明,本模型的表现优于前沿的生成对抗网络主干的文本到图像合成模型。(2)针对当前模型特征编码器的跨模态特征提取能力不足的问题,提出了一种基于视觉Transformer预训练模型CLIP的文本到图像合成模型,提供了在文本到图像合成研究中结合生成对抗网络和预训练模型的新范式。本模型设计了文本特征适配器、视觉提示监督块等组件,通过提示微调迁移CLIP的跨模态特征提取能力到本研究中,并设计特征提取块提升判别器的特征鉴别能力。此外,在对抗损失函数中加入了 CLIP相似性度量以充分利用多模态特征间的相互信息。实验表明,本模型的表现不仅优于前沿的生成对抗网络主干的文本到图像合成模型,在与一些大型自回归、扩散模型的比较中也表现出了相当的竞争力,并且推理速度更快。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001521
{DOI}: 10.27517/d.cnki.gzkju.2023.001521
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的智能医疗多轮对话模型的设计与实现
{Author}: 庞雨奇
{Tertiary Author}: 嵇少林
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多轮对话;层归一化;改进的Transformer Block;拼接键值注意力;MTrm
{Abstract}: 对话系统是自然语言处理任务中最具有发展前景的应用方向之一,而多轮对话却是其中比较复杂的工作。所谓多轮对话,旨在根据上下文信息,进行连续不间断的、以达到解决某一特定任务为目的的对话。在当今这个快节奏的时代,人们会为了节省时间通常会进行网上咨询,因此构建智能医疗多轮对话模型成了必需。针对对话系统,大都直接采用Transformer、GPT-2的结构,虽然效果得到了改善,但也有一定的缺陷。因此,为了优化Transformer基础模块,同时避免让多轮对话模型采用历史拼接的形式,本文在已有Transformer层归一化的基础上,进行改进,然后采取不同的信息交互方式来设计模型。本文的主要工作包括:第一,本文提出一种针对Transformer层归一化进行改进的基础组件——Con-LN Transformer Layer,即在注意力模块中将层归一化放在残差块中,在前馈神经网络模块中将层归一化放置在残差块之外。并在理论上简要证明了改进的合理性,这种调整让不同层的梯度更加接近,使得其在初始化时梯度表现良好,可取消学习率预热阶段,在输出层附近参数的预期梯度不会很大。本文对Transformer、CPT-2和[→D]、[E→D]进行对比实验,针对本文的多轮对话系统验证此调整是有效可行的。第二,本文参考已有的模型设计方案构建了用来整合历史信息的多轮对话模型——MTrm。基于 Con-LN Transformer Layer 得到改进的 Transformer Block,利用增加历史信息的拼接键值注意力机制来辅助Encoder、Decoder、Mccoder之间信息的传递。其中,设计新加入的Mccoder的输入来源及信息传递方式,构建多轮对话模型MTrm。Mccoder作为Encoder和Decoder的交互中介,成为MTrm处理上下文信息的核心,同时这三部分结构采取完全相同的改进的Transformer Block,实现参数共享,使得参数快速收敛。第三,本文对得到的实验结果进行了深入分析。采用实验评价指标PPL、BLEU-2和F1,对实验进行评估。实验验证了 MTrm的有效性和可行性,同时通过对比试验可知,以改进的层归一化——Con-LN为基本组件构建的模型整体效果都不错,层归一化位置的调整是有效可行的。Mccoder同时给Encoder和Decoder两者提供历史信息的模型整体占优,采用效果相对较好的MTrm模型即E(?)M→D,M(?)D进行智能医疗多轮对话实现,模型整体上回复是比较贴合主题的,这表明模型的效果较好。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006768
{DOI}: 10.27272/d.cnki.gshdu.2023.006768
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数据表的开放域检索式问答系统的设计与实现
{Author}: 张志豪
{Tertiary Author}: 郑岩
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;开放域问答;检索模型;负采样;表格问答
{Abstract}: 开放域问答任务是自然语言处理领域中的热门研究方向之一,可应用的场景多种多样,如语音管家、智能搜索引擎等。在开放域问答任务中,用户所提出的问题并不限定于某一领域,因此,如何从海量知识库中检索出最有可能包含用户问题答案的文档是提升开放域问答系统的答案预测准确率的关键所在。数据表格是当前互联网上数量最多、最容易获取与处理的结构化数据之一,并且具有结构清晰、时效性高等优点,因此适合作为开放域问答系统中的知识库存储形式。综上所述,构造基于数据表格的开放域问答模型,在实际应用中有着十分重要的意义。本文使用开放域问答模型中的检索-排序-阅读三段式框架,构建了基于数据表的开放域检索式问答系统。主要工作如下:(1)针对开放域问答模型中的检索模型,本文使用预训练语言模型对问题文本与数据表进行编码,构造基于双塔结构的稠密向量检索模型。针对双塔结构模型训练中的负采样过程进行优化,设计并实现基于采样区域限制的难负样本采样方法,对同一批次内的样本在特征空间中的分布进行限制,从提升检索模型的训练效果。实验证明,优化后的检索模型在召回率上得到了进一步提升。(2)针对开放域问答中的重排序模型,本文使用预训练模型对问题文本-数据表格进行交叉编码,并基于编码器输出的特征进行匹配度计算。除此之外,本文通过添加列级别匹配度计算任务,构造了多任务匹配模型,使排序模型的效果得到了进一步的提升。(3)本文构建了填充式Text-to-SQL模型作为阅读模型,通过将问题文本转换为对应数据表格的结构化查询语言,从数据表中抽取出对应答案。本文将上述各模块整合后,设计并实现了完整的基于数据表的开放域检索式问答系统,并进行了功能和性能测试,最终证明系统运行良好,符合设计需求。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000135
{DOI}: 10.26969/d.cnki.gbydu.2023.000135
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向轻量化架构设计的多模态推理方法研究
{Author}: 金子添
{Tertiary Author}: 余宙
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多模态推理学习;视觉问答;多模态预训练;轻量化方法;模型部署
{Abstract}: 多模态推理学习作为人工智能领域近年来的研究热点,其旨在学习任务中同时对多种模态信息进行处理,例如图像、文本模态数据。当下研究者们为了更好地处理多模态任务并取得较优的性能,通常会采用参数量大、计算量要求高的深度学习模型,为模型落地带来严峻的挑战。为解决该问题,针对多模态推理的轻量化方法亟待研究。目前,轻量化多模态推理方法研究主要存在两个难点:1)单任务层面,以视觉问答任务为例,现有模型部署时如何适应不同的硬件条件。当前视觉问答模型通常为固定大小,而现实中硬件设备种类繁多,模型无法根据不同硬件的计算资源做出调整。2)多任务层面,如何解决现有多模态预训练模型部署时存储和计算开销过大问题。传统全量微调方法在模型部署时会导致存储开销过大,而现有的适配器微调方法在模型部署时会增加推理计算开销,如何既做到降低存储开销又能减少推理计算开销是当下多模态预训练模型多任务部署时面临的难题。为解决上述两个难点,本文提出以下两个方法:针对视觉问答模型部署时无法适应不同的硬件条件问题,本文提出了一种基于双向可切分Transformer的通用轻量化视觉问答方法,其针对Transformer结构模型在深度和宽度维度上设计了一种高效、合理的双向切分策略,使每个切分后的子模型都保持着较优的结构。同时,该方法采用一种训练前的三角过滤原则来去除冗余的子模型并提高模型收敛速度。最后,一种基于知识蒸馏的采样训练算法被提出,保证了子模型精度并进一步降低训练开销。针对多模态预训练模型部署时存储和计算开销过大问题,本文提出了一种基于蒸馏训练的剪枝填补式适配器微调方法,其先对预训练模型部分权重进行裁剪,随后在裁剪部位插入轻量化可学习任务适配器,使模型在保留多模态通用知识的情况下仍具备下游任务的学习能力。最后,为了更好的填补预训练任务和多模态下游任务之间的差异,一种渐进式引导蒸馏训练算法被提出以保证模型在下游任务上的性能。为了验证所提出方法的有效性,本文在广泛的多模态数据集上开展了充足的实验,结果表明本文提出的方法对比现有的方法在多项指标上都存在优越性。同时,本文以提出的方法为核心设计并实现了一个轻量化多模态推理系统。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2023.000951
{DOI}: 10.27075/d.cnki.ghzdc.2023.000951
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于“专利+微博”的人工智能颠覆性技术综合识别研究
{Author}: 于佳文
{Tertiary Author}: 王海军
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 颠覆性技术;技术识别;专利数据;人工智能
{Abstract}: 在技术飞速发展的背景下,人工智能等具有颠覆性的技术不断涌现,这些技术显著改变了传统市场的格局。在这种情况下,学界和产业界高度重视颠覆性技术,而“如何识别颠覆性技术”成为目前的热点话题。由于社交平台的普及,关于颠覆性技术的各类信息呈现在各种媒介上。例如,专利数据可以反映技术的发展情况,而社交网络数据则可以反映技术的市场认可程度等。因此,通过合理地利用专利和微博数据,结合颠覆性技术的特性,可识别出颠覆性技术,有利于企业及时进行技术布局,并给予国家研发方向指导。基于颠覆性技术概念及特征,本研究采用单案例分析,总结出颠覆性技术特性包括创新性、扩散性、转轨性、提升性以及替代性。以此为出发点,构建了基于专利和微博数据的颠覆性技术识别模型。首先,从颠覆性技术的技术特性出发,构建了颠覆性技术评价指标体系,以专利为数据,依据所构建的指标体系筛选出具有颠覆性的专利;其次,以具有颠覆性能力的专利摘要为数据,运用LDA主题模型提取出颠覆性技术主题;最后,以微博文本为数据,运用Bi LSTM对提取出的技术主题进行市场特征的验证,并进行技术应用场景分析,实现对颠覆性技术的识别。本文以人工智能(AI)为例进行实证分析,以验证本研究提出模型的可行性和有效性。首先,在美国专利商标局(USPTO)数据库检索人工智能领域的相关技术专利,依据指标评价体系对各项专利进行测算,获得各项专利的最终得分。其次,利用自然间断点法获取在技术维度上具有高颠覆性的技术专利,并利用LDA主题模型识别出具有颠覆性的技术主题。最后,基于微博数据,运用情感分析的方法探究潜在颠覆性技术或产品的用户感知和市场状况,并对颠覆性技术进行应用场景分析,识别出颠覆性技术。结果表明,本研究从技术维度和市场维度出发,使用专利和微博数据表征颠覆性特性,并进行颠覆性技术识别,是行之有效的,同时也为颠覆性技术的识别提供了新的研究视角。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2023.000050
{DOI}: 10.27322/d.cnki.gsgyu.2023.000050
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练的程序理解与生成
{Author}: 郭达雅
{Tertiary Author}: 印鉴
{Publisher}: 中山大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 程序理解与生成;代码预训练模型;代码表示学习;代码结构;注意力矩阵
{Abstract}: 程序理解与生成是人工智能和软件工程领域中重要的研究方向,旨在让计算机自动分析、处理和生成程序,以协助人类完成复杂的任务。近年来,预训练技术的发展在程序理解与生成方向上取得了许多重要的成果。这些技术不仅能够帮助程序员减少编程错误、提高生产效率和软件质量,还可以使普通用户通过自然语言完成需要编写复杂程序才能实现的任务,从而降低学习成本和提高工作效率。因此,该方向上的研究具有广泛的应用前景和重要的社会价值。
然而,当前基于预训练的研究工作在程序理解与生成方向上仍然存在着一些亟待解决的问题。在数据方面,现有的代码预训练模型尚未利用诸如数据流图和抽象语法树等代码结构所提供的丰富信息,同时也没有充分考虑代码之间的外在关联性,如函数调用和代码复用等,这导致模型难以准确地理解和生成程序代码。在模型方面,需要构建适应不同任务需求的通用模型以降低成本,同时还需要进一步优化模型的计算复杂度以提高效率,从而更好地支持实际场景中的应用。为解决上述问题,本论文进行了以下四个方面的研究工作,以提高代码预训练模型在程序理解与生成方向上的性能与效率:
1、针对代码结构利用不充分的问题,本论文提出了一种基于代码结构的程序理解方法。该方法首先对图结构的数据流进行序列化,同时利用图引导的注意力机制来保留其结构信息,使模型能从序列化的数据流中理解并建模其图结构的信息。此外,本论文还引入了边预测和节点对齐的图结构预训练任务,以便从大量的图结构数据中进一步学习代码的语义,从而提升模型的性能。实验结果表明,代码结构信息的利用和面向图结构的预训练任务都可以增强预训练模型在程序理解方面的性能,并在多个程序理解任务上取得更优异的性能。
2、针对代码关联性处理不足的问题,本论文提出了一种基于检索增强的程序生成方法。该方法通过代码的上下文,在数据库中检索相关联的数据,以辅助模型生成代码。为此,本论文根据不同的场景,提出了基于变分自编码器和基于对比学习的两种检索方式,并采用元学习的方法利用检索到的数据辅助模型生成代码。实验结果表明,基于检索增强的代码生成方法能更有效地利用相关联的代码数据,提高生成的代码质量,并在多个程序生成任务中取得更优异的性能。
3、针对模型结构通用性较差的问题,本论文提出了一种统一的代码预训练模型。该模型利用掩码注意力矩阵控制模型的行为,并在多个预训练任务目标下进行学习,以支持不同类型的下游任务。同时,为了增强模型对程序理解与生成的能力,本论文在预训练过程引入基于自然语言的代码注释和基于抽象语法树的代码结构,促使模型学习代码的语义和语法信息。该模型在程序理解和生成任务上的九个数据集上进行了评估,并在大多数任务上实现了更好的性能。
4、针对模型计算复杂度较高的问题,本论文提出了一种高效的优化方法。该方法利用代码之间的依赖关系,并结合四种稀疏注意力模式,对现有的代码预训练模型进行计算优化。这些注意力模式将模型计算复杂度从平方级别降至线性级别,有效地减少了模型的内存消耗并提高了推理速度。实验结果表明,该模型在长代码的理解和生成任务中表现出更优异的性能和效率。
{URL}: https://link.cnki.net/doi/10.27664/d.cnki.gzsdu.2023.000006
{DOI}: 10.27664/d.cnki.gzsdu.2023.000006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于社交媒体的校园网络舆情智能监测平台的设计
{Author}: 孔科迪
{Tertiary Author}: 杨文阳
{Publisher}: 西安石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 舆情分析;校园社交媒体;情感分类;深度学习;数据可视化
{Abstract}: 网络舆情作为网络环境中重要组成部分,对网络安全产生重要影响。高校网络舆情的发生往往包含多数学生群体的思想观点,为此,基于校园网络环境设计舆情智能监测平台可以有效的帮助高校管理者有效进行舆情分析。从社交媒体中的用户评论数据开展舆情分析工作,涉及对用户评论文本的情感分类任务。在情感分类任务中,传统方法需要消耗大量人力工作且效率低,以深度学习为主的情感分类任务随着相关技术的发展,也具备了一定的改进空间。目前情感分类任务大多为二分类、三分类任务,情感分类结果细粒度有待深化。针对以上不足,本文研究一种基于社交媒体的校园网络舆情智能监测平台并对其实现,论文主要完成了以下几方面工作:1.针对通过用户评论实现舆情情感分析问题,给出了一种批量获取用户评论的方法。该方法通过封装请求的网页信息,模拟用户访问目标网页,解析网页资源获取用户评论并保存至本地。对用户评论数据进行文本去噪、文本预处理操作,使用预训练的ERNIE语言模型完成字词的词向量化。2.针对目前文本情感倾向分类结果简单的问题,提出一种用于情感特征提取与分类的EBAF算法,实现对文本情感的七种情绪分类。算法首先通过预训练语言模型学习句中字词的完整语义表示,融合Bi LSTM和注意力机制实现多维度情感特征提取,结合全连接分类器完成情感特征向量与实例情感标签的映射关系,确定文本情感属性,通过对比实验发现,EBAF算法达到了87.7%的精确率、86.9%的召回率和86.8%的F1得分,相较于其他语言模型或特征提取模型具有更好的表现。3.针对数据展示与交互问题,完成对舆情分析的可视化设计。建立数据与图表的映射关系,设计具有交互性的图表以实现数据的选择查看,结合多种方式表达用户评论所蕴含的关键信息。实现并运行测试基于社交媒体的校园网络舆情智能监测平台,各模块开发完成后进行单元测试验证各模块功能完整性,对各模块进行集成整合并对其进行整体流程测试,验证平台完整性。通过研究实验与平台实现,该平台能够较好的体现舆情分析的各个功能,为用户提供舆情事件下多维度各项数据指标,部分可视化数据带有一定交互性。该平台为高校网络环境下开展学生思想指导工作提供决策依据,研究结果对高校校园网络舆情监测分析领域具有一定理论意义与应用价值。
{URL}: https://link.cnki.net/doi/10.27400/d.cnki.gxasc.2023.000615
{DOI}: 10.27400/d.cnki.gxasc.2023.000615
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的自然语言生成SQL语句的关键技术研究
{Author}: 曹东昱
{Tertiary Author}: 龙华
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: Text2SQL;单表;多表;图神经网络;模板填充
{Abstract}: 近年来,自然语言处理(NLP)在人工智能领域取得了飞速发展。采用自然语言与数据库进行人机交互查询数据,能够降低用户学习专业知识的门槛并提高数据查询的效率。因此,自然语言查询生成SQL语句的技术,简称Text2SQL,在实践中具有极高的应用价值。Text2SQL任务旨在将自然语言查询转换为结构化查询语言(SQL)语句,从而简化用户与数据库的交互。该任务的关键挑战在于精确把握自然语言的语法和语义细节,同时消除自然语言查询、数据库数据表结构和内容以及SQL语句之间在表达和结构方面的差异。在单表查询场景下,通常是使用基于草图(sketch-based)的方法和多任务分类模型来解决Text2SQL问题,传统方法大多仅利用数据库表的元信息,而没有充分考虑查询语句与表内容的相互关系。在SQL中存在多条件列或列名重复等情况下,还存在条件值不能正确映射的问题,例如SQLNet模型无法充分捕获问题和查询的全局语法约束。在多表查询场景下,传统的方法是基于深度学习模型,尤其是图神经网络(Graph Neural Networks,GNNs)和中间表示语言的应用。如IRNet,将Text2SQL任务分解为生成中间表示和生成查询语句两个子任务,降低了任务复杂性,但生成中间表示的过程可能导致信息丢失,影响最终查询语句的准确性。本文着重研究了单表和多表查询场景下的Text2SQL生成方法,提出了针对这两种场景的创新性解决方案。针对单表查询场景,本文提出了一种基于BERT预训练模型的Text2SQL生成方法,该方法通过强化问题与表内容之间的联系,构建特征向量,并将Text2SQL任务分解为基于模板填充的多分类子任务。在预测SQL语句中的条件值时,增加了条件值获取模型来区分文本和数字类型,提高了自然语言查询描述和数据库中存储的数据之间的匹配率。实验结果表明,在Wiki SQL数据集上,该方法在准确率方面至少提升了9.8%,测试集上的准确率达到了81.5%。针对多表查询场景,本文提出了一种基于图神经网络的树状模型解析与生成方法,该方法能有效处理复杂的SQL结构,提升模型在多表查询场景下的生成能力。GNN可以有效地捕捉多表查询任务中涉及的表间关系和属性间关系,有助于提高模型的推理能力。通过在编码器层加强自然语言查询描述与数据库表结构和内容的联系,在解码层利用基于图神经网络的树状模型编码所获得的节点特征表示来生成目标SQL查询,进一步提升了模型对数据库表和列的预测能力。根据实验结果,在SPIDER数据集上,该方法在准确率方面至少提升了10.1%,测试集上的准确率达到了68.3%。本文在单表和多表查询场景下的实验结果表明,所提出的方法在Text2SQL任务上均取得了显著的性能提升。未来研究可以在以下方面进行拓展:(1)进一步探索基于预训练模型的优化和改进方法,提升模型在处理复杂查询任务时的性能;(2)研究更多领域和类型的数据集,以实现跨领域和跨语言的Text2SQL生成;(3)探索将Text2SQL技术与其他自然语言处理任务相结合,以提升整体的人机交互效果。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2023.000812
{DOI}: 10.27753/d.cnki.gcqgx.2023.000812
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 医疗知识图谱中实体关系抽取技术研究
{Author}: 王永盼
{Tertiary Author}: 刘勇
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;实体关系抽取;图卷积网络;远程监督;注意力机制
{Abstract}: 随着生物医学和互联网技术的发展,近年来生物医学领域相关资料、文献、数据等数字化文本信息呈现出指数级增长趋势。将大量医疗文本通过自然语言处理技术转化为医疗资源,提高医疗质量和健康水平,是一项非常重要的工作。本文对医疗知识图谱和实体关系抽取技术进行了深入研究,针对数据标注问题和模型可解释性问题进行了研究,并在最后构建了一个医疗知识图谱。本文的主要研究如下:(1)有监督的算法对于标注数据有很强的依赖性,而人工标注数据费时费力,代价昂贵。针对大规模数据标注耗时耗力问题,本文提出了一种基于MIL(Multiple Instance Learning)的远程监督关系抽取算法MILRE(Multiple Instance Learning Relation Extraction)。该模型利用基于段落的编码机制来嵌入上下文信息,通过使用自注意力机制放宽了传统远程监督假设,利用知识蒸馏来缩小机器标注的误差。在数据集NYT-10上,MILRE的AUC分值达到了54.6,P@M分值为86.0,能够在数据自动标注研究中发挥有效作用。(2)医学领域的实体关系复杂,关系预测工作对模型的可解释性要求较高,现有的模型难以满足需要,为此本文提出了一种基于GCN(Graph convolutional network)的医疗实体关系抽取算法MGCN(Medical Graph convolutional network)。该模型使用共现图和图卷积网络建立实体间的关系网络,可以结合上下文信息,为医学实体的关系预测提供全局可解释性;使用开放世界假设构建相关实体间的潜在关系,并通过知识-意识注意力机制给出所关注的实体对的关系预测,可以有效解决跨句子级别的关系抽取问题。在数据集CTF上,MGCN的F1分值达到了0.831,证明其在医学实体关系抽取方面的有效性,具有重要的医疗意义。(3)本文利用MILRE构建了一个电子信息健康记录语料库,将MGCN在其上进一步训练并进行关系抽取工作得到(实体,关系,实体)三元组,之后将三元组相关信息存储在图数据库Neo4j中,构建了一个医疗知识图谱并进行了可视化处理。本文的研究结果在一定程度上为学者和医生等的研究工作提供了便利,对于医学数据挖掘和知识发现研究的展开有着非常重要的意义和应用价值。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2023.000002
{DOI}: 10.27264/d.cnki.gqdhc.2023.000002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的自动问答技术研究与应用
{Author}: 张田雨
{Tertiary Author}: 陈志云
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;智能问答;多任务学习;知识表示学习;深度学习
{Abstract}: 知识图谱是目前流行的研究方向之一,在学术界和工业界都有广泛应用。本文主要研究基于知识图谱问答(Knowledge Base Question Answering,KBQA)任务。该任务旨在使用知识图谱中的三元组回答用户给出的问题,其主要难点在于知识图谱的大规模性以及问题和答案数据之间的异构性。很多研究从不同角度解决上述难点,但仍然存在以下两点不足。第一,现有方法对于实体链接和关系检测子任务是通过精确匹配来获得候选的,并且直接对其排序忽略了候选中可能存在影响效果的噪声。第二,对于句法结构更加复杂的多跳问题,很多方法将其看做语义匹配任务来解决,但只考虑了关系路径的词级别语义,或者只是简单的对关系名称进行随机初始化,泛化能力依赖于关系的命名规则。针对上述不足,本文开展了相关研究工作,主要研究内容和贡献总结为如下几点:(1)基于指针网络和检索重排的单跳KBQA方法:该方法在实体链接和关系检测子任务中通过检索重排框架来访问知识图谱,使用信息检索方法根据相关性评分生成更高质量的候选,缓解了之前方法对于候选质量考虑不足,忽略其中可能存在影响效果的噪声的问题。并且该方法使用多任务学习对子任务进行联合训练考虑了子任务之间的相关性。最后,在Simple Questions、NLPCCICPOL-2016-KBQA两个数据集上的多个相关实验证明了方法对于整体任务和子任务的效果均有提升作用。(2)基于知识表示学习的多跳KBQA方法:本文提出了一种新的关系路径提取方法用于多跳KBQA任务,可以缓解之前方法的泛化性依赖于关系命名规则的问题。该方法引入了知识表示学习,利用基于旋转的知识嵌入模型Rotat E对知识图谱进行预训练,并把多跳的关系路径嵌入看做从第一个关系到最后一个关系的转换。最后在Meta QA、Web Questions SP两个数据集上的多个相关实验证明了该方法可以有效提升多跳KBQA任务的Hits@1分数。(3)基于知识图谱的计算机百科问答系统:结合目前的教育数字化转型情况,以及对水杉百科的需求进行分析,本文收集了两种来源的计算机热点词汇相关知识,整理融合构建了计算机百科知识图谱。然后,本文将前面章节提出的KBQA方法加以扩展,增加了基于相似度匹配的FAQ问答模块,最终基于Vue和Flask框架实现了一个以智能小杉和用户进行交互的计算机百科问答系统并投入使用,赋予了平台一定的智能化,并对后续的计算教育学领域研究提供了一定的参考价值。本文首先提出了一种基于检索重排框架分两阶段完成知识图谱问答子任务的策略,缓解之前方法忽略候选中可能存在噪声,对于候选质量考虑不足的问题,并且还使用了多任务学习的训练方式考虑任务之间的相关性进一步提升了模型效果。然后重点研究了复杂问题中的多跳链式问题,提出了一种新的基于知识表示学习的多跳关系路径提取方法,缓解了之前方法效果受到关系命名规则限制的问题,实现了更好的多跳问答性能。最后根据实际需求,本文对所提出的方法进行扩展并应用,证明了其实用性,并给计算教育学领域的相关研究提供了参考价值。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000989
{DOI}: 10.27149/d.cnki.ghdsu.2023.000989
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 小学生数学语言转换能力的质性研究
{Author}: 计民美
{Tertiary Author}: 姚琳
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小学生;数学语言;语言转换能力
{Abstract}: 《义务教育数学课程标准(2022年版)》将培养学生能用数学的语言表达现实世界这一目标列为中小学生数学学习的三个核心素养之一。语言是培养思维的重要工具,数学语言可以帮助学生形成抽象的数学思维,还可以帮助学生更好地理解和掌握数学知识。发展学生的数学语言转换能力对于促进学生数学思维的发展至关重要,小学生数学语言转换能力的现状究竟如何?怎样培养学生的数学语言转换能力?因此,基于此疑惑,本研究从以下六个部分开展:绪论部分是通过文献分析法,以数学语言、数学语言转换为关键词进行文献综述,梳理国内、国外研究成果。同时,对数学语言、数学语言转换能力等两个核心概念进行界定。确定本研究的理论基础为SOLO分类理论,从而进行研究设计确定质性研究的研究方法。第一部分是结合SOLO分类评价理论制定评价标准,对长沙市D小学四年级1809班学生共8套数学期末模拟试卷进行质性分析,对教师进行访谈,分别从转换的方向、水平、性别分析小学四年级学生数学语言转换能力的现状。第二部分是依据学生的错题展开错因分析,归纳出小学生在数学语言转换中存在着数学语言的识别、理解、转换和表达等四个方面的障碍。第三部分是根据学生出现的数学语言转换障碍,分析障碍形成的原因或影响因素,主要有数学语言、数学内容、学生自身、教师方面等四个方面。第四部分是对照小学生数学语言转换障碍及其原因,在此基础上,有针对性地提出发展学生数学语言转换能力可采取的有效策略:(1)关注数学语言教学,培养学生语言理解能力。(2)建构数学知识网络,创建学生系统知识结构。(3)重视语言转换训练,发展学生数学建模能力。(4)强化语言变式教学,培养学生语言转换能力。第五部分是研究展望。研究表明:(1)从转换方向看:学生将符号语言和文字语言相互转换的能力最好;将符号语言转换成图式语言的能力最差。(2)从转换能力的水平看:文字语言和图式语言的互相转换,以及符号语言向图式语言的转换,能力较弱,较多同学处于较低的前结构水平和单点结构水平。而在文字语言和符号语言的互相转换,以及图式语言向符号语言的转换中表现较好,较多同学达到多点结构水平,但关联结构水平的同学较少。(3)从性别看,男生在文字和符号语言的相互转换中,以及图式向符号语言的转换中表现比女生更好。而女生则在文字语言和图式语言的相互转换、符号语言向图式语言的转换中表现比男生更好。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.000235
{DOI}: 10.27684/d.cnki.gxndx.2023.000235
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: “九寨沟导游辱骂游客”事件旅游网络舆情情感特征研究
{Author}: 李倩
{Tertiary Author}: 何军
{Publisher}: 沈阳师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 旅游网络舆情;情感;自然语言处理
{Abstract}: 近年来,互联网领域迅猛发展,传播媒介层出不穷,社交媒体的交流已成为当代人们信息交流和舆情演变、传播等最主要的渠道。网络舆情事件引发高度的社会关注度及广泛的讨论,如在微博、微信、小红书、知乎等社交平台广泛讨论从而形成较为重大的网络舆情事件。随着数字技术的迅猛发展,大数据时代已经覆盖到生活方方面面,旅游业与信息技术的融合也正在不断深入,社交媒体、大数据分析云旅游等产品也应运而生,同时社交媒体也成为了大数据时代游客进行沟通及评价的最主要的平台。本文研究了生命周期理论在旅游网络舆情事件中的应用,并总结了旅游网络舆情事件的情感特征。介绍了旅游网络舆情关键词提取算法,分析九寨沟导游辱骂游客事件的关键词特征和情感态度特征。并将生命周期理论应用在旅游网络舆情事件中,旅游网络舆情事件的发展历经四个阶段:潜伏期、爆发期、成熟期和衰退期。这其中潜伏期是指事件首次出现但并未引起舆论大范围关注,爆发期指的是已经引起舆情关注的阶段,开始在网络空间快速传播的阶段;成熟期是指舆情事件的传播速度逐渐减缓,但舆情情绪仍然存在的阶段;衰退期是指舆情事件的情绪逐渐平息,事件逐渐淡出人们的视野的阶段。针对旅游网络舆情事件,从4R危机理论的角度,探讨网络舆情事件对旅游业的影响,以及如何通过4R危机理论实现网络舆情事件的有效管理。网络舆情事件会对旅游业产生诸多影响,首先网络舆情事件可以对旅游业的消费者决策产生重大影响。消费者在选择旅游目的地或旅游产品时,通常会查看相关的网络评价和口碑。如果出现了负面的网络舆情事件,消费者可能会对该旅游目的地或旅游产品产生质疑,从而降低了消费者对该旅游目的地或旅游产品的信任和满意度。其次还会影响旅游企业形象,网络舆情事件对旅游企业的形象也会产生很大的影响。负面的网络舆情事件可能会导致旅游业的整体形象受损,减少游客数量和旅游收入,从而影响整个旅游业的健康发展。
{URL}: https://link.cnki.net/doi/10.27328/d.cnki.gshsc.2023.000976
{DOI}: 10.27328/d.cnki.gshsc.2023.000976
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的中文短文本分类研究
{Author}: 隋德义
{Tertiary Author}: 祁云嵩
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中文短文本分类;文本表示;ERNIE;RoBERTa;混合池化
{Abstract}: 随着互联网的蓬勃发展,文本信息数量呈现出指数级增长的态势。在大数据时代下,文本成为获取信息的主要来源。文本信息的分类使人们对海量数据进行归纳分析变得简单,也是自然语言处理的重要任务之一。从日常生活中获取到的大多是短文本数据,但文本具有噪声大、稀疏度高、体量巨大、上下文内容少等特征,所以如何根据用户需求,从海量数据中准确快速地挖据出其中的重要信息,对现今快速且智能化的社会生活有着极其重要的推进作用。目前,随着神经网络的不断发展,文本表示方法主要是通过传统的Word2Vec词向量模型和新兴的BERT预训练语言模型将词语以向量的形式进行表示。虽然能够很好的对文本进行向量化表示,但无法解决中文短文本歧义性强、语义差、特征稀疏等问题。本文针对上述问题,对基于深度学习的文本分类模型进行研究。本文主要研究内容如下:(1)针对现有模型没有同时考虑文本整体特征与局部特征的问题,本文在主流的文本分类模型中引入平均池化和最大池化相结合的混合池化,进行了三种混合池化方法对模型性能提升的对比实验,主要分为求和混合池化、级联混合池化以及比例混合池化。(2)针对中文文本歧义性问题,本文提出了基于ERNIE模型的混合Bi LSTMMix神经网络模型,首先利用ERNIE模型对文本数据进行向量化表示,生成动态词向量表示,获得更丰富的语义特征信息,然后通过双向长短时记忆网络模型(Bidirectional Long Short-Term Memory)获取上下文语义特征,再利用最大池化和平均池化相结合的混合池化对文本特征进行二次提取,从而获取到更加准确的特征信息。(3)为了解决中文短文本特征稀疏问题,本文首先建立了Ro BERTa-DPCNN模型和Ro BERTa-Bi GRU-Mix模型两种单通道模型,并在此基础上提出了基于Ro BERTa模型的双通道神经网络模型,利用Ro BERTa模型对文本进行更符合语境的语义表达,通过Bi GRU-Mix通道对上下文全局特征进行二次提取,利用DPCNN通道获取深度局部特征,最后将全局特征和局部特征进行拼接。实验结果表明,本文提出的双通道模型与传统神经网络模型和本文建立的单通道模型相比,在中文短文本分类任务中性能最佳。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2023.000257
{DOI}: 10.27171/d.cnki.ghdcc.2023.000257
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 菜粕替代鱼粉及缩合单宁对大口黑鲈生长生理机能的效应研究
{Author}: 康鹏
{Tertiary Author}: 华雪铭
{Publisher}: 上海海洋大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 大口黑鲈;菜粕;缩合单宁;营养代谢;肠道菌群
{Abstract}: 大口黑鲈是我国淡水鱼养殖的主要品种之一,随着大口黑鲈养殖业的不断发展,针对大口黑鲈精准营养需求的专用配合饲料研发的重要性日益凸显,利用价格低廉的菜粕替代昂贵的鱼粉和豆粕仍有必要。但其中的抗营养因子,易对水产动物产生不良影响,成为限制其应用的重要因素。缩合单宁是其中一种主要抗营养因子,低剂量能够促进动物生长,增强机体抗氧化能力和免疫力,调节肠道微生态平衡,提高生产性能,可以用做天然的抗生素。为探究大口黑鲈对饲料中菜粕的最大耐受量以及对应不同用量菜粕中的缩合单宁对大口黑鲈的影响,基于传统养殖实验,开展不同水平的菜粕对大口黑鲈幼鱼生长性能、机体组成、血浆指标、营养代谢、抗氧化免疫、肝肠健康等方面的效应分析,在此基础上,通过肠道微生物和代谢组学分析,剖析大口黑鲈幼鱼对于饲料菜粕和其中缩合单宁的响应及作用机制,阐述菜粕中的缩合单宁是否为配合饲料中菜粕用量的限制因素,以及是否与菜粕中其他抗营养因子存在交互作用。1.饲料中菜粕替代鱼粉及缩合单宁对大口黑鲈生长性能、消化能力、代谢指标以及肌肉组成的影响为了评价饲料中菜粕对大口黑鲈生长、消化能力、营养代谢和机体组成的影响,及该过程中缩合单宁发挥的作用,配制八组等氮等能饲料,其中6组为实用饲料组,设定1组不使用菜粕的鱼粉组为对照组(CG),其他5组为菜粕等蛋白替代鱼粉组,菜粕用量分别为 5%(RM5),10%(RM10),15%(RM15),20%(RM20),25%(RM25),另外2组为半纯化饲料,分别添加0.062%的缩合单宁(≈5%菜粕中的缩合单宁含量,CT5)、0.31%的缩合单宁(≈25%菜粕中的缩合单宁含量,CT25)。使用上述饲料饲喂55天后,菜粕替代鱼粉实验结果显示:随着菜粕的替代水平提高,大口黑鲈的增重率、成活率、特定生长率呈现下降的趋势;5%的菜粕对大口黑鲈生长性能无显著性影响;菜粕水平达到10%及以上时,增重率和特定生长率显著下降,菜粕水平达到20%及以上时,成活率也显著下降。25%的菜粕组蛋白质效率、饲料系数等生长性能所有指标均表现最差。与对照组相比,菜粕各组的肥满度、肝体比、脏体比和肠体比无显著性变化(P>0.05)。随着菜粕替代鱼粉量的增加,胃蛋白酶活性无显著性变化,胃淀粉酶活性呈现先上升后下降的趋势,5%的菜粕组最高。饲料菜粕水平在10%及以上时胃脂肪酶活性受抑制。除20%菜粕组外,其余菜粕组肠胰蛋白酶活性均被抑制。肠脂肪酶不受饲料菜粕影响,并且菜粕对肠淀粉酶活性有增强作用。菜粕水平在15%及以上时,血浆TG含量明显升高。RM25组血浆BUN、LDL含量最高,其余各组无显著性差异。当菜粕水平为20%及以上时,血氨的含量显著升高。随着菜粕替代鱼粉用量增加,血糖含量呈现先下降后升高的趋势,在用量为5%时达到最低,对照组的血糖含量显著高于RM5组,饲料菜粕水平在10%及以上时,血糖水平高于对照组。与对照组相比,菜粕组肝脏GPT活性降低。当饲料菜粕水平不超过10%时,肝糖原含量与对照组无显著性差异,当饲料菜粕水平超过15%时,肝糖原含量显著升高。与对照组相比,菜粕替代鱼粉用量不超过10%时,肝脏T-CHO含量无显著变化,菜粕替代鱼粉用量为15%及以上时,肝脏T-CHO含量升高。在菜粕水平超过20%时肝脏TG含量会显著升高。菜粕使肌肉蛋白质和脂肪含量降低,但5%以下的菜粕影响不显著。菜粕对肌肉ΣSFA、ΣPUFA、TNEAA及TEAA含量均无显著影响,但会降低肌肉ΣMUFA含量。缩合单宁浓度实验的结果显示:添加0.062%的CT对大口黑鲈增重率、特定生长率、蛋白质效率及饲料系数均有积极效果,但影响不显著(P>0.05)。添加0.31%的CT显著降低增重率、特定生长率、成活率及蛋白质效率,并且升高了饲料系数和脏体比指数。添加0.31%的CT,抑制了胃中蛋白酶、脂肪酶、淀粉酶活性以及肠胰蛋白酶、脂肪酶活性。而0.062%的CT,仅有胃脂肪酶活性受抑制,肠淀粉酶活性升高。对照组与CT各组间的血浆T-CHO、LDL、HDL、TG、BUN含量均无显著性差异。0.062%的CT显著降低血糖浓度,0.31%的CT显著升高血氨和血糖的浓度。添加CT提高了肝脏GPT活性,对肝脏T-CHO、GOT、GLN无显著性影响。0.31%的CT组肝脏HG和TG含量上升。0.062%的CT组肝脏HG含量下降,肝脏TG含量无显著性变化。CT添加对肌肉水分、粗蛋白及灰分均无显著影响,但肌肉脂肪含量显著降低。CT添加对肌肉ΣSFA、ΣPUFA、ΣMUFA、TNEAA及TEAA均无显著影响。单独添加缩合单宁和菜粕中的缩合单宁对比实验结果显示:CT5组增重率、蛋白质效率及饲料系数优于RM5组。与RM5相比,CT5组肠胰蛋白酶和淀粉酶活性升高,CT5组血浆BUN、GLU及TG均低于RM5组,但差异不显著(P>0.05)。与RM5相比,(CT5组肝脏GPT活性升高,肝脏HG及TG含量下降,肌肉组成无显著性变化。CT25组与RM25组相比,生长性能无显著性变化,胃脂肪酶、肠胰蛋白酶及胃蛋白酶活性降低,淀粉酶、肠脂肪酶活性升高,血浆中血氨、TG以及肝脏HG、T-CHO含量降低,血浆中T-CHO、GLU含量上升,肌肉成分无显著变化。因此,在不影响大口黑鲈生长、消化及代谢功能的前提下,可以耐受5%的饲料菜粕。从缩合单宁浓度实验证明,0.062%的缩合单宁对大口黑鲈消化代谢具有调节作用,提高饲料利用率。根据对比实验可以证明,菜粕中抗营养因子存在交互作用,其它抗营养因子在低菜粕水平下协同作用明显,在高水平菜粕时,拮抗作用更明显。2.饲料中菜粕及缩合单宁对大口黑鲈抗氧化能力、免疫及肝肠健康的影响为了评价饲料中菜粕对大口黑鲈免疫-抗氧化功能的影响,并推测缩合单宁在其中的可能作用,就第一章中的实验鱼样本进行进一步检测分析。菜粕替代鱼粉实验结果显示:与对照组相比,RM组血浆MDA含量及DAO活性显著升高,RM组血浆SOD、GSH-Px活性降低。RM20和RM25组血浆总抗氧化能力显著性高于对照组和其他RM组,其他RM组和对照组血浆总抗氧化能力无显著性差异。RM25组血浆ROS含量显著高于对照组和其余RM组。RM5组和RM10组后肠二胺氧化酶活性显著性高于对照组,其余菜粕替代组之间无显著性差异。菜粕组肝脏ROS含量升高,GST活性下降,10%及以上的菜粕组肝脏MDA含量显著升高,15%及以上的菜粕肝脏CAT活性下降,25%的菜粕组肝脏AKP活性下降。10%菜粕用量及以上可以显著提高后肠过氧化氢酶活性。各菜粕组后肠MDA含量均显著性高于对照组,25%的菜粕替代组后肠PC、ROS含量显著升高,后肠抗菌肽、补体C3活性显著降低。缩合单宁浓度实验的结果显示:各组之间血浆ROS无显著性变化,但CT5组最低,CT25组最高。与对照组相比添加0.062%的CT组,血浆总抗氧化能力、MDA、DAO含量及GOT、GPT、GSH-Px活性无显著变化,肝脏T-AOC、PC、MDA含量及后肠ROS、PC、DAO含量等无显著变化,血浆SOD活性,肝脏中CAT活性、GSH-Px活性、GST活性,后肠CAT活性、AMP活性,头肾LZM活性等均显著性提高,并且肝脏中ROS含量、DAO活性显著降低。在添加0.31%的CT组,血浆中MDA含量、DAO活性、GOT活性、GSH-Px活性,肝脏中PC含量、ROS含量、DAO活性、后肠ROS活性显著升高,CT25组血浆中总抗氧化能力含量、SOD活性,肝脏中CAT、GST及后肠中SOD活性、LZM活性、补体C3活性的显著下降。CT组后肠MDA含量升高。根据单独添加缩合单宁和菜粕中的缩合单宁对比实验结果显示:CT5组和RM5组血浆MDA无显著性差异,CT25组血浆MDA显著性高于RM25组。CT5组血浆氧自由基含量和RM5组之间无显著性差异,CT25组血浆氧自由基含量和RM25组无显著性差异。CT5组血浆二胺氧化酶活性显著性低于RM5组,CT25组血浆二胺氧化酶活性和RM25组相比无显著性差异。CT5组后肠过氧化氢酶活性显著性高于RM5组,CT25组后肠过氧化氢酶活性显著性低于RM25组。CT25组后肠二胺氧化酶活性显著性高于RM25组。CT5组后肠丙二醛活性和RM5组相比无显著性差异,CT25组后肠丙二醛活性和RM25组相比也无显著性差异。CT5组后肠超氧化物歧化酶活性显著性高于RM5组,CT25组后肠超氧化物歧化酶活性与RM25组相比无显著性差异。根据后肠抗氧化与炎症基因表达结果显示:在肠道IL-6表达中,RM5显著低于对照和RM25。RM25和对照组之间没有显著差异,CT5显著低于对照和CT25组。在肠道TGF-β2表达中,RM5显著高于RM25,RM5与对照无显著差异。对照组、CT5组和CT25组之间无显著差异。在肠道TGF-β1的表达中,RM5显著高于对照和RM25,CT5显著高于CG和CT25,CT25显著低于对照。在肠道Nrf2表达中,RM5显著低于对照但高于RM25,CT5显著高于对照和CT25,CT25显著低于对照。因此,使用15%以上的菜粕对鱼体的肝脏和肠道造成氧化损伤,使用25%菜粕加重肠道炎症反应。添加0.062%缩合单宁可提高机体抗氧化能力和肠道免疫功能,而添加0.31%缩合单宁则抑制机体抗氧化能力和免疫功能。基于对比试验结果,推测5%菜粕组所含缩合单宁的抗氧化性受到其它抗营养因子的抑制作用,而25%菜粕组的多种抗营养因子存在拮抗作用抑制缩合单宁的促氧化作用。3.饲料中菜粕及缩合单宁对大口黑鲈肝脏代谢组学和肠道微生物的影响为探究菜粕以及缩合单宁影响营养物质代谢以及抗氧化和免疫的作用机制,就第一章中的实验鱼样本进行进一步肝脏代谢和肠道微生物群落检测,肠道微生物结果显示:在肠道微生物群落丰富度和多样性方面,RM5组ACE指数低于RM25组,和对照组几乎无差异。CT5组ACE指数高于CT25组和对照组,RM5组ACE指数低于CT5组,Chao1指数和observed species指数呈现出相同的趋势。在门水平上,其中相对丰度前5位的门是Proteobacteria(变形菌门),Firmicutes(厚壁菌门),Bacteroidetes(拟杆菌门),Actinobacteria(放线菌门),Fusobacteria(梭杆菌门),这些相对丰度最高,总比例占95%以上。变形菌门和厚壁菌门是样本中的优势菌门。其中相对丰度前十的属为Sphingomonas(鞘氨醇单胞菌属),Plesiomonas(邻单胞菌属),Muribaculaceae(Muri 菌),Burkholderia-Caballeronia-Parabukholderia(伯克霍尔德氏菌属),Bacteroides(拟杆菌属),Clostridium-sensu-stricto(梭状芽胞杆菌属),Prevotella(普雷沃氏菌属),Escherichia-Shigella(大肠埃希菌属-志贺氏菌属),Enterococcus(肠球菌属)。秩和检验(Kruskal Wallis)统计发现RM5组变形菌门和厚壁菌门相对丰度显著性高于RM25组,而RM25组拟杆菌门和放线菌门相对丰度显著低于RM25组。CT5组变形菌门相对丰度显著低于CT25组,而CT5组厚壁菌门,拟杆菌门和放线菌门相对丰度显著高于RM25组。CT25组类志贺邻单胞菌相对丰度显著高于其他各组,RM5组维氏气单胞菌相对丰度显著高于其他各组和对照组的琼式不动杆菌相对丰度显著高于其他各组。在代谢组学分析结果表明,大口黑鲈肝脏中,对照组和RM5组之间共鉴定出887个差异代谢物,与对照组相比,RM5组中有479个代谢物上调,408个代谢物下调。与对照组相比,RM25组共鉴定出897个差异代谢物,有446个代谢物上调,451个代谢物下调。CT5组和对照组相比,共鉴定出880个差异代谢物,其中445个代谢物上调,435个代谢物下调。CT25组和对照组相比,共鉴定出751个差异代谢物,其中379个代谢物上调,372个代谢物下调。RM25组和RM5组相比,共鉴定出792个差异代谢物,其中337个代谢物上调,455个代谢物下调。CT25组和CT5组相比,共鉴定出850个差异代谢物,其中446个代谢物上调,404个代谢物下调。CT5组和RM5组相比,共鉴定出780个差异代谢物,其中334个代谢物上调,446个代谢物下调。CT25组和RM25组相比,共鉴定出782个差异代谢物,其中406个代谢物上调,376个代谢物下调。其中菜粕组和对照组相比,差异代谢物中,大部分标志性代谢物与脂质代谢有关,仅有少部分与糖代谢有关。缩合单宁组和对照组相比,大部分标志性代谢物与蛋白代谢、能量代谢有关。富集分析这些营养物质代谢的改变可以是与一些代谢通路相关,菜粕组:花生四烯酸代谢,亚油酸代谢,甘油磷脂代谢,半乳糖代谢,氨酰-tRNA生物合成,半胱氨酸和甲硫氨酸代谢,嘌呤代谢,氧化磷酸化,β-丙氨酸代谢,肌醇磷酸代谢,mTOR信号通路和柠檬酸循环(TCA循环)。单宁组:花生四烯酸代谢,半胱氨酸和蛋氨酸代谢,神经活性配体-受体相互作用,亚油酸代谢,甘油磷脂代谢,氨酰基-tRNA生物合成,柠檬酸循环(TCA循环),mTOR信号通路,β-丙氨酸代谢,牛磺酸和次牛磺酸代谢,半乳糖代谢,精氨酸生物合成。通过标志代谢物和差异菌种对鱼体的影响发现,5%菜粕使用可以提高厚壁菌门的相对丰度,从而促进胆汁酸代谢,降低脂质沉积,25%菜粕会造成脂质代谢,蛋白代谢异常,造成机体内环境紊乱,病原菌入侵,影响机体健康。0.062%的缩合单宁添加可以提高肠道有益菌丰度,维持肠道内稳态,0.31%的缩合单宁则会破坏肠道内稳态,损伤机体健康。所以,高剂量缩合单宁是菜粕增加使用量的限制因素。
{URL}: https://link.cnki.net/doi/10.27314/d.cnki.gsscu.2023.000588
{DOI}: 10.27314/d.cnki.gsscu.2023.000588
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向问题解决能力培养的“三步转译”编程教学法的应用研究
{Author}: 田君慧子
{Tertiary Author}: 柳栋;潘以锋
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 三步转译;编程的本质;编程教学法;问题解决能力
{Abstract}: 近年来,编程教育受到了广泛关注,新的《义务教育信息科技》明确指出要提升学生问题解决的能力,在编程教学的研究中,针对落实学科素养培养上的面向编程教与学方向的教学方法比较缺乏。因此,本研究从当前有关编程教育现状与问题出发,从原有注重语句与参数的教学方法有所突破,从信息科技的本质、从编程的本质来探索一种较为适切的编程教学法并将其应用于教学活动。
本研究主要包括六个阶段:第一阶段,通过研究背景和文献梳理,提出了构建三步转译教学法的设想,产生了研究问题;第二阶段,通过理论分析,设计研究了三步转译教学法的教学样式;第三阶段,通过问卷调查等方式收集前期数据,设计三步转译法的教学活动;第四阶段,通过两轮的行动研究将三步转译教学法应用于编程教学课堂;第五阶段,记录和分析教学实践中的数据;第六阶段,对本研究进行总结与展望。最后研究结果表明,说明该教学法能够在教学中运用,并在一定程度上提升学生的问题解决能力。
本研究对准信息科技学科基本方法的学与教这个方向,力求细化和落实学科素养的具体培养上,为以后的编程教学活动的开展提供一定的参考;希望通过本次的设计与实践研究,可以为我国编程教学方法的研究提供新的思路和方向。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2023.001164
{DOI}: 10.27312/d.cnki.gshsu.2023.001164
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本分类在网络新闻中的研究
{Author}: 胡丰麟
{Tertiary Author}: 朱立忠
{Publisher}: 沈阳理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本分类;深度学习;Mish函数;卷积神经网络;长短时记忆网络
{Abstract}: 随着互联网技术的发展,网络媒体成为了信息的主要载体,新闻作为信息的重要组成部分,如何将海量的新闻进行分类成为了一个值得去探究的问题。机器学习在文本分类领域的应用逐渐取代了传统人工分类的方法,深度学习作为机器学习的一个重要分支,在处理海量的信息时,深度学习的性能要优于非深度的传统机器学习方法,因此如何通过深度学习高效地完成网络新闻的分类任务,对自动文本分类技术的发展有着重要意义。本文使用卷积神经网络(Convolutional Neural Networks,CNN)和长短时记忆网络(Long Short Term Memory,LSTM)相结合的混合模型对网络新闻文本进行分类,并对卷积神经网络的结构和激活函数进行改进,以提高模型在网络新闻分类任务中的准确率。所做的主要工作如下:(1)概述了文本分类技术在自然语言处理中的应用背景及意义,并分析了当前国内外在文本分类中的研究现状和文本分类的相关技术,重点剖析了几种文本表示模型,提出了多种优化方法,为后续神经网络的训练奠定了良好的理论基础。(2)针对传统的CNN在文本分类任务中出现训练速度慢和准确率较低的问题,本文提出了将卷积层和BN层融合的方法来减少神经网络层数,并将激活函数替换为更加平滑的Mish函数,使神经网络能够获得更多的信息,以提高分类的效率和准确率。通过对比实验,证明了使用Mish函数的模型在文本分类任务中的效果更优。(3)针对原始神经网络模型在特征提取时出现信息丢失的问题,提出了一种将CNN和LSTM相结合的网络模型,该模型结合了CNN提取文本局部特征和LSTM挖掘文本更深层语义关系的两种优点,并利用Word2vec将网络新闻文本转换成词向量,输入到结合后的神经网络中训练,将训练得到的特征向量输入全连接层中进行融合,通过Softmax函数进行分类,最后设计出分类系统的可视化界面。经过实验证明,改进后的深度学习模型在网络新闻分类任务中有着更好的分类效果,准确率达到了94.04%。
{URL}: https://link.cnki.net/doi/10.27323/d.cnki.gsgyc.2023.000018
{DOI}: 10.27323/d.cnki.gsgyc.2023.000018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于POI数据和Doc2Vec模型的城市功能区识别研究
{Author}: 陈鑫美
{Tertiary Author}: 王勇
{Publisher}: 中国测绘科学研究院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: POI;Doc2Vec;LDA;城市功能区;地理语义挖掘
{Abstract}: 我国城市化水平不断提高,城市发展进入城市更新的重要时期,精细化空间“存量挖掘”是城市发展的新趋势,厘清城市功能区布局对加强存量利用和优化城市产业结构具有重要作用。随着大数据时代的到来,新兴数据类型不断涌现,其中,兴趣点(point of interest,POI)是一种代表地理实体的点状空间数据,具有体量大、精度高和时效性强等特点。同时,结合新兴自然语言处理深度学习模型能够充分挖掘空间大数据的语义信息。因此,本文基于POI数据和路网数据,构建面向城市功能区定量分析的地理语义特征提取、城市功能区识别、精度比较与评价的研究框架,并进行验证分析,本文主要研究工作如下:首先,对POI数据、路网数据进行数据预处理以及数据清洗。针对POI数据充分考虑其空间位置关联信息,构建顺序序列;针对路网数据利用形态学图像分割技术提取道路中线;针对基本研究单元,比较格网和路网划分方式及其相对应的三种尺度下的研究单元中POI相关指标,选择最佳研究单元。其次,结合自然语言处理模型提取研究单元和POI类的潜在语义特征,将POI类看作文本中的词汇、POI序列为句子、研究单元为文档,构建训练词向量和段落向量的语料库。通过训练词向量和段落向量获得可表征空间分布的高维语义特征向量,同时利用训练所得的词向量比较POI类之间的功能相似性。然后,利用K-means算法对训练所得段落向量聚类,并基于LDA模型对聚类结果(城市功能区识别结果)进行主题提取,结合富集因子对功能区进行标注。最后,使用随机森林分类器对TF-IDF、Word2Vec和Doc2Vec等模型进行精度评价。结果表明,借鉴新兴自然语言处理模型,能够有效地提取城市基本研究单元的潜在语义特征并识别城市功能区,模型中训练的POI类向量可计算各类之间的功能相似性,且Doc2Vec模型在城市功能区识别中的应用明显优于TF-IDF和Word2Vec模型。本研究能够动态监测城市空间发展并为城市规划提供参考,同时为城市空间中的POI类别划分提供新的思路和方法。
{URL}: https://link.cnki.net/doi/10.27481/d.cnki.gzcky.2023.000009
{DOI}: 10.27481/d.cnki.gzcky.2023.000009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多形态因果关系抽取及因果知识图谱构建
{Author}: 周浩
{Tertiary Author}: 兰曼
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 信息抽取;因果关系抽取;知识图谱;深度学习;提示学习
{Abstract}: 科学研究的一个基本目标就是了解事物之间的因果关系,探索现象背后的本质和事物发展的基本规律。然而,现有的人工智能研究方法更多的是从单纯数据关联的角度而非因果推理的角度出发的。为了更好地了解因果关系并推动因果推理的发展,最重要的一步便是从现实世界的各类数据中抽取因果信息。因此,本文主要是探究自然语言文本中的多形态因果关系抽取、篇章级事件因果关系识别和推理,并最终构建一个涵盖多个领域的因果知识图谱。首先,本文主要研究多形态因果关系抽取,包含句内因果关系抽取和句间因果关系识别两个任务。针对于句内因果关系抽取任务,本文采用流水线式的方法:先抽取句子中的所有名词性词或词组(Nominals),然后再通过句中因果信号词的语义信息来识别具有因果关系的Nominals对。这种方法避免了现有工作中直接采用序列标注方法所存在的因果嵌套问题。针对于句间因果关系识别任务,由于缺少因果信号词,隐式因果关系识别性能较差。本文采用提示学习的思想,将句间因果关系识别任务改造成更靠近大规模语言模型预训练任务的形式,以此来充分挖掘大规模预训练语言模型中所蕴含的常识知识,有效提升模型在隐式因果关系识别任务上的性能。其次,本文将研究篇章级事件因果关系识别,主要包括句子内和跨句子的事件因果关系识别。针对于现有研究工作中标注数据不足的问题,本文提出融入外部知识库中的常识知识的方法,将与事件相关的常识知识融入到事件的编码表示中,以此来帮助模型识别事件间的因果关系。与此同时,在跨句子事件因果关系识别任务中,由于句子跨度较大、上下文信息复杂繁多,导致模型无法有效进行因果关系识别的问题。本文通过上一章的句间因果关系识别研究过滤掉了大量的负样本对,从而提升了模型识别的准确率。在篇章级事件因果关系识别的基础上,本文进一步探索事件因果关系推理,尝试在给定上下文及原因(或结果)事件的前提下,推理出其对应的结果(或原因)事件是什么。最后,本文利用上述研究方法,在足球领域新闻、金融领域新闻和医疗领域诊断报告等文本数据上进行因果关系抽取。然后利用图数据库Neo4j来构建一个多领域因果知识图谱,并在对应领域上探索因果知识图谱的应用。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000915
{DOI}: 10.27149/d.cnki.ghdsu.2023.000915
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练-微调的多模态任务型对话语义理解与生成方法研究
{Author}: 马志远
{Tertiary Author}: 李剑军
{Publisher}: 华中科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 多模态任务型对话;模态对齐;知识推理;预训练-微调;图文回复
{Abstract}: 近年来,随着多媒体设备的普及,面向多模态场景的任务型对话系统有了越来越广阔的应用前景。预训练-微调作为一种有效的参数迁移方法,能够在几乎无需标注的大规模图像-文本数据集上进行多模态的自监督表征学习,从而为下游多模态任务提供表征嵌入支持。然而,由于现有的预训练模型存在模态对齐差、视觉理解难、知识推理弱和回复质量低等诸多问题,因此不能很好地被直接迁移到下游的多模态任务型对话模型中。
针对这些问题,从纵向的角度提出了一种渐进式预训练-微调方法,即首先在大规模的图像-文本数据集上进行基于模态对齐的表征预训练,以增强预训练模型的跨模态语义嵌入能力,之后在两个子任务:视觉问答和知识型对话上分别进行微调,从而进一步增强预训练模型在视觉理解和问答、知识检索与推理两大方面的能力,最后在多模态电商对话场景上进行组合式微调,以最终提升多模态任务型对话的语义理解和回复生成性能。
首先,在基于模态对齐的视觉-语言预训练方面,现有基于掩码重建和对比学习的预训练方法普遍忽略了显式的细粒度模态对齐训练,这对下游多模态任务型对话的用户语义理解和表征迁移是不利的。为解决这一问题,提出了一种基于跨模态联想学习的视觉-语言预训练方法,能够通过跨模态的特征提示和上下文的注意力交互在一个隐式的联想映射空间中去建模不同模态之间的细粒度语义映射关系,从而增强视觉-语言预训练模型的跨模态对齐表现。在包括视觉问答、视觉推理、视觉蕴含和指示表达理解等四种下游多模态任务上的实验结果表明,所提出的联想学习方法具备细粒度的语义理解和模态对齐能力,能够为下游多模态对话中的问答、推理、辨别和理解提供有效的跨模态表征嵌入支持。
其次,在面向视觉理解的问答任务微调方面,针对现有基于视觉-语言预训练模型直接在下游多模态对话和问答任务上微调存在的上、下游任务不兼容和语言偏置的问题,提出了融入人类先验的混合提示微调策略。该策略通过构建类似于上游的掩码建模式的完型填空模版去进行提示微调,可以有效地缓解上、下游任务不兼容的问题,并且通过可训练的提示槽可以引导模型进行有效的视觉理解和问答,以缓解多模态问答中的语言偏置难题。实验结果表明,引入人类先验的混合提示微调策略能够较好地提升预训练模型的视觉理解和多模态问答能力。
接着,在面向知识推理的任务型对话微调方面,针对视觉-语言预训练模型和当前的任务型对话方法存在的知识检索和推理能力弱、推理过程不可解释等问题,提出了一种基于意图推理网的任务型对话方法,其先通过利用一种记忆网机制进行粗粒度的知识检索,然后利用一个意图推理模块进行细粒度的知识推理,能够大大增强对话模型的细粒度知识检索和推理能力。此外,通过设计一种新颖的意图机制和分层回复机制,能够进一步提升模型回复的鲁棒性和可靠性,最终提升用户的对话体验。实验结果表明,引入外部知识推理的增量式微调策略能够较好地提升对话模型的知识检索、推理以及任务型回复的能力。
最后,在面向高质量的多模态回复生成方面,针对当前解耦式的任务型对话模型存在的视觉、文本和知识嵌入不统一、回复质量差等问题,提出了一种基于统一表征框架的多模态任务型对话方法,其通过利用一个统一的多模态对话嵌入器可以将不同模态的信息嵌入到一个统一的语义空间,在此基础上,该方法通过采用一个粗粒度的图像-文本匹配任务和细粒度的单词-区域对齐任务,可以对预训练的嵌入器进行微调,从而获得更好的用户意图表征,并将其作为用户意图感知的查询向量用于知识查询。之后,通过设计一个细粒度的基于键值记忆的知识查询和推理模块,可以有效的进行实体级别的知识记忆和多模态图文回复。最后,通过组合式的微调策略可以有效的训练这个支持多模态对话语义理解及回复生成的任务型对话模型。实验结果表明,该方法能够有效提升多模态任务型对话的图文回复质量,且具备在跨模态语义理解和多模态知识推理等相关任务上的适用性。
{URL}: https://link.cnki.net/doi/10.27157/d.cnki.ghzku.2023.001054
{DOI}: 10.27157/d.cnki.ghzku.2023.001054
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合事件和立场分析的虚假信息检测研究
{Author}: 谢冬冬
{Tertiary Author}: 姬东鸿
{Publisher}: 武汉大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 事件分析;谣言检测;虚假新闻检测;篇章事件抽取;事件语篇指代消解
{Abstract}: 在互联网高度发达的今天,社交媒体已经成为人们获取信息和交流情感的主要渠道。社交媒体的发展给人们的日常生活和交流带来了极大的便利,但也给虚假信息的滋长和传播提供了媒介。互联网中常见的虚假信息包括虚假新闻、谣言、误导性广告以及点击欺诈等等,其中虚假新闻和谣言是传播最广、危害最大的两种虚假信息。
为降低和防止虚假信息带来的危害,迫切需要针对互联网的虚假信息进行实时监测和分析。然而,目前的虚假信息检测仍然存在一些不足之处。首先,事件信息的作用尚未得到充分的重视。目前虚假信息的检测模型主要是提取目标文本及其相关上下文的特征,缺乏对事件信息的深度利用。其次,对立场信息的利用尚不充分。立场信息通常体现了群体认知,对虚假信息检测也有着重要作用。最后,外部新闻和社交媒体评论的信息未能充分融合。为了识别虚假信息,一方面可以利用外部新闻提供的背景及证据信息,另一方面可以利用社交媒体的评论中包含的群体知识和观点。
针对上述问题,本文开展了以下方面的研究:
第一,针对虚假信息检测对事件信息利用尚不充分的问题:本文在事件分析的基础上,提出了融合新闻事件信息的虚假新闻证实关系识别方法。该方法可以通过对新闻中的事件进行分析,获取虚假信息发生的背景及支持或不支持的证据,在此基础上判断待检测信息的可信度。具体而言,本模型通过事件编码和文本编码分别获得待测信息及相关新闻中的上下文信息和事件信息,针对新闻中可能出现的多个事件,信息融合模块基于注意力机制过滤无关事件及凸显重要事件。在公开数据集上的实验表明,本文提出的模型可有效利用文本中的事件信息提升虚假信息检测的效果。
第二,针对虚假信息检测对立场信息的利用尚不充分的问题:本文设计了基于分区过滤网络(Partition Filter Network,PFN)的谣言和立场联合检测模型,该模型可同时利用两个任务的共享特征和交互特征。此外,本文根据社交网络评论的关联关系构建了对话中的立场网络,并通过Graph Transformer利用立场网络中的群体交互特征。实验表明,该模型可有效利用社交网络评论中的立场信息,从而提升社交网络中的虚假信息检测效果。
第三,针对外部新闻和社交媒体评论的信息未能充分融合的问题:本文首先通过事件抽取和事件关系抽取构建一个针对谣言数据集的事件图谱,该图谱代表了外部新闻中的客观信息,然后通过立场网络获取社交网络中广大用户的群体知识和观点。基于所构建的事件图谱和立场网络,可实现外部客观信息和主观信息的有效融合,从而提升社交网络中虚假信息的识别效果。
第四,针对当前的篇章事件抽取缺乏全局语义信息的问题:本文通过引入指代链、最长名词短语链等篇章级信息,将句子级AMR结构扩展为篇章级的AMR结构。基于这些篇章级的语义信息,本文提出了基于文档抽象语义表示的篇章级事件抽取模型。在三个篇章事件抽取数据集上的实验表明,本模型在篇章事件抽取任务中取得了较好的效果,在远距离论元和长文档数据中的效果均强于现有模型。
第五,针对当前的事件指代研究忽视复杂事件指代的问题,本文提供了一个面向复杂事件的语篇指代标注数据集,并设计了一个面向该数据集的多粒度图网络模型,融合字、词、分句和句子等不同粒度的语义信息,识别篇章中的事件语篇回指。实验表明,本文提供的标注语料库可以用来支撑大型深度学习模型的训练,所提出的模型在该标注语料库上取得较好的性能。
本文的总体定位是采用自然语言处理技术进行虚假信息检测。围绕这个目标,本文对事件分析、立场分析以及基于事件和立场信息的虚假信息检测进行了研究。本文针对相关任务提出了新的模型和方法,对一些研究的内容进行了拓展,并通过实验验证了本文中方法的有效性。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2023.000606
{DOI}: 10.27379/d.cnki.gwhdu.2023.000606
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 区块链智能合约的民事法解释
{Author}: 方懿
{Tertiary Author}: 李宇
{Publisher}: 上海财经大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 区块链;智能合约;法律解释;数字资产;去中心化
{Abstract}: 区块链作为一个新兴的技术发展方向和产业发展领域,引起了全球科技、经济、法律和政府人士的广泛关注。同时,区块链技术的出现也为当前的法律和监管提出了新的问题。智能合约的概念早于区块链技术的诞生,但运行于区块链平台上的智能合约才能够真正发挥出其自动履行约定的功能设计。自以太坊公链诞生以来,区块链智能合约作为区块链平台在应用层面最为重要的技术手段,在社会经济生活中大放异彩,近年来在区块链网络中大热的非同质化通证(NFT)、去中心化自治组织(DAO),以及元宇宙、Web 3.0等概念,也均与区块链智能合约的应用密不可分。与上述概念的流行所不相称的是,法学研究对区块链智能合约的研究尚不成体系,现有研究成果对一些应用场景的技术原理理解不够深刻甚至存在偏差,对一些现象未能结合基础理论与实际场景进行融贯性解释,导致对区块链智能合约的研究存在碎片化和表面化的问题。本文在实际观察应用场景的基础上,深度结合技术原理,从民事法体系性解释的角度出发,试图对区块链智能合约在不同应用场景下的实践样态进行法律解释,并进而对解释结果进行总结,对规制路径进行探索。
本文第一章旨在梳理区块链智能合约的技术原理与应用场景,并在此基础上提出需要进行法律解释的核心问题。通过分析区块链的技术原理与智能合约的演化历程,以及深入观察智能合约的应用场景与实例,进而从概念梳理的角度,对名为“Contract”的不同概念进行历史溯源和比较分析,指出智能合约中的“合约”概念体现的是网络空间的契约精神与契约化自治模式,而并非法律合同在网络空间中的简单替代形态。区块链智能合约是区块链网络的基础治理手段,去中心化的区块链网络空间不借助法律规制而能够实现自主秩序,在很大程度上需要依赖于智能合约的部署与执行。正因为如此,区块链智能合约对社会经济生活的影响才不仅仅局限于合同法的领域,其对传统民事法的多个领域都提出了挑战。结合区块链智能合约的具体应用场景,后文将围绕合同法、财产法、组织法以及争议解决的不同领域与视角对其进行法律解释。
第二章着眼于区块链智能合约应用于法律合同场景下的合同法具体问题。就区块链智能合约与法律合同的关系,本文认为该问题不是简单的“是”与“否”的判断,而要根据实践来分析智能合约对法律合同的实际影响。通过观察,智能合约可以被应用于合同订立与履行的不同阶段,并且通常都包括履行阶段,因为当事人之所以引入智能合约的技术,主要目的即在于保障合同自动履行。当区块链智能合约应用于合同订立时,即产生在“要约-承诺”结构、合同要式性以及合同条款解释等方面的特殊问题,需要通过法律解释的方法,尤其是借鉴对传统电子合同的解释方法使其得到妥善应对。当区块链智能合约应用于合同履行阶段时,合同自动履行的特征使得合同债权获得了更强的履行保障、甚至更为“物权化”的效力,这是智能合约对传统法律合同最大的改变。
第三章讨论区块链智能合约应用场景下有关财产法的具体问题。针对作为区块链数字资产的数字通证,由于多数数字通证来源于区块链智能合约的创设,智能合约的技术与法律特征也直接影响数字通证所呈现的权利属性。作为新类型的网络虚拟财产,区块链数字通证在支配性和公示性上都与传统的网络虚拟财产存在本质差别,应认可区块链数字通证具有较强的对世效力,国内外的司法判例也均对此进行了不同程度上的实践认可。同时,数字通证的财产权利内容又与传统意义上的绝对权法定存在差别,其权利本身来源于智能合约的创设而非法律规定,合约代码可以对权利内容及权利行使进行自由创设,故应承认其权利内容与交易规则和传统的绝对权存在差异。最后,数字通证的真正资产价值来源于其所关联的底层资产,也即数字通证的本质是“权利凭证”,而根据底层资产的不同其“通证化”的形式也在实践中呈现出不同样态。通过区块链智能合约的创设,数字通证自身可作为数字资产,而“凭证化”正是这一类型数字资产的核心特征。
第四章主要讨论由复数智能合约构成的去中心化自治组织的组织法问题。虽然历史上有类似的“公司契约论”可提供理论依据,但去中心化自治组织的问题无法仅从合同法的角度得到全部解决,而必须通过组织法的视角对其进行解释。就内部治理来看,去中心化自治组织的治理问题与传统公司存在本质差别,其治理的核心不在于如何约束中心化管理层,而在于如何解决扁平化的治理结构所带来的低效甚至无效决策的问题。通过事先约定的决策制度与经济激励手段并通过智能合约予以具体落实,才能实现去中心化自治组织的日常运转。就外部主体资格而言,对去中心化自治组织赋予民事主体地位存在理论上的可能性与强烈的现实需求,国外已有多个立法明确对此类组织的主体地位予以认可,并借鉴传统LLC的模式赋予组织成员对外承担有限责任的特权。我国现行法上目前来看将其解释为非法人组织更为合适,但仍需一些特殊的制度设计才能与该种新类型组织体进行适配。
第五章讨论关于区块链智能合约引发的争议解决问题。虽然区块链智能合约的核心功能即实现合同的自动履行以避免出现合同违约,但这只是理想状态,而实际上如同传统合同一般,围绕区块链智能合约的争议也未必完全产生于合同违约,且智能合约在合同之外的应用也可能由于各种原因引发纠纷。随着区块链智能合约被越来越广泛地进行应用,相应的纠纷解决机制也成为了必要的配套制度。本文观察到,与之相适应的纠纷解决机制同样具有去中心化的特点,不论从争议解决主体还是具体裁决方式上,都体现出与传统的法院或仲裁等争议解决所不同的特征,其中包括匿名化的裁决主体、社区共识得出的裁决结论、博弈论与经济激励的应用,并最终同样通过智能合约执行的方式实现以上功能。去中心化的争议解决方式是适应于区块链网络的争议解决手段,有其现实性以及相应的理论基础。但同时,并非所有的与智能合约相关的争议都可以用以上方式得到解决,探索链上与链下争议解决方式的分工与衔接具有现实的必要性。
通过对区块链智能合约在不同应用场景下引发现象与问题进行民事法解释,本文试图将其尽量纳入现行民事法概念与体系中,同时也发现了若干需要由法律进一步明确的问题,以及通过主权国家法律较难进行完全规制的领域。需要认识到,区块链智能合约作为区块链网络自治的基础工具,对构建网络空间中的超国家秩序起到核心作用,也是法律对网络空间进行规制的重要介入手段,其同时作为规制对象和规制手段而存在。有鉴于此,在我国进一步推行数字化转型的大背景下,有必要深入研究有关区块链智能合约的法律问题,并由此出发探索对整个去中心化区块链网络的治理之道。
{URL}: https://link.cnki.net/doi/10.27296/d.cnki.gshcu.2023.001779
{DOI}: 10.27296/d.cnki.gshcu.2023.001779
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 开放式增温对双季籼稻籽粒蛋白质含量的影响及其机理
{Author}: 王海媛
{Tertiary Author}: 潘晓华;黄山
{Publisher}: 江西农业大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 籽粒蛋白质;全球变暖;双季稻;氮素吸收;转录组学
{Abstract}: 由于人类源温室气体的大量排放,全球表面平均温度持续上升。气候变暖对水稻产量和品质会产生重要的影响。蛋白质是稻米中最重要的营养物质。水稻籽粒蛋白质的含量不仅决定了稻米的营养品质,同时也与稻米加工、外观和蒸煮食味品质密切相关。明确对双季稻籽粒蛋白质含量对气候变暖的响应及其机理对未来全球变暖下提升稻米品质具有重要的意义。因此,本研究采用开放式增温方法,于2021～2022年在南方双季籼稻区开展了大田增温试验,以常规高产（早稻:中嘉早17;晚稻:天优华占）和优质食味（早稻:湘早籼45;晚稻:万象优华占）籼稻品种为试验材料,研究增温对双季籼稻籽粒蛋白质含量的影响及相关生理生态机制。同时,通过盆栽15N示踪试验明确了增温对双季稻氮素来源和氮肥利用效率的影响。此外,借助转录组学技术,揭示了增温影响双季稻籽粒蛋白质合成代谢的分子机制。主要研究结果如下:（1）开放式增温导致早稻和晚稻冠层日平均温度升高1.9℃和2.0℃。增温显著增加早稻有效穗数和结实率,而降低每穗粒数和粒重,对早稻产量无显著影响。增温显著降低晚稻产量（-6.3%）,主要是由于粒重显著降低。增温显著提高了早稻成熟期的氮素吸收（+9.4%）,而对晚稻成熟期氮素吸收无显著影响。（2）早稻和晚稻籽粒粗蛋白及蛋白组分含量对增温的响应一致,且常规高产和优质食味品种水稻的趋势基本一致。增温显著提高早稻和晚稻糙米（+10.0%和+7.5%）和精米（+11.1%和+7.6%）中的粗蛋白含量。增温处理下,早、晚稻糙米中清蛋白含量显著降低,球蛋白、醇溶蛋白和谷蛋白含量均呈增加趋势;精米中各蛋白组分含量均呈增加趋势。（3）15N示踪试验结果表明,增温显著提高了早稻来自于肥料和土壤的氮素吸收;提高了晚稻对土壤氮的吸收,而降低了其对肥料氮的吸收。在早稻季,增温显著提高了氮肥回收率,而降低了氮肥残留率,在晚稻季则降低了氮肥回收率,而提高了氮肥残留率。增温处理下,早稻和晚稻季的氮肥损失率均显著提高。（4）开放式增温使早稻季和晚稻季土壤温度分别提高了1.3℃和1.2℃。增温显著提高了早、晚稻两个品种抽穗期根系活力,增加了双季稻田土壤铵态氮和硝态氮含量,从而提高了水稻来自于土壤的氮素吸收。此外,增温显著影响了双季稻籽粒灌浆过程中蛋白质合成关键酶的活性。增温处理下,水稻灌浆期籽粒中蛋白酶活性呈降低趋势,谷氨酸合成酶、谷氨酰胺合成酶、谷丙转氨酶和谷草转氨酶活性均呈升高趋势,从而促进了籽粒蛋白质的合成与积累。（5）转录组学分析结果表明,增温对早稻和晚稻籽粒蛋白质合成的调控存在差异。湘早籼45和中嘉早17籽粒中由增温导致的差异表达基因（DEGs）均与“对活性氧簇的响应”、“细胞热响应”和“伴侣介导的蛋白质折叠”等功能有关。增温激活了早稻两个品种的“内质网中蛋白质的加工”通路。晚稻两个品种的DEGs功能富集差异较大,但均参与了氨基酸代谢。综上所述,在早、晚稻生长季日平均分别24.9℃和28.4℃的背景温度下,开放式增温（约2.0℃）对早稻两品种产量无显著影响,而显著降低晚稻产量。增温提高了双季籼稻籽粒粗蛋白及蛋白组分含量,且常规和优质稻品种的趋势一致。对早稻而言,一方面是因为增温加快了土壤净氮素矿化速率,提高了水稻根系活力,从而提高了水稻的氮素吸收;另一方面是由于增温提高了籽粒中蛋白质合成关键酶的活性,以及诱导了水稻热激蛋白基因表达上调,促进了籽粒蛋白质的合成与加工,从而导致蛋白质含量增加。而对于晚稻,虽然增温也提高了土壤净氮素矿化速率和水稻根系活力,但植株的氮素吸收没有显著差异。然而,增温提高了晚稻籽粒中蛋白质合成相关酶活性,促进了籽粒的氨基酸代谢,表明晚稻籽粒蛋白质含量的增加主要是因为增温促进了蛋白质的合成过程,而不是增加了氮素吸收。然而,水稻籽粒中各种蛋白组分的具体合成途径以及增温对这些途径的调控尚不清楚,需要进一步研究。
{URL}: https://link.cnki.net/doi/10.27177/d.cnki.gjxnu.2023.000021
{DOI}: 10.27177/d.cnki.gjxnu.2023.000021
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于ChatGPT微博评论文本的聊天机器人使用意愿影响因素研究
{Author}: 王汉璋
{Tertiary Author}: 马维忠
{Publisher}: 哈尔滨工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 聊天机器人;ChatGPT;文本分析;情感分析;使用意愿;结构方程
{Abstract}: 随着信息科技进入到信息量爆炸式增长的时代,对于机器学习、文本分析以及自然语言处理等技术的使用,可以让计算机“听懂”人的语言,并做到模仿人类语言与人对话,也就是聊天机器人技术。聊天机器人从人机对话系统发展而来,经历了多个阶段,直到2022年ChatGPT的推出,极大地颠覆了从业者以及用户对于其模型能力的认知。因此本次研究以ChatGPT为例探究用户使用聊天机器人意愿的影响因素,一方面可以形成聊天机器人使用意愿和行为的有关理论模型,另一方面可以为研发团队和科研人员优化聊天机器人服务和提升满意度做参考。本文整体的技术路线是首先通过爬虫获取有关ChatGPT的微博文本,再利用文本分析的方式挖掘文本的高频词、主题并做情感分析获取积极和消极情感相对充分的词,对照经典理论筛选其中部分关键词,依据关键词提出聊天机器人使用意愿的影响因素假设,并通过问卷调查实证研究的方式探究模型的有效部分。基于文本分析技术,通过爬虫获取并筛选有效文本150392条,通过利用中文分词、词频分析、LDA主题模型分析以及模型内部的共现网络分析、情感分析技术进行分析。共获取到5个主题,分别是企业技术创新、工作和教育、人机体验、科技领域进步与社会发展、金融投资五个部分。基于文本分析和情感分析的结果,分别对于五个主题内部进行分析,结合内部的关键词、共现关系以及情感高频词,参考经典理论,提取主题内部的范畴,共提取到九个指标,依此提出理论模型假设,本文正式调研量表共包含39个题项。共收集到220份问卷,去除无效和非研究对象的后共182份问卷。采用SPSS和SmartPLS3进行数据的信度分析、效度分析以及模型的路径分析、中介效应分析。本研究的结论如下:用户针对聊天机器人主要关注的点主要有企业技术创新、工作和教育、人机体验、科技领域进步与社会发展、金融投资;绩效期望、价格价值、时尚感知、服务品质对于聊天机器人使用意愿产生显著的正向影响;同样的,价格价值、时尚感知和使用意愿都对于使用行为产生显著的正向影响。并依研究结论对于聊天机器人研发的方向做出建议。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2023.003423
{DOI}: 10.27061/d.cnki.ghgdu.2023.003423
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器学习的建筑施工事故数据挖掘研究
{Author}: 胡家琦
{Tertiary Author}: 黄锐;邹柏华
{Publisher}: 中南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 安全管理;事故文本;事故致因;相关分析;防控建议;文本挖掘
{Abstract}: 随着安全信息化的普及,在建筑施工领域积累了大量的事故文本数据,但是,传统的对非结构化文本数据的处理方式多为人工处理,事故文本数据利用效率不高,并且存在主观性。为了改善建筑施工领域安全管理水平以及提升对事故文本的利用效率,充分挖掘潜藏在事故文本中潜藏的致因因素,并发现致因因素之间的相关关系,本研究以网络爬虫得到的1000份建筑施工事故报告为数据,利用大数据思维设计了基于机器学习的建筑施工事故挖掘框架与流程。
(1)首先对文本进行文本预处理,采用了词频-逆文档频率(TF-IDF)加权的词袋(Bo W)模型、均值word2vec模型以及TF-IDF加权的word2vec模型对文本进行向量化处理,并结合支持向量机(SVM)、K最近邻(KNN)、朴素贝叶斯(NB)三种机器学习算法进行事故文本的分类研究,通过评估9个模型的性能,发现SVM组合TF-IDF加权的word2vec模型能更好地对建筑施工事故文本进行文本分类。
(2)基于事故文本分类得到的结果,对分类得到的事故文本进行事故致因主题挖掘研究。以高处坠落事故与坍塌事故为例,引入潜在狄利克雷分配模型(LDA)进行主题挖掘,得到高处坠落的7项事故致因主题与坍塌事故的8项事故致因主题,发现主题模型能够较好地挖掘非结构化的事故文本中隐藏的事故致因主题要素。
(3)构建事故致因要素词共现网络,以此来分析各要素之间的相关关系。以高处坠落事故与坍塌事故为例,构建了事故致因要素共现网络,并计算了致因要素的度中心度与网络中心势,量化分析了共现网络的中心性。研究发现,建筑施工高处坠落事故与坍塌事故的网络中心势分别为10.08%与11.21%,因此,事故致因要素相对较为分散。词共现网络分析能够挖掘事故致因要素关键词的相关关系与语义关系,能够指导事故文本数据的深入分析。
图39幅,表31个,参考文献121篇
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2023.005805
{DOI}: 10.27661/d.cnki.gzhnu.2023.005805
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态数据的国土资源知识图谱构建与知识服务研究
{Author}: 程鑫
{Tertiary Author}: 张永军
{Publisher}: 武汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 国土资源知识图谱;多模态;命名实体识别;知识图谱检索与推理;知识服务原型系统
{Abstract}: 国土资源是国家发展生产、繁荣经济、促进社会进步的物质源泉。目前,国土资源数据的来源多种多样,且各具特点,如遥感土地覆盖产品时效性与时序性较好,全国国土调查成果数据更准确,国土资源相关文本的知识性强。然而,这些数据的类型各异,彼此之间独立管理,无直接关联,导致相关研究者在使用国土资源数据时难以充分发挥各种数据的优势。近年来,随着人工智能技术的发展,知识图谱技术在领域知识建模与知识推理方面表现突出,尤其在多源信息的融合方面,有助于提升领域整体知识化水平。到目前为止,在地学领域,知识图谱的研究仍然处于初级阶段,且大多数研究的重点关注如何构建知识图谱,而忽略了知识图谱与领域应用的结合。并且,地学领域知识图谱目前没有一个好的共享方式,导致其未能像当前流行的开源通用知识图谱那样被众多研究者使用,并通过使用者的反馈不断更新迭代知识图谱,提升知识图谱质量。而在遥感方面,领域知识图谱的研究更加缺乏,还未出现与国土资源这个遥感应用场景相关的较有影响力的知识图谱研究工作。针对上述问题,本文研究了基于多模态数据的国土资源知识图谱构建与知识服务原型系统构建的系列相关技术,提升了国土领域知识化水平,具体的研究内容如下:(1)国土资源本体模型构建。国土资源知识图谱本体构建对于规范国土资源知识图谱数据组织架构与国土资源知识图谱的迭代更新有着重要作用。本文主要采用了自顶向下的方式,结合具体的应用需求,人工构建了国土资源的本体模型。与注重知识广度的通用知识图谱本体模型不同的是,研究更加注重国土资源相关应用需求所涉及到的本体。虽然在本体模型的通用性上不及通用知识图谱,但是在知识的深度方面更具优势。考虑到现有国土资源数据特点、后续的迭代更新与知识服务平台建设,研究设计了具有层级结构的本体对区域进行了划分,并通过大量文献调研对抽取的国土资源知识类型进行了设计,最终构成国土资源知识图谱本体模型。(2)多模态数据国土资源知识图谱构建与知识存储。知识图谱的构建主要根据本体模型的设计从多模态数据中提取知识并组织成三元组。本文结合领域数据特点,设计了国土领域知识抽取框架,构建了包含2273640个节点,2528515条关系的可动态更新的国土资源知识图谱。对于规则数据,设计了规则映射将其可转化成同为规则型数据的知识图谱;对于文本数据,研究提出XLNet+Bi LSTM+CRF模型进行知识抽取,并通过消融实验证明该模型相较传统RNN模型精度大幅提升;对于知识图谱存储,研究采用了更易于进行数据管理的图数据库——Neo4j,并通过设计合理的索引字段将知识图谱存入图数据库,实现高效的数据检索与图计算。(3)基于知识图谱的检索与推理。地学相关领域缺乏知识图谱解决实际问题的应用。本文针对国土资源数据获取繁琐的实际问题,设计了基于知识图谱的数据获取与更新算法,它能通过语义化的方式快速获取区域国土资源数据,并且提供了一种新的数据管理与发布形式;针对土地覆盖数据集之间数据一致性差导致的区域精度无法保证的情况,研究设计了基于知识图谱的潜在异常数据推理算法,并且推理发现了全国92个一致性差的区域供数据使用者参考;针对地学领域常出现的感兴趣点(POI)的获取需求,研究结合国土资源知识图谱设计了感兴趣图节点(GNOI)快速获取算法;最后,研究尝试结合Node2vec图表示学习算法推理核心城市,省去了复杂繁琐的规则设计,并对推理出的核心城市空间分布进行了分析,以及对图表示学习算法学习到的特征进行了推测。(4)基于B/S架构的地学知识服务原型系统设计。大量研究者的使用与反馈是验证知识图谱质量,促使知识图谱迭代更新的有效方式。与其它领域不同的是,地学相关领域具有很强的可视化与可交互特点。研究将地学相关知识图谱与GIS可视化相结合,实现了一种较好的领域知识图谱共享方式。考虑到现阶段需求,本文基于B/S架构,构建了集知识图谱管理、知识图谱检索、知识问答、数据推荐、领域应用等多种功能一体的可视化知识服务原型系统。系统数据库采用了图数据库Neo4j与关系型数据库My SQL,后端主要采用了Flask的Python框架,前端采用了Vue框架,整个系统前后端分离,高度解耦,易于功能的扩展与后期维护。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2023.000459
{DOI}: 10.27379/d.cnki.gwhdu.2023.000459
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多特征提取的农业病害知识图谱构建方法研究与系统实现
{Author}: 周烨
{Tertiary Author}: 徐向英;周新法
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 农作物病害;知识图谱;关系抽取;深度学习;实体嵌入
{Abstract}: 农业生产中,作物病害一直是制约作物产量和品质的主要因素之一。近年来,部分农区由于气候等因素的影响,作物病害呈现加重趋势。目前,对作物病害的统计数据主要依靠人工进行归类、整合从而实现数据的分析和查询,这一工作不仅需要耗费大量的时间,还需要依靠专家经验进行相应的专业分析。随着大数据时代的到来,农业生产与信息技术的结合越来越紧密。农业大数据呈现几何级数的增长,加快农业智能化转型的同时,也为信息的提取和分析提供了新的方案。知识图谱技术是一种图数据库形式的知识库,通过构建农业病害知识图谱可以有效地管理作物病害数据,为农业下游任务提供便利的查询、分析等知识服务。论文基于自然语言处理,结合深度学习和神经网络算法设计了农业病害知识图谱,并在知识图谱基础上建立了农业病害检索系统,能够为农业从业者以及普通大众提供农业病害的查询服务。本文针对农业病害知识图谱构建过程中文本嵌入信息不充分和实体关系抽取不准确的问题,提出了使用深度学习模型的实体关系抽取方法,并在此基础上改进了针对中文农业文本的实体关系抽取效率。在农业文本的嵌入和实体关系数据集的构建基础上融合了多层次的农业文本特征,建立了多层次粒度的农业病害特征向量,在此特征向量的嵌入基础上进行实体关系的识别并建立了实体关系的三元组。利用农业病害三元组在neo4j图数据库上构建了农业病害知识图谱。最终基于该知识图谱,实现了一个能够查询农业相关作物病害和防治方法的智能化检索系统。本文的工作主要包括以下几个方面:(1)完成了实验数据的收集处理,通过利用python爬虫技术从维基百科等网站爬取水稻、小麦、玉米以及大豆等农作物的病害数据,将农业文本数据输入深度学习模型进行向量嵌入,嵌入之后构建三层粒度的特征提取模型来聚合文本的特征向量,将三个层次的注意力特征向量全连接作为整个文本的嵌入,发现通过这种方式的嵌入能够使农业病害语料具有更多的特征维度,极大地提高农业病害文本的实体识别精确度。(2)利用python包装器从农业科学大数据网站抽取了大量结构化数据,之后利用清洗和关键字匹配技术选取了其中大量的农业文本。将大量文本通过繁简转化,中英文过滤等操作提取了中文农业作物病害语料,对所有的农业病害文本做了分词和人工标注处理,抽取了实体和关系数据集,并为农业病害定义了七种关系类型。通过使用基于FastBert的深度学习模型实现了中文农业病害语料的实体关系抽取。通过对比发现,本文的方法在实体关系三元组的抽取精度和效率上都比现有模型有所提高。(3)设计了一个农业病害检索系统。通过自建的农业病害三元组集合在neo4j数据库上构建了作物病害领域知识图谱,并利用vue.js设计前端框架,django设计后端框架,实现了一个病害检索系统。该系统通过实体属性链接技术提取前端输入信息的关键词链接到图数据库,实现了农业病害的实体和关系以及防治方法等信息的查询,为农业从业人员提供必要的需求信息,也为后期构建农作物病害知识问答系统和智能防治推荐系统等下游应用提供支撑。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2023.002648
{DOI}: 10.27441/d.cnki.gyzdu.2023.002648
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向计算思维培养的问题解决模型设计与应用
{Author}: 韦雪梅
{Tertiary Author}: 常淑娟;马凤云
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算思维;问题解决;问题解决模型
{Abstract}: 随着社会的迅速进步以及信息技术的飞速发展,计算思维作为人类三大科学思维之一,已成为目前人才培养的焦点之一。在《普通高中信息技术课程标准(2017年版)》当中,将计算思维列为信息技术学科的核心素养之一,要求信息技术课堂培养学生计算思维,发展学生信息技术学科的核心素养。迅速发展的社会对于人才的要求越来越严格,除了基本的听说读写能力以外,还应该具备解决实际问题的计算思维能力。与此同时,简单易懂的Python程序语言也进入高中信息技术课程当中,凭借着其独特的优势与特点,在高中信息技术课程程序设计与编写模块占据重要的地位。因此,如何在高中Python课程教学当中有效培养学生计算思维,成为了当前值得深入探究的问题。本研究首先梳理了国内外已有的文献,对计算思维、问题解决、问题解决模型的相关研究现状进行了深入的分析,以此作为本研究的理论基础,在对研究对象的计算思维现状分析后,结合多个典型问题解决模型以及Python编程语言的特点,按照《普通高中信息技术课程标准(2017年版)》的指导要求,构建面向计算思维培养的问题解决模型。在研究过程中,结合研究前期的教学设计分析与准备,开展了基于问题解决模型的教学实验,采用行动研究法,通过三轮实验,在行动研究过程中发现问题解决模型的不足之处,并且采取有效的措施,不断优化问题解决模型,让其更适合高中信息技术课堂教学。最后,对实验过程中获得的计算思维前后测量量表、学生课堂自评调查问卷以及课堂观察记录所得数据处理分析,验证优化后的问题解决模型在Python课程教学当中具有较好的应用效果,可以实现高水平培养学生的计算思维的目标,帮助学生在学习过程中更好的应用计算思维解决真实问题。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2023.000476
{DOI}: 10.27280/d.cnki.gsdsu.2023.000476
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于HowNet的金融领域新闻知识库的构建研究
{Author}: 赵杰杰
{Tertiary Author}: 耿朝阳;胡永
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识库;知识抽取;HowNet;义原;金融
{Abstract}: 随着我国经济的飞速发展和科技的不断进步,各行各业对于信息和知识的需求日益增加。在各个行业中,金融领域对于信息和知识的需求更为突出。然而金融信息量迅速增长以及大量非结构化的金融公告文本的存在,给金融研究团队在信息处理和公告研读的工作中带来了困难。为了解决这一问题,金融知识库应运而生,该知识库旨在从海量文本中抽取出相关的实体、关系以及属性等信息,以帮助人们更好地了解和把握市场的发展动态和趋势。本文旨在构建一个金融领域的新闻知识库系统,以金融领域新闻为数据来源,设计并实现了知识库系统,主要研究工作如下:(1)了解构建金融领域新闻知识库所需要用到的相关技术,并针对本文需求进行系统的设计,主要可以分为四个模块:数据获取、知识抽取、事件抽取、知识存储。(2)本文提出了SAH(Skip-gram-Attention-HowNet)的词向量表示模型,在Skip-gram框架中融合了注意力机制和HowNet义原,以更好地理解词义,提高词汇学习效率。通过利用HowNet中的义原作为语义特征,将其加入Bi LSTM-CRF模型中,提出了SAHBi LSTM-CRF-HowNet模型,该模型通过使用HowNet对词进行深层次的挖掘,寻找命名实体之间的关联,经过对比实验,本方法较其他方法准确度提高了3.2%,召回率提高了2.43%,F1值提高了1.7%。(3)基于本文提出的SAH-Bi LSTM-CRF-HowNet模型构建了一个金融领域的实体关系库,这个库首先利用知识抽取技术获取实体信息,然后利用HowNet中的上下位关系和层次结构计算出每个实体的义原之间的距离,从而得出实体之间的相似度,实现了实体消歧的目标。(4)本文首先对新闻文本进行分类,定义不同类型的事件模板;然后通过事件抽取技术提取新闻事件的关键信息,构建事件的结构化描述;随后,基于(3)中构建的实体关系库,将事件的主体和关系进行关联,构建事件之间的联系;最终实现了一个完整的金融领域新闻知识库。总体而言,本文提出了基于HowNet的金融领域新闻知识库的构建方案,并通过Python开发应用平台,实现了知识库的整合、展示和搜索功能,为用户提供快速获取所需信息的服务。经过系统功能实现和测试,完成了金融领域新闻知识库的构建。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000751
{DOI}: 10.27391/d.cnki.gxagu.2023.000751
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图神经网络的漏洞检测技术研究
{Author}: 薛阳
{Tertiary Author}: 郭军军
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 漏洞检测;图神经网络;融合特征;深度学习
{Abstract}: 随着生产力水平的发展,人们对于软件功能的需求不断增加,导致软件的体系结构也随之变得复杂,无形之中提高了软件中可能存在安全缺陷的概率。此外,代码复用也会给漏洞的传播提供可乘之机。一旦这些安全漏洞被不法分子所利用,所造成的损失不可估量。因此,如何保证软件安全成为人们亟待解决的问题。随着深度学习技术在图像领域以及自然语言处理领域获得了巨大的成功,大量的信息安全研究人员也开始使用深度学习的方法来进行漏洞检测。然而,目前基于深度学习的漏洞检测方法大多使用单个图来进行源代码表征,并没有完整的保留源代码中所有的语法、语义、控制流等信息,导致在代码表征过程中出现信息丢失的现象。此外在进行特征学习时单纯的将漏洞特征输入到深度学习模型当中,并没有考虑到其中与漏洞关联度较低的特征,将会对模型的性能产生影响。针对上述问题,本文提出了基于图神经网络的漏洞智能检测方法,具体的研究内容如下:(1)由于目前信息安全领域内缺乏大规模、有效的源代码数据集,本研究利用爬虫程序从NVD、Github等网站收集数据样本。首先从漏洞公开披露网站获取含有漏洞的源代码文件;其次利用人工的方式来对含有错误信息的样本数据进行修改,从而得到一个含有49736个样本的漏洞数据库;最后通过代码切片、抽象语法树提取、控制流图提取等操作分别得到源代码对应的抽象语法树以及控制流图,将其作为后续模型训练与测试的样本数据。(2)针对漏洞检测模型,使用了基于注意力机制的消息传递网络模型来进行漏洞检测。首先将源代码视为文本序列,通过token-focused方法来进行代码图特征的构建,并使用PL(Programming Language)模型中的预训练模块来进行节点的初始化。在特征学习过程中,通过使用通道空间注意力机制将输入的特征分别进行平均池化和最大池化操作,对于漏洞相关的特征赋予更高的权重,提升模型对于漏洞相关节点信息的敏感度,从而使得模型性能得到有效提升。实验结果表明,该模型的漏洞检测精度优于其他基于的自然语言处理的深度学习模型。(3)针对目前代码表征过程中出现的信息缺失、信息不丰富问题,本文提出了源代码表征方法Multi-Graph Fusion,使用抽象语法树以及控制流图来进行代码表征。并且使用了MGFN(Multi-Graph Fusion Network)模型,分别对两个特征向量进行提取。在特征融合方面,考虑到抽象语法树和控制流图对于漏洞检测结果的不同影响,为了更好的融合两种尺度的特征,本文使用了基于注意力机制的注意力特征融合(Attentional Feature Fusion,AFF)。该方法分别将两个向量输入到MS-CAM模块中,通过两个通道来进行局部和全局的特征融合,利用sigmod激活函数获得不同特征的权值,并利用该权重对于输入的两个向量进行加权平均,从而得到最终的融合特征。综合以上内容,本文利用所提出的基于图神经网络的漏洞检测模型在所构建的数据集上进行对比实验。实验结果表明,与现有的模型相比,该模型在此数据集上的精确率提高了13%;召回率至少提高了11%;F1分数则提高了10%。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000055
{DOI}: 10.27391/d.cnki.gxagu.2023.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图神经网络的多标签文本分类算法研究
{Author}: 王兵
{Tertiary Author}: 李熙铭
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多标签文本分类;图神经网络;对比学习;图数据增强
{Abstract}: 随着人工智能和大数据技术的广泛应用,在庞大的用户数据中检索有用的信息是研究者和技术人员十分关注的话题。文本分类是信息检索社区的基础任务,即对互联网中的非结构化文本内容进行自动化地分类,例如对新闻的主题进行分类,对用户的情感分类等。如今,大部分的文本分类技术都已开始采用基于反向传播的深度神经网络,相比于传统的基于人工构建特征的机器学习方法,深度神经网络能够捕获到更加具有判别性的文本特征。在现存的深度文本分类方法中,有一种基于图神经网络的方法由于其优越的表现得到了广泛的关注。具体地,基于图结构的文本分类方法首先将文本内容转化为图结构的形式,再使用特定的图神经网络进行图上的特征编码,最后进行特征的分类。这种方法无疑可以更有效地考虑到文本中的单词之间的依存关系。然而,通过分析前人提出的大量文本分类的方法,本文认为这些方法依然存在着一些问题。第一,文本分类任务基本可以被分为单标签文本分类任务和多标签文本分类任务,他们的区别在于文本的真实标签是一个还是多个。前者的大部分工作都只将考虑文本内容信息,而忽略了标签本身包含的特征。而后者的相关工作虽然考虑了标签的信息,但他们将文本和标签进行分别的编码,最后将二者的特征拼接分类,这种简单的特征拼接的方式无疑忽略了文本和标签之间的相关性;第二,现有的文本分类方法都仅使用一个监督的交叉熵损失作为其目标函数,进行深度模型的训练,但单一的监督目标函数不足以使文本特征具有判别性和鲁棒性。为了解决以上提出的两个问题,本文提出了一种新的模型,被称为基于对比学习的文本图网络模型(Text-level Graph Networks with Contrastive Learning,TGNCL),它针对以上的问题的解决办法是:(1)本文结合二者的优点,提出了一种基于图的方法,不仅对预定义的标签构建图,还构建了文本图,并将二者合并成同一个异构图结构。这种方法不仅考虑了标签蕴含的信息,还通过异构图的形式考虑了文本和标签之间的相关性。另外,在此异构图的基础上,本文也提出了一个基于移动平均的图注意力神经网络,使得图神经网络中边的权重能进行动态地、合理地更新。(2)本文在原有的目标函数中增加了一个图对比学习正则项,希望不同类的样本能够远离,从而使特征更具判别性。而且,图对比学习十分依赖于图结构的数据增强,对这些增强的图数据进行监督学习也达到了对训练样本进行扩充的目的。最后,本文也在多标签和单标签文本分类任务的4个公开数据集,如AAPD和Reuters-21578数据集上验证了本文提出的TGNCL模型的准确性。实验结果表明TGNCL模型在大部分的数据集和实验设定下都超过了被对比的基线方法。且本文也进行了敏感性分析和收敛性分析,找到了模型最佳的超参数组合,以及收敛的迭代数。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.005218
{DOI}: 10.27162/d.cnki.gjlin.2023.005218
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的实体关系联合抽取方法研究与系统实现
{Author}: 何怀前
{Tertiary Author}: 常姗
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 联合抽取;注意力机制;依存句法分析;数字图书馆
{Abstract}: 实体关系联合抽取旨在从非结构化的文本中自动抽取结构化的三元组,对实现知识图谱构建、语义问答具有重要意义。然而,现有的联合抽取模型主要解决实体重叠和关系重叠问题,忽略了实体识别带来的误差传播,导致对错误的实体对进行关系抽取,降低实体关系抽取的精度。此外,现有的模型忽视了文本中词的词性特征和依存关系特征的重要性。针对上述问题,本文提出了词性注意力机制和融合先验知识的实体关系分类器,提高了实体关系抽取的精度。本文的主要研究工作如下:(1)为解决实体识别引起的误差传播,基于句子中词的词性和依存关系特征,提出词性注意力机制。首先,在词表征中融入词性信息,对预训练语言模型得到的词表征进行优化。然后,在实体分类器和关系分类器中增加词性、依存关系和实体长度等先验知识。在公开数据集上的实验结果表明,融合词性等先验知识的实体关系分类器能显著提高分类精度,与词性注意力机制模块协同合作可以提高模型的实体关系抽取精度。(2)为解决联合抽取模型中存在的实体重叠和关系重叠问题,本文采用片段标注策略,基于预训练模型得到的词表征,设计实体和关系分类器。在实体分类器中,通过枚举所有的候选实体片段解决实体嵌套问题。在关系分类器中,通过枚举所有的候选实体对,预测实体对之间的关系,解决实体重叠和关系重叠的问题。(3)设计并实现了大学数字图书馆系统。将文本三元组抽取方法应用于大学课本的实体关系抽取,实现自动化抽取三元组。基于得到的三元组实现知识图谱构建、知识检索、关系检索和语义问答等功能,解决了实际教育场景下课程内容多、知识点关系复杂的问题,提高学习者的学习效率。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.000461
{DOI}: 10.27012/d.cnki.gdhuu.2023.000461
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的领域知识图谱构建关键技术研究
{Author}: 王鹏翔
{Tertiary Author}: 黄岚
{Publisher}: 长江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;自然语言处理;关系抽取;知识图谱;大豆病虫害
{Abstract}: 在中国,大豆的种植和生长过程中会受到多达30多种疾病和大约100种害虫的威胁,造成重大经济损失。大豆病虫害防治专业知识大多存在于专业书籍和科技论文等文献资源中,实际田间作业时,农民无法便利地获得最新的专业知识,信息利用效率低。如何利用计算机技术,辅助农民实时获取相关信息,成为日益突出的需求。针对上述信息鸿沟问题,本文提出用自然语言处理技术,自动从领域文献资源中提取专业知识,对其进行清洗、梳理、整合,构建领域知识图谱,并以此为基础,提供面向田间作业的知识检索服务。主要内容归纳如下:(1)信息来源筛选及标注数据集。针对领域数据集缺乏的问题,本文选择《大豆病虫害原色图谱》一书作为数据来源自建实体及关系数据集。参照前人研究和书中表述,将大豆相关实体之间的关系分为5大类,分别是为害部位、发病症状、防治手段、形态特征和其他,并参照面向开放领域的基准数据集的标注格式对本文自建数据集进行人工标注。(2)领域实体关系抽取方法研究。本研究分别以管道结构和联合学习结构为基础架构,实现了两种关系抽取模型,并以开放领域基准数据集和领域数据集为基础进行了对比分析、消融实验。以管道结构为基础,实现了基于CNN、PCNN、BERT的关系抽取模型。实验结果表明,在大豆病虫害领域文本上,BERT模型的效果优于CNN和PCNN,F1值达到0.9849。以联合学习结构为基础,对实体识别和关系识别任务统一建模,利用两个任务间的关联信息减少错误累积,实现了SPNet关系抽取模型。然而,领域知识中的数据稀疏特性严重影响了联合关系抽取模型的性能。针对数据稀疏问题,引入数据增强方法,有效提升了联合实体关系抽取模型的准确性。比较两类学习结构和模型,管道结构模型可用于构建初始知识图谱,能准确识别已标注实体间的实体关系,而联合学习结构可同时识别实体和关系,可用于拓展知识图谱,但需要注意数据稀疏性的负面影响。(3)领域知识图谱构建方法研究。在关系抽取任务基础上,使用Neo4j知识图谱构建工具搭建领域知识图谱,使用Cypher语言处理数据并搭建领域知识图谱,并搭建基于Web的知识图谱检索服务。本课题以大豆病虫害为样本领域,研究领域知识图谱的构建方法及关键问题。以深度学习为技术框架,在调研现有基准数据集、主流方法和模型的基础上,研究了面向领域文本的实体关系抽取和面向知识图谱的实体关系存储、表示和检索等知识图谱构建过程中的关键问题,实现了动态、个性化的大豆病虫害防治知识检索,强化理论知识和田间的衔接,高效助力实现精准农业。
{URL}: https://link.cnki.net/doi/10.26981/d.cnki.gjhsc.2023.000656
{DOI}: 10.26981/d.cnki.gjhsc.2023.000656
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 变电站一次设备故障知识图谱构建方法研究
{Author}: 杨帅松
{Tertiary Author}: 郭树强
{Publisher}: 东北电力大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;实体识别;关系抽取;故障处理
{Abstract}: 随着特高压电网和新能源的快速发展,变电站一次设备故障处理任务要求工作人员具备更高的业务能力。但目前该任务主要依赖员工的知识储备和长期经验积累,需要反复记忆和查询大量文本形式的知识。由于缺乏高效精准的电力领域知识抽取、组织与管理技术,存在故障处置的精准性和规范性难以得到保证的问题。针对该问题,提出了变电站一次设备故障知识图谱构建方法。该方法以一次设备故障处理相关资料为研究对象,通过自然语言处理、深度学习等技术对故障语料中蕴含的实体及关系进行识别与抽取,进而构建变电站一次设备故障知识图谱。该图谱包含了一次设备拓扑关系、设备故障数据、故障处理方法等信息,通过对这些信息的整合和归纳,可为工程师提供全面准确的故障诊断和处理方案。该研究面向三个问题:(1)如何从非结构化的一次设备故障文本中提取专业词汇,并构建包含嵌入信息的领域词典?(2)如何从一次设备故障文本中自动准确地识别电力实体片段及类型,以将其作为知识图谱的节点?(3)如何对实体间的关系进行抽取,并构建变电站一次设备故障知识图谱?针对这三个问题,开展了以下三个研究内容:(1)对一次设备故障语料进行文本清洗后,利用N-Gram模型、信息熵和互信息对专业词汇进行挖掘,并利用词嵌入模型训练得到领域嵌入词典;(2)根据实体识别思想提出BERT-FLAT-CRF模型,通过结合领域嵌入词典信息和引入相对位置编码,实现对一次设备故障文本中实体及类型的识别。(3)在完成实体识别任务的基础上,提出基于BiLSTM-ATT的故障知识图谱构建方法,实现变电站一次设备故障知识图谱的构建。采用一次设备故障维修手册、故障排除问答等相关语料为实验数据,对整体研究方法进行有效性验证。在构建一次设备领域嵌入词典后,利用BERT-FLAT-CRF模型结合词典信息对实体进行识别,并开展对比实验。实验结果表明,该模型对于一次设备故障语料中的实体识别效果最优,精确率、召回率和F1值分别达到了86.2%、81.11%和83.58%。然后,利用BiLSTM-ATT模型对实体间关系进行抽取,并与其他三种模型进行对比实验。实验结果显示,该模型在一次设备领域语料的关系抽取任务中,各项指标均优于其他模型。因此,该模型能够自动准确地提取实体之间的关系,从而构建变电站一次设备故障知识图谱。
{URL}: https://link.cnki.net/doi/10.27008/d.cnki.gdbdc.2023.000161
{DOI}: 10.27008/d.cnki.gdbdc.2023.000161
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于特征融合与数据增强的古汉语命名实体识别研究
{Author}: 李靖
{Tertiary Author}: 徐昊
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;古汉语命名实体识别;特征融合;数据增强
{Abstract}: 古汉语命名实体识别作为古汉语自然语言处理研究的重点领域之一,其主要作用是从历史古籍中提取出人名实体、地点实体、机构实体、官职实体或其他类型的实体。作为古汉语自然语言处理中一项基础任务,古汉语命名实体识别在古汉语信息抽取和古汉语知识图谱构建等古汉语自然语言处理任务中承担着重要的角色。近年来,古汉语命名实体识别发展迅速,但该领域仍然存在以下问题:(1)现有的方法多数利用单一层次的特征,没有同时考虑到字结构特征与字-词特征,难以获取足够的字结构信息与词汇信息。(2)汉字读音也包含一定的语义信息,现有的方法没有充分利用到字读音特征。(3)古汉语命名实体识别数据集较为稀缺,数据标注成本高昂,导致深度学习算法在这一领域的性能受限。针对以上问题,本文对古汉语命名实体识别中的特征融合机制和数据增强方法展开研究,旨在提升模型性能并降低该领域数据标注工作量。本文主要研究工作及贡献如下:(1)针对现有的古汉语命名实体识别方法中大多只利用单一层次的特征这一问题,本文提出了融合字结构特征与字-词特征的特征融合模型(SLFFN)。该模型通过融合字-词特征与汉字的字结构特征来同时获取词汇信息与字结构信息,从而提升模型实体识别性能。实验结果表明SLFFN在公开数据集C-CLUE上的效果优于基线模型。(2)针对现有的古汉语命名实体识别方法忽略了字读音特征这一问题,本文在SLFFN基础上进一步融合了字读音特征,提出了融合多特征的特征融合模型(MFFN)。该模型通过将字-词特征分别同字结构特征与字读音特征进行融合,使得模型具备同时获取字-词信息、字结构信息与字读音信息的能力。为了进一步验证模型的有效性,本文构建了两个古汉语实体识别数据集,并在这两个数据集和C-CLUE数据集进行了实验。实验结果表明SLFFN与MFFN在这三个数据集上的效果均优于基线模型,并且MFFN的效果优于SLFFN。(3)针对古汉语实体识别数据集标注成本高昂这一问题,本文提出了两种用于生成新数据供模型训练的数据增强方法,分别是随机实体替换法和随机句子生成法。随机实体替换法通过替换数据中相同类型的实体,来生成包含新实体的数据。随机句子生成法通过交换相邻句子的前后子句来生成新的句子。实验结果显示本文提出的两种数据增强方法可以提升模型实体识别效果,并可以减少数据标注的工作量。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.002195
{DOI}: 10.27162/d.cnki.gjlin.2023.002195
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人格特征的个性化学习内容推荐研究
{Author}: 杨梓涵
{Tertiary Author}: 徐昊
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 学习推荐系统;推荐系统;人格特征;自然语言处理;学习者模型
{Abstract}: 近年来随着教育信息化的普及,学习者的学习方式逐渐由线下课堂转为在线学习,鉴于互联网的海量学习资源,学习者在学习过程中容易出现信息过载问题。对于在线学习的学习者来说,信息过载问题会因其大量的冗余信息干扰学习者对其所需的学习资源的精准选择,从而影响学习者在线学习的效果。因此,为学习者推荐所需的学习资源,提高学习者学习效率的个性化学习推荐系统应运而生。在目前的在线学习过程中,往往只关注于学习者与学习资源间的联系,而学习者与在线学习推荐系统产生的交互信息中蕴含着丰富的心理学特征,如人格特征等,大量主观的心理学信息往往会被忽略。将心理学特征与个性化学习推荐系统结合,形成“心理学+教育”的在线学习方式,是未来学习推荐系统的重要研究方向。利用学习者人格特征为其设置个性化参数,推荐更符合学习者心理预期的学习资源,是目前个性化学习推荐系统所欠缺的。本文为解决这一问题,以在线学习网站的学习者和学习资源为例,整合了丰富多样的在线教育数据,通过抽取学习者特征,以其人格特征为核心特征完成学习者建模和学习对象建模,并基于学习者和学习对象模型设计学习推荐算法模型进行在线学习推荐。本文充分利用了学习者蕴藏的丰富心理学信息为其进行学习推荐,使学习推荐系统更加个性化,实现了在线教育资源与学习者心理学信息的整合和学习内容的推荐。本文的工作主要包含以下几点:1.本文以捕获学习者蕴藏的心理学大五人格特征为出发点,针对学习者建模,首先抽取了在线学习的学习者多元特征,进行了数据预处理、文本词嵌入和PANDORA模型训练,构建了以大五人格特征为核心特征,其余特征为辅助特征的学习者模型。2.针对学习对象建模,抽取了在线学习资源的多元特征,经数据分析设计了一种基于自注意力机制的BERT文本词嵌入方式,并设计了自编码/解码器,用于对学习对象特征的进一步抽取,最后对其核心特征进行了映射处理,构建了以大五人格特征为核心特征,其余特征为辅助特征的学习对象模型。3.针对学习内容推荐算法,本文设计了基于大五人格特征的Pan-BF-PMF算法模型,其充分利用了学习者蕴藏的心理学大五人格特征,经实验证明,在为学习者推荐学习内容方面性能优异。基于该模型的全面特征考量,优化设计了PanBF-PMF+算法模型,本文在真实数据集上进行了实验探究,并设计与基线模型的对比实验,实验结果证明了其对于学习内容推荐的优越性能。最后探究了本文设计的驱动参数对实验结果的影响。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.002324
{DOI}: 10.27162/d.cnki.gjlin.2023.002324
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多任务学习的多模态情感、情绪和讽刺联合分析
{Author}: 俞洋
{Tertiary Author}: 张亚洲
{Publisher}: 郑州轻工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;多模态情感分析;多任务学习
{Abstract}: 近年来,基于多任务学习的多情感联合分析已成为自然语言处理和人工智能领域的重要研究课题,旨在通过结合多模态信息和相关任务的共享知识来识别话语所表达的多个情感的类别。情感分析、情绪识别和讽刺检测是情感计算领域中三个密切相关的任务,本文以情感分析、情绪识别和讽刺检测为研究对象,并结合当前所面临的挑战对这三个任务进行研究。具体工作包括以下三个方面:(1)针对当前中文多任务学习模型发展受到数据集限制,本文建立一个中文多任务多模态对话感情语料集来支持多任务多模态情感分析的发展。该数据集同时标注了多个任务标签(如情感、情绪、讽刺和幽默等),并首次人工标注了情感和情绪、讽刺和幽默的相关性。经过科学评估分析,表明该数据集具备高质量和代表性。(2)根据所构建的数据集,本文主要从上下文交互、多模态特征融合和多任务学习这三个方面来考虑,提出一种基于多任务学习的多模态情感分析模型。通过实验评估,证明该模型的有效性。(3)针对(2)所提出的模型未能考虑到多任务之间的相互关联,本文提出了一种基于软参数共享的多任务学习模型来学习不同任务之间的共性和差异。通过对比其他先进的基线的实验结果,证明了该方法提出的先进性和高效性。
{URL}: https://link.cnki.net/doi/10.27469/d.cnki.gzzqc.2023.000045
{DOI}: 10.27469/d.cnki.gzzqc.2023.000045
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 数据库通用动态查询工具的设计与实现
{Author}: 涂文奇
{Tertiary Author}: 李柏岩
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 数据库查询检索;通用查询;数据字典;NL2SQL方法
{Abstract}: 随着科学技术的发展,人类的生产、生活活动产生大量有用的数字化数据信息,这些数据主要存储在各种数据库中。其中,关系型数据库是一种主流的数据库,很多企业、机构都将关键业务信息存储在关系数据库中。要利用这些数据,需要根据需求对数据进行查询检索。传统的关系型数据库主要通过结构化查询语言(SQL)进行查询,但SQL语句对非专业人员来说不够友好,而功能固定的信息应用系统用户接口很难满足企业用户不断变化的数据查询需求。为满足企业用户实际数据查询需求,本文设计了一种通用的关系型数据库动态查询工具,该工具允许用户根据不同需求自定义查询语句,又支持采用自然语言交互查询方式灵活查询数据库。论文主要工作内容及贡献如下:(1)提出了一种自定义SQL查询语句的方法。该方法包括解析数据表Schema获取表信息、使用表信息构建数据字典以及基于数据字典自定义查询语句三个步骤。通过查询数据库管理系统提供的包含列信息的元数据视图,获得数据表的表结构,如表名、列名、数据类型以及是否为空等内容,并构造用于描述数据库结构的数据字典,再使用数据字典定义查询语句。这种方法可以构建包括分组、排序连表查询等多种SQL查询语句。(2)提出了一种基于自然语言理解生成SQL查询语句的方法,实现了中文单表自然语言问句到简单SQL查询语句的自动转换。该方法基于现有的M-SQL多任务学习模型,融合了知识图谱字段和别名实体关系来修正模型预测的表名和投影字段,同时还使用数据分量和别名实体关系来构建候选条件子句集合,通过筛选候选子句进行条件子句列名、列值匹配,使基于表结构和内容的NL2SQL方法准确率更高。(3)设计并实现了一个数据库通用动态查询工具。该工具支持两种方式查询数据库:自定义查询和自然语言交互查询。工具由查询生成器和查询解析器两个模块构成,查询生成器支持自然语言转SQL查询语句、自定义生成查询语句模板、系统安全管理和管理数据表结构等功能;查询解析器负责解析查询生成器生成的SQL查询语句模板,根据需求填入具体内容生成不同的SQL查询语句并执行,得到查询结果。论文给出了数据库通用动态查询工具的系统设计和实现方案,并且详细介绍了如何解析数据表结构、实现SQL语句的自定义创建、设计并优化NL2SQL模型,为灵活的数据库查询检索提供了一种通用便捷的实现方式。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.000381
{DOI}: 10.27012/d.cnki.gdhuu.2023.000381
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的小麦品种问答系统设计与实现
{Author}: 司贺杰
{Tertiary Author}: 马新明;张浩
{Publisher}: 河南农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小麦品种;知识图谱;意图识别;问答模型;机器学习
{Abstract}: 为解决传统互联网农业知识问答系统存在的短问句分类及用户意图理解匹配精确度低、答案质量难以保证等问题,本论文以小麦品种知识问答为例,依据领域知识本体技术,收集整理小麦品种数据和短问句数据集,构建了小麦品种知识图谱;采用自然语言处理和多种机器学习技术,将小麦品种短问句的用户意图理解任务转化为短问句分类与问句模板匹配任务;运用多种机器学习和自然语言处理技术,提出和优化了短问句分类与问句模板匹配模型,通过用户意图识别模型构建,确保了小麦品种短问句分类与问答的准确性和有效性。最终,选择最优的小麦品种短问句模板匹配模型进行集成开发,设计和实现了基于知识图谱的小麦品种问答原型系统。主要研究结果与结论如下:1.基于本体的小麦品种知识图谱构建。小麦品种专业知识属于垂直领域知识,为提高本体的系统性、完备性和可扩展性,本文采用自顶向下的方法构建了小麦品种本体知识体系,以满足不同层次、不同需求的用户对小麦品种知识问答服务的需求,设计了四个层次的小麦品种知识本体,确立了小麦品种知识的领域和范围。同时,针对小麦品种数据采集,从中国作物种质信息网、种业商务网爬取11151个小麦品种审定信息,在数据爬取、清洗、抽取与融合的基础上,设计和抽取了小麦品种实体18404个以及实体之间的关系131653个,建立了基于RDF的小麦品种知识图谱,为智能问答提供数据准备。2.小麦品种问答模型设计与验证。通过领域专家,采用基于规则的模板构建,设计了9种问题模板,构造了142811条短问句、116类自然语言问句;针对小麦品种命名实体识别,采用Han LP对短问句进行命名实体识别,构建了小麦品种词典,将短问句用户意图分解为短问句实体识别与问句模板的匹配任务;基于朴素贝叶斯(NBC)、基于转换器的双向编码表征量(BERT)和双向长短时记忆网络+注意力机制(Bi-LSTM+Attention)等机器学习方法,设计和验证了小麦品种问答模型。通过“7:3”数据样本比例的训练与测试,评估了NBC、BERT和Bi-LSTM+Attention三种机器学习模型对短问句与问句模板分类匹配的表现。结果显示,三种模型的准确率依次为92.85%、94.45%和96.59%,均能够提供高质量的分类匹配结果。其中Bi-LSTM+Attention表现最优,其在精确率、召回率和F1值三个方面,均高于96.4%,优于其他两个方法。实验表明,采用机器学习模型结合知识图谱的方法,可以高质量地实现小麦品种短问句到问句模板匹配,能够满足用户意图识别需要,为精确问答提供质量保障。3.基于轻量级框架的小麦品种问答原型系统。基于小麦品种知识图谱,集成命名实体识别技术、基于Bi-LSTM+Attention用户意图匹配模型和Neo4j图数据库检索技术,后端采用轻量级Spring Boot框架,前端用户页面使用HTML、CSS、Java Script语言和Thymeleaf页面渲染技术,设计和实现了基于知识图谱的小麦品种问答系统,具有信息检索、智能问答等功能,对于开发和普及推广小麦品种知识服务具有重要的价值和意义。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2023.000104
{DOI}: 10.27117/d.cnki.ghenu.2023.000104
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 保险精准营销中智能语音技术应用研究
{Author}: 刘瑶瑶
{Tertiary Author}: 黄立强
{Publisher}: 辽宁大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 保险营销;智能语音技术;保险科技;PAR理论
{Abstract}: 2021年我国保险行业保费收入、保险深度和密度均有所下降,保险深度和保险密度低于世界平均水平,保险市场仍未达到饱和,与此同时,宏观经济发展、消费者保险意识提高和科技进步促使保险市场更加差异化、专业化,消费者主动收集信息、线上交互、自主消费的意识增强,保险营销方式亟须向更精准的方向推进。近年来,保险业在国家政策与宏观市场环境的双重推动下正积极地进行数字化营销转型,但仍然存在营销模式与平台受限、营销中敏捷性与行动力欠缺、对客户问题相关性响应不充分等难题。在此背景下,作为人工智能重要分支之一的智能语音技术因其具有强交互属性与保险行业有着天然的适配性和结合性而受到关注,成为理论与实践领域关注的焦点,并在保险精准营销实践中取得了显著的效果。智能语音技术虽是近年才逐步成熟发展的新兴技术,但早期保险业引入电话客服这一自动化系统时,就能发现智能语音技术的雏形。近年来人工智能的飞速发展使得语音识别和语音合成不再作为单一的技术,而是作为一个智能语音交互整体发展应用,智能语音可以通过语音互动改善对顾客的服务、挖掘客户保险需求,赋能营销人员,同时降低销售合规风险,为保险精准营销提供有效的技术支撑。人工智能的飞速发展使得市场营销理论也从最初产品导向背景下的理论不断向以客户为导向的理论进化,唐·E·舒尔茨教授的PAR理论正是在人工智能背景下诞生的以客户为中心的营销理论,它由模式与平台、敏捷性与行动、相关性与响应三部分组成,消费者将占据主导地位,营销要从以消费者为中心的平台上去进行深度的数据解读。该理论是从技术的角度去认可技术所提供的支持,去认可技术做出的贡献,与智能语音技术作用于保险营销之后产生的赋能效果不谋而合,可以较好地解释智能语音技术发挥作用的现实路径。本文首先选取了北京循环智能科技有限公司推出的智能销售助手这一典型智能语音产品,对其基于语音识别、自然语言处理、语音合成等技术,帮助保险公司实现销售管理的智能化提升、一线人员的实时赋能以及更全面的客户洞察进行介绍,引出智能语音技术参与保险精准营销的研究主题。其次基于PAR理论从模式和平台、敏捷性和行动、相关性和响应三个方面分析目前我国保险营销中存在的问题,从而指出运用智能语音技术解决这些困难的必要性与可行性:智能语音技术可以帮助构建保险公司的数字化沟通平台、可以完善动态用户画像、可以辅助提高代理人产能、可以降低销售合规风险。正是由于保险业语音交互广泛、智能语音与保险业适配度高、智能客服目前应用效果较好、智能语音市场红利持续,为保险精准营销中应用智能语音技术提供了可行性。接着分析了智能语音技术用于保险精准营销中的售前、售中、售后各个环节中分别呈现出的不同程度的降本增效效果,也列举了目前各环节存在的应用难题,同时基于PAR理论对智能语音技术与保险科技其他技术方案对保险精准营销的赋能效果作对比,分析概括出智能语音技术的优势。鉴于智能语音技术在国外保险业中运用更早更成熟,便选取了国外先进产品案例,挖掘这类语音产品的亮点,比较我国的差距,为我国保险业在智能语音技术应用上的发展指引了方向。最后从保险公司、保险科技公司、保险监管机构三个方面提出有针对性的对策意见,建议保险公司加大科技建设的资金投入、重视对营销人员的科技赋能,建议科技公司在符合保险行业特性的基础上针对性地开发语音解决方案,建议保险监管机构针对新兴技术完善其监管政策、并用科技手段提高监管效能。建议的提出有利于补充和完善现有的理论和方法,使智能语音技术更好地运用到保险精准营销。
{URL}: https://link.cnki.net/doi/10.27209/d.cnki.glniu.2023.002283
{DOI}: 10.27209/d.cnki.glniu.2023.002283
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义相似度的领域智能问答系统研究与实现
{Author}: 孙溪骏
{Tertiary Author}: 宋宝燕
{Publisher}: 辽宁大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 语义相似度;智能问答;注意力机制;交互网络;混合相似度
{Abstract}: 互联网技术的高速发展带来了网络中数据量激增,如何高效地帮助用户在互联网的海量数据中获取特定领域的信息是一个重要问题,智能问答系统正是解决这一问题的有效方法。智能问答系统以一问一答形式,精确地回答用户的提问,智能问答系统通过与用户进行交互,为用户提供个性化的信息服务。语义相似度(Semantic Similarity)是通过计算两个文本的相似程度,来研究不同文本之间关系的一种技术,是自然语言处理领域的一个重要的研究方向。尤其是在智能问答系统的信息交互中有着效率与准确度的优势。在目前的大部分智能问答系统中,尤其是特定领域的智能问答系统,由于传统方法大多基于关系进行问答,对于知识库以及问句的预处理效率不高,因此设计并研发一套基于语义相似度的领域智能问答系统是非常必要的。对于智能问答流程中关键的三元组排序问题,本文采用语义相似度方法解决该问题,将三元组排序分为粗粒度三元组排序和细粒度属性三元组排序两个任务。针对粗粒度三元组排序,本文提出了基于注意力交互网络的语义文本匹配模型(Text Semantic Matching Model based on Attentional Inter-Networks,简称TSM-AIN),来进行三元组排序。首先,该模型融合了表示型网络的匹配抽取与交互型网络中的交互矩阵;其次,采用混合共同注意力机制接收复杂特征信息,并强化文本对中重要文本的特征信息,从而实现文本对之间的信息交换;然后,使用混合共同注意力模块输出的高维特征,通过动态注意力匹配矩阵的循环网络,来处理文本对之间的关键特征表示,并保存关键特征。对于细粒度属性三元组排序,本文提出了基于混合相似度计算的三元组属性匹配算法(Attribute Matching Algorithm based on Mixed Similarity Calculation,简称AM-MSC),对粗粒度三元组排序后的结果进行最终排序。最后,通过与其他模型算法进行对比实验,验证了本文所提出模型与算法的可行性与有效性。基于上述关键技术,本文设计并实现了基于语义相似度的领域智能问答系统。本系统提供了通用领域和特定领域两种智能问答方式,系统的主要功能包括数据集成、知识库构建、智能问答以及用户管理。该系统采用B/S架构搭建,使用Python语言开发完成。最后,通过系统测试表明,本文所构建的系统实现全部需求,并提供了通用领域和特定领域(如:金融领域)的智能问答功能和服务。
{URL}: https://link.cnki.net/doi/10.27209/d.cnki.glniu.2023.001400
{DOI}: 10.27209/d.cnki.glniu.2023.001400
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的中文事件因果关系抽取研究
{Author}: 陈祚华
{Tertiary Author}: 吴国华
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 事件因果关系抽取;事件抽取;事件因果关系识别;提示学习;预训练语言模型
{Abstract}: 事件因果关系抽取是信息抽取领域中的一个重要且具有挑战性的任务,其目的是从非结构化的文本中抽取事件,并识别出具有因果关系的事件对。事件因果关系抽取是许多人工智能应用的基础,在自动问答、知识图谱构建、事件预测等应用领域中发挥着重要作用。近年来,预训练模型技术的出现推动了信息抽取技术快速发展,但是针对事件因果关系抽取的研究还不充分。事件因果关系抽取包含事件抽取和事件因果关系识别两个步骤。在事件抽取中现有的方法受限于标记数据分布不均匀,导致抽取准确率较低。而在事件因果关系识别的研究中存在标注数据稀缺和常识知识匮乏的问题。针对上述问题,本文基于BERT预训练模型对事件因果关系抽取的两个关键步骤展开研究。本文的研究内容如下:(1)针对现有的中文事件抽取方法准确率较低的问题,本文提出了一种基于BERT和标签语义增强的中文事件抽取方法。该方法首先对事件类型标签的语义信息进行扩展,得到标签语义扩展词,并提出了一种衡量扩展词质量的指标,用于对扩展词进行筛选。其次,将扩展词和原始文本拼接为模型的输入,利用扩展词与事件触发词之间的语义关联来增强模型识别事件的能力。最后基于BERT预训练模型,构建了一种能同时抽取事件触发词和事件论元的联合抽取框架,该框架消除了流水线式架构导致的传递误差问题,能有效提升识别准确率。实验结果表明,本文提出的方法在中文事件抽取数据集上的效果优于现有算法。同时,消融实验和样例研究证明了标签语义增强方法的有效性。(2)针对中文事件因果关系识别中标注数据稀缺和常识知识匮乏的问题,本文提出了一种基于常识知识增强的中文事件因果关系识别方法。该方法基于BERT预训练模型,利用提示学习范式来激发预训练模型的小样本学习能力,从而缓解标注数据稀缺的问题。并通过将常识知识融入提示模版,缓解了常识知识匮乏的问题,有效提升了模型因果关系推理的能力。在多个公开的中英文事件因果关系数据集上的实验表明,该方法能有效提升事件因果关系识别的准确率,并且在泛化性和小样本学习能力上均优于现有算法。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2023.001544
{DOI}: 10.27075/d.cnki.ghzdc.2023.001544
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于上下文语义的幽默文本识别和生成方法研究
{Author}: 熊思棋
{Tertiary Author}: 王荣波;黄孝喜
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 幽默计算;幽默文本识别;幽默文本生成;幽默文本特征;AIGC
{Abstract}: 幽默是日常生活和工作中不可缺少的表达方式,是交流中润滑剂,在语言学研究中,幽默也是一种重要的表达手段。研究表明,幽默具有主观性的特点,这也使它成为自然语言处理的各种任务当中比较难的一项。本文针对幽默计算中的幽默文本识别和幽默文本生成问题进行深入研究分析,并结合幽默脚本理论、深度学习相关技术以及预训练语言模型提出了解决方案。在幽默文本识别方面,提出了面向幽默文本识别的多维潜在语义网络,结合幽默文本中多个特征来提高幽默文本识别的性能。该模型通过捕获笑话的不一致特征、语音特征和歧义作为语义特征,自动识别句子是否包含幽默表达。该模型分别在Pun-Of-The-Day、200K-Oneliners、SemEval-2021 Task 7这三个公开可用的幽默数据集上进行了实验,并与当下最流行的语言模型进行了比较。结果表明本文所提出的幽默文本识别模型具有更好的幽默识别准确性,可以为语言理解的研究做出贡献。在幽默文本生成方面,提出了基于上下文语义的幽默文本生成。为了提高生成文本的幽默性,在当下最流行的语言生成模型之一GPT-2的基础进行改造,集成了一个幽默模型,由语言模型生成多个候选文本由幽默模型进行打分,筛选出最幽默的文本。其中,幽默模型主要考虑到了笑话的不一致特征、语音特征和歧义作为语义特征。同时,为了验证该模型在幽默文本生成方面的普适性,分别在两个不同形式的数据集上进行实验,这两个数据集一个是前置-妙语形式的Setup2Punchline数据集,一个是将原始文本转化为幽默文本的SemEval-2020 Task 7数据集。结果证明该模型能很好地生成幽默文本,其效果好于当下广泛使用的其他语言生成模型。基于幽默文本识别和幽默文本生成的研究工作,设计并实现了幽默计算系统。该系统提供了幽默文本识别、妙语生成和幽默转化等核心功能。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2023.000579
{DOI}: 10.27075/d.cnki.ghzdc.2023.000579
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于信息科技课程标准的小学生计算思维评价研究
{Author}: 魏磊
{Tertiary Author}: 徐继红
{Publisher}: 内蒙古师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 信息科技课程标准;计算思维;小学生;评价工具;指标体系
{Abstract}: 随着知识与信息技术高速发展,社会对计算机领域的人才需求激增。为了满足这一要求,计算思维被视为21世纪人才必备的核心素养之一。世界各国也相继把计算思维纳入到本国的课程标准,回应计算思维培养的诉求。相关研究表明小学阶段是计算思维意识形成的启蒙期,也是关键期。因此,如何有效的培养小学生的计算思维是亟待解决的问题,而评价是计算思维培养效果的“风向标”。基于时代背景,本研究致力于解决本土化的、符合小学生计算思维发展评价工具。因此,本研究通过文献分析构建了计算思维评价框架,基于义务教育《信息科技课程标准(2022版)》制定了计算思维评价指标体系,并开发了分别针对四年级、五年级和六年级的计算思维评价工具。研究成果对后续思维评价、计算思维评价实践有一定的借鉴意义,能在一定程度上推动本土化的、符合中国学生特征的小学计算思维评价工具形成和发展。根据上述问题解决的过程,本论文分为七部分。第一部分主要基于计算思维评价的时代背景,阐述了研究问题提出、理论和实践意义、研究目标与内容、研究方法与技术路线;第二部分主要综述了计算思维研究的评价框架、评价指标体系和评价工具研究现状,特别关注了小学阶段计算思维评价的研究现状;第三部分主要对思维和计算思维的概念进行了界定,阐述了皮亚杰认知发展理论、泰勒的测量评价理论,为进一步研究奠定基础;第四部分主要梳理了问题解决过程、教育目标模型,并以此为依据构建了计算思维评价框架;第五部分依据构建的评价框架设计了小学生计算思维评价指标体系,并根据专家的问卷调查进行了适当修改;第六部分根据评价指标体系编制了针对四、五、六年级的计算思维评价工具,并进行了试测、正式测试和分析;第七部分总结梳理了研究的过程得出结论,并阐述了研究的不足以及展望。本研究依据课程标准,经历从计算思维评价框架到计算思维评价指标体系,再到计算思维评价工具的研制过程,完成了基本符合小学生四、五、六级学生的评价工具,工具易于操作,符合课程标准要求。但是在研究过程中,受时间和研究条件的制约,计算思维评价框架未作进一步的验证和修改;计算思维评价指标体系中权重未能根据实践进行验证,笔者将在后续的研究中进行多次的研究实践,以期对相关的研究结论做进一步的修正与完善。
{URL}: https://link.cnki.net/doi/10.27230/d.cnki.gnmsu.2023.000401
{DOI}: 10.27230/d.cnki.gnmsu.2023.000401
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于本体的神经系统变性疾病知识图谱构建及应用
{Author}: 马浩
{Tertiary Author}: 万艳丽
{Publisher}: 北京协和医学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 神经系统变性疾病;本体;知识图谱;问答系统
{Abstract}: 神经系统变性疾病是一类较为常见的神经系统疾病,在老年人口中较为常见。该类疾病的早期症状往往不明显,疾病的病程一般较长,通过对疾病的早发现、早诊断和早治疗对于延缓疾病进展具有重要意义。通过基于本体的疾病知识图谱构建可以对疾病知识进行结构化表示,在此基础上可以基于知识图谱构建知识问答、智能导诊、辅助诊断等系统,为疾病的早期诊疗提供帮助。研究目的:首先通过对神经系统变性疾病的诊疗知识进行提炼构建疾病本体,为西医疾病本体的构建提供借鉴。其次在构建的本体的基础上,基于临床指南、医学教材等数据源,抽取疾病相关的诊疗知识,构建面向临床场景的神经系统变性疾病知识图谱,对疾病的临床诊疗知识进行结构化表示。最后基于知识图谱设计自动问答系统,为基于知识图谱的自动问答系统研究提供参考。研究方法:首先通过文献调研相关研究现状,确定本体和知识图谱构建的数据来源和构建流程。通过借鉴斯坦福大学提出的七步法进行本体构建,复用已有的本体并定义本体中的概念和属性。将本体作为知识图谱的模式层,以临床指南、医学教材和网络数据作为数据源,经过知识抽取、知识融合和质量评估得到结构化的三元组,经过知识存储,将其存储于Neo4j,构建神经系统变性疾病知识图谱。研究结果:本研究构建了面向临床诊疗的神经系统变性疾病本体和知识图谱,并基于知识图谱设计了自动问答系统。所构建的神经系统变性疾病本体中包含10类概念,17种对象属性和7种数据属性;所构建的神经系统变性疾病知识图谱中包含有疾病相关的诊断、就诊和治疗等相关知识,共包含2012个疾病相关的实体,其中疾病的临床表现类实体有668个,疾病的检查项目类实体有199个,疾病的检查结果类实体205个,疾病的治疗药物类实体249个,疾病的非药物治疗类实体217个。基于知识图谱设计的自动问答系统通过深度学习的方法对用户问句进行语义解析,再通过模板将用户问句转换为cypher查询语言在数据库中进行查询,返回相应的答案。研究结论:本研究提出了一种基于本体的知识图谱构建框架,并基于此构建了神经系统变性疾病本体和知识图谱。通过构建的本体为其他疾病本体构建提供了参考。通过知识图谱构建,对神经系统变性疾病的诊断、就诊和治疗等知识进行了结构化表示,对疾病的临床表现、药物治疗、非药物治疗等知识进行分类分级,全面的提取了疾病的临床表现、检查项目、检查结果及治疗等类型实体及其中的语义信息,促进了疾病知识的管理和利用,为相关研究提供了借鉴。通过对疾病自动问答系统的设计,明确了问答系统的实现步骤和方法,为问答系统的研究提供了参考。
{URL}: https://link.cnki.net/doi/10.27648/d.cnki.gzxhu.2023.000744
{DOI}: 10.27648/d.cnki.gzxhu.2023.000744
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 高脂饲料中添加菊粉对鲤生长、抗氧化能力及脂质代谢的影响
{Author}: 王浩彤
{Tertiary Author}: 吴莉芳
{Publisher}: 吉林农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 高脂饲料;鲤;菊粉;抗氧化能力;脂质代谢
{Abstract}: 在鱼类饲料中,适当的增加脂肪含量,可以节约饲料蛋白质,降低饲料成本。但鱼类摄入过多脂肪,容易造成脂肪沉积及代谢紊乱,引起相关疾病,造成经济损失。菊粉是一种果聚糖型植物多糖,具有促进水生动物生长、提高免疫力、促进脂质代谢、抗氧化及改善肠道健康等功能。鲤是我国主要的大宗淡水经济鱼类之一,在养殖过程中,体内脂肪过度沉积现象越来越严重。为了探究高脂饲料中添加菊粉对鲤生长、抗氧化能力及脂质代谢的影响。本试验以鲤为研究对象,试验共分6组,即基础饲料CK组(粗脂肪,80.00 g/kg),高脂饲料G0组(粗脂肪,120.00 g/kg),高脂饲料添加菊粉的G1组(5.00 g/kg)、G2组(10.00 g/kg)、G3组(15.00 g/kg)和G4组(20.00 g/kg),进行为期8周饲养试验。饲养试验结束后,采用生物化学、免疫学、组织学及分子生物学等技术手段。研究高脂饲料中添加菊粉对鲤生长性能、消化代谢、免疫功能、抗氧化能力及肝胰脏和肠道组织的影响。结果表明:1.高脂饲料中添加菊粉对鲤生长性能及肌肉营养成分的影响与CK组相比,G0和G1组末体质量(FW)、增质量率(WGR)、特定生长率(SGR)、饲料效率(FER)和蛋白质效率(PER)显著降低(P<0.05),与G0组相比,G2、G3和G4组FW、WGR、SGR、FER和PER显著升高(P<0.05)。通过线性回归分析,高脂饲料中菊粉添加量为15.23 g/kg,SGR最高。与CK组相比,G0组肌肉粗脂肪含量显著升高(P<0.05),而G3组肌肉粗脂肪含量显著低于G0组(P<0.05)。2.高脂饲料中添加菊粉对鲤消化酶及蛋白质代谢酶活性的影响与CK组相比,G0和G1组肝胰脏、前肠、中肠和后肠脂肪酶(LPS)活性显著降低(P<0.05)。与G0组相比,G3组肝胰脏、前肠、中肠和后肠LPS活性显著升高(P<0.05)。与CK组相比,G0组和G1组血清谷丙转氨酶(GPT)和谷草转氨酶(GOT)的活性显著升高(P<0.05),肝胰脏GPT和GOT活性显著降低(P<0.05)。与G0组相比,G2、G3和G4组血清GPT和GOT活性显著降低(P<0.05),而肝胰脏GPT活性显著升高(P<0.05)。3.高脂饲料中添加菊粉对鲤脂质代谢酶活性及相关基因表达量的影响与CK组相比,G0组血清甘油三酯(TG)和总胆固醇(T-CHO)含量,G0和G1组肝胰脏乙酰辅酶A羧化酶(ACC)和脂肪酸合成酶(FAS),以及G0、G1和G2组肌肉ACC和FAS活性显著升高(P<0.05);G0、G1和G2组肝胰脏激素敏感性甘油三酯脂肪酶(HSL)、甘油三酯脂肪酶(ATGL)和肉毒碱棕榈酰转移酶-1(CPT-1),以及G0和G1组肌肉HSL和ATGL活性显著降低(P<0.05)。与G0组相比,G2、G3和G4组血清TG和T-CHO含量以及肝胰脏和肌肉ACC和FAS活性显著降低(P<0.05),而G2、G3和G4组肝胰脏和肌肉HSL和ATGL活性显著升高(P<0.05)。与CK组相比,G0组肝胰脏和肌肉乙酰辅酶A羧化酶-1(ACC-1)、FAS和LPL,肝胰脏过氧化物酶体增殖物激活受体β(PPARβ)、过氧化物酶体增殖物激活受体γ(PPARγ)和固醇调节元件结合蛋白(Srebp)的m RNA表达量显著升高(P<0.05);肝胰脏ATGL,以及肌肉CPT-1和HSL的m RNA表达量显著降低(P<0.05)。与G0组相比,G1、G2、G3和G4组肝胰脏PPARβ、固醇调节元件结合蛋白-1(Srebp-1)和ACC-1,G3和G4组肝胰脏和肌肉FAS和脂蛋白脂酶(LPL)的m RNA表达量显著降低(P<0.05);G3组肝胰脏ATGL、CPT-1、HSL和过氧化物酶体增殖物激活受体α(PPARα)显著升高(P<0.05)。4.高脂饲料中添加菊粉对鲤免疫指标的影响与CK组相比,G0和G1组血清溶菌酶(LZM)和碱性磷酸酶(AKP)活性,以及G0、G1和G2组补体3(C3)、补体4(C4)和免疫球蛋白M(Ig M)含量显著降低(P<0.05)。与G0组相比,G2、G3和G4组血清LZM和AKP活性,以及G3和G4组C3、C4和Ig M含量显著升高(P<0.05)。5.高脂饲料中添加菊粉对鲤抗氧化能力的影响与CK组相比,G0和G1组肝胰脏、前肠、中肠和后肠丙二醛(MDA)含量显著升高(P<0.05);G0和G1组肝胰脏和后肠总抗氧化能力(T-AOC)以及肝胰脏、前肠、中肠和后肠还原性谷胱甘肽(GSH)含量,G0组肝胰脏、前肠、中肠和后肠总超氧化物歧化酶(T-SOD)活性以及肝胰脏、中肠和后肠谷胱甘肽过氧化物酶(GSH-Px)活性,以及G0、G1和G2组后肠过氧化氢酶(CAT)活性显著降低(P<0.05)。与G0组相比,G3和G4组肝胰脏、前肠、中肠和后肠MDA含量显著降低(P<0.05);G3组肝胰脏和后肠T-AOC,G3和G4组肝胰脏、前肠、中肠和后肠GSH含量和T-SOD活性,G3和G4组肝胰脏、中肠和后肠GSH-Px活性以及肝胰脏和后肠CAT活性显著升高(P<0.05)。6.高脂饲料中添加菊粉对鲤肠道及肝胰脏组织形态的影响与CK组相比,G0组前肠皱襞高度,G0和G1组中肠和后肠皱襞高度及皱襞宽度均显著降低(P<0.05)。与G0组相比,G2、G3和G4组前肠、中肠和后肠皱襞高度,以及G3和G4组前肠、中肠和后肠皱襞宽度显著上升(P<0.05)。与CK组相比,G0和G1组中肠和后肠观察到肠粘膜损伤和萎缩。与G0组相比,G3和G4组肠粘膜皱襞形态结构完整,皱襞发育良好。与CK组相比,G0和G1组肝胰脏观察到大量的脂质空泡,部分细胞核溶解或消失,细胞边界模糊。与G0组相比,G3和G4组肝胰脏细胞形态规则,组织结构完整。综合分析以上试验结果,在本试验条件下,考虑经济因素,鲤高脂饲料中菊粉的适宜添加量为15.00 g/kg。
{URL}: https://link.cnki.net/doi/10.27163/d.cnki.gjlnu.2023.000768
{DOI}: 10.27163/d.cnki.gjlnu.2023.000768
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于感性工学和人工神经网络的电动牙刷感性意象造型设计研究
{Author}: 罗峰
{Tertiary Author}: 吴正仲
{Publisher}: 福建工程学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 电动牙刷;感性工学;网络爬虫;Word2vec;人工神经网络
{Abstract}: 如今,消费者们越来越注重产品造型情感意象的传达,且电动牙刷作为近年来新兴实用的家用清洁工具,广受人们青睐。因此本研究通过挖掘电动牙刷的形态设计特征和用户的情感意象,探究分析产品设计要素与用户感性意象间的关联关系,并应用指导于电动牙刷造型设计指标的优化与开发,从而为消费者设计出符合其情感意象的电动牙刷产品。本研究通过网络爬虫技术采集消费者线上的产品评论(21.5827万笔)与样本(200款);再以Word2vec、因子分析、聚类分析法和欧几里得距离判别法等,对庞大的评论集进行萃取得到代表感性词汇共3组;并以多维尺度、聚类分析法等,将收集的样本进行分析萃取为32款代表样本;再透过形态分析法对样本造型进行解构(分解得6个项目及25个类目)。应用语义差异法问卷评量消费者的感性意象,共取有效样本415份,最后将产品设计要素和用户感性评价结果通过数量化Ⅰ类理论(Quantification Theory TypeⅠ,QTTⅠ)构建产品设计要素与消费者感性意象关系的线性预测模型和反馈型神经网络(Back-Propagation Neural Network,BPNN)、遗传神经网络(Genetic Algorithm-based BPNN,GA-BPNN)的非线性预测模型。对三者模型以平均误差判别法通过测试样本预测的比较评估择优,结果显示QTTⅠ模型预测效果更为精准;再邀请5位设计师通过自主设计和根据最优模型生成的设计指标进行产品设计与评价验证,并以五组样本的135对评价值进行相依样本T检定,结果显示p值均大于0.05,表明本研究中QTTⅠ线性预测模型具可靠性和应用价值,且可有效提供造型项目、类目对感性意象的影响关联指标,可作为本研究产品造型意象的设计指标的指导。最后基于最优设计指标结合人机工程学、审美理念指导原则进行产品实践设计开发,完成了电动牙刷的形态、色彩与材质的造型整合设计、人机尺寸设计、内部结构设计以及人机交互界面设计,最终完成产品建模并生成设计效果图。本研究结合网络爬虫技术并透过系统分析,提出了一套科学完整的产品感性设计的优化设计方案,可为设计师传统的黑箱设计模式提供明确设计指标与参考。
{URL}: https://link.cnki.net/doi/10.27865/d.cnki.gfgxy.2023.000038
{DOI}: 10.27865/d.cnki.gfgxy.2023.000038
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BART的文本摘要模型研究
{Author}: 芮琦霖
{Tertiary Author}: 彭超
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本摘要;TextRank;指针生成网络;BART模型
{Abstract}: 文本摘要(Text Summarization)任务的目标是对一段文本的主要内容进行精简和概括,然后输出一段远小于原文长度但能表达原文基本含义的摘要。BART(Bidirectional and Auto-Regressive Transformers)预训练模型是目前在文本摘要领域广受欢迎的模型之一,然而由于其输入文本长度的限制,通常需要对输入文本进行裁剪,这就造成了源文本关键信息的丢失,同时BART模型时常生成语义与原文不符的词汇,造成最终摘要结果错误。为了解决上述问题,本文基于Text Rank算法、指针生成网络等技术,提出了两个文本摘要模型:·基于改进TextRank算法和BART模型的文本摘要模型本文首先基于Text Rank算法使用关键词共现情况计算语句重要性排名的基础上,向算法中引入了文本的结构信息和语义信息对算法进行重构,提出了HT-Text Rank算法,使得算法在对文本中的语句进行排序时,排名靠前的语句中包含源文本中更多的关键内容。随后将HT-Text Rank算法应用到BART模型的输入阶段,作为模型的预处理器对输入文本进行语句顺序重排的预处理,使得在BART模型的有效输入长度内尽可能包含了整个输入文本的关键信息。·基于指针生成网络和BART模型的文本摘要模型在使用HT-TextRank算法对BART模型的输入文本进行预处理的基础上,向模型引入指针生成网络模型。在此之前,本文首先对指针生成网络模型的生成概率参数进行修改,加入模型生成词汇与注意力分布指向的原文词汇之间的相似度,当模型在生成语义错误的词汇时,由于该词汇与原文词汇的相似度较低,使得模型使用模型生成词汇的概率降低,取而代之去复制原文中的词汇。通过这种方式,降低了BART模型由于生成语义错误词汇而造成摘要内容与原文不符的概率。本文构建的两个文本摘要模型在公开的数据集中进行了对比实验,结果表明,本文提出的模型在三项ROUGE指标上均优于目前常用的模型。同时,本文还进行了具体的案例分析,从案例中可以看出,本文提出的模型所生成的摘要更加贴合原文的主旨大意。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000902
{DOI}: 10.27149/d.cnki.ghdsu.2023.000902
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向人机交互的意图识别方法研究
{Author}: 李兰婷
{Tertiary Author}: 刘淑华
{Publisher}: 东北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 隐式意图识别;提示学习;多模态意图识别;T5模型;密集视频描述
{Abstract}: 意图识别作为对话系统的核心模块之一,其主要作用是基于用户话语判断对话中的真实意图。准确识别用户意图对于实现有效、流畅的人机对话至关重要。然而自然人机交互场景的复杂性和人类意图表达方式的灵活多样性,给意图识别领域带来了巨大挑战。现有的意图识别研究大多局限于简单、直接的显式意图识别,缺乏对用户深层语义信息的充分理解,进而影响人机交互体验。此外,在复杂场景下,用户意图在单一模态下往往难以完整表达,因此基于单一文本模态的意图识别应用场景有限。针对以上问题,本文分别从文本和多模态两个视角开展用户意图识别的研究。具体研究内容包括以下三个部分:(1)构建了一个跨领域中文隐式意图识别数据集CIID(Chinese Implicit Intent Dataset)。本文基于社交媒体平台数据构建了用户隐式意图识别数据集。该数据集包含7种常见的人机交互意图,总计5042条标注数据,数据内容均为包含用户隐式意图的文本。以往的研究较少涉及用户隐式意图识别,因此缺乏相应的开源数据集,但其对于实现更加智能、自然的人机交互具有重要意义。因此,本文提出的数据集能在一定程度上推动隐式意图识别的研究与发展。(2)提出了一种基于提示学习的隐式意图识别方法。本文首次将提示学习应用于隐式意图识别领域,该方法通过构造合适的自然语言提示模板,使模型能够充分挖掘话语中隐含的语义信息。提出的方法在CIID数据集上进行了实验评估,与通用预训练语言模型BERT、BART和T5-pegasus相比,本文提出模型的识别准确率分别提高了1.6%、1%、0.8%,F1分数分别提高了1.7%、0.9%、0.7%,达到了目前最优的实验结果。为进一步证明提出方法的有效性,本文在另一个公开的中文意图识别数据集CAIS上进行实验评估,与其他先进工作相比,本文提出的方法表现出一定优势,识别准确率达到95.73%。此外,本文还探究了低资源设置下模型的识别效果,实验结果表明该模型具有良好的小样本学习能力。(3)为解决单一模态下意图识别效果受限的问题,本文提出一种注入解释的多模态行为意图识别方法。该方法利用T5模型作为骨干网络,对视频和文本两种模态特征进行充分学习融合,并且以完形填空的形式生成用户行为意图。为了帮助模型更好地理解视频信息,为意图识别提供更加丰富的语义线索,本文利用PDVC(Parallel Decoding Video Captioning)模型生成密集视频描述并将其作为辅助文本共同输入到模型中进行训练。该方法在WHYACT数据集上进行实验评估,实验结果表明本文提出模型的F1分数超过了单模态与多模态基线模型,验证了提出方法的有效性。
{URL}: https://link.cnki.net/doi/10.27011/d.cnki.gdbsu.2023.000226
{DOI}: 10.27011/d.cnki.gdbsu.2023.000226
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 煤矿工种知识图谱的构建及智能问答研究
{Author}: 程浩然
{Tertiary Author}: 刘鹏
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 煤矿工种;知识图谱;意图识别;槽位提取;智能问答
{Abstract}: 煤矿安全生产一直是煤矿产业中关乎全局的一件大事,煤矿涵盖的作业工种繁多,切实提高煤矿作业人员的专业知识和能力,对减少煤矿事故发生,促进安全生产水平,具有基础而重要的现实意义。本文通过对知识图谱和智能问答的理论及实践研究,在搜集大量工种专业知识的基础上,构建煤矿工种知识图谱,并以此研究智能问答系统,旨在改善煤矿工种结构化知识缺失的局面,并为煤矿工种人员快速、准确获得相关专业知识提供有益途径。本文的主要工作如下:煤矿工种知识图谱的构建研究。根据领域数据对图谱的Schema进行初步构建,基于此Schema通过爬虫框架搜集相关工种专业知识,并对其进行整理,随后运用煤矿专业理论对工种专业进行梳理分类。采用BIO标注策略对数据进行标注,并构建BERT-Bi LSTM-CRF模型抽取工种知识构成工种实体和属性信息。而后对工种图谱的关系进行定义,基于实体、关系及属性信息对工种知识图谱的Schema进行完善,运用Neo4j图数据库保存三元组信息,实现煤矿工种知识图谱的构建。知识图谱的智能问答方法研究。基于煤矿工种数据特点以及构建的知识图谱,设计智能问答流程,并在此基础上研究BERT意图识别和槽位提取的方法。分别对BERT的单句分类任务和槽位提取任务进行研究,基于此构建意图识别和槽位提取的BERT-wwm-ext联合模型,并与单个模型任务的指标进行比对。根据煤矿工种知识图谱数据特点,利用Sentence-BERT模型对问句提及词和知识图谱的候选目标实体进行关联,结合相似度匹配和重叠词比对,得到实体链接的最终结果。基于识别的意图和提取的槽位结果,结合实体链接的目标实体,构建Cypher查询语句,从煤矿工种知识图谱中查询得到相应答案。基于煤矿工种知识图谱的智能问答系统的研发实现。运用Python等语言和Django框架对系统进行构建,完成知识图谱展示、意图识别和槽位提取、实体链接以及工种知识问答模块的人机交互实现。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.001674
{DOI}: 10.27623/d.cnki.gzkyu.2023.001674
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: “双减”背景下YC教育培训机构战略转型研究
{Author}: 茹景玉
{Tertiary Author}: 蒙永亨
{Publisher}: 桂林理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: “双减”政策;战略转型;教育培训机构
{Abstract}: 随着我国经济水平和素质教育的不断发展,家长对改进教育水平的需求不断提高,中小学家长的教育理念也逐步发生改变,不单纯满足于学校的正式教学,反而将目光慢慢转向校外中小学课外辅导机构。白皮书显示(2020),义务教育阶段中小学课外辅导培训的平均教育支出占家庭总支出的13.35%,超前式的教育模式不仅使中小学生的作业负担加重,更使家长深受其扰,这种教育状况引起了国家部门和社会的高度重视。2021年7月份国家教育部门正式印发《关于进一步减轻义务教育阶段学生作业负担和校外培训负担的意见》。教育部颁布的政策顺应时代发展,符合我国教育大方针,然而对多数学科类教育培训机构来说是一个很大的挑战。政策的提出对中小学课外辅导机构的主营业务产生了重大影响,尤其对于主营业务单一的校外中小学课外辅导机构,如果不及时进行战略转型,将会面临极大的生存挑战。YC教育培训机构是一个以中小学课外辅导为主营业务的教育公司,也是“双减”政策下亟待战略转型的培训机构的典例。本文以YC教育培训机构为研究对象,深入剖析了YC教育培训机构的战略转型问题,希望能够为教育培训机构的战略转型提供一定的帮助和借鉴。本文研究的逻辑顺序是:首先梳理了“双减”、培训机构、战略转型概念,企业战略转型相关理论以及PEST分析法、波特五力竞争模型等相关分析方法,为本文后面的战略转型研究打下了坚实的理论基础。其次通过实际调研全面搜集YC教育培训机构的资料,了解了YC教育机构的组织架构、资源能力等发展现状,分析了YC教育培训机构的战略问题和原因,剖析了战略转型的必要性,以此为基础对YC教育培训机构的战略转型问题展开研究。再次,对京津冀地区的其他教育培训机构进行抽样调查,为YC教育机构提供案例参考,接着利用PEST分析、波特五力竞争模型、CPM矩阵、EFE矩阵、IFE矩阵等分析方法,对YC教育培训机构的行业环境、内外部关键因素进行分析。基于上述分析明确了YC教育培训机构的战略转型原则、目标,利用QSPM分析方法确定了YC教育培训机构的扭转型战略以及提出了战略转型可行策略和实施方法。最后为YC教育培训机构的战略转型提出了一系列保障机制。希望帮助YC教育培训机构顺利完成战略转型。本文的研究为YC教育培训机构探索出一条顺应国家政策、符合国家教育要求的可行路线,帮助YC教育培训机构渡过难关,对于其他教育培训机构的战略转型有重要的借鉴意义。
{URL}: https://link.cnki.net/doi/10.27050/d.cnki.gglgc.2023.000904
{DOI}: 10.27050/d.cnki.gglgc.2023.000904
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CNN模型的医疗知识图谱问答系统研究
{Author}: 白云宇
{Tertiary Author}: 李勇;马满福
{Publisher}: 西北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医疗知识图谱;自然语言处理;问答系统;深度学习
{Abstract}: “COVID-19”等烈性传染病爆发以来,医疗资源不足已成为一个严重的社会问题,医疗健康领域的在线问答系统已经成为人们获取健康知识和诊疗建议的重要途径之一。然而,由于医疗领域的专业性和复杂性,医疗问答系统的准确性不足成为制约其发展的主要因素之一。大数据、人工智能以及知识图谱等技术的发展,为在线医疗问答系统的优化提供了新的思路和方法。知识图谱作为一种新兴的知识表示和推理技术,可以将医疗领域的专业知识融合到一个可视化的图数据库中,建立准确、全面、可扩展的知识体系,以支持在线医疗问答系统的优化和发展。本文主要完成以下研究工作:1.构建了医疗知识图谱NWNU＿KG。从医疗电子文档、垂直医疗站点及医疗症状库等多个数据源,通过建立规则抽取结构化数据,并使用爬虫解析器对医疗站点的数据进行爬取,经过实体对齐和实体消歧等操作,将获取的医疗数据进行融合,构建医疗知识图谱NWNU＿KG,包含7种类型的44112个实体,10种类型的291164个关系。2.基于构建的知识图谱提出了医疗问答联合模型MBCD。为了解决实体识别的问题,MBCD模型采用了深度学习和词典相结合的方法。深度学习模型MC-BERT＿BILSTM＿CRF识别失败则使用词典进行二次实体识别,以提高实体识别的准确性和覆盖率。为了准确识别用户提问意图,MBCD模型将text CNN和规则模板两种方法进行结合。text CNN模型对用户输入的问题识别失败,则通过调用设定好的规则模板对可能存在的用户意图进行匹配,以此实现二次意图识别。MBCD模型的提出有效地解决了医疗问答系统中实体抽取和提问意图识别的难题,进一步提升了问答系统的准确性和性能。3.研发了一个基于知识图谱NWNU＿KG和MBCD模型的医疗问答系统。该系统通过数据层、业务层和展示层来构建,前端展示页面采用HTML和CSS技术开发,并通过Django框架快速搭建。主要实现了实体关系查询和问答交互及知识图谱的可视化,可以提供医疗问答服务以及医疗知识图谱可视化应用等功能。本文研究发现,医疗知识图谱NWNU＿KG具备较好的可扩展性且便于迁移,可为后续医疗领域智能问答研究提供数据支撑,具有广阔的应用前景;联合模型MBCD准确率较高,在实体识别和关系抽取中的准确率分别为89.32%和85.68%,可以准确识别到用户输入的自然语言中的实体和实体关系,具有一定的实用价值;基于MBCD模型的智能医疗诊疗服务平台具有较快的响应速度、简洁易懂的人机交互页面并且能够准确的识别用户问题并返回正确的答案,具备较好的稳定性和可靠性。
{URL}: https://link.cnki.net/doi/10.27410/d.cnki.gxbfu.2023.000770
{DOI}: 10.27410/d.cnki.gxbfu.2023.000770
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于时序知识图谱的问答系统研究
{Author}: 彭琛琛
{Tertiary Author}: 石小川
{Publisher}: 武汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 时序知识图谱;问答系统;知识抽取;知识表示学习
{Abstract}: 互联网的蓬勃发展带来了数据的快速增长。如何高效、准确地从大量的互联网数据中提取有效信息逐渐成为人们关注地问题。基于知识图谱的问答系统以结构化的数据内容和高效的检索方式为用户提供便捷的个性化信息服务。常规知识图谱通常是静态的,无法刻画事实的动态演化的过程,这限制了它的应用场景。时序知识图谱在时间维度上对静态的知识图谱进行扩展,包含了知识的时序信息,具有重要的研究价值。目前,时序知识图谱已经成为知识图谱领域的研究热点,但以时序知识图谱作为问答系统知识源的研究还处于起步阶段。为了充分发挥时序知识图谱建模结构化知识动态变化的优势,提升问答系统的覆盖范围和准确度,本文对基于时序知识图谱的问答系统进行了研究,主要包含以下三个方面的内容:(1)针对现有知识抽取模型的不足进行改进,提出了基于改进的BERT-Bi LSTMCRF方法的知识抽取模型用以构建时序知识图谱。在实体、关系数据的获取之外引入时间抽取模块,实现了时间维度信息的抽取。实体、关系与对应时间信息融合形成时序知识图谱四元组。通过对比实验证明了本文提出的时序知识抽取方法的有效性。(2)构建了金融领域时序知识图谱数据集和问答数据集。针对时序知识图谱问答数据集匮乏的问题,采用(1)中的时序知识抽取模型对公开的金融领域中文文本数据进行挖掘,从而构建了中文金融时序知识图谱。在此知识图谱的基础上采用基于规则模板的方法生成了时序知识图谱问答数据集,为问答系统的构建提供了数据基础。(3)提出了基于时序知识图谱的问答系统Temp-KGQA。本文采用基于时间图卷积网络的时序知识图谱表示学习方法获取实体、关系和时间的表示向量,将其应用于问答系统中以实现包含时间信息和多条知识的问题推理。通过对比实验证明了本文提出的模型相比现有的基线方法在中文金融领域时序知识图谱问答上取得了更好的效果。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2023.000311
{DOI}: 10.27379/d.cnki.gwhdu.2023.000311
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer机制的自动问答系统设计与实现
{Author}: 沈佳诚
{Tertiary Author}: 谷俊
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 税收政策;问答系统;深度学习;Transformer;TF-IDF
{Abstract}: 随着信息技术的飞速发展,智能化、网络化、数据化已经成为当下社会的发展趋势。税务作为国家财政的重要组成部分,也需要不断地适应这一趋势,提升自身服务水平和管理效能,因此,智慧税务应运而生。智慧税务是指利用信息技术手段,将税务管理、服务、执法等各个方面的工作智能化、网络化、数据化,以提高税务工作的效率和质量,优化营商环境和公平竞争环境,实现税务现代化和智慧化的管理方式。税务行政行为是国家最高行政机关及税务机关按照税法的规定实现国家税收职能的行为,是国家经济层面进行宏观调控的重要手段。目前,税务从业者查找自己所需的税收政策使用的主要方法是通过搜索引擎查找或者前往各地税务局人工查询,这使得从业者们必须面临耗时耗力,且无法快速找到所需信息的窘境。因此,税务从业者们亟需一套专业的、可以快速上手使用的自动问答系统。
我国已有一套较完整的税收政策体系,能够对税收征管、征税和税收政策进行总体规划和设计。税收政策体系的建立和完善,能够有效地促进经济发展,优化营商环境,提高税收征管效能,促进社会公平和经济可持续发展。本文以税收政策作为数据源,提出了一个面向税收政策的自动问答系统,该系统运用了文本检索技术和深度学习模型,为税务从业者提供了一个方便、易上手的操作平台。本文主要做了以下几方面的工作:
1、根据税收政策文件专业性强的特点,构建了税收政策知识库,这是税收政策类文件首次在自动问答系统中运用。
2、为了能够使系统响应快速、且更完整构建面向税法领域的问答系统,将Transformer模型用于税收政策问答系统,将基于Transformer模型与传统的基于向量的文本检索算法相互相融合,实现了财税领域的自动问答系统,和以往使用一种模型的方法不同,两种模型的结合可以保证准确率的同时,大大减少的响应时间。本文将重点放在较为固定的数据库中,所提出的方法结合了transformer的先进性、准确性与向量模型的易操作性,可以胜任用户提出的税收政策问题的回答。
3、将Transformer模型与传统的基于向量的文本检索算法相结合,实现了税收政策自动问答系统。同时,开发了原型系统聊天机器人,使税务从业者能方便、高效地学习税法领域相关知识。经过与其他模型对比和系统的测试,本文提出的基于向量结合基于深度学习的税收政策问答系统效果较好。在本次自动问答系统在税法领域的尝试中,实现了降低人力成本,24小时可运作的特点,十分具有推广性,值得深入研究。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2023.001922
{DOI}: 10.27312/d.cnki.gshsu.2023.001922
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT的智能医疗诊断辅助系统的研究
{Author}: 冯子辉
{Tertiary Author}: 张敏
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言处理;BERT;分类算法;医疗诊断
{Abstract}: 随着人们生活水平的迅速提高,也产生了很多问题,其中最值得人们关注的就是健康问题。比如青少年人由于偏食、挑食、爱吃零食存在营养不良或肥胖等问题,中年人由于生活压力过大、生活不规律存在很多亚健康问题,老年人由于身体机能下降更会存在很多健康问题。解决健康问题已经迫在眉睫,早诊断早治疗,高效且准确的医疗诊断将成为人们生活必不可少的一部分。在上述背景下,大量医疗诊断系统层出不穷。但传统医疗诊断系统有一些通病,比如系统需要大量医生去维护、医疗诊断效果完全依赖于诊断医生的个人水平等等。因此本文尝试运用自然语言处理技术为医疗诊断赋能,设计并实现了基于BERT的智能医疗诊断辅助系统,旨在推动医疗诊断系统实现更快更好的发展。本文的主要工作如下:1)提出了将自然语言处理与医疗诊断相结合进而解决传统医疗诊断系统通病的方案。同时选用BERT+下游任务的训练方式来对诊断模型进行训练。医疗诊断归根结底就是一个分类问题,即根据症状信息判断患者是何种疾病。支持向量机和人工神经网络是两种不错的分类算法,本文运用不同的分类算法做下游任务设计出了两个诊断模型。2)基于BERT原生模型并结合医疗诊断场景设计出了一种优化的MDBERT模型。MDBERT模型从四个方面对BERT模型进行了优化:第一,为预训练任务选择了更适合医疗诊断的文本语料库。第二,针对MLM预训练任务采用了数字整体化的训练方法。第三,对神经网络参数进行L2正则化,在一定程度上降低模型的过拟合程度。第四,针对下游任务采用了mean＿max＿pooled的训练方法。3)基于诊断模型以及上述优化方案,完成了智能医疗诊断辅助系统。该系统实现了患者、医生的友好交互,比如患者就诊病历、医生预诊断病历(此功能运用了诊断模型,诊断模型可以辅助医生对病历做出诊断)、医生诊断病历等。同时对该系统进行了功能性测试和非功能性测试等多方面的测试,得出了该系统基本满足预期效果的结论。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.002711
{DOI}: 10.27149/d.cnki.ghdsu.2023.002711
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 健康饮食领域知识图谱构建及推荐系统研究
{Author}: 李尚霏
{Tertiary Author}: 唐东平
{Publisher}: 华南理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 健康饮食;本体;知识图谱;知识抽取;推荐系统
{Abstract}: 随着人民生活水平的提高和互联网技术的快速发展,人们对于获取健康饮食知识服务的需求日益增长,互联网上积累了大量多源异构的健康饮食知识,人们难以从中高效地检索出符合自身需求的健康饮食知识。因此,本文采用自顶向下的方式,利用前沿的自然语言处理技术对多源异构的健康饮食相关知识进行抽取、融合,构建健康饮食领域知识图谱,并设计了基于知识图谱的菜谱推荐系统,具体研究内容如下:
第一,研究了健康饮食领域知识图谱模式层构建。基于改进的“七步法”构建了健康饮食领域本体,利用TF-IDF算法挖掘了社会化问答平台“知乎”的“健康饮食”话题下的问题文本,从而探究用户的健康饮食信息需求,辅助领域核心概念的列举,进一步扩充、细化了健康饮食领域本体的实体类别,设计了融合用户需求的细粒度健康饮食本体,并使用Protégé工具进行构建,形成知识图谱的模式层,为下一步数据层的构建提供指导。
第二,研究了多源异构的健康饮食领域知识图谱数据层构建。通过爬虫工具采集了多源异构的健康饮食知识,对结构化、半结构化数据直接进行预处理。针对非结构化的数据,采用流水线的抽取模式,首先利用融合词典信息的LEBRT-CRF模型进行命名实体识别,再使用BERT-Bi GRU-Attention模型进行关系抽取,并分别验证两个模型的有效性,在经过实体对齐后,最终存入图数据库Neo4j和RDF数据库Apache Jena中,进一步扩充了知识图谱的数据层,为推荐应用打下基础。
第三,研究了基于知识图谱的菜谱推荐方案与系统设计。从用户的典型需求出发,划分三类推荐场景,设计了健康饮食领域知识图谱加持的多层次推荐服务体系,并采用分模块的思想对推荐系统进行设计。
本文通过“七步法”和文本挖掘技术构建出细粒度的健康饮食本体,在一定程度上融入用户健康饮食需求。在此基础上,针对多源异构数据设计了数据层构建流程,提升了知识抽取环节的准确性。同时,基于构建好的知识图谱提出了菜谱推荐方案,具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27151/d.cnki.ghnlu.2023.000373
{DOI}: 10.27151/d.cnki.ghnlu.2023.000373
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 数字化企业生态位与动态能力匹配研究
{Author}: 李润宜
{Tertiary Author}: 谷斌
{Publisher}: 华南理工大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 生态位;动态能力;数字化企业;组态匹配
{Abstract}: 随着数字技术的蓬勃发展和全面赋能,数字化企业成为发展最快和辐射最广的数字创新载体,推动社会经济高质量发展。复杂动态的数字化创新环境模糊了产业边界,深刻改变了竞争格局,为数字化企业创造出前所未有的发展机遇。与此同时,数字化企业面临资源开发利用和价值占领的双重挑战。生态位体现了企业的相对资源优势和功能定位,是解决上述挑战至关重要的概念工具。在众多能力中,动态能力被认为是资源整合配置的关键能力,是生态位得以构建和转化为竞争优势的有效手段。然而,尽管现有研究分别探讨了生态位与动态能力对企业绩效的作用机制,但忽视了数字化企业生态位与动态能力的匹配。其中生态位的研究主要关注生态位与创新能力、网络能力的关联。动态能力的研究多基于清晰边界和静态视角的理论情境展开,聚焦企业内部资源的匹配和环境变化频率的影响。此外,先前研究构建了传统创新环境下的评价指标,但无法适应数字化企业的发展需求。
因此,本文在产业融合理论、生态位理论、动态能力理论等相关研究基础上,系统梳理了数字化企业、生态位、动态能力与企业绩效的文献,构建“生态位—动态能力”匹配的理论框架,揭示复杂动态的产业融合环境下,数字化企业生态位与动态能力匹配的优势组合。并通过中国数字化上市公司的数据分析,验证了本研究的可行性。
研究通过以下两个步骤展开:第一,通过产业融合周期与模式的分析,揭示中国数字化赋能下独特的产业发展规律,构建研究的理论情境。第二,基于组态视角,结合生态位与动态能力理论,探索数字化企业如何匹配生态位与动态能力以维持高绩效。主要包括以下四个研究:(1)基于跨文本相似的数字化赋能下产业融合周期与模式研究;(2)基于数字业务识别的企业生态位测度与分布研究;(3)基于TOPSIS-灰色关联分析法的数字化企业动态能力综合评价研究;(4)基于多阶段fs QCA的数字化企业生态位与动态能力适配组态研究。
研究结果显示:(1)数字化赋能下的产业融合可划分为形成期(2012-2013)、成长期(2014-2017)以及成熟期(2018-2020),其中形成期产业融合开始萌芽,成长期的产业融合程度较深,成熟期融合幅度最大;(2)数字化企业的生态位在坐标系上呈三角状分布,可分为共生型,压缩型,错位型和扩充型;(3)数字化企业的动态能力评价指标体系由十三个代理变量构成,其中数字化企业补助和数字技术应用对企业动态能力构建有重要影响;(4)单个生态位要素和动态能力要素并非企业获得高绩效的必要条件,生态位与动态能力相互匹配对企业绩效发挥作用;(5)产业融合环境下数字化企业存在八条产生高绩效的生态位与动态能力匹配路径,可归纳为能力优势型,位势优势型与位势能力互补型。
本研究旨在揭示数字化企业生态位与动态能力匹配的有效路径,是对生态位与动态能力理论的拓展和深化,为数字化企业的管理实践提供理论参考。主要贡献在于:(1)结合科学技术侧和市场侧的数据验证了数字化赋能下独特的产业融合发展规律;(2)拓展生态位与动态能力理论,实现了数字化企业生态位与动态能力的有效测度;(3)突破现有研究的单一视角,从组态视角揭示了生态位与动态能力匹配作用的发挥过程;(4)有别于静态视角的研究,以产业融合为理论情境揭示数字化企业生态位与动态能力匹配的动态演进规律。
{URL}: https://link.cnki.net/doi/10.27151/d.cnki.ghnlu.2023.000466
{DOI}: 10.27151/d.cnki.ghnlu.2023.000466
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的文本摘要生成研究
{Author}: 于子健
{Tertiary Author}: 李欣
{Publisher}: 中国人民公安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本摘要生成;预训练语言模型;提示学习;编码器-解码器;司法摘要
{Abstract}: 公安机关的执法办案过程产生了卷宗、警情、案例等海量非结构化文本数据,从大规模文本数据中获取简洁、准确、可靠的信息,是提高公安民警高效利用文本资源水平的基础条件,能够支撑警情摘要、卷宗摘要、案件情况简报等具体任务。作为一种信息压缩技术,文本摘要能够用更简短的语句表达源文本内容。深度学习技术的引入使文本摘要模型效果获得明显提升,但仍存在摘要内容不精炼、准确性不足以及摘要与原文描述事实不一致的问题。本文结合裁判文书摘要、案例摘要等公安实际应用对算法模型进行优化改进,主要工作有以下方面:(1)提出一种基于Transfomer的编码器-解码器结构的文本关键短语抽取模型。模型结合位置特征强化关键短语边界预测能力,解决现有模型存在的短语边界识别不准确问题。此外,基于匈牙利算法计算得出模型预测与标注短语的最优对应序列,动态调整模型的训练方向,消除样本数据中关键短语排序固定的影响。在公开数据集Inspec、Sem Eval2017以及KP20K上与已有的Cat Seq、Ex Hi RD-h等模型相比,模型在F1@5、F1@10和F1@M评价指标上均取得了最优效果。(2)提出一种基于关键短语提示学习的文本摘要生成模型。将关键短语作为提示信息融合到文本摘要生成模型的输入中,分别优化原文与关键短语的语义表示。同时,模型在训练过程中增加对比学习机制,改进训练目标以解决暴露偏差问题。在公开数据集CNN/DM和XSum上,与GSum、Sim CLS等模型相比,模型在ROUGE-1,ROUGE-L等指标上效果取得了提升。(3)为减少生成摘要的事实性错误,利用领域预训练语言模型提供背景事实特征;并在模型训练阶段构造摘要正例负例样本,通过对比学习提升编码过程的语义一致性;此外,增加摘要实体错误检测与修正模块来优化摘要生成。在公开数据集CAIL2020、CAIL2021以及CAIL2022上,模型的BERTScore与Mover Score指标均取得提升。最后,设计并实现了中文司法领域摘要原型系统。面向公安司法业务需求,实现了裁判文书、司法问答、司法案例摘要等功能,验证了论文模型的有效性。
{URL}: https://link.cnki.net/doi/10.27634/d.cnki.gzrgu.2023.000103
{DOI}: 10.27634/d.cnki.gzrgu.2023.000103
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于网络RTK技术的高精度滑坡监测方法研究
{Author}: 何元浩
{Tertiary Author}: 王利
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 滑坡监测;网络RTK;对流层建模;VRS;虚拟大气约束
{Abstract}: 滑坡等地质灾害的监测和预警是防灾减灾的重要前提。GNSS(Global Navigation Satellite System,GNSS)技术以其高精度、全天候和无需通视等独特优势被广泛用于地质灾害滑坡监测中。目前,RTK(Real Time Kinematics)技术因具有出色的实时性和监测精度而广泛用于地质灾害监测预警中。然而,该技术需要为每处滑坡建立基准站,这存在着监测成本高、基准站信号质量无法保证、基准站易发生位移等多种问题。我国近年来在建设连续运行参考站(Continuously Operating Reference System,CORS)网络方面取得了蓬勃发展,这一网络拥有广泛的覆盖范围、高质量的数据和稳定的点位,有望广泛应用于地质灾害监测中,为目前滑坡监测中存在的问题提供了可能的解决方案。但事实上,滑坡灾害常常发生在复杂的山区地形中,大气条件活跃,传统网络RTK技术对大气建模误差过于敏感,其监测效果难以得到保障。为解决这些传统网络RTK技术在滑坡监测中遇到的问题,本文从滑坡起伏地形对流层建模和网络RTK建模大气使用方法等方面展开了研究和探讨。文中的研究成果包括:(1)详细介绍了基于虚拟参考站(Virtual Reference Stations,VRS)技术的网络RTK的数学模型和观测方程,并包括了模糊度解算、大气误差校正和VRS虚拟观测值的生成方法。同时总结了复杂环境下RTK终端滑坡监测模型,主要包括数据质量控制策略、参数估计方法以及互补集合经验模态分解(Complementary Ensemble Empirical Mode Decomposition,CEEMD)和中值滤波等监测序列降噪方法。(2)针对对流层建模精度受滑坡地形起伏影响较大的问题,以平面参数拟合(Linear Interpolation Model,LIM)、高程因子作为参数估计(Height Linear Interpolation Model,HLIM)、基于全球气温气压(Global Pressure and Temperature,GPT)的先验高程因子改正(LIM-GPT2w和LIM-GPT3)模型为例,对比并分析了这四种传统的对流层建模方法在较为平坦地区和高差较大环境下的大气建模精度。实验结果表明,综合考虑建模精度和运算效率的前提下,当地形起伏较为平缓时,传统平面参数拟合(LIM)模型是较为合适的选择,而基于先验高程因子改正(LIM-GPT2w和LIM-GPT3)模型在参考站间高差较大时仍可获得较高的建模精度,适用于大高差环境中进行建模。研究成果为大高差下的网络RTK滑坡监测选择合适的对流层建模模型提供了重要参考。(3)针对传统网络RTK虚拟参考站(VRS)技术对大气建模误差敏感问题,提出了一种基于虚拟大气约束(Virtual Atmospheric Constraints,VAC)的网络RTK算法。该算法将网络RTK大气建模值作为虚拟观测值,并为大气建模值提供相应的精度信息。在得到监测坐标后,采用CEEMD和中值滤波对坐标序列进行平滑降噪。以甘肃省黑方台滑坡为例,使用周围CORS站数据验证了上述算法的有效性。对于滑动监测点HF06,VACRTK水平和高程方向RMS统计值分别为1.0cm和2.7cm,而传统VRS-RTK水平和高程方向RMS统计值则分别为1.8cm和4.7cm。相比传统VRS-RTK,所提出的VAC-RTK算法在水平和高程方向上的监测精度分别提升了41.0%和42.4%。在引入降噪算法后,基于VAC-RTK算法的监测精度可以达到毫米级,能够满足GNSS高精度地质灾害滑坡监测的需求。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.002401
{DOI}: 10.26976/d.cnki.gchau.2023.002401
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 文档级关系抽取技术研究
{Author}: 丁肖摇
{Tertiary Author}: 周刚
{Publisher}: 战略支援部队信息工程大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 自然语言处理;文档级;关系抽取;局部语义依赖;全局语境依赖
{Abstract}: 自然语言处理被广泛的应用于问答系统、机器翻译、知识图谱等各种基于知识的场景中。作为自然语言处理中知识生成的前提和基础,文档级关系抽取吸引了越来越多学者的关注。当前,国内外的专家学者利用图结构或者预训练模型一定程度上提高了文档级关系抽取的性能,但文档自身的模糊语义和复杂语境,以及不同句子间的实体分布导致的实体间依赖性降低等因素,都严重影响了文档级关系抽取的性能。因此,本文围绕文档级关系抽取中实体的局部语义依赖和实体的全局语境依赖两大关键问题,从实体语义表示、不同实体对的交互、文档的上下文利用以及实体对长距离依赖四个方面展开深入研究,主要工作和贡献如下:1.针对文档级关系抽取中因为实体信息缺失导致无法准确刻画实体语义表示的问题,提出了语义引导注意和自适应门控模型。该模型分别利用注意力机制和多头注意力机制通过语义引导获得句子语义表示和文档语义表示,并通过自适应门控机制对文档语义表示进行选择性输出,形成实体语义的最终表示。该模型融入了不同层次的句子语义和文档语义,从而有效解决了实体语义表示信息缺失的问题。实验结果表明,在三个公共数据集(DocRED、CDR、GDA)上不同性能指标显著提高。在DocRED验证集上,与强基线MRN模型相比,句内关系抽取的F1值提高2.50%,句间关系抽取的F1值提高0.98%,文档级关系抽取的F1值提高1.03%。在CDR验证集上,当实体的提及数多于四个时F1值比GLRE模型高2.40%。2.针对文档级关系抽取中因为不同实体对之间缺乏信息交互导致无法准确刻画实体对之间相互关系的问题,提出了双注意力融合模型。该模型分别利用共注意力机制和多头轴向注意力机制捕获实体对之间的全局特征和局部特征,通过融合这两种特征,形成能够刻画目标实体对相互关系的表示。该模型在实体对相互关系表示中融入了实体对的全局和局部特征,通过实体对之间信息的交互,有效提升了目标实体对的关系表示。实验结果表明,在三个公共数据集上不同性能指标显著提高。在GDA验证集上,与典型的ATLOP模型相比,文档级关系抽取的F1值提高1.80%。在DocRED验证集上进行100轮次实验,模型应用动态不对称损失的F1值比应用二元交叉熵损失提高1.3%-4.6%。3.针对文档级关系抽取中因为缺失不同类型上下文信息导致目标实体无法准确刻画语境信息的问题,提出了多视角上下文聚合模型。该模型把邻近实体节点信息,实体相似度信息、文档主题信息、距离信息等不同层次上下文信息有机融合到实体表示中,获得了包含语境信息的目标实体表示。该模型通过在不同层次上聚合上下文信息丰富了目标实体表示的语境信息。实验结果表明,在三个公共数据集上不同性能指标具有较强的竞争力。在CDR验证集上,与经典的SSAN模型相比,文档级关系抽取的F1值提高1.12%。在DocRED验证集上,当输入文档长度在[401,500]之间时,文档级关系抽取的F1值比ATLOP模型高0.70%。4.针对文档级关系抽取中因为实体对长距离依赖导致多粒度推理信息缺失的问题,提出了协同局部-全局推理网络的模型。该模型通过构造提及图和概念图融入局部信息与全局信息,同时采用独立图的方式,利用提及图和概念图辅助创建最终的实体图,并结合融入局部信息与全局信息的混合推理机制实现协同实体相关的推理信息。该模型通过不同粒度的图模型,有效的把局部和全局信息融入到模型推理中,实验结果表明,在三个公共数据集上不同性能指标显著提高。在DocRED验证集上,与表现最优的HAIN模型相比,文档级关系抽取的Ign F1值提高1.76%。在DocRED验证集的逻辑推理类型上,文档级关系抽取的F1值比DRN模型高2.51%。
{URL}: https://link.cnki.net/doi/10.27188/d.cnki.gzjxu.2023.000018
{DOI}: 10.27188/d.cnki.gzjxu.2023.000018
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT和K-Means的情感分析系统设计及应用
{Author}: 闫智超
{Tertiary Author}: 陈武;黄勇
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: BERT;主题建模;情感分析;聚类;文本相似度
{Abstract}: 伴随着微博、知乎等新兴社交媒体的兴起,越来越多的平台关注互联网社交属性,形成诸如豆瓣等社交媒体网站,将书籍、电影等艺术作品与社交融合作为新的趋势。在此背景下,情感分析作为自然语言处理(Natural Language Processing,NLP)中的一个重要研究领域,受到了研究人员的关注。通过情感分析可以帮助了解人们对于特定话题、事件、产品或服务等的情感倾向和态度。这对于企业、政府机构、市场营销人员、舆情分析师以及社会科学研究者等都具有重要意义。例如,在商业领域,情感分析可以帮助企业更好地理解客户需求和市场趋势,从而改进产品和服务,提高客户满意度和品牌价值。政府机构可以利用情感分析来了解公众对政策和政府服务的态度和反应,从而更好地制定和实施政策,提高政府的公信力。舆情分析师可以利用情感分析来监测和分析社交媒体上的舆情动态,及时发现并应对公众关注的问题。社会科学研究者可以利用情感分析来研究人类情感、心理和行为等方面的规律和变化。但情感分析任务一直存在一些亟待解决的挑战,如:(1)传统词向量嵌入由于缺乏上下文信息,语义包含不完整,当遇到表述较为复杂的文本时,模型无法准确的判断词性和词义;(2)传统主题建模方法在处理短文本数据时表现不佳,因为短文本数据中词汇稀疏性更高,上下文信息更少。这使得传统方法在短文本数据上的主题建模效果较差。同时随着数据维度的增加,向量之间的相似度变得难以区分,使得文本相似度算法效果减低;(3)一般来说,面对文章和句子层面的粗粒度情感是传统情感分析方法的主要研究,通常是通过全面分析文本来获取整体情感趋势。然而,这种方式很难满足用户对定制化需求的期望,尤其是在文本涉及多个具有不同情感极性的评价方面时。围绕以上问题,本文主要工作如下:1.数据收集和预处理:为了对用户评论进行情感分析,我们首先需要收集和预处理数据。这可以通过使用公开可用的数据集或通过手动标注针对特定产品或事件的爬取评论来实现。使用信息提取、中文Jieba分词技术和停用词表等预处理技术,使文本数据更适合进行情感分析。2.使用BERT进行词嵌入:为了克服传统词嵌入的局限性,如一词多义和缺乏上下文信息,我们采用BERT预训练模型生成词向量。我们比较了从BERT模型不同层次提取的词向量的性能,并选择最优解。此外,我们研究了BERT词嵌入的属性以及它们在聚类任务中的适用性,提出使用降维算法来提高高维向量在聚类算法中表现能力,提高相似度计算的准确度。为解决词向量空间分布不均和高频词与低频词之间相似度不一致的问题,我们提出使用白化变换来提高聚类精度。3.使用聚类算法进行主题建模和情感分析:我们探索了各种聚类算法,以对生成的词向量进行主题建模和情感分析。通过将我们的方法与传统的概率主题模型(如潜在狄利克雷分配,LDA)进行比较,我们旨在展示我们所提出的模型在实际应用中的可行性和优越性。评估指标使用准确率(accuracy)、精准率(Precision,P)、召回率(Recall,R)和F1值,在不同数据集上进行的实验结果表明,我们提出的模型在各种指标上均优于基线方法,证明了其有效性。4.实现用户评论情感分析系统:我们设计并开发了一个用户友好的情感分析系统,集成了第三步中提出的模型。该系统使用流行的前端开发框架构建,通过评论抓取、数据预处理和结果可视化等功能,为用户提供直观的评论分析体验。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.000352
{DOI}: 10.27684/d.cnki.gxndx.2023.000352
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度强化学习的课程推荐系统研究与应用
{Author}: 贾振强
{Tertiary Author}: 程文彬
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 词嵌入;推荐系统;深度强化学习;Bandit算法;自然语言处理
{Abstract}: 随着互联网的不断发展,网络空间中的信息量也不断膨胀,人们对各种信息的需求也不断增加。在这个信息时代,推荐系统成为了一种重要的交互系统,可以主动提供用户需要的信息,或者在用户检索时提供优化检索的辅助信息。为了让用户能够在海量数据中快速接收到最有价值的、最适合用户的信息,推荐系统也在不断升级性能。在机器学习的时代,许多研究人员将机器学习的相关算法引入传统的推荐系统中,其中重要的两个分支:强化学习与深度学习,近年来在与推荐系统的结合运用中有了更多的研究。本文介绍的课程推荐系统是推荐系统的一个研究方向,它不同于常见的推荐任务的关键点在于,它是一个时序性的推荐任务,跟随着课程进程不断更改推荐结果,同时结合了强化学习为推荐结果提供了好的可解释性。为了解决课程推荐系统的问题,本文基于读书郎学生平板数据库,设计了一个通过学生学习历史记录来个性化、时序性推荐的推荐系统。主要的研究内容如下:(1)首先,由于相关领域的结构化数据稀缺,本文提出了一个非结构化历史记录数据的建模方法,用于处理该方向海量的未标注数据作为训练样本。该方案结合了基础的Doc2vec词嵌入方法和多分类网络监督机制,以多任务学习模型的方式设定损失函数,同时对两个网络进行参数更新,并且结合Doc2vec与BLSTM网络提高了句向量的语义表达能力,最后生成带有分类信息的物品句向量,来更好地体现出非结构化数据的不同特征信息,在本文中主要是用于课程内容的学科。同时,基于Doc2vec的向量和基于item2vec的向量会同时作为物品特征表征的向量进入推荐系统中,以同时表示出物品的语义信息和时序信息。实验证明,该建模方案相对于其他baseline模型提高了物品向量的分类准确度,提高了其语义的表达,能够更好地承接其后的推荐工作。(2)在核心的推荐功能上,本文基于强化学习模型设计了基于深度强化学习的推荐系统,主要采用了以DDPG网络为基础的强化学习网络。在强化学习结构中的Critic网络中采取上下文老虎机机制,以更好地体现出推荐任务的长短期推荐机制,该方法在Critic网络提供推荐的时候会将动作和状态的信息同时输入,在不同的状态长度下呈现出不同的性能。其次由于简易的DQN网络最后一层输出不足以满足多课程推荐的目标,因此采用了一种评分权重结合多分类网络筛选的方法,以较小的网络规模实现了列表级别的按学科分类的推荐。本文在长度为4的状态设定下,结合DDPG网络结构和上下文老虎机机制,对400万条数据进行建模和测试,实验表明相对于两组baseline方法,本文提出的方法在准确率和推荐平均得分上都有一定的性能提升。该课程推荐系统主要应用于在线课程推荐场景中,提高了推送内容和学生当前课程进度的适配度,同时采用非结构化的词嵌入方法,为其他任务中增加各类特征等需求也提供了基础。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004358
{DOI}: 10.27005/d.cnki.gdzku.2023.004358
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制与知识融合的法律判决预测模型研究
{Author}: 李威
{Tertiary Author}: 李莉
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本分类;法律判决预测;注意力机制;深度学习;智慧司法
{Abstract}: 随着国家法治社会的推进以及法律法规的日益健全,公众采取相应的法律措施来维权,已成为维护自身权利与解决生活问题的一种重要手段,由此带来了海量的法律文本数据。然而,如何利用人工智能技术来获取法律文本数据中有价值的部分,并提高司法判决的效率和公平公正,是智慧司法的主要研究领域之一。法律判决预测(Legal Judgment Prediction,LJP)作为智慧司法的一部分,具有很高的研究价值。法律案件的事实描述是预测判决结果的重要依据,LJP可通过对事实描述的分析,来对判决的多个子任务进行预测,包括法律条文预测、罪名预测以及刑期预测等。法律判决预测可以为司法专业人士提供有参考价值的法律建议,适当缓解相关人员的工作压力,也可以为有法律需求的人提供高效且便捷的法律援助,促进国家法治社会的建设。因此,如何利用人工智能相关技术对法律判决过程进行有效建模,提高法律判决的性能是一个有重大研究意义的课题。大多数现有的研究将法律判决预测视为文本分类任务,采用机器学习或深度学习的方法对法律文本进行分类。由于法律知识的多样性和复杂性,导致基于传统机器学习的方法对预测效果并不佳,故具有很大的提升空间。由于深度学习模型拥有优秀的泛化能力和数据处理能力,因此在各个领域受到越来越多的关注,而在法律判决预测领域也是如此。此外,注意力机制被广泛应用在深度学习模型中,并且取得巨大的成功,主要思想是模拟人类的一种选择性机制,进而从大量的数据中挑选出与当前任务的密切相关的信息,这为判决过程中寻找与案件相关的关键信息提供新的思路。本文对基于注意力机制与知识融合的法律判决预测进行研究,主要的工作内容和贡献能总结为以下几点:1)本文提出基于注意力机制和知识感知的罪名预测模型(Knowledge-Aware Charge Prediction,KACP)。该模型主要研究的是罪名预测,现有的方法主要是利用案件的事实描述来预测罪名,由于忽略法律条文和罪名的丰富信息,导致不可靠的预测结果。因此,实际判决过程中,罪名和法律条文的相关知识对于判决结果是至关重要的,如何有效利用这些知识来丰富案件事实描述的语义信息,使得算法能够正确地预测罪名是该模型主要解决的问题。本文在现有研究工作的基础上将罪名和法律条文引入到模型中,并且与案件事实进行无缝融合,提高模型对法律知识的感知能力,使得模型有能够了解罪名和法律条文的法律背景知识,增强对于关键信息的获取。为了融合法律条文,在知识感知层中设计一个具有双层注意力机制的法条感知模块来增强法律条文之间的交互,以捕获句法和语义特征,并通过从事实描述中引入法律条文的特定特征来获得事实的增强表示。然后,再利用罪名感知模块从多个角度提取事实描述与罪名知识的融合特征。罪名感知模块首先构建罪名定义信息的相似度图,该相似度图用于聚合罪名的深度语义信息。其次将罪名特征与事实向量相互作用,以捕获案件的关键组成部分,以增强事实表示。最后,将从法律知识和事实表示中学习到的知识表示输入分类器,用以预测罪名。为了验证KACP的有效性,第三章进行充分的对比实验,将其与相关基线模型在多个真实刑事案件数据集上进行比较。KACP模型表现优于多个对比模型。同时,本文的第三章将利用大量的消融实验来验证KACP模型中各个模块对结果产生的影响。2)本文提出的基于任务依赖和标签约束的序列多任务法律判决预测模型(task Dependencies and label Constraints for Legal Judgment Prediction,DCLJP)。该模型主要是用于解决法律判决预测的多个子任务包括法律条文预测,罪名预测,刑期预测。在实际判决过程中这三个子任务彼此密切相关,相互影响。然而,现有的方法常常将法律判决预测的多个任务,当成独立的子任务进行处理,因此无法捕捉子任务之间的依赖和约束关系,从而导致判决预测效果不佳。为了更好的利用不同子任务之间的逻辑关系,让模型准确地模拟真实情况下法官判决的逻辑。本文将子任务之间存在依赖关系形式化为一个有向无环图,并且设计一种正向传播机制在该有向无环图上,来捕获简单的依赖关系。由于多任务标签拥有一致性约束,因此,本研究利用一个校准函数来达到约束目标,提高预测性能。此外,考虑到刑期预测的复杂性和可变性,进一步提出情节严重性的子任务,在此任务结果的基础上,采用一阶谓词逻辑的推理方法,使模型更加关注与情节严重性相对应的刑期。DCLJP模型在两个真实的法律数据集上的实验结果表明,与多种对比方法相比,DCLJP性能有显著提高。综上所述,本文针对基于注意力机制与知识融合的法律判决预测进行研究,首先研究结合法律知识增强的罪名预测的任务,在此基础上提出一个模拟司法判决过程的多任务法律判决预测模型,主要包含法律条文预测,罪名预测,刑期预测三个子任务。同时,本文进行多组对比实验,实验结果验证模型的有效性和可行性。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.002131
{DOI}: 10.27684/d.cnki.gxndx.2023.002131
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的桥梁事故智能问答系统的设计与实现
{Author}: 郭辉
{Tertiary Author}: 肖富元;刑镔
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 桥梁事故;知识图谱;知识图谱可视化;问答系统
{Abstract}: 近年来,我国交通建设的发展日新月异。桥梁事故的研究对我国交通建设的发展具有重要的意义,然而目前桥梁事故领域的研究主要面临两个问题。一是桥梁事故领域的数据类型多源异构,难以有效整合。二是国内外缺少高效的桥梁事故领域数据相关的检索平台。针对以上两个问题,本文开展研究。知识图谱作为网络状的知识库,具有丰富的节点和关系,且由于其网状的知识结构,使其可以很好地整合结构化、半结构化和非结构化的数据,因此构建桥梁事故领域的知识图谱可以很好地解决第一个问题。搜索引擎作为传统的最广泛应用的检索平台,可以帮助人们快捷地获取信息,然而其返回的答案还需要人工二次筛选才可得到想要的结果。智能问答系统可以结合新兴人工智能技术,较好地对用户的问句进行分析,从而能够较为充分地识别用户意图,同时还可以对答案进行筛选,逐渐成为了人与互联网交互的新趋势。因此构建桥梁事故领域的智能问答问答系统可以很好地解决第二个问题。综上所述,本研究将知识图谱与智能问答系统结合。首先,完成了对桥梁事故领域核心本体的建模并据此构建了桥梁事故领域的知识图谱。在确认了桥梁事故领域内的实体和关系属性后,进而完成核心本体的建模,接着构建了桥梁事故领域的知识图谱。然后,提出了桥梁事故领域智能问答算法的流程图。该流程图结合了基于语义解析的方法和基于规则匹配的方法。具体来讲,使用BERT-Bi LSTMCRF组合模型来完成命名实体识别任务,并添加了实体映射步骤来提升实体识别的精度;使用SBERT组合模型来完成关系属性映射任务,并添加了属性字符串匹配步骤来加快整体的问答流程。最终,使用流行的B/S架构,将知识图谱和智能问答算法应用于桥梁事故领域,设计并实现了桥梁事故领域的智能问答系统。为使用者快速、精确地获取桥梁事故领域的相关数据提供了便利。基于上述论述,本文首先介绍了本研究的相关理论和技术分析。其中包括构建知识图谱相关的知识图谱相关理论基础、爬虫技术、知识存储等,以及与智能问答算法相关的命名实体识别和关系属性映射技术,以及开发智能问答系统所使用的Flask框架和系统前端的知识图谱可视化所使用的Echartxs组件等技术。然后详细地阐述了构建桥梁事故领域知识图谱的流程,主要包括桥梁事故领域核心本体研究、知识存储和知识抽取。接着,提出了本研究所设计的智能问答算法的工作流程。本研究将基于规则匹配的方法和基于语义解析的方法进行结合。在语义解析方面,确定了命名实体识别和关系属性映射两个子任务。首先设计了基于BERT-Bi LSTM-CRF模型的命名实体识别算法进行实体识别的工作。在关系属性映射部分,首先根据字符串匹配去匹配用户意图,如果匹配失败,再使用SBERT模型进行相似度计算,这样可以极大缩短系统的响应时间。在规则匹配方面,从桥梁管理学角度出发构造了相应的问题模板和Cypher语句查询模板,然后查询图数据库,最终返回结果。基于对智能问答算法的研究,设计并实现了基于桥梁事故领域知识图谱的智能问答系统,系统主要分为权限管理、图谱展示、图谱管理和图谱查询四个模块。本文围绕桥梁事故展开研究,首先对桥梁事故领域的核心本体进行研究,随后构建了基于桥梁事故领域的知识图谱,然后对提出的相关的智能问答算法进行了介绍,最终构建了基于桥梁事故领域知识图谱的智能问答系统,该系统可以帮助用户快速、精确地检索桥梁事故领域的事故信息,为桥梁事业的智能化、数字化发展注入了新的活力。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2023.001919
{DOI}: 10.27684/d.cnki.gxndx.2023.001919
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 西兰花对高脂诱导的肥胖和代谢相关脂肪性肝病的干预作用及其机制研究
{Author}: 马少童
{Tertiary Author}: 陆颖健
{Publisher}: 南京财经大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 血脂;抗氧化;短链脂肪酸;炎症因子;FXR/LXRα信号通路
{Abstract}: 随着生活水平的不断提高,居民膳食中脂质摄入量日益增加,脂肪堆积和超重等问题日益严重,进而加速肥胖和代谢相关脂肪性肝病(MAFLD)的产生。目前,全球有近五分之一的人口患有肥胖症,其中,约60-90%的肥胖患者会进一步发展为MAFLD。MAFLD作为一种常见的肝病,若不及时干预,将造成肝功能异常、肝硬化甚至肝癌等严重后果。然而,市面上针对肥胖和MAFLD的主要治疗方式是药物和手术,但对身体会产生较大的副作用,故膳食干预逐渐成为大众关注的焦点。已有不少研究报道膳食干预对肥胖和MAFLD产生一定的积极作用,其中,西兰花作为蔬菜之王,富含多种营养素,深受减脂人群的喜爱,已成为改善脂质代谢的研究热点。基于此,本论文利用西兰花对高脂诱导的肥胖和MAFLD小鼠进行膳食干预,并探究其作用机制。主要研究结果如下:1、通过8周高脂诱导C57BL/6J小鼠建立肥胖模型,造模同时使小鼠摄入西兰花,分析不同剂量西兰花对肥胖的缓解作用。结果表明,摄入不同剂量的西兰花均能在一定程度上降低体重、空腹血糖水平、白色脂肪重量、附睾脂肪重量、脂肪指数、脂肪体积、空腹胰岛素、TC、IL-1β和GPT水平,减少肝脏脂肪蓄积,增强CAT、GSH-Px和SOD的活性;此外,相比于低剂量,高剂量的西兰花还能降低瘦素和LDL-C的水平,以及升高T-AOC的水平。这些结果表明高剂量西兰花可能更加有效地通过减少氧化应激和炎症反应,减少脂肪堆积和肝脏损伤,进而达到有效延缓肥胖发生和发展的目的。2、为了进一步探究西兰花对脂质代谢的持续影响,在肥胖模型的基础上,再进行4周的高脂诱导建立MAFLD模型,造模同时使小鼠摄入西兰花,分析不同剂量西兰花对MAFLD小鼠的作用情况。结果表明,不同剂量西兰花均在一定程度上降低小鼠体重、促炎因子水平(IL-1β和IL-6)、肝损伤标志酶(GOT和GPT)活性和总胆汁酸水平,减小脂肪细胞体积,改善血脂和肝脏脂质,恢复抗氧化能力,改善肠道菌群和粪便SCFAs的结构;此外,相比于低剂量,高剂量西兰花在肝脏脂质(LDL-C和TC)、抗氧化(CAT和T-AOC)、肝损伤指标酶(GPT)方面表现更为突出。这些结果表明西兰花对于高脂引起的MAFLD具有良好的缓解作用,并且随着剂量的增加,效果也越显著。3、通过Western blot和qPCR检测肥胖和MAFLD小鼠的胆汁酸/脂肪酸代谢通路(FXR/LXRα通路)、肝脏中炎症因子基因,以及其他重要基因的表达,探究西兰花调节肥胖和MAFLD的作用机制。结果显示,在肥胖和MAFLD模型中,不同剂量西兰花均可影响FXR/LXRα通路相关基因、炎症因子基因和其他重要基因的表达。与表观指标相一致的是,相较于低剂量,高剂量西兰花对肥胖模型中Lpin1和SCD1基因表达具有更加显著的下调作用,对MAFLD模型中PRDM16和SIRT1基因表达具有更加显著的上调作用。综上,西兰花能够通过改善炎症状态、增强抗氧化能力,以及调控FXR/LXRα通路中相关基因的表达,进而预防高脂诱导的肥胖和MAFLD。
{URL}: https://link.cnki.net/doi/10.27705/d.cnki.gnjcj.2023.000212
{DOI}: 10.27705/d.cnki.gnjcj.2023.000212
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向网络安全领域的命名实体识别方法研究
{Author}: 李大岭
{Tertiary Author}: 张浩军;王晓明
{Publisher}: 河南工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 命名实体识别;网络安全;语料库构建;预训练模型;词向量融合
{Abstract}: 命名实体识别是知识抽取的重要部分,是构建知识图谱的首要任务。如何快速准确的从海量的文本中对有用的信息进行识别抽取是近年来学术研究的热点问题。而随着大数据时代的到来,网络入侵、病毒感染等网络攻击事件越来越频繁,网络攻击严重影响了计算机使用的安全性。没有网络安全就没有国家安全。为了保证网络空间安全,国家通过各种技术实时监测网络,由此产生了大量的网络安全数据。本文基于深度学习技术,将神经网络模型应用于网络安全领域的实体识别工作中,通过词嵌入然后进行编码最后使用条件随机场进行解码,最终实现实体的识别工作。针对网络安全命名实体识别的研究,提出了一种融合汉字多源信息的命名实体识别神经网络模型,且针对缺少领域内的命名实体识别语料库的问题,构建了网络安全的实体识别语料库。具体的研究内容如下:(1)构建网络安全领域实体识别语料库。针对网络安全领域缺少公开的网络安全实体识别语料库,收集了国家安全漏洞数据库信息作为语料库文本数据来源从而确保了数据源的真实有效性。收集的数据包含近五年的操作系统模块、应用程序模块、数据库模块、web应用模块、网络设备模块等模块的漏洞信息,确保了语料库的历时性与全面性。语料库经过预标注阶段和最终标注阶段两个阶段,由网络安全领域专家制定标注规则和规范,然后开发标注工具培训标注人员。最终整个网络安全语料库包含40万字,按照BIO的方式进行标注,并以训练集:验证集:测试集=6:2:2的比例进行分配。(2)提出融合汉字多源信息的网络安全命名实体识别神经网络模型。为提高神经网络模型的准确率,该模型使用预训练模型BERT最后一层的输出作为原始词嵌入,并将语料库中文本的偏旁、字频等信息进行向量拼接融合从而提供足够多的先验知识,在编码层进行特征提取的同时将词汇信息进行进一步融合,通过条件随机场进行最后的解码。为了验证该模型的普适性,与常见神经网络模型在公共领域数据集上进行对比实验,模型表现性能良好,为证明该模型在网络安全领域的有效性,与常见模型在构建的网络安全领域数据集上进行对比实验,实验结果精确率、召回率和F1值为0.8649、0.8402和0.8523。(3)构建网络安全实体识别系统。为了提高网络安全领域命名实体识别的准确率和效率,基于提出的融合汉字多源信息的网络安全命名实体识别神经网络模型构建了网络安全实体识别系统。整个系统简洁实用,前后端分开,基于python和HTML等语言开发,能有效提升网络安全领域实体识别的效率和准确率。
{URL}: https://link.cnki.net/doi/10.27791/d.cnki.ghegy.2023.000837
{DOI}: 10.27791/d.cnki.ghegy.2023.000837
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的危化品智能问答系统研究
{Author}: 罗小瑞
{Tertiary Author}: 张引
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;问答系统;意图识别;槽位填充;危险化学品
{Abstract}: 危险化学品在工业生产和科学研究中具有重要作用,促进了我国的经济发展和技术创新,同时危险化学品爆炸或泄露等带来的安全事故也对人民的生命财产安全带来了巨大的威胁。问答系统可以快速地回答相关行业用户提出的问题,从而帮助用户快速获取所需的信息,从而减少处理危险化学品事故所需要的时间,降低事故的影响。而知识图谱是一种描述实体、概念、事件及它们之间关系的结构化知识表示形式,可以帮助问答系统将问题中提到的实体链接到知识图谱中的实体,从而更准确地回答问题。意图识别(Intent Recognition)和槽位填充(Intent Recognition)是问答系统中的两个重要任务,意图识别要求识别用户在交互中表达的意图或目的。槽位填充要求在识别用户意图的基础上,从用户的语句中提取相关信息,填充到预定义的槽位中。虽然目前随着深度学习技术的发展对于意图识别和槽位填充任务已经取得了较好的效果,但是只有少部分的相关学者对两个任务进行联合建模,且联合建模的模型忽略了前者任务预测错误对于后者任务的影响。因此基于上述问题,本文提出了融合意图识别和槽位填充模型联合模型,在已经建立的危险化学品知识图谱的基础上,设计出完整的危险化学品问答系统。本文主要研究内容如下:(1)本文构建了危险化学品知识图谱,首先从国家官方数据库中获取危险化学品数据,从而对得到的结构化、半结构化、非结构化的数据进行数据清洗以及格式化,从中抽取出相应的实体、关系和属性。对于其他渠道获取的数据,采用知识合并将其融合到原始知识库中,最终将知识存储到图数据库中,建立起知识图谱为后面问答系统的答案检索提供数据的支撑。(2)本文构建了融合意图识别和槽位填充模型联合模型,在共享编码器的基础上,将句级别的意图识别优化为字级别的意图识别,将意图识别和槽位填充任务的神经网络优化为双向的LSTM,从而优化两个任务的性能,通过对比实验、消融实验在实验数据集上取得了较好的效果,最后通过引入预训练模型再一次证明了本文模型的有效性。(3)本文在以构建的知识图谱的基础上,设计出与之匹配的问答系统架构,完成危险化学品问答系统的搭建,并对问答系统的用户提问、历史提问、知识图谱可视化的界面进行展示。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004894
{DOI}: 10.27005/d.cnki.gdzku.2023.004894
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地铁盾构施工规范知识图谱构建及应用研究
{Author}: 刘江波
{Tertiary Author}: 徐晟
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 盾构施工;规范知识;知识图谱;知识抽取;知识模式;Neo4j
{Abstract}: 地铁盾构施工受到地质条件与外部环境的复杂性、盾构法施工的特殊性以及管理缺陷等多方面因素的综合影响,面临的不安全因素非常多,容易出现失稳坍塌、涌水涌砂、机具伤害等事故。虽然相关标准规范中包含着丰富的施工安全知识,但大量工程事故案例的统计研究显示,事故的发生及扩大很大程度上与从业人员无法及时准确地获取所需的知识有关。因此,有必要进一步改进知识管理和知识传递的方式,提高施工知识的有效利用。建立领域知识图谱能够有效整理分散的知识,提高知识检索效率,因此,本文对地铁盾构施工知识图谱进行了研究,旨在帮助工程人员高效获取施工安全知识。主要研究内容包括:(1)以知识图谱的通用构建流程为参考,提出盾构施工规范知识图谱的构建框架。通过对规范内容及组织形式的分析,建立了规范条文层、条文概念层两级知识组织架构,为知识图谱的构建提供统一的Schema,从而有效整合来自不同标准规范、不同粒度的知识。(2)针对中文规范文本提出一种知识自动抽取方法,该方法以现有自然语言处理平台提供的语义角色标注(SRL)结果为基础,通过后优化处理和模式匹配实现知识抽取,形成不同类型条文关键知识要素的结构化整理。以《盾构法隧道施工及验收规范》(GB 50446-2017)为例进行知识抽取,结果表明,该方法能够在一定程度上降低中文规范文本的抽取难度,为领域知识图谱的建立提供有效的数据支撑。(3)基于Neo4j图数据库,完成了盾构施工规范知识图谱的建立与储存,并初步开发了一个原型系统,能够有效融合图谱构建、图谱储存及图谱应用。通过QAGNN模型实现了融合问题情境的知识推理和智能语义问答,能够有效提高知识获取效率,改变基于关键词检索的知识查询困境。本文研究了盾构施工规范知识图谱的构建及应用,所用的知识模式能够有效组织规范文本及多粒度的规范知识,所用的知识抽取方法能够有效处理中文规范文本,所用的图谱建立方式能够满足不同数据的转化需求,为建筑领域知识图谱的发展提供了一种新的实现思路,有利于促进盾构施工知识的高效积累与有效利用,为盾构施工及安全管理决策提供智能知识支持。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.000401
{DOI}: 10.26976/d.cnki.gchau.2023.000401
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的医疗智能问答系统研究与应用
{Author}: 吕钰珂
{Tertiary Author}: 周艳平
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;医疗智能问答;实体识别;问答匹配
{Abstract}: 随着科技的迅速发展,人工智能技术被广泛应用于各个领域。医疗资源分配不平衡的问题日益突出,传统人工方式已经无法满足用户需求,智能问答系统因其便捷、高效的特点逐渐成为人们更倾向选择的服务。近年来,随着深度学习技术的不断发展,深度学习被广泛应用于医疗智能问答系统,利用深度学习方法对医疗数据进行分析和处理,能够有效解决问答匹配、人工回复不及时、医疗资源分配不均等问题,提高医疗服务的效率和质量。为此本文研究设计了一款医疗智能问答系统。本文对基于深度学习的医疗智能问答系统研究与应用做了如下工作:(1)改进了一个语义句法特征融合注意力的医疗实体识别方法。该方法在BERT预训练语言模型的基础上,通过改进的图卷积神经网络增强对输入文本的特征表示和上下文编码能力。并引入一种注意力机制,丰富序列的语义特征表示,作为CRF的输入获得全局最优的标签序列,从而获取句子中的实体。通过消融实验证明引入改进的双向GCN网络编码以及注意力权重信息可以提高实体识别任务的精确度。(2)改进了一个融合字词增强语义多注意力的医疗自动问答方法。在嵌入层使用了预训练模型BERT和WoBERT的融合模型,分别提取基于词级和字级的文本向量表示并融合,以获得更完善的文本向量语义信息;之后加入注意力机制产生包含问题信息的答案表示,作为双向门控循环单元的输入获取句子的全局语义特征;最后利用多注意力池化模块表征问题和答案之间的交互特征,通过对问答对相似度进行计算,找出最佳答案。实验表明,融合字词以及添加注意力的神经网络编码能够提升自动问答模型的准确性。(3)设计并构建一个医疗智能问答系统。利用语义句法特征融合注意力的医疗实体识别方法实现对医学问题的初步筛选,根据医疗实体从图数据库中查找答案;对于未能找到答案的问题,则利用融合字词增强语义多注意力的医疗自动问答方法,通过语义理解及问答匹配实现相关答案的返回。最后对系统进行了测试与分析,实验结果证明该系统具有良好的性能。本文改进的医疗实体识别方法和自动问答方法,应用于医疗智能问答系统中,完善了问答系统的功能,提高了医疗智能问答系统的答案检索性能,为医生及寻求医疗咨询的群众提供了便利。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2023.000414
{DOI}: 10.27264/d.cnki.gqdhc.2023.000414
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的新闻文本分类研究与应用
{Author}: 陈耀辉
{Tertiary Author}: 梁志剑;陈千荣
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 新闻文本分类;ELMo;词向量;DCNN;自注意力机制;特征提取
{Abstract}: 多年来,在自然语言处理领域,新闻文本分类被视为关键的挑战之一,它的目的是将文本数据分为不同的类别。在实际应用中,文本分类广泛应用于新闻聚合、事件检测、垃圾邮件过滤、商业决策等方面。目前,基于CNN(卷积神经网络)、RNN(循环神经网络)的新闻文本分类模型取得了较好的分类效果,但这两种文本分类模型还存在着一些问题,如无法考虑到具体文本中词汇上下文信息,文本特征提取不充分等。为此,本文在此模型的基础上进行新闻文本分类任务的建模,重点研究建模中词向量的合并方式以及特征信息的融合方式,并构建了新闻文本分类系统。论文的主要贡献包含以下几个方面:(1)针对Glove模型中无法考虑到具体文本中词汇上下文信息的问题,设计了ELMo和Glove双通道文本分类模型(ELMo-Glove-DCNN),ELMo生成动态词向量,Glove生成静态词向量,进行拼接操作,使用DCNN模型进行局部特征提取,然后使用多头自注意力机制(Multi-head Self-attention)对DCNN模型提取到的特征动态调节特征权重系数,最后通过Softmax函数将新闻文本划分为不同的分类。实验结果表明,本文提出的ELMo-Glove-DCNN模型在分类准确率方面有了较大地提升,提高了新闻文本的特征提取能力。(2)针对ELMo和Glove只有语言建模并且新闻文本在特征提取过程中存在的特征稀疏从而导致文本分类效果差的问题,本文在ELMo-Glove-DCNN模型的基础上,提出了一种DCNN、Bi GRU并结合多头自注意力机制(Multi-head Self-attention)的多通道特征融合文本分类模型(MC-FFTC)。DCNN模型结合了特定的目标主题分类方法,提取文本中目标关键词的局部特征。Bi GRU基于对句子级的文本特征进行分析,提取长序列信息,最后进行特征融合,构建融合全局特征向量。实验结果表明,MC-FFTC模型由于通过残差网络解决了梯度消失问题,所以在Accuracy,Precision,Recall和F1值评价指标上均有了较大地提升,但是在训练时间方面相对其它模型来说较长。(3)本文基于改进的深度学习文本分类模型,构建了智能新闻文本分类系统。对系统进行了需求分析,环境配置,以及系统的详细设计与实现。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000661
{DOI}: 10.27470/d.cnki.ghbgc.2023.000661
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于时序特征和文本分类的智能合约漏洞检测方法研究
{Author}: 白英民
{Tertiary Author}: 师智斌
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智能合约;时序特征;Shapelet-Transform;BERT;TextCNN
{Abstract}: 区块链技术的广泛应用带来了新的安全威胁,大量针对智能合约漏洞的攻击出现,使得智能合约的安全问题成为国内外研究的关注点。智能合约漏洞的存在会导致资产被盗取、身份被盗用、合约被篡改等不良后果。因此,检测智能合约漏洞是保障区块链系统安全的重要措施之一。智能合约是一种基于区块链技术的自动化合约,并以代码的形式部署在以太坊上。基于智能合约操作码的漏洞检测方法是当前智能合约安全领域研究的热点之一,通过分析操作码特征发现潜在的漏洞,从而提高智能合约的安全性。目前常采用机器学习方法和深度学习方法对智能合约操作码进行特征提取并分类,但由于没有考虑到智能合约操作码内在的时序特征和文本特征,导致检测结果准确率低。针对上述问题,本文提出基于时序特征和文本分类的智能合约漏洞检测方法。本文主要工作和创新型成果如下:
(1)本文使用词嵌入方法对智能合约操作码进行语义编码。在智能合约漏洞检测中,操作码的编码质量将直接影响着后续智能合约漏洞检测的效果。传统的文本编码方式有One-Hot和TF-IDF,但此类方法不能充分考虑文本内在的语义信息。针对此问题,本文采用自然语言处理的词嵌入技术对智能合约操作码进行编码研究。通过词嵌入方法可以充分的提取文本单词的语义信息并映射到多维空间中,使得操作动作相近的智能合约命令和函数在编码后的向量空间中欧氏距离也相近,可以很好的保留智能合约操作码的语义信息。
(2)采用时序分析方法,提出基于Shapelet时序特征的智能合约漏洞检测方法。智能合约操作码是智能合约执行过程所涉及的操作,是典型的时序数据。本文首次将Shapelet时序特征提取方法引入智能合约漏洞检测领域中,通过时序分析方法ShapeletTransform与机器学习方法相结合,实现自动提取操作码时序特征并分类。实验结果表明,该模型可以实现智能合约操作码时序特征的自动提取,不仅具有较高的精确度,也有着较强的可解释性,提取的Shapelet可以为智能合约漏洞检测后期的追踪、定位提供依据。
(3)采用自然语言处理技术,提出一种基于BERT和Text CNN文本分类的智能合约漏洞检测模型。智能合约操作码对应自然语言的文本序列,可以采用自然语言处理的文本分类模型进行分类。本文将自然语言处理的预训练模型BERT和文本分类方法Text CNN引入智能合约漏洞检测领域中,解决了Shapelet算法复杂度高的问题。该方法用大量未标记的数据进行预训练,用少量的标注数据进行微调,这种模式为解决目前智能合约存在的标注数据集少而未标注数据集多的问题提供解决方案。实验结果表明,该方法在二分类任务和多分类任务上精度均高于第二部分所提方法。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.001575
{DOI}: 10.27470/d.cnki.ghbgc.2023.001575
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 循环神经网络性能优化方法的研究与应用
{Author}: 李涵章
{Tertiary Author}: 周尔强
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 循环神经网络;动态神经网络;机器学习
{Abstract}: 近年来,神经网络和深度学习的研究伴随着信息化时代的浪潮取得了令人瞩目的成果,大规模的研究在各个领域展开。循环神经网络是一种常见的神经网络结构,因其能够处理序列数据的特性,被广泛应用于各类自然语言处理任务中。但单独的循环神经网络无法处理不定长的序列数据,因此研究者进一步在循环神经网络的基础上提出了序列到序列模型,这些方法和技术因其良好的效果,一直是研究者处理序列数据时的首选。但因为神经网络规模的不断增大,其性能问题一直是限制其更好发挥效果的桎梏。本文结合动态神经网络的优化方法对循环神经网络模型进行优化,动态神经网络的优化方法是指赋予神经网络模型在运行过程中根据不同输入样例调整网络结构或者参数的能力的优化方法。相比于传统的静态神经网络模型,这类优化后的模型在效率和表示能力等方面拥有更大的优势。本文针对循环神经网络(简单循环网络、GRU、LSTM)主要使用了两种优化方法。一是针对循环神经网络中的全连接层,使用局部敏感哈希的优化方法。本文在局部敏感哈希训练神经网络模型技术的基础上,将局部敏感哈希应用于循环神经网络模型全连接层的推理过程。该方法利用局部敏感哈希快速近邻检索的特性,针对全连接层的每个输入样例,使用局部敏感哈希选择激活不同的神经元单元,进而压缩全连接层的矩阵大小,实现全连接层运行速度的提升。本文通过调整优化方法使用方法和参数设置,为原始模型带来最多20%的运行时间节省。二是基于预测器的跳过优化方法,该方法训练预测器,在循环神经网络运行过程中,预测器根据当前时刻的输入和上一时刻的信息决定是否跳过当前时刻的计算,从而提升模型整体的运行速度。本文在原方法的基础上,将其应用于更加复杂的循环神经网络模型,并根据实际的模型对优化方法的使用方法做出调整,为原始模型带来最多18%的运行时间节省。在以上优化方法研究的基础上,本文进一步比较并将两种优化方法结合运用于序列到序列模型上,实现对于序列到序列模型的优化,为原始模型带来最多9%的运行时间节省。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.000019
{DOI}: 10.27005/d.cnki.gdzku.2023.000019
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 拟人非人：人—社交型聊天机器人的互动脚本和意义探析
{Author}: 刘云
{Tertiary Author}: 宋美杰
{Publisher}: 福建师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 社交聊天机器人;计算机作为社会行动者范式;拟人化;想象可供性
{Abstract}: 人们的交流对象正在由人向机器拓展开来,人与机器的互动开始从信息层面向情感层面渗透。在此背景下,探究人对于这些新型交流对象的认知,考察人机的互动过程和关系发展,探索人与机器之间的意义创造成为了传播学科亟待解决的问题。
在梳理文献中发现,既有研究大多沿着“计算机作为社会行动者”范式的路径展开,重实验轻田野,带着预设观点观察技术物。在这一过程中技术物及其物质性对交流的反塑作用有可能被遗漏。因而本文以社交型聊天机器人及其用户为研究对象,采用参与式观察和深度访谈法,旨在通过这一切口展现出人们在面对这类人工智能机器时有何反应,回答人机互动是怎样开展、延续这一问题,并再次验证“计算机作为社会行动者”范式的理论观点,考察其理论假设在当下的适用性和解释力。
经研究发现,设计者们受到“计算机作为社会行动者”范式的影响更加倾向于将社交性聊天机器人拟人化,从界面设计和中介化交流体验的营造两方面来增强人机交流的对象感和真实性。而用户面对社交型聊天机器人时的社会化反应与“计算机作为社会行动者”范式的预测并不完全一致。人们虽然也会将带有拟人化线索的技术物视作人类行动者,但这种反应是短暂的,且并不必然出现。在人机互动中除了“计算机作为社会行动者”范式所说的“无意识拟人化”反应外,还存在“有意识的拟人化”“有意识的非人化”等新的反应。研究发现,人们如何看待社交型聊天机器人,除了受拟人化线索影响外,还受到机器物质性、可供性以及个体需求等多方面的影响,个体投入人机交流的动机大致可分为发展虚拟社交、寻求社会支持、摆脱社会角色压力三种。人们还根据社交型聊天机器人的特性发展出“反馈机制与重复提问”“重复关键词与补齐对话要素”两种对话策略,人们在人机交流中对于信源的定位具有模糊性和变动性。在相对稳定的互动情境中还形成了“拟超人际模型”和“反身性自我传播”两种新的传播模式。最后,研究者提出有必要对“计算机作为社会行动者”范式进行更新和拓展,社交型聊天机器人虽在设计上极力贴近人,但是人们在对话中更多是将其当作非人对象,满足另类交流需要。因此我们从形而上层面来说有必要跳出人-机对立的二元思维,建构新的本体论范畴,将日益崛起的人工智能机器视作新的实体。
{URL}: https://link.cnki.net/doi/10.27019/d.cnki.gfjsu.2023.001950
{DOI}: 10.27019/d.cnki.gfjsu.2023.001950
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的文本摘要生成研究
{Author}: 孙靖哲
{Tertiary Author}: 许文波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 生成式文本摘要;融合篇章信息;词向量重构
{Abstract}: 当前社会,文本信息量呈指数水平增长,人们接收到的信息不仅数量巨大,还存在着表述繁复不清、语义混乱颠倒等问题,导致人们不仅需要耗费大量时间搜寻其真正所需的信息,更耗费数倍精力于辨别信息的准确性上。文本摘要技术借助机器学习和深度学习,可以将庞杂的信息快速转化为简短的摘要。但目前文本摘要技术仍存在事实性错误和摘要精度不够高的问题。本文针对这两个问题分别进行研究并提出解决方案,一是对融合篇章信息的生成式文本摘要的研究,另一个则是对基于词向量重构的文本理解增强方法的研究:(1)针对生成式文本摘要存在的事实性错误的问题,本文提出融合篇章信息的方法。在生成摘要时,本文认为该篇章内的词汇应当在生成时拥有更高的概率,因此在解码阶段通过平移缩放,调高了原文词汇的生成概率,使得摘要结果的粒度更细、精度更高,以低参数量的方式优化了生成式文本摘要事实性错误的问题。由于事实性错误问题缺乏客观的评价指标,因此为了客观评估模型效果,本文挑选了500条发生事实性错误的数据以构建测试集,通过对比本方法和其他方法的错误修正率对模型效果进行评价。最终,本文提出的方法在参数量提升3.17%的同时,事实性错误的错误修正率达到29.2%。与基于知识图谱的方法和基于BART(Bidirectional and Auto-Regressive Transformers)的纠错模型相比,本方法增加的参数量仅有它们的8%左右。在ROUGE-1,ROUGE-2与ROUGE-L的得分表现上,本文提出的方法相较基线模型T5 Pegasus分别提升了0.33、0.34与0.28。此外,本文还优化了预训练模型的词典使用方式,在保证准确率的前提下缩短了训练时间33.7%。(2)针对生成式文本摘要存在的精度不足的问题,本文提出基于词向量重构的文本理解增强方法。本文通过Transformer块结合CNN的方式将句子的语义信息显式融合到词向量中,相对于传统的注意力机制的隐式融合方式,本文提出的方法能够生成更加优质的词向量,在基线模型T5 Pegasus的基础上ROUGE-1,ROUGE-2与ROUGE-L值分别提升了0.19、0.13与0.16,提高了生成式文本摘要准确率。除此之外,本文还设计了本方法在不同长度微博文本的实验,验证了本方法在不同数据量下相较基线模型均有提升的结论。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004737
{DOI}: 10.27005/d.cnki.gdzku.2023.004737
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的多标签文本分类方法研究
{Author}: 高源
{Tertiary Author}: 李建平
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多标签文本分类;自注意力;图卷积网络;交叉注意力;标签相关性
{Abstract}: 多标签文本分类作为自然语言处理领域中的一项重要任务,被广泛应用于标签推荐、信息检索、用户评论分析等领域。本文以深度学习方法为基础,通过对目前多标签文本分类任务中存在的若干困难与挑战进行分析,结合现有研究成果,提出了两种多标签文本分类模型。1.基于图卷积和交叉注意力的多标签文本分类模型。在传统的多标签文本分类模型中,通常没有考虑标签语义信息以及标签之间的关系,导致分类效果不佳。针对这一问题,本文首先基于标签共现信息作为先验知识构建标签的关系图,通过训练图卷积网络隐式地学习标签之间的关系,优化标签特征表示。然后通过交叉注意力感知标签和文本之间的语义联系,获取具有标签语义的文本表示特征。同时,在文本特征建模方面,引入结构化自注意力机制对文档文本表示进行优化。最后基于门控机制建立自适应的特征融合策略,从标签文本表示和文档文本表示中抽取相对重要的特征信息进行融合,从而获得更全面的文本表示特征。模型在两个公开文本数据集上与多个基准模型进行对比实验,结果表明了模型具有较好的分类效果。2.基于全局和局部信息整合的多标签文本分类模型。在多标签文本分类任务中,传统方法通常存在文本语义特征提取能力欠佳的问题,而且数据标签通常呈现长尾分布。为了提高模型对文本信息的理解和提取能力,整合了自注意力机制与卷积神经网络,从而兼顾对文本序列的全局信息和局部信息的感知。模型首先基于多头自注意力机制提取文本的全局上下文信息,然后将其引入卷积神经网络,强化对文本局部信息的理解。这种方法同时整合了文本的全局信息和局部特征,提升了模型对文本高级语义信息的理解能力。同时,本模型引入Cor Net网络,学习标签之间的相关性知识,对分类预测结果进行增强。针对标签长尾分布的问题,模型采用一种改进的Focal Loss损失函数,通过提高尾部标签样本的训练损失权重,增强模型在标签样本分布不均衡情况下的分类能力。通过与基准模型进行一系列对比实验,验证了模型的分类能力有一定的提高。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.002193
{DOI}: 10.27005/d.cnki.gdzku.2023.002193
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 领域知识图谱半自动化构建技术研究与实现
{Author}: 杨东升
{Tertiary Author}: 匡平
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 航空领域知识图谱;命名实体识别;关系抽取;知识图谱半自动化构建
{Abstract}: 信息时代,数据得到大量增长,为了更好地对领域知识进行存储和利用,需要构建高质量的领域知识图谱。本文主要着眼于航空领域知识图谱的构建,针对领域知识图谱构建过程中自动化程度低、人工成本高的问题,提出了一套半自动化的信息抽取方法来构建航空领域知识图谱。本文的主要目标是提高信息抽取步骤中实体识别和关系抽取的自动化程度,为此开展了以下几点研究内容:(1)规范了航空领域知识图谱的构建流程,包含数据获取、信息抽取、知识融合、知识加工及应用,使领域知识图谱构建技术路线更为清晰规范和系统化。(2)在实体识别任务中,构建了航空实体数据集,设计了ElmBERT-BiLSTMCRFMask实体识别方法。基于预训练的BERT-BiLSTM-CRF模型有三点不足:第一点是对于实体级别的局部信息不敏感;第二点是空间和计算复杂度高。第三点是CRF解码器会生成非法标签序列。ElmBERT模型做了以下两点改进:第一点在预训练期间加入实体级别掩码策略,引入词向量上的卷积操作,提升了模型对实体信息的感知能力。第二点是引入了混合注意力机制,使用动态卷积替代一半的注意力头部,减少了模型占用内存大小。针对CRF解码器的问题,本文引入了一种基于掩码的CRF变体,解码阶段对候选路径施加限制,提高了解码效率和准确率。在公开数据集上进行了对比实验证明了模型的良好性能,在航空领域数据集上验证了模型的有效性,最后进行了消融实验对各个模块的作用进行了分析。(3)在关系抽取任务中,构建了航空领域的关系数据集,设计了一种基于注意力机制的句法依存关系抽取模型Atti-BRDCNN。Atti-BRDCNN模型的主要改进有两点:第一点是针对BRCNN模型中使用的LSTM全局信息提取能力的局限性,在输入层之后引入多头自注意力机制丰富提取的词向量特征,并解决了LSTM的长依赖问题;第二点是针对常规CNN模型提取的特征不能反映上下文且卷积核参数过多的问题,将常规卷积改进为动态卷积,可以根据上下文动态生成卷积核并减少卷积核参数的大小,同样在公开数据集上进行了对比实验,在航空领域关系数据集上进行了验证实验,证明了模型的有效性,最后进行了消融实验对各个模块分析。(4)完成航空领域知识图谱的本体构建后,将三元组导入Neo4j图数据库中进行存储。在此基础上设计构建了一个集查询、问答、知识可视化功能为一体的航空领域知识图谱平台,最后对航空领域知识图谱平台进行了全面展示。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003355
{DOI}: 10.27005/d.cnki.gdzku.2023.003355
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于任务型对话的中医辅助问诊系统研究与实现
{Author}: 吴燎
{Tertiary Author}: 李巧勤
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 中医问诊;任务型对话;自然语言理解;自然语言生成;自动诊断
{Abstract}: 中医诊断是中医诊疗的基础,也是中医诊疗过程最关键的一环。中医诊断的主要方法为望诊、闻诊、问诊、切诊,其中问诊是中医诊断方法中的重要组成部分,问诊通过中医医师与患者多轮对话的方式,了解患者疾病的发生、发展情况、现有症状等。在中医问诊过程中,问诊内容和问诊顺序往往为中医医师的行医经验决定。目前的任务型对话与中医问诊的结合还处于发展阶段,并没有建立个性化专有中医问诊模型。因此,论文以中医问诊任务型对话为研究对象,开展中医问诊自然语言理解、问诊自然语言生成研究、中医证候辨识研究,设计实现基于任务型对话的中医问诊平台,主要工作如下:1.针对现有的自然语言理解模型在槽位填充任务和意图识别任务上二者缺乏有效结合,以及现有的模型在长文本对话中存在信息遗忘问题,提出基于BERT+Bi-GRU+Attention机制的自然语言理解联合模型(Joint Model of Intention recognition and Slot filling based on BERT+Bi-GRU+Attention mechanism,JMIS-BBA),将当前自然语言理解任务中的意图识别和槽位填充任务联合训练,引入Bi-GRU+注意力机制提高对长文本的识别准确率。实验结果表明,JMIS-BBA在SNIPS(Spoken Natural language processing in service of Intelligent Personal Asistants,SNIPS)数据集、ATIS(Airline Travel Information System,ATIS)数据集的Slot-F1分数、Intent-F1分数、Sentence准确率分别为97.8%、97.6%、92.8%和98.0%、97.6%、92.0%,在中医临床数据集的Slot-F1分数、Intent-F1分数、Sentence准确率分别为96.3%、100.0%、100.0%,为中医问诊的自然语言理解提供了有效的方法。2.针对现有的模型采用固定编码的方式,将对话动作编码为One-hot形式,虽然在固定对话动作集取得了很好的效果,但是新增对话动作需要重新编码,模型维护性差;此外现有模型将多个槽位同等对待,忽略了不同槽位对对话生成的影响,提出基于对话动作和槽位对的自动编码器对话生成模型(Action and Slot pairs based Auto-Encoder conversation generation model,ASAE),采用对话动作和槽位对的自动编码器学习对话的行为特征,解码器根据不同权重槽位对生成自然语言回复。测试结果显示,ASAE在SF(San Francisco,SF)数据集的Hotel、Restaurant、Laptop领域下BLEU-4得分分别为68.9%、80.1%、42.3%,ERR得分分别为2.6%和2.8%、2.7%。3.针对现有模型存在忽略时间、空间特征信息和无监督信息,提出融合无监督信息的自动编码器和卷积神经网络的证候辨识(Automatic Encoder and Convolutional Neural Network with unsupervised information,AECNN),通过融合无监督信息与监督信息,引入LSTM编码器和CNN网络捕获中医特征的序列特征和空间特征,学习中医专家问诊经验特征。测试结果显示,AECNN可提高中医证候辨识准确率,在CIFAR10公开数据集和TDCC中医临床数据集上识别准确率分别为74.1%和95.3%。4.通过SpringBoot、MyBatis和Vue等框架,基于BS(Browser/Service,B/S)架构,采用Java语言和Python语言、My SQL数据库设计并实现基于任务型对话的中医问诊平台,具备意图识别、槽位填充、证候辨识和场景交互等功能,通过功能测试和性能测试,模拟实现了中医问诊的效果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003659
{DOI}: 10.27005/d.cnki.gdzku.2023.003659
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 中文命名实体识别与事件抽取方法研究
{Author}: 王文杰
{Tertiary Author}: 侯晓荣
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 实体抽取;事件抽取;多元特征;任务关联;重叠事件
{Abstract}: 实体抽取、事件抽取作为自然语言信息抽取的主要研究任务,为情感分析、图谱构建等众多下游任务提供结构化的数据支撑,具有重要的研究意义。近年来,随着深度学习技术的发展,实体抽取、事件抽取已经取得了许多进展。中文实体抽取方面,汉字具备丰富的字词、偏旁部首、象形以及拼音特征,目前使用单一特征的抽取模型可能引发信息偏置问题,使模型陷入局部字词关注,导致实体抽取性能降低。事件抽取方面,通过将其分解为关联的子任务实现,目前的算法由于连接不同子任务的词向量缺失了全局的事件类型及触发词信息,并且方法中忽略了重叠触发词与元素的复杂情况,导致较大的误差传播、精度不高的问题。本文针对上述问题,分别对实体抽取与事件抽取提出了对应算法。本文的主要研究工作如下:1、基于多元特征融合的中文实体抽取。已有模型采用单一特征进行数据增强,缺失了中文汉字的丰富语义特征,可能引发模型关注局部字词过高,对全局语义信息关注不足。针对此问题,本文提出了多元特征融合实体抽取模型,在语句的字词混合特征的基础上,通过整合汉字分解结构特征、汉字象形图像特征以及拼音特征,获取丰富的语义信息,改进单一特征模型所存在的缺陷。实验表明,提出的多元特征融合模型能有效提升中文实体抽取性能。2、基于注意力与门控条件网络的事件抽取。已有事件抽取研究中关联子任务的词向量缺失了全局事件类型以及触发词信息,以及忽略了复杂文本的触发词、元素重叠的情况。针对此问题,本文提出如下方法:(1)基于门控条件的关联网络,通过引入语料中全局事件类型以及触发词信息,使得网络获得充分表征事件信息的词向量;(2)基于注意力与关联网络的事件抽取模型,通过引入注意力机制,使得网络更加关注对事件触发词以及元素分类更重要的位置区域。实验表明,算法有效降低了误差传播,显著提升了事件整体抽取任务以及重叠抽取任务的性能。3、金融新闻文本抽取原型系统。针对现有金融新闻领域缺少规模结构化抽取工具的问题,本文基于上述算法实现了信息抽取系统原型设计,实现金融新闻数据的自动化标注、信息化管理。通过测试,信息抽取原型系统满足功能需求,为金融机构提供便捷的信息提取工具。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001278
{DOI}: 10.27005/d.cnki.gdzku.2023.001278
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于动态词向量表示的词义历时变化自动发现研究
{Author}: 孙佳
{Tertiary Author}: 肖航
{Publisher}: 中国社会科学院大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 词义历时变化;词向量;预训练语言模型;自动发现;历时语料库
{Abstract}: 信息技术的快速发展为研究自然语言的变化提供了更多的便利。近年来,人工智能崛起,深度学习技术高速推进,语料数据持续丰富,数据处理能力不断提升,使得大规模语言计算成为可能,为词义历时变化自动发现提供了新的理论、方法、资源和技术上的支撑。本文以词义历时变化的监测和发现为研究对象,建设大规模长时间跨度的历时语料库,运用基于预训练模型和构词法相结合的动态词向量表示技术,先通过向量距离来衡量词汇的语义相似性,再对比不同时期词义相似程度及分布特点,进而检测词义随时间产生变化的情况,提出了一种以概念义为主、语法义和色彩义为辅、结合候选词汇使用领域和形式标记等的多维度多策略融合的词义历时变化自动发现方法。本文的工作主要有:首先,以报纸新闻数据和网络媒体数据为主要材料,构建了时间跨度达73年,约27.5亿字的大规模长时间跨度的历时语料库,并对其进行了有针对性的标注加工;其次,从概念义、色彩义和语法义三个维度出发,设计提出了一种词义历时变化自动发现方法;第三,以词典释义发生变化的词语为参考,通过实验分析,验证了该方法的有效性;第四,在大规模语料库中自动挖掘词义变化词语,并从语言学角度来分析和归纳这些词语的词义变化特点。同时,本文基于实验和语料数据分析验证了词义随时间变化的一些模式和规律:一是概念义、色彩义和语法义是词义变化的主要部分;二是语法义的变化更容易在单音节词和动词中产生;三是词义转移呈现多向多元的特点。本文研究的特色和创新主要体现在三个方面。第一,提出了多维度多策略融合的词义历时变化自动发现新方法,从概念义、色彩义和语法义三个维度来检测词义的历时变化,以词语的使用领域变化和词语的形式标记与搭配词变化为线索辅助变化检测,为后续研究提供了新的视角。第二,所提出的融合了构词信息的动态词向量表示方法加强了多义词不同义项向量表示的准确性,为词义变化计算提供更精准的输入,为动态词向量表示应用于词义计算研究提供了新的思路。第三,提出了以数据驱动的词义变化候选词筛选新方法,与人工手动挑选候选词或简单选择实词等作为候选词不同,可以更好结合构词法、词性、音节等语言学特征,以及词频、分布、使用稳定性等统计学特征,全面筛选发生词义变化概率较大的候选词,为提升词义变化检测效率提供了新的优化方向。
{URL}: https://link.cnki.net/doi/10.27642/d.cnki.gskyy.2023.000024
{DOI}: 10.27642/d.cnki.gskyy.2023.000024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 认知隐喻的信息流逻辑研究
{Author}: 洪峥怡
{Tertiary Author}: 黄华新
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 认知隐喻;信息流理论;情境理论;认知逻辑;形式语义
{Abstract}: 在认知隐喻的研究中,隐喻通常被定义为一种由一个相对熟悉的概念来理解另一个事物的基本认知方式。在这一定义下,隐喻的意义被大大提高,它不再简单地被视为语言技巧或修辞艺术,而是作为人类复杂思维的一种显性表现。这一观点也使得隐喻研究的关注点不再局限于语句的语形层面,而更多地涉及语义、语用层面以及包括隐喻推理机制在内的思维层面的内容,希望以此揭示人类获取知识、传递信息的基本模式。然而,认知理论对隐喻的分析高度依赖语言学家的直觉,缺少程序化的规范。随着自然语言处理技术的快速发展,隐喻这一非字面表达的机器识别和理解也成为了备受关注的话题。目前,对隐喻的自动处理需要依赖大样本的数据库,如果给出一个一般化的形式模型,则可以突破个人认知和特定语料的局限。因此,隐喻理解的形式化自然也成为了一项重要的工作。本研究以情境理论和认知逻辑为理论工具,从信息流动的视角重新探讨认知隐喻理论传统中的隐喻定义、特征和隐喻理解过程。通过给出相应的形式化方式,考察隐喻判定、理解和信念更新中的信息传递情况,揭示隐喻认知的一般框架和特殊性质。本文共分为八个章节,各章主要内容安排如下:第1章为绪论,首先叙述研究背景,概述了本文两个主要的理论出发点——隐喻的认知研究和隐喻的形式化研究——的历史和现状。然后提出,本研究希望遵循认知隐喻理论对隐喻理解的认识,对隐喻理解过程中涉及的信息流动进行逻辑表征,以此深化对隐喻推理过程的认识,并对隐喻自动化处理有所启发。最后简要介绍论文的框架结构。第2章首先回顾了主流隐喻理论的几种隐喻定义,从中得到隐喻判定的基本标准和隐喻表达的主要特征。然后从隐喻的真值条件出发,探讨了隐喻语义的生成和模型论解释方式。由于隐喻语句需要生成非字面义,因此无法完全遵循语义组合性原则。我们提出了一种解决方案,通过增加语义调适过程使得参与组合的语义不再是字面义。而调适函数本质上反映的是不同语境对语义的影响,所以隐喻含义的选择具有语境上的动态性。第3章以信息流研究的两条主要路径为线索,介绍了持信息限度论的认知逻辑、信念逻辑,持信息关联论的情境理论、信息通道模型,以及尝试对两种观点进行融合的逻辑模型。这些信息流的经典处理方式既是本文的背景知识,也是本文后续对隐喻进行形式化的理论基础。第4、5章从微观层面讨论静态环境中的隐喻理解,关注对一个隐喻语句本身进行理解时的信息传递。其中第4章基于情境理论和情境语义学对隐喻理解的静态信息结构进行分析,探讨隐喻概念和单句隐喻表达的构成信息,以及字面义到非字面义的信息转换方式。在第4章的分析基础上,第5章中首先引入隐喻算子和偏好算子,对极小模态逻辑进行扩充,构造了一个基于信息元的隐喻判定逻辑,从基本信息单位的层面上审视概念映射的基本要求;然后给出一个隐喻理解逻辑,对标准形式和特殊形式(如否定形式、间接隐喻等)的隐喻作出统一的解释。同时结合对隐喻表达实例的刻画来说明这些特点。第6、7章则从相对宏观的层面讨论动态环境中的隐喻理解过程,分析会话中预设、上下文、会话场景等语境要素对隐喻语句理解的影响。第6章以信息通道理论为工具,为隐喻理解中的动态信息建模。该模型将隐喻理解视为源域所包含的信息向目标域传递的过程,以说明不同概念域信息传递的信息通道是如何构建的,传递所需要的制约是如何表达的。基于第6章中信息通道模型的初步分析,第7章进一步讨论了隐喻理解中的信念更新。在动态信念逻辑语言和球系统语义的基础上,增加对置信度的考虑,给出一个动态隐喻逻辑。并结合隐喻表达实例,刻画隐喻理解从含混到清晰的信念更新过程,以此描述隐喻信息更新过程的信息不确定性、双向制约性、主体偏好性等特殊性质。第8章是全文的总结,简述了论文的结论和贡献,指出主要的创新点。同时也分析了存在的不足,给出有待进一步思考和探讨的问题,展望今后的研究工作。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.002185
{DOI}: 10.27461/d.cnki.gzjdx.2023.002185
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的知识抽取和多意图识别方法研究
{Author}: 曹玉峰
{Tertiary Author}: 黄金杰
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 知识图谱;知识抽取;注意力机制;图神经网络;多意图识别
{Abstract}: 目前,基于知识图谱的问答系统逐渐占据人工智能领域中越来越重要的地位。基于知识图谱的问答系统中所涉及到的任务也逐渐成为研究重点。因此,为过滤冗余信息,更智能化地满足用户需求,提高工作效率,本文依次从知识抽取、多意图识别这两个方面对基于知识图谱的问答系统所涉及到的任务进行研究。首先,由于输入数据多为非结构化的短文本数据,而短文本数据缺乏上下文语义背景知识,所以准确的提取实体之间的关系具有很大的挑战性。同时,实体抽取模型与关系抽取模型之间的交互性以及实体之间的多种关系给知识抽取任务带来了很大的困难,会影响下游任务执行。为此,本文提出了一种基于全局注意力机制的知识抽取联合模型,通过实体抽取模块和关系抽取模块同时进行,有效缓解了现有联合模型存在的问题,即实体抽取任务和关系抽取任务分开进行带来的误差叠加问题。然后,在抽取出实体和关系的基础上,为了进一步识别用户提出的问题中所包含的多个意图,本文提出一种基于图注意力机制与门控机制的多意图识别与槽位填充模型。在意图识别模块中采用多意图识别解码器将句子中的多个意图预测出来。针对主流联合模型解码速度较慢问题,利用图注意力机制,把预测的多个意图结果与槽位构成图网络结构,实现槽位填充的并行解码,提高槽位填充速度。同时,为了提高联合模型之间的交互性,采用门控机制连接多意图识别模块和槽位填充模块之间的特征,提高槽位填充在短文本上的识别精度。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2023.000217
{DOI}: 10.27063/d.cnki.ghlgu.2023.000217
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 古汉语预训练语言模型研究与应用
{Author}: 周波
{Tertiary Author}: 张寅
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 预训练语言模型;评估基准;古汉语;自然语言处理
{Abstract}: 古汉语(包括文言文、诗词歌赋等)是中国数千年文化的结晶,古文文献理解难度较大,并且传世古籍数量巨大,整理和发掘其中的价值需要极大地工作量。因此,有必要引入高效的NLP(自然语言处理)技术来处理、理解和研究此类文献。当前预训练语言模型在NLP领域,包括英文、中文等,都取得了巨大的成功,但文言文行文与现代汉语存在较大差异,因此通用的现代汉语预训练语言模型并不适用。本文提出了WYWLM(Wen Yan Wen Language Model),在大规模的语料集上,针对古汉语句子短、用词精炼、文本整齐、引用多等特征,采取多种预训练技巧进行语言模型训练。其中,本工作提出了一种新的基于对比学习的预训练任务,该任务以词典为媒介,可以利用海量的现代文文本,允许模型学习更好的汉字、词表示;引入了风格桥接解码器以增强语言模型并弥合古典汉语和现代汉语之间的差异;使用包含字/词释义和出处的古汉语词典将知识引入语言模型。对于预训练语言模型研究起重要作用的评估基准,允许研究人员评估其语言模型的性能,理清改进方向,然而,目前的评估基准都不适用于文言文。为了能够使研究者以统一的标准评测预训练语言模型,本文提出了专门用于文言文的自然语言处理评估基准WYWEB(Wen Yan Wen Evaluation Benchmark),它包含八个任务,实现了句子分类、序列标记、阅读理解和机器翻译等类型的任务,使得古汉语领域的预训练语言模型研究者能够以统一的标准评估其模型的能力。在WYWEB上,对多个的古文预训练模型以及WYWLM进行了评测,结果表明,WYWEB能够用于在多个维度评估预训练模型的性能;而WYWLM取得了最佳的分数,表明本工作针对古汉语设计的预训练方法是有效的。上述技术将作为一款国学典籍阅读器的后端支持组件,向用户开放RESTful接口。在此研究的基础上,WYWEB数据集和WYWLM模型将进行开源,为古文NLP研究社区提供一定的贡献。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.001600
{DOI}: 10.27461/d.cnki.gzjdx.2023.001600
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 贵州近代历史人物知识图谱构建研究
{Author}: 赵浩宇
{Tertiary Author}: 曾桢
{Publisher}: 贵州财经大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 数字人文;知识图谱;领域本体;信息组织;问答系统
{Abstract}: 人文历史文献是信息服务机构收藏的重要对象,也是当前社会主义核心价值观等精神文明建设的宝贵财富。然而,不同类型的文献资源包含的信息较为多元,在进行知识组织时,仅采用一种方式难以展现其中丰富多元的细节。传统的知识组织方式难以展现人文历史文献资源内容的细节,不利于用户宏观把握和快速检索所需的人物历史信息。而且,大部分人文历史文献的内容通常以非结构化文本形式记录,缺乏系统性和语义性,阻碍了其深层次的利用和开发。历史人物知识图谱是一种有效的组织方法,可以将历史人物的多方面信息通过结构化数据进行反映,从而提高历史学习和研究的便利性、智能化管理、查询、推理和可视化,并揭示历史人物之间的复杂联系,挖掘出隐藏在数据中的规律和价值,促进对历史发展规律和趋势的认识。贵州近代历史人物知识图谱构建研究对于文献资源内容数智化开发利用具有重要意义,但目前还缺乏统一且通用的构建方法和标准。基于以上内容,本文以数字人文理念为切入点,深入揭示历史人物相关文献资源的内容特征,对其细粒度知识元进行关联重组,以人物为中心,辅以事件、地点、机构、时间等核心特征,构建历史人物资源聚合本体模型,在此基础上完成贵州近代历史人物知识图谱的搭建,并开展实证研究,实现人物知识内容的可视化展示、语义检索和知识问答等应用层服务。以期解决贵州近代历史人物相关文献资源知识内容“闲置”、思维“困囿”、技术“迟滞”等问题。鉴于此,本文的主要研究内容分为三个部分。首先,通过回顾国内外文献,梳理了与本研究相关的概念和理论意义,并确定了知识图谱构建方法和工具。其次,通过文献调研法,归纳总结了相关文献资源的内外部特征,并进行了文本分析,筛选出相关概念和概念之间的关系。然后,基于已有的本体描述语言和本体库,设计了贵州近代历史人物的本体模型,在此基础上通过知识抽取等技术完成了知识图谱实例化过程。最后,对贵州近代历史人物知识图谱展开实证研究。其中,知识图谱模式层采用本体模型设计,描述了人物相关概念和关系。实例层运用自然语言处理和深度学习技术,对非结构化数据进行知识抽取、整合和存储,实现了人物实体的可视化展示,在此基础上搭建了前端应用平台,实现了人物知识查询、实体识别和知识问答等功能。本文基于贵州近代历史人物相关文献资源,从多维视角构建本体模型并且实现了知识图谱实例构建。前端可视化界面采用B/S架构设计,实现了前后端分离的应用层服务平台,包括人物信息可视化浏览界面、实体关系识别界面以及知识问答系统,满足用户对贵州近代历史人物知识的可视化查询、知识发现、知识问答等需求,不仅有利于学者和用户对历史人物相关资源的使用和开发,也有助于推动历史文献资源从数字化向数智化转型升级。本研究为历史人物知识图谱的构建和应用提供了一个可行且有效的方法和实例,对于推动人文历史资源的数字化和智能化发展,以及促进人文精神的传承和弘扬,具有一定的理论和实践意义。
{URL}: https://link.cnki.net/doi/10.27731/d.cnki.ggzcj.2023.000168
{DOI}: 10.27731/d.cnki.ggzcj.2023.000168
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本挖掘的医护人员心理健康知识图谱构建与应用研究
{Author}: 张斯扬
{Tertiary Author}: 崔雷
{Publisher}: 中国医科大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 文本挖掘;自然语言处理;知识图谱
{Abstract}: 目的:随着大数据时代的到来,怎样在爆炸性上升的数据中发掘、组织并管理有用信息成为研究重点。知识图谱作为知识管理最重要的方法之一广受关注。因此本研究将从Pub Med数据库下载的医护人员心理健康领域文献作为基础数据,利用文本挖掘等方法,研究了医护人员心理健康知识图谱的构建与应用,为用户有效梳理和呈现相关信息单元,对探究医护人员心理健康及其影响因素之间的已知和未知关联,为医护人员心理健康保护和治疗提供指导有重要意义。方法:按照知识图谱开发的程序,本文在如下几个方面进行了改进。(1)在领域概念和实体识别阶段,本文构建Bio BERT-Bi LSTM-CRF模型进行命名实体识别。首先,使用Bio BERT获取高质量的词向量,更适用于生物医学领域的专业医疗词汇;在特征提取阶段,使用Bi LSTM进行上下文特征的提取,对长短期的词向量有很好的适配;最后,CRF层可以向最终的预测标签添加一些约束,以确保其有效性。(2)在关系抽取阶段,本文使用基于规则模式匹配和基于共现的方法进行实体关系抽取,将预处理好的数据匹配制定的适用于文献数据的依存句法模式,然后与基于共现的方法得到的结果相结合,得到实体关系三元组。(3)在本体构建阶段,通过医学主题词表自动匹配和计算实体与医学主题词之间的相似度实现心理健康实体标准化,使用七步法构建医护人员心理健康影响因素本体,并利用基于规则和机器学习的方法对影响因素实体进行分类,最终将数据导入Gephi构建知识图谱并实现可视化。(4)在知识图谱应用阶段,计算知识图谱指标对知识图谱进行网络分析,找到知识图谱中关键节点。并通过对比分析选择模型进行知识图谱补全,探究知识图谱中实体之间的未知关联。结果:构建了医护人员心理健康影响因素本体以及医护人员心理健康知识图谱,并实现了实体查询。对知识图谱的网络图形式进行网络分析,发现其具有小世界性,以及知识图谱中最重要的风险因素包括年龄、性别、工作、婚姻状态、受教育程度、经济条件等;最重要的保护因素包括社会支持、心理弹性、心理一致感、交流、心理接受度等。最后,通过Conv KB模型对知识图谱进行链路预测,得到风险因素、保护因素与心理健康状态之间的新关联。结论:通过实验证明,本文所研发的医护人员心理健康知识图谱的构建方法,从医护人员心理健康领域科学文献中提取关键信息,获得实体与实体间的关系,最终构建了医护人员心理健康知识图谱,并根据知识图谱网络分析和知识图谱补全,确定关键影响因素,预测影响因素和心理健康问题之间的潜在关联,作为数字医疗的前期基础为科研工作者的前期工作提供指导理论,并为后人开发科学文献这一潜藏资源引领道路。
{URL}: https://link.cnki.net/doi/10.27652/d.cnki.gzyku.2023.000753
{DOI}: 10.27652/d.cnki.gzyku.2023.000753
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂场景下的文本语义理解方法研究
{Author}: 张凯
{Tertiary Author}: 陈恩红;刘淇
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 自然语言处理;语义理解;文本表示;注意力机制;预训练模型
{Abstract}: 自然语言语义理解旨在使机器可以理解人类通过文本表达的抽象语义信息。作为人类几千年知识与智慧的结晶,文本不仅是人类语言极为重要的承载方式,也是机器理解人类语言的最重要的入口之一。因此,研究自然语言文本的语义理解方法不仅具有重要的科学和应用价值,同时也是探索人工智能完备性问题的重点研究内容。传统自然语言文本语义理解的研究主要集中于单一场景,限制了复杂场景下自然语言语义研究的深度和广度,因此仍面临着诸多关键问题。例如:在细粒度文本语义表征方面,传统自然语言文本语义理解方法往往不能有效地表达文本中的微小差异,因此无法进行更加精准的文本分析和语义理解。在跨领域文本语义迁移方面,不同领域之间的语言表达方式和语义特征存在很大差异,传统方法难以将不同领域的语义知识进行有效迁移和应用。在物品推荐下文本语义融合方面,由于推荐系统需要综合考虑多种因素,如文本内容、用户兴趣等,因此需要将文本语义与其他信息进行融合,但传统方法难以实现有效的融合。本文针对上述问题,围绕复杂场景下的文本语义理解方法,开展系统性研究工作,探索自然语言文本在细粒度、跨领域和物品推荐场景下的特征,全方面提升复杂场景中的文本语义建模效果。本文主要的创新与贡献可以概括如下:首先,本文研究了细粒度场景下文本语义表征方法。传统的文本分类研究大多是针对文本进行整体的语义挖掘,而在当下诸多应用场景中,自然语言文本通常包含人们多方面的语义或情感表达。因此,研究文本在细粒度场景下的语义表征是深层次理解自然语言语义的重点。一方面,针对细粒度语义理解中文本语义的静态抽取问题,本文提出一个基于方面感知机制的语义表征框架。该框架首先基于文本内部所包含的不同方面,利用它们之间的语义相似性,同时通过设计方面感知注意力模块,抽取出方面级别的细粒度情感语义特征。在方面级的情感分析任务进行的大量实验结果验证了模型具有精准的预测性能和较强的泛化性。另一方面,针对细粒度语义理解中文本语义的动态表征问题,提出基于动态加权网络的预训练语言模型。该模型通过设计一个轻量级的语义自适应器来模拟人类在新场景下对自然语言文本的语义理解全过程,并将其嵌入到大规模预训练模型进行微调以实现细粒度语义的有效表征。在方面级情感分析领域的基准数据集上进行的广泛实验表明了模型的准确性和可解释性。其次,本文研究了跨领域场景下文本语义迁移方法。跨领域语义理解场景中广泛存在低资源、少标注的问题,传统方法需要大量的标注数据,人力成本和时间成本较大。为了探索在少量人工标注样本下的语义理解问题,本文提出基于注意力机制的交互式迁移学习框架。该框架包含语义表征模块、语义迁移模块和语义交互模块,并通过设计长短期记忆网络建模跨领域的语义知识,从而解决了在缺少高质量和多标注样本情况下的文本语义挖掘、表征与分类问题。在跨领域情感语义分析数据集进行的实验表明了模型的分类准确性和跨域稳定性。更进一步,针对文本语义迁移过程中存在的数据质量低、可迁移特征少的问题,从文本内部结构间的语义相关性出发,本文提出基于图神经网络的自适应语义迁移模型。该模型通过对文本构建其独特的句法关系图统一表示文本内部的语义结构,并设计一种混合的图卷积网络来聚合上述句法特征。实验结果表明模型大幅提升了跨领域场景下的文本情感分类准确率和无标签数据的利用率。最后,本文研究了物品推荐场景下文本语义融合方法。在真实的物品推荐场景下,用户兴趣漂移问题是指用户的兴趣随着时间、地点甚至是用户的情感变化而变化,如何高效建模隐含在文本信息中的用户兴趣也是当前推荐系统面临的一大难题。针对异构数据分布不一致、特征难对齐问题,本文首先提出基于动态协同机制的语义融合框架。该框架通过对用户的物品评论文本信息和物品属性信息进行挖掘,设计双向循环神经网络来建模动态的文本语义特征和静态的物品属性特征,让算法可以在二者的训练优化过程中实现高效的融合,更大程度地利用文本中的语义信息,并最终提高模型在众筹物品成功率预测任务下的表现。进一步地,针对文本属性信息对物品推荐效果的影响问题,提出了基于层级交互网络的语义增强模型。该模型利用多交互层级注意力网络建模用户文本属性、物品文本描述等细粒度语义特征,并将应用场景更进一步扩展到了点击率预测任务上,以捕捉隐含在文本表征之下用户偏好之间的潜在关系。在物品推荐领域真实数据集的实验结果表明模型大大提升了物品的预测和推荐效果。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.000348
{DOI}: 10.27517/d.cnki.gzkju.2023.000348
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向医学大数据的实体关系联合抽取方法研究
{Author}: 史斌彬
{Tertiary Author}: 张蕾
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;电子病历;知识图谱;联合抽取;数据增强
{Abstract}: 命名实体识别和关系提取是自然语言处理领域的重要任务,旨在从文本数据中提取由实体及实体之间的语义关系组成的关系三元组,这些三元组可以用来构建知识图谱、智能问答系统等信息化智能应用。在医学领域中,电子病历作为患者信息的载体,记载了入院记录、出院记录等大量半结构化和非结构化的文本信息,传统的技术难以从电子病历中提取有效的关系三元组。
现有的传统抽取模型方法是采用流水线的方式进行,首先通过实体识别模型,得到文本数据中的实体内容,接着将其作为输入进行关系抽取。传统抽取模型采用两个模型进行训练,在操作流程上更灵活,更便捷,但是,其存在着错误累积、割裂关系、冗余信息等缺点。因此,为克服传统方法的弊端,实体关系联合抽取模型被提出,不仅充分的考虑了实体与关系之间的联系性,还提升了对重叠三元组提取的性能。
本文的主要工作和成果如下:
(1)针对中文医学数据集中存在的长文本和重叠三元组的问题,本文提出了基于交谈注意力机制和条件层归一化的联合抽取模型。该模型使用了Ro BERTa预训练模型提取中文句子的语义信息。之后,利用条件层归一化方法来学习实体与关系之间的相关性。随后,使用交谈注意力机制加强了句子中注意力之间的交互。基于交谈注意力机制和条件层归一化的联合抽取模型在解决重叠三元组提取上性能良好。
(2)针对真实的电子病历中存在的标注数据缺乏和语义复杂的问题,本文提出一种新颖的基于医学知识库的数据增强方法(MEDA)。该方法使用开源的知识搭建了脑血管病的医学知识库,并通过处理了脑血管病患者的电子病历和现有的医学数据集来构建Bit Emr数据集。随后,采用联合抽取模型,并设计了自训练方法将Bit Emr数据集用MEDA方法扩增后进行学习,实验证明了联合抽取模型使用该方法后有较好的普适性,能够直接应用在电子病历的信息抽取场景中。
(3)本文设计了面向脑血管病的智能医学系统,该系统基于Vue和Flask框架,包含了电子病历展示、知识图谱检索、联合抽取系统、人工标注工具等多个功能,将理论研究真实的落地到医学领域场景之中。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000348
{DOI}: 10.27840/d.cnki.gzjkj.2022.000348
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于历史事故的煤矿安全知识图谱构建及应用
{Author}: 李敏敏
{Tertiary Author}: 孟祥瑞
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 煤矿安全;知识图谱;命名实体识别;关系抽取
{Abstract}: 煤炭作为我国能源支柱产业,煤矿安全占据着极其重要的位置,煤矿安全是实施煤矿开采的基本要求。目前煤矿事故的相关信息以事故概况的文本形式存在各个网站中,这些事故涵盖了事故时间、事故地点、事故煤矿、事故伤亡等知识,这些信息对煤矿安全有着重要意义。如何高效的将这些来源异构、分布散乱的数据进行统一管理成为近年来人们关注的热点。构建煤矿事故知识图谱可实现煤矿事故的有效集成与持续积累以及对事故案例的快速检索,同时可统计事故发生的时间、地点、原因等数据完成事故分析,为事故预防工作提供知识支持,构建煤矿事故知识图谱对于提高煤矿安全工作效率具有重要意义。因此根据以上背景,从实际出发,本文引入深度学习的相关方法构建煤矿安全知识图谱,对煤矿安全知识图谱构建中涉及的命名实体识别模型以及关系抽取模型进行深入研究分析。主要研究内容如下:提出融合字词特征的双网络煤矿命名实体识别模型。利用ALBERT、Word2vec获取字词向量,将拼接得到的向量分别传入到双向LSTM模型以及迭代膨胀卷积网络中,相比于单一的模型而言,并行使用IDCNN主要以丰富模型的特征输出为目的,将两个模块并联起来,可以对不同粒度的文本特征进行提取,通过增加输出的文本特征来提高煤矿命名实体识别准确率。提出引入位置特征的ALBERT-BiLSTM-ATT模型,通过对输入句子中实体对的特殊标记,有效解决同一实体在不同关系中的特征表示。同时引入依存句法分析对煤矿安全规程进行三元组抽取,将两种方法结合完成煤矿知识三元组抽取。最后构建出煤矿事故案例知识图谱,并对其有效性进行验证,证实了构建煤矿安全知识图谱的准确性以及可行性,为最终的煤矿安全搜索系统提供了数据支撑。煤矿安全知识图谱搜索系统采用Flask框架开发,帮助用户在不需要熟练掌握Cypher查询语句的情况下也能快速查找知识。图[40]表[15]参[98]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2022.000636
{DOI}: 10.26918/d.cnki.ghngc.2022.000636
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于中文短文本的命名实体识别和实体链接方法研究
{Author}: 高蕾
{Tertiary Author}: 黄杰
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 中文短文本;命名实体识别;实体链接;实体链接系统
{Abstract}: 随着网络上中文短文本的爆炸式增长,以及由中文短文本组成的网络语料库也逐渐增多,中文短文本在各种网络应用中都发挥着重要作用。命名实体识别和实体链接是自然语言处理中的关键任务,也是处理中文短文本的重要技术,能够将非结构化的中文短文本数据转换为结构化的可利用数据,同时影响着自然语言处理中许多下游任务的准确性。然而,由于中文短文本表达不规范,以及语义极其稀疏等特点,对中文短文本进行命名实体识别和实体链接仍是一项具有挑战性的问题。目前中文短文本研究领域,对于命名实体识别的研究大都采用结构化的特征融合方式,无法使得特征进行深入知识交互,对于实体链接的研究大都存在语义信息利用不足问题,且忽略了标签与原始短文本间的交互作用。为此,本文围绕中文短文本的命名实体识别和实体链接展开深入研究,提出了基于预训练模型改进的新型模型,并且将本文提出的模型用于可视化的实体链接系统中。本文具体研究成果如下:
(1)针对现有的中文短文本命名实体识别方法未考虑将部首特征进行充分融合问题,本文提出了一种基于Roberta部首增强适配器的命名实体识别模型。该模型设计了一个部首适配器将中文短文本的部首信息融合到预训练模型Roberta的底层,使得部首特征与Roberta提取的语义特征进行深入知识交互,最后使用考虑相邻标签依赖性的条件随机场模型预测标签序列。通过公开数据集上的对比实验,证明了该模型能够提高实体识别的准确率。
(2)针对现有的中文短文本实体链接方法未充分利用语义信息和忽略标签与文本间的交互问题,本文提出了一种基于Roberta句向量标准化和标签嵌入的实体链接模型。该模型首先通过预训练模型Roberta来充分捕捉上下文语义信息并以句向量表征提取的上下文信息,然后通过流模型修正句向量的各向异性问题,使得句向量中的上下文信息能被更精确地表征。此外,还通过标签嵌入和文本嵌入间的交互来改善不可链接实体的分类性能。通过公开数据集上的对比实验,证明了该模型可以有效提升实体链接的性能。
(3)针对命名实体识别和实体链接的可视化问题,本文构建了一个面向中文短文本的实体链接系统。该系统前端允许用户输入一段中文短文本,然后经过后端的命名实体识别和实体链接模块输出识别的实体指称、实体指称的候选实体集和最终链接情况。该系统能够通过随机短文本验证本文提出模型的实用性,并且能够用于智能问答和知识图谱扩建等下游任务中。
通过上述的研究工作,证明了我们提出中文短文本命名实体识别和实体链接模型的有效性,能够促进命名实体识别和实体链接研究方法的进步,对许多自然语言处理任务提供了新的思路。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000316
{DOI}: 10.27840/d.cnki.gzjkj.2022.000316
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的实体和关系联合抽取模型的研究
{Author}: 剌凯俊
{Tertiary Author}: 雷景生
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 命名实体识别;关系抽取;联合模型;关系三元组
{Abstract}: 科技的飞速进步,使得互联网文本信息呈现指数化增长的趋势。从浩如烟海的文本信息中准确抽取实体和关系,对于构建知识图谱、实现智能对话等前沿技术有着重要的意义和价值。实体识别和关系抽取任务过去常采用的是流水线方法,不考虑两个子任务的关联性,而将它们独立看待。即先从文本中抽取出可能的实体并进行类别预测,然后对得到的结果集中的实体两两进行关系的分类。流水线方法存在诸多问题,例如级联误差、子任务相关性不足、信息冗余、语义信息获取不足等。针对上述问题,本文围绕实体和关系抽取联合任务,对命名实体识别、关系抽取以及联合模型领域的研究现状进行了充分的调研,分析了当前相关研究中的缺陷,重点针对文本语义增强方法和分解的方法,研究了两种联合抽取模型,并实现了两个模型的应用。以下是本文的主要工作内容:
(1)针对流水线方法对命名实体识别和关系抽取两个任务的相关性关注度不足以及上下文语义信息获取不充分等问题,研究了一种基于上下文语义增强的联合实体与关系抽取模型。通过共用BERT编码器实现参数共享,并采用对比学习的方法获取句子级文本和实体间文本的语义特征,将其融入到实体和关系的特征表示中,同时动态调整两个任务的损失以使联合模型的整体性能最优化。模型在Co NLL04、ADE和ACE05数据集上实体识别和关系抽取均取得了较好的性能,证明了模型的有效性。
(2)针对实体冗余以及重叠关系识别欠缺等问题,研究了一种基于分解策略的实体关系联合抽取模型。将原任务拆分为两个子任务,一个是头实体识别,另一个是相应的尾实体及其关系的联合识别。对于特定的头实体,其特征信息对尾实体的识别具有正向增益,因此采用层次化的方法,在进行尾实体和关系抽取子任务中融入头实体信息,同时采用指针机制来加强边界的感知以及类别信息的抽取。模型在数据集NYT和Web NLG上取得了较好的成绩,证明了模型的有效性。
(3)设计构建了实体和关系抽取的原型系统,将本文所研究的两种模型相结合,对文献摘要进行知识获取。实现了从非结构化的文献摘要中抽取实体关系三元组,并对结果进行了分析展示。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000295
{DOI}: 10.27840/d.cnki.gzjkj.2022.000295
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图卷积神经网络的社区问答专家发现方法研究
{Author}: 史伟志
{Tertiary Author}: 王磊
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 社区问答网站;专家推荐;图卷积神经网络;门控循环单元;基于变换器的双向编码器表示技术
{Abstract}: 互联网快速发展给用户带来了巨大便利,用户可以从互联网上得到各种信息,但随着信息的爆炸性增长,用户精准地获取知识已变得越来越困难。一般来说,用户会使用搜索引擎查询其所希望得到的答案,但目前的搜索引擎通常只是检索用户输入问题的关键词,并不考虑被检索问题的上下文语义,因此经常出现查询不到所需答案的情况。同时,随着用户参与意识的增强,网民逐步从知识的获取者转变为生产者和分享者,因此,社区问答网站如Quora、知乎等应运而生。但是随着社区问答网站中用户数量的增加,提问者提出的问题可能很久后才能得到答案,甚至得不到答案。因此,对社区问答网站来说,为用户提出的问题推荐有能力回答该问题的专家非常重要。研究者们提出了各种各样的专家推荐方法,但目前大多数专家推荐方法都忽略了用户知识储备会随时间动态变化及用户兴趣会发生动态偏移等问题。针对现有研究方法的不足,本文开展了一些针对性的研究,具体工作如下:(1)本文提出了一种时间敏感的社区问答专家发现方法,该方法根据用户的共同回答和关注关系构建多关系共同回答网络。按周为单位构建问答文本序列,对于每个回答者,记录其每周提供的答案文本,如其在某一周未参与回答,则使用其上周的答案文本。提取这些问答文本的语义特征,学习多关系共同回答网络的拓扑结构以捕获空域社交特征,学习随时间动态变化的问答文本以捕获时域语义特征,最后通过全连接层进行分类。(2)本文提出了一种基于长短期兴趣的社区问答专家推荐方法。该方法通过预训练的语言模型获取问题特征向量。通过语言模型及循环神经网络处理用户历史回答文本从而学习用户短期兴趣。通过在多关系共同回答网络中使用图神经网络捕获用户长期兴趣,用户的长期兴趣和短期兴趣结合形成用户特征向量。通过计算用户特征与问题特征的余弦相似度获得推荐专家列表。(3)最后,构建面向社区问答网站的原型系统,将本文中提出的时间敏感的社区问答专家发现方法和基于长短期兴趣的社区问答专家推荐方法应用到原型系统中,并验证两种方法的可用性和有效性。通过具体的应用,证明本文方法是解决面向社区问答网站的专家推荐问题的有效方案。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001551
{DOI}: 10.27251/d.cnki.gnjdc.2022.001551
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态信息的物体间关系检测研究
{Author}: 楼婧蕾
{Tertiary Author}: 周亮
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多模态;视觉关系检测;深度学习;知识图谱;跨模态知识图谱
{Abstract}: 随着信息技术的高速发展,人们的日常早已和互联网密切相关,每天有海量的数据产生,数据的模态呈多样化趋势。如文本、图像等多模态数据的爆炸式增长,使用户很难有效地从中获取有价值的信息。因此,研究如何从大量多模态数据中提炼有效信息,并刻画多模态信息间关联有极其重要的意义。传统的信息抽取通常是从无结构的初始文本中抽取出结构化、半结构化和非结构化的数据,再将这些数据信息储存到结构化的数据库中,方便用户的使用。这种方式早已无法满足如今针对海量多模态分析的需求。近年来,深度学习在计算机视觉和自然语言处理方面的研究都取得了突破性的进展,推动了基于多模态信息的物体间关系检测研究的快速发展。为此,本论文通过研究基于多模态信息的物体间关系检测,为跨模态知识图谱的构建提供理论依据。具体而言,论文首先设计基于关系三元组的视觉关系检测模型;在上述研究基础上提出了文本描述协助的跨模态关系检测模型;最后利用跨模态关系检测模型搭建跨模态知识图谱。论文的主要创新工作如下:(1)本文提出了一种基于目标检测与多特征融合的视觉关系检测模型。所提模型将视觉模块、语义模块以及损失计算构建为一个端到端的多支路并行协作网络。其中视觉模块借助目标检测获取视觉特征并且预测目标类别;语义模块通过使用外部语义库提取目标语义特征;在损失计算模块中,所提模型联合基于语义表征的softmax三元损失和基于视觉特征的三元损失,引导视觉以及语义模块彼此交互“共现”信息。通过在公共多模态Visual Genome数据集上进行实验,验证了所提网络的优势。(2)考虑到单模态信息抽取获取的实体关系具有多义性高、表述力不强等不足,本文在视觉关系检测模型的基础上进一步构建了一个跨模态关系检测网络架构。所构建的跨模态关系检测网络引入文本表述分支,将文本编码与视觉特征提取动态融合,通过设计文本-视觉交互损失函数引导文本以及视觉信息最大化彼此的共性,这可有效提升关系检测模型在复杂场景下鲁棒性。(3)本文提出了跨模态知识图谱构建新范式,通过将跨模态关系检测与跨模态知识表征相结合,构建跨模态知识图谱(Cross Modal Knowledge Graph,CMKG)。具体而言在联合跨模态关系检测与跨模态知识表征的过程中,着重研究如何不需要额外辅助工具即可获取精准的跨模态知识三元组。区别于传统单一模态知识图谱,所构建的CMKG旨在为多模态知识检索提供一种更为可靠的结构化多模态知识存储及表征方式。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001043
{DOI}: 10.27251/d.cnki.gnjdc.2022.001043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Seq2Seq框架的文本风格迁移研究
{Author}: 杨子农
{Tertiary Author}: 陈可佳
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;文本风格迁移;Seq2Seq;预训练语言模型;对比学习
{Abstract}: 随着大数据时代的到来,文本已经成为互联网中最常见的数据形式之一。自然语言处理是人工智能领域的一个重要研究方向,帮助理解人类的文本信息,并且学会如何创作有意义的文本。作为自然语言处理研究的一个新兴课题,文本风格迁移(TST)任务旨在保留文本内容的前提下,对文本的风格进行转换。TST常见的应用场景包括但不仅限于:文本润色、对话系统、诗歌创作等。尽管前人已经在TST任务上进行了较为深入的探索,但是当前的TST方法仍然存在诸多挑战,包括:1)极度缺乏平行语料;2)缺乏非英语的语料数据;3)难以分离文本的内容与风格特征。为了解决以上挑战,本文针对TST任务进行了系统的研究,并且提出了以下的具体工作:针对平行语料匮乏以及非英语语料训练数据不足的问题,本文首先收集并建立了一个句子级别的“古汉语-现代汉语”平行语料库。在此数据集上,本文使用了基于Seq2Seq的编码-解码模型进行训练。为了获得更加优秀的风格迁移效果,本文引入了预训练模型UNILM和Guwen BERT。在文学和历史数据集上的实验结果表明,本文方法在人工评估和自动评估指标上都取得了最优的性能。针对难以分离文本的内容与风格的问题,本文提出了基于对比学习的Seq2Seq风格迁移方法。对比学习能够学习无平行语料数据的底层特征与分布,用于潜在分离文本的内容与风格。首先,通过回译的方法扩充训练语料,并基于对比学习在文本编码阶段区分文本的内容与风格。随后,使用基于内容-情感对偶编码的Seq2Seq模型,并结合风格分类器以指导文本的风格迁移过程。实验结果表明,本文方法可以产生更高质量的风格迁移文本。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.000468
{DOI}: 10.27251/d.cnki.gnjdc.2022.000468
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 古籍文本的自动断句与标点研究
{Author}: 王瑶
{Tertiary Author}: 顾磊
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 古文句读;BERT模型;双向长短记忆网络;条件随机场;数据预处理;动态编码
{Abstract}: 随着自然语言处理技术的发展,部分研究学者尝试将深度学习模型应用到古籍文本的处理中。古文相较于现代文不仅在用词、语法等方面存在巨大的差异,还缺少标点。目前仅有少部分古籍文本经过人工处理,具备断句或标点符号,仍还有大量的古籍文本没有断句或标点。通过人工对古文进行断句或标点,既需要有较高的专业知识,还需要对文本对应的当时的历史文化有一定的了解,因此对古文进行断句和标点的速度缓慢。为了加快对古籍文本的断句和标点的速度,部门研究学者尝试使用深度学习模型对古籍文本进行断句和标点。本文主要研究基于深度学习的古籍文本自动断句和标点算法,并对模型进行优化改进,进一步提高模型对古籍文本断句和标点的性能。本文的主要工作如下:(1)将深层语言模型BERT、双向长短记忆网络(Bi LSTM)和条件随机场模型(CRF)相结合用于古籍文本自动标点任务。首先将BERT模型应用于古籍文本处理任务中,使模型能够充分学习文本语义信息。同时结合Bi LSTM+CRF模型能够学习标签规范信息的特性,进一步增强模型的规范性,使得模型的预测结果更加准确。(2)提出了新的数据预处理方法,即数据按照段落分行处理。将按照标点分行的数据预处理方法改变为按照段落分行,数据的一行作为模型的一个数据处理单元,改变后的数据预处理方法使得模型的一个数据处理单元包含更多的文本信息,使得模型能够更加充分的学习文本上下文关联信息。(3)提出基于动态编码和以段落分行的数据预处理方法的BERT深度学习模型,考虑到古文的段落长度长短不一,对数据向量化时使用动态编码的方式,进一步减少了不必要信息的加入,缩短了模型的处理单元数量,提高模型预测结果的准确率。并且设计并开发了一个古籍文本自动断句和标点系统,使得用户能够直接通过该系统对想要断句或标点的文本进行处理,方便用户使用。本文在自行收集的数据集上进行实验,采用了统一的评价指标进行评判。最终的实验结果表明,改进后的BERT模型使用以段落分行的数据预处理方法和动态编码方式不仅能够更好的学习古文的语义信息和上下文关联信息,还能够学习标签的规范信息,可以有效地提高古籍文本自动断句和标点的准确率。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001300
{DOI}: 10.27251/d.cnki.gnjdc.2022.001300
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BiTCN和预训练的文本情感分析研究
{Author}: 卞玉露
{Tertiary Author}: 王国明
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 特征提取;时间卷积神经网络;扩张卷积;注意力机制;预训练语言模型;深度学习;情感分类
{Abstract}: 文本情感分析是自然语言处理领域的基本任务之一,通过使用相关算法对网络平台上大量文本数据中蕴含的情感观点进行研究和分析,对消费者和商家都具有重要意义。在传统方法中,卷积神经网络只能较好地挖掘文本局部特征而不会过多地关注上下文信息,而循环类神经网络在训练时极易出现梯度问题,所以本文针对在卷积神经网络基础上具备处理序列问题能力的时间卷积神经网络(TCN)展开研究,并基于改进模型进一步实现文本情感分析。以下是本文的研究内容:(1)给出一种结合双向时间卷积神经网络(Bi TCN)和注意力机制(Attention)的情感分析方法,解决以下问题:主流情感分析方法不能充分捕捉文本特征,对长文本的分析能力较弱;评论文本的表达较为口语化,导致文本内词语的重要程度无法区分。首先使用Word2vec模型训练得到长文本中所有的词向量表达;其次使用Bi TCN从两个方向进行编码学习上下文信息,以获取更加充分的文本表征,借助扩张卷积改变感受野大小,借助因果卷积防止数据泄露;随后引入Attention机制为文本中的每个词特征向量添加权重以突出其内部相关性;最后通过分类器得到模型的输出结果,在数据集上完成情感三元分类。实验结果显示,所给Bi TCN-Attention模型的分类准确率达85.1%,与CNN、RCNN、LSTM、TCN、Bi LSTM和Bi TCN模型相比均有不同程度的提升,证明了该方法的有效性。(2)基于上述模型给出一种结合预训练的文本情感分析方法,解决由于文本中目标词与情感词相隔较远导致使用传统词向量方法无法充分表示出语义信息这一问题。首先给出一个融合字词向量的特征提取模块(CW),该模块一方面借助Word2vec训练语料得到词向量特征,另一方面通过ALBERT进一步提取字向量特征;随后把从两方面提取到的组合特征作为Bi TCN-Attention层的输入;最后通过分类器得到模型的输出结果。实验结果显示,所给CW(ALBERT)-Bi TCN模型的分类准确率达83.6%,与仅使用字向量或词向量特征作为输入的模型相比有提升;所给CW(ALBERT)-Bi TCN-Attention模型的分类准确率达86.4%,与仅添加CW模块或仅添加注意力机制的方法相比也有一定程度的提升,更进一步论证了前文Bi TCN-Attention模型的适用性。图[22]表[9]参[76]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2022.000689
{DOI}: 10.26918/d.cnki.ghngc.2022.000689
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 模糊性认识研究
{Author}: 黄丽芬
{Tertiary Author}: 欧阳康
{Publisher}: 华中科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 马克思主义认识论;社会认识论;不确定性;模糊性认识;精确性认识
{Abstract}: 现代社会对精确性知识的偏好塑造了“精确性崇拜”的认识结果,驱使人们在认识活动中主要关注确定性因素,聚焦精确性认识,从而忽略了模糊性认识及其所蕴含的特殊价值。在马克思主义认识论中,精确性和模糊性是人类认识活动的两个基本维度,人的认识可以划分为精确性认识和模糊性认识两种类型。在过去的马克思主义认识论研究中,学者们主要聚焦于以理性认识为基础的精确性认识的研究,对模糊性认识缺乏必要的观照。在社会实践极度复杂化和认识对象日益多元化的当代社会中,人类面临的不确定因素日渐增多,模糊性认识也随之剧增。因此,对于当代马克思主义认识论研究而言,既要强化精确性认识的研究,又要高度重视模糊性认识问题,进而不断提升人类认识自然、社会和自我的能力。模糊性认识指的是认识主体在采取一定认识工具观念性地把握认识客体的过程中出现的类属边界和性质状态的不精确性。西方认识论发展史一定程度上是一部在不断追求确定性和精确性认识的过程中因屡次受困而发现并确认不确定性和模糊性的历史。在理解模糊性认识的道路上,本体论者认为认识对象本身是模糊的,语言学和逻辑学强调语义模糊性,认知主义主张模糊性认识根源于认识主体的有限性。马克思主义哲学科学地揭示出了模糊性认识的客观普遍性,厘清了模糊性认识根源于物质世界的模糊特性,解释了模糊性认识的物质实践基础,阐明了模糊性认识和精确性认识的辩证关系。从模糊性认识的历史演进来看,人类认识演进史中的原始神秘主义思维阶段、古代经验主义思维阶段、近代简单科学思维阶段、当代复杂科学思维阶段;个体认识发生和发展过程中的感知-运动阶段、前运算阶段、具体运算阶段、形式运算阶段;个体认识具体过程中的感性认识阶段、理性认识阶段、实践检验阶段,因为认识能力、认识工具、认识环境等的影响,模糊性认识的表现形式、特点性质等具有显著差异,模糊性认识和精确性认识的关系形态不断辩证发展。从模糊性认识的主客体依据来看,认识主体感知思维力、经验知识力和情感意志力的有限性;认识主体在信息接收过程中的模糊选择、信息识别过程中的模糊判断、信息存储过程中的模糊记忆、信息处理过程中的模糊推理、信息传输过程中的模糊表达;认识客体的多样性、复杂性和变动性;认识中介系统中认识工具、符号系统和认识环境的不确定性和模糊性,共同构成了模糊性认识的生成机制。模糊性认识的社会功能具有双面性,过度的模糊性认识导致社会失序、提升社会风险,因而要及时消除和超越模糊性认识;适度的模糊性认识为日常社会交往和社会创新提供可能,因而要保持适度模糊状态。不相容原理指出,随着社会复杂度不断提高,精确性和有意义性之间的张力越来越大,社会发展呼唤充分发挥模糊性认识方式和模糊思维方法的平衡性、包容性、自反性、适应性和创新性价值。与自然认识的客观性不同,社会认识不可避免地具有主观性,社会世界是模糊性认识的集中地和生产地,社会认识中的模糊性是模糊性认识的深层次问题。社会认识系统极度复杂,导致社会认识不同于自然认识的模糊性特点。从社会认识方法来看,理解方法的开放性、可错性和人文性取向与模糊性认识具有逻辑相通性。可以从结构层次的角度对社会认识中的模糊性展开研究,包括不同社会领域的模糊性认识、模糊性社会认识的向度结构和程度结构。
{URL}: https://link.cnki.net/doi/10.27157/d.cnki.ghzku.2022.006468
{DOI}: 10.27157/d.cnki.ghzku.2022.006468
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义理解的文本情感挖掘研究及其应用
{Author}: 胡振达
{Tertiary Author}: 王英林
{Publisher}: 上海财经大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 文本情感分析;语义理解;方面级别情感分析;机器阅读理解;情感元素抽取;时间序列预测
{Abstract}: 文本情感分析是自然语言处理领域的一项重要任务,旨在通过对带有情感色彩的非结构化文本进行采集、处理、分析、归纳和推理,挖掘文本中的意见、情绪、态度和感知等,其涉及到人工智能、机器学习、数据挖掘、自然语言处理等多个研究领域。
文本情感分析任务按照所研究文本的粒度可以分为文档级别(Document level)情感分析、句子级别(Sentence level)情感分析和方面级别(Aspect level)情感分析。对于文档级别或句子级别情感分析任务,目前大多数现存方法仅限于对文档或句子进行粗粒度情感极性分析,即仅判定文档或句子是否为积极、消极或中性的情感,并且鉴定方法未结合人类阅读认知过程,因此针对该研究任务的不足值得进行更深入的探索。
另外,方面级别情感分析(Aspect-based Sentiment Analysis)一直是文本情感分析中一个比较有挑战的任务,也一直是该领域的研究热点。尤其对于近年提出的情感三元组抽取(Aspect Sentiment Triplet Extraction)任务,其旨在对于给定文段抽取出目标词和意见词,并同时决定相应的情感极性。由“目标词-意见词-情感极性”构成的情感三元组使得方面级别情感分析的结果更加完整以及更具有可解释性,因此如何对文本进行深层次语义理解以及如何有效利用外部知识提升方面级别情感分析任务表现也成为本文研究的重点之一。
此外,随着近年来机器阅读理解的发展,以文本评论理解、评论观点抽取和机器问答为核心的评论阅读理解(Review Reading Comprehension)任务也成为文本情感分析领域中一个具有挑战性和值得探索的任务,其对于评论文本的关键信息抽取和理解具有重要意义,RRC因而也成为本文的研究重点之一。
除了上述任务,考虑到反应投资者情绪的新闻舆情对于金融市场的影响,如何将经过文本情感计算后的新闻舆情引入到金融时间序列预测任务中值得探索,尤其对于国际原油市场,对原油新闻舆情分析和原油价格波动的研究相对较少,因此该任务也值得研究。
因此,基于以上任务和挑战,本文以文本情感分析为核心,通过文本语义理解技术,着重围绕文本情感挖掘中的文档和句子级别情感分析、方面级别细粒度情感分类和情感三元组抽取、评论阅读理解、情感计算在金融时间序列预测中的应用这四个重要任务进行研究。主要研究内容如下:
(1)对于文档和句子级别情感分析任务,本文提出了一种基于多层级知识库的细分粒度多类别情感分析方法,名为“Mi Mu SA”。该方法涉及多级模块结构,包括基础情感知识库、否定词和特殊词情感知识库、反讽规则和转折知识库、情感极性强度知识库等多个知识库,旨在模拟人类阅读认知和语言理解过程,例如矛盾情感处理过程、情感强度处理过程等。在识别总体积极或消极情感的基础上,进一步理解情感极性的强度(如Strongly positive、Slightly positive等)。本文在两个不同领域数据集上进行了实验,验证了方法的有效性。
(2)对于方面级别情感分析(ABSA)任务,考虑到其重要价值和广泛应用性,文本选取了方面级别细粒度情感分析和情感三元组抽取(ASTE)作为研究任务。具体来看,鉴于BERT模型直接应用在ABSA任务上的表现不佳,本文针对ABSA引入了一个自监督的句子对关系分类任务,提出了一个名为“多层级语义关系增强学习网络(MSRL-Net)”的基于预训练语言模型的方法。在MSRL-Net中,原始的ABSA任务被重新转换为句子语义匹配任务后,模型利用词语之间的依存关系和词句之间的关系来增强句子语义匹配任务的词级语义表示;同时,利用句子语义关系和句子对关系增强句子级语义表示,进行句子对关系分类任务。模型通过充分利用样本中的标签信息以及构建的两个子任务更好地进行语义理解并实现方面级别情感极性判定。另一方面,本文针对方面级别情感三元组抽取任务提出一个新颖的端对端模型,叫做“GCN-EGTS”,它是一个针对ASTE任务的增强的网格标注方案(Grid Tagging Scheme(GTS)),其利用了基于图卷积神经网络(GCN)模型编码的句法成分分析树和常识知识图谱信息。两种类型的GCN被分别用于建模这两种信息:Span GCN用于捕捉句法成分分析树信息,Relational GCN(R-GCN)用于获取常识知识图谱信息。另外,模型设计了一个新的损失函数,其通过在原始的网格标注方案中加入约束条件来增强原方案。针对以上两个研究任务,本文通过在公开数据集上进行大量对比实验,证明了所提出模型的有效性。
(3)对于基于机器阅读理解(MRC)任务提出的评论阅读理解(RRC)任务,为了解决人类和RRC模型之间的差距,本文提出了一种基于BERT的“融合外部知识和多粒度注意力的神经网络(KMA-NET)”模型。具体来说,本文利用包括任务-aware知识、领域-aware知识和实体-关系知识在内的多类型外部知识,来克服RRC任务的来自任务本身和来自领域知识的挑战。此外,本文还利用先验知识通过句子级别信息来丰富语义表示,并添加了多粒度注意力以探索不同层次的交互信息从而增强文段和问题之间的信息融通。最后,本文在两个数据集上进行实验,证明了所提出模型的有效性。
(4)对于引入情感计算的金融时间序列预测任务,鉴于新闻舆情对金融时间序列预测的巨大影响,文本选取了股票价格序列和国际原油价格序列作为研究对象,通过情感计算,将相关的新闻舆情量化为情感因子引入到时间序列预测模型中。具体来看,针对股市价格预测,本文将股价涨跌预测问题作为一项分类任务来解决,将股票技术指标和新闻情感值作为影响因子引入到不同的机器学习和深度学习模型中。结果表明融合股票技术指标和社交媒体情感指数是提高人工智能模型在股市趋势预测性能表现的正确方向。此外,为了探讨股票新闻不同层面信息对股价走势的影响,本文提出了一种多层级文本向量构造方法,对新闻多个文本特征进行编码,包括主题特征、情感特征和语义特征,并构建深度学习模型,利用金融数据和新闻文本多维度特征来预测股价短期趋势。针对国际原油价格预测,本文提出了一种基于“分解和集成”框架的国际原油价格预测模型,名为“CEEMDAN-LSTM＿attention-ADD”,该模型将CEEMDAN、LSTM与注意力机制相结合,基于构建和计算的原油新闻文本情感指数,并根据原始序列分解后每个分量的特点,充分利用原油价格序列和新闻情感序列特征,对子序列进行预测,最后完成原始原油价格序列的预测。通过上述两个应用场景和真实的金融市场数据实验,本文证明了基于新闻舆情的文本情感计算对于金融时间序列预测的有效性。
{URL}: https://link.cnki.net/doi/10.27296/d.cnki.gshcu.2022.001962
{DOI}: 10.27296/d.cnki.gshcu.2022.001962
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地缘政治风险与黄金期货波动率
{Author}: 张静
{Tertiary Author}: 吴鑫育
{Publisher}: 安徽财经大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 地缘政治风险;价格极差;黄金期货波动率;REGARCH-MIDAS模型
{Abstract}: 黄金作为“金属之王”,既具有商品属性,又因为化学性质稳定、资源稀少等特性,兼具天然的货币属性。由于黄金具有抗通胀(高位的通胀会拉低实际收益率)与避险的优点,其开始转换为可靠的金融投资工具,由此黄金产生投资属性。可以看出,作为金融市场的重要组成部分,黄金价格的波动影响着实体经济的正常运行和金融市场的稳定发展。然而,近年来国际地缘政治格局正在不断调整,大国之间对战略空间的争夺持续发生,无论是中美贸易战、还是2019年底新型冠状病毒、2022年初乌克兰危机、北约冲突,均使得全球经济形势变得愈加复杂。因此,黄金期货作为黄金市场进行风险对冲和规避价格急剧波动风险的主要工具,研究地缘政治风险对黄金期货市场波动率的影响不仅对世界各国经济发展具有重要意义,也对金融市场投资者有重要的现实意义。传统计量学中多使用广义自回归(GARCH)模型对波动率进行建模,但该模型对于数据的频率有着严格限定,为了研究地缘政治风险对于黄金期货波动的影响,本文将混频抽样方法(MIDAS)引入广义自回归模型中,构建混频广义自回归(GARCH-MIDAS)模型,可以解决数据非同频问题。但该模型一方面没能考虑到波动率的非对称性,另一方面考虑的仍是日度数据,无法有效利用日内信息。因此,本文将REGARCH和GARCH-MIDAS模型的优点结合,在已有的研究基础之上进一步优化得到REGARCH-MIDAS模型。不同于以往使用收益率构建的已实现测度,本文将基于价格极差(RNG)构建的已实现测度引入黄金期货波动率建模之中,即利用测度方程将隐条件波动率与由日内数据构建的已实现测度联合建模。此外,本文不仅研究了地缘政治风险对黄金期货波动率的影响,还研究了本文构建的模型与基准模型在黄金期货波动率预测方面的优劣。实证分析中,本文选择了我国黄金期货(上海期货交易所的黄金主力合约)真实数据,研究地缘政治风险指数(GPR)对黄金期货波动率的影响。此外,为了更加深入研究GPR对于黄金期货波动率的影响,本文进一步将代理变量GPR细分为地缘政治威胁(GPT)指数和地缘政治行为(GPA)指数。实证结果显示,引入了杠杆效应、日内数据和地缘政治风险指数的REGARCH-MIDAS模型可以很好地利用金融市场中的有效信息,从而提高对黄金期货市场波动率的拟合能力;在分别研究GPR、GPA和GPT对黄金期货波动率的影响时,发现GPR和GPA对黄金期货价格波动的影响随着时间衰减较快,而GPT随时间衰减较慢,地缘政治风险中是地缘政治行为而非地缘政治威胁是引起中国黄金期货价格波动的具体风险因素;基于地缘政治风险的双因素模型中的核心参数,即衡量地缘政治风险对黄金期货长期波动的参数的正负性和显著性总体不变,地缘政治风险对于中国黄金期货市场的长期波动率有显著的正向影响,且该影响存在一定的滞后效应;相比于比较模型,引入GPR和RNG的模型拥有更好的样本外预测结果,且该结果通过了MCS和DM检验,表明REGARCH-MIDAS模型具有更好的预测黄金期货波动率的能力。
{URL}: https://link.cnki.net/doi/10.26916/d.cnki.gahcc.2022.000699
{DOI}: 10.26916/d.cnki.gahcc.2022.000699
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 智能评教系统的研究与实现
{Author}: 陈雨
{Tertiary Author}: 陈蕾
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 教学评价;可信度;文本排序;前后端分离;数据可视化
{Abstract}: 教学质量评估是高校监控、保障和提高教学服务与教学质量的重要手段,是教学管理者加强教学管理和决策教育发展的核心,是教师及时调整教学方式的参照。因此评教工作得到了高校、教学管理者和教师的普遍重视。但在目前的评教系统中普遍存在如下两个问题:学生敷衍应付评教或不适应新型教学模式等诸多因素大大削弱了评教结果的真实性;评教结束后,系统仅将学生评教的原始文本反馈给教师,未对文本进行质量评估后再行展示,降低了教师的查阅效率。针对上述问题,本文完成了以下三方面的工作:针对评教数据不够客观真实的问题,本文引入电商领域的评价可信度概念,提出了基于行为特征及关系网络的可信度算法。首先构建影响评论可信度的特征,借助多项式回归模型拟合并预测评论的诚实度,然后构建学生、评论内容和课程的关系网络,将依据特征生成的评论诚实度作为关系网的输入,利用学生、评论以及课程间的潜在联系,迭代计算学生的可信度、课程得分的可靠性和评论的诚实度。实验结果表明,该算法的平均绝对误差、均方误差和平均绝对百分比误差均低于经典回归模型和关系模型。针对评论文本质量良莠不齐的问题,本文提出了基于BERT语义度量的文本排序算法,按照评论质量进行排序,凸显更有价值的评论。算法模型包括两个阶段:在第一个阶段中,根据上下文偏置和句法关系提取出评教领域的属性词和观点词,将其作为核心词并加以组合,随机生成带有目标语义和结构上下文噪声的句子,从而泛化出一些观点性强、信息密度高的目标评论;在第二个阶段中,对Sentence-BERT进行微调后,计算待召回评论与目标评论的语义相似度,得到待召回评论的质量评估分值,最后将待召回评论按照分值降序排列,得到前Top-K条评论。本文提出的算法在折损累计增益、平均准确率和用户满意度上均优于传统模型。将上述算法的结果可视化,从而构建出全新的智能评教系统。系统基于B/S的开发模式,采用前后端分离的开发方式,选取Vue作为前端开发框架、Flask作为后端开发框架、My SQL作为数据库。开发完成后,对系统进行了功能测试和非功能性测试,测试结果符合预期。两个月的试运行表明系统功能完备且用户体验良好。综上,本文针对评教数据真实性不足和评论文本质量参差不齐等问题,创新性地研发了一个较为完整的教学评价系统,该系统生成的评教结果更加客观公正,同时提高了教师和教学管理者查阅评论的效率。该系统能更好地为教学评价提供智能计算支撑。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000303
{DOI}: 10.27149/d.cnki.ghdsu.2023.000303
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多语言图文识别关键问题研究
{Author}: 李永瑞
{Tertiary Author}: 汪增福
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度学习;计算机视觉;自然语言处理;文本图像;图文识别
{Abstract}: 作为传递信息的重要载体,文本图像在人们的生产生活中扮演着越来越重要的角色。本文以文本图像为主要研究对象,对图文识别算法及其下游应用算法进行了深入研究。
首先,本文研究了低资源语言的图文识别问题。低资源语言是指数据资源相对匮乏的语言。在多语言的图文识别领域,现有研究已经在图文数据资源较多的语言上实现了令人满意的识别性能。对于低资源语言,现有的方法并没有获得良好的图文识别效果,不能满足实际的应用需求。因此,如何解决图文数据资源匮乏的问题,提高低资源语言的识别准确率是一项重要挑战。
其次,随着跨国贸易和跨国旅游的日益发展,现实场景中多语言共存的情况越来越常见。许多相关应用只有在文本图像的语言类别已知的情况下才能正常地发挥作用。然而,现有的研究忽略了对共享同一字符表的不同语言的场景文本图像进行区分。为了解决现有研究存在的不足,本文研究了自然场景文本图像的细粒度语言判别问题。
最后,文本图像检索是图文识别算法的一个重要应用。现有的大部分场景文本检索研究以图像中包含的文字内容为线索完成检索任务。很多情况下这种单一的线索不能很好地满足人们对检索的实际需求。在这样的背景下,本文研究了场景文本图像的细粒度检索问题,综合考虑文本图像中的视觉目标和文字内容来完成图像检索。
本文的主要贡献和创新点如下:
1.以印地语为低资源语言的代表,研究了自然场景文本识别问题。一方面,本文根据印地语的特点设计了印地语文本图像合成引擎,合成了大量图文数据用于支撑模型的训练。另一方面,本文设计了印地语文本识别网络。实验结果表明,本文的方法在印地语图文识别任务中的识别准确率超越了已有研究中的最先进方法。
2.研究了自然场景文本图像的细粒度语言判别,解决了已有研究无法区分共享同一字符表的不同语言的文本图像的问题。不同于已有研究中的方法,本文提出的语言判别网络构建了图像中文本的语义表征,并基于语义特征预测文本图像的语言类别。语义特征为判别网络利用语言知识提供了载体。实验结果表明,本文方法的性能显著优于已有研究中最先进方法的性能。
3.研究了以自然语言描述的查询语句检索文本图像,所提出的方法以细粒度的方式考虑了用户检索文本图像时对于图像中文字内容和视觉目标的不同要求。给定一个自然语言描述的查询语句,本文的方法从图像中文字内容的角度和视觉目标的角度分别构建候选图像与查询语句的匹配特征,综合利用两种角度的匹配特征计算匹配度得分。实验结果表明,本文的方法有效应对了不同检索意图混在的挑战。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.002089
{DOI}: 10.27517/d.cnki.gzkju.2022.002089
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向军事领域的土-汉神经机器翻译关键问题研究
{Author}: 张贵林
{Tertiary Author}: 易绵竹
{Publisher}: 战略支援部队信息工程大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 土-汉机器翻译;神经网络;标准Transformer模型;军事领域;形态分析
{Abstract}: 面向军事领域的土耳其语-汉语神经机器翻译研究,属于低资源语言垂直领域机器翻译研究范畴。采用基于神经网络的机器翻译方法,通常需要将源语言词表的规模控制在3-5万之内,且神经机器翻译模型的训练往往需要大规模平行语料数据作为支撑。对于土耳其语这种低资源语言来说,必然面临着严重的数据稀疏问题,即常见土耳其语单词的数量可以达到百万量级,大量低频词将被处理为“未登录词”,进而影响翻译模型生成译文的流利程度。受利用源语言知识可进一步提升神经机器翻译性能这一发现的启发,本文尝试从“未登录词”处理、平行语料库构建、融入源语言句法信息等关键问题研究入手,分别利用形态分析方法构建土耳其语神经机器翻译词表、基于反向翻译的句对齐检验方法筛选开源土-汉双语平行句对、基于相似形态结构的句子聚类方法扩充土-汉双语平行数据、基于土耳其语军事术语自动抽取及替换的方法增强平行数据的军事领域属性,以期通过源语言数据精加工的方法提升土-汉神经机器翻译模型处理军事领域文本的能力,相关成果对于推动土耳其语-汉语神经机器翻译理论、方法和技术的发展无疑具有重要的学术探索意义。本研究的主要学术贡献如下:(1)针对土耳其语神经机器翻译词表构建、命名实体识别、领域术语抽取等多个自然语言处理任务,提出了一种基于词典和规则的土耳其语单词形态分析方法,构建了一个由“词根+形态句法标记”、“词根+形态标记”和“词根+屈折组”三种不同形态分析形式构成的土耳其语形态分析器。该形态分析器的形态分析词典以TS-Corpus形态分析词表为基础,额外增加了固定搭配、命名实体词缀、未登录词、拼写错误、复合词和形态消歧规则表,词条总数为1120000余个。形态消歧规则包括基于单词同现约束、基于格词缀标记约束和基于单词整体形态句法标记约束的消歧规则三类。土耳其语形态分析器具有开放式的词表优化功能,可有效避免规则之间发生相互冲突的问题。实验分析结果表明,利用上述三种方法对词表规模为742060词形式的153万句土耳其语训练语料进行形态剖析,土耳其语总词表规模分别缩减84.36%、84.78%和85.33%,相较于基础形态分析词表,基于“词根+屈折组”的形态分析方法可使常用词汇减少21.4%。(2)针对土-汉双语平行语料资源匮乏问题,提出了一种基于形态分析的土耳其语句子聚类方法,设计了一个基于句子聚类的土耳其语简单句抽取工具。该程序主要包括基于“词根+UNK”的词根结构聚类、基于“词缀+UNK”的句法结构聚类和动态增加专有名词、时间、日期、数字标记的句子结构聚类三种聚类方式。按照高频结构语句抽取、在线机器翻译实验和半监督式译文选取三种操作,本文首先从规模为500万句的土耳其语单语语料库中抽取了500种最常见结构语句,然后利用必应、小牛和谷歌在线翻译系统获取相应的汉语译文,通过人工干预的方法构建了一个规模约为10000句的土-汉双语平行语料库,结果表明通过该方法可有效获取一定规模较高质量土-汉双语伪平行数据来扩充训练语料。(3)针对开源土-汉双语平行数据对齐错位、译文质量差等问题,提出了一种基于反向翻译的土-汉双语句对齐检验方法。该方法首先利用谷歌在线机器翻译系统获得待检验语句的反向翻译译文,然后通过构建词袋模型进行句子语义相似度计算,进而自动实现土-汉平行语句对齐的检验和抽取。本文基于该方法对210万个土-汉双语句对进行筛选,共抽取保留153万个句对作为通用领域翻译模型训练语料,有效提升了土-汉双语平行语料库的质量。(4)针对军事领域机器翻译系统无法回避的专业术语问题,提出了一种基于混合策略的土耳其语军事术语抽取方法,设计了一个面向军事领域文本的土耳其语军事术语自动抽取工具。本文首先对航空、通信和军事三个领域的术语词典进行对比分析,提取了土耳其语军事领域术语的独有特征,然后根据这些特征构建了停用词表、关键词表和形态分析词表序列模式列表,并最终通过点互信息、信息熵和左右临接词缀实现了术语自动抽取工具的构建。在此基础上,本文构建了一个规模为1500个词条的土-汉军事术语词表,并利用该词表对规模为9万句的军事领域土-汉伪平行数据进行了优化。(5)针对神经机器翻译模型无法学习数据之外先验知识的短板,提出了基于序列和基于表示学习的词法信息融合方法,对土耳其语词根序列和形态句法标记序列分别进行编码,并将拼接后的隐层状态表示用于模型训练的词向量表示,结合基于BPE算法的子词切分方法,训练了7个面向通用领域和2个面向军事领域的标准Transformer土-汉神经机器翻译模型。根据BLEU评测结果,基于形态分析构建土耳其语神经机器翻译词表的方法明显优于基于BPE算法的子词切分方法,其中“词根+屈折组”的形态分析方式效果最佳,据此训练的通用领域翻译模型BLEU评测结果相较于BPE基线模型提高了1.15,据此训练的军事领域翻译模型BLEU评测结果相较于通用领域翻译模型分别提高了1.82和1.58。通过“词根+形态句法标记”和“词根+形态标记”的方式进行形态分析结果表明,基于表示学习的平行编码方式训练的翻译模型优于基于单一序列编码方式训练的翻译模型。本文探讨了融合语言学知识和数据增强方法在低资源条件下土-汉神经机器翻译领域的应用,主要针对神经机器翻译词表设计、军事术语自动抽取和土-汉伪平行数据构建这三个关键问题分别制定了适用性强的技术策略,可显著提升土-汉神经机器翻译的性能,并取得了良好的实验结果,为垂直领域土-汉神经机器翻译研究提供了新思路和新方法。在将来的研究工作中,相关数据和技术成果可扩展应用于其他低资源语言信息处理任务,以满足未来军事任务需求。
{URL}: https://link.cnki.net/doi/10.27188/d.cnki.gzjxu.2022.000109
{DOI}: 10.27188/d.cnki.gzjxu.2022.000109
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于依存语法理论的柬埔寨语句法分析研究
{Author}: 帅洪福
{Tertiary Author}: 吕春燕
{Publisher}: 战略支援部队信息工程大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 柬埔寨语;依存语法;句法分析;NLP;语料库
{Abstract}: 柬埔寨语句法分析对于柬埔寨语语言本体研究、NLP研究和教学实践等均具有十分重要的理论意义和实用价值。从语言学角度来看,柬埔寨语句法分析是上承词法分析、下启语义分析的关键环节,是表层语法结构与深层语义结构连接的枢纽。从NLP角度而言,柬埔寨语句法分析的成效,直接影响到问答系统、机器翻译、信息抽取等高级任务的运行效率,是柬埔寨语NLP研究的重点和难点。从教学实践角度来说,柬埔寨语句法分析是真正弄通学懂柬埔寨语的必备技能,也是判断教学效果的重要依据。然而,目前学界对于柬埔寨语句法的研究仍然比较薄弱,在语言学方面缺乏系统的描写和阐释,在NLP方面还主要停留在词法分析阶段,教学实践中对句法分析也是浅尝辄止。本文以柬埔寨语句法为研究对象,采用依存语法理论从语言学和NLP两个层面对柬埔寨语的句法问题展开论述,以期促进柬埔寨语句法研究的开展,重点推动柬埔寨语NLP研究实现由词法分析向句法分析的突破。根据任务特点,按照“先上游再下游、先理论后实践”的研究顺序,主要着眼于解决以下四个问题:(1)解决柬埔寨语中缺乏大规模高质量标注语料库的问题,通过构建符合规范的大规模标注语料库,为后续柬埔寨语词法和句法研究创造基础条件。(2)解决柬埔寨语词法分析难题,主要包括分词和词性标注两大主干任务,以奠定句法分析的基础和前提;(3)解决缺乏理论分析的问题,使用依存语法理论对柬埔寨语句子进行语言学层面的阐释和说明,以形成柬埔寨语句法研究的理论依据;(4)解决实际应用问题,以依存语法理论为指导,提出柬埔寨语自动句法分析的策略,并开发一个小型句法分析器进行验证。主要解决思路和研究内容如下:(1)以柬埔寨语文本中存在的零宽度空格(ZWSP)为突破口,利用爬虫获取大规模包含ZWSP的语料数据,并使用正则表达式对数据进行标准化处理。通过将ZWSP转换为半角空格,跳过人工分词环节,最终搭建起一个大规模的分词语料库,作为本研究的数据支撑。本环节旨在解决柬埔寨语中缺乏大规模高质量标注语料库的问题,为后续柬埔寨语词法和句法研究创造基础条件。(2)通过统计分析,获取语料库中常用词的分布及单音节词的使用频率等数据。并基于这些语料库统计信息和柬埔寨语官方词典,构建一个高质量的词表。融合利用“双向最大匹配算法”“正则表达式”“高棉字符簇”三种方法,采用“规则+统计”的处理思路,开发出高质量的柬埔寨语分词模型。在分词模型的基础上,利用柬埔寨语官方词典和基于N-gram模式的三元搭配信息以及使用频率,开发出分词和词性标注联合模型。本环节旨在解决柬埔寨语词法分析难题,尤其是分词和词性标注准确性不够的问题。通过综合分析问题原因、提出解决问题思路以及开发联合模型的方式,最终使柬埔寨语分词和词性标注的准确性达到较高水平,能够支撑下游任务的开展。(3)高质量分词和词性标注联合模型的开发,为柬埔寨语句法研究打下坚实基础。本研究使用依存语法对柬埔寨语句法结构进行了系统全面地描述和说明,从“多词结构”“基本句法结构”“特殊句法结构”三个方面详细进行了举例阐释。同时依据柬埔寨语的语言特点,按照Universal Dependencies的依存关系规范,对柬埔寨语句子成分之间的各类依存关系进行了约定,认为柬埔寨语中包含27种依存句法关系。本环节旨在解决柬埔寨语句法研究缺乏理论分析的问题。本文使用依存语法中关于句法分析的理论对柬埔寨语句法进行了全面的描写和阐释,首次从理论层面对依存语法在柬埔寨语句法研究中的应用进行了探讨。(4)在上述研究的基础上,基于“分治策略”,提出可以利用传统语言学中“词性”“位置”“搭配”“句法功能”等要素,按照“逐层合并”“支配权转移”等思路,实现句法分析由词汇层向句法层的移进。最终以规则驱动的方式设计出柬埔寨语依存句法分析的主要流程,为柬埔寨语依存句法分析器的开发提出了策略思路。本环节旨在解决柬埔寨语句法分析的实际应用问题。本文对柬埔寨语依存句法分析器的设计提出了构想,从基于规则角度指出柬埔寨语依存句法分析的实践路线。经过范例测试,验证了该思路的可行性,并开发出一个简单的依存句法分析器进行语料的测试和训练。可以看到,一是ZWSP在构建柬埔寨语大规模高质量标注语料库中能够切实地发挥效果,极大地节省了人工标注的时间和精力,尤其是能够确保标注标准的统一以及取得较高的准确度;二是依存语法理论在应对柬埔寨语句法分析问题时,无论从语言学理论层面,还是NLP实践层面均能够较好地得到运用,是一种值得进一步关注和研究的理论。三是柬埔寨语句法分析研究,在大规模标注语料库和依存语法理论的支撑下已经真正地实现了理论和实践的结合,柬埔寨语NLP研究实质性地由词法分析转向句法分析。
{URL}: https://link.cnki.net/doi/10.27188/d.cnki.gzjxu.2022.000135
{DOI}: 10.27188/d.cnki.gzjxu.2022.000135
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的事件论元抽取方法
{Author}: 林家驹
{Tertiary Author}: 金健
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自然语言理解;信息抽取;事件论元抽取;提示学习;因果推断
{Abstract}: 事件论元抽取是事件抽取的一个子任务,是信息抽取领域的一个重要研究方向。该任务旨在从无结构文本中抽取结构化信息。在情报收集、知识提取、文档摘要、知识问答等领域有着广泛应用。具体来说,给定一个事件类别与对应的事件触发词(trigger)的前提下,从句子中抽取对应的论元(argument)。目前主流的事件论元抽取模型是基于序列标注的方法。然而这些方法无法在低数据的条件下表现良好,同时这些方法也不能有效地建模跨句论元之间的依存关系。近年来,一种被称为提示学习的方法逐渐流行。其利用语言模型的庞大参数量,将一段自然文本作为提示词语,直接生成任务所需的结果。这类方法能一定程度上缓解训练样本过少的问题,然而,目前对有效构造提示语句的方法研究较少。同时对提示学习如何适应论元抽取任务的相关研究也仅仅处于起步阶段。针对上述问题,本文对事件论元抽取中如何更好地利用和改进提示学习技术,进行了一系列探索性研究。首先,本文提出了一种基于课程学习的提示调优方法,研究了如何充分利用小样本数据与跨句论元构造提示文本,改进抽取效果。进一步地,本文探索了不同提示文本构造方法之间的区别,并研究了它们的作用机理。在此基础上,本文提出了一种基于后门调整的方法改进提示语句的构成。本文贡献如下:1针对长距离论元-触发词依赖与论元关系建模问题。本文提出了一种基于课程学习的方法,借助于AMR图和课程学习,有效地利用了提示模版的知识。实验结果表明,我们的方法在RAMS和Wiki Events两个数据集上取得了最优结果。2主流的离散提示方法分为两种:基于名称的与基于本体的,我们比较了两种提示构造方法。在三个数据集上的实验结果表明,基于本体表示的提示语句能依靠句法依存关系进行抽取,进而取得更好的效果。3基于本体表示的提示语句能依靠句法依存关系进行抽取,但是这也会带来新的偏差。基于以上研究,我们从因果分析的视角,对基于提示学习的论元抽取方法进行了分析,发现了其中存在的后门路径,并对其进行了调整,实验结果表明,经过后门调整后的方法更加鲁棒,在少样本的实验设置中表现更加优异。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000301
{DOI}: 10.27149/d.cnki.ghdsu.2023.000301
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的问答系统的研究与医学场景应用
{Author}: 李瑞东
{Tertiary Author}: 鄂海红
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;问答系统;智能问诊
{Abstract}: 国民生活水平随着经济发展的提高,对健康民生问题的观念愈发重视,人们的问诊需求亦不断增加,传统的搜索引擎也难以满足人们日益增长的获取知识的需要,现常常面临如下挑战:1)医疗问诊需求大,传统医疗问答系统精度不足2)智能问答系统搭建技术门槛、行业门槛高,训练语料的获取和标注困难。3)高血压问诊领域尚未有满足知识深度的智能问答系统。针对以上问题和挑战,本文对基于知识图谱的智能医疗问答系统进行设计与实现,主要研究内容如下:1)设计并实现一个基于知识图谱的医疗问答原型系统。分离业务与技术,减少医疗专家的依赖,降低计算机知识门槛,简介高效地搭建智能医疗问答系统。支持图谱管理,语料标注、意图配置。业务人员导入图谱后,配置意图、标注语料,即可一键训练一个具有专业知识的智能医疗问答系统。2)提出一种语料构建方案和基于知识文本的问答方案。设计并实现了一种基于实体与关系拼接的语料构建工具,通过替换本体域下的不同实体及对应关系构造训练样本,引入对比损失函数,提高语言模型对自然语言问句与知识文本的匹配能力,提升问答流程的精度的稳定性。3)基于高血压领域的专业文献抽取了专业知识。结合面向高血压场景的智能问诊,设计了本体域与实体关系,构建了高血压知识图谱,并面向该场景实现了高血压知识领域的智能医疗问答系统。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.001504
{DOI}: 10.26969/d.cnki.gbydu.2022.001504
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体表征与场景理解的隧道施工风险识别评估与管控方法研究
{Author}: 陈再励
{Tertiary Author}: 吴立
{Publisher}: 中国地质大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 隧道施工;危害识别;风险管控;计算机视觉;深度学习
{Abstract}: 隧道施工安全管理是支撑我国隧道产业高质量发展的重要基础,面向复杂作业环境和工程条件时的隧道施工现场安全风险识别评估与管控是亟需解决的关键问题。为转变传统施工安全检查以人工为主、时间人力密集、流程主观、管理被动的工作模式,本文以基于视觉深度学习的风险影响因素识别为基础,深入研究施工场景中“人、机、环、管”等因素的结构化表征与理解算法,探索适应于视觉检查对象结构化、本体化安全规则的动态检查方法,研发基于计算机视觉的风险自动识别管控系统VAHIMS,建立隧道施工场景数据档案、安全标签与画像,并为安全管理人员根据场景安全特征分类采取有针对性、差异化的管控措施提供决策辅助。具体研究内容与贡献如下:(1)隧道施工的安全风险影响因素及其作用机理分析。以隧道工程的施工特点为基础,结合施工危险源在隧道场景研究中的内涵与外延,开展隧道施工风险要素研究,并应用解释结构模型建立关键风险因素间多层次逐级递进的关系作用结构,总结隧道安全管理与风险管控工作模式及面临挑战,指明隧道风险识别评估与管控的研究目标和控制对象。(2)基于人体结构化表征的隧道施工作业人员风险评价。为降低施工人员不规范作业行为产生的安全风险影响,研究视觉感知下非侵入式、无接触的作业行为风险评价方法。首先,构建复杂施工环境下人体姿态估计模型,提高光照不均、背景差异、部分遮挡等条件下的人体二维数据结构化表征能力;然后,提出一种人体骨骼关节运动相位状态特征提取方法,通过人体动作时关节点间的同、异步关系规律,判断作业规范性;接着,改进人机工效学领域REBA评估方法,结合模糊逻辑优化关节点角度临界时的跳变干扰,提高评分准确度;最终,通过攀爬作业的案例研究,展示了以人体骨骼关节点结构化信息的作业姿势风险自动化识别评估流程,结果表明该方法能够有效预防因不恰当作业姿势带来的施工风险,改进作业姿势规范,预防职业相关骨骼肌肉疾病及进一步演化,降低因其影响工人身心状态导致事故发生的概率。(3)围绕施工场景视觉语义信息理解的现场风险识别与分级预警。考虑到脱离场景中作业机具、施工环境等信息,孤立地讨论人的作业行为对整体的安全管理而言相对低效,本文通过施工场景中实体目标检测和语义关系分类两阶段场景图生成方法,提取场景图像中“人、机、环”视觉信息和语义关系特征,建立面向隧道施工现场的多模态表征和语义理解,并提出基于场景检查规则图的风险自动推理框架。首先,基于领域先验知识对目标检测结果稀疏化,完善实体目标配对预处理,提升视觉关系预测效率;其次,融合视觉表象、位置关系、人体姿态、语义先验等特征实现以人为中心的视觉关系检测,并采用样本数据调整和Logit Adjustment损失函数训练优化的策略抑制长尾效应影响,改善视觉关系预测检测结果精度;进一步地,提出基于施工现场的安全规则三元组格式化后的检查策略,识别风险并分级预警。最后,通过实验案例进行分析说明,展示了基于施工现场场景信息和规则语义比对的风险自动推理过程,提升了安全风险检查的智能化水平。(4)融合场景规则的隧道施工风险管控体系建立。为适应不断迭代更新的安全管理规则对施工风险管控提出的动态优化要求,研究了施工安全规则和知识本体的结构化处理算法,并构建了基于场景数据档案的安全标签画像分类,支撑风险管控有针对性、差异化的决策输出。首先,设计了基于自然语言处理技术的安全规则文本内容结构化模型,自动提取施工规则文档中的关键语义并将数据三元组格式表征;其次,构建了基于本体理论框架的安全规则知识库,有效管理施工过程中文本形式的各类显隐性安全知识,弥补了人工提取文本规则的缺陷,完善了基于“场景语义图—检查规则图”匹配比对机制的施工风险自动推理机;最后,建立施工场景安全检查档案库,通过数据聚类算法提取场景标签和安全画像,为安全管理人员提供直观的风险管控决策依据,同时落实“PDCA-SDCA”双循环管理模式,建立反馈、优化的动态调整机制,促进隧道施工安全管理工作逐级稳步提升。(5)隧道施工风险识别评估和管控的实际案例研究。鉴于以一线安全员人工观察为中心的现场安全检查主观依赖、劳动密集、耗时费力,研发基于施工现场视觉监控数据的风险识别、评价管控、决策辅助统一VAHIMS系统,并通过福州引水工程输水隧洞建设项目安全管理工作的实际应用,介绍了VAHIMS系统的架构设计、开发方案和应用逻辑并结合同一施工区域前后两阶段的对比实验,分析了VAHIMS系统的实战效果,结果表明基于视觉的安全风险检查能够有效地辨识场景中的各类风险,减轻安全员工作负荷,同时结合场景标签画像的分类管理策略促进施工现场人员安全意识,提升整体安全水平。最后,结合自身体会提出了隧道施工风险管控的发展建议。本文针对隧道施工安全管理任务中风险识别评估和管控任务,应用视觉传感和深度学习技术,实时感知隧道施工场景中视觉可测的风险因素,建立场景安全档案和标签画像,采取针对性分类管理措施,有效提升场景的安全属性,促进隧道安全管理发展。
{URL}: https://link.cnki.net/doi/10.27492/d.cnki.gzdzu.2022.000322
{DOI}: 10.27492/d.cnki.gzdzu.2022.000322
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 蒙古语复合名词语义网络构建研究
{Author}: 阿木古楞
{Tertiary Author}: 青格乐图
{Publisher}: 内蒙古师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 蒙古语复合名词;概念;语义关系;区别特征;语义网络
{Abstract}: 蒙古语复合名词语义网络是以蒙古语近义复合名词集为概念表征,连接概念之间多种语义关系和区别特征而建立的一种词汇语义知识库。目前,蒙古文信息处理研究中基于语法信息的词法分析、浅层句法分析等研究取得了一定的成果。为使计算机具有更深层次的蒙古文信息处理能力,建立面向信息处理的蒙古语语义知识库的需求越来越紧迫。本文在系统分析英语、汉语词汇语义网络研究以及蒙古语词典学研究的前提下,从蒙古语复合词词库中选择五千七百多条蒙古语实体复合名词作为研究对象,运用语义场理论、文献法、义素分析法、合并法等理论和研究方法开展词汇语义分析与应用研究。重点探讨蒙古语复合名词语义网络框架、蒙古语复合名词概念库、概念关系库以及基于此的检索应用平台有关学术问题,构建了反映蒙古语实体复合名词语义特征的蒙古语复合名词语义网络。其目的在于将其应用于词汇语义分析、信息检索、词义消歧、文本校对、机器翻译、知识推理等应用系统,为计算机更好的理解和处理蒙古文提供一个强有力的、适用的词汇语义知识库资源。论文由绪论、五章正文、结语、参考文献等四个部分组成。绪论部分,阐述了选题缘由、词汇语义网络国内外研究现状、语料来源、研究内容与目的、研究方法、研究意义等内容。第一章,深入分析词汇语义网络相关理论研究。对英文词网Word Net的词类划分、概念表征方法、概念之间的多种关系、数据库、具体实现方法等多项研究内容以及蒙古语词典编纂与研究总体情况进行了系统的论述。通过上述分析,为蒙古语复合名词语义网络框架的构造提供了理论与实践基础。第二章,研制蒙古语复合名词语义网络的框架结构。在参考英语、汉语词汇语义网络以及蒙古语词典学研究的基础上,根据蒙古语特有属性和蒙古文信息处理研究的现状与需要,以“蒙古语复合名词语义网络的基础研究”和“蒙古语复合名词语义网络的具体实现”两个研究部分,重点探讨并刻画了蒙古语复合名词语义网络的框架结构。第三章,建立以蒙古语近义复合名词集为概念表征的蒙古语复合名词概念库。首先,基于蒙古语近义复合名词的研究,提出了“同义、近义、语义相关”三种蒙古语近义复合名词的细分体系。其次,深入研究了蒙古语近义复合名词每个种类的定义、判定方法、语义特征、形式关系、构成情况、各种类之间的关联与区别等多项理论问题。最后,以人工为主、人机交互为辅的方式总计建立了由6406个词组成的4905个蒙古语近义复合名词集,从而构建了蒙古语复合名词概念库。第四章,开展构建蒙古语复合名词概念关系库的研究。在对蒙古语复合名词之间反义、上下位、类义等三种语义关系和部分整体一项区别特征的定义、判定方法、语义特征、种类、形式关系、各类关系之间的关联与区别等多项理论问题进行重点研究的基础上,分别建立了上述蒙古语复合名词概念之间的多个种类关系库。同时,提出了建立蒙古语复合名词概念的属性和修饰、功能与推理两种区别特征的方法并做了实验研究。第五章,设计和实现蒙古语复合名词语义网络应用平台。对蒙古语复合名词概念库和概念关系库的数据进行了关联,并为词典编纂者提供了附有持续扩充与修改功能的蒙古语复合名词语义网络数据库,也为用户构建了蒙古语复合名词语义网络检索平台。从而实现了蒙古语复合名词概念之间多种语义关系和区别特征的检索,进而完成了蒙古语复合名词语义网络的初步构建。结语部分,归纳总结了蒙古语复合名词语义网络框架、蒙古语复合名词概念库、蒙古语复合名词概念关系库、蒙古语复合名词语义网络应用平台等四项主要研究内容。同时,基于本文研究经验,提出了下一步的研究展望。
{URL}: https://link.cnki.net/doi/10.27230/d.cnki.gnmsu.2022.001192
{DOI}: 10.27230/d.cnki.gnmsu.2022.001192
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于领域知识图谱的FAQ问题匹配研究
{Author}: 赵昊旻
{Tertiary Author}: 刘宇
{Publisher}: 武汉科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 预训练模型;知识图谱;语义相似度;问答系统
{Abstract}: FAQ系统的工作原理是将用户提出的问题与问题库中的问题进行匹配,找到语义相似的问题。现有FAQ系统并未针对特定领域进行优化,没有引入领域知识。本文以操作系统领域为例,研究了基于领域知识图谱的FAQ问题匹配。在操作系统FAQ中,用户所提问题通常存在包含缩写、专有名词较多和表述不规范等情况,从而影响了问题匹配结果的效果。此外,用户所遇问题通常与操作系统的操作界面有关,利用截图信息可以有效地增强问题匹配的性能。针对缺少领域知识的情况,本文构建了操作系统知识图谱,以期增强问题匹配的性能。为提高融入知识的准确性,本文提出了知识筛选方法,先从知识图谱中尽可能地选取候选实体,再使用知识筛选模型分析候选实体与问题之间的语义关联,确定相关知识实体。为了充分地利用知识,本文对融入知识的预训练模型K-BERT做出了改进,提出了FK-BERT模型。FK-BERT模型既考虑了单个问题内部实体之间的关系,也考虑了两个问题之间的实体关联关系。针对未充分利用图像信息的情况,本文从领域图像中提取了信息。为了利用操作系统截图中包含的文本,本文使用OCR识别图像中的文本,并使用图像中的文本是否高亮、相对位置和与问题文本的关联程度三个指标,筛选出图像中重要文本。为了将图像文本信息输入FK-BERT模型,本文对模型做出了如下改进:将图像中的每一块重要文本的相对位置设为相同,同时,使图像中的文本对原始问题文本没有注意力影响。实验结果表明,知识筛选步骤能有效的提升融入知识准确性,其对K-BERT和FK-BERT的性能均有所提升。FK-BERT相较于K-BERT模型考虑了更多实体间的关系,融入的知识更完整,在问题匹配上取得了较好的效果。同时,使用领域图像信息增强来优化问题对匹配是有效的,使用图像信息增强的问题匹配,取得了更好的精确率提、召回率和F1得分。此外,本文还实现了操作系统领域的FAQ原型系统,该系统在速度和准确率指标上能较好的满足实际需要。
{URL}: https://link.cnki.net/doi/10.27380/d.cnki.gwkju.2022.000513
{DOI}: 10.27380/d.cnki.gwkju.2022.000513
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向不同语义粒度约束的文本生成方法研究
{Author}: 潘囿丞
{Tertiary Author}: 王晓龙
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 语义粒度;语义约束;文本生成;问题生成;查询语句生成
{Abstract}: 近年来随着深度学习模型的快速发展,与文本生成相关的研究工作日渐增多,并取得了突破性进展。文本生成方法也在越来越多的任务场景中得到应用,所带来的实际价值日益凸显。但在面对不同粒度的语义约束时文本生成仍面临如下挑战:(1)在基于词的离散语义约束下,如何处理离散词与生成目标之间存在一对多的映射关系;(2)在融合词间关系的结构化语义约束下,如何在生成模型中对词间的结构化关系进行表示;(3)在基于短文本的语句级语义约束下,如何保证源语句与生成目标之间的语义一致性;(4)在基于长文本的篇章级语义约束下,如何实现生成目标与长文本片段之间的语义关联。本文围绕上述问题开展研究工作,主要研究内容包括以下四个方面:第一,针对离散语义在文本生成过程中的多样化表示问题,进行了基于离散语义约束的多样化问题生成方法研究。该方法首先采用Transformer作为主体框架,其次在编码时将已生成的历史问题与离散词信息进行拼接共同作为输入,既可以保证生成的问题不偏离主题又可以使得当前生成的问题与历史问题有足够的区分度,最后在解码时引入可训练的控制信号对每一类问题的公共特征进行表征学习,进一步确保了生成问题的多样性。以百度知道为来源构建任务数据集并进行验证。实验结果表明,本文提出的方法在相关性和多样性两项指标上均明显优于其他基线方法,展示了历史信息和控制信号对模型性能的提升作用。第二,针对结构化语义关系在文本生成模型中的表示学习问题,进行了基于结构化语义约束的文本生成方法研究。该方法首先采用基于门控循环单元的双向编码器对离散的主题词进行编码,其次采用基于多头自注意力机制的编码器对知识图谱进行编码,并将节点的邻接关系纳入到注意力机制的运算当中,使得实体之间的关联关系更加明确,最后将主题词和知识图谱表示共同输入到解码器中进行文本生成。以中文医学文献为基础构建任务数据集并进行验证。实验结果表明,使用医学知识可以有效帮助文本生成模型提高性能,并验证了对知识图谱整体结构进行建模可以进一步增强模型性能。第三,针对语句级语义表示与生成目标之间的语义一致性问题,进行了基于语句级语义约束的查询语句生成方法研究。该方法首先对给定的输入文本进行实体链接并采用预训练语言模型进行编码,其次按照查询语句的结构特性将文本问题解码成对应的抽象语法树作为中间表示,最后根据语法规则将中间表示转换成可执行的查询语句。在公开的医学文本到查询语句数据集上进行验证。实验结果表明,在包括逻辑形式、执行准确率等各项指标上,本文提出的方法均远远优于其他基线方法,验证了实体链接和抽象语法树在保持语义一致方面的有效性。第四,针对篇章级语义表示与生成目标之间的语义推理问题,进行了基于篇章级语义约束的复杂问题生成方法研究。该方法首先采用基于门控选择机制的编码器对给定长文本以及答案分别进行编码,其次根据正确答案使用预训练模型对问题意图进行预测并将意图表示作为解码器的初始化表示,最后通过使用注意力机制将长文本和答案进行融合共同用于生成问题。在公开的机器阅读理解数据集上进行验证。实验结果表明,在各项评价指标上,本文提出的方法均高于其他基线方法,验证了意图信息可以有效地增强生成问题与长文本之间的语义关联。综上所述,本文对不同语义粒度约束的文本生成方法进行了深入研究和讨论,并针对其中的关键问题,分别提出了基于离散词的多样化问题生成方法,基于知识图谱的文本生成方法,面向短文本的查询语句生成方法以及面向长文本的复杂问题生成方法。通过进行大量实验和分析,在对应数据集上进行了验证,最终所有提出的方法均获得了不错的表现。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.000163
{DOI}: 10.27061/d.cnki.ghgdu.2022.000163
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理技术的电商商品标题类目分类算法研究
{Author}: 闫俊阳
{Tertiary Author}: 薛河儒
{Publisher}: 内蒙古农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;短文本分类;机器学习;TF-IDF词向量;Word2vec词向量;LSTM-Self-Attention模型
{Abstract}: 电商直播带货是国内近年以来新兴起的一个行业,它大大地推动了国民经济的发展,并且为国民带来了巨大的生活便利,也为商家提供了一个更有利于发展的平台。然而这个新兴起的行业发展异常迅速,平台在巨大的利益面前忽略了在数据处理方面的缺点,即数据的自动化处理,所以在这个领域依然处于人工处理阶段,这大大地降低了数据处理的效率。所以基于此,本文针对电商直播带货行业产生的商品标题类目分类进行了研究。内容如下:(1)利用网络爬虫技术针对淘宝与抖音2021年排名前十主播所属直播间曾直播带货销售过的商品信息进行抓取,共得到31237条数据,数据集共识别四类商品标题:服饰、美妆、生活和食品,其中“服饰”类别10035条,“美妆”类别8954条,“生活”类别6845条,“食品”类别5403条。针对总数据量将其随机分为三个不同训练集和测试集比例的数据集:数据集Ⅰ、Ⅱ和Ⅲ,数据量分别为10000条、10000条和11237条,其训练集和测试集比例分别为60%和40%、70%和30%、80%和20%。(2)针对数据利用Jieba工具进行预处理操作,即去噪、分词,由于数据本身特征原因,所以并不需要去停操作。然后利用TF-IDF和Word2vec两种词向量模型分别提取文本特征,将输出的结果分别输入到机器学习模型和LSTM-Self-Attention混合模型中进行分类。(3)利用决策树、随机森林、朴素贝叶斯和XGboost四种机器学习算法模型对商品进行分类,经分析计算,针对数据集Ⅱ的分类正确率均高于其他两个数据集,并且其中XGboost效果最好,准确率达到90.89%。(4)构建LSTM-Self-Attention混合模型,模型由三层组成,分别是自注意力加权层,长短期记忆网络分类层以及Softmax归一化处理层,其中自注意力加权层为Word2vec模型输入的词向量赋予Attention权重,然后输入到长短期记忆网络分类层中进行分类,最后再通过Softmax层进行归一化处理得到最终的商品标题分类的类别。LSTM-Self-Attention混合模型相比于机器学习算法模型,其分类效果更好,针对数据集Ⅱ的分类准确率达到92.09%。
{URL}: https://link.cnki.net/doi/10.27229/d.cnki.gnmnu.2022.000599
{DOI}: 10.27229/d.cnki.gnmnu.2022.000599
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于检索和知识图谱结合的开放域中文问答系统设计与实现
{Author}: 缪鹏飞
{Tertiary Author}: 张小洪
{Publisher}: 重庆大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 中文问答系统;多问答模式;问句分解;问句匹配;语义实体识别
{Abstract}: 问答系统作为一种自动问答的智能答疑方式,基于深度学习和自然语言处理相关技术,通过分析自然语言问题,充分理解用户意图并实时反馈答案,兼具精准性、敏捷性、高效性,传统的问答模式根据信息来源和格式可以分为离线检索、在线检索和知识图谱检索。离线检索问答系统基于文档型的问答对,检索效率和准确率高,适用于专业性较强的限定领域;在线检索问答系统基于在线社区问答,数据时效性高范围广,适用于开放域的信息检索;知识图谱问答系统针对事实型问答,以大型语义库作为数据支撑,适用于知识类检索。虽然以上三种问答系统在特定应用场景下具备较好的问答效果,但是单一模式的问答系统无法充分利用不同来源的信息,并且难以从跨领域的数据中筛选出最佳答案,使得问答系统的灵活性和准确性受到影响。本文的开放域中文问答系统应用于智能客服平台的智能问答模块,充分融合三种单一问答模式的优点,旨在为不同业务领域提供智能咨询服务。具体研究工作包括以下几个方面:首先,提出了基于语义解析的问句分解方法框架。为了解决问句分析阶段仅使用命名实体识别和语义角色标注算法无法有效区分语义实体的问题,本文在语义解析工具的基础上,提出SDP-enhance方法,通过实体词特征、连续实体特征、连接词特征、反转词特征、修饰词特征等多个维度的特征组合分解问句,识别有效的语义实体,提取包含并列和叠加关系的三元组语义槽,并提出OSG-enhance方法,通过知识图谱进行实体链接和实体扩充,提高语义实体的覆盖率。其次,提出了基于多标签分类和句向量相似度的问句匹配方法。在数据预处理阶段,选取高质量的开放域中文问答对,根据标签关键词构造每个标签对应的语义空间,通过文本分类算法得到问句的标签,再通过句向量算法将问句转换为向量形式归类到问句标签对应的语义空间下;对于用户输入的问题,先计算出问句的候选语义空间集合,然后遍历候选语义空间,通过计算问句和候选问题的句向量相似度得到相似度最高的10个候选问题。最后,在实验中对本文提出的方法进行有效性验证,设计与实现了应用于智能客服平台中的开放域问答系统,并在生产环境中对系统服务进行验证。通过实验验证,基于语义解析对问句进行分解,能提高语义实体识别的准确率,进而在一定程度上提高问句生成和答案抽取的准确率;基于文本分类和句向量模型对问句进行分步匹配,有利于加快候选问题集的匹配速度,提高检索效率。系统使用本文提出的问句语义分解方法和问句分步匹配方法,实现了三种问答模式下的问句分析、问句重构、信息检索、答案抽取、答案生成的完整问答流程。系统测试结果表明,本文设计的应用于智能客服平台的开放域中文问答系统拥有良好的准确性和系统响应时间。
{URL}: https://link.cnki.net/doi/10.27670/d.cnki.gcqdu.2022.001324
{DOI}: 10.27670/d.cnki.gcqdu.2022.001324
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的网络舆情文本分类方法研究
{Author}: 马冰
{Tertiary Author}: 张彤;彭伟
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本分类;网络舆情;深度学习;BERT;卷积神经网络
{Abstract}: 随着各类网络社交媒体平台的兴起,社会舆论已经转向网络空间,形成了海量的网络舆情,并且大量专业术语和特定用语的出现,导致网络舆情难以及时发现,舆情事件频发。为了防范潜在的舆情风险,一般使用文本分类方法对网络文本进行初筛,然后使用数据挖掘方法对高敏感主题进一步分析处理。但是针对大规模的网络文本,现存方法对掺杂其中的语法和句法信息未能充分利用,并且未针对敏感主题文本的低资源问题进行处理,导致舆情文本分类的准确率和效率偏低。本文利用自然语言处理等技术,提出了基于深度学习的文本分类模型,提高了网络信息监管机制的效率。本文主要包括以下三个方面:
(1)针对网络文本中语法句法知识未充分利用的问题,本文提出了一种基于多层信息融合的网络舆情文本分类模型。该模型采用基于注意力机制的多层信息融合算法,实现提高句向量表征的信息维度,并且对特征提取器输出的多层向量按照训练出的权重参数进行特征融合,从而提高了文本分类的预测精度。在真实数据集上的实验表明,本文提出的基于多层信息融合的网络舆情文本分类模型多类别分类下F1值达到83.98%,较基准模型提升达6.41%。
(2)针对大规模的不平衡数据文本分类效率较低的问题,本文分析了数据集中文本间的关系和主题模型理论,提出了一种基于主题识别的网络舆情文本分类优化方法。该方法通过对文本聚合成的文档进行主题识别实现聚类处理,从而在网络舆情类别样本数量较少的情况下能够高效地排除无关类别数据。在真实数据集上的实验表明,本文提出的方法使得文本分类效率提升59.55%,改进的文本分类模型F1值较基准模型提升6.17%。
(3)基于上述方法,为了实现网络舆情识别的便捷化,本文设计并实现了一种可对网络舆情文本进行分类的系统,并在该系统中集成了上述两种文本分类模型。依据软件工程的开发流程,本文对该系统的工程化开发步骤进行设计并实现。用户可通过简单操作快速进行对网络舆情文本的分类,这为网络舆情文本的快速甄别提供了有效的技术手段。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2022.000956
{DOI}: 10.27398/d.cnki.gxalu.2022.000956
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向新浪微博的谣言检测研究
{Author}: 陈梦圆
{Tertiary Author}: 谢天保
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 谣言检测;文本分析;情感分析;主题模型
{Abstract}: 近年来随着信息技术的不断发展,新浪微博作为当下最受欢迎的社交网络平台之一,其便捷性和开放性使得信息传播更加快速广泛,微博谣言也开始甚嚣尘上,严重危害健康的网络环境。因此,微博谣言检测研究逐渐受到研究人员的广泛关注,如何挖掘微博谣言深层次的有效特征,构建识别效果良好的谣言检测模型成为研究人员的重点研究方向。本文以微博谣言为研究对象,分析微博用户信息、传播信息和文本信息,提取出11个浅层特征和3个深层文本特征,同时基于特征选择的方法从中筛选出对微博谣言检测模型效果最优的特征子集,构建多种算法模型并对关键参数进行调优,实现对微博谣言的自动检测。主要研究内容包括以下几个方面:(1)从用户特征、传播特征和文本特征三个特征维度入手分析微博谣言特征,提取谣言微博区别于普通微博的关键浅层特征,并深入分析微博原文及其评论的文本特征,发现微博原文具有一定的主题倾向性,同时谣言微博评论区存在很多情感色彩较重的评论以及理性网民的辟谣评论,挖掘深层文本特征的提取思路;(2)利用自然语言处理技术对微博原文及其评论进行深层文本特征提取。首先利用LDA主题模型提取微博的主题分布特征;然后构建辟谣评论关键词库和辟谣账号集合,设计算法提取结合评论文本的微博质疑度特征;最后利用SnowNLP提取评论情感特征;(3)将提取到的候选特征集合进行特征选择,寻找最优特征子集。首先对单个特征进行分析,通过统计的方法验证本文新提取三个深层文本特征对谣言检测具有显著性作用,然后基于Wrapper递归特征消除算法,将不同机器学习算法作为基模型对候选特征集合进行特征选择,筛选出对微博谣言检测影响最优的特征子集,为后续建模做准备;(4)基于随机森林、XGBoost、支持向量机和全连接神经网络四种算法分别构建模型,并对各模型的关键参数进行调优,对比分析不同模型的谣言检测能力;同时选取不同特征子集作为对照实验,利用随机森林算法构建分类模型,验证本文构建深层文本特征的有效性。实验结果表明,在传统浅层特征集合的基础上,依次加入本文提取的三个深层文本特征,模型分类效果得到提升,准确率为87.42%,验证了本文深层文本特征提取的有效性;而四种算法模型的实验对比结果表明,经过对激活函数、损失函数和batch＿size等一系列关键参数的调优,全连接神经网络模型在谣言检测问题上表现最优,准确率达到90.26%。基于上述研究,从多个角度分析提取关键浅层特征,并对微博原文及其评论进行深层文本特征挖掘,进而基于特征集合利用各种分类算法构建新浪微博谣言检测模型,可以达到很好的谣言自动化检测效果,为人工辟谣的方式提供决策依据,大大降低了谣言检测成本。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2022.000037
{DOI}: 10.27398/d.cnki.gxalu.2022.000037
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 实验教学智能管理平台自动评分模块的设计与实现
{Author}: 慕元
{Tertiary Author}: 覃远年
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;BERT;文本分类;文本相似度;自动评分
{Abstract}: 随着“人工智能+教育”模式的兴起,利用人工智能的优势来促进教育的改革与创新具有非常广泛的研究前景。其中,在自动评分领域,对主观题的自动评分是当前考试智能批改任务的主要难点,目前的阅卷难度主要体现在对主观题的批改上,其批改完全依赖专业领域的相关人员,利用自然语言处理相关技术进行自动评分,对促进教育的公平性和智能化具有重要意义。本文的主要研究内容如下:1.本文通过词向量的方式分别对使用基于文本分类模型和基于语义相似度模型的自动评分任务进行了实验,此外,在这两种方式的自动评分上分别采用CNN、LSTM、BERT三种不同模型架构来进行实验对比,通过对比实验验证了,BERT这种基于预训练的模型相比于传统的CNN、LSTM模型,在分类任务上准确率可提升4%-7%,在语义相似度任务上的准确率能提升3%左右。2.本文设计了一种用于构造相似文本对和不相似文本对数据集的方法。其中相似文本对通过使用相同分数的答案样本进行组合获得正样本,不相似的文本对可以通过不同题目答案之间的组合来获得负样本。该方法可以有效的对采用基于文本相似度方法来进行自动评分的数据集进行扩充,进而可以有效缓解采用深度学习模型进行自动评分时存在数据样本稀缺的问题。3.在对自动评分的算法进行研究之外,本文还设计了一种采用Spring Boot技术的主观题自动评分系统。该系统可供学生用户和教师用户进行注册和登录,教师用户模块的主要功能是试题管理,通过试题管理模块,教师可以进行出题,设置题目的关键词、标准答案和分数。学生用户通过登录该系统来查看教师发布的试题并进行作答,作答完成之后通过自动评分模块给出分数,进而完成在线答题的自动评分任务。4.在自动评分模块中,本文通过使用基于关键词特征和语义相似度相结合的方法对学生答案和参考答案进行对比评分。通过本文的实验,我们提出的模型对比了基于杰卡德相似度评分算法,在自动评分任务上本文提出的模型在平均绝对误差上更小,进一步验证了本文模型在自动评分上具有一定优势。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000565
{DOI}: 10.27049/d.cnki.ggldc.2022.000565
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的旅游领域知识图谱构建及智能问答应用
{Author}: 罗琳凡
{Tertiary Author}: 周晓宇;何广
{Publisher}: 东南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 旅游知识图谱;预训练模型ERNIE;本体构建;实体对齐;旅游问答系统;命名实体识别;属性分类
{Abstract}: 伴随互联网的高速发展,旅游业迎来了智慧旅游、数字旅游的新变化。游客通过传统搜索引擎获取景点信息的方法不够直接、高效,而且不同网站的不同内容、虚假广告进一步加重了用户的出行负担。因此为用户提供一个精确便捷、真实有效的旅游信息检索服务能够有效降低游客获取信息的时间成本。知识图谱的出现为规范化海量数据提供了有效解决方案,基于知识图谱的问答模型在问句理解、答案展示方面具有突出优势。本文以山东省为例,应用强大的语义预训练模型ERNIE,构建了旅游领域知识图谱,并以其为知识支撑,设计并实现了旅游智能问答系统。本文主要工作如下:(1)提出并实现了一套旅游领域的知识图谱构建流程。本文采集各大旅游网站客观性较强的半结构化数据和结构化数据;改进本体构建方法,在七步法的基础上结合旅游领域数据特点和图谱应用需求,构建高包容性的旅游本体;为了解决异源数据融合问题,本文提出深度结合实体地理位置特征的实体对齐模型POI-ERNIE-SN,设计多组对照实验证明了模型的有效性;本文采用Jena+Fuseki进行知识推理、利用百度地图API做知识扩充来解决部分孤立节点的问题;最后使用图数据库Neo4j存储知识,构建出山东省旅游知识图谱。(2)主流的基于规则的问答存在人工成本较高和迁移性较差的问题,本文以基于深度学习的问答模型为主体,辅以少量模板规则。整体问答模型主要包括四个工作:问句实体识别、实体链指、属性分类和属性精排序。针对问句中核心实体的识别,设计命名实体识别模型ERNIE-CRF;提出基于模糊查询的实体链指算法;设计并改进融合答案信息的属性分类模型ERNIE-CNN,在ERNIE词向量编码层后接一层CNN,进一步挖掘深层文本特征,基于逐跳思想改进模型输入,使其能够处理复杂二跳问句;提出基于组合相似度的属性精排序算法。最终通过实验证明了整体问答模型的可行性和优越性。(3)在知识图谱和问答模型的基础上,本文设计并实现了一个山东省旅游领域智能问答系统,使其能够处理图谱内问题、天气问答和闲聊对话。由于新冠疫情对当地旅游的严重影响,本系统在现有旅游问答系统的基础上,添加疫情防控查询功能,更贴合游客的出行需求。综上,本文应用语义预训练模型ERNIE,构建旅游领域知识图谱,设计并改进了以模板规则为辅、深度学习为主的问答模型,设计与实现了基于知识图谱的旅游问答原型系统。本工作成果将降低用户获取旅游信息的时间成本,为推进智慧旅游、数字旅游提供支持。
{URL}: https://link.cnki.net/doi/10.27014/d.cnki.gdnau.2022.001730
{DOI}: 10.27014/d.cnki.gdnau.2022.001730
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: KINβγ调节拟南芥花粉中线粒体和油体数量的分子机制
{Author}: 李非
{Tertiary Author}: 高新起;张宪省
{Publisher}: 山东农业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 拟南芥;SnRK1;KINβγ;WRKY;花粉;油体;线粒体
{Abstract}: 花粉在柱头表面的黏附和水合,是植物授粉识别的开端,与作物的产量息息相关。我们前期的研究发现拟南芥Sn RK1复合体的βγ亚基(KINβγ),通过调控花粉中线粒体的发生,进而影响了花粉中ROS(Reactive Oxygen Species)的水平,调控花粉在柱头表面的水合。但是KINβγ如何调控线粒体的发生还不清楚。前期的研究通过对拟南芥kinβγ-1/+突变体花粉RNA-seq结果分析发现,kinβγ-1/+突变体中差异表达基因的启动子上大多含有WRKY转录因子的结合位点W-box。分析发现WRKY2和WRKY34在花粉中的表达水平最高,通过酵母双杂交、Pull-down等实验方法发现WRKY2和WRKY34与KINβγ相互作用。wrky2 wrky34双突变体的成熟花粉中线粒体数量明显少于野生型,花粉在柱头上不能正常水合的比例也明显高于野生型。因此,WRKY2和WRKY34与KINβγ相互作用,调控拟南芥花粉中线粒体的数量,进而影响花粉在柱头表面的水合。分析kinβγ-1/+突变体与wrky2 wrky34双突变体花粉的RNA-seq结果,发现了一个在两个突变体中表达量都上调的功能未知的基因,命名为PALD(Protein Associated with Lipid Droplet)。PALD的启动子上有一个W-box位点,WRKY2可以结合该位点,WRKY34和KINβγ与WRKY2相互作用可以增强WRKY2对PALD表达的抑制作用。因此,WRKY2、WRKY34与KINβγ相互作用形成复合体,结合到PALD启动子上并抑制其表达。拟南芥PALD在成熟花粉粒和花粉管中特异性表达,PALD定位于油体(Lipid Droplet,LD)。蛋白结构预测发现PALD可以分成六个区段(I-VI),其中第I和第V个区段中含有一个α双亲螺旋,通过亚细胞定位分析发现PALD的第I到第IV个区段以及第I个区段中的α双亲螺旋,对PALD在油体上的定位至关重要。PALD的表达量与花粉发育过程中油体的数量呈正相关,PALD功能缺失导致突变体花粉中油体的数量和直径较野生型均降低,线粒体的数量明显多于野生型,花粉在柱头表面不能水合的比例也明显高于野生型。因此,PALD参与调控花粉中油体和线粒体的数量,影响花粉在柱头表面的水合。前人的研究发现GPT1(Glucose-6-Phosphate 1)定位于质体,参与调控花粉中油体的积累。为进一步分析花粉中线粒体和油体数量的关系,我们创制了gpt1-2突变体。该突变体花粉中油体的数量少于野生型,线粒体数量多于野生型,表明花粉中油体与线粒体数量呈负相关,油体数量的减少可能会导致线粒体数量的增加。综上所述,KINβγ通过与WRKY2、WRKY34相互作用形成复合体,增强WRKY2对PALD表达的抑制作用,调节花粉中线粒体和油体的数量,影响花粉在柱头表面的水合。
{URL}: https://link.cnki.net/doi/10.27277/d.cnki.gsdnu.2022.000056
{DOI}: 10.27277/d.cnki.gsdnu.2022.000056
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 实体方面级情感分析算法研究
{Author}: 宋金剑
{Tertiary Author}: 杨春霞
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;方面级情感分析;深度学习;图卷积网络;紧密连接
{Abstract}: 随着数字技术的快速发展,微博、淘宝、京东等平台上评论呈爆发式增长,并大致可分为2类:单实体多方面的评论类文本和多实体多方面的经验分享类文本。商家研究这些文本将有益于更好地了解和服务大众,因此进行情感分析研究是十分必要的。本文将基于深度学习的方法对这两种不同类型的文本进行方面级情感分析和多实体方面级情感分析,主要工作与创新如下:(1)针对现有的依存树修剪方法存在删除部分有用信息的问题,以及图卷积网络无法获取图结构中丰富的全局信息问题,本文提出了基于多头自注意力的图卷积网络(MSGCNs)模型。该模型首先通过多头注意力机制自动学习如何有选择地关注对分类任务有用的结构信息,将原始依存树转变为完全连接的边加权图;其次将紧密连接引入图卷积网络中,并结合修剪后的依存树,使图卷积网络能够捕捉丰富的局部和全局信息。实验结果表明本文提出的依存树修剪策略和GCN改进方法有效提高了分类效果。(2)针对MSGCNs模型只考虑句法结构信息而忽略原文中序列信息的问题;其次现有方法捕捉语义和结构信息不充分的问题,本文提出了基于深度BiLSTM(DBiLSTM)和紧密连接的图卷积网络(DDGCN)模型。该模型首先通过DBiLSTM获取方面词与上下文单词间的深层语义信息;然后利用引入紧密连接的图卷积网络捕获依存图上的结构信息,最终将融合以上2种深层信息的文本表示用于情感分类。实验结果表明同时考虑并捕捉文本中深层次的语义和结构信息进一步地提高了分类效果。(3)针对多实体方面级情感分类任务,现有方法存在未考虑依存树上图结构信息的问题,以及使用GCN获取上下文隐藏表示时无法突出与指定实体方面词更相关部分信息的问题。为此,本文提出了门控双向图卷积网络(GBGCN)模型。该模型首先使用位置注意力和BiLSTM对上下文进行建模;其次在双向图卷积网络中引入门控机制,生成输出隐藏表示是面向指定实体方面词的门控双向图卷积网络;然后使用此门控BiGCN提取依存树上的图结构信息;最终将方面词与实体词的隐藏表示用于情感极性预测。实验结果表明考虑依存树上图结构信息和在GCN中引入门控机制能更有效地提取实体方面对与上下文间的句法信息,进而提高分类效果。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2022.001109
{DOI}: 10.27248/d.cnki.gnjqc.2022.001109
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器学习自然语言处理的兰新高铁信号设备故障诊断
{Author}: 朱玉林
{Tertiary Author}: 石磊;陈力
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 铁路信号设备;自然语言处理;主题模型;支持向量机;故障诊断
{Abstract}: 兰新高速铁路又称兰新高铁或兰新客运专线,是推进国家“一带一路”战略的重要助力之一,但由于途径地区地理环境复杂,气候环境多变,导致沿线信号设备易出现各类故障,严重影响线路的安全高效运营。在长期的运营维护过程中,电务部门通过自然语言的形式记载了大量非结构化的故障文本信息,其中包含了各类相关故障的发生时间、发生地点、故障表现、故障类别以及故障后续处理方法等重要信息。而长期以来,维修人员在处理现场故障时,多依据个人经验以及专家知识,通过人工的方法对故障进行诊断,并未对相应的故障数据加以有效的分析与利用,无法对蕴含其中的巨大价值进行挖掘。因此,为了响应国家大数据发展战略,推进大数据在铁路安全领域的应用,研究一种能够有效利用故障记录文本提高信号设备故障诊断效率、提升线路运输安全保障的故障诊断方法具有十分重要的意义。首先,根据目前我国铁路信号设备故障记录多为非结构化的中文短文本形式,其中包含着大量铁路信号的专业词汇,并且夹杂着数字、字母以及一些特殊符号,在传统的人工故障诊断方式下,并不能得到有效的分析与利用,本文采用数据挖掘寻找高频词结合铁路信号领域专业词汇的方式,构建铁路信号领域故障词库;在此基础上采用基于HMM(Hidden Markov Model,隐马尔科夫模型)的Jieba中文分词技术对故障文本进行分词处理,并去除停用词。由结果可知,在采用自定义铁路信号领域词库后,有效的解决了中文分词处理过程中容易出现的错分与不分的问题,为后续特征提取工作提供保障。然后,采用VSM(Vector Space Model,向量空间模型)的方法,将分词后的故障信息转化到词项特征空间上,为了针对传统词项特征方法对文本隐含语义联系考虑不足的问题,本文采用LDA(Latent Dirichlet Allocation,隐狄利克雷分布)主题模型的方法对铁路信号设备故障记录进行特征提取,通过多次试验的方式选择合适的主题数后,以不同主题对应相应词项的形式将原有故障信息转化到主题特征空间上,使语义与词项特征相关联,同时降低故障数据的维度,便于后续进行故障诊断。最后,通过对兰新高铁信号设备故障数据的统计,发现故障样本存在着分布并不均衡的问题。因此本文采用机器学习分类算法与自然语言处理(Natural Language Processing,NLP)的方法相结合对故障进行诊断,通过对比传统空间向量模型与主题空间模型分别结合支持向量机(Support Vector Machine,SVM)、朴素贝叶斯(Naive Bayes,NB)、逻辑回归(Logistic Regression,LR)、随机森林(Random Forests,RF)、K-最邻近(K-Nearest Neighbor,KNN)等多种机器学习分类算法对故障分类器进行训练。在此基础上以兰新高铁信号设备故障文本数据进行实验分析,并通过对比不同组合Precision(精确率)、Recall(召回率)以及F1-measure(F1值)三项指标的方法,对提出方法的有效性进行验证;实验表明,结合LDA主题模型后SVM分类算法的准确率可以达到0.84,验证了利用自然语言处理的方法能够有效地对电务部门长期记载的故障文本数据加以利用,以实现信号设备的故障诊断,对现场信号设备的维护具有一定的指导意义。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2022.001121
{DOI}: 10.27205/d.cnki.gltec.2022.001121
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 人工智能技术在双一流高校图书馆中的应用研究
{Author}: 胡尹洁
{Tertiary Author}: 周淑云
{Publisher}: 湘潭大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图书馆;人工智能;技术应用
{Abstract}: 本文以42所双一流高校图书馆为例,调查人工智能技术在我国高校图书馆的应用现状,总结出人工智能技术在高校图书馆中应用的主要领域;最后分析人工智能技术在高校图书馆中应用面临的困境,并提出相应的改进策略。本课题研究的意义一方面体现在提出了人工智能技术在高校图书馆建设与发展中应用的新方向与新思路,另一方面为普通高校图书馆应用人工智能技术提供经验借鉴。本文通过文献分析法、比较总结法以及实证研究法,对人工智能技术在高校图书馆中应用的相关概念与理论基础、人工智能技术在42所双一流高校图书馆的应用现状与面临困境进行研究分析,具体分为六个章节。第一章论述论文的研究背景和意义、国内外研究综述、研究方法、研究思路、以及研究创新点,提出文章研究重点。第二章介绍人工智能技术在高校图书馆中应用的相关概念与理论基础。第三章以42所双一流高校图书馆为调查对象,调查人工智能技术在高校图书馆中的应用现状,总结人工智能技术在高校图书馆中应用的主要领域,从而对人工智能技术如何助力高校图书馆建设进行更深入的分析。第四章根据前三章的理论研究以及实例分析,指出人工智能技术在双一流高校图书馆中应用面临的困境,即智能用户识别系统中用户个人信息存在泄露风险;智能图书定位系统中数据采集与维护困难;智能信息推送系统受众小;智能座位预约系统中管理机制不完善;智能服务机器人交互性不足。第五章提出人工智能技术在双一流高校图书馆中应用的改进策略,即加强用户个人信息保护;优化数据采集与维护流程;扩大信息推送受众面;完善座位预约系统管理机制;提高人机交互水平。第六章对文章进行总结,对人工智能技术未来在高校图书馆中的应用进行展望。
{URL}: https://link.cnki.net/doi/10.27426/d.cnki.gxtdu.2022.000429
{DOI}: 10.27426/d.cnki.gxtdu.2022.000429
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于模板和规则的声明式代码生成
{Author}: 冯俊辉
{Tertiary Author}: 刘晨
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 规则;模板;Text2SQL;Drools;深度学习
{Abstract}: 随着技术的发展,声明式编程越来越受到重视。通过编写声明式代码,编程人员可以将精力聚焦于逻辑控制,无需以算法指明每步具体执行步骤。但是,对于非编程人员而言,编写代码并非易事,编程工作依托大量专业知识。因此,自然语言合成代码成为研究热点。其中,SQL查询代码作为典型的声明式代码类型之一,被学术界深入研究。本文将声明式代码生成工作聚焦于Text2SQL任务,提出基于模板和规则的方法以实现自然语言到SQL查询语句的合成。本文主要工作有:(1)以往解决Text2SQL任务的深度学习模型未充分运用数据库内容,未考虑表字段取值涉及的实体类型对模型准确率的影响,且未充分利用数据库先验知识。为此,本文提出基于模板和规则的深度学习方法TRSQL,通过数据库内容和表字段取值涉及的实体类型对表征模型进行了改进。TRSQL首先生成自然语言序列对应的草图模板,再利用草图模板和生成规则约束SQL查询语句生成。在权威的公开数据集Wiki SQL上对TRSQL方法进行了评测,并与诸如Hydra Net、X-SQL、Sea D等方法进行了对比。与具备相同预测任务的Coarse2Fine模型相比,准确率提升了近11%;(2)以往基于NLP技术解决Text2SQL任务的方案只是简单运用了分词、词性分析等技术,提出的方法均未在权威、大规模数据集上进行验证,可解释性差且泛化能力不足。为弥补以往方案的不足,本文提出基于模板和规则的NLP方法——nTRSQL。nTRSQL在前人方案基础上增加多种解析模板和解析规则,融合了提出的投票选举机制和染色树技术。实验结果表明,nTRSQL方法在适用条件下的Text2SQL逻辑准确率可高达90.3%;(3)提出两种方案将nTRSQL和TRSQL方法相结合,共同实现英文自然语句到SQL查询代码的合成。一是基于Drools规则引擎实现,二是改进基于BERT的传统分类器,解决nTRSQL、TRSQL的选用问题;(4)基于nTRSQL、TRSQL结合后的方法,构建一套数据库自然语言查询系统,为用户提供了可通过自然语句对数据库进行检索的交互接口。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2022.000614
{DOI}: 10.26926/d.cnki.gbfgu.2022.000614
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的生成式文本摘要方法研究
{Author}: 王一如
{Tertiary Author}: 刘高军;付晓宇
{Publisher}: 北方工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本摘要;抽取式;生成式;文本特征;深度学习
{Abstract}: 自然语言处理的研究目标是实现对自然语言的理解,这种“理解”被应用到很多领域,如:问答任务,阅读理解任务,文本摘要任务等,其中文本摘要任务指基于对源文本的“理解”得到精简摘要,在读者阅读大量文本内容时,这项任务能帮助读者减少阅读量,提高阅读效率,因此对文本摘要任务的研究具有十分重要的意义。的方式主要有抽取式和生成式,抽取式指抽取文本重要内容拼接成摘要,但如果对文本特征提取的不全面会丢失关键信息,生成式能够结合上下文内容生成摘要,摘要结果内容更丰富,但受原文中干扰信息的影响可能出现与原文不相符的内容。本文主要研究与人工总结方式接近的生成式,利用强化学习将抽取式结合到生成式模型中,保留了生成式能够考虑全文内容的优势,并利用抽取式能够过滤文本中干扰信息的优势解决了生成式存在的不足,强化学习模型在文本摘要任务中常用只考虑词汇匹配程度的Rouge作为反馈值,缺乏对内容的重视,本文的研究内容可分为两个方面:(1)针对抽取部分存在的重要信息丢失的问题,本文提出将源文本内容的特征表示和BI-LSTM得到的特征表示进行拼接,使信息不再被门控选择而是全部进入到下一层网络结构中,能够最大限度的保留文本的重要内容。在特征拼接后加入自注意力机制能够关注文本内容之间的语义依赖关系,保留足够多的重要特征。实验结果证明当进行特征拼接且加入自注意力机制后,生成的摘要结果更具有多样性,与参考摘要更接近。(2)对于强化学习模型使用Rouge作为反馈值时只考虑摘要结果与参考摘要之间词汇的匹配,未考虑内容相似度的情况,本文将评估指标BERTScore优化后作为反馈值,并将评价指标Rouge与BERTScore相结合,兼顾了词汇匹配情况和内容相似度,相关实验和对比实验的结果均表明此改进方案生成的文本摘要与参考摘要相比不仅词汇匹配度高,内容也更加相似。最后,本文在研究的基础上,将理论方法应用到实际操作中开发了文本摘要系统,生成文本摘要模块完成了对整篇文章总结重要内容的任务。
{URL}: https://link.cnki.net/doi/10.26926/d.cnki.gbfgu.2022.000619
{DOI}: 10.26926/d.cnki.gbfgu.2022.000619
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态特征的信息抽取方法研究
{Author}: 魏素忠
{Tertiary Author}: 吴含前
{Publisher}: 东南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多模态;信息抽取;图神经网络;特征融合;多模态预训练
{Abstract}: 随着移动互联网的飞速发展,推特、微博等社交平台凭借其便捷性、共享性获得了广大用户的青睐。人们可以很轻松地在社交平台上发表意见、分享生活日常。以推特为例,这些推文通常不只有文字,用户还会添加图片来增强自己的情感。信息抽取任务旨在从自然语言文本中提取出实体、关系、事件等特定的结构化信息.该任务可以为知识图谱、自动问答、推荐系统等下游应用提供数据支撑。推特文本一般比较简短且噪音多,表述也不规范。但是图片与文本相关性较高,借助于图片模态可以弥补文本表达的不足。因此基于传统单文本的信息抽取方法已不再适用,利用图片进行多模态信息抽取已成为近年来的研究热点。本文展开了基于文本和图片的命名实体识别、社交关系抽取和实体链接三个信息抽取任务的研究,具体研究内容如下:首先,本文提出了一种基于目标视觉对象指导的多模态命名实体识别方法。该方法在输入的文本和图片间构建了一个统一的多模态图神经网络。图中的每个节点表示一个语义单元,即文本化的单词或者目标检测出来的视觉对象。设置两种边来分别捕捉同一模态内和不同模态间语义单元的关联性。然后基于该图网络,堆叠多层多模态特征融合层来迭代性地进行节点交互:对于在同一模态内的节点,使用Transformer直接捕捉节点间的依赖关系;对于在各自不同模态的节点,使用跨模态门控机制来收集每个节点的跨模态邻居节点的语义信息。最后,利用CRF对增强后的文本表征解码从而抽取出命名实体。实验结果表明,该方法在处理多模态命名实体识别任务时较其它基准模型取得了较优的性能,后续的消融研究进一步验证了该方法的有效性。其次,本文提出了一种基于句法和面部特征的图融合的多模态社交关系抽取方法。该方法在文本层面融入词性、依存边和依存标签三种句法信息,在图片层面使用Transformer来建模头尾实体面部的隐式关联信息。为了构建多模态图神经网络,将头尾实体对应的词向量最大池化成两个文本节点,对应的面部表征则设为两个视觉节点;同时每一个文本节点都与其它两个视觉节点相连,每一个视觉节点都与其它两个文本节点相连。接着利用跨模态注意力机制实现多模态特征的融合。此外,由于数据集中样本分布不均衡,大量社交关系类别对应的样本数稀少,本文基于原型网络进行少样本学习。实验结果表明,该方法可以有效融入句法和面部特征,并通过多模态融合生成更高质量的文本向量。在少样本学习的各种实验设置下,模型分类准确率大幅领先其它基准方法。最后,本文提出了一种基于图片文本预训练和提示词微调的多模态实体链接方法。受限于高昂的人工标注成本,本文首先根据推文的特点,利用脚本程序自动化构造出一份多模态实体链接数据集并在此基础上进行实验。在多模态预训练阶段,该方法基于BERT模型设计了遮蔽词预测和图片文本对齐两个任务。其中,遮蔽词预测有助于提升模型对推特文本的归纳偏置能力,图片文本对齐则鼓励模型去学习两种模态之间的隐式依赖关系。在微调阶段,由于标注样本较少,为了充分利用预训练模型学到的知识,本文基于提示词的方式构造输入模板,保持与预训练阶段的任务一致,这样就能从预训练模型中直接获取尽可能多的语义信息。实验结果表明,多模态预训练可以为下游任务带来明显的性能提升,提示词微调可以在低资源学习下取得较优的效果。后续的消融研究进一步证明了预训练任务设计的合理性和预训练模型的泛化性。
{URL}: https://link.cnki.net/doi/10.27014/d.cnki.gdnau.2022.001219
{DOI}: 10.27014/d.cnki.gdnau.2022.001219
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于餐饮业评价的细粒度情感分析研究
{Author}: 王琪
{Tertiary Author}: 金哲植
{Publisher}: 延边大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 细粒度情感分析;深度学习;预训练模型;多任务学习
{Abstract}: 情感分析是自然语言处理领域的重要组成部分,其目的是分析和挖掘主观性文本中蕴含的情感倾向。情感分析任务可以分为粗粒度情感分析和细粒度情感分析,前者可以判断实体级别的情感倾向,后者可以判断实体属性级别的情感倾向。随着大众生活水平的提升,人们开始崇尚个性化,网络上的用户评价也趋于多维化,致使评价性文本变得更复杂,仅研究实体级别的评价已经不能满足大众的实际需求,因此细化情感分析的粒度已成必然趋势,但情感分析粒度的细化导致模型捕捉关键信息的难度急剧增加,并且使情感分析从单任务问题变成了多任务问题,许多简单的情感分析模型难以应对细粒度情感分析任务,使情感分析效率大幅度降低。针对此情况,本文设计了既能提高分类准确度又能节约计算时间的细粒度情感分析模型。主要研究内容如下:首先,选择餐饮业评价数据集,对数据进行去除停用词、去除无效字符等预处理。其次,选取部分数据,选择原有的深度学习模型分别使用单任务学习和多任务学习的方法对选取的数据进行情感分析对比实验,通过分析实验结果得到多任务学习更适合细粒度情感分析的结论。再次,提出单独使用预训练模型进行情感分析的方法。使用BERT模型和BERT+ERNIE模型分别在单任务学习和多任务学习的基础上对部分数据进行细粒度情分析,实验结果验证了预训练模型有足够的特征提取和捕捉上下文信息的能力,能够在不添加下游模型的情况下胜任自然语言处理任务,验证ERNIE模型能弥补BERT模型在解决中文情感分析问题时的不足,证明了ERNIE模型的能力。同时对比预训练模型在使用单任务学习或多任务学习方法时的实验结果,验证多任务学习方法同样适用于预训练模型。最后,提出本文的BERT-ERNIE-LSTM-Attention并行计算模型,在BERT+ERNIE模型的下游加入长短时记忆网络与注意力机制,以便提高模型的准确度,引入并行计算结构,以便减少模型训练时需要耗费的时间。使用数据集的全部数据,将本文提出的模型与多个深度学习模型进行情感分析对比实验,实验结果表明本文提出的模型能在提高情感分析准确度的同时减少训练时间。
{URL}: https://link.cnki.net/doi/10.27439/d.cnki.gybdu.2022.000128
{DOI}: 10.27439/d.cnki.gybdu.2022.000128
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 知识图谱分布式表示学习方法研究
{Author}: 王诗蕊
{Tertiary Author}: 周文安
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 知识图谱;分布式表示;嵌入向量;认知智能;知识推理
{Abstract}: 随着认知智能时代的到来,越来越多的智能应用更加关注学习结果的可解释性和大数据中蕴含的知识。面对这一需要知识赋予智能的需求,知识图谱以其大规模、自动化的知识获取特点和可解释、可推理的知识应用特点为认知智能赋能,被广泛应用于智能搜索、问答系统和个性化推荐等场景。然而,传统离散符号式知识表示方法在应对现代知识图谱的大规模需求、语义关联性度量及深度模型应用等方面受到了限制。近年来,受自然语言处理领域分布式假说的启发,知识图谱分布式表示方法为解决上述问题提供了思路:通过将知识图谱中的实体和关系表示成低维的数值向量,从而将对应的语义信息嵌入到稠密、连续的向量空间中,具有高效实现语义关联性计算、易于捕获隐性知识、易于与深度模型集成的优点。因此,知识图谱分布式表示学习逐渐成为现阶段知识图谱领域的热门研究方向。受分布式假说启发,知识图谱分布式表示认为知识图谱中的实体和关系的语义取决于其周围的分布。但是,由于数据的“不完备性”导致知识图谱普遍存在的数据稀疏问题,使得现有方法也无法较为准确地学习出长尾实体的表示,在知识推理相关任务上往往准确率较低。此外,现代知识图谱的规模化需求使得现有方法很大程度上仍旧依赖弱逻辑约束,无法充分表达知识图谱蕴含的复杂知识结构如网状结构和动态结构,为知识图谱分布式表示带来了挑战。为此,本文在深入调研和分析之后,在知识图谱分布式表示学习领域开展了以下三个创新性研究工作:(1)面向数据稀疏问题,提出了一种融合实体描述信息的知识图谱分布式表示学习方法,将实体描述信息作为知识图谱中已有结构化信息的辅助与补充,为其提供更加深入的细节描述并挖掘可能遗漏的新知识,增强长尾实体的表示。首先,针对实体相关语义抽取不足的问题,提出了基于分层双向长短期记忆网络和预训练语言表征的实体描述信息编码模型,有效地抽取实体描述中包含的丰富语义信息。其次,针对文本空间与知识空间融合不足的问题,提出了一种知识约束与对齐方法,能够同时从结构三元组和实体描述中学习实体表示,并实现文本空间和知识空间的交互式融合对齐。在知识图谱补全任务上(全部及长尾案例数据)的实验结果充分证明了上述方法能够帮助建立更好的知识图谱表示并增强长尾数据的表示。(2)面向网状知识结构问题,提出了一种基于图邻域结构信息的知识图谱分布式表示学习方法,通过考虑知识图谱所蕴含的多步关系路径、节点邻域等图结构特性,从另一个角度更加丰富的刻画实体和关系的网状语义分布。首先,针对多步关系路径语义抽取的问题,提出了一种基于局部和全局注意力的多步关系路径编码模型,在对单条路径编码的基础上,考虑实体对之间的多条路径的局部和全局注意力进行编码。其次,针对实体邻域信息聚合问题,提出了一种基于图注意力网络的分层结构模型:邻域级注意力→层级注意力,有效地聚合多步邻域信息。在知识图谱补全任务上(实体及关系预测)的实验结果充分证明了上述方法能够有效地利用图结构信息学习实体和关系的分布,增强知识图谱分布式表示的知识推理能力。(3)面向动态知识结构问题,提出了一种基于时序历史记忆的知识图谱分布式表示学习方法,从双过程理论的角度解决实体和关系随时间发展的非线性演化及不确定性给知识图谱表示带来的问题。首先,提出了基于直接历史线索和关联历史线索作为预测未知事实的线索信息的重要性。其次,提出了一种可以同时考虑历史线索重复次数与时间轴趋势的滤波函数,实现更为细致的复制推理。最后,提出了一种改进的自注意生成机制,可以促使模型关注与待预测事件更为相关的实体词汇,并赋予模型从头开始预测的能力。在时序知识图谱补全任务上(未知事实推断)的实验结果充分证明了上述方法能够有效的增强时序知识图谱分布式表示的知识推理能力。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.000006
{DOI}: 10.26969/d.cnki.gbydu.2022.000006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 属性抽取及属性级情感分类方法研究
{Author}: 刘宁
{Tertiary Author}: 沈波
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 情感分析;属性级情感分类;属性抽取;自然语言处理;深度学习
{Abstract}: 随着互联网技术的发展与应用的普及,社交网络和电子商务等平台上产生了海量的文本数据。这些数据中往往蕴含着人们对相关事件、产品与服务的观点,具有某种情感倾向性。如何让机器理解文本语义,从中识别出观点所针对的目标对象,并判别其中的情感极性,已成为学术界和工业界的研究热点。这其中,属性(Aspect)抽取及属性级情感分类,是关键任务之一。虽然目前基于深度学习的方法在这方面取得了显著的进展,由于人类语言及情感表述的复杂性,现有方法仍存在诸多局限性。如编码方法缺乏编码更多有用信息的能力;训练过程过度依赖标注数据;模型在建模位置不变性、局部模式、长距离依赖关系和序列信息等方面能力不足等。鉴于此,本论文针对属性抽取及属性级情感分类方法进行研究,着重讨论如下问题,并构建了相应的模型:属性词(Aspect Term)抽取中如何编码信息丰富的文本表征、整合周围词信息、建模动态词义;属性类别(Aspect Category)抽取中如何实现无监督学习及融合上下文信息和名词信息;属性级情感分类中如何既能编码序列信息和语义依赖关系、又具有位置不变性和对局部模式敏感、过滤注意力机制产生的噪声;属性级情感分类中如何在记忆网络等深度学习模型上实现强注意力交互、词嵌入包含上下文信息以及利用模型中的每一跳(层)信息。论文的研究工作得到国家重点研发计划“内外网信息受控同步的审判执行流程及节点信息自动化发布技术研究”(No.2018YFC0831306)和中央高校基本科研业务费研究生创新项目“属性级情感分析及相关技术研究”(No.2019YJS022)等的支持。论文的主要工作和创新点如下:1.构建了一种面向属性词抽取的信息增强神经网络(Information-Augmented Neural Network,IANN)模型。为了克服序列到序列方法中编码器产生的文本表征缺乏丰富信息、难以整合周围词信息、无法对词的动态词义进行建模等问题,构建了信息增强神经网络IANN。在IANN的上下文嵌入层中引入BERT,实现了对动态词义的建模。在IANN的编码器中,通过多重卷积与循环操作,实现了对蕴含丰富信息的文本表征的编码,并整合了周围词信息。通过将编码器的单层结构扩展为多层结构,学习了更适合于具体任务的高阶语义特征。在解码阶段,提出了一种AO({Aspect,Outside})标签作为输出标签,提升了模型的表现。多个数据集上的实验结果表明,IANN的性能优于所对比的基线模型。实验结果验证了IANN在属性词抽取上的有效性。2.提出了一种面向无监督属性类别抽取的多信息融合神经网络(MultiInformation Fusion Neural Network,MIFNN)模型。在属性类别抽取中,为克服现有模型过度依赖于标注数据,解决在无监督学习中没有利用与融合上下文信息和名词信息以及建模序列信息和语义依赖等问题,提出了多信息融合神经网络模型MIFNN。MIFNN是一种带有自编码器结构的模型。MIFNN编码器中设计了属性辅助模块,用于编码和融合上下文信息和名词信息,并提供通用知识和属性相关知识。为了捕捉上下文词和属性类别之间的语义关联关系,提出了名词感知注意力机制,并得到属性类别相关的上下文句子表征。为捕捉信息融合表征和句子中词的语义关系,在MIFNN的编码器中,构建了融合信息注意力机制。MIFNN的解码器通过可学习的属性嵌入,重构编码器输出的句子表征。多个数据集上的实验结果表明,在无监督属性类别抽取上,MIFNN的表现优于所对比的基线模型。实验结果验证了MIFNN在无监督属性类别抽取中的重要性。3.构建了一种用于属性级情感分类的门控交替神经网络(Gated Alternate Neural Network,GANN)模型。为克服循环神经网络缺乏位置不变性和对局部模式不敏感、卷积神经网络不擅长建模序列信息和捕捉长距离依赖信息、注意力机制可能会引入噪声等问题,提出了一种门控交替神经网络GANN。为更好地捕捉句子中的属性相关信息,构建了情感线索的概念。设计了门控截断RNN,将句子分为多个情感线索,并编码了情感线索中每个上下文词与属性词之间的相对距离、序列信息及语义依赖关系等信息。为获取更准确的情感线索表征,构建了门控过滤机制,控制编码过程中的信息流向。GANN引入卷积和池化机制,实现对局部关键情感特征的捕捉,并获得位置不变性。多个数据集上的实验结果表明,GANN的性能优于所对比的基线模型。实验结果验证了GANN的有效性。4.提出了一种用于属性级情感分类的循环记忆神经网络(Recurrent Memory Neural Network,ReMemNN)模型。为克服记忆网络等深度学习模型中的二元注意力机制无法建模属性词和上下文之间的强交互关系、多跳模型中每一跳信息未得到充分利用、词嵌入缺乏来自上下文的具体语义信息等问题,提出了循环记忆神经网络ReMemNN。在ReMemNN中,构建了嵌入调整学习模块,使词嵌入学习了来自上下文的语义信息。为实现属性词和上下文之间的强交互,提出了一种多元素注意力机制,并生成更准确的注意力权重和属性依赖的句子表征。为充分利用模型中每一跳编码的属性依赖的句子表征,构建了显式记忆模块,并分别生成用于多元素注意力和情感极性预测的句子表征。多个数据集上的实验结果表明,ReMemNN获得了优于所对比的基线模型的性能。实验结果验证了ReMemNN的有效性。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000213
{DOI}: 10.26944/d.cnki.gbfju.2022.000213
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于迁移学习的小样本命名实体识别方法研究
{Author}: 李思凡
{Tertiary Author}: 陈万志
{Publisher}: 辽宁工程技术大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 科协活动;命名实体识别;迁移学习;BERT;条件随机场
{Abstract}: 目前命名实体识别技术已较为成熟,但由于仅有法律文书、电子病历等行业领域的数据集限制其应用泛化效果,而符合科协大数据分析需求的研究仍处于探索阶段。针对各级科协活动实体类型自动获取的问题,提出一种基于迁移学习的、具有BERT-Bi LSTM-CRF和ALBERT-Bi GRU-Attention-CRF两种模型的小样本数据集命名实体识别方法。首先,利用爬虫技术通过爬取全国各级科协官方网站科协活动数据构建小样本数据集;然后,选取不同的模型进行训练,对于算力资源充足的应用场景,采用基于转换器的双向编码表征、双向长短期记忆、条件随机场相结合的模型,利用参数量大的BERT模型生成字符向量,Bi LSTM学习全文特征,CRF对输出向量添加约束条件;而资源较少的场景,则采用轻量级ALBERT、双向门控循环单元、注意力机制、CRF相结合的模型,利用ALBERT代替BERT生成词嵌入向量,泛化能力较强的Bi GRU获取上下文特征,多头自注意力机制扩展对不同位置的关注度,CRF规范输出,最终得到标注序列结果。所构建小样本数据集测试实验结果表明,与Bi LSTM-CRF相比,BERT-Bi LSTM-CRF模型F1值提高了6.79%,与Bi GRU-CRF相比,ALBERT-Bi GRU-Attention-CRF模型F1值提高了1.30%,验证了所提出的方法的有效性;并进一步通过项目2015-2019年典型数据利用模型分析各类实体的识别结果,验证了所提出方法的可行性。因此,所提出方法在科协政策改革要点落实情况评估中,能够自动识别活动实体类型,减少人工参与度,提高处理效率,为科协政策研究信息化提供了方法支撑。该论文有图34幅,表16个,参考文献55篇。
{URL}: https://link.cnki.net/doi/10.27210/d.cnki.glnju.2022.000333
{DOI}: 10.27210/d.cnki.glnju.2022.000333
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的军事知识问答系统设计与实现
{Author}: 彭昊
{Tertiary Author}: 苗建松
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;问答系统;深度学习;自然语言处理
{Abstract}: 随着互联网、大数据和人工智能技术的发展,如何充分利用并挖掘信息之间的联系,为研究与应用提供先验知识是目前一个重要的研究热点。知识图谱因具有图结构,支持图神经网络的表示学习、图论等数学理论的推理计算,在表示与关联知识方面有独特的优势。问答系统相较于传统的搜索引擎,在分析用户问题时更能准确把握用户的意图,因此本文设计与实现了基于知识图谱的问答系统,并将其应用到军事领域,为未来信息化联合作战样式的转变提供一个具有查考价值的思路与方案。本文的主要工作如下:(1)针对构建知识图谱过程中对知识图谱信息利用不充分的情况,设计了一种融合知识图谱信息的实体关系联合抽取的方案,该方案先对文本中存在的关系进行抽取,使用TransE对关系进行嵌入表示后输入到实体关系联合抽取器中,抽取器同时融入Bert模型对问句的编码,最终并行解码出三元组。通过设置对照实验,证明了使用Bert编码器以及融入知识图谱的信息能提升模型的抽取能力。(2)针对在基于知识图谱的问答系统中存在的知识图谱信息不完整导致无法回答相关问题的情况,设计了一种包含候选答案的知识图谱子图构建方法。该方法使用基于Bert的命名实体识别模型对问句中的实体进行识别,选取与问句相关的邻居节点作为表征知识图谱的信息来源,同时设计了基于Bert编码器、LSTM和自注意力机制的文档和句子的相关度计算方法,找出对知识图谱起到补充作用的句子。最终在子图中抽取答案,并设计了对照实验证明了该方法的可行性。(3)针对缺乏军事领域公开知识图谱的情况,根据相关军事知识设计了本体层,通过行动把装备进行关联,为军事领域的数字化转型提供数据和技术支撑,该系统的主要功能有本体层编辑、知识抽取和知识问答。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.001252
{DOI}: 10.26969/d.cnki.gbydu.2022.001252
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本数据增强和ELECTRA语言模型的中文文本情感分析方法
{Author}: 余宏斌
{Tertiary Author}: 张顺香
{Publisher}: 安徽理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: ELECTRA预训练模型;文本情感分类;文本数据增强;注意力机制;BiLSTM
{Abstract}: 中文文本情感分析是数据挖掘的重要基础之一,旨在自动判定文本中观点持有者对某一话题所表现出的态度。对中文网络评论文本进行情感分析,可以应用于舆情监测,话题监督,口碑分析等场景。对中文网络评论文本进行情感分析存在两个问题:一方面中文网络评论文本的表达方式灵活,语义表达复杂,为抽取高区分度的情感特征带来了一定的难度;另一方面存在负面情感语料远远多于正面情感语料的“类不平衡现象”,进而导致模型训练“失衡”的问题。为了解决这两个问题,本文提出基于文本数据增强和ELECTRA语言模型的情感分类模型。主要的研究工作内容为:(1)针对中文网络评论文本难以抽取高区分度情感特征的问题,本文提出Ea Bi LSTM模型,以强化中文网络评论文本情感特征抽取的过程。基于目前热门的“迁移学习”方式,该模型分别在嵌入层和训练层强化文本情感特征的学习过程。首先,作为优选,在嵌入层,通过ELECTRA模型抽取文本特征;然后,在训练层,通过注意力机制和Bi LSTM模型抽取情感特征并分析相关语义联系;最后在分类层通过Softmax分类器进行分类。实验对比了迁移ELECTRA预训练语言模型与BERT模型的不同特点,并且证明了本文构建的Ea Bi LSTM模型起到了强化中文网络评论文本情感特征抽取的作用。(2)针对“类不平衡场景”下的模型训练“失衡”问题,本文在Ea Bi LSTM模型的基础上提出EDA-Ea Bi LSTM模型。该模型通过文本数据增强技术在模型的训练上引入更多的先验信息。首先,针对类不平衡的语料,通过EDA文本数据增强技术对其进行部分数据增强以平衡语料(第一次先验信息引入);然后通过构建的组合模型(基于ELECTRA)对增强后的语料进行迭代训练,抽取情感特征(第二次先验信息引入);最后通过全连接层和Softmax分类器进行分类。对比那些仅采用模型调优或扩充文本的方法,实验证明了两次引入先验信息的思路能够在F1指标上获得更多的增益,以更好地解决“模型训练失衡”问题。另外,实验还对比了全面增强策略和部分增强策略,结合不同模型所表现出来的效果;并选择F1值的均值作为评价标准,研究了生成文本对比真实文本在训练中的“替换代价”的大小。本文主要的创新和贡献为:针对网络评论这种“过于自由化”的评论文本,提出一种在嵌入层和训练层强化文本情感特征抽取过程的新方法,该方法可以提高情感分类模型的准确率;为了解决“模型训练失衡”问题,本文提出一种“两次引入先验信息”思路下的EDA-Ea Bi LSTM模型;本文还探索了“迁移学习”中预训练语言模型的应用规律,并以EDA增强技术为切入口,对文本数据增强进行了更深入的研究。图[25]表[11]参[84]
{URL}: https://link.cnki.net/doi/10.26918/d.cnki.ghngc.2022.000376
{DOI}: 10.26918/d.cnki.ghngc.2022.000376
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融入自然元素的现代陶艺创作语言研究
{Author}: 张健
{Tertiary Author}: 许雅柯
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 现代陶艺;创作语言;自然元素
{Abstract}: 20世纪80年代初,以台湾陶艺家李茂宗先生和美籍华人许以琪先生为首的现代陶艺家将西方的“陶艺新观念”传入我国,极大的推动了陶艺界对中国陶艺的“现代性”探索,也打开了我国现代陶艺新的篇章。现代陶艺不仅是现代陶瓷艺术的简称,其中还包含着一种全新的精神内涵和审美取向,任何艺术创作的灵感都来源于自然,人类从有审美意识开始,发展到如今的陶艺创作,融入自然元素的陶艺作品比比皆是,自然元素在现代陶艺创作中始终扮演着重要角色。受社会环境、教育、科技等因素的影响,陶艺家们对自然元素的表现,不管是在题材上、观念上还是形式上都逐渐走向多样,开拓了现代陶艺“新境界”。本文以现代陶艺的发展为背景,以融入自然元素的现代陶艺作品为研究对象。首先对自然元素进行了总体的概括,对自然元素的定义、分类及运用进行了阐述;其次通过分析传统与现代、国外与国内陶艺作品,明确了自然元素在陶艺创作中的重要性;通过对受不同的审美观念、教育、社会环境、科技运用及艺术家们的个体属性的影响下,认识到多样化的现代陶艺作品所展现出艺术家们对自然元素的不同理解;最后,通过归纳总结融入自然元素的陶艺创作在题材、材料、造型和装饰等方面的表现,对现代陶艺的未来发展方向有了新的认知和理解,同时也对个人的创作产生了重要影响。探索融入自然元素的现代陶艺创作语言对中国陶瓷艺术文化的再发展、增强中华民族文化自信具有重要意义。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2022.002168
{DOI}: 10.27262/d.cnki.gqdau.2022.002168
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于主题模型的文本语义增强及短文本分类方法研究
{Author}: 卫红敏
{Tertiary Author}: 唐焕玲
{Publisher}: 山东工商学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本表示;Word2vec模型;主题模型;语义增强;短文本分类
{Abstract}: 近年来,随着深度学习和预训练技术的不断进步,自然语言处理的研究取得了优异成绩。文本表示和短文本分类对自然语言处理领域中的自动翻译、文本摘要、情感分析等任务产生了重要的影响。由于自然语言具有复杂性、多样性等特点,使得目前文本表示存在“维数灾难”、“向量高度稀疏”和“浅层语义”等问题,从而导致文本向量不能充分表达出文本的语义信息。由于短文本具有数据量少、数据特征稀疏等特点,导致目前短文本分类的效果不理想。文本语义表示和短文本分类仍然是目前研究的重点和难点。针对上述问题,本文结合主题模型、词嵌入和文本分类等方法展开以下方面的研究:(1)提出了一种结合LDA主题模型和Word2vec模型的文本语义增强模型(Semantic to vector,Sem2vec)。Sem2vec模型在Word2vec模型的输入层前面增加主题嵌入层,首先利用LDA主题模型获得单词的主题分布,计算单词与其上下文词的主题相似度,作为主题语义信息融入到词向量的训练中。然后得到主题权重嵌入词向量,来代替one-hot向量输入至Sem2vec模型。在目标函数的约束下,得到模型的最优参数,最终输出增强的语义词向量表示,并进一步得到文本的语义增强表示。为了验证Sem2vec模型的有效性,在搜狗、清华和20新闻组数据集上与经典模型进行实验比较。在语义相似度和文本分类两个任务上的结果表明,Sem2vec模型在语义相似度计算方面更为准确,在textcnn、Bi LSTM和Transformer文本分类算法上的分类结果,较经典模型可以提升0.58%-3.5%,同时提升了时间性能。(2)提出了一种基于BTM主题模型的有监督双词主题模型(Supervised Biterm Topic Model,SBTM),并将其应用于短文本分类任务中。该模型在BTM主题模型的基础上,引入主题-类别分布参数,由此来识别主题与类别间的语义关系,并准确地将主题与类别进行映射,完成文档的主题分类。通过主题分类,更精确地计算出单词-主题的概率,从而使短文本分类更加准确。为了验证SBTM模型的有效性,在搜狗新闻标题、清华新闻标题和亚马逊评论短文本数据集上与经典模型进行实验比较。实验结果表明,SBTM主题模型用于短文本分类时,能够建立起主题与类别的准确映射,且分类结果较经典模型可以提升1.3%-10.2%。
{URL}: https://link.cnki.net/doi/10.27903/d.cnki.gsdsg.2022.000099
{DOI}: 10.27903/d.cnki.gsdsg.2022.000099
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于内容语义分析的文本摘要方法研究
{Author}: 陈凯
{Tertiary Author}: 陈清财
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自动文本摘要;大规模中文长文本数据集;分层图推理模型;主题引导;动态上下文规划;生成记录重构
{Abstract}: 自动文本摘要是自然语言处理中的一个重要和极具挑战的任务,旨在将文本或文本集合在机器理解的基础上自动生成流畅、简洁并保留关键信息的摘要,包括新闻标题生成、自动报告生成、会议摘要生成等众多应用场景。随着深度学习在自然语言处理中的广泛应用,自动文本摘要的研究也取得了突破性进展。尽管现有方法可以抽取或生成相对可用的摘要,但仍然面临以下挑战:1)针对中文摘要的开放语料很少,大规模中文长文本自动文摘语料更加匮乏;2)序列化的摘要模型缺乏对文档结构的理解和分析,容易使远距离依赖信息丢失;3)序列生成模型缺乏对主题上下文的语义分析,使得生成的文本偏离主题;4)传统摘要或文本生成方法通过静态内容选择的方式,缺乏对事实细节的语义分析,无法满足特定场景下对摘要事实一致性的要求。本文针对以上问题开展研究,主要研究内容包括:针对中文长文本摘要数据集匮乏的问题,提出大规模中文长文本摘要数据集的自动构建方法。首先使用微博和网页爬虫自动抓取微博1上热门媒体用户自然标注的<新闻,微博>对。然后,使用少量约束和新提出的平均摘要指数自动过滤非摘要候选。最后,通过人工进行部分数据标注和审核,并通过实验和对比证明了本文构建的CLES(Chinese Long-text Extractive Summarization dataset)数据集的可用性和挑战性。所构建的CLES包含103,389摘要对。本文将该数据集划分为训练集,验证集和测试集,并选取了多个已发布的摘要模型进行实验。证明了本文所提方法构建的数据集是高质量和更具挑战性的,也为后续中文摘要研究提供了真实可靠的基准结果。针对序列化编码模型缺乏文档结构分析,造成跨句子间重要信息丢失的问题,提出基于分层图推理的摘要抽取方法。该方法首先使用节点的方式表示文档的句子向量,同时增加词语的语义节点用于辅助构建句子间连接。通过图节点之间的连接对文档的各个句子进行语义推理,不但解决了长文本无法完整表示带来的信息缺失问题,同时缩小了位置距离带来的信息衰减。然后,使用关系图网络快速对原文本的句子进行关系建模,获得句子的差异性表示。最后,通过句子分类器选取关键句子作为摘要。在中英文的抽取式摘要任务上进行的实验结果表明,本文提出的分层图推理方法能够有效编码长文本,并提升文档中句子间的语义交互和差异性表示。本文方法在各类评价指标上均优于已发表的传统的神经网络方法和预训练方法,进一步证明了方法的有效性。针对大多数摘要模型缺乏对主题上下文的语义分析,生成的摘要容易偏离主题的问题,本文提出基于主题句子引导的摘要生成方法。该方法首先使用训练好的抽取式摘要模型抽取文章的句子集合作为主题文档。其次,在文档编码器的基础上设计了主题编码器。最后,基于文档向量和主题向量提出了新的加权注意机制,用于指导解码器生成主题更相关的摘要。在大规模英文摘要数据集CNN/Daily Mail的实验结果表明,所提出的主题引导的摘要生成方法较已公开的基准方法在摘要评价指标上有明显提升。通过样例分析可以发现,相比于缺乏主题信息监督的模型,本文提出方法能够生成更贴近主题的摘要。针对传统的摘要或文本生成方法缺乏事实细节的语义分析,无法满足特定场景下对生成文本的连贯性和事实一致性要求高的问题,本文提出了基于动态上下文内容规划的文本生成方法。并在此基础上提出了生成记录重构机制,对已生成文本进行再优化。首先,该方法可以根据已生成的历史文本和数据记录本身的重要性,动态的选择源数据;其次,所提出的生成记录重构机制在特定损失函数的作用下,可以激励解码器从编码器获取更准确的信息。在基准数据集ROTOWIRE和NBAZHN数据集上的结果表明,本文提出的方法在关系生成、内容选择、内容排序和BLEU等多类指标上较已发表方法均有显著提升。通过最好最差标度进行的人工评价结果表明,本文提出的动态选择机制生成的文本比静态选择方法生成的文本质量高。此外,样例分析也表明重构机制有利于提高生成文本的忠实度。综上所述,本文围绕基于内容语义分析的文本摘要方法开展深入研究,针对相关任务存在的四个问题,分别提出了大规模中文长文本摘要数据集自动构建方法,基于分层图推理模型的摘要抽取方法,基于主题句子引导的摘要生成方法以及基于动态上下文规划驱动的结构化文本生成方法。在各自对应的数据集上进行了验证和分析,最终都取得了最优的效果。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.000121
{DOI}: 10.27061/d.cnki.ghgdu.2022.000121
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于社交媒体评论的消费者感知风险测量研究
{Author}: 舒涛
{Tertiary Author}: 贾华丁
{Publisher}: 西南财经大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 心理感知;消费者感知风险;社交媒体评论;机器学习
{Abstract}: 在消费市场的研究领域中,基于心理学基础发展起来的消费者感知风险理论是管理学的重要理论之一,感知风险是影响消费者行为重要因素。传统消费者感知风险的测量方法以设计心理结构的量表为主,通常采用问卷调查、访谈等形式进行数据收集。然而,采用传统数据获取方法的研究,在样本规模、及时性、周期、空间跨度、丰富性等方面存在局限性。因此,无法掌握大部分消费者的心理感知情况,部分研究还面临可重复性危机。
随着移动互联网的普及,社交媒体打破了物理世界的时空和地理位置的边界限制,逐步渗透人们的工作和生活。特别是新冠疫情以来,微博、抖音、今日头条、西瓜视频等社交媒体逐渐演变成消费者评价商品的重要渠道,有关商品评价的日级信息发布数量远超百万级别。由于社交媒体具有平等、多边和开放等特性,消费者可以通过文字、视频、符号等多种数字化形式传递观点、态度和情绪,社交媒体评论能够更加直观地反映发布者的真情实感,成为消费者表达心理认知和情感的主要载体。因此,社交媒体评论中蕴含着丰富的、可测量的消费者感知风险研究数据。
本文在心理学和消费者感知风险理论的研究框架之下,通过智能化计算机程序获得多源社交媒体评论,并对先前研究进行梳理和综述。在此基础上,借助基于机器学习方法的自然语言处理技术对消费者评论文本进行处理,构建消费者感知风险测量流程,具体分为三个相互关联的部分:
首先,关于社交媒体评论语料库的创建。社交媒体评论语料库的创建为准确、全面、及时地测量不同商品的消费者感知风险提供了数据基础,克服了传统问卷调查和访谈的感知风险测量方法局限性,提高了数据的全面性和丰富性。值得注意的是,不同商品具有不同的特性,受众群体也不尽相同,体现在评论中的内涵和外在表现差异较大,有必要对比不同类型商品的感知风险测量过程和结果。为此,本文选择了在产品形态、营销模式、运营方式和受众群体上都存在巨大差异的两种商品(电动汽车和网络游戏)构建语料库,以检验本研究设计的测量框架是否具备良好适应性和可扩展性。并且,在数据预处理后,本研究以消费者感知风险理论为指导随机选取部分数据进行了人工标注,形成消费者感知风险测量研究所需的数据基础。
其次,基于机器学习方法的消费者感知风险测量框架构建。本文参考中文自然语言处理领域的前沿成果,构建了“主题特征挖掘——感知风险语义识别——情感分析”三个任务来实现消费者感知风险测量目标。(1)感知风险主题特征的挖掘任务。其目的是确定基于感知风险特征属性的分类标签,以作为第二个任务中,多标签分类模型识别评论中多类别感知风险语义的标签基础。具体而言,为了解决机器学习方法与消费者感知风险理论的兼容性问题,本研究在感知风险主题特征挖掘过程中,借助先前人工标注的数据,采用有标签的隐含狄利克雷分布主题模型(Labeled Latent Dirichlet Allocation,Labeled LDA)对语料库中感知风险主题特征进行挖掘,以确定不同商品的消费者感知风险主题的种类。然后,在以往商品的消费者感知风险研究的基础上,通过可迭代的匹配过程进行验证归纳,提高标签设定与感知风险理论的兼容性。(2)消费者评论文本中感知风险语义的识别任务。为了从消费者评论的语义表达中,识别出可能涵盖多个感知风险的主题,本研究设计了一个多标签文本分类模型。该模型融合卷积神经网络和长短时记忆人工神经网络(CNN-LSTM),以第一个任务的感知风险主题挖掘结果作为分类标签基础,分析获得单个或者组合的感知风险评论数量分布结果,完成不同感知风险主题的复杂语义分类识别。(3)评论文本的情感分析任务。因为第二个任务仅能展现消费者对各种感知风险关注程度或者认知情况,无法洞察和明晰消费者对商品不同感知风险的情感立场的问题。所以,在第三个任务中,本研究设计了动态文本向量化、双向循环神经网络和注意力机制的(BERTBi LSTM-Attention)情感分析模型,对第二个任务的感知风险语义识别结果进行解释补充,从而获得了每种感知风险在消费者心理的情感倾向。
最后,基于实验结果的拓展研究和管理启示。(1)基于实验结果的讨论。在本研究实验结果的基础上,深入分析了电动汽车和网络游戏两种商品的感知风险主题与情感倾向。并且,采用社会网络的分析方法,生成感知风险主题的共现网络,揭示出社交媒体评论中共现次数多的感知风险主题组合。(2)基于实验结果的实证研究。针对每种感知风险的实验结果,与同时期重大事件进行匹配,以实证研究视角探究基于时间线的动态评论量变化和情感波动,检验社交媒体评论中消费者感知风险测量的及时性和有效性。(3)基于实验结果的对比分析。横向上,对不同商品的实验结果进行比较;纵向上,现有消费者感知风险研究结果进行比较。以此进一步论证本研究的可行性和创新性。(4)基于实验结果的管理启示。依据两种商品的实验结果,从政府和企业不同主体,阐述管理启示。
本研究的创新性主要包括以下几个方面:
第一,相对于传统的心理测量研究获取数据的方法,本研究创新性地以大规模社交媒体评论数据为驱动,丰富了消费者感知风险理论的研究视角,为未来相关研究提供全新的数据支撑。本文创建了电动汽车和网络游戏商品的与消费者感知风险相关的社交媒体评论语料库,并对语料库进行多次人工标注,通过机器学习模型对其进行了训练、测试和验证。
第二,创新性地以系统论为基础,设计和验证了基于机器学习方法的测量框架,系统地构建了“主题特征挖掘——感知风险语义识别——情感分析”三个任务的消费者感知风险测量,对不同商品的消费者感知风险进行充分地识别和测量。本文测量框架的第一和第二个任务组成了一个可迭代的过程。在这个过程中,参考以前研究而预设的消费者感知风险维度,与从评论中挖掘的客观结果不断验证、修改和适配、产生新的感知风险主题(粒度),从而保证了机器学习挖掘、识别过程置于相关理论研究的可解释范畴。同时,语料库中新发现的感知风险主题,也很容易回顾到理论中检验,并补充至现有理论的实证或修订,保障了消费者感知风险测量研究领域,机器学习与感知风险理论的兼容性。更为重要的是,验证、修改和适配过程,不仅保证了测量框架对新的感知风险主题的发现能力,还具备了对不同商品感知风险测量的泛化能力。
第三,创新性地将情感分析任务纳入到测量框架,突破了消费者感知风险语义识别中,只能量化各类风险主题中消费者评论数量的技术难题,实现了感知风险关注度和认知情况的测量,明确了消费者对各个感知风险情感倾向。具体而言,在本研究设计的情感分析模型中引入了动态向量转化模型和注意力机制,提高了情感分析的效果。基于情感分析结果,明确了每个感知风险维度和粒度情感倾向。并且,面向各个感知风险维度和粒度识别结果,获得消费者支持、中立和反对的立场,为判断消费者对各类感知风险的整体认知强弱程度提供了方法和技术支撑。
综合而言,本文依据“回顾式”的创新思想,重新检验和发现研究问题,挖掘研究价值,利用研究成果及时发现新变化,帮助检验、修正和补充现有消费者感知风险测量的研究基础。本文提出的基于社交媒体评论数据的消费者感知风险测量框架,既能够获得多维度、细粒度的消费者对不同商品的感知风险认知和情感倾向,也能够捕捉到时间和事件引发的波动情况。该测量框架具有适应性、及时性、扩展性,为当前消费市场的前沿研究和数据分析提供借鉴。本文的研究一定程度上促进了计算机科学、心理学与管理学在消费者感知风险理论的交叉研究。本研究成果也对政府的产业战略的调整和实施,促进可持续发展提供支持,为相关产业与企业的战略规划、市场营销策略的制定提供参考。
{URL}: https://link.cnki.net/doi/10.27412/d.cnki.gxncu.2022.003384
{DOI}: 10.27412/d.cnki.gxncu.2022.003384
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于大数据的新世纪中国教育哲学知识图谱研究
{Author}: 王银铎
{Tertiary Author}: 高伟
{Publisher}: 山东师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 教育哲学;知识图谱;大数据;人工智能;实证研究
{Abstract}: 新世纪以来,在教育改革与现代化的整体背景下,作为教育学基础理论学科之一的教育哲学,它的研究离不开阶段性成果的总结与回顾。基于新世纪二十余年已有成果的反思与批判,既有助于梳理学科历史发展脉络,又有助于探索内在逻辑规律与价值。然而,近些年,我国教育哲学研究成果丰硕,但受限于思辨研究主导地位的影响,在对现有学科发展的探究过程中,常沉浸于研究者自身的经验逻辑,易陷入主观臆断的旋涡中,造成学科的“可验证”与“普遍性”略显不足。既缺乏对学科发展全貌的客观、系统刻画,也难以支撑内在思想与价值逻辑的动态变化。这就需要我们引入实证研究,对其加以完善。
如今,大数据可以有效地弥补思辨研究产生的“缺憾”。尤其时下较为流行的知识图谱,它对于科研文献数据的搜集、统计、分析、挖掘及可视化等方面具有独到的“见解”。不但可以通过对海量数据进行精细加工与挖掘,而且还可以动态地展示学科发展规律。这有助力于从宏观层面对新世纪中国教育哲学研究进行梳理与分析。而知识图谱归纳出的关键词又可视为“锚点”,借助人工智能技术将其“嵌入”到文本数据中,并通过定位、拆分、排列及重构,尝试性地“预测”中国教育哲学发展的趋势特征。
按照上述思路,本研究以2000—2021年“中国社会科学引文索引数据库(CSSCI)”所搜录的教育哲学类期刊文献为蓝本,总计8445篇。将它们视为新世纪中国教育哲学知识图谱的基础数据,并按照关键词、研究热点及研究突现三个层级予以梳理,力求全方位、多角度地展现新世纪中国教育哲学研究的全貌。尔后,研究以期刊文献所筛选出的关键词,通过“标记”的形式融入到书籍本文数据中,并借助自然语言处理技术,预测未来中国教育哲学知识图谱的趋势特征。
新世纪中国教育哲学知识图谱相对聚焦在传统教育哲学的审视、教育哲学价值的反思、教育哲学理论的批判以及面向现代化教育哲学的构建等若干领域。2000年至2006年,我国教育哲学学科整体呈现为改革与人文价值特色,以知识与经济社会转型期为中心的我国教育哲学的改革研究成为热点,相继从人文精神、实践、价值及理论创新等多个领域详细探究。以此来回应新时代背景下中国教育哲学研究新方向。2007年至2013年,我国教育哲学学科整体呈现为转变与实践的特色,我们在面对时代潮流之“变”的同时,“不变”的是教育哲学所赋予我们的求知与求真。因而,教育哲学在理论、思想、价值及实践等方向上依然追寻“永恒不变”的真谛,力求在主体性、知识论、本体论、课程论、教师教育的审视等方面来寻求“突破”,具体表现为:一是中国教育哲学研究围绕民主、公平或正义等关系范畴探究自身发展的本质与内涵;二是中国教育哲学研究的热点转向了教育实践及其关系范畴的大讨论中,并逐步迈进构建本土化、全球化、多元化及实践化的中国教育哲学体系框架。2014年至2021年,我国教育哲学学科研究总体上呈现为责任与话语权,主要涵盖现代化教育哲学体系的构建、教育哲学的责任意识以及人的生成与价值塑造。而未来中国教育哲学知识谱图的趋势特征是将以人本主义为中心,贯穿整个教育哲学研究的基本范畴、理论、价值及实践等方向来构建具有中国气质的“新时代”教育哲学。
这反映出中国特色社会主义教育哲学既要借助中西教育哲学的融合共筑它的发展之基,也要提升中国教育哲学的自我创生性。特别是在以大数据为基础的人工智能分析或实证研究已然成为一种趋势的前提下,我们在借助“混合”研究方式对新世纪中国教育哲学研究热点进行“量化”探析的同时,更需要不断地补充“质性”分析。并且,站在技术哲学的高度,对大数据应用于我国教育哲学实证研究的认识、逻辑及价值进行审视。而本文的最终研究目的是既要探索性地证明我国教育哲学研究能够进行实证分析,同样也要为教育哲学研究方法提供一种可能与借鉴。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2022.002139
{DOI}: 10.27280/d.cnki.gsdsu.2022.002139
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向鲁棒性的跨模态预训练关键技术研究
{Author}: 时磊
{Tertiary Author}: 苏森
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 预训练-微调;跨模态信息融合;密集对比学习;对抗攻击与防御
{Abstract}: 在深度学习领域,如何在有限数据下训练高效的深度学习模型是需要面对的一个基本问题。解决该问题的一个有效方法是通过预训练-微调范式。受到BERT、GPT等工作的启发,国内外研究者已经提出几种联合表征图像和文本的跨模态预训练-微调方法,但是目前的研究不能从构建模型阶段、预训练模型阶段和微调模型阶段的全局角度考虑跨模态预训练研究的鲁棒性,因为当前的研究存在以下三方面的不足。第一,在构建模型阶段,存在表征不对称场景下的跨模态融合问题。由于同时期的跨模态预训练研究并不能实现端到端的学习过程,因为输入的视觉信息是经过深度神经网络提取的视觉区域特征,而文本信息并未经过深度表征,利用当前的跨模态信息融合方法不但会引入文本浅层噪声信息,而且还忽略了跨模态信息的跨层交互,导致跨模态模型鲁棒性变差。第二,在预训练模型阶段,存在跨模态视觉语义表征稀疏的问题。已有的跨模态预训练模型在视觉分支使用了有监督的分类任务,该方式限制了跨模态视觉语义信息获取细粒度表征的能力,当面对视觉内容产生细粒度的语义变化时,模型鲁棒性变差。第三,在微调模型阶段,存在混合粒度攻击场景下跨模态模型鲁棒性差的问题。因为在面对场景复杂多样的跨模态下游任务时,跨模态模型容易受到不同扰动粒度的攻击,该扰动攻击可能同时来自连续形空间产生的微小扰动以及文本离散空间产生的近义词替换,从而使模型做出错误预测,导致跨模态模型鲁棒性不足。本文针对面向鲁棒性的跨模态预训研究集中在以下三个方面,即表征非对称下的跨模态信息跨层融合方法,面向密集视觉语义表征的跨模态无监督预训练方法和面向混合粒度攻击的跨模态鲁棒性微调方法。并取得了以下创新成果:1)针对表征不对称场景下的跨模态信息融合问题,提出基于四元复数内积的跨层融合方法。在已有的研究中,视觉输入信息通常来自视觉区域特征,此时视觉、文本信息存在不对称性的表征,现有的Transformer机制只针对同层的跨模态信息进行融合,所以当前的方法不但会引入文本浅层噪声信息,而且忽略了不同层跨模态信息的交互,导致跨模态模型鲁棒性变差。本文提出基于四元复数内积的跨层融合方法,利用该方法构建了四元复数块堆叠的网络(Quaternion Block Network-QBN),解决了表征不对称场景下的跨模态信息融合问题,实现了跨模态信息跨层融合。在四元复数块内,通过多层内容学习,多层关系学习不但可以去除文本浅层噪声信息,还可以捕获不同模态之间的跨层交互,提升模型鲁棒性。另外,通过文本特征对视觉特征进行动态缩放,验证了引入更多文本相关的视觉特征可以有效地提高模型性能。本研究利用VQAv2数据集对提出的QBN模型和子模型进行验证,QBN模型在视觉问答任务(VQA)的效果可以超过同时期的其他模型,甚至可以超过早期的跨模态预训练模型效果,验证了基于四元复数内积的跨层融合方法的有效性。2)针对跨模态视觉语义表征稀疏的问题,提出面向密集对比学习的跨模态预训练方法(Dense Contrastive Visual-Linguistic Pretraining-DCVLP)。在已有的跨模态预训练研究中,针对视觉区域特征添加了基于掩码的分类和回归任务来进一步提升预训练模型的效果,但是该方法属于有监督的代理任务,会引入稀疏的语义理解,导致跨模态模型面对细粒度的复杂问题时鲁棒性变差。本文提出面向密集对比学习的跨模态预训练方法,解决了跨模态视觉语义表征稀疏的问题,实现了自适应的学习跨模态细粒度语义的共现性,确保当视觉内容产生细粒度的语义变化时,模型能够具有鲁棒性。本文设计了两种实现密集对比学习的跨模态预训练方法:基于掩码扰动任务的跨模态对比预训练方法和基于对抗扰动任务的跨模态对比预训练方法。本文通过在经典的单流模型和双流模型对提出的面向密集对学习的跨模态预训练方法进行验证,实验结果表明该方法对原有模型效果提升显著,证明了该方法的广泛适用性。该方法在多个视觉-语言下游任务的效果可以超过同时期的其它模型,证明了面向密集对比学习的跨模态预训练方法的有效性。3)针对混合粒度攻击场景下跨模态模型鲁棒性差的问题,提出面向混合粒度攻击与防御的跨模态微调方法,解决了混合粒度攻击场景下跨模态模型鲁棒性差的问题。该方法分为两个阶段,在攻击阶段,通过混合攻击方法同时在Token粒度和Embedding粒度产生攻击,可以在近似语义空间中获得高质量的对抗样本,该对抗样本同时包含了近似语义攻击和微小扰动攻击。在防御阶段,为使模型能够抵抗混合攻击,本研究利用蒸馏损失在混合攻击的输出分布和原始模型的输出分布之间进行知识蒸馏,为跨模态微调阶段提供动态监督,提升下游任务模型的鲁棒性。本文在多个视觉-语言下游任务数据集对面向混合攻击与防御的跨模态微调方法进行验证,实验结果表明该方法对下游任务准确率提升显著,从而验证了面向混合粒度攻击与防御的跨模态微调方法的有效性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.000238
{DOI}: 10.26969/d.cnki.gbydu.2022.000238
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 学术论文中“问题—方法”关系抽取研究
{Author}: 张颖怡
{Tertiary Author}: 章成志
{Publisher}: 南京理工大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 科学研究问题;科学研究方法;问题与方法关系;学术论文内容抽取;学术论文内容分析;学术论文知识管理
{Abstract}: 新需求的提出和生产工具的改进涵盖了人类社会的基本活动。新需求可视为问题的提出,生产工具的改进可视为方法的设计。科学研究亦如此,其是一个从提出问题到设计方法、使用方法以解决问题的实践活动。问题和方法是科学研究中的重要组成部分。科研工作者的研究成果通常以学术论文、专著、专利或报告等学术文献形式作为交流与传播的载体。浩如烟海的学术文献是科研工作者的隐性知识的显性表达,可通过抽取学术文献中的“问题-方法”关系实现学术文献的组织和管理。学术文献“问题-方法”关系抽取是管理科学与工程中知识管理领域中知识发现、分类、组织的实践,也是科研成果评价的基础。从学术文献中发现问题和方法并抽取其关系,对知识管理评价的深入研究具有重要的理论和现实意义。学术论文是科学研究成果的主要形式,因此,在研究中本文以学术文献中的学术论文这一类型作为研究对象。互联网的快速发展促进了学术论文的数字化和开放获取,这为学术论文的内容抽取提供了基础。学术论文的“问题-方法”关系抽取任务与一般文本抽取任务不同。首先,该任务需要明确何为问题和方法、其间存在何种关系。其次,学术论文存在科学性和逻辑性等表达特征。再者,学术论文的摘要和全文存在内容层面、处理难度等方面的差异。现有关于学术论文的“问题-方法”关系自动抽取的研究中不同程度上忽视了这三点:第一,在问题和方法及其关系的定义上,现有学术论文“问题-方法”关系自动抽取的相关研究中较少结合科学哲学等理论;第二,在学术论文信息自动抽取研究中,已有研究注意到学术文本和普通文本的不同,通过使用在海量学术论文上训练的SCIBERT等预训练语言模型来提升该任务的性能,但较少通过分析该任务中的特有难点来设计和优化自动抽取算法;第三,当下学术论文全文本抽取已成为一种研究趋势,但是,相比于摘要的内容精炼和易处理等特性,在学术论文全文的内容多样且分散和处理难度较大等情况下,缺少研究来说明从学术论文全文本中抽取“问题-方法”关系的价值。为将以上三点考虑到学术论文的“问题-方法”关系抽取研究中,本文沿着定义问题和方法及其关系、设计关系自动抽取方法来缓解学术论文中自动抽取任务的难点、分析和对比学术论文摘要和全文中关系抽取结果的基本路径。本文主要工作包括以下四个方面:(1)针对目前学术论文中问题和方法及其关系的定义中较少结合科学哲学中的问题学等理论的现状,本文使用理论、文献和数据调研,设计一个两层次“问题-方法”关系体系。该关系体系的两个层次分别是通用“问题-方法”关系体系和特定领域“问题-方法”关系体系。通用“问题-方法”关系体系的设计以不同科学研究领域中的共同点为依据。特定领域“问题-方法”关系体系以通用体系为基础,结合特定研究领域的特点对通用体系进行细分和扩充。本文根据可实现性原则,选择自然语言处理为特定研究领域。(2)由于现有研究在学术论文“问题-方法”关系抽取任务中较少根据该任务中的特有难点来设计模型,本文沿着“杜威思考五步法”,首先分析和界定自然语言处理领域中学术论文“问题-方法”关系自动抽取任务中的特有难点,然后针对难点设计和优化“问题-方法”关系自动抽取算法,最后验证本文提出的算法的有效性。为减少学术论文全文带来的噪音,本文将“问题-方法”关系抽取分为三个步骤,分别是问题与方法句分类、问题与方法词识别及“问题-方法”关系抽取。经分析,本文发现问题与方法句自动分类的难点包括公式化表达影响和上下文信息依赖。针对这两个难点,本文提出基于公式化表达替换的数据增强方法和引入上下文信息的模型来缓解。问题与方法词自动识别的难点包括公式化表达影响和边界识别错误。针对这两个难点,本文提出基于公式化表达替换的数据增强方法和基于指针网络的边界识别加强模型来缓解。“问题-方法”关系自动抽取的难点包括指代解析错误、关系方向预测错误及各关系类别下数量不均衡导致的语义理解困难。针对这三个难点,本文分别使用Transformer模块来学习词语间关系以更好发现句子间词语的指代关系,使用交叉编码器(Cross-Encoder)判断关系抽取结果的方向,使用主动学习来扩充数据集以丰富各关系类别的语义信息。本文在两个人工标注英文实验数据集上验证了各类方法的有效性。(3)为了分析学术论文全文本在“问题-方法”关系抽取中的价值,本文抽取、分析和对比特定领域下学术论文全文和摘要中“问题-方法”关系抽取的结果。本文以自然语言处理为特定研究领域,选择ACL会议的1979至2020年的论文集作为语料进行关系抽取和分析。该语料是英文语料。在抽取中,本文使用本研究提出的“问题-方法”关系抽取模型。在分析中,本文划分语义时期、传统机器学习时期和深度学习时期这三个时间段。为比较学术论文摘要和全文关系抽取的结果,本文在该语料的基础上构建摘要语料和全文语料,然后设计数值指标和内容指标来分析和对比从这两类语料中识别的问题和方法及抽取的“问题-方法”关系。(4)本文分别构建“问题-方法”关系自动抽取系统与特定领域中“问题-方法”关系抽取结果分析系统,可用于学术论文中问题和方法的知识挖掘,同时为学术论文中知识的组织和评价提供基础。其中,“问题-方法”关系自动抽取系统包括三个模块,分别是学术论文问题和方法句分类模块、问题和方法词识别模块和“问题-方法”关系抽取模块。特定领域中“问题-方法”关系抽取结果分析系统用于展示自然语言处理领域下的“问题-方法”关系抽取结果,其包含两个模块,分别是问题与方法词的关系摘要模块和问题与方法的内容分析模块。
{URL}: https://link.cnki.net/doi/10.27241/d.cnki.gnjgu.2022.000062
{DOI}: 10.27241/d.cnki.gnjgu.2022.000062
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于代码相似性比较的二进制程序漏洞检测技术研究
{Author}: 于璐
{Tertiary Author}: 陆余良
{Publisher}: 国防科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 二进制代码相似性比较;漏洞检测;神经网络模型;自然语言处理;导向式模糊测试
{Abstract}: 软件漏洞是各种网络安全事件产生的主要原因,对网络空间安全的影响至关重要,得到安全研究机构、科研学术团体和企业广泛而持续的关注。在软件开发过程中,开发人员往往复用已发布的代码实现程序的特定功能,这种方法一方面可以有效提高开发效率,缩短开发周期;另一方面,也将复用代码中的安全漏洞扩散到大量的相关程序中,带来的安全隐患不容忽视。对复用代码漏洞的检测是漏洞分析的一个重要的研究方向,也是软件供应链安全的关键研究内容。与源码已知的程序相比,对二进制程序复用漏洞检测的难度更大:二进制程序缺乏数据结构和数据类型等丰富的代码语义信息;由于编译优化设置的不同,即使是同一源码编译的二进制程序也存在较大的代码特征差异。论文旨在研究针对源码未知的二进制程序的复用漏洞检测方法,基于代码相似性比较技术,将机器学习算法对代码特征学习的优势与程序分析技术结合,从基于语义学习模型的二进制代码函数级相似性比较方法、基于数据流分析的二进制代码组件级相似性比较方法和基于导向式模糊测试的二进制程序漏洞验证方法三个方面展开研究,主要内容包括:1.针对当前函数级别相似性比较的研究在代码特征提取时存在的结构特征表征不全面、对语义特征提取粒度较粗且语义表征不足的问题,论文提出一种基于语义学习模型的二进制代码函数级相似性比较方法。该方法从指令、基本块和函数三个不同粒度提取二进制程序特征,借鉴自然语言处理技术并利用图神经网络模型,对代码上下文语义和结构语义特征进行向量表示,训练语义学习模型对代码的相似程度进行学习。基于相似性比较的语义学习模型可以在函数级别判断目标代码与漏洞代码的相似程度,以检测代码复用漏洞。实现的原型系统在验证集上的表现好于代表性工具Gemini;在对包含103数量级函数数目的真实固件漏洞检测中,得到的top-5、top-10和top-50的精确度分别比Gemini高出113.3%、60.0%和32.7%。2.针对当前组件级二进制程序相似性比较方法存在的因特征提取过粗,导致对差异较大的代码匹配精度不高的问题,论文提出一种基于数据流分析的二进制代码组件级相似性比较方法。根据比较粒度的不同,提出包括自上而下和自下而上两阶段的代码相似性比较方法,以定义的锚函数和函数调用关系为基础,一方面基于锚函数和数据流分析方法,筛选组件中可能存在对应关系的候选函数;另一方面使用语义学习模型,对函数语法语义特征进行提取表示,以确认候选函数的对应关系。该方法在保证效率的同时,提高了组件级比较结果的精度。实验证明本文提出的方法在对Busybox跨架构的比较上,平均召回率和准确率比代表性工具中表现最好的BinDiff高出69.8%和60.5%。该方法不仅可以应用于二进制代码组件级漏洞检测中,还可以辅助软件供应链安全分析中的补丁比较和恶意代码检测。3.针对静态漏洞检测方法存在的误报率较高、缺乏有效的动态验证方法的问题,论文研究了面向二进制程序的导向式模糊测试方法,实现对漏洞静态检测结果的验证;同时对导向式模糊测试方法进行优化,以解决导向式模糊测试方法对代码在执行导向时起的不均等作用考虑不充分等问题。利用代码相似性语义学习模型,自动识别目标代码区域,并结合静态分析结果和动态执行过程信息,根据代码在引导执行中的不同作用对其赋相应的权值,使用遗传算法选择种子生成新的测试用例,使其更容易执行到目标代码区域,提高模糊测试的导向性。同时,论文实现的导向式模糊测试方法在自动定位目标代码区域时,不局限于特定类型的漏洞,通用性更强。实验结果证明,与相关模糊测试工具相比,论文提出的方法不仅能够在LAVA-M上触发更多的异常,还可以有效应用于漏洞复现和异常发现中。
{URL}: https://link.cnki.net/doi/10.27052/d.cnki.gzjgu.2022.000140
{DOI}: 10.27052/d.cnki.gzjgu.2022.000140
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的复杂多元关系嵌入与文本知识增强研究
{Author}: 黄炎
{Tertiary Author}: 张新访;路松峰
{Publisher}: 华中科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 表示学习;迁移学习;文本知识增强;文本事件抽取;文本自动生成;知识图谱嵌入;复杂多元关系
{Abstract}: 互联网时代的快速发展催生了海量网络数据,呈现出类型多样、语义复杂、多元异构的特点,为了高效地理解和利用这些数据所蕴含的关键信息,人们借助知识图谱(Knowledge Graph)来组织和管理其中的关联知识并提供智能化服务。作为人工智能的重要组成部分,知识图谱以图结构形式描述客观世界中的实体、概念和关联关系,具备开放互联特性和较强的语义推理计算能力,可以作为外部知识库用于智能客服对话、智能搜索、疾病诊断和智能阅卷等场景并产生重要应用价值。然而,现有的知识图谱技术在知识表示和应用方面还存在以下问题:首先,通常把知识表示为三元组结构形式,缺乏对复杂多元关系的合理表示和嵌入方法,难以完整表达和推理现实世界中的事件、程序等复杂关联知识;其次,缺乏利用知识图谱中的背景知识助力自然语言语义理解的有效手段,知识图谱的符号化表示方式不便于计算机矢量计算,而查询检索和远程监督的方法在语义的准确理解和推理上存在局限性,阻碍了知识图谱在自然语言处理等领域的应用和推广。基于上述问题,从如下四个方面进行了深入研究:针对多元关系知识图谱表示学习中的实例聚集效应进行研究。提出一种实例分组约束优化策略和基于该策略的知识图谱多元关系嵌入方法,把多元关系实例的实体和事实节点从实体空间映射到关系空间,并研究不同距离约束方法对多元关系映射结果的影响。在多个数据集上的实验结果表明相比现有多元关系表示方法,该实例分组约束优化策略能够有效建模多元关系实例的聚集效应,在链接预测和实例分类任务上达到较优性能,并对不同多元关系嵌入扩展模型具有一致增强效果。针对多元关系知识图谱表示学习中的异构知识关联特性进行研究。提出一种基于事实关联建模的复杂多元关系嵌入方法,把多元关系实例的实体、关系、事实分别映射到不同的低维向量空间,并对实体-关系、实体-事实、关系-事实关联分别进行建模构成一个组合优化问题,最后采用随机子梯度下降算法求解该问题。在2个多元关系数据集和4个二元关系数据集上的实验结果表明,相比已有多元关系嵌入工作,该方法能够有效建模多元关系实例内部的事实关联特性,模型的鲁棒性和可扩展性均优于现有方法。针对低资源少样本场景下文本事件抽取难的问题,研究基于事件知识图谱嵌入与知识领域迁移的新方法,以增强事件语义理解与候选事件抽取能力。提出一种知识图谱与文本事件的联合嵌入框架,将候选事件映射到知识图谱嵌入空间,并通过最近邻搜索推断候选事件提及和论元的类型。该模型采用知识图谱进行事件知识迁移学习,利用知识图谱中的已知事件类型和知识推理判别候选事件类别和抽取对应事件属性。在ACE-2005和MAVEN数据集上的实证分析结果表明,该方法不仅能提高对已知事件的分类精度,还能显著提高少样本甚至零样本条件下未知事件抽取的性能。针对自动生成文本的主题控制问题,研究基于外部常识知识图谱嵌入的辅助解决办法。提出一种基于知识图谱增强的篇章级主题文本自动生成框架。该框架针对主题描述语句,结合知识图谱进行联合嵌入表示,然后通过语义空间搜索生成写作主题规划,最后提出改进的主题可控文本生成模型,基于聚类主题词生成每个段落文本。模型分别从文本主题分布、注意力评分方式、常识知识搜索和主题词覆盖生成四个方面,对文本生成基准模型提出了具体的改进策略,并通过实验证明了所提出方法的有效性。综上所述,提出了基于知识图谱的复杂多元关系嵌入方法和文本知识增强方法,充分利用知识图谱的结构化知识关联特征,提供多元异构知识建模和知识表示推理、低资源条件下文本事件抽取和主题可控文本生成,解决大规模知识图谱的表示和推广应用技术难题。
{URL}: https://link.cnki.net/doi/10.27157/d.cnki.ghzku.2022.006133
{DOI}: 10.27157/d.cnki.ghzku.2022.006133
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于结构特征和多层信息交互的文本语义匹配关键技术研究
{Author}: 齐乐
{Tertiary Author}: 刘挺;张宇
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自然语言处理;文本语义匹配;文本结构特征;注意力机制;跨模态应用
{Abstract}: 文本语义匹配是自然语言处理中一个基础且重要的研究方向,其目的是判断两段文本是否符合给定的语义关系,其包含了大量的下游任务,如自然语言推理、复述识别、答案句选择等等。任务不同,文本语义匹配所需判断的语义关系也不一致。然而无论哪一种语义关系,判断文本间语义是否匹配都需要研究:(1)如何表示文本语义?(2)如何判断文本间语义关系?针对这两个核心研究点,研究者们将文本语义匹配研究分为基于表示和基于交互的文本语义匹配研究。前者主要研究如何设计更好的文本编码器来表示文本,而后者则更注重于研究判断文本间语义关系的方法。本文将利用文本结构特征对基于表示的文本语义匹配展开研究,并利用多层交互匹配过程中产生的历史信息对基于交互的文本语义匹配进行探索。此外,针对非纯文本格式的异构文档(如PDF、网页、扫描文档等等),现有自然语言处理应用如开放域问答系统通常需要预先根据不同的文档格式设计不同的内容抽取算法,再从中抽取文本内容进行后续的分析处理。这无疑需要消耗大量的人力物力,而且损失了原始文档中有价值的布局和视觉信息。为此,本文从视觉角度通过文档图像描述异构文档,对文本和文档图像间的跨模态文本语义匹配及其在问答领域的应用展开研究。具体来说,本文的主要研究内容包括以下四个方面:1.基于文本线性结构表示的文本语义匹配研究。在基于表示的文本语义匹配研究中,现有研究通常会用自注意力网络取代卷积神经网络和循环神经网络来构建表示能力和可并行化能力更强的文本编码器。然而,由于自注意力机制的位置独立性,自注意力网络难以利用文本的位置结构特征去捕获文本内的语义依赖。本文分析了文本线性结构,利用词的绝对位置、词间相对距离和词序三种结构特征对其描述。在此基础上,本文提出基于双向线性位置感知的Transformer,通过绝对位置可感的相对位置编码和双向掩码策略将上述三种结构特征有机地融合在一起,共同建模文本线性结构,并利用文本线性结构更精准地建模文本顺序、文本内的关键信息以及局部语义依赖信息。在自然语言推理和复述识别两个文本语义匹配任务上的实验验证了该方法的有效性。2.基于文本混合结构表示的文本语义匹配研究。文本结构特征多种多样,不同结构特征间相辅相成,仅从单一角度无法全面地建模文本结构。为了同时从不同角度建模文本结构,本文利用多头注意力机制的多视角建模优势,提出了多掩码式多头注意力机制,并在此基础上提出了混合结构特征引导的Transformer,将词序、词相对距离和词依存距离同时引入到Transformer中。在多种结构特征的帮助下,该模型可以同时建模文本的线性结构和语义依存结构,更好地捕获文本内局部和非局部语义依赖。在自然语言推理和复述识别中的实验结果表明,该方法与只利用文本线性结构的基于双向线性位置感知的Transformer模型相比有了进一步的提升。3.基于多层网络交互历史的文本语义匹配研究。在基于交互的文本语义匹配研究中,现有研究通常会利用多层交互匹配更好地判断文本间的语义关系。在此过程中,前序匹配产生的历史表示信息和历史交互信息都会对后序匹配起到指引的作用。然而现有研究往往只能传递并利用其中一种信息,无法很好地利用所有的历史信息。为了更好地传递并利用这两类历史信息,本文提出了全信息传递网络。该网络使用一种新颖的原始-平均混合链接模式更高效地传递表示信息,并使用基于记忆的注意力机制利用全局交互矩阵保存并传递交互信息。在自然语言推理和复述识别中的实验结果表明,在资源受限的情况下该方法要优于其他非预训练模型和同等规模的预训练模型。4.基于布局结构的跨模态文本语义匹配研究。针对广泛存在的非纯文本格式异构文档,本文从文本语义匹配研究延伸到面向文本和文档图像间的跨模态文本语义匹配研究。在文本语义匹配被广泛应用的开放域问答中,现有系统需要针对不同格式的异构文档设计特定的内容抽取算法预先抽取文本内容作为其信息来源。这不仅大幅度增加了可规模化开放域问答系统的构建成本,而且损失了原始文档中的布局和视觉信息。为此,本文提出开放域文档视觉问答任务,以异构文档的文档图像集合为信息源回答用户提问。同时,本文融合前面所有的研究内容对面向文本和文档图像间的跨模态文本语义匹配展开研究,提出了联合布局结构及文本线性结构的全信息传递网络,并将其应用于开放域文档视觉问答任务中的精排阶段,对问题和检索返回的候选文档图像进行匹配。在本文提出的首个中文开放域文档视觉问答数据集上的实验验证了模型的有效性。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.000532
{DOI}: 10.27061/d.cnki.ghgdu.2022.000532
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于神经网络的对话生成方法研究
{Author}: 崔福伟
{Tertiary Author}: 刘泽;徐金安
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自然语言处理;对话生成;多轮对话生成;多轮情感对话生成;低资源对话生成
{Abstract}: 对话是人与人之间交流的重要方式,同时也是人机交互的主要手段。随着人工智能技术的发展,对话生成技术也得到快速发展,但其仍不能满足人们日益增长的生活需求。研究基于神经网络的对话生成新技术,对促进对话系统和人机交互技术的发展具有理论价值和实际指导意义。目前,基于深度神经网络的对话生成方法已经取得了较大的进展,但仍存在一些问题需要探索:(1)现有的端到端对话生成模型容易生成通用性回复,并且生成的回复包含有用信息较少且多样性较差。因而如何生成富含较多有用信息、多样的回复成为实际应用中亟待解决的问题。(2)人与人之间的交流是富含情感的,而现有的对话生成模型缺乏共情能力。因而,构建多轮情感对话生成模型成为一个新的研究热点。(3)性能优越的对话生成模型依赖于大规模高质量的对话语料,尤其是在面对新领域时,较少的对话语料会导致其性能严重下降。因此,低资源场景下对话生成方法的研究成为迫切需要解决的问题。面对对话生成现存的问题,本文深入研究基于神经网络的对话生成方法,围绕生成富含有用信息且多样回复的对话生成模型、多轮情感对话模型以及低资源对话生成模型的解决方案开展研究,研究方法及成果总结如下:1、针对现有对话生成模型生成的回复有用信息少且多样差的问题,提出了两种主题感知的分层隐变量对话模型(VHCR-T),即带有注意力机制的主题感知模型和带有双主题隐变量的主题感知模型。两种模型通过对主题级别的信息提取特征来感知上下文中包含的主题信息,然后将提取的特征输入解码器以生成包含更多信息的回复。同时,两种模型中使用的句子级别隐变量能增加回复的多样性。实验表明,相较于基准模型,VHCR-T可以有效提升回复的信息量和多样性。2、为进一步提升对话回复的信息量同时保持回复的多样性,提出了一种基于知识和多样句法的对抗对话网络(SDAN)。考虑引入知识图谱中的知识增加回复的信息量,但保持回复多样性所使用的语义隐变量可能会影响知识图谱中知识解码的准确性。因此,为了实现增加多样性和保持知识解码准确性之间的平衡,该网络引入多样的句法信息用于生成句法多样的回复,同时不会影响到知识解码的准确性。此外,SDAN还引入对抗生成网络到语义编码模块,以确保语义编码模块不包含句法信息,从而保持句法的可控性。实验表明,SDAN在保持回复语义不变的基础上,既能保持知识解码的准确性,又能提高回复的多样性。3、针对生成具有共情能力的回复问题,提出了一种多轮情感对话模型(MECM),该模型在分层隐变量模型的基础上增加了一个情感隐变量,用于建模上下文之间的情感传递过程。同时,引入了一个情感分类器,一方面用于增加对话过程中模型的情感识别能力,另一方面用来指导情感隐变量。此外,采用多任务学习的思想,将情感识别和对话生成两个任务同时训练以增加对话生成的效果。实验结果表明,MECM相较于基准模型,既能提高回复的语义相似性,又能极大地提高回复的多样性和情感表达的准确性。4、针对低资源场景下的对话生成问题,提出了一种基于逆课程学习的多源低资源对话生成模型。该模型首先使用复述生成模型、回译模型和预训练对话生成模型生成基于源数据的增强数据,并将源数据与增强数据融合在一起训练。然后,采用了课程学习、逆课程学习和课程学习+逆课程学习三种训练策略对融合后的数据进行训练。最后,用源数据对训练好的模型进行微调。实验结果表明,相较于基准模型,提出的模型在语义一致性和回复多样性方面都得到了显著的提高。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000041
{DOI}: 10.26944/d.cnki.gbfju.2022.000041
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合篇章知识的汉英神经机器翻译研究
{Author}: 苗国义
{Tertiary Author}: 徐金安
{Publisher}: 北京交通大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自然语言处理;篇章神经机器翻译;篇章结构;小句;多任务学习
{Abstract}: 机器翻译是人类打破语言屏障、实现语言互通的关键技术,也是自然语言处理和人工智能领域最重要的研究方向之一,因此,机器翻译研究不仅具有重要的应用价值,也具有重要的理论意义。当前,神经机器翻译在捕捉词与词的语义关联以及句子翻译上取得了长足的进展,已经成为当前主流的机器翻译技术。面向篇章的神经机器翻译在融合篇章上下文信息方面的研究也涌现出很多成果。然而,当前篇章神经机器翻译在建模篇章内句子或小句间的篇章结构关系方面存在着不足,导致翻译模型经常生成连贯性和可读性都较差的篇章译文。尽管研究者们提出了很多利用上下文信息的方法来解决这个问题,但这些方法大多依靠参考大范围序列化的篇章上下文信息获取篇章知识,其建模缺乏针对性,融合篇章知识的方式也较为粗浅,并不能有效地获取深层的篇章结构语义知识。尤其在面对像汉语这种意合型、隐式篇章关系较多的语言时,上述方法在融合篇章结构知识方面的效果较差。因此,在神经机器翻译中探索更为精准有效的篇章结构知识建模和融合机制,对提升篇章译文的连贯性具有重要的意义。本文围绕如何在汉英篇章神经机器翻译中建模和融合篇章结构知识这个中心问题,结合篇章结构分析理论,提出一系列的解决方案。论文的研究方法及成果总结如下:(1)提出了一种融合小句对齐知识的汉英神经机器翻译方法当前神经机器翻译建模篇章结构知识的问题在于:没有明确的基本建模单位,建模缺乏针对性,篇章结构知识的融合方式也较为粗浅。针对此问题,本文提出把小句作为篇章结构的基本建模单位,并深入研究汉英双语基于小句的篇章结构对齐方式,以及将小句对齐的篇章结构知识融入翻译模型的方法。一方面,本文采用人工和自动相结合的标注方法构建了大规模的基于小句对齐的汉英平行语料库,为神经机器翻译模型提供了显式的小句对齐知识;另一方面,本文设计了一种融合小句对齐知识的汉英神经机器翻译模型,该模型通过增强源端基于小句成分的句子语义表示,以及增强源端和目标端的小句对齐学习来有效地融合小句对齐知识。实验结果表明,本文提出的方法可以有效地建模和融合篇章结构知识,提升篇章神经机器翻译模型的性能。(2)提出了两种融合篇章主从结构对齐知识的汉英神经机器翻译方法当前篇章神经机器翻译缺乏在语义层面对篇章主从结构知识的建模和融合,导致模型在面对复杂长句时经常出现源语言和目标语言主从结构转换错误,严重影响到篇章翻译的语义连贯性。由于汉英语言形式上的差异,语义连贯性问题在汉英篇章机器翻译中尤其突出。针对此问题,本文探索在汉英神经机器翻译中对篇章主从结构知识进行建模,并提出两种融合篇章主从结构对齐知识的神经机器翻译方法。具体来讲,本文首先采用人工和自动相结合的标注方法构建了大规模的汉英篇章主从结构平行语料库,为神经机器翻译提供了丰富的篇章主从结构对齐知识。在此基础上,本文进一步提出了:融合篇章主从结构编码的神经机器翻译方法和融合篇章主从结构对齐知识的多编码器神经机器翻译方法,分别从编码策略和模型结构两个方面探索篇章主从结构对齐知识融入神经机器翻译的方法。实验结果表明,本文提出的两种神经机器翻译方法均能有效地建模和融合篇章主从结构对齐知识,进而提升神经机器翻译模型的性能。(3)提出了一种基于多粒度融合和多任务学习的篇章神经机器翻译方法当前篇章神经机器翻译面临的一大挑战是篇章级训练数据稀缺。如何在篇章训练数据匮乏的条件下训练神经机器翻译模型学习篇章结构语义知识是当前机器翻译研究需要解决的问题。针对此问题,本文提出了一种基于多粒度融合和多任务学习的汉英篇章神经机器翻译方法。一方面,在神经机器翻译中引入了基于小句、句子和篇章三种粒度的篇章上下文结构性信息,从多粒度融合的角度学习篇章结构知识。另一方面,在翻译任务中加入句子连贯性检测和句子复原两个篇章连贯性建模的辅助任务,使翻译任务与辅助任务以参数共享的方式进行联合训练,从而通过辅助任务引导翻译模型充分地学习额外的篇章结构翻译知识。两方面结合起来进一步增强了篇章神经机器翻译模型的性能。实验结果表明,本文提出的方法可以帮助模型在数据资源受限的条件下充分地学习篇章结构知识,进而提升了篇章译文的翻译效果。综上所述,本文针对篇章神经机器翻译中篇章结构知识建模和融合方式的不足,在小句对齐知识建模和融合、篇章主从结构对齐知识建模和融合、多粒度融合与多任务学习等方面提出了一系列的解决方法。同时,本文构建的篇章结构平行语料库深化与丰富了面向机器翻译的篇章结构数据资源。实验结果验证了本文所提出的方法可以有效地提高篇章译文的连贯性,提升模型的篇章翻译质量。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.000212
{DOI}: 10.26944/d.cnki.gbfju.2022.000212
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于对象关系建模与注意力机制的视觉问答研究
{Author}: 郭子汉
{Tertiary Author}: 韩德志
{Publisher}: 上海海事大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉问答;计算机视觉;自然语言处理;深度学习;注意力机制;视觉关系推理;情感计算;智能医疗诊断
{Abstract}: 视觉问答是一项涉及计算机视觉、自然语言处理以及知识表示与推理等多个领域的多模态学习任务。在视觉问答系统中,给定一幅图像和一个与图像内容相关的自然语言问题,要求模型能够给出一个准确的自然语言答案。目前,得益于人工智能相关技术和领域的蓬勃发展以及众多科研工作者的不懈努力,视觉问答系统从早期只能勉强地回答答案为“是”或“不是”的是非类问题,发展到现在已经可以正确地回答需要复杂推理和外部常识知识的问题,其取得的成就已经远远地超出了人们的预期。现有的视觉问答模型中存在仅建模对象级视觉表征而忽视了视觉对象之间的关系问题,以及因建模每个图像区域与每个问题单词之间的相互作用而导致模型的注意力被分散问题。并且,在情感视觉问答网络中将问题引导的注意力与情感引导的注意力区分开来十分困难。为此,本文从视觉关系推理、注意力机制以及情感计算三个方面对视觉问答系统进行了研究与讨论,提出了用于视觉问答任务的多模态协同注意关系网络、多模态显式稀疏注意网络、基于阈值的稀疏协同注意视觉问答网络以及双层情感视觉问答网络。基于主流的视觉问答数据集,本文实现了相应的视觉问答系统并通过对比实验和消融研究验证了所提出的模型的有效性和可解释性。最后,本文结合信息管理、迁移学习、视觉问答以及人机交互等先进技术设计并实现了一个智能医疗诊断原型系统。本文的主要研究内容如下:
(1)当前主流的视觉问答模型中存在仅建模对象级视觉表征而忽视了视觉对象之间的关系问题。为了解决这一问题并在视觉问答任务中有效地利用视觉对象的位置信息以及它们之间的相对几何关系,本文提出一种结合协同注意与视觉对象关系推理的多模态协同注意关系网络。多模态协同注意关系网络使用协同注意力机制学习对于正确地回答输入问题更为关键的文本特征和对象级视觉表征,并进一步利用视觉对象关系模块在关系级对视觉表征进行建模。该网络在视觉问答基准数据集VQA 2.0的test-dev集合上达到了 70.83%的整体准确率。基于多模态协同注意关系网络,本文通过堆叠视觉对象关系模块进一步提高了该模型在Number型问题上的精度。受多模态协同注意关系网络的启发,本文还提出两种结合协同注意力机制与视觉对象的相对几何特征的模型RGF-CA和Cos-Sin+CA,分别实现了优异的综合性能和在Other型问题上取得了更高的准确率。该工作验证了协同注意力机制与视觉对象关系建模在视觉问答任务中的协同作用。
(2)针对先进的视觉问答方法因建模每个图像区域与每个问题单词之间的相互作用而导致模型的注意力被分散问题,本文提出一种多模态显式稀疏注意网络。多模态显式稀疏注意网络通过显式地选择输入特征中与预测正确答案最相关的局部特征集中模型的注意力。这种基于top-k选择的方法能够减弱不相关信息带来的干扰并最终帮助视觉问答模型获得更好的性能。该网络在视觉问答基准数据集VQA 2.0的test-dev集合上达到了 70.71%的整体准确率。此外,本文还通过注意力可视化结果证明多模态显式稀疏注意网络相比于其他先进的视觉问答模型能够捕获更好的被关注特征。该工作证明结合稀疏注意力机制的模型同样可以在视觉问答任务中获得具有竞争力的结果。
(3)大多数现有的视觉问答模型在学习输入图像与输入问题之间的协同注意时选择建模每个图像区域与每个问题单词之间的稠密交互。然而,要正确地回答与图像内容相关的自然语言问题通常只需要理解输入问题中的几个关键单词并捕获输入图像中的部分区域所包含的视觉信息。与输入问题不相关的图像区域以及与预测正确答案不相关的问题单词之间的交互所产生的噪声信息会分散视觉问答模型的注意力并对模型的性能产生负面影响。为了解决这一问题,本文提出一种基于阈值的稀疏协同注意视觉问答网络。基于阈值的稀疏协同注意视觉问答网络通过设置注意力分数阈值筛选出对于预测正确答案最有帮助的图像特征和问题特征并最终提高了其模型的整体性能。该网络在视觉问答基准数据集VQA 2.0的test-dev集合上达到了 70.82%的整体准确率。
(4)情感视觉问答网络利用输入图像中包含的情感信息生成带有情感的自然语言答案,该模型在丰富对视觉问答任务的理解和分析的同时保持了与传统视觉问答基线模型相同的精度水平。将图像中包含的情感信息集成至视觉问答系统是一项相当新颖的任务。然而,在该模型中将问题引导的注意力与情感引导的注意力区分开来十分困难。这是因为情感视觉问答网络使用串联的方式连接输入问题单词与输入图像的情感标签。并且,这种类型的串联还会对视觉问答模型的性能产生负面影响。为了解决这一问题,本文提出一种双层情感视觉问答网络。双层情感视觉问答网络将视觉问答中生成带有情感的答案的任务划分为两项相对简单的子任务即生成无情感答案与生成输入图像的情感标签,并使用两个独立的层分别完成这两项子任务。该网络在实验数据集上的整体精度比情感视觉问答网络高出7.6%。此外,本文还在情感视觉问答网络和双层情感视觉问答网络中引入了更先进的词嵌入方法以及更细粒度的图像特征提取器以进一步提高这两种模型的性能。实验结果证明,与情感计算相结合的视觉问答模型与通用视觉问答模型一样可以通过改进这两个模块提高其模型的整体性能。
(5)为了缓解我国医疗资源紧张引发的如医疗纠纷频繁发生和医疗保险难以实施等问题,本文提出一种智能医疗诊断原型系统以提供高效的医疗诊断服务并推动医疗信息整合,从而帮助医务人员提升工作质量与工作效率。智能医疗诊断原型系统基于本文提出的视觉对象关系模块、基于阈值的多头稀疏按比例点积注意以及双层情感视觉问答网络中将复杂任务划分为简单子任务的思想,并利用迁移学习等先进技术收集、处理、分析和理解医疗诊断信息。该系统通过结合其内部经验知识回答医学图像中与医疗诊断相关的自然语言问题。此外,智能医疗诊断原型系统能够从其与外界环境中的医疗诊断信息的交互中累积、完善、学习并更新经验知识以实现自主学习。智能医疗诊断原型系统以自动化方式完成医疗诊断任务,从而使得用户无法直观地感受到该系统的可靠性。因此,本文通过注意力可视化方法证明了该系统的有效性和可解释性。最后,本文指出了智能医疗诊断原型系统的缺点和不足并以此作为未来工作的主要内容与方向。
{URL}: https://link.cnki.net/doi/10.27304/d.cnki.gshhc.2022.000056
{DOI}: 10.27304/d.cnki.gshhc.2022.000056
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于关注机制的图像语义理解方法研究
{Author}: 苏静
{Tertiary Author}: 戴青云
{Publisher}: 广东工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 层级图像分类;视觉叙事;关注机制;CNN-LSTM
{Abstract}: 图像作为人类视觉感知的重要途径,是人工智能时代海量数据的主要来源,因此,如何对海量的图像数据进行智能化理解是当前图像理解领域需要解决的主要问题。近年来,深度学习在图像分类和图像描述等图像理解研究与应用中取得了显著的研究成果,但是,具有复杂语义的图像理解,例如层级图像分类和视觉叙事等任务,仍然存在很大的探索空间。层次图像分类和视觉叙事任务需要对图像本身高层复杂语义进行理解,它们相对于当前流行的图像分类与图像描述任务显得更加复杂、也更具挑战性,有着很强的理论研究与应用价值。层级图像分类问题中,由于层级图像中的类别之间具有严格的层级关系,且精细级类别之间相似度较高,准确识别这些层级类别对计算机仍然是个难点问题。视觉叙事旨在为连续的图像生成连贯的和富有表现力的故事性描述,它不仅需要对复杂场景以及图像之间的关联关系进行识别,更需要对抽象语义进行理解,这给当前计算机图像理解技术提出了更高的挑战。基于以上问题,本文在对深度学习相关理论研究基础上,采用关注机制分别从双关注、局部特征关注-全局语义以及多层级关注这三个方面对于图像理解中的层级图像分类和视觉叙事问题展开了深入研究。论文的主要研究工作如下:(1)提出了一种基于双关注机制的层级图像分类模型。针对现有层级图像分类方法多用于固定层级的识别,本文构建了一种基于CNN-LSTM的通用识别模型DACL(dual-attention CNN-LSTM),引入空间特征维度和空间语义维度的双关注模块,用于同时解决固定和可变层级分类问题。该模型通过空间特征关注机制学习不同类别对应的更具判别性的细粒度特征,并且通过空间语义关注机制对各类别间的相关性进行建模,从而增强模型关键信息的判别能力,有效提升模型的泛化性。本文使用CIFAR10、CIFAR100和外观专利图像数据集对所提方法进行了验证,实验结果表明了所提出的DACL方法在精准度和准确率方面相对其他现有的层级图像分类方法的优越性。(2)提出了一种融合局部特征关注机制和全局上下文语义的视觉叙事方法。本方法采用一种端到端的长短时记忆网络模块并行方法实现视觉叙事,解决了传统的视觉叙事方法采用串行长短时序记忆网络模块,网络参数过多,计算量大,过度耗费网络资源的缺陷。本文在考虑全局上下文语义的条件下结合局部特征关注机制,将序列图像信息作为全局图像特征,通过多层感知器学习序列图像的故事主题信息,同时将单张图像信息作为局部特征并引入关注机制,得到文本对应的特征关注图,分别实现对图像与图像间、图像与文本间依赖关系的构建。本方法有效解决了传统长短时记忆网络模块方法中因序列图像分开输入,只关注单图像与文本之间的关系,忽略了序列图像间关联关系存在的不足。本文的方法在两个公用图像数据集(DII和SIS)上进行了实验,实验结果显示本文的模型取得了良好的效果。(3)提出了一种基于层级关注机制的视觉叙事生成算法。本文利用BERT模型丰富的语义提取能力,构建了句子级和词语级两层长短时记忆网络模型,并引入句级与词级关注机制实现序列图像的故事性描述。该模型在底层首先对句级语义进行建模,关注每个图像与对应句子语义间的映射关系同时也关注图像与图像、句子与句子间的关联关系,负责提取每个图像的高层主题信息,再在第二层基于该主题对词级语义进行建模,重点关注每个图像与该句文本中的每个单词的映射关系,负责学习每个单词对应的图像特征信息。本方法能够有效改进传统视觉叙事方法生成的句子语法问题多,表达方式过于简单的缺点。实验结果表明,在自动评估指标BLEU和CIDEr下,本文的模型优于大多数方法,同时,本文的方法在人类评估中的各项指标中表现良好。综上所述,本文基于关注机制的图像理解中的若干关键问题,结合最新深度学习理论方法展开研究,其内容是计算机视觉与自然语言处理交叉学科的创新研究,对解决现实中的应用问题有着十分重要的研究意义。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000055
{DOI}: 10.27029/d.cnki.ggdgu.2022.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向序列数据特征学习的深度动态生成模型构建方法研究
{Author}: 鲁瑞颖
{Tertiary Author}: 陈渤
{Publisher}: 西安电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 序列模型;深度学习;循环神经网络;注意力机制;图模型;Transformer
{Abstract}: 第三次科技革命以来,人类社会步入了信息爆炸、数据海量增长的多源大数据时代。在人类社会生活中存在海量的按一定次序关系排列的序列数据,如文本数据,语音、图像、视频、基因序列等等,而如何对高维复杂序列数据的序列关系进行分析并有效利用,引起了研究学者的广泛关注。基于深度动态模型的序列建模方法,通常以数据为驱动,对数据的统计特征及其它相关特征进行有效提取,并根据历史观测数据建立对未来数据进行建模与预测。在现实应用中,对序列数据的建模通常面临样本复杂、监督信息难获取、时序长程依赖难挖掘、序列信息推理速度慢等问题与挑战。针对这些问题与挑战,本文面向复杂序列信号深入研究了特征提取方法与生成建模问题,聚焦动态生成建模,立足于高光谱图像重建、单曝光压缩视频重构、文本生成、跨模态图像文本标注等任务。本论文针对不同类型的序列数据研究如何提取其中隐含的动态特征,探索不同序列模型如何在实际应用中进行动态生成建模,并利用专家知识例如高层语义先验信息、目标类别信息、动态变化信息等进行动态建模指导。本文的主要工作总结如下:1.循环神经网络是一种应用广泛的序列模型,在处理高维复杂信号时面临着梯度消失,记忆遗忘等问题,本论文探索了循环神经网络针对复杂序列信号如何进行有效序列建模。高光谱像元的光谱是一种高维且特征混合复杂的序列数据,如何合理构建循环机制对光谱信号进行特征提取和生成建模具有一定的挑战性。本论文针对高光谱数据的序列特性,设计变分概率分层循环神经网络对光谱信号进行序列特征提取,将高分辨的空间特征与高分辨的光谱特征进行融合,在无监督的方式下生成高分辨的高光谱图像。此外,本论文在单曝光压缩视频的重构过程中也探索了序列特征对视频图像生成的影响,基于循环机制逐帧生成视频中的各帧图像,同时引入相邻两帧之间的动态变化信息指导视频动态生成。2.考虑到上述循环神经网络对所有样本均利用同一组参数刻画序列关系,然而对于一些复杂分布的样本集上这种无差别地建模是需要改进的。本论文提出了一种变分框架下的基于非参贝叶斯混合模型的专家循环神经网络,对样本的复杂分布进行分析建模,并根据样本特异性选取相应的专家模型对序列数据进行特征建模。同时,样本间的异构性可以作为一种可学习的先验知识引入所学特征隐空间,能够与变分框架下的概率隐空间设计相耦合。在高光谱图像融合场景中,由于不同的光和大气条件以及物质混合等引起的空间变化,高光谱图像的像元光谱变化复杂。本论文所提出的基于非参贝叶斯混合模型的专家循环神经网络,能够对高光谱像元样本中复杂的异构性高光谱特征进行建模,从而通过不同的专家模型进行生成不同的高光谱像元。3.面对长序列信号,循环神经网络在实际应用中显露出了一些弊端,例如记忆时间短,难以利用长距离特征信号,串行处理阻碍了训练样本间的并行化,处理速度慢等问题。基于注意力(attention)机制的Transformer模型能够捕获长距离特征联系,同时可以并行训练与处理。注意力(attention)机制通过直接对时间序列中任意两个时间点信号之间的关系进行建模并学习相应的特征表示,而无需考虑它们在序列中的距离。Transformer模型完全依赖于注意力机制对各时间点信号的全局依赖关系进行建模,突破了循环神经网络模型无法并行计算且记忆遗忘的限制,但其注意力局限在局部输入范围内而丢失了上下文信息,且忽略了语义层面上的一致性。相反,深度概率主题模型能够针对文档内部的语义主题统一性,学习得到层次化的语义主题信息。因此,本论文设计了三种主题学习方法将上下文的语义信息用以指导语言模型进行文本生成,最终使得Transformer能够生成指定语义的文本。另外,我们在跨模态图像文本任务上,设计了跨模态主题学习模型,利用所学多层主题语义信息帮助语言模型生成图像的描述,并设计了对应的快速推理方法学习跨模态语义信息。4.Transformer模型有一个显而易见的缺点是模型计算资源消耗会随着输入长度呈指数增长。在面对长序列建模时,有限的计算资源会限制模型的输入长度并影响性能。如何在学习多个特征之间的关系的同时能够控制相应的计算消耗是有待解决的一个关键问题。针对计算资源限制对时序长程依赖建模的桎梏,本论文引入了图注意力模型的思想,构造了一个动态图模型对视频序列数据进行建模,不仅能够捕获帧与帧之间的长时依赖关系,同时可以控制计算消耗,最终自适应地寻找每个特征的相关性来更新图网络中每个节点的隐表示。本论文将动态图模型应用于单曝光视频压缩重构任务上,并在图注意力机制中引入动态稀疏性,利用视频光流信息帮助网络学习视频帧与帧之间的空时动态关系。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.000054
{DOI}: 10.27389/d.cnki.gxadu.2022.000054
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于提示学习的少样本文本分类研究与应用
{Author}: 魏志宇
{Tertiary Author}: 李睿凡
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 预训练语言模型;少样本学习;提示学习;文本分类
{Abstract}: 近年来,基于深度学习的方法在诸多自然语言处理任务上取得了令人骄傲的成绩。然而,深度模型通常需要大量高质量的标注语料,以达到对网络中大规模参数的不断调优的目的。目前的数据标注工作更多依赖于人工方式,这使得想获取大量优质的标注数据依旧十分困难。文本分类任务作为NLP领域最常见的任务类型之一,对每个新的领域任务都去标注大规模的数据通常是不现实的。少样本学习旨在利用已学习的先验知识,通过有限的带有标注的训练数据,就可以快速的在目标任务上完成模型的优化。通过少样本学习,既可以降低有标注数据的获取成本,又可以加速模型的落地部署和缩短迭代周期。随着BERT等预训练语言模型的提出,基于预训练和微调的两阶段训练范式逐渐成为新的趋势,并在多数的自然语言处理任务上取得了空前的成功。但是在微调阶段,模型的性能通常取决于任务和有标注训练数据的数量。然而在大多数情况下,通常难以获取大量相关领域的标注数据,这使得当模型在面对仅含少量训练样本的下游任务时,往往表现不佳。与微调方法不同的是,基于提示学习的方法,通过添加灵活的提示信息,将具体下游任务与预训练任务在形式上相统一,使得在低资源场景下也能够取得良好的效果。提示学习的优势在于既不需要大量相关领域的数据进行提前训练,也无需显著的改变预训练语言模型结构和参数,仅通过对任务形式和输入形式的改变,就可以达到利用预训练语言模型中已经获得的通用领域知识的目的,实现真正的少样本学习。本文针对文本分类任务,对基于提示学习的方法进行少样本学习研究,开展如下工作:1)当前基于提示学习的少样本文本分类方法仅利用了预训练语言模型中的通用知识,而忽略了下游任务中的具体类别表征表示。本文提出了一种基于提示学习和三元组损失的少样本文本分类算法。该算法将文本分类任务转换成基于自然语言推理的提示学习形式,通过任务形式的转换,实现在利用预训练语言模型的先验知识的基础上,达到隐式的数据增强,并通过两种不同粒度的损失进行优化。并且,为了捕获下游任务中丰富的类别表征信息,通过三元组损失进行联合优化,同时引入掩码语言模型任务作为正则项,提升模型的泛化能力。此外,本文又在所提出方法的基础上设计了合适的预训练任务进行进一步地预训练。最终在中、英文数据集中验证了本文提出方法的有效性。2)设计并实现了基于少样本学习的文本分类任务智能标注工具。在本系统中,保留了传统标注工具中通过自定义快捷操作方式进行的人工标注形式,便于用户灵活标注。同时基于上述的算法研究成果,用户仅需提供少量的标注数据,通过简单地参数配置,就可以完成模型的在线训练以及对数据的智能标注工作。此外,用户可通过智能标注结果的反馈,更新训练数据,即通过主动学习策略,持续提升模型的性能和数据标注质量。最后通过一系列的系统测试,表明本系统功能满足设计需求,可稳定运行。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.002959
{DOI}: 10.26969/d.cnki.gbydu.2022.002959
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 本地生活O2O平台在线评论有用性的影响因素研究
{Author}: 王宗狄
{Tertiary Author}: 王林
{Publisher}: 重庆大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 本地生活O2O平台;在线评论;评论有用性;产品类型
{Abstract}: 在线评论为消费者的购买决策提供了重要的参考信息,但在线评论的数量激增导致了严重的信息过载问题,增加了消费者寻找有用在线评论的负担。为解决这个问题,众多学者对在线评论有用性的影响因素展开了研究,但大多数研究都以亚马逊、淘宝等网购平台的在线评论为研究对象,缺少对本地生活O2O平台在线评论有用性的影响因素探究。基于此,围绕“在本地生活O2O平台上,什么样的在线评论对消费者来说更有用?”这一核心问题,研究本地生活O2O平台在线评论有用性的影响因素以及这些因素的影响效应。首先,从信息采纳模型中的信息质量和信息源可靠性两个维度以及本地生活O2O平台的特点,识别出5个与评论内容特征(评论深度、评论情感极端性、评论情感负向性、评论情感不一致性、评论时效)和2个与评论者特征(评论者专业程度、评论者可信度)相关的影响因素,并且从产品是否具备网红属性的视角将产品类型划分为网红产品和非网红产品,将其作为调节变量;其次,结合相关理论基础、前人的研究结论和本地生活O2O平台在线评论的实践情境,提出14个各影响因素与评论有用性之间关系的研究假设,并建立研究假设模型;再次,以Python爬虫技术获取的大众点评网站15,533条有效剧本杀在线评论为样本,通过文本相似度计算和文本情感分类等自然语言处理方法对评论文本进行处理;最后,通过SPSS软件进行多元回归分析,对研究假设进行实证检验,共验证7个研究假设,具体结论如下:1)评论内容特征对本地生活O2O平台在线评论有用性的影响:评论深度、评论情感极端性和评论情感负向性对本地生活O2O平台在线评论有用性有着显著的正向影响;评论情感不一致性对本地生活O2O平台在线评论有用性有着显著的负向影响;而评论时效对本地生活O2O平台在线评论有用性的影响需要进一步检验。2)评论者特征对本地生活O2O平台在线评论有用性的影响:评论者专业程度对本地生活O2O平台在线评论有用性有着显著的正向影响;而评论者可信度对本地生活O2O平台在线评论有用性的影响需要进一步检验。3)网红产品/非网红产品的调节效应:与非网红产品相比,评论深度和评论情感极端性对本地生活O2O平台在线评论有用性的影响在网红产品中的作用更加明显。而网红产品和非网红产品对评论情感负向性、评论情感不一致性、评论时效、评论者专业程度和评论者可信度与本地生活O2O平台在线评论有用性之间关系的调节效应还需进一步检验。研究成果补充了关于本地生活O2O平台在线评论有用性影响因素的相关研究空白,同时也为本地生活O2O平台及其商家对在线评论进行有效管理提供了建议。
{URL}: https://link.cnki.net/doi/10.27670/d.cnki.gcqdu.2022.001936
{DOI}: 10.27670/d.cnki.gcqdu.2022.001936
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 施氮水平对不同氮效率水稻品种氮代谢及产量的影响
{Author}: 赵佳鹏
{Tertiary Author}: 赵宏伟;孙世臣
{Publisher}: 东北农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 水稻;氮效率;施氮水平;氮代谢;产量
{Abstract}: 氮素作为水稻生长所需的重要营养元素,对水稻生长发育具有重要影响,直接影响水稻氮代谢和产量,确定适宜的施氮水平,可以为水稻高产栽培提供理论依据。关于不同施氮水平对水稻氮代谢和产量影响的报道较多,但以不同氮效率寒地粳稻品种为试验材料开展该方面研究的报道较少,因此,探究施氮水平对寒地粳稻氮代谢和产量的影响具有重要意义。试验于2021年在东北农业大学校内实验实习基地进行,以农丰1705(氮低效品种)和松粳21(氮高效品种)为试验材料,设置5个氮肥施用水平,每公顷施用纯氮分别为0、75、150、225、300kg,分别记为N0、N1、N2、N3、N4,研究氮肥施用水平对不同氮效率水稻品种氮素积累、分配、转运,根系、功能叶片及籽粒氮代谢关键酶活性,根系伤流强度、伤流液中氨基酸总量,籽粒蛋白质及蛋白组分,产量以及氮肥利用率的影响,明确最适施氮水平,为黑龙江省水稻氮肥高效利用及高产栽培技术体系的建立提供理论依据及技术支撑。本研究主要结果如下:(1)不同施氮水平条件下,两品种植株氮素积累量、各器官氮素分配比例、氮素输出量、输出率、转运贡献率和稻谷生产效率均存在差异。随施氮水平的提高,两品种植株氮素积累量显著增加,茎鞘和叶片氮素分配比例显著升高,分蘖期至乳熟期根系氮素分配比例显著降低,蜡熟期和完熟期显著升高,穗部氮素分配比例显著降低;氮高效品种植株氮素积累量显著大于氮低效品种,根系、穗部和分蘖期至乳熟期茎鞘氮素分配比例也显著高于氮低效品种,但叶片和蜡熟期至完熟期茎鞘氮素分配比例显著低于氮低效品种。两品种氮素输出量随施氮水平提高而显著增加,氮素输出率和转运贡献率随施氮水平的提高先增加后降低,在N3处达到最大值。两品种稻谷生产效率随施氮水平提高而显著降低,且氮高效品种的氮素输出量、氮素输出率、转运贡献率和稻谷生产率均高于氮低效品种。(2)不同施氮水平处理对两品种根系、功能叶片和籽粒氮代谢关键酶活性影响显著。施氮水平的提高有利于不同氮效率水稻品种根系、功能叶片和籽粒的氮代谢关键酶NR(硝酸还原酶)、GS(谷氨酰胺合成酶)、GOGAT(谷氨酸合成酶)、GOT(谷氨酸-草酰乙酸转氨酶)、GPT(谷氨酸-丙酮酸转氨酶)活性的提高,但当施氮水平超过N3时NR、GS和GOGAT活性增加幅度显著降低,GOT和GPT活性降低。氮高效品种的氮代谢关键酶活性显著高于氮低效品种。(3)不同施氮水平对两品种根系伤流强度和伤流液氨基酸总量影响显著。施氮水平的提高会造成不同氮效率水稻品种根系伤流强度和伤流液氨基酸总量的先升后降,峰值出现在N2或N3,且氮高效品种根系伤流强度和伤流液氨基酸总量均显著高于氮低效品种。相关分析表明根系伤流强度和伤流液氨基酸总量与产量间存在显著正相关,因此,N3施氮水平可以更好维持水稻植株体内氮代谢水平。(4)不同施氮水平对两品种籽粒蛋白质总量、醇溶蛋白含量及氮低效品种清蛋白含量影响显著,对氮高效品种清蛋白含量及两品种球蛋白和谷蛋白含量影响不显著。施氮水平的提高会促进籽粒蛋白质总量和各组分蛋白含量的升高,完熟期氮高效品种籽粒蛋白质总量、清蛋白含量显著高于氮低效品种,完熟期N3和N4处理条件下氮高效品种籽粒醇溶蛋白含量显著高于氮低效品种,N0、N1和N2处理条件下二者醇溶蛋白含量差异不显著。球蛋白和谷蛋白含量两品种间无显著差异。(5)不同施氮水平对两品种氮肥农学利用率、氮肥偏因素生产力、氮肥生理利用率、氮肥吸收利用率、氮素收获指数和产量影响显著。施氮水平的提高会造成不同氮效率水稻品种氮肥农学利用率、氮肥偏因素生产力、氮肥生理利用率和氮素收获指数显著降低。氮肥吸收利用率随施氮水平的提高先增加后降低,氮低效品种在N2处理条件下达到最大值,氮高效品种在N3处理条件下达到最大值。两品种产量随施氮水平的提高先升高后降低,均在N3处理条件下达到最大值。同时发现,相同施氮水平条件下,氮高效品种的氮肥农学利用率、氮肥偏因素生产力和产量均显著高于氮低效品种。N1和N2处理条件下氮高效品种的氮肥生理利用率及N0和N1处理条件下氮素收获指数显著高于氮低效品种,其他处理条件下氮低效品种高于氮高效品种。N1和N2处理条件下氮低效品种的氮肥吸收利用率显著高于氮高效品种,N3和N4处理条件下,氮高效品种显著高于氮低效品种。
{URL}: https://link.cnki.net/doi/10.27010/d.cnki.gdbnu.2022.000433
{DOI}: 10.27010/d.cnki.gdbnu.2022.000433
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自注意力长短期记忆网络的日志异常检测关键技术研究
{Author}: 耿非凡
{Tertiary Author}: 崔艳鹏;沈震
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 异常检测;日志解析;语义嵌入;词权重分布矩阵;LSTM;自注意力机制
{Abstract}: 日志作为记录系统实时运行状态和程序执行状况的数据,既是软件开发人员和运维人员监测系统运行状态重要资源,也是实现系统异常检测的绝佳数据源之一。当下基于深度学习的日志异常检测已经成为自动化系统异常检测研究领域的重点关注内容之一,但仍存在以下难题亟需解决:日志文本数据其中所包含的信息和特征很难直接作为输入被深度学习模型所学习,需要构建特定的日志解析方法;传统的日志异常检测模型仅适合特定系统,忽略了日志所特有的时序特征与统计特征,使得日志前后事件之间的上下文信息难以被捕获进而导致检测能力的不足。
本文在现有的日志异常检测流程基础上,以优化和改善现有日志异常检测方法为核心目的,针对日志解析模块中存在的结构化解析精度不高的问题,以及传统异常检测方法忽略了日志的普遍特征而导致的仅能处理特定系统的问题进行了深入研究,并提出了相应的改进优化方案。全文完成了以下三个方面的工作。
1.日志数据的采集和分析是整个日志异常检测流程的基础。本文首先针对日志数据存储位置不确定而导致的日志采集困难的问题,分别设计了集中式和分布式两种不同的日志采集方案以应对不同系统部署环境下的日志采集需求。随后针对日志格式不统一而难以构建特征用于解析和检测的问题,对不同系统产生的日志的结构进行了分析,通过将日志拆解为不同的关键字段,并结合日志的产生模式,归纳总结出日志的语义分布、领域依赖、同源同构以及时序和统计等特征用于日志的解析和异常检测。
2.日志消息的结构化解析是准确检测的前提。本文针对传统日志模板提取解析方法存在的语义忽略问题和日志向量化解析方法存在的易受噪声干扰的问题,提出了一种基于语义嵌入的日志向量化解析方法。该方法借助词嵌入与语义嵌入方法实现日志中词的向量化表示,并以日志的语义分布特征为基础,设计了日志词权重分布矩阵用于凸显不同日志词在日志消息中的语义影响,实现了日志消息的向量表示。并依照日志的同源同构特征设计了基于密度空间的日志向量聚类算法,以提取不同日志事件的向量模板,从而实现对日志消息的解析。实验结果显示,本文提出的方法在五种真实系统环境下产生的日志数据集上的解析准确率均达到了94%以上,具有比较优秀的解析准确性和稳定性。也经过实验验证,以该解析方法对日志进行结构化表示能够在一定程度上提高现有异常检测模型的检测准确性。
3.针对传统异常检测模型忽略了日志的普遍特征而导致的仅能处理特定系统的问题,本文设计了一种基于长短期记忆网络的日志异常检测模型。该模型通过学习日志序列中特有的时序模式和统计模式,利用日志序列的事件前后依赖关系对下一时刻的日志事件进行预测,并基于预测结果判断系统是否存在异常。除此之外,模型还通过引入自注意力机制,将模型计算的并行度从O(1)提升到了O(n),最长路径依赖从O(n)优化至O(1),提高了模型对长序列的时间依赖性。随后通过实验在HDFS系统在实际运行过程中产生的日志数据集上对该模型进行了测试,并与Deeplog在内的另外四种传统的日志异常检测模型的检测结果进行对比。实验结果显示,基于自注意力长短期记忆网络的日志异常检测模型在保持检测准确率的同时,降低了误报率和漏报率,达到了97%的F1-measure分数,是所有模型中的最高得分。这证明了本方案相比于已有的日志异常检测模型,具有一定的性能提升,从而验证了本文所提出方案的有效性。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.002378
{DOI}: 10.27389/d.cnki.gxadu.2022.002378
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的工业领域问答系统研究与实现
{Author}: 曲芮莹
{Tertiary Author}: 杨清海
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;问答系统;问句分类;命名实体识别;深度学习
{Abstract}: 在工业智能化改革浪潮中,各类企业逐渐向数字化转型,利用热门的人工智能技术和互联网上规模庞大的数据为相关企业和人员提供工业信息查询服务成为企业发展的必然要求。然而现阶段工业领域智能查询系统尚不成熟,许多技术性问题亟待解决。本文研究的基于知识图谱的工业领域问答系统是智能制造中的重要一环,极大地方便了企业进行数据存储、技术查询和内部管理,为企业科学决策、高效运转提供技术支撑。
问答系统的构建涉及知识图谱、意图识别、命名实体识别(Named Entity Recognition,NER)和数据库检索等多种自然语言处理技术。本文立足于项目需求,深入研究基于深度学习的问句分类模型和实体识别模型,同时搭建一个高质量工业知识图谱为问答系统提供全面、科学的知识来源,以此为基础构建工业领域问答系统。本文主要贡献如下:
为准确识别用户意图,本文提出了基于数据增强的混合神经网络问句分类模型,即DA-MCNN-ABi GRU模型,并构建工业问句数据集进行验证。该模型首先使用数据增强模块对样本进行扩展,并引入Word2Vec向量表示模型;其次引入卷积神经网络(Convolutional Neural Network,CNN)、双向门控循环单元(Bidirectional Gated Recurrent Unit,Bi GRU)和注意力机制,同时获取问句局部特征和全局语义特征;最后将两种特征分别输入softmax分类器,通过算数平均的方式得到分类结果。与基准模型相比,DA-MCNN-ABi GRU具有更好的工业问句分类效果和鲁棒性。
为准确识别问句中的工业实体,本文提出了基于多粒度特征融合的NER模型,即MFF-Bi LSTM-CRF模型,并构建工业实体语料验证模型性能。该模型通过多粒度卷积层和双向长短期记忆(Bidirectional Long Short-Term Memory,Bi LSTM)网络相结合的方式提取问句特征,并使用条件随机场(Conditional Random Field,CRF)自动学习并添加全局约束信息,具有较好的工业实体识别效果。
基于上述两个模型,设计并实现基于知识图谱的工业领域问答系统,系统核心功能模块包括:数据收集模块、知识图谱模块、问答逻辑模块和展示模块。数据收集模块利用企业数据和互联网数据,保证数据实用性和多样性;知识图谱模块根据业务场景设计标签类型,使用Neo4j图数据库进行存储;问答逻辑模块结合上述两个模型完成意图识别、实体识别、实体链接、模板匹配等关键任务,并在知识图谱中进行查询;展示模块将答案进行整理并反馈给用户。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.001300
{DOI}: 10.27389/d.cnki.gxadu.2022.001300
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向铁路语音购票场景的智能语音交互关键技术研究
{Author}: 王心雨
{Tertiary Author}: 单杏花
{Publisher}: 中国铁道科学研究院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 语音购票;智能语音交互;语音识别;编码-解码结构;多机制融合;任务型多轮对话;自然语言处理
{Abstract}: 铁路12306手机客户端应用仅支持手动购票,操作流程较长,包含信息较多,需要自行筛选,不利于老年人群体使用。智能语音交互操作便捷,成为实现人与机器使用语言通信的纽带。因此,对铁路12306手机客户端应用进行适老化改造的方式之一,是利用智能语音交互技术,在手机应用上增加语音购票的功能,更好地解决老年人群体独自使用智能手机购票困难的问题。目前语音识别技术已经达到较高水平,但通常建立在实验环境基础之上,在面向应用实现落地时,存在无法准确识别特定领域专有名词的问题。自然语言处理技术的局限性在于预测未来事件的能力有限,因而在交互式对话系统中,机器难以像人类一样做出反应。本文针对铁路语音购票应用场景,结合语音识别技术与自然语言处理技术,研究面向铁路语音购票场景的智能语音交互关键技术。本文的主要研究内容和贡献包括以下两大方面。(1)设计实现基于编码-解码神经网络的语音识别模型。铁路语音购票的要求主要体现为需要准确且快速地识别用户的输入语音,结合上述需求,本文提出基于编码-解码神经网络的语音识别模型。针对准确识别问题,提出多重语言模型融合与热词赋权的解决方案,提高铁路专有名词的识别准确率,优化语音识别模型识别性能。针对快速识别问题,提出流式与非流式识别并行的解决方案,对Conformer编码结构进行流式改进,设计基于连接时序分类的流式解码和基于注意力机制的非流式解码,提高模型的识别速度。实验表明,本文提出的基于编码-解码神经网络的语音识别模型在识别准确率上比基线模型提升2.126%,将其部署到实际应用中同样取得良好表现。(2)设计实现基于规则匹配与RASA的任务型多轮对话系统。铁路语音购票是一个不断收集用户提供信息并做出相应反馈的过程,为准确抽取信息及灵活做出反馈,本文设计基于规则匹配与RASA的任务型多轮对话系统。针对购票信息抽取问题,提出基于规则匹配的对话系统的解决方案,提高时间、地点、车次等购票信息的抽取准确率。针对多轮对话的灵活性问题,提出基于RASA的多轮对话系统的解决方案,沿用RASA对话系统的流水线结构,在结构中引入基于结巴分词的分词模型、基于Bert-BiLSTM-CRF的命名实体识别模型和基于BiGRUCRF的意图识别模型,降低铁路专有名词被错误切分的概率,实现用户购票意图的准确定位和购票关键信息的准确抽取。实验表明,以上3个模型的F1值分别达到91.48%、92.64%、92.49%,并在实际应用中表现出良好的性能。综上所述,本文根据铁路购票的流程以及语音购票的特点,研究设计适用于铁路语音购票场景的基于编码-解码神经网络的语音识别模型和基于规则匹配与RASA的任务型多轮对话系统,解决机器识别和听懂用户需求的问题,完成面向铁路语音购票场景的智能语音交互关键技术研究。
{URL}: https://link.cnki.net/doi/10.27369/d.cnki.gtdky.2022.000061
{DOI}: 10.27369/d.cnki.gtdky.2022.000061
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的端到端任务型对话系统研究
{Author}: 王路宝
{Tertiary Author}: 王俊华;王聪
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 任务型对话系统;预训练词向量模型;多轮对话技术;卷积神经网络
{Abstract}: 近年来,任务型对话系统在工业界得到了广泛的使用,智能设备可以有效地搭载一个甚至多个对话平台。同时,元宇宙(Metaverse)作为虚拟现实的新型数字空间,无疑会增加人机对话的使用场景和使用频率。但是,人机对话领域仍然面对众多挑战,譬如模型优化方式、数据集不充分问题、对话响应准确率问题等等。在对话模型构建方式上,管道的方法需对各个模块的功能进行单独设计,实现起来比较复杂。随着对话数据量的增加,端到端的任务型对话系统依赖神经网络的特性,可以通过大量的数据训练捕获完整的对话信息。本文通过对端到端的任务型对话系统开展研究,大多数模型在对话编码和解码阶段对于数据集信息的使用存在不充分的问题。于是,针对这一问题,本文在多个公开数据集上进行了大量实验,基于多级记忆网络和Mem2Seq网络开展研究,提出了新的模型优化思路并进行实现与评估。本文的贡献主要有:(1)基于多级记忆网络和Mem2Seq网络结构,对其在端到端任务型对话模型中的使用进行分析,针对编码和解码阶段中对于不同来源的数据使用进行优化,对其底层结构进行微调,并进行在公开数据集In Car、Cam Rest和DSCT2数据集上进行实验,验证和评估我们的模型,最终实现较好的效果。(2)通过对词向量技术进行研究,基于Bert模型的预训练词向量,分析词向量内部的相关性,使用主成分分析算法进行优化。对优化结果的词向量进行分析,并将其作为端到端的任务型对话系统模型的输入映射表,最后我们的模型表现较Glove词向量有比较好的提升。(3)通过使用web开发技术,将端到端的任务型对话模型嵌入对话平台中,进行整体的架构设计并使用相关技术进行对话数据走向的控制。对实现的对话平台进行全面的测试,验证我们的设计思路以及对话平台的功能。整体上,本文对端到端的任务型对话系统的模型研究以及落地实现技术进行了全面的研究,对人机对话领域有较好的借鉴意义。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000447
{DOI}: 10.27805/d.cnki.gccgy.2022.000447
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的新闻自动摘要技术研究
{Author}: 许文军
{Tertiary Author}: 郑虹;王聪
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本摘要;seq2seq;Transformer;深度学习;ALBERT
{Abstract}: 目前,随着网络科技的日益蓬勃发展,大数据信息化时代也必将到来。尤其是文本信息的指数型增长,各种各样的新闻文本更是给人们的阅读带来了巨大的挑战。再加上越来越多的标题党新闻,因此,如何从海量的新闻中获取对读者有价值的信息越来越重要。文本自动摘要技术是一种可以从新闻文本集合中产生简洁而重要的信息的方法,已成为国内外的研究热点。根据组成句子中是否只存在原文中的短语或者词组,文本自动摘要技术可分为抽取式自动摘要和生成式自动摘要。抽取式自动摘要利用原文中的词语对句子结构进行重组,形成新的句子,且具有更简洁、更有效的概括等特点。与抽取式自动摘要相比,生成式自动摘要的组成部分不需全部来自于原文本,会产生新的词和短语,正是由于生成式自动摘要具有更加多维的表达方式,才使其更具多样性、灵活性等特点。近年来,人工智能在计算机领域的广泛应用,尤其是深度学习的神经网络模型不断应用于文本生成领域。生成式自动摘领域取得了突破性的进展,目前主流的生成式自动摘要技术采用的是序列到序列的深度学习框架,通过该框架将文档表示为向量,然后通过解码器将编码器产生的向量解码,最终形成符合要求的文本摘要。本文提出了一种基于预训练模型的序列到序列的生成式文本摘要模型,首先编码器对输入序列进行编码,转化为带有上下文特征的向量表示,然后再通过解码器的两个阶段的解码形成摘要。对于模型的编码器端,使用ALBERT将输入序列转化为上下文表示形式。在解码器端,第一阶段首先使用一个多层堆叠的多头注意力机制的解码器生成一个草稿序列。第二阶段将草稿序列并输入ALBERT中并使用mask机制,进一步转化为上下文表示形式,然后继续使用一个多层堆叠的多头注意力机制的解码器与通过编码器转化的上下文表示相结合,最终形成摘要输出。并在ROUGE评测方法和人工评测方法上评估了此模型,本文模型生成的摘要具有语言流畅性高的优点,有效解决了语句重复,信息冗余等问题。实验结果表明,此模型在LCSTS数据集和Gigaword数据集上都取得了很好的效果。此外,本文设计并实现了一个新闻文本摘要系统。概述了摘要系统的整体架构,系统整体结构包括展示层和数据层,将展示层的输入输出与数据层的文本预处理模块和摘要算法模块集成,最终实现了文档摘要可操控的前端展示界面,并通过实例测试验证了文本摘要系统可以生成高质量的文本自动摘要。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000356
{DOI}: 10.27805/d.cnki.gccgy.2022.000356
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的微博谣言识别系统的设计与实现
{Author}: 王蓉
{Tertiary Author}: 刘忠宝;周国奇
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 谣言识别;微博;深度学习;融合模型
{Abstract}: 近年来,随着互联网技术的快速发展,社交平台上的信息量爆增,给人们的生活带来了很大的变化。与此同时,也伴随着大量的谣言。谣言一旦散播开来,那么造成的危害是难以估计的,它的散播速度和广度都是相当惊人的。那么如何高效地识别谣言且尽可能地减小其造成的危害,无疑已经成为一个亟待解决的难题。鉴于此,社会各界及政府部门都采取了不同的措施,力求通过相关技术来及时、准确地识别出谣言,进而维护社会的公平和正常秩序。作为自然语言处理中的一项重要的文本分类任务,谣言识别的意义毋庸置疑,它是不可忽略的一部分。而目前的谣言识别方法主要还是依靠人工判断,此方法既耗时耗力又效率低下,所以引起了许多研究者的关注,人们力求通过各种机器学习或深度学习模型来更高效地识别谣言。而在众多社交平台中,微博因其独特的优势成为了当今主流的舆论传播媒介,因此本文选择将微博作为进行谣言识别的平台。经过对一系列文本分类方法的研究,本文提出了一种融合深度学习模型的谣言识别方法,并证明了其高效性,进而建立了微博谣言识别系统。(1)本文在对现有的辟谣平台进行调研的基础上,提出一种深度学习融合模型,采用目前效果较好的Ro BERTa模型作为自然语言预训练模型,将微博文本转化为向量表征。采用三种大小不同的文本卷积核来学习微博文本的特征,并将这些特征最大池化拼接操作后得到对应的特征序列,然后输入到Bi-LSTM层进一步学习该序列特征,最后增加注意力机制来计算注意力分布概率,从而达到谣言识别的目的。在两种公开的微博数据集上的实验结果证明,与其它方法相比,本文所提方法对谣言的识别性能方面有了显著的提升,可以挖掘出微博文本的深层特征。(2)在实验中验证了该深度学习融合模型的有效性之后,本文设计了一个基于此模型的微博谣言识别系统,用训练好的深度学习融合模型对微博信息进行判别,并将结果展示给用户,供用户进一步分析或使用。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.001293
{DOI}: 10.27470/d.cnki.ghbgc.2022.001293
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 作文自动评分模型的研究与实现
{Author}: 周险兵
{Tertiary Author}: 杨勇
{Publisher}: 新疆师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 作文自动评分;多层次语义;异构网络;语义偏差;自然语言处理
{Abstract}: 作文自动评分技术能够自动地对作文进行分析和评分,其已成为自然语言处理技术在教育领域应用的热点研究问题之一。自1966年提出以来,作文自动评分技术已成功地应用于美国教育考试服务中心、中国大学生英语等级考试等大型作文考试中,对作文评分起到了较好的辅助作用。作文自动评分不仅节约了人力物力成本,同时还大幅提高了作文评分的公平性和准确性。相比于传统的机器学习方法,基于深度学习的神经网络方法在作文评分任务中取得了较好的性能。但是,作文评分是一项复杂的人类行为,需要从不同层面对作文进行综合的评价,如作文主题、用词、修辞等都对作文的得分产生影响,因此单一神经网络模型的性能往往并不理想。其次,深层次的神经网络模型,其参数数量较多,在模型训练过程中需要更多的计算资源。另外,虽然预训练词向量在许多任务中取得了较好的表现,但是在作文自动评分中性能并不理想。针对上述问题,本文首先研究深层次和浅层语义特征对作文评分的性能影响;其次,研究了一种端到端的轻量级作文自动评分模型;再次,对预训练词向量带来的语义偏差问题进行了深入探讨;最后,本文在总结了前三部分作文自动评分方法优势的基础上,提出了一种基于异构网络融合的作文自动评分方法。本文的主要研究内容包括以下四个方面:(1)针对目前作文自动评分方法割裂了深层和浅层语义特征,忽视了多层次语义融合对作文评分影响的问题,本文提出了一种基于多层次语义特征的神经网络模型。首先,采用卷积神经网络捕获局部语义特征,采用混合神经网络捕获全局语义特征,从深层次获取作文语义特征;其次,利用篇章级的作文主题向量获取主题层特征;同时构建神经网络模型难以挖掘的语法错误等浅层语言学特征;最后通过特征融合对作文进行自动评分。实验结果验证了该算法在作文自动评分任务中的有效性。(2)针对当前基于深度学习的作文自动评分方法效率不足,以及特征工程的局限性,本文提出了一种基于注意力词嵌入网络的轻量级作文自动评分方法。该方法采用端到端的训练方式,不包含任何的特征工程,参数少且易于训练。实验结果表明该模型可以有效地对作文进行自动评分,且模型效率得到显著提高。(3)研究发现,由于预训练词向量的训练语料和作文语料在语义表达、语言风格等方面有较大区别,使用预训练词向量会带来语义偏差的问题。因此,本文提出一种基于混合词向量的作文自动评分模型,该方法同时包含预训练词嵌入和自训练词嵌入。实验结果表明本文模型可以有效缓解这种语义偏差问题。(4)针对目前作文自动评分方法缺少对不同结构神经网络的融合,以及忽视不同结构网络所提取的作文语义可以相互补充的问题,本文在总结了前三部分方法优势的基础上,提出了一种基于异构网络融合的作文自动评分方法,包括卷积神经网络、循环神经网络和自注意力网络。此外,通过对不同规模结构的预训练词向量进行实验,分析了不同预训练词向量和自训练词向量对作文自动评分性能的影响。
{URL}: https://link.cnki.net/doi/10.27432/d.cnki.gxsfu.2022.000803
{DOI}: 10.27432/d.cnki.gxsfu.2022.000803
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于指针生成网络的文本生成及应用研究
{Author}: 秦硕
{Tertiary Author}: 侯秀萍;卢少男
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 指针生成网络;摘要生成系统;ERNIE;CNN;深度学习
{Abstract}: 伴随着互联网时代的到来,信息的获取已经不再是一件难事,人们每时每刻都处在信息爆炸的状态,新闻的爆料、名人的消息、政治局势的动荡以及经济的变化等信息充斥人们身边。在这些信息的充斥之下,快速分辨出哪些是需要的哪些是不需要的信息是亟需解决的问题。文本摘要生成技术可以很好地解决上述问题,该技术可以有效地将长文本信息中的重要信息汇聚起来制作成摘要文本供人们阅读,以此更好地分辨信息的优劣。本文是在现有模型指针生成网络模型的基础上进行改进后,使模型在中文摘要上获得更好的词嵌入表示,在文本的特征表示上有着良好的改善。本文所作研究如下:首先,由于指针生成网络(Pointer Genrator Network,PGN)存在中文语义表示不够准确、特征提取不够充分以及中文词法信息缺失的问题,本文在词嵌入阶段加入ERNIE预训练模型增强模型对中文的语义表征,其对于中文词法信息的缺失问题进行专门的建模,极大的增强了模型对中文语义的理解,使得对中文语义表示更准确。然后,针对长文本文档文本过长在生成模型中会存在对文本特征提取不充分的问题,本文加入卷积神经网络(Convolution Neural Network,CNN)对长文本进行特征提取,经过预训练后在CNN中进行进一步的特征提优,再结合指针生成网络的处理未登录词(Out Of Vocabulary,OOV)和重复问题的优势,继而改善了文本摘要的质量。构建新的文本摘要生成模型——ECPGN模型。再次,对本模型进行对比实验,实验使用的评价指标是loss值和Rouge评分,并在统一数据集NLPCC2017上进行实验,使用相同的实验参数和实验设备分别对传统方法Text Rank、Seq2Seq、Seq2Seq with attention、PGN和BERT+PGN进行对比实验,设置了五组对比实验,并在loss值与Rouge评价指标的共同判定下,发现生成摘要效果优于其他模型,说明改进后的模型更优,本模型生成的摘要更有质量。由于本模型的评价指标增长不够明显,本模型还需要在日后工作中继续完善。最后,基于本文模型进行系统设计,从司法工作者需求出发,研究需要解决的问题;从提出的问题与需求作为出发点做系统的详细设计,设计了多个模块;最后将设计的模块实现并在真实的文本数据对本系统进行测试,经过测试,本摘要系统通过测试,成功实现本系统设计。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2022.000174
{DOI}: 10.27805/d.cnki.gccgy.2022.000174
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 法律文本智能问答的研究
{Author}: 吴嘉业
{Tertiary Author}: 罗旭东
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 法律智能;文本问答;法律问答;神经网络
{Abstract}: 法律智能,旨在应用人工智能技术赋予机器理解法律文本数据的能力,以帮助解决法律领域的各项难题,是自然语言处理的重要应用场景之一。文本问答,旨在构建能够回答自然语言形式问题的系统,是自然语言处理领域内最具难度的挑战之一。法律文本问答,又称法律问答,是法律智能中的一个典型应用,同时也是现实中法律咨询的一个重要组成部分。一个好的法律问答系统能够为许多人带来极大的便利,因此具有重大的研究价值。近年来,随着以裁判文书为代表的大规模法律文本数据的不断公开以及自然语言处理技术的快速发展,有关应用人工智能技术为司法领域赋能的研究取得了瞩目的进展,这些研究的成果将有助于辅助司法从业人员提高处理案件的效率。法律问答作为法律智能中的重要应用,也受到了学术界和工业界的极大关注,逐渐成为法律智能研究的热点之一。目前,法律问答研究仍存在许多挑战:1)公开司法大数据的构建需要耗费大量成本,当前仍缺乏面向具体场景的与较新事件相关的公开法律文本数据,如与新冠肺炎疫情相关的裁判文书数据;2)当前面向检索式问答的语义匹配模型存在语义表征学习与检索式目标不一致的问题;3)当前法律开放域问答方法的模型结构无法有效利用法律知识,当前知识利用方法存在制约模型性能的问题。因此,为了应对上述挑战,本文聚焦法律文本智能问答,从面向具体场景的法律文本数据的收集与构建、语义匹配模型和法律开放域问答中知识利用方法等方面展开有关关键技术研究与实验分析。本文主要贡献总结如下:第一、针对当前有关新冠肺炎疫情的公开司法数据集的缺乏问题,以及当前语义匹配模型的有监督训练目标与检索式方案设计的不一致问题,本文首先从有关官方网站收集并人工标注构建了一系列支持问答系统实现的数据集,同时提出了一个由对比学习任务辅助训练的语义关系学习网络。该网络引入了句子级的有监督对比学习任务,通过将该任务与语义关系学习任务进行联合训练来解决上述提出的问题,并有效学习到了可进行语义区分的句子表征。在数据集上的实验结果表明,相比之前的模型本文提出的方法取得了极大的性能提升。基于上述贡献,本文开发了一个基于微信公众平台的法律智能问答系统,为相关问答系统的设计实现提供了有益的参考。第二、针对当前开放域问答流水线方法不能直接适用于法律开放域问答任务JECQA的问题,以及当前JEC-QA任务的最先进方法无法有效利用知识信息的问题,提出了一个面向JEC-QA的补全-检索-问答网络。该网络包含科目信息补全、相关依据抽取以及问答模型三个模块。其中,我们提出了基于问题-依据关系图的问答模型。具体而言,在该模型中我们首先构建了问题-依据关系图,然后使用了图注意力来完成依据表征的选择与聚合,以在关系图上实现依据信息的有效利用并提高模型的性能表现。在基准数据集上的实验表明,本文提出的方法使得模型的答案预测精度得到大幅度提升。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.000882
{DOI}: 10.27036/d.cnki.ggxsu.2022.000882
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成式与检索式融合学习的图像描述方法
{Author}: 刘俊浩
{Tertiary Author}: 杨敏;曲强
{Publisher}: 中国科学院大学(中国科学院深圳先进技术研究院)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像描述;自然语言生成;多模态学习;深度学习
{Abstract}: 随着移动互联网时代的高速发展,多媒体内容在互联网中的数量呈现爆炸性地增长。图像作为人类交流最常使用的信息媒介之一,能够直观地表达丰富的视觉信息。图像描述旨在通过学习的手段让计算机能够像人类一样通过理解图像中的内容,利用自然语言生成技术产生对应的文字描述。图像描述跨越了图像与文本的语义鸿沟,因此在信息检索、人机交互等领域具有重要的意义。如今,图像描述任务大多采用深度生成模型技术以灵活地产生与图像语义匹配的文本描述,然而单纯依赖生成式模型产生描述的方法仍然面临着无意义生成、逻辑错误生成、语法错误生成、长序列建模困难等问题。与此同时,图像描述任务的检索式方法虽然能够产生细节丰富且文法正确流畅的描述,却缺少足够的灵活性而无法根据图像内容量体裁衣地产生与之最匹配的描述。为此,本论文探究如何有效地结合生成式方法与检索式方法各自的优点以改善图像描述的效果,主要研究内容包括:1.提出生成式与检索式融合学习的图像描述语句生成模型。针对图像显著区域描述难以产生精准语义的问题,构建了基于图像语义相似度的检索模型与结合检索知识的语言生成模型,并提出拷贝机制将检索结果中相关的词语引入到文本生成中,设计了检索式判别器与描述生成器的交互式对偶对抗训练机制。2.提出检索知识推理的层次化融合图像描述段落生成模型。针对语言生成模型在长序列文本生成中产生无意义、不相关描述的现状,构建了图像描述段落的场景图谱。通过引入检索知识的手段,辅助模型完成层次化的句子级别的主题规划与词级别的语义建模,并通过相关描述与知识三元组辅助模型生成精准且流畅的长文本描述,此外构建了图像描述段落生成任务的中文数据集。3.构建图像描述视觉辅助系统。针对市面上缺少图像描述视觉辅助系统的现状,通过对前述算法的整合研发了一个在线图像描述系统。该系统将基于生成式与检索式融合学习的方案应用于图像描述生成中,并提供语言生成的参数控制,将生成结果可视化,达到了较好的描述效果。
{URL}: https://link.cnki.net/doi/10.27822/d.cnki.gszxj.2022.000121
{DOI}: 10.27822/d.cnki.gszxj.2022.000121
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的改进智能生成式对话算法研究
{Author}: 刘彩真
{Tertiary Author}: 李宇
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;开放域;生成式对话系统;Seq2Seq;知识图谱
{Abstract}: 对话系统是当前人机交互领域的研究热点,被广泛应用于在线客服、问答等领域。传统的生成式对话系统由于缺乏海量知识的支撑和对问答解空间搜索范围的约束,还存在如下问题:生成的响应内容多样性指标不高、契合用户需求的程度不高、与真实的响应还有较大的差距等。针对这些问题,本文作出如下研究:(1)通过对比封闭域和开放域对话系统的特点和优缺点发现,开放域的对话系统具有更广泛的应用前景;通过对比检索式和生成式的对话模型得出,生成式的对话系统表现地更为灵活。因此,本文选择设计开放域生成式对话模型。(2)设计基于GRU(Gated Recurrent Unit)的Seq2Seq生成式对话算法、基于GL＿G的生成式对话算法和基于知识图谱的GL＿G生成式对话算法,分别验证双向GRU单元、对话目标序列和知识图谱对生成式对话模型的提升效果。首先,本文提出将原Seq2Seq基线模型中的普通GRU单元替换为双向GRU单元,使模型能够生成连贯的、符合上下文的响应内容,改进后的Seq2Seq模型能在一定程度上避免生成不连贯的回复。其次,引入对话目标序列模块,让模型能够根据目标序列智能引导对话的走向,解决了容易生成较为通用的回复和陷入对话死循环的问题。最后,针对生成的响应内容较为空洞、单一、缺乏多样性等问题,本文提出将知识图谱引入对话模型,为对话提供更多可以借鉴的关键知识,生成响应的过程中能够利用更多的关键词汇。实验结果表明,引入知识图谱后的对话模型在多样性指标Dist-2上相较于GL＿G模型提升了4.0%,生成的内容更加饱满。通过对以上三种算法进行对比分析得出,基于知识图谱的GL＿G算法在各项评估指标上表现最优,但还存在缺乏对问答解空间搜索范围的约束和难以捕捉用户话语背后深层次意图等问题。(3)为了解决以上问题,本文提出设计一种改进型的基于知识图谱的生成式对话系统。在研究及设计了多种改进算法后,最终选择在系统中添加对话场景和参与对话的人物背景信息这两大模块,一方面引入缩小搜索范围的方法,让对话更具针对性;另一方面引入提供背景信息的方法,让模型更了解用户,从而生成更加契合用户需求的响应。在公开的Du Rec Dial数据集上的实验结果表明,引入这两大模块后的UPST＿G算法模型取得了比原基于知识图谱的GL＿G模型更好的效果。其中在检索相关的指标Hits@1、Hits@3上都提升了0.6%,在生成相关的指标F1、BLEU2上分别提升了1.0%、1.4%,并使PPL指标下降了0.3%,在知识利用度相关指标Knowledge P/R/F1上分别提升了1.5%、2.9%和4.2%。另外,通过单轮对话和多轮对话的模式,分析对话模型产生的响应内容,证实了该算法产生的响应内容质量更高。综上所述,基于知识图谱的UPST＿G算法模型相比传统生成式对话算法更有效,证明了该算法在生成式对话系统中的可行性和有效性。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2022.000258
{DOI}: 10.27698/d.cnki.gwhxj.2022.000258
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向中医药临床循证指南制定的RCT文献证据采集方法学研究
{Author}: 陆沈羿
{Tertiary Author}: 李海燕
{Publisher}: 中国中医科学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 中医药;循证指南;RCT;语义模型;自动抽取
{Abstract}: 随着循证医学与信息化的不断发展,临床证据也越来越受关注和重视,随机对照试验(Randomized Controlled Trial,RCT)证据作为质量最高的原始研究,为临床循证实践指南的制定提供了高质量证据支持,近年来国内外开展了大量中医药RCT研究,The Cochrane Library中已有4万余篇中医药RCT,为中医临床循证指南的制定提供了证据基础。目前在临床循证指南制定过程中,对RCT文献证据关键信息的提取和评价主要以人工为主完成,费时费力而且很难保证信息提取的全面、准确和一致,为解决RCT循证证据关键信息的快速识别、抽取、评价以及共享,本研究以中医药RCT文献为研究对象,构建中医药RCT证据采集语义模型,并基于语义模型探索建设中医药RCT证据采集知识组织系统,为中医药RCT证据自动化抽取奠定基础。1目的为了能够全面、准确和自动提取中医药RCT证据的关键信息,本研究面向循证实践指南制定的需求,从中医药RCT相关研究现状出发,结合前期近视指南制定经验,依据循证医学 PICOS(Participant/population,Intervention,Comparison,Outcome,Study design)模型,探索适合中医药RCT文献信息采集语义模型。本研究一方面调研中医药临床循证指南制定中对证据阶段需求,确定中医药RCT文献证据的核心概念,提供规范化结构化的概念术语框架,构建中医药RCT证据采集语义模型;另一方面依托本体与自然语言处理相关技术建设中医药RCT证据采集知识组织系统,并探索中医药RCT证据自动抽取的可行性,从而为循证研究人员提供全面且快捷的数据,满足中医药临床循证指南制定中临床问题构建与证据获取及评估阶段的需求。2内容与方法本研究调研了循证医学与RCT证据相关文献,熟悉和掌握了中医药RCT证据相关评价标准与评价工具,并开展了以下研究工作:首先,通过语义标注平台,依据循证医学PICOS模型,以中医药治疗近视RCT中文文献为示范,对其进行文献检索与预处理;然后,依据文献调研到的相关评价标准及工具,对中医药RCT文献中所涉及的文本结构以及证据采集所需关键信息进行分析,并提取中医药RCT证据相关核心概念及关系;再进一步对所提取的概念进行规范化处理,规范化的过程中逐步确定中医药RCT语义模型的概念来源;接着,基于项目研发的中医药学知识组织系统(Knowledge Organization System,KOS)平台,依据FAIR原则,采用七步法构建中医药RCT证据采集本体,同时利用中医药文献实体标注管理平台对200篇中医药治疗近视RCT文献进行人工标注,并将标记导出数据作为实例导入平台中。最后,在此基础上进行验证,本研究选用KOS平台质量检测工具进行质量验证;选用本体推理机进行命名一致性与逻辑性验证;选用BERT-WWM与BILSTM-CRF结合的预训练模型完成数据训练与自动抽取验证。此外,将自动抽取与人工提取进行效率与内容准确性比较,验证自动抽取能否有助于人工提取,能否有助于指南制定证据提取阶段。3结果本研究通过文献调研,确定模型核心概念来源于指南国际网格(Guidelines International Network,GIN)证据表最小数据集、随机对照试验报告规范(Consolidated Standards for Reporting Trials,CONSORT)及其中医药扩展版、系统评价和 Meta 分析优先报告的条目(Preferred Reporting Items for Systematic Reviews and Meta-Analyses,PRISMA)、Cochrane handbook 等,确定了基于 PICOS的29个核心元素。通过参考中医药临床研究证据库系统等循证医学数据库,将语义模型划分为文献基本信息与PICOS信息两个模块,确定34个核心概念,接着借鉴EBMO本体,运用斯坦福大学医学院的七步法,复用SEPIO本体完成中医药RCT证据采集本体,共设置85个类,17个对象属性,31个数据属性,实现了中医药RCT知识的整合和结构化表示,系统地表示了循证中医药指南证据制定阶段RCT证据所需关键知识。经文献检索与筛选纳入327篇中医药治疗近视RCT中文文献,前期先随机选取200篇进行人工标注,对BIO标注集进行24轮模型训练后,中医药RCT证据采集结果验证集准确率84.63%,召回率91.46%,F1值87.91%,效果较为理想。然后,将训练后模型融合中医药RCT证据采集本体,初步实现中医药RCT证据的自动抽取。最后,选取未标注5篇中医药治疗近视的RCT文献进行比较验证,自动抽取总耗时约两分半,较人工提取显著提升研究者提取证据效率,此外自动抽取的内容准确度较好,但抽取内容的完整性还有待提升。4 结论中医药RCT证据采集本体可为中医药RCT证据的规范化处理提供参考,也有助于信息加工、重用与共享,实现循证中医学领域的知识整合及知识表示,为循证指南制定人员和科研人员提供更增加直观、准确的中医药RCT证据知识以便利用。中医药RCT证据自动化抽取辅助指南制定人员提取数据,提升人工提取效率,为中医药临床实践构建临床问题和证据提取阶段提供RCT信息参考,实现资源的最大化利用。
{URL}: https://link.cnki.net/doi/10.27658/d.cnki.gzzyy.2022.000169
{DOI}: 10.27658/d.cnki.gzzyy.2022.000169
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的细粒度情感分析算法研究
{Author}: 李强
{Tertiary Author}: 夏鸿斌;周丹平
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;情感分析;深度学习;方面情感分类;方面情感三元组抽取
{Abstract}: 文本情感分析研究人们在文本中表达的情感、观点、态度。细粒度情感分析是其中的一个细分领域,相比于研究文本整体情感的粗粒度情感分析,细粒度情感分析直接对文本中的实体进行情感分析,具备更多的实用价值。细粒度情感分析的目标是提取出文本中实体,并对根据句中观点对每个实体的情感倾向进行分类。按提取的项目不同,其可以分为方面项抽取、观点项抽取及方面情感分类三个子任务。本文主要研究方面情感分类和结合三个子任务的方面情感三元组抽取任务。(1)对于方面情感分类,大部分的研究都是通过使用注意力机制及外部语义知识对全局上下文进行建模,以完成这项工作。方面的情感极性往往取决于与方面高度相关的局部上下文,但大多数模型将过多的注意力集中于全局上下文,这使得模型的参数量普遍都比较大,导致计算量也随之增大。为此,本文提出一种基于多头注意力机制的轻量化网络模型——局部与全局特征融合网络模型。根据与方面项的语义相关距离获取局部上下文,然后对局部上下文与全局上下文分别进行特征抽取,并融合两者的提取结果进行最后的分类。在三个标准数据集上进行的实验结果表明,该模型在参数量较小的情况下,取得了比其他基于方面的情感分类算法更好的结果。(2)对于方面三元组抽取,现有方法大多将这类型的任务分为多个子任务,将子任务组成流水线,完成这类任务。然而,基于流水线思想的方法在实际应用中会受到误差传播、不易使用等影响。为此,本文提出词对关系学习方法,将方面情感三元组抽取任务转化为端到端的词对关系学习任务。将句中的词对关系进行统一标注以表示所有三元组,并使用多头自注意力的注意力图作为词对关系输出,通过词对关系解码器即可获得句中所有三元组。在四个标准数据集上的实验表明,该方法性能较优。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000396
{DOI}: 10.27169/d.cnki.gwqgu.2022.000396
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本匹配算法研究及应用
{Author}: 季昌华
{Tertiary Author}: 张涛;刘全胜
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本匹配;注意力机制;特征对齐;图神经网络
{Abstract}: 文本匹配任务旨在从两段文本中挖掘内在的语义特征,预测文本间相关性或者矛盾性。作为自然语言处理领域最重要的任务之一,文本匹配一直是领域内众多研究们关注的焦点任务。受益于其部署易、响应快、模型小、通用性强等特点,在智能问答、搜索引擎以及手机小助手等领域占据核心地位。但该领域仍然存在一些问题,阻碍着文本匹配进一步的发展。为了提高模型研究的准确率,研究者们提出对文本表征进行交互,加强文本之间的联系性。但是对于一般性的数据,其效果依旧差强人意。此外,对于长文本匹配中存在噪声信息过多的问题,目前还没有固定的解决方法。针对文本匹配任务,本文围绕领域中现存的问题展开算法研究、实验验证以及实际应用。本文的主要工作和贡献分为以下三点:(1)针对当前文本匹配模型参数量过多,以及模型对一般性数据集的预测能力有限,本文提出了一种基于残差增强模块和简单注意力机制的文本匹配框架,该框架可以同时兼顾模型的准确率以及参数量的大小。框架中设计的增强残差模块,能够极大程度上保留文本的低层传播特征,增强网络对于文本特征信息的抽取。对于文本编码后的特征,框架采用了简单注意力机制来实现文本之间的特征对齐。利用注意力机制的并行处理特性,不仅提高了模型的运算速度,也增强了网络预测的准确性。(2)目前流行的长文本匹配算法大都使用参数量庞大的预训练模型,再进行文本之间相似度的计算。尽管取得优异的准确率,但是训练速度慢并且参数量巨大。为了减少模型的参数量,本文提出解决方案。首先在Bang Liu等人工作的基础上,利用图分治的思想,化整为散,减少图中顶点数量,增加每个顶点包含的关键信息量,从而减少了模型的参数量,提高模型运算速度。接着通过图神经网络聚合关键匹配信息。最后,本文从多角度提取文档的全局特征,将局部和全局特征统一聚合,以提升算法预测的准确性。(3)为了验证本文所提算法在一般数据上的有效性,以及在人们日常生活中的智能问答系统、搜索引擎以及手机小助手等产业中的实用价值。本文设计并实现了一款基于中文维基百科语料库的智能问答系统。该系统实现了中文语料上的问答匹配。系统根据用户输入的问题信息,在语料库中精确匹配答案,并在客户端反馈得分最高的结果。用户在查询过程中能直观感受本文所提算法的可行性。同时,也证明了本文模型在智能问答、搜索引擎以及聊天机器人等产业中的实用价值。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000335
{DOI}: 10.27169/d.cnki.gwqgu.2022.000335
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于混合神经网络的联合实体关系抽取研究
{Author}: 陈俊
{Tertiary Author}: 何庆
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 实体识别;关系抽取;异构图神经;联合学习;知识图谱
{Abstract}: 随着信息技术的迅猛发展和广泛应用,大量的非结构化文本散布在互联网的每个角落。如何快速且准确地从海量的非结构化文本中提取出有用信息已成为自然语言处理领域的研究热点和难点。因此,本文主要围绕信息抽取任务中的实体关系抽取技术进行研究,旨在从非结构化文本中识别出实体和实体之间的语义关系。本文的主要研究工作和创新如下:1、针对现有实体关系抽取模型,在提取实体之前未充分利用实体信息和关系信息的问题,本文提出了一种基于异构图注意力机制的实体关系抽取模型(HGAT-RE)。首先,采用BERT预训练模型作为词嵌入层,使模型能够更好地理解句子的语义信息;其次,为了得到适合关系提取任务的特征表示,本文将实体属性、关系类别和单词建模为图上节点,并采用异构图注意力机制对节点特征进行融合;最后,使用层叠指针的标注方式对三元组进行抽取。实验结果表明,在NYT,Web NLG数据集上,HGAT-RE模型的F1值相较于基线模型分别提升了2.7%和1.2%,同时与其他改进模型相比,具有更好的性能。2、针对实体关系抽取的流水线模型存在暴露偏差问题,本文提出了一种基于全局指针标注的实体关系联合抽取模型(GP-RE)。首先,采用BERT预训练语言模型作为词嵌入层,以获取更好的上下文语义信息;然后,提出联合编码层作为模型的特征提取层,用于学习文本深层特征,增强子任务之间信息交互;最后,采用嵌套全局指针的标注方式对三元组进行抽取,以解决多关系同时抽取和实体嵌套问题。实验结果表明,在NYT,Web NLG数据集上,GP-RE的F1值相较于基线模型分别提升了2.4%和3.1%,与主流模型相比,具有较强的性能。3、将上述研究成果应用于中文司法盗窃裁判文书数据集上,对中文司法盗窃裁判文书中的实体关系进行抽取,并对中文司法盗窃案判决文书建立了知识图谱,以此推动该方法在相关领域的实际落地。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.002705
{DOI}: 10.27047/d.cnki.ggudu.2022.002705
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的自动文本摘要技术研究与应用
{Author}: 孙泽凯
{Tertiary Author}: 孟祥茹
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;自然语言处理;文本摘要;生成式摘要;知识增强
{Abstract}: 在过去的四十多年改革开放政策的影响下,中国的社会发展迅速。特别的是,在上世纪九十年代,中国引入了互联网技术,这就更加丰富了人们的社会文化生活。人们可以通过上网冲浪的方式获取到各种各样的信息。但是互联网每天都有海量的信息数据产生,在这些大量数据中只有极小部分才是我们需要的信息。如何从这些海量的数据中,过滤多余和无效的信息,快速并准确的获取对自己有用的信息,是需要耗费大量成本的事情。人们也在想方设法的节省获取信息的成本。经过大量科学家和研究者的共同努力,自然语言处理领域发展迅速,自动文本摘要技术也逐渐走入大众的视野。文本摘要技术通过对文本的结构、文本的特点进行分析研究,从而提取若干文本的中心句构成文本的摘要,或者通过对文本的词法、语法、语义等进行学习和训练,理解原始文本的表达含义,进而生成能够概括原始文本的句子摘要。本次研究从项目服务对象出发,根据服务对象多为老年人的特点,提出使用文本摘要技术对项目中涉及的新闻和文章等信息进行处理。将这些长文本信息生成对应的文本摘要,进而能够提高服务对象获取信息的速度,节约获取信息的各项成本。本文研究过程中学习一些前人经典的思路和想法,深入学习了一些经典模型的执行流程和总体思想,对比了各个模型间的优点和不足。对于自然语言处理任务,一般分为第一阶段的上游词向量处理和第二阶段的下游具体任务微调。本文研究的主要创新点有以下几点:第一,在词向量处理过程中,通过改进经典模型的掩码策略来提升模型的效果。第二,根据项目使用的语料环境特点,把词向量的处理过程使用另外的模型进行替换,让本来使用于英文环境的生成式预训练模型能够处理中文语料环境的任务。第三,通过微调和改进现有的生成式预训练模型,让模型能够处理不同长度的文本数据。最后,挑选了合适的中文数据集进行一系列的实验验证,在短文本和中长文本数据处理中取得了良好的效果,但在超长文本数据处理效果上还有很大的进步空间。总体上来说,使用改进后的模型能够满足本次研究的任务功能需求。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000009
{DOI}: 10.27587/d.cnki.gksjs.2022.000009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的任务型对话系统的设计与实现
{Author}: 孙皓源
{Tertiary Author}: 赵春一;李宝祥
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 任务型对话系统;注意力机制;自然语言理解;自然语言生成
{Abstract}: 人机对话是数代计算机与人工智能领域研究者和从业者为之努力和奋斗的方向,对话系统通常分为闲聊型对话系统、常见问题解答型对话系统和任务型对话系统,本文主要围绕任务型对话系统展开工作。任务型对话系统在实现方式上有端到端和管道式两种,管道式的对话系统通常由对话状态追踪模块、策略学习模块和回复生成模块组成。目前任务型对话系统在与用户进行多轮交互时,往往会存在意图和槽位识别困难、无法准确向用户传达信息的情况,同时因为任务型对话系统的数据获取成本较高,因此如何使对话系统在缺少数据甚至无数据的新领域中仍然能够拥有一定的效果,是近年来的研究热点。本文基于对话任务的结构描述信息展开研究,通过基于注意力机制的模型和运行时计算任务结构与对话内容的信息交互的方式,可以使模型在数据不足甚至没有数据的情况下,仍然可以利用任务的机构信息识别用户的意图和抽取槽位值。同时本文提出的ADDST模型可以在多轮对话的情况下更好地解决意图识别和槽位填充的问题,尤其在分类类型槽位填充中,不仅提升了模型效果,还降低了计算量。本文还提出了实现对话系统中策略学习模块和回复生成模块的方法,这些模块采用的模型均在无样本训练的新领域中有着不错的效果。使用本文提出的对话状态追踪模块、策略学习模块和回复生成模块的实现方法,可以以管道式的结构完成对话系统搭建并与用户流畅地进行多轮对话。最后,本文设计了一套在车舱场景下的任务型对话系统,该系统由部署在车舱的对话系统终端和部署在云端的对话系统服务端组成,两个系统协同运作,完成整个对话系统的功能。其中,部署在云端的对话系统服务端由基于注意力机制的多轮对话系统的研究成果实现。在经过系统的设计、开发和测试后,证明了本文的研究成果在多轮对话系统中应用的可行性。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000044
{DOI}: 10.27587/d.cnki.gksjs.2022.000044
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进LSTM模型的文本分类研究与应用
{Author}: 谢超平
{Tertiary Author}: 许永峰
{Publisher}: 西北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本分类;浅层学习;深度学习;LSTM
{Abstract}: 在大数据时代,各行各业都产生了大量的数据,这些数据分为结构化数据和非结构化数据。对于结构化数据,现已具有相当多且效果良好的研究方法。但各行各业产生的数据中有80%是非结构化数据,如文本、语音、视频等。短文本数据存在无规则、上下文信息稀疏以及语义和语法干扰等问题,为解决上述问题。本文引入文本分类技术,以增强用户对文档对象的认知与理解判断,从而帮助用户从海量文本数据中快速筛选出有价值的信息。本文以MOOC某课程评论数据为研究对象,对中文短文本数据的情感分类进行了探究分析,主要研究内容如下:首先,利用网络爬虫技术获取MOOC某课程评论数据集和已被人工标注的淘宝商铺评论数据集,使用BERT预训练模型将MOOC课程评论数据集按照不同的情感特征打上伪标签。然后,将基于主题的文本分类方法、基于浅层学习的文本分类方法和基于深度学习的文本分类方法进行实验对比,实验结果表明:针对本文数据集,基于深度学习的文本分类方法的分类性能表现最优。最后,以LSTM模型为基础框架,在其网络下游堆叠关系网络并融合注意力机制,对LSTM模型进行改进。将改进LSTM模型的文本分类性能与其余文本分类方法在本文数据集上进行实验对比。实验结果表明:本文提出的改进LSTM模型的各项文本分类指标均有所提升,且分类性能表现最优。因此,本文提出的文本分类方法具有一定的现实意义和实用价值。
{URL}: https://link.cnki.net/doi/10.27405/d.cnki.gxbdu.2022.000861
{DOI}: 10.27405/d.cnki.gxbdu.2022.000861
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的健康咨询系统研究
{Author}: 张涛
{Tertiary Author}: 孟令国
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 电子医疗数据;命名实体识别;知识图谱;问答系统;健康咨询
{Abstract}: 如今,互联网上的电子病历、网上问诊、医疗科普网站等积累了海量的电子医疗数据。随着人们越来越重视自身健康,以及缓解线下医疗资源的压力,如何有效地利用这些电子医疗数据,并结合自动问答系统,为人们提供更有针对性、更为精准的医疗健康方面的搜索反馈,已经成为自然语言处理技术方向研究的重点。与此同时,知识图谱相关技术的成熟与广泛应用,为问答系统的精准化构建起到了关键作用。本文使用自然语言处理相关技术从电子医疗数据中提取得到数据中的实体与实体关系,并以知识图谱的形式进行存储,随后设计了基于该知识图谱的健康咨询系统,该系统可以帮助人们更为准确地搜索医疗健康相关知识,方便人们简单了解疾病和症状,同时可作为医疗辅助工具,减轻医生的问诊负担,在理论与实践方面具有一定的价值。本文的主要工作内容总结为以下两点:(1)汇总和整理网上海量的电子医疗数据,构建医疗健康方面的知识图谱。首先通过爬虫技术获取权威医疗网站的医疗健康相关数据,得到半结构化的文本数据,之后使用改进的BERT-BiLSTM-CRF模型对处理好的数据进行实体识别,使用PCNN模型将文本中的医疗实体以及实体之间的关系提取出来,最后把得到的实体与实体关系存放在Neo4j图数据库中,完成了健康问答领域知识图谱的构建。(2)设计并实现了基于医疗数据的健康咨询系统。在该系统中,对于用户输入的问题,采用基于BERT-TextCNN的文本分析模型进行问句的意图理解,使用BiLSTM-CRF模型以及AC自动机做槽填充,将问句中的实体与实体关系映射到知识图谱中,通过Cypher语言,在知识图谱中检索答案。使用Flask框架搭建问答系统平台,将问答系统以网页的形式呈现,把在知识图谱中检索到的答案以文字的形式返回给用户。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.004656
{DOI}: 10.27272/d.cnki.gshdu.2022.004656
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理的方剂功效分类研究
{Author}: 高婉卿
{Tertiary Author}: 丁长松
{Publisher}: 湖南中医药大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 药向量;方剂功效;自然语言处理;深度学习;预训练模型;文本分类
{Abstract}: 目的:方剂作为中医临床用药的主要载体,利用药效物质的协同来增强药效降低毒副作用。相关研究显示,方剂功效与其组成药物间存在着非线性关系。深度学习作为拟合非线性关系的有效技术,在方剂功效研究中主要为模型的简单调用,忽略了方剂数据自身的特点与中医复杂的理论背景,导致模型学习效果不佳。本研究借鉴自然语言处理领域研究方法,融合中医理论,提出一种“预训练+微调”形式的药向量预训练模型,同时结合方剂数据的特点提出了一种改进的深度学习模型对方剂进行功效分类,以此来探究方剂配伍与功效的关系,并为中医智能辅助、中医药现代化发展提供经验。方法:收集方剂数据,对方剂药物组成、方剂功效信息进行规范化、标准化,并进行数据统计与分析;借鉴预训练方法,融合中医理论,构建药向量预训练模型TCM2Vec,包含基于FM算法的中药关系特征预训练模型FMh2v与基于双层编码器的微调网络DECNN,最终得到包含更多语义信息的药向量表示;最后结合方剂数据弱语序与样本量较小的特点,设计基于特征偏差的无参网络层,同时提出一种融合特征对齐偏差的损失函数以更新网络参数,得到深度学习模型FATCNN进行方剂功效分类。结果:实验表明,FMh2v训练得到的药向量作为初始嵌入后Text CNN、LSTM、Text RCNN、Transformer以及GRU分类ACC与F1值均优于无预训练嵌入、以CBOW和BERT为初始化嵌入的分类结果;以少量有标签方剂数据为实验对象,与五个基线模型的分类结果相比,具有双层编码器的DECNN的ACC为71.15%,F1为72.17%,优于基线模型;提出的分类模型FATCNN实验结果与基线模型中性能最好的Text CNN相比,FATCNN方剂功效分类ACC提升1.93%,F1提升1.25%,在两个公共数据集中,FATCNN也具有较好的表现。结论:本文借鉴自然语言处理领域的词向量技术,结合中医理论进行改进后的药向量训练模型TCM2Vec具有获得更为准确语义表示的能力;在获取药向量的基础上,本文设计的基于特征偏差对齐的分类模型FATCNN具有更优秀的方剂功效分类性能。
{URL}: https://link.cnki.net/doi/10.27138/d.cnki.ghuzc.2022.000450
{DOI}: 10.27138/d.cnki.ghuzc.2022.000450
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向BIM消防审查的规范语义模型构建方法研究
{Author}: 刘玥
{Tertiary Author}: 周小平;王佳;陆东
{Publisher}: 北京建筑大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 建筑信息模型(BIM);语义模型;工业基础类(IFC);消防设计审查
{Abstract}: 在建筑行业中,建筑工程项目必须按照建筑规范的规定对其进行设计审查,消防设计审查作为保障建筑防火安全的关键环节,是建筑工程项目设计审查的重要内容。然而,现阶段消防智能审查主要以人工审查或机器半辅助审查为主,这种审查方式需要消耗大量的时间和精力,并且难以保障审查结果的准确性和全面性。在建筑工程行业向数字化、信息化、智能化转型的过程中,建筑信息模型(Building Information Modeling,BIM)不仅是转型的关键技术,同时提供了消防审查工作新的方向。BIM整合了建筑模型的几何、属性、语义信息数据等,数字化表达了建筑工程项目全生命周期的信息数据。面向BIM的消防审查工作改变了传统的面向二维图纸的工作方式,但对于消防规范的处理方面很难达到实际审查的需求,同时在几何空间方面也难以提取建筑构件的几何空间关系。本文针对消防智能审查中计算机难以理解规范条款的语义信息并进行推理的问题,以及在BIM模型中仅能提取少量构件几何语义关系的问题,提出了面向BIM消防审查的规范语义模型构建方法。主要的研究内容和成果如下:(1)提出了消防规范知识本体的构建方法。消防规范知识具有较强的专业性,是消防规范标准中的核心内容。然而,计算机难以准确的理解和表达消防规范知识的含义。因此在本文中,首先对IFC(Industry Foundation Classes,工业基础类)标准进行了分析,得到了消防规范知识在IFC标准中的语义表达机制,为消防规范知识本体的构建提供了属性信息。然后依据改进后的七步法构建了规范知识本体,并在规范知识本体的属性中补充了IFC属性,达到规范知识本体与建筑信息模型的映射,为计算机提供了理解规范知识概念的能力。(2)提出了规则逻辑表达式的构建方法。消防规范条款是在消防审查时必须遵守的规范依据,然而规范条款覆盖的范围广并且具有严谨的逻辑关联性。本文通过构建规则逻辑表达式的方法,为计算机提供了语义理解和规则推理的功能。首先选取消防审查所需的规范标准,进而对消防规范进行了分词处理。然后基于上下文无关法对消防规范的语义进行分析,归纳了规范的结构化表达式。最后通过自然语言处理技术,将规范条款转变为计算机可以推理的规则逻辑表达式,为消防审查提供了规范的规则逻辑库。(3)提出了BIM几何空间的语义扩展方法。在消防规范标准中包括了大量对建筑构件几何空间关系的判断,然而IFC标准中构件的空间语义信息难以满足消防规范中构件几何空间判断的需求。为此,本文提出了几何空间计算方法补充构件的几何空间关系。在本文中将几何空间关系分为相邻、相交和相离三种,首先对BIM构件进行三角网格化,然后将几何空间计算分为粗判和细判两步对构件的几何空间关系和相离距离进行提取,最后通过实验验证了所提方法的实用性和可操作性。本文基于上述的理论研究基础,设计和开发了面向BIM模型的消防审查系统,实现了属性审查、几何空间审查和审查结果可视化等功能。本文选取了10个不同建筑类型的BIM模型作为实验对象,从三个评价指标和时间效率两个维度对所提方法进行评估。实验结果表明,本文所提方法保障了消防设计审查的准确性和查全性,并且提高了审查效率,节省了消防审查的时间成本。
{URL}: https://link.cnki.net/doi/10.26943/d.cnki.gbjzc.2022.000582
{DOI}: 10.26943/d.cnki.gbjzc.2022.000582
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于事件知识图谱的事件关系识别及应用
{Author}: 谢群丽
{Tertiary Author}: 王先传
{Publisher}: 阜阳师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 事件类;事件知识图谱;事件共现;事件实例检测;事件关系
{Abstract}: 与静态实体相比较,动态的事件更符合人们认识和理解现实世界的认知逻辑。目前在自然语言处理领域中大多采用事件作为基本单元对非结构化文本进行处理,而事件之间往往存在一定关联,如何从非结构化文本中识别出事件与事件之间的关系,也是自然语言处理领域的一项重要任务。当前的事件关系识别方法有基于模式识别方法、传统机器学习方法以及目前非常热门的深度学习方法,这些方法的研究效果表现优异,然而,事件与事件之间往往存在多种事件关系,这些方法目前都只是面向单一的事件关系,针对同时识别多种事件关系的研究较少,不足以应付上层应用对于获取多种事件关系的需要。事件知识图谱是以事件类为节点、事件类关系为边构建的,对比传统知识图谱,事件知识图谱包含了更为丰富的语义信息,可以很好的展现客观世界中动态事件的发生和演化规律。本文提出利用事件知识图谱映射事件关系的方法识别事件关系,可以同时识别出事件与事件之间可能存在的多种事件关系以及间接联系,对于面向事件的后续应用研究具有一定意义。本文主要包括以下两部分工作:第一,融合事件共现和时间、环境要素进行事件相关性判断。基于事件知识图谱的事件关系识别,首先需要判断两事件之间是否具有相关性。根据事件的动作要素和对象要素的联合共现概率以及推理规则判断两事件之间的环境要素和时间要素相差窗口范围是否在规定窗口范围内以计算事件相关度,并结合事件相关度阈值来判断两事件之间是否相关。第二,基于事件知识图谱的事件关系识别。在事件相关性判断工作基础上,若相关即可继续进行事件关系识别工作。本文首先利用事件知识图谱进行事件实例检测,将事件实例的各要素与事件知识图谱中事件类对应要素的共同特征集合进行匹配,即可判断两事件所属的事件类,并且在构建好的事件知识图谱中找到对应事件类。若两事件都能在构建的事件知识图谱中找到对应事件类,利用给出的事件关系推理规则以及事件知识图谱已有知识进行推理和映射事件关系,实现事件关系识别。
{URL}: https://link.cnki.net/doi/10.27846/d.cnki.gfysf.2022.000074
{DOI}: 10.27846/d.cnki.gfysf.2022.000074
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的文本情感分析研究
{Author}: 叶星鑫
{Tertiary Author}: 徐杨
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本情感分析;ALBERT网络;卷积网络;注意力机制;预训练语言模型
{Abstract}: 自然语言处理是计算机科学领域与人工智能领域中的一个重要方向,情感分析又是自然处理领域的重要分支和关键任务,被广泛应用于社交媒体、问答服务和舆情分析中,它协助人们解决了各种难题,成为了目前研究的热点方向。但是该研究面临着文本内容灵活、表达方式多样和语句歧义等难点,同时传统的情感分析方法需进行词典构建和数据标注,费时费力的同时还极度依赖领域语言知识,大大阻碍了情感分析的进一步发展。预训练语言模型可在极少的人为干预情况下,完成海量文本数据的特征提取工作,为文本情感分析提供了长足的发展动力。针对当前文本情感分析任务在不同层面和不同粒度上面临的难点与挑战,本文深入探索了预训练语言模型内部原理,做了总结与改进。主要工作和贡献如下:(1)为了解决在句子级情感分析任务中大部分网络不能充分利用不同通道间的文本语义信息和关联信息的问题,以及传统网络忽略了文本的词语位置信息的问题,提出了结合ALBERT(A Lite BERT For Self Supervised Learning Of Language Representations)和注意力特征分割融合网络的文本情感分析模型ALBERT-AFSFN。该网络通过引入ALBERT优秀的结构设计,动态提取句子语义信息和位置信息;并融入注意力分割网络优秀的通道特征提取能力,有效挖掘句子各个通道中的语义信息;同时利用特征注意力网络优秀的特征融合能力,有效融合各通道间的语义信息和关联信息。在公开数据集Chn Senti Corp、waimai-10k和weibo-100k上分别进行了验证实验,准确率达到93.33%、88.98%和97.81%,表明本文提出模型在句子级情感分析任务中具有很强的适用性和竞争性。(2)为了解决大部分方面级情感分析网络没有充分利用文本中局部特征信息和全局特征信息的问题,提出了轻量级ALBERT卷积级联网络ALBERTC-CNN。该模型能够利用卷积网络有效捕获局部特征的能力,同时还能有效结合ALBERT模型中自注意力机制捕捉长依赖信息的能力,提取出文本当中更细粒度、更全面的特征信息,得到更准确的情感分析结果。在Sem Eval-2014开放性任务的laptop和Restaurant评论数据集上进行了验证,实验得到该模型分类准确率在ALBERT网络基础上分别提升了1.72%和0.72%,这验证了本文模型可以有效提升文本方面级情感分析任务的分析效果。(3)为了能更直观地观察本文提出模型的效果,并实现文本情感分析结果的可视化,本文开发了一套短文本情感分析系统。该系统能够对用户的需求做出快速且准确的分析,并将分析结果渲染到前端,实现了文本情感倾向性的闭环分析和展示过程;同时本系统还可以进行自我升级和优化,即当模型分析的结果不符合用户预期时,系统会自动将用户反馈的正确结果带入到模型新一轮的训练中,从而更新网络参数,达到增加其健壮性、保证其使用周期的目的。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.002701
{DOI}: 10.27047/d.cnki.ggudu.2022.002701
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的问答系统在政务数据领域的应用研究
{Author}: 李岩
{Tertiary Author}: 李少波
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;政务问答;实体识别;BERT-BiGRU-CRF;语义分析
{Abstract}: 随着互联网技术的广泛应用和不断发展,信息呈爆炸式增长。传统的政府搜索引擎逐渐无法满足公务人员检索信息的需求。其返回的信息过于冗杂,而公务人员想要获取真正的答案需要耗费大量的时间与人力去阅读返回的信息。可见,传统搜索引擎已经无法满足用户,知识图谱的快速发展推动了问答系统在政务数据领域的发展。基于以上背景,本文研究并开发了基于知识图谱的政务知识问答系统,使用网络爬虫从政务网站获取政务数据,利用网页解析工具Xpath和Beautifulsoup对下载的原网页进行提取解析,根据爬取的政务数据构建政务节点信息,制定不同节点之间的关系,形成一个较为完整的政务领域的知识图谱。通过查阅知识图谱相关论文、实际体验其他平台的问答系统,从技术可行性、社会可行性和经济可行性的角度出发,确定了该系统的需求,在完成对系统的需求分析之后,对系统进行概要设计,采用层次体系架构的方式,明确了系统的功能模块。在概要设计的基础上,依照软件工程的开发流程,对功能模块进行了详细的设计编码开发。最后对整个系统进行系统测试,根据测试结果不断对系统进行改进。本文的主要内容有:1.利用Scrapy爬虫框架对政务网站进行大规模爬取,并对数据进行结构化处理,分析政务知识领域的问答实体属性和实体间关系,构建面向政务领域的知识图谱。2.对问题进行解析,包括分词、词性标注、去掉无效字符等预处理操作,设计了基于BERT-Bi GRU-CRF的实体识别模型来提升实体识别精确度和效率,设计了对BERT模型进行改进的BERT-CNN模型对问句进行意图识别。3.实现基于知识图谱的政务知识问答系统,为了帮助政府公务人员办公,采取适用于公务员办公环境的B/S体系架构进行系统开发,用可视化的形式为公务人员展示所搜索的政府公文。基于知识图谱的政务知识问答系统,根据系统不同功能模块的划分,该系统分为服务器端和用户前端。利用Flask框架实现后台服务器的功能模块,前端开发技术采用Bootstrap框架,结合Element的UI组件完成前端界面构建。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.000986
{DOI}: 10.27047/d.cnki.ggudu.2022.000986
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向多领域政策的文本分类技术研究与应用
{Author}: 邓琛
{Tertiary Author}: 于碧辉
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多领域政策;自然语言处理;文本分类;BERT;上下文信息
{Abstract}: 在当今大数据的时代中,海量多领域政策文本出现在在日常生活中,如果可以有效利用这些多领域政策文本数据,不仅可以有效的帮助人民理解、维护政策,同时可以协助国家规范执政手段、提升执政效率。正因如此,许多研究人员围绕政策文本展开了研究,希望可以更有效地应用这些数据。作为自然语言处理的重要任务之一,文本分类是许多任务的基础,本文利用多个领域政策的文本分类技术,为多领域政策知识图谱的构建项目做出支撑,针对多领域下的政策文本分类提出了相应的模型,以提升分类任务的精确性。本文针对多领域的政策文本,提出了一种高效准确的通用政策文本分类模型BERT-RC,在预训练模型的基础上,进一步改进文本表示,将更多的文本上下文信息融入到文本特征表示中。模型首先通过预训练模型得到优秀的词向量表示,然后通过双向循环网络充分提取文本的上下文特征,接下来通过卷积神经网络强化局部的文本特征提取、优化文本信息的捕捉、突出内容的特征,最后通过这些文本特征得到文本分类的结果。在政策文本数据上,BERT-RC模型相比于基线模型F1值均有提升,实验表明,本文提出的BERT-RC模型可以优化文本特征表示,提升模型的分类精度,消融实验也证明了模型各个模块的积极作用。同时针对层级性多元文本分类任务,提出了一种快捷有效的HFT-Trans模型,使用Transformer和BERT词向量优化文本特征表示,并利用分层的模型结构解决层级性多元文本分类中下层类别的文本训练数据过少、分类粒度更细致的问题,将上层的模型参数迁移到下层的模型中,使下层模型包含上层模型的分类信息,利用上层的数据促进下层的分类。同时加入了对抗训练,使复杂模型在少量数据集上避免过拟合的问题,动态学习率也加速了模型的最终收敛,在此基础上,最后还加入了集成学习,验证了集成学习的网络确实优于单一网络,可以提升模型的泛化能力。在层级性多元本分类任务场景下,本文提出的HFT-Trans模型取得了较好的结果,实验表明,HFT-Trans模型可以很好的处理层级性多元文本分类任务,提升任务的精度。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000059
{DOI}: 10.27587/d.cnki.gksjs.2022.000059
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义分析的学涯智能问答系统的设计与实现
{Author}: 商胜彭
{Tertiary Author}: 李金;武靖恺
{Publisher}: 中国科学院大学(中国科学院沈阳计算技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: BERT;语义分析;问答系统;知识图谱
{Abstract}: 传统的问答系统中,大多数是基于规则或字面相似度在知识库中进行检索的,其问答系统可以快速检索匹配的问句,缺点是匹配的准确率并不高。而基于深度学习的问答系统的准确率虽然很高,但其缺点是匹配时花费的运算的时间较多,而且训练模型也需要依赖很多优质的数据资源。因此本文提出了一个以深度学习匹配算法为主的语义分析智能问答系统,该问答系统是一种具有上下文理解能力的基于信息检索的深度向量匹配和深度学习排序的问答系统,该系统采用两段式排序算法,在第一阶段使用简单的检索模型,检索出多个相关的问题,以减少训练所依赖的数据以及召回所用的时长,第二阶段采用排序算法在检索出的多个问题的基础上使用预训练模型进行再次的精排,从而取得最好的答案,还模型需要的数据资源少并且在准确率上优于大多数模型。主要由检索模块,排序模块两大部分组成。首先对用户的提问进行分词、实体识别以及长难句压缩的处理,该模块主要使用AC自动机进行关键词的提取。其次检索模块根据预处理好的问句,通过字面检索、语义检索和知识图谱查询多个相似答案所在知识库中的位置并快速筛选出得分靠前的句子,该模块主要使用了基于词袋的BM25统计模型和基于深度向量匹配的word2vec语言模型。最后排序模块根据检索到的结果进行归并,通过实体对齐策略过滤一些不合理的答案,使用重排技术对过滤的答案进行重新排序得到最合适的答案,该模块主要使用了基于关键词的实体对齐方法以及基于Pointwise的Learningto Rank重排模型。其中知识库和知识图谱的优化和补充是通过知识挖掘、数据分析、信息提取、阅读理解等方法在资讯事件、对话日志、条款知识等文本中获得。本课题实现了基于文本匹配的智能学涯测评问答系统,分别解决了字面匹配、深度向量匹配和带有逻辑推理的知识图谱文本匹配系统,通过三者的进一步融合结合,使得答案更为精准、全面,解决了学涯测评领域自然语言问答处理技术的实际应用问题。
{URL}: https://link.cnki.net/doi/10.27587/d.cnki.gksjs.2022.000069
{DOI}: 10.27587/d.cnki.gksjs.2022.000069
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向生物医学文本的实体识别和标准化研究
{Author}: 孙曰君
{Tertiary Author}: 杨志豪
{Publisher}: 大连理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 生物医学信息抽取;命名实体识别;临床术语标准化;文本匹配
{Abstract}: 随着医疗信息化建设和生物科技的迅猛发展,生物医学文献和电子病历的数量呈现出指数级增长的态势,蕴含在这些生物医学文本中的信息成为生物医学研究的宝贵资源。但由于生物医学文本大都是以自然语言描述的非结构化形式存在,计算机无法直接对其进行有效的分析和利用。因此,通过生物医学文本挖掘技术对生物医学文本进行有价值信息的提取和利用,将对生物医疗技术的进步和医疗健康领域信息化建设的发展产生深远和积极的影响。生物医学命名实体识别和标准化是生物医学文本挖掘的基础任务之一,旨在从生物医学文本中识别出预定义的生物医学实体,并将其映射到标准的ICD编码或其他生物医学本体。它们为下游的生物医学知识图谱构建、智慧医疗以及智能医保控费的研究提供支持。基于此,本文分别研究了生物医学命名实体识别和临床术语标准化任务。针对中文医学命名实体识别任务中存在嵌套实体和低资源等问题,本文提出了基于指针网络和对抗训练的医学实体识别方法。通过使用指针网络标注的方式,可以无差别地识别非嵌套实体和嵌套实体,通过使用对抗训练在文本向量表示上添加扰动生成对抗样本,可以有效的缓解模型鲁棒性差的问题。实验结果表明,该方法对标注策略的改进及引入对抗训练可以有效的提高模型性能。针对中文临床术语标准化任务中,术语描述具有口语化、不规范性以及多样性的问题,本文提出了基于深度语义匹配的临床术语标准化方法。通过使用Jaccard相似度算法从标准术语集中生成候选术语集,使用BERT模型提取临床术语的深层语义特征,并构建二分类模型得到标准的临床术语名称。该方法在CHIP2019临床术语标准化评测数据集上进行了实验,准确率达到了90.04%,验证了该方法的有效性。针对中文多蕴含临床术语标准化任务中,蕴含标准词数量不确定、原始文本与标准词之间字面重叠度低、标准词之间存在依赖关系和标准词类目多等问题,本文提出基于知识增强的多蕴含临床术语标准化方法。该方法的总体思路是粗召回、精排序、再匹配的三阶段策略,通过构建标准词数量预测模块,引入知识表示学习算法捕获标准词之间的内在联系,构建临床诊断文本与标准词之间的映射规则集合,来达到提升性能的目的。该方法在CHIP2020临床术语标准化评测数据集上进行了实验,实验结果验证了该方法对于多蕴含临床术语标准化任务的有效性。
{URL}: https://link.cnki.net/doi/10.26991/d.cnki.gdllu.2022.002222
{DOI}: 10.26991/d.cnki.gdllu.2022.002222
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于政务领域的知识图谱构建研究
{Author}: 李祥
{Tertiary Author}: 徐博
{Publisher}: 大连理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 政务领域;关系抽取;实体识别;知识图谱
{Abstract}: 知识图谱是人工智能研究的重要组成部分,对于解决人工智能的可解释性问题具有重要意义。然而当前知识图谱的研究还主要集中于通用领域,垂直领域的知识图谱构建研究较少,所以本文对垂直领域的政务知识图谱构建展开研究。根据政务领域文本语料特点,本文提出了基于政务领域知识图谱的实体识别和实体关系抽取方法,旨在提高模型的关系抽取性能,为政务领域知识图谱的自动构建提供技术支持。针对政务文本中并列结构实体数量众多,实体分布集中等的特点,本文提出了基于BERT机制的政务实体预训练模型,并且结合双向长短期记忆网络(Bi LSTM)提出了政务实体识别模型。首先使用BERT预训练模型对政务文本进行预训练,得到初始化向量表示,然后利用Bi LSTM对政务文本实体进行识别,并引入注意力机制来确定输出向量的权重。实验结果表明:对于中文政务命名实体识别问题,本文算法比传统神经网络有更好的性能;对不同类型政务文本样本均取得较好的结果。针对现有政务文本关系抽取方法在卷积及池化操作时会损失局部特征信息的问题,本文提出了特征序列分割卷积神经网络的自适应池化方法。首先利用自适应池化和最大池化方法来提取政务文本的局部特征,然后结合Transformer模型来提取政务文本的整体特征,最后将每个子模块编码结果叠加处理,再进行交叉熵损失计算,得到文本局部、全局特征结合的输出向量。实验结果表明:对于中文政务文本关系抽取问题,本文算法比传统单一模型具有更好的抽取结果;对于并列、平行结构的政务实体关系有较好的抽取效果。本文改进了在政务文本数据集上命名实体识别和关系抽取的网络模型,构建了基于政务文本的知识图谱可视化系统,清楚的展示了各实体之间的关联信息。这项研究表明本文模型构建方法的有效性,体现了将自然语言处理和知识图谱技术应用于政务文本的潜力。
{URL}: https://link.cnki.net/doi/10.26991/d.cnki.gdllu.2022.001415
{DOI}: 10.26991/d.cnki.gdllu.2022.001415
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的文本表示优化方法研究
{Author}: 梁雨昕
{Tertiary Author}: 郑杰
{Publisher}: 西北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本表示;预训练语言模型;BERT;对比学习;模板学习
{Abstract}: 文本的表示学习是很多自然语言处理任务的基础,文本表示的质量也直接影响了下游分类、生成等任务的表现。从简单的独热表示、词包表示,到静态词嵌入以及有监督文本表示学习,文本表示方法已经取得了一系列的进展。近年来,以BERT为代表的基于Transformer结构的预训练语言模型在各类自然语言任务上取得了显著的进步,已经成为了提取文本表示的默认选择,得到广泛应用。但最新研究表明这类预训练语言模型提取的文本表示存在各向异性问题,即文本表示在不同方向上的分布极不均匀,这使其词相似度和文本相似度的计算准确性较低,影响文本表示在下游任务上的表现。本文分别针对预训练语言模型的词表示和句表示进行研究和改善。1.针对预训练词表示存在的各向异性问题,提出基于权重地去除词嵌入主导方向的方法进行改善。通过测量BERT预训练模型词嵌入的平均余弦相似度等几何特征,并分析其主成分方向投影和奇异值分布,发现BERT预训练词嵌入存在不同方向上的非均匀分布,导致词向量的表示能力受到损害。因此,本文提出了有权重去除BERT词表示中的主导方向来解决该问题,每个主导方向对应一个可学习权重来确定该方向去除的比例,通过在词相似度任务上学习调整这些权重。实验表明本方法缓解了词向量的各向异性问题,并提升了其在词相似度、词类比和文本语义相似度三个标准评估任务上的表现。2.针对预训练模型句表示存在的各向异性问题,提出结合模板(Prompt)技术和对比学习的方法进行改善。首先本文通过模板工程在无训练的情况下提升BERT预训练句表示在文本语义相似度任务上的表现,并分析不同模板对句向量的影响,发现标点使用对BERT模型句向量存在很大影响。基于上述分析,本文提出基于模板数据增强的无监督对比学习模型,该模型使用模板中的[MASK]符号输出层向量作为句表示,并在维基百科语料上使用归一化温度控制交叉熵损失函数(NT-Xent)进行无监督对比学习。模型在多个文本语义相似度的公开数据集上进行实验,验证了该方法对于改善BERT句表示的有效性。
{URL}: https://link.cnki.net/doi/10.27405/d.cnki.gxbdu.2022.001744
{DOI}: 10.27405/d.cnki.gxbdu.2022.001744
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理技术的建筑工程安全事故风险研究
{Author}: 兰志成
{Tertiary Author}: 崔志明;吴俊
{Publisher}: 苏州科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理技术;风险分析;安全管理;神经网络;事故报告
{Abstract}: 长期以来,建筑工程中安全事故频繁发生所导致的人员伤亡和财产损失,受到国家和社会的广泛关注。为了防止类似事故的发生,在每次事故发生后会形成事故调查报告,通过从历史事故中总结经验教训,从而制定安全管理策略和防范措施用于预防未来的风险发生。而以往对事故的分析研究依赖于专家利用专业知识进行人工分析,这使得分析结果很容易受到人的主观影响。同时,随着事故报告数据量的不断增加,人工分析耗时耗力,已经无法满足需求。因此,采用自动化的方法分析建筑工程安全事故对安全管理至关重要。面对这些通常以非结构化或半结构化形式存在的事故报告,当前研究普遍使用浅层机器学习结合手工提取文本中词语、句法和语义特征的方法,存在学习性能差以及信息抽取精确率不足的问题。针对上述问题,本文基于自然语言处理技术,开展事故类型与风险因素自动抽取的模型研究,并将其用于安全风险分析。具体研究内容如下:(1)针对事故报告中长距离词语之间依赖信息无法捕捉的问题,提出一种基于图神经网络的文本分类算法,用于从报告中抽取事故类型。首先,根据事故报告中词语共现关系,将序列化文本转化为图结构数据;然后,利用LSTM网络将词语节点与周围邻居节点进行信息交互,通过设置多层LSTM实现高阶邻居节点的信息捕捉;最后,通过注意力机制将词语节点信息聚合为整个报告的图表示用于分类。在所构建的篇章级文本分类数据集上进行实验,获得92%的平均F1值,验证了我们所提算法的有效性。(2)针对现有方法无法有效提取建筑事故报告中风险因素的问题,提出一种结合多层次神经网络与启发式规则的模型,实现事故报告中风险因素的抽取。首先,使用预训练语言模型BERT获得文本的字符级向量表示;然后,使用CNN与BILSTM,分别提取上下文的局部与全局特征信息;接着利用CRF学习标签之间的依存关系,完成文本中的风险实体抽取;最后,在此基础上根据7种启发式规则提取事故报告中风险因素。在所构建的句子级实体标注数据集上进行实验,模型在风险实体和因素抽取任务上分别获得了91.4%和86%的F1值性能,表明该模型具有较好竞争性。(3)面向建筑施工安全管理需求,基于上述事故类型与风险因素抽取结果进行关联分析,构建了一种建筑安全事故风险分析系统。根据输入的不同,系统主要实现风险分析与数据库更新功能。其中,风险分析功能根据输入的隐患排查文本,给出可能导致事故发生的已知风险因素、潜在风险因素以及事故类型;数据库更新功能根据输入的事故报告集,对关联规则库自动更新。通过对搜集到的事故报告数据集提取事故类型与风险因素,并对两者关联分析后,得到256条关联规则。相关测试表明,所构建系统可以满足实际应用需求。本文结合自然语言处理技术面向建筑工程安全管理环境下的实际需求,有效改善了事故风险分析中信息抽取困难以及精确率不足问题。测试结果表明对安全事故报告中事故类型以及风险因素的抽取效果均有一定程度上提升,为建筑工程安全管理领域提供有效的帮助。
{URL}: https://link.cnki.net/doi/10.27748/d.cnki.gszkj.2022.000094
{DOI}: 10.27748/d.cnki.gszkj.2022.000094
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多任务学习的中文分词序列标注方法研究
{Author}: 吕书宁
{Tertiary Author}: 徐金安
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多任务学习;中文分词;序列标注;神经网络;自然语言处理
{Abstract}: 中文分词作为自然语言处理(Natural Language Processing,NLP)领域的奠基性任务,是学术界的重点研究方向,其效果是影响后续下游任务发展的关键因素。近年来,得益于深度学习在各领域的广泛应用,基于深度学习神经网络的分词算法受到许多关注认可。该方法采用大量标注数据训练,区别于传统方法利用规则或统计的模式,使得模型的泛化能力大幅提升,但仍存在分词规范不清晰、歧义切分和未登录词识别等难点;中文分词任务有很强的领域适应性,标注语料耗费大量资源且许多领域根本无法提供大规模数据,为各领域均构造专属语料库非常不现实;传统NLP任务采用管道模型,将分词看作独立的单任务再作为后续工作的输入。这种模式无法避免错误传播的缺点,不能有效实现任务间信息资源共享,严重影响后续任务学习效果。因此,如何克服传统分词方法的困难,解决管道模型错误传播问题,以及缓解领域数据资源稀缺并提高领域适应性,是目前亟待解决的问题。针对上述挑战,本文提出基于多任务学习的中文分词序列标注方法,通过将分词及相关序列标注任务进行联合学习的模式,打破传统管道模型壁垒,为任务间的信息共享提供渠道,缓解资源稀缺问题,将珍贵资源最大化利用,达到多个任务彼此助益,提升领域及任务适应性和学习效果的目的。本文的主要贡献如下:(1)分析主流单任务神经网络框架不足,针对BiGRU-CRF系统进行改进。增加预训练语言模型并结合卷积神经网络,得到BERT-BiGRU-CRF及BERTBiGRU-CNN-CRF框架。聚焦语境信息学习语义特征,感受野获取隐藏局部特征。(2)提出多任务学习序列标注框架。引入命名实体识别和词性标注作为辅助任务,组成序列标注任务联合模型。分别基于联合损失函数、参数共享、标签一致性机制三种多任务学习阶段,递进性探索研究,得到多任务共享信息的最佳模式。(3)提出基于多任务学习的中文分词序列标注方法,设置预训练标注、多任务共享学习、联合训练三大模块。针对领域数据资源稀缺问题,构建多任务学习特殊数据集,任务间共享数据信息,增大资源利用率,提高任务及领域适应性。(4)提出基于标签一致性机制的损失计算模式。训练中引入词汇信息强化实体边界,强调边界信息的学习,达到词汇增强的目的。有效缓解规范问题和歧义切分难点,同时减轻未登录词识别问题。方法在小样本低资源的领域效果更为显著。实验结果表明本文方法的有效性及解决分词难点、管道模型错误传播缺陷、资源稀缺问题、提高领域适应性的能力,更好接轨单模型解决多问题的领域发展趋势。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.002556
{DOI}: 10.26944/d.cnki.gbfju.2022.002556
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理技术的建筑工程合同风险条款自动提取研究
{Author}: 蔡翟源
{Tertiary Author}: 盛胜利（Victory Sheng）;杨敬晶
{Publisher}: 苏州科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 建筑工程合同;自然语言处理;风险管理;合同审核;建筑智能化
{Abstract}: 随着建设项目规模的大幅增长以及工程复杂程度的增加,为确保参与各方之间的合同地位和权利,对施工合同的撰写和审查提出了更高的要求。大多数国际建设项目都要求合同管理团队在招标期间审查合同中可能存在的所有风险。然而,面对如此庞大的建筑合同文本,在短时间内审查其中的风险是非常困难的,因此亟需一种自动化审核工具来辅助人们完成工作。但是,目前的自动化审核工具大多只能审核最基本的格式问题,无法审查语义风险;并且大多数系统都是面向通用领域的,很少有面对建筑领域设计的专有自动化审查系统。有鉴于此,本文基于自然语言处理技术开展了建筑工程合同风险条款自动提取的研究工作,工作内容划分如下:(1)针对建筑合同文本高度抽象、语义信息复杂的问题,提出ALBERT-Bi LSTMAttention-CRF模型进行合同文本的实体识别。该模型利用ALBERT表征词汇,使用Bi LSTM和Attention提取文本特征,运用CRF解码模块预测实体标签。通过实验验证,该模型在自建的建筑工程合同数据集中,综合F1值达到了87.2%;对比现有模型,实验效果最佳,并且相较于BERT预训练模型,拥有参数量小、训练耗费少的优点。(2)针对建筑合同文本多关系分类的问题,提出一种结合实体位置的BERT+Multi-head关系提取模型。该模型将实体位置信息融入BERT预训练模型中用于提取文本特征,然后利用Multi-head多头分类器完成多种关系的分类。对比没有融入实体位置信息和使用线性关系分类器的模型,在自建的建筑工程合同数据集上,本文提出的模型F1效果最好,且多头分类器的引入减少了内存空间的开销。(3)面向建筑工程合同风险自动化审查的需求,本文结合了自然语言处理技术构建了风险条款自动提取系统。首先使用语义检索和数据挖掘技术挖掘风险来源、关联相关法律条文,然后定义建筑工程合同风险等级并制定风险条款匹配规则库,最后使用语义相似度技术提取风险条款。经过实际测试,系统识别效率较高,可以满足工程应用需求。本文使用自然语言处理技术,面向建筑工程合同风险条款自动提取任务需求,经过文本信息抽取、风险源识别与风险等级定义、风险规则库与匹配机制的制定等流程,最终完成了一种面向建筑领域的工程合同风险条款自动化提取系统。从而支持建筑企业的智能风险管理,推进了建筑领域的智能化,具有较大的实际应用价值。
{URL}: https://link.cnki.net/doi/10.27748/d.cnki.gszkj.2022.000593
{DOI}: 10.27748/d.cnki.gszkj.2022.000593
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于政策文本和基金项目的研究前沿识别研究
{Author}: 牛晓蓉
{Tertiary Author}: 刘艳丽
{Publisher}: 中国科学院大学(中国科学院文献情报中心)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 研究前沿;政策文本;基金项目;LDA模型;指标体系
{Abstract}: 随着科学技术的快速发展,其在国家发展过程中的作用日益凸显,发展高科技成为大国之间战略竞争的重要手段。然而每个国家的科技资源都是有限的,一个国家不可能对所有的科研领域进行支持。因此,科学研究前沿的洞察和识别,对于科研管理者和政策制定者掌握科研的进展和动态,以有限的资源来支持和推动科学进步具有重要意义。传统的基于单一数据源(例如基于论文或专利等)的研究前沿识别结果可能会由于数据单一或限制存在时滞性、局限性等问题。本研究从多源数据融合的角度,将研究前沿识别的数据源拓展到更具前瞻性和战略性的政策文本和科研基金项目数据,采用自然语言处理、文本挖掘等方法进行主题识别,并构造判断研究前沿的指标体系,形成一套较为系统、完整的方法,可以识别某一领域的科学研究前沿,丰富现有的研究前沿探测理论,拓展研究方法体系。本研究梳理了研究前沿的概念、识别方法、数据源、基于政策文本和基金项目的研究前沿判别指标等,阐述了LDA主题模型和Critic客观赋权法的原理,在此基础上构建了基于政策文本和基金项目的研究前沿识别模型。从政策文档库和基金项目网站分别获取两类数据,采用主题模型识别两类数据的研究主题,通过计算JS散度归并两类数据中的共同主题,区分非共同主题;根据政策文本发布的时间、文档数量和基金项目的立项时间、立项数量、资助时长、资助金额等属性分别构造两类数据源中主题的新颖度和主题强度,共同主题在计算指标时还需对两类数据赋予不同的权重来区分其在研究前沿识别中的重要性差异,通过指标判别得到热点、新兴、潜在研究前沿、非研究前沿主题。本文以人工智能领域为例进行实证研究,通过本文构建的模型,得到了20个热点研究前沿主题、4个新兴研究前沿主题、3个潜在研究前沿主题以及2个非研究前沿主题,通过对论文数据进行时间切片的主题分析以及共被引聚类分析,发现有些研究主题比如人工智能在流行病预测、传播和治疗等方面的应用,确实在政策文本和基金项目中出现的时间相对于论文更早,以及本研究识别出的计算神经科学、网络安全、社交媒体等主题并未在论文数据中形成聚类簇,并通过最新的研究报告数据进一步证明了本研究结果的有效性。本研究的创新之处在于:(1)本研究充分利用政策文本的发布时间、文档数量,以及基金项目的立项时间、立项数量、资助时长和资助金额等外部特征信息,采用客观赋权法对上述特征信息指标赋予不同的权重,构建前沿主题新颖度和主题强度等判别指标,使指标体系更加合理完善。(2)本研究充分考虑不同数据源对研究前沿识别的不同贡献,对政策文本和基金项目识别出来的研究主题赋予不同的权重;此外,还考虑了不同层面的政策文本对研究前沿识别的不同贡献,对其赋予不同权重,以此区分不同类型数据源在研究前沿识别中的重要程度。本研究存在一些局限和不足:(1)在主题识别上,采用目前广泛使用的LDA模型,识别的粒度不够精细,未来可借助深度学习方法更好地挖掘语义内容,便于解读。(2)对政策文本和基金项目两类数据源的融合,仅体现在各自进行主题识别后,利用构建的指标对两类数据识别的主题进行融合识别,未来可将融合前置,进行实质的语义层面的融合。(3)由于缺乏权威且全面的政策文本数据来源,政策文本数据采集不全面,可能会对研究结果产生影响。(4)研究前沿的识别应该是全球的,本研究由于数据的获取难度、语言等因素,在实证研究中,仅选取了人工智能领域处于领先地位的美国来做分析,是有所欠缺的,未来可进一步丰富数据源,得到更为全面的结论。(5)政策文本和基金项目二者是相互促进、循环发展的,后续应继续探讨二者之间是如何相互影响的。
{URL}: https://link.cnki.net/doi/10.27600/d.cnki.gwqbz.2022.000005
{DOI}: 10.27600/d.cnki.gwqbz.2022.000005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向文本的对抗攻击与防御技术研究
{Author}: 朱斌
{Tertiary Author}: 顾钊铨
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;自然语言处理;文本分类;对抗攻击;对抗训练
{Abstract}: 近年来,随着深度学习相关理论与技术的飞速发展,深度学习模型已经逐步在现实世界中被大量应用与部署。随着研究的不断深入,研究者发现深度神经网络在恶意制造的对抗样本面前表现出了极大的脆弱性。只需在输入样本中添加微小的、人类无法察觉的扰动,深度学习模型便会出人意料的给出错误预测。为了进一步理解深度学习模型的安全性问题,研究者们首先从模型的内部结构与信息出发,在白盒设置下以极高的成功率误导图片分类等模型。随后,研究者又提出了许多黑盒攻击算法,根据模型的输入与输出,分别从模型的输出置信度、对抗样本的迁移性等方面入手,在不了解模型内部结构和信息的设置下,成功攻击了深度学习模型。为了提升模型对于对抗样本的防御能力,研究者开始关注深度学习模型的鲁棒性,一系列经验性或可验证的防御方法被提出,用于提升模型的对抗鲁棒性。本文关注自然语言处理领域。目前面向自然语言处理模型的防御算法仍比较少。模型在面对攻击时的防御能力极为弱小。考虑到攻击与防御是密不可分的,本文首先从攻击者的角度出发,分别在白盒与黑盒设置下提出了两种隐蔽性更强的攻击算法;接着从防御者的角度出发,提出一种经验性的对抗训练防御算法。本文将攻击与防御紧密结合,给出了对抗学习的新见解,在以下方面具有创新性:1.基于模型梯度的白盒攻击算法。在白盒设置下,利用模型梯度,本文在单词的词嵌入上添加梯度方向的微小扰动,对单词进行重要性排序。为了寻找最优替换词,本文对词嵌入进行最近邻搜索,找到使模型最可能出现错误决策的单词,完成白盒的文本对抗攻击,解决了词嵌入攻击可能无法对应原始单词的问题。2.基于迁移性的黑盒攻击算法。在黑盒设置下,基于对抗迁移性,本文从替代模型挑选脆弱性单词。为了更好地探索搜索空间,本文改进了传统的波束搜索,应用多重扰动位置以全面地探索样本空间,实现了更有效的黑盒攻击算法。3.基于几何感知的对抗训练算法。本文基于对决策边界的感知,生成靠近决策边界的友好对抗样本,并在友好对抗样本上应用对抗训练算法,在减少搜索步骤、不影响原始准确率的同时,显著提升了模型鲁棒性。本文同时通过大量实验验证了上述方法的有效性,并和前沿的对抗攻击、防御算法进行了比较,实验结果也验证了本文所提方法的优势。本文希望通过对自然语言处理领域对抗攻击与防御的研究,提升文本处理模型的鲁棒性和安全性,为深度神经网络在文本领域的安全应用提供支持。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2022.001335
{DOI}: 10.27040/d.cnki.ggzdu.2022.001335
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的微博文本分类研究
{Author}: 柳子旭
{Tertiary Author}: 狄巨星
{Publisher}: 河北建筑工程学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 文本分类;深度学习;循环神经网络;预训练语言模型
{Abstract}: 自2019年受新冠肺炎病毒出现,越来越多的人在家进行隔离,这种背景下,互联网成为了更主要的信息传播渠道。人们比以往更高频率在社交平台表达自己的看法和情绪。获取其中情绪的信息,对政府舆情监测打赢舆论战具有重要作用。而微博作为最大的中文社交平台,是主要的信息获取途径。传统词典分类法和机器学习分类法,有着需要过多人工干预并且无法应对大数据量任务的局限性,而深度学习的高效性更具有竞争力。目前循环神经网络(RNN)等结构已广泛应用在文本分类中,但仍存在可优化方向:虽然RNN变体结构一定程度减少了梯度弥散或爆炸的概率,但局部信息关注度较低;其次特定领域的分类任务中,只是调整网络模型并没有对具体问题进行分析;部分预训练模型在应用时忽略了上下游任务间语种表达习惯的影响。根据以上内容,本文的主要研究内容如下:(1)针对RNN处理长序列依赖关系时局部关键信息影响随迭代逐渐减弱的缺陷,本文将限制单个神经元计算信息流长度的中断机制,融合进双向门控循环单元(BGRU),并为隐藏状态输出进行最大池化和平均池化,这种结构在保留RNN变体结构优点的同时增强了对局部信息的提取,并在学习局部极端数据时,减少模型过激调整。为了减弱中断机制对语义切割产生的影响,在词向量生成过程引入多头自注意力机制(Multi-headed Self-attention),提出一种新的网络结构MT-D-BGRU,对具有关联性的字词施加更高权重,使模型具有时间感知和空间感知能力。通过4项评价指标证明了这种结构分类性能优于多组对比实验。(2)针对社交平台文本的特殊性,提出了一种新的数据清洗策略。在这种方法中,对表情和标点并没有直接进行删除操作,而是进行了分情况讨论。删除了对情感没有影响的标点等符号,将剩余信息一一对应的替换为特殊占位符,让模型以词组的形式来识别这些内容,进而更完整的获取文本情感。并应用在后续对比实验中,证明了其有效性。(3)为了使语言模型考虑不同语言中语法差异造成的影响,本文运用了增强知识语义模型(ERNIE),使生成的词向量更完整的保存中文语义,并优化了遮罩层处理数字信息的逻辑,减少了数字信息对情感不必要的干扰。之后结合深度金字塔网络(DPCNN),增强了模型应对长序列文本时的局部信息提取能力。最后本文提出的ERNIE-DPCNN结构在两组数据集的多次对照实验中,取得了更好的分类效果,证实了本文提出优化方案对模型有提升作用。
{URL}: https://link.cnki.net/doi/10.27870/d.cnki.ghbjz.2022.000101
{DOI}: 10.27870/d.cnki.ghbjz.2022.000101
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的机器阅读理解技术研究
{Author}: 白子薇
{Tertiary Author}: 王小捷
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 机器阅读理解;预训练语言模型;深度学习
{Abstract}: 阅读理解自然语言文本是人类重要的语言处理能力,让智能机器具有与人类类似的阅读理解能力是人工智能研究者长期的梦想之一。具有阅读理解能力的机器可以极大地缓解人们日益增多的文本信息处理负担,具有广阔的应用前景。作为发展高级阅读理解能力的第一步,研究人员在二十多年前就提出了 机器阅读理解(Machine Reading Comprehension,MRC)任务,即给定无结构自然语言文本,机器能基于此回答与文本相关的自然语言问题。二十多年来,MRC研究取得了长足的进步,尤其是近年来,大规模预训练语言模型以其强大的从海量语料中进行学习的能力极大地推动了自然语言处理的研究进展,在MRC任务上也取得了不少重要的成果。但是,由于MRC任务本身的复杂性,现有研究仍存在一些问题亟待解决。首先,从模型的结构来看,现有模型存在对内部知识利用不足、缺乏对外部知识有效利用的问题。例如,具有多层结构的预训练语言模型被认为在不同层蕴含了不同类型的语言知识,但是,目前的阅读理解模型在利用不同层次知识方面还缺乏有效的结构;从模型的训练来看,现有模型存在着依赖大规模领域内数据集、跨领域迁移能力差以及答案提供的监督信号不充分等问题。例如,当领域内阅读理解数据资源稀缺时,经典监督学习方法通常表现不好。本文在综述相关研究工作的基础上,针对上述问题展开了一系列的研究,主要内容和成果如下:提出了一种能对预训练语言模型多层信息进行自适应选择和决策的阅读理解模型。通过在预训练语言模型的不同层构建决策模块,模型能够自适应地选择不同层次的编码表示来回答不同类型的阅读理解问题;为避免在模型微调过程中不同层次的信息多样性被多个相似的监督信号损坏,本文提出了一种学习率衰减方法来减弱监督信号对低层参数的影响。在公开数据集上的实验结果表明,本文提出的模型在性能和推理速度上均优于基线模型。进一步对不同层所正确回答的问题进行定量和定性分析发现,本文提出的模型可以较好地为需要不同类型信息的问题选择包含该类信息的层进行回答。提出了一种能显式利用外部知识的算术阅读理解模型。将外部数字引入算术阅读理解模型中,并提出一种外部数字的动态表示方法,以在生成算术表达式时,能正确选择外部数字;同时,本文还提出了一种基于数字关系的注意力机制,通过比较数字之间的二元关系,来辅助模型更准确地选择算术表达式中的操作数和操作符。在公开数据集上的实验结果表明,本文所提出的外部数字动态表示方法和基于数字关系的注意力机制能帮助模型生成更准确的算术表达式,取得更好的性能。提出了一种基于多源知识学习的跨领域阅读理解模型。首先,提出了一种多任务变换器网络,可以同时在领域外阅读理解数据集和领域内自监督数据集上学习任务知识和领域知识,并降低任务噪音;其次,提出了一种“直接领域自适应”方法和一种“间接领域自适应”方法来降低领域噪音。在公开数据集上的实验结果表明,本文所提出的方法能提升模型在低数据资源阅读理解任务上的性能,只用一半的数据就能达到其它模型在全量数据上训练的结果。提出了一种基于辅助任务的阅读理解模型。模型利用证据抽取任务与片段选择任务之间的相似性,将片段选择任务作为辅助任务,并设计了一种可导的软提取方法,来帮助模型在解决“是/否”类任务时,能同时关注篇章中与问题相关的片段,过滤掉无关片段。在公开数据集上的实验结果表明,本研究提出的模型不仅能提升“是/否”类任务上的性能,还能对答案给出解释信息。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.000277
{DOI}: 10.26969/d.cnki.gbydu.2022.000277
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的股票趋势预测模型的研究与实现
{Author}: 闫昊宇
{Tertiary Author}: 万能
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 股票预测;情感倾向分析;生成式对抗模型;BERT;优化器
{Abstract}: 中国经济的快速发展带动了金融市场的繁荣,股票市场作为金融领域重要的投资方式具有复杂、多变的特性,其未来走势受行业发展前景、历史价格信息、国家政策法规等诸多因素影响,股票预测也成为相关专家学者与市场投资者不断探索的课题。本文通过对股票未来走势影响因子的全面分析,在行情面数据基础上增加了资金面、市场面及技术指标面等相关数据类型,构建了数值方面的基础数据集。同时,由于新闻报道等股票情绪化风向内容对市场的高度影响,本文通过爬取目标股票每日相关研报,利用自然语言处理领域中的情感倾向分析技术,对爬取的研报文本进行情感分析,从而为股票趋势预测模型提供文本数据集的因子输入。模型方面,本文摒弃传统的单一时序预测模型,引入生成式对抗模型GAN这一更匹配股票市场运转逻辑的模型框架,提出文本辅助的生成对抗网络股票预测模型STP-GAN。该模型同时利用数值数据集与文本数据集,在GAN模型的基础上增加了 Text Pathway,将股价预测与情感倾向分析结合为同步的一体的网络结构,从而减少了模型训练的误差累积。同时,STP-GAN模型引入Transformer结构,更好提升对股票相关数据特征的学习能力。此外,STP-GAN利用BERT进行金融领域微调,并加入金融词典,以增加模型对特定金融领域的适配性。本文在提出STP-GAN的基础上,对模型训练采取了进一步的优化提升。针对GAN网络的难收敛性与易过拟合性,本文提出更适用于本课题研究背景下的新型优化器RMSPropW。该优化器将指数加权的移动平均作为衰减系数中的梯度积累,且利用weight decay,提升了预测模型的训练稳定性与训练速度。实验论证方面,本文依据上述章节构建的核心模型详细设计了多组对照实验证明了 STP-GAN模型与RMSPropW优化器的有效性。在市场回测验证中,本文构建了基于zipline的量化回测平台,通过交易策略与大盘指数的对比证明了 STP-GAN模型良好的市场应用价值。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.002556
{DOI}: 10.26969/d.cnki.gbydu.2022.002556
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于模型的需求文档自动生成研究
{Author}: 包天舒
{Tertiary Author}: 杨静
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: UML;OCL;需求模型;需求文档;文档生成
{Abstract}: 需求文档是贯穿软件生命周期的一个重要工件。作为客户和开发人员之间的共同协议,需求文档用于客户对需求的审查与确认。面对模型驱动开发中需求文档的缺少,从模型生成需求文档被广泛研究。当前面临的主要问题是模型附带的对象约束语言(Object Constraint Language,简称OCL)约束解释困难以及单个模型图生成的需求文档信息不足,本文研究基于模型的需求文档生成,具体工作如下:(1)针对模型附带的OCL约束解释困难的问题,本文提出一种从OCL合约生成自然语言解释的方法OCL2NL。首先,根据OCL表达式在合约中的不同作用将其划分为15种基本操作,对每种基本操作制定不同的转换规则。通过应用这些转换规则,将OCL表达式映射为解释其语义的自然语言;其次,根据OCL合约签名部分的输入参数和返回类型的信息,在合约中找到解释这些信息的表达式,应用转换规则将表达式映射为自然语言,从而生成参数描述和结果描述。在四个案例中进行了实验,结果表明,97.06%的OCL表达式和87.68%的OCL合约签名可以成功生成自然语言,经过人工评估,生成的自然语言可以有效地解释OCL。(2)针对单个模型图生成的需求文档信息不足的问题,本文提出RM2Doc方法。首先RM2Doc以概念类图、用例图和系统序列图多个模型图作为输入,将各个模型图生成的自然语言需求密切联系起来,形成一份生成结构清晰的需求文档。其次,作为RM2Doc的一部分,OCL2NL根据系统操作合约生成自然语言,这些自然语言需求被组织到需求文档中以完善文档中的需求信息。对四个案例进行案例研究,结果表明,除了19.57%的系统操作说明中出现部分内容生成失败之外,其他各个部分都可以成功生成。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.001141
{DOI}: 10.27047/d.cnki.ggudu.2022.001141
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于情感分析的个性化推荐研究
{Author}: 代雨聪
{Tertiary Author}: 吴志刚
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;文本情感分析;深度学习;用户偏好;个性化推荐
{Abstract}: 随着网络对人们生活方式的影响越来越大,人们可以在社交平台中直接发表自己的看法,也可以在电商平台中对一些自己使用过的产品发表一些建议。人们的情感信息都隐藏在这些文本评论中,通过人工智能手段可以从中挖掘出有价值的信息特征,这些信息对企业、社会的发展也有很大的帮助。自然语言处理技术的应用领域包括情感分析、机器翻译、语音识别等等。情感分析使用特征提取和情感分类两种主要方法对用户的文本信息进行处理。在推荐系统领域中可以基于用户对商品的显性评分做物品推荐,也可以通过情感分析的技术对用户做一些个性化推荐。通过挖掘用户历史行为数据信息进行个性化推荐,不仅能够提升用户的体验感,而且还能为商家带来收益,也能够进一步优化服务系统。因此本文选择Amazon平台中的电商数据进行情感分类任务,并且基于情感分类任务中的情感分析模块进行个性化推荐,主要的研究内容如下:(1)本文设计了BERT-CNN-Bi GRU(BCB)情感分类模型,该模型主要解决了静态词向量表达能力不足问题和传统情感分类模型对文本的情感特征提取能力不足的问题。在文本的预处理阶段中,经过去重,分词等处理后,使用BERT预训练模型来获取动态词向量,这种方法不仅将位置信息、词性信息等特征融入到词向量中,而且还能够得到更深层的词语特征信息,也能很好地缓解中文语义偏差问题,使得词向量具有更加丰富的语义特征。在情感分析模块,使用CNN与Bi GRU的组合神经网络模型提取用户评论文本中的特征信息与情感特征。其中CNN网络适用于获取文本的局部特征,Bi GRU网络提取文本的上下文语义,将两种不同特征进行组合,能够得到深层次的信息特征,提高情感分类模型的性能,这种方法能够弥补单一的CNN网络或者Bi GRU网络提取情感特征的不足。最后在公开的Amazon电商数据上进行实验,实验结果表明BCB模型优于其它对比模型,提高了情感分类的性能。(2)本文设计了CNN-Bi GRU-FM(CBF)个性化推荐模型。很多传统的推荐模型都是基于用户显性评分去做物品推荐,忽略了用户评论文本中包含的隐藏的用户信息和商品特征信息,也不能很好地解决数据稀疏的问题。该模型在编码层中使用上文情感分类模型中的情感分析模块,充分挖掘用户评论文本得到用户和商品的特征信息,同时也可以缓解数据稀疏的问题。首先将中文文本向量化,然后在编码层中提取用户特征和商品特征,将两种不同特征空间的向量通过特征融合层进行特征融合,并且进行特征排序,最后输出用户预测商品的评分。经过实验表明,该模型与设置的对比模型相比推荐精度更高,提升了推荐性能。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000592
{DOI}: 10.27012/d.cnki.gdhuu.2022.000592
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图卷积神经网络的方面级情感分析研究
{Author}: 刘欢
{Tertiary Author}: 窦全胜
{Publisher}: 山东工商学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 方面级情感分析;情感极性;邻域表征;卷积神经网络;注意力机制;先验知识;图卷积神经网络
{Abstract}: 随着科技的发展,社交网络变得日益繁荣,如何从海量文本信息中挖掘用户所表达的情感引起学者们的广泛关注,成为自然语言处理(Natural Language Processing,NLP)领域的研究热点。情感分析分为文档级、语句级和方面级三类,文档和语句情感分析分别将整篇文档或文档中的具体句子作为分析对象,常用于产品评价、影评和视频字幕等场景的文本内容情感识别。方面级情感分析(Aspect-based Sentiment Analysis,ABSA)旨在判断句子中的单词或短语的情感极性,以便更细腻分析句子或文档所蕴含的感情色彩,这里的单词或短语通常称之为“方面”(Aspect)。目前,基于深度神经网络的方面级情感分析已经成为研究主流,将其与其它编码结构结合,构建的深度网络模型受到了许多学者的青睐,但目前关于情感分析的研究方法,无法同时关注方面词的上下文和语法信息,且未引入语句的语义信息,导致模型无法正确判断方面的情感倾向。传统的情感分析方法可以提取具有固定几何关系的数据特征,而现实中存在许多含有图结构的数据信息,图卷积神经网络可有效捕捉图结构的依赖关系。因而本文以图卷积神经网络为基础,融合方面的不同邻域信息和语句的语义信息,进而构建不同的方面级情感分析模型,以捕获判定情感极性的关键特征,提高模型性能。本文的主要工作包括:(1)提出嵌入不同邻域表征(Embedding Different Neighborhood Representations,EDNR)的方面级情感分析模型。采用卷积神经网络并结合近邻策略来获取方面邻域信息,减小较远无关信息对情感极性的影响。同时,利用图卷积神经网络提取节点邻域信息,以获取句子的语法依赖关系。将两种邻域表征信息融合后,使用注意力机制对确定方面情感极性的重要信息进行特别关注。文中还提出一个信息评估系数,来评价上下文和语法信息对情感极性的影响程度。在5个公共数据集上进行实验,实验结果表明EDNR模型的有效性。(2)提出融合先验知识(Incorporate Prior Knowledge,IPK)的方面级情感分析模型。构造单词之间的知识图,利用图卷积神经网络来捕获知识图的依赖信息。根据输入文本,获取单词的词性信息。将词性特征与知识信息进行融合,可获得最终的先验知识特征表示。IPK模型为每个单词提供相应的语义和词性信息,减少了语句中情感信息表述模糊带来的不良影响,有效判别复杂自然语句中的方面情感极性。在标准数据集上与其它模型进行对比实验与分析,实验表明该模型可获得较高准确率和F1值。本文所提模型能够有效提取图结构的数据特征,且获得更丰富的情感信息编码,改善网络的方面级情感分析效果,推进ABSA任务在社交平台、电商平台或舆情平台等场景中的应用。
{URL}: https://link.cnki.net/doi/10.27903/d.cnki.gsdsg.2022.000122
{DOI}: 10.27903/d.cnki.gsdsg.2022.000122
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于蒙古语学术语体语料库的句法计量研究
{Author}: 乌优坛
{Tertiary Author}: 达胡白乙拉
{Publisher}: 内蒙古大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 蒙古语学术语体;依存树库;句法特征;复杂网络;计量研究
{Abstract}: 在大数据时代背景下,基于语料库的语言研究成为研究热点。基于语料库的句法研究是自然语言研究的重要组成部分。语料库作为提供语言信息的知识库,在自然语言处理研究中起着重要作用。随着社会发展,不同学科领域的理论与方法相互影响,开始将数学的概率论、统计学等的研究方法运用到语言研究当中,形成了计量语言学这一新的分支学科。计量语言学以真实的语言活动中产生的言语材料为研究对象,力求通过定量方法来探索语言的结构模式与演化规律。本文以现代蒙古语学术语体语料库作为基础,采用计量方法研究现代蒙古语学术语言句法特征,主要包括句长、依存关系特征、词类句法功能和句法网络特征,尝试回答以下几个问题:(1)现代蒙古语学术语言有哪些句法特征、规律?(2)现代蒙古语学术语言词类句法功能分布情况如何?(3)现代蒙古语句法特征在不同语体之间是否存在差异?(4)现代蒙古语学术语体句法网络有哪些特征?文章由六个章节组成。第一章,介绍了研究意义、研究现状、研究理论与方法和研究内容与步骤等内容。第二章,介绍了现代蒙古语学术语体语料库的设计、创建以及加工步骤,并从词汇、词类和句式等角度做了相关统计研究,归纳了蒙古语学术语言在词汇、词类和句式方面的特征和规律。第三章,研究分析了蒙古语学术语言句法特征。主要使用现代蒙古语学术语体语料库的平均句子长度、句子长度分布特征、依存关系类型、依存关系类型分布特征、依存距离、依存距离概率分布、依存方向、词类句法功能等句法指标对蒙古语学术语言句法特征和规律展开研究。第四章,基于蒙古语不同语体依存树库,比较分析了蒙古语句法特征的语体差异。主要分析研究蒙古语不同语体的平均句子长度、句子长度分布特征、依存关系类型、依存关系类型分布特征、依存距离、依存距离概率分布、依存方向、各词类句法功能等方面的语体差异,力图突出蒙古语学术语言的特征和规律。第五章,基于现代蒙古语学术语体依存树库,使用复杂网络方法,构建了现代蒙古语学术语体句法网络。并分析了学术语体句法网络的基本参数特征以及复杂网络特征。第六章,总结全文,并对后续研究工作进行了论述。本文创建了现代蒙古语学术语体语料库,拓展了基于蒙古语语料库的研究领域,并通过计量方法得出的结果为理论性研究结论提供了客观数据佐证,以推动语言研究更加深入发展。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2022.001642
{DOI}: 10.27224/d.cnki.gnmdu.2022.001642
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 中文文本纠错关键技术研究
{Author}: 林楠铠
{Tertiary Author}: 蒋盛益
{Publisher}: 广东外语外贸大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 汉语语法纠错;汉语拼写纠错;语法纠错评估;参数共享;语法泛化
{Abstract}: 中文文本纠错是中文自然语言处理的一项挑战任务,该任务旨在检测并纠正使用者在使用汉语时产生的文本错误。随着自然语言处理的发展与端到端模型的出现,中文文本纠错研究取得了明显的进步。在汉语语法纠错任务上,现有的标注语料规模仍然较难支撑起端到端模型的训练,因此,近年来的研究主要集中在数据增强研究方面,极少有研究去通过降低模型的训练难度以适配现有的语料规模。此外,目前的汉语语法纠错评价体系存在不足,评价结果在一定程度上受中文分词算法的影响,针对汉语语法纠错任务需要深入探究更合理的评价体系。针对汉语拼写纠错任务,现有的研究只关注于模型的纠正能力,而忽略了对模型的易混词识别能力的关注与训练。为了使汉语语法纠错任务有更合理的评价方式,同时解决汉语语法纠错模型训练困难的问题,本文从汉语语法纠错任务的评估与模型改进出发,研究针对汉语语法纠错任务的评估框架与模型优化方法,同时利用拼写纠错模型辅助语法纠错任务,主要内容包括:(1)面向汉语语法纠错的评估框架。本文针对现有评估指标与评估框架的不足,对NLPCC提供的测试集进行了人工标注与扩充,使原有测试集样本的黄金标准校正注释集可以包含更多的修正结果。针对中文语法纠错评价体系的缺陷,为中文语法纠错任务提出了三个新的评估指标。(2)基于Transformer的语法错误纠正模型。本文介绍了Transformer模型在语法错误纠正任务上的应用,并设计了多个策略提升语法纠错模型的效果,通过对比实验验证了Transformer模型的优越性能与所设计策略的有效性。(3)基于模型压缩与语法泛化的语法错误纠正模型。本文从另一个角度出发,提出了一种更易于学习的中文语法纠错模型,实验结果验证了本文提出模型的效果。此外,本文也在英语语法纠错数据集上验证了提出的模型的有效性。同时,本文进行了消融实验和参数探究实验,验证了各个策略的有效性和参数的最优值。(4)基于反向对比学习的拼写错误纠正模型。本文提出了反向对比学习策略并应用于构建拼写纠错模型,进而辅助提升语法纠错的性能。本文详细描述了反向对比学习策略,并将构建的拼写错误纠正模型用于汉语语法纠错任务的预处理与后处理阶段,验证了拼写错误任务对于提升汉语语法纠错任务效果的有效性。本文在汉语语法纠错与汉语拼写纠错任务上都取得了一定的性能提升,为汉语语法纠错与汉语拼写纠错任务提供了新的研究思路与研究方向。
{URL}: https://link.cnki.net/doi/10.27032/d.cnki.ggdwu.2022.000369
{DOI}: 10.27032/d.cnki.ggdwu.2022.000369
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本自动纠错研究
{Author}: 林浩文
{Tertiary Author}: 李金龙
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自动文本纠错;自然语言处理;深度神经网络;依存句法解析;模型集成
{Abstract}: 近几年来,自动文本纠错已经逐渐成为自然语言处理领域中的一个重要研究方向。自动文本纠错旨在通过计算机将一个带有语法错误的句子纠正成对应的正确句子。自动文本纠错技术在文书纠错,教育,数据预处理,语音识别后处理等领域具有广泛的应用。随着算力的大幅提升,深度学习的方法在文本纠错任务中占据了主要地位。在深度学习的帮助下,文本纠错的精度得到了大幅提升。目前主流的深度文本纠错方案分为两种:一种是基于序列到序列架构的文本纠错模型;另一种是基于序列标注的文本纠错模型。尽管主流纠错方案依靠数据驱动的方式已经能达到不错的纠错精度,但它们仍存在一些问题,例如主流序列到序列纠错模型没有加入句法结构信息,传统的模型集成策略和解码策略效果提升有限等。针对这些问题,文本进行如下研究:(1)我们提出了基于依存自注意力机制的序列到序列文本纠错模型:目前文本纠错任务中主流序列到序列纠错模型Transformer仅额外编码了句子中每个词的位置信息,但没有额外编码句法信息。这些信息需要Transformer在训练数据中学习。在机器翻译任务中,许多研究已表明将句法信息加入Transformer中能提升模型的翻译精度。作为句法结构高度相关的文本纠错任务,加入语法信息提升文本纠错能力是一个值得尝试的方法。不同于机器翻译任务,文本纠错任务中输入句子是语法错误的,直接对其进行句法解析会得到错误的句法信息。因此,文本提出了针对错误句子的依存解析器来提取错误句子中有效的依存信息。并通过提出的依存自注意力机制将依存信息结合到纠错模型中。本文在BEA-2019,CoNLL-2014和JFLEG测试集上进行实验,实验结果验证了该方法的有效性。(2)我们提出了基于序列标注和序列到序列的集成纠错模型:本文使用基于错误类型的编辑结合方案将序列标注纠错模型和序列到序列纠错模型进行模型集成,以充分结合两种不同纠错模型在不同错误类型上的纠错优势。文本使用验证集获得子模型在不同错误类型上的表现差异。在纠正时,让子模型仅对自己擅长的错误进行纠正,提升总体纠错精度。在集成模型的解码过程中,本文使用迭代纠错对句子进行多轮纠正,并且使用R2L重排考虑输出句子的双向流畅性。本文在BEA-2019和CoNLL-2014测试集上进行实验,实验验证了集成模型各个模块的有效性。最终的集成模型在BEA-2019测试集上获取了 76.8%的F0.5分值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.001023
{DOI}: 10.27517/d.cnki.gzkju.2022.001023
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于智慧便携脉诊仪设计的中医健康调养系统研究
{Author}: 赵楚伊
{Tertiary Author}: 王华斌
{Publisher}: 华南理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智能化中医健康;中医四诊理论;Kano模型;脉诊仪;系统设计
{Abstract}: 如今,随着经济、文化、科技的快速发展,人们的工作和生活节奏不断加快,人们每天都面临着巨大的压力,必须集中精力解决各种突发性问题和矛盾。中医在养生保健方面独具特色,对亚健康状态下的身体调养有指导作用。现代科学技术的融入与推动中医诊疗事业发展的前沿探索,与互联网的结合也是加快智能化转型的必经之路。本课题探索新的智能化中医健康调养场景,通过开发基于智能便携式脉诊仪的中医健康调养平台,实现用户在家中进行健康检测,慢病及亚健康问题长期调养,从中医的视角进行食疗调养,唤醒人们对亚健康重要性的认识,尝试传统中医现代化改造研究,为后续积累更多的健康数据,为中医智能化转型提供更好的数据支持,让用户更好的了解中医,保持健康体质,从平时的生活做起,养成良好的生活习惯。本课题在中医四诊理论以及八纲辨证的指导下,运用STP理论分析智能中医健康市场,寻找市场突破口,找到研发设计的方向及价值,并从中确定设计的可行性方案;通过用户研究法,问卷访谈等形式,分析用户对智能便携脉诊仪的需求,总结用户对智能中医健康产品的需求模式;通过KANO模型收集用户功能需求,将用户需求转化产品需求。在产品设计的过程中,运用并改进用户对中医诊断产品需求模型,同时对患者画像数据进行了预测、对功能需求进行优先级分类,从而凝练出系统定位,并为产品设计实践提供依据。在此基础上进行产品实践,从功能架构推导出信息架构,在企业实习的基础中进行用户可用性测试,分析出现有产品以及流程中存在的缺陷,进而优化升级,对产品形态及机械功能结构进行设计推敲,最终确定方案。通过建模与渲染软件进行实践、Figma软件输出产品原型,并根据原型再次进行可用性测试、分析结果,从而得出新的优化迭代方案,以此进行持续不断的研究。
{URL}: https://link.cnki.net/doi/10.27151/d.cnki.ghnlu.2022.000407
{DOI}: 10.27151/d.cnki.ghnlu.2022.000407
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的自动变速器变更设计
{Author}: 娄璇
{Tertiary Author}: 李玉良;陈萌
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;Neo4j;变更设计;自动变速器;自然语言处理
{Abstract}: 知识图谱的具体应用已经覆盖了问答查询、搜索引擎、人工智能等众多使用场景,但将知识图谱与机械行业相结合的应用相对较少。复杂机械产品在设计过程中会频繁地发生设计变更,由于设计参数之间的复杂关系将会导致设计变更过程变得极为困难,由此会造成设计成本的增加。本文从机械产品设计变更的角度出发,以自动变速器为例,提出了基于知识图谱的自动变速器变更设计方法。该方法以知识图谱中的节点来存储零部件、设计参数和计算公式,用边来表示相关信息间的关系,利用边连接节点来描述设计变更传播过程,通过该方法可以实现自动变速器的设计变更过程,并且为设计过程提供相关知识。该方法不仅为机械产品设计变更计算过程提供了一条新思路,而且在某种程度上对知识图谱应用于机械领域中具有探索意义。本文的主要工作内容如下:首先,在阅读众多的文献资料后,发现了目前国内外对通用知识图谱的研究较为成熟,而将知识图谱与机械领域相结合的研究相对较少,结合设计变更的研究现状,提出了利用知识图谱可以存储和描述复杂关系的特点来解决复杂机械产品的设计变更问题的方法。其次,通过对知识图谱的概念、构建过程和图数据库进行研究分析,结合本文的数据来源,确定了本文自动变速器知识图谱的构建流程和图数据库的存储方式,抽取得到实体、属性、关系并将其存储为三元组数据,再利用Python程序将其存储在Neo4j图数据库中,最终构建得到一个包含278个节点、510条关系的自动变速器知识图谱。然后,设计自动变速器变更设计系统。分析用户需求,根据用户需求确定了系统的总体架构和功能结构。使用Python语言及其相关开发工具完成了该系统软件的开发。该系统包含有编辑功能模块、变更设计功能模块、查询与查看功能模块。在编辑功能模块中实现了由用户上传文件实现批量创建节点和关系的构建方式。在变更设计功能模块中,不仅实现了用户手动输入的变更设计模式,并且在此基础上,采用了自然语言处理方法,结合自定义词典、停用词词典、同义词词典实现了用户输入变更语句的识别输入变更设计模式。在查询与查看功能模块中,通过分析用户查询需求、问题模板分类、创建Cypher查询语句模板等方法,并结合自然语言处理技术设计实现了自动变速器的知识问答查询功能。最后,对该系统进行测试验证。通过采用示例的方法,模拟用户分别对用户登录页面、编辑功能模块、变更设计功能模块、查询与查看功能模块中的各项功能进行功能性测试。测试结果明显证明了该系统功能的可行性和设计变更结果的准确性。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000893
{DOI}: 10.27012/d.cnki.gdhuu.2022.000893
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于情感感知与数据增强的虚假新闻检测研究
{Author}: 花璐璐
{Tertiary Author}: 曹玖新
{Publisher}: 东南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 虚假新闻检测;情感分析;时序建模;半监督学习
{Abstract}: 如今,在线社交网络(Online Social Network,OSN)凭借其独特的平等性、隐蔽性、交互的便利性、传播的快捷性等优势,为用户获取、分享、传播及交流信息提供了极大的便利。所以,相对于传统的新闻媒体,在线社交网络能够快速广泛地获得大批受众。然而,由于信息传播成本低廉以及监管滞后等问题,在线社交网络(OSN)成为了滋生大量虚假新闻的温床。社交网络中传播的各类虚假新闻,不仅对个人的生活造成了困扰,甚至会威胁社会治安及国家安全。因此,如何高效地进行虚假新闻检测成为了近年来学术界、工业界和政府机构共同关注的重要课题。情感在检测在线社交网络中存在的虚假新闻的研究中扮演着重要角色。现有虚假新闻检测工作主要侧重于挖掘虚假新闻的文本语义、行文风格、评论内容、传播结构及简单的情感极性特征,但情感信号的时变性仍未被探索。此外,由于标签数据数量不足导致的深度学习特征学习能力性能受限的问题也亟待解决。如何获取高质量的标签样本并避免因增强的标签数据带来的预测偏差,成为了基于标签数据增强的虚假新闻检测任务中的另一大挑战。针对现有研究缺乏对新闻受众情感演化的时序建模分析、特征融合方式停留在浅层加性拼接难以挖掘出特征间的深层次关联以及虚假新闻标签样本过少等挑战,本研究基于多维表示学习提出了一种新型虚假新闻检测方法。论文的具体工作如下:1.从时序角度对新闻受众的情感演化进行建模分析,并用实验验证了该特征在进行真假新闻鉴别时的有效性。区别于已有研究仅从语义、传播结构进行时序建模,或是将整个评论集视为一个长句建模情感词嵌入表示的依赖关系的工作,本研究的时序情感特征保留了单条评论作为情感表达独立单元的完整性,能够更有效地挖掘虚假新闻下的评论情感演化模式。2.设计了Co-Attention机制对新闻与评论间的不同特征进行充分交互融合,从而习得语义级(semantic level)、情感级(emotion level)更加全面而丰富的高层特征表示。区别于以往工作在特征融合阶段采用的简单拼接、加性操作这类粗粒度的融合方式,本研究分别针对新闻与评论的语义、情感隐向量进行共同注意力计算,从而实现两者在语义及情感层面的对齐,挖掘出特征间的深层次关联。这种关联关系具体体现为语义/情感的一致性或冲突性。3.针对新闻和评论深度融合后的特征,从内容语义、情感信息和时序信息三个维度得到新闻语义(News Semantic)、评论语义(Reply Semantic)、新闻情感(News Emotion)、评论全局情感(Reply Emotion)、时序情感(Temporal Emotion)、双向情感(Dual Emotion)这六种不同的特征,并基于上述特征设计了基于多维表示学习的虚假新闻检测模型。4.基于回译等数据扩充技术对标签样本进行增强,利用伪标签技术在带噪学习的语境下基于置信度阈值对伪标签进行筛选,从而获得更多可信标签数据以进一步提升模型的分类性能。据调研了解,这是基于阈值筛选的半监督学习技术在虚假新闻检测任务中的首次尝试。5.为验证本研究所提出模型的有效性,基于目前虚假新闻检测任务中的基准数据集,与已有的先进算法进行对比实验与消融实验,在三个数据集上的效果均已超越SOTA。最终,基于本研究所提出的模型,设计并实现了增量式虚假新闻检测原型系统EDFND(Emotion perception and Data enhancement Fake News Detector)。
{URL}: https://link.cnki.net/doi/10.27014/d.cnki.gdnau.2022.002713
{DOI}: 10.27014/d.cnki.gdnau.2022.002713
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习文本情感分类研究
{Author}: 潘雅丽
{Tertiary Author}: 李芸
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;文本情感分类;词向量表示;注意力机制
{Abstract}: 随着互联网的飞速发展,各式各样的网络交流平台以及购物平台不断涌现,网络上出现了各种类型的文本数据,也随之产生了许多与文本处理相关的技术。文本分类作为自然语言处理任务中的基础性任务应用十分广泛,例如搜索引擎中的网页分类、购物平台中的商品分类、微博评论情感分类等等。如果仅仅依靠人力来对海量的文本数据进行分类与处理,那么不仅需要消耗大量的时间,而且效率非常低。因此本文利用现有的深度学习理论与技术研究实现文本情感的自动分类,具有十分重要的现实意义。本文的主要研究工作如下:本文首先对文本情感分类任务的研究背景与相关意义进行阐述,将传统的文本情感分类方法与现有的文本情感分类方法进行对比。使用预训练语言模型BERT完成文本情感分类任务,得到文本的句子向量表示,从而使文本能够表征出更丰富的情感语义信息。其次使用BERT作为词向量模型得到文本的词向量表示,分别与DPCNN和Bi GRU网络相结合进行文本情感分类任务的研究。通过DPCNN网络能够有效发现文本中的长距离关联以及更多全局信息,提取待分类文本中更深层次的情感特征,而Bi GRU网络能够保留文本中词与词之间的上下文关联信息,提高模型的分类效果。针对BERT与DPCNN相结合的模型在小数据集上表现效果不尽人意的情况,对模型进行进一步改进,提出一种基于注意力池化的APDPCNN模型。该模型用注意力池化层代替原有的最大池化层,根据文本中不同词对于最终情感分类结果的贡献度分配不同的权重,更加全面的关注文本情感特征,从而使模型达到更好的表现效果。其次也在BERT与Bi GRU相结合的模型上引入注意力机制,突出文本中更能表达分类结果的情感词的权重,提高情感分类的准确率。将上述几种情感分类模型分别在Acllmdb＿v1和酒店评论两个公开数据集上进行测试,通过对比实验验证了这几种模型对于改善情感分类任务的有效性。最后在上述研究的基础上,设计了一个文本情感分类系统,整个系统分为算法模型训练部分和文本情感分类部分,算法模型训练部分是利用本文所设计的文本情感分类算法进行模型训练以及对算法模型参数进行调优,文本情感分类部分是实现对所输入文本进行情感的自动分类。该系统主要分为数据爬取模块、数据预处理模块、模型训练模块以及用户交互部分,最后通过用户交互界面将测试结果展示出来,进一步验证了本文文本情感分类方法的有效性。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.001251
{DOI}: 10.27075/d.cnki.ghzdc.2022.001251
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数字足迹的旅游机会识别与旅游机会时空图谱构建研究
{Author}: 张旭源
{Tertiary Author}: 张仁军
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 数字足迹;旅游机会时空图谱;自然语言处理
{Abstract}: 虽然大数据在旅游产业中的应用已得到广泛重视,但作为旅游产业发展的基础数据,旅游机会大数据的建设却一直建设缓慢。近年虽然有进行跨区域旅游资源普查数据的建设工作,但这些数据仍存在代价昂贵、更新慢等问题。本文提出的旅游机会时空图谱,可以解决以上问题。“旅游机会时空图谱”是指记录全区域旅游机会时空分布信息的数据库,它具有空间多尺度、时间多粒度、分类多维度等特点。更加重要的是,旅游机会时空图谱可以通过对旅游数字足迹的挖掘,实现旅游机会识别和数据更新,从而实现了旅游机会大数据的低成本、快速更新。基于旅游数字足迹的旅游机会识别,必须要解决对旅游数字足迹的语义识别和关键内容采集问题。本文运用自然语言处理技术,实现了基于语义识别的旅游机会智能识别的方法。该方法可以对采集的微博、微信公众号、新闻、评论等数字足迹内容,自动识别旅游机会类型、旅游机会内容、时间、地点,从而实现基于数字足迹的旅游机会大规模、快速识别和建库。同时,本文选择重庆市九龙坡区为案例,研究基于数字足迹的旅游机会时空图谱构建的效果,探索旅游机会时空图谱的应用。本文选择了都市旅游、乡村旅游、怀旧旅游三个典型的旅游机会类型,构建了九龙坡区春、夏、秋、冬四个季度的旅游机会时空图谱,并在ArcGIS中进行可视化表达。研究表明,本文构建的基于数字足迹的旅游机会时空图谱构建方法是可行的,通过九龙坡旅游机会时空图谱的挖掘和应用也证明了旅游机会时空图谱具有广泛应用前景。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2022.000289
{DOI}: 10.27753/d.cnki.gcqgx.2022.000289
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于对抗学习与全局指针生成网络的实体关系抽取研究
{Author}: 胡佳
{Tertiary Author}: 郑德权
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;实体关系抽取;知识蒸馏;对抗学习
{Abstract}: 现有的知识图谱通常作为搜索引擎、智能客服的外部知识库进行任务性能加强的方式。在构建知识图谱中实体关系抽取作为重要的基础方法,旨在从现有的海量非结构化文本中自动抽取出关系三元组。此外,实体关系抽取方法在金融、旅游和医疗等垂直领域有着重要的文本抽取关键信息的应用。因此,实体关系抽取方法得到了工业界和学术界的广泛关注,如何构建一个高效且精确的实体关系抽取模型成为了研究热点。实体关系抽取方法中采用流水线方式,独立的执行实体识别和关系分类两个子任务,由于缺乏交互性,造成了大量的误差传播。因此,采用联合抽取方式以其良好的交互性成为研究的主流方法。深度学习的发展,使得以联合抽取方式的实体关系抽取模型准确率得到了大幅提升,但是模型性能的提高带来的实际问题为模型参数更多,网络结构更宽更深,从而模型规模更大,推理时间更长,使得在计算资源有限的服务器上难以训练部署。针对以上问题,本文首先提出了基于对抗学习和全局指针生成网络的实体关系抽取模型AGPGN。该模型基于BERT模型共享编码层作为实体识别和关系分类的交互依赖,同时在实体识别中提出融合特定关系特征的全局指针生成网络,更好的处理关系抽取中实体重叠问题。为了提高模型的泛化能力,模型训练中加入基于PGD的对抗训练。在数据集上的表现相比基准模型的F1值提高了 0.8%,优于现有其他模型。然后本文将知识蒸馏应用于实体关系抽取模型。知识蒸馏属于模型压缩的一种常用方式。该模型以基于对抗学习和全局指针生成网络的模型AGPGN为教师模型,分别以LSTM编码的基于全局指针生成网络模型为学生模型和BERT自蒸馏的基于全局指针生成网络模型为学生模型,通过知识蒸馏方法进行实验,实验结果表明经过知识蒸馏后的模型仍可以取得良好的结果表现。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2022.000498
{DOI}: 10.27787/d.cnki.ghrbs.2022.000498
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多源异构信息融合的潜在工艺失效模式的机器识别
{Author}: 吴中义
{Tertiary Author}: 刘卫东
{Publisher}: 南昌大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: PFMEA;过程构成要素;工艺指令规范;多源异构信息;潜在工艺失效模式;机器识别
{Abstract}: 工艺失效模式及影响分析(Process Failure Mode and Effects Analysis,PFMEA)是一种经典的制造过程可靠性与质量控制方法。为确保制造过程的可靠性与产品制造质量,必须对其潜在的工艺失效模式进行逐一识别并科学地评估其风险水平,从而为制造过程的持续改进提供依据。而系统、准确且高效地识别出制造过程中所有的潜在工艺失效模式是PFMEA技术有效应用的基础和前提。对于大批量生产模式下的制造过程,其所积累的失效模式数据和历史经验极为丰富,从而为制造过程潜在工艺失效模式的识别奠定了基础。但在小批量定制生产模式下,如何在历史数据极度缺乏的条件下,提出具有普遍应用价值的潜在工艺失效模式识别方法,则是PFMEA技术有效应用的前提。目前,虽已有具有完备性和普适性的基于制造过程构成要素的潜在工艺失效模式识别模型及其应用程序,但其识别过程基本依靠工程师们的智力完成的。特别是将该方法应用于复杂产品制造过程的PFMEA时,潜在工艺失效模式的挖掘和识别需要耗费大量的人力与物力,且受到环境和人心理因素的影响,导致出现穷举识别效率不高和识别质量不稳定等问题。为此,本文基于过程构成要素的潜在工艺失效模式人工识别模型,以装配工艺过程为研究对象,综合运用自然语言处理、数据挖掘、案例特征类比推理等技术,分析研究制造过程构成要素的属性与自动生成问题、工艺指令的规范化、细粒度工序知识的重用和失效模式的机器识别等问题,形成系统的潜在工艺失效模式的机器识别技术。论文完成的主要工作包括:1、研究了工艺过程构成要素的自动生成与属性度量方式。利用Seq2Seq—LSTM算法建立了基于关键词规划的过程构成要素自动生成模型,并分析给出其应用受限的可能原因。进而逐个类别地分析研究了过程构成要素的工艺元素及其指标属性的特征度量问题,给出了其在不同类型过程构成要素下的具体计算方法,为后续的潜在工艺失效模式的机器识别研究奠定基础。2、提出了基于过程构成要素的工艺指令规范化的方法。分析了工步的六个过程构成要素所需包含的工艺内容,并运用改进FP-Growth数据挖掘算法挖掘其各自内容的表述方式。据此,从工步过程构成要素的具体内容和表述方式两个维度对工步指令提出规范化的具体要求。利用多色集理论研究了过程构成要素到工步指令的规范过程,以综合模糊评价法量化了工步指令规范前后对工艺质量的影响程度。规范的工艺指令不仅有助于提升潜在工艺失效模式机器识别的质量,也是保证制造工艺质量的关键因素。3、研究了细粒度装配工序知识的重用问题。以过程构成要素的输入、辅助活动、增值控制活动和输出四个维度的工序信息进行系统性的分析,提出了基于基因结构的工序多源信息的表示与评价方法。通过对四类过程构成要素的碱基属性进行了精细化的相似度定量度量,构建出灰色关联分析方法对四类过程构成要素的异构信息进行了有效融合,实现不同的装配工序之间的重用与修订。重用过程的研究为相似的工序在分解成更加细致的工艺过程构成要素指令中,节省了大量工艺人员在逐个要素划分时耗去的时间与人力成本,有效弥补了基于关键词规划的自动生成技术的不足。4、提出了潜在工艺失效模式的机器识别方法。以规范的工步过程构成要素为基础,通过引入可拓物元表示方法对工步过程构成要素的工艺指令实例、特征项以及特征词统一表示,建立失效判据和句法依存关系之间的映射,利用自然语言处理技术结合语义角色、语法与词性等混合相似性度量方法描述工艺指令之间的特征相似性,通过实例检索方式获得过程构成要素指令的特征,再经可拓算子的类比运算实现潜在工艺失效模式的识别;以制造过程需求特征为切入点,解决短语资源过程构成要素的潜在工艺失效模式识别问题。以准确率、召回率和综合值F来衡量每类过程构成要素指令通过案例类比推理实现制造过程潜在工艺失效模式机器识别的质量。5、将上述的研究内容应用于装配工艺的具体工程实际中,结合具体应用例,系统阐述了研究内容的实施过程,验证了所提出的潜在工艺失效模式机器识别技术的可行性、有效性和适用性。论文系统全面地研究了基于过程构成要素模型的潜在工艺失效模式的机器识别涉及的工艺指令的规范化、细粒度装配工序的重用等问题,研究成果不仅保证了PFMEA技术的应用质量与效率,也极大程度地提升了PFMEA技术对于各种生产模式的适应性。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.001286
{DOI}: 10.27232/d.cnki.gnchu.2022.001286
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言推理和零样本文本分类的Facebook用户评议研究
{Author}: Kaleemullah Qasim
{Tertiary Author}: 陈姚
{Publisher}: 西南财经大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 应用程序评论;零样本学习;文本分类;自然语言推理;BERTopic模型
{Abstract}: 随着互联网的发展,社交媒体APP已经成为人们工作生活不可分割的一部分。截至2021年9月,Facebook的每日平均活跃用户达到28.2亿。Facebook在苹果应用商店的社交媒体软件类目中平均排名前三。然而它的用户评分却并不高,例如,美国用户的平均评分只有2.2分。因此,对于应用开发者和用户而言,分析这种现象背后的产品属性和用户心理,有利于优化应用程序更新迭代,提高用户群体忠诚度。这也是笔者选题的初衷。近些年来,针对应用程序用户评论的研究是学者们广泛关注的热点。然而,现有的研究还存在很多局限。首先,学者们对于用户评论文本的分类不够全面,目前研究的主要分类可以概况为:软件缺陷报告,特征需求,信息检索和其他。但Facebook本身功能复杂多样,以上这些宏观的分类并不能将用户评论中反馈的信息和问题具体呈现出来。其次,大部分学者只选取了美国用户的英文评论,没有针对不同国家和语言,不同地区和文化的用户进行对比性研究。最后,现在的研究选取的研究方法主要还是监督学习模型,这种模型需要对数据进行大量的注释工作,过程比较繁琐。因此,基于以上研究局限,笔者从霍夫斯泰德文化维度理论出发,收集了来自24个国家的共计510717条Facebook用户评论数据,通过文本语言检测对数据进行处理,利用BERTopic和n-gram模型归类出5个宏观标签分类和64个微观标签分类,结合自然语言推理(NLI)零次学习和Distil BERT预训练模型对数据进行分析挖掘,探索用户评论背后反映的用户需求。研究发现,从宏观分类看,软件功能问题“Software Functionality”在所有用户评论中占比63.64%,社会相关问题“Social Issues”占比20.38%。从微观分类看,软件更新“update issue”占比18.07%,值得一提的是,占比前十的标签中有三类都是社会相关问题,这三类分别是:歧视“discrimination”5.28%,暴力“violence”3.80%,审查制度“censorship”2.74%。研究还发现了不同国家在用户评论的标签分类上的相似性和差异性。从宏观分类出发,埃及、阿曼、巴基斯坦、卡塔尔和沙特阿拉伯的Facebook用户首要关注点是社会相关问题“Social issues”,而其他国家的用户首要关注点都是软件功能问题“Software Functionality”。此外,笔者还通过分析用户评论的时间线发现,用户评论会受到应用程序自身以外因素的影响。比如,重大的社会政治事件、冲突或战争都会给Facebook评分带来消极影响;同时,硬件系统的升级也会产生消极影响。研究结果还表明,用户评论需要深度文本分类来分析用户需求。笔者希望这项研究可以指导企业和应用程序开发者更好的为用户服务,有针对性的改进产品功能。同时希望本文的研究方法也可以为以后的研究提供新的研究思路。
{URL}: https://link.cnki.net/doi/10.27412/d.cnki.gxncu.2022.002513
{DOI}: 10.27412/d.cnki.gxncu.2022.002513
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理的房地产网络舆情监测研究
{Author}: 程枫
{Tertiary Author}: 许艳
{Publisher}: 华东交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 房地产网络舆情监测;自然语言处理;文本聚类;LSTM预训练模型;词云技术
{Abstract}: 舆情体现了民众的情感和观点意见,在大数据背景下,民众成为信息的接收者、生产者和传播者,网络舆情逐渐成为社会舆情组成部分之一,在社会舆情中的重要性越发突出。房地产在我国区域经济构成中扮演重要角色,与人们基础生活紧密联系,对房地产网络舆情进行监测,有利于相关机构便捷地对舆情进行合理的引导和管控,有助于房地产行业的可持续发展。本文归纳并总结了现有研究成果中的舆情监测方法,从自然语言处理的角度,以长短期记忆网络(LSTM)为基础网络结构,构建了网络舆情监测的预训练模型,该模型能有效从文本数据中提取情感特征,分别计算情感趋向为正面和负面的情感值,并通过探究房地产网络舆情中的情感倾向性,对相关部门提出相关政策意见。本文的主要研究内容具体如下:(1)对文本数据进行初步分类。本文考虑到对所有文本数据直接进行分类有失合理性,在构建房地产舆情监测模型之前,对从微博平台爬取并整理的12344条房地产网络舆情文本数据进行文本聚类。以TF-IDF为特征计算方法构建向量空间模型,以文本间的余弦相似性为相似性度量、用K-means的划分法构建文本聚类模型,将文本分为基于“政府”的舆情文本、基于“市场”的舆情文本,再进行后续的舆情监测。(2)针对房地产网络舆情监测模型的构建问题,以LSTM为网络结构建立预训练模型,并选取适用于本文实验的短文本数据集为预训练的数据集。在网络结构设计方面,本文在LSTM网络后增加了Softmax分类器作为分类器,Softmax分类器区别于传统SVM,能直观地输出分类的概率值,并引入Dropout层以防止网络出现过拟合问题。本文构建的预训练网络模型在10%的测试集上的准确率为91.2%,召回率为87.3%,精确率为96.8%,F1得分为91.7%,认为本文建立的网络舆情监测预训练模型较好。(3)根据构建的舆情监测模型,得到以下结论:围绕“市场”的评论中有大约86.9%的舆情信息为负面情绪表达,表达了民众对房价、房产相关机构、房产中介及二手房市场等的关注,约10%左右的舆情信息为正面情绪表达,表达了对未来房地产市场发展形式看好;围绕“政府”的评论中有大约63.7%的舆情信息为正面情绪表达,表达了民众对政府约谈行为的支持,约33.7%的舆情信息为负面情绪表达,认为政府行为对房地产市场的管控作用不大,民众的关注度主要围绕政府的相关举措对房地产市场的影响。(4)根据房地产网络舆情监测结果,认为我国房地产网络舆情的情感倾向性总体保持乐观,但是舆论中依旧存在乐观、悲观交替的情况,民众虽然认为政府部门未来将采取的的管控措施将改善房地产市场现今不良现象,但是民众对于现下部分地区的房价上涨、房产机构的炒房行为等现象表达了的消极情绪不容忽视。政府及相关部门应该加强房地产行业的网络舆情监测,同时加强对房地产市场的管控,保障我国房地产行业未来的可持续发展。
{URL}: https://link.cnki.net/doi/10.27147/d.cnki.ghdju.2022.000501
{DOI}: 10.27147/d.cnki.ghdju.2022.000501
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和信息检索技术的代码生成方法的研究与应用
{Author}: 杨志成
{Tertiary Author}: 齐影虹;李宇
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 代码生成;信息检索;命名实体识别;预训练模型
{Abstract}: 随着信息技术的迅速发展,各种各样的应用软件已经融入到人们的工作与生活中,人们对于软件功能的需求也在日益增多。开发一套符合用户需求的软件涉及到的流程十分复杂,并且对于编程人员的专业水平有很高要求。因此,为了提高软件的开发效率和降低软件开发的技术门槛,自动代码生成技术应运而生。相比于传统的代码生成技术,基于深度学习的代码生成技术研究的是将自然语言内容描述转化为对应意图的程序代码,具有智能程度高、使用门槛低、适用范围广等优点。但由于自然语言与程序代码的结构差异性和这项任务本身所具备的复杂性,现有的神经网络代码生成技术仍存在着可应用性不强、单语数据利用率低等问题。考虑到仅从模型结构上的改进无法从根本上解决上述问题,本文将深度学习模型与信息检索技术结合起来,并引入对话、问答和传统代码生成领域的一些方法,来提高生成代码的准确性和可应用性。本文主要研究内容如下:(1)提出了基于命名实体抽取技术和检索技术的代码生成方法。为了进行该方法研究,本文首先通过手工标注、数据增强、数据合成等方法,构建一个带有函数、变量等实体信息的数据集,然后通过在Bi LSTM模型的基础上增加BERT词向量层和CRF条件约束层,实现实体信息的高准确率抽取,接着使用BM25信息检索算法获取匹配的模板信息,最后通过编写每种模板对应的代码生成逻辑实现自然语言到代码的转化过程。(2)提出了基于Code T5模型和信息检索技术的检索生成式代码生成方法。在Code T5模型的基础上引入了BM25稀疏检索技术和基于DPR模型的密集向量检索技术,通过自然语言输入到代码数据的检索过程,获取与目标代码相关的代码片段并与自然语言输入进行拼接融合,以让模型在训练和预测过程中带有更多的先验知识。实验表明,检索生成式模型在检索数据与训练数据相关性很高的情况下,能大幅度提高模型的代码生成能力。(3)建立了Text2Chart智能图表生成系统。利用构建的数据集和提出的代码生成方法建立了一个智能图表生成系统。通过结合web前后端技术,设计并实现了代码生成、图表生成等功能模块,以向用户提供智能、便携的服务。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.001814
{DOI}: 10.27232/d.cnki.gnchu.2022.001814
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 结合数据增强及图神经网络的方面级文本情感分析
{Author}: 陈明非
{Tertiary Author}: 张云港
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 方面级文本情感分析;关系图注意网络;数据增强;对抗训练;Mixup
{Abstract}: 近年来,互联网大数据发展十分迅速,自媒体平台和各类在线购物网站上均出现了大量的带有用户情感的在线评论。这些评论文本数据蕴含着大量的情感信息,不仅可以帮助商户挖掘出用户对商品或服务的情感倾向,还可以作为商品性能与质量提升的依据。文本情感分析是自然语言处理领域里一项重要的研究课题,具有广泛的应用前景。文本情感分析按粒度属性可分为篇章级、句子级和方面级三类。与篇章级和句子级别情感分析任务相比,方面级情感分析任务具有更加细粒度的信息,一般体现为用户对商品的某一方面做出的情感评价。这些评价信息可以为商户指明更为细致的商品性能提升与服务推送的方向和思路。因此,方面级情感分析任务具有更高的研究价值和商业价值。方面级情感分析任务是判断输入文本中给定方面的情感极性,目前常见的方法为使用神经网络对输入句子进行编码,并提取方面词与上下文情感词关系,根据相关情感词得出评论针对特定方面的情感判断。但是大多数已有模型只注意到句子中单词之间的上下文位置关系,导致长距离非临近的词的匹配效果不理想,且忽略了句子的语法结构,无法体现文本语法结构特点。另外,解决方面级情感分析问题的方法多利用神经网络,其本身会存在对训练标记数据的质量和数量上的依赖问题,在缺乏训练数据或标注不够理想时,神经网络会往往表现不理想,甚至不够健壮和稳定。基于以上背景和问题,本文提出结合数据增强与图神经网络进行方面级情感分析。本文主要研究内容如下:(1)本文提出了结合对抗训练与关系图注意网络模型(RGAT-BAT)用于方面级情感分析。关系图注意网络具有多层体系结构,每一层都使用近邻的特征编码和更新图中节点的表示。在语义语法树结构上利用关系图注意网络,可以有效地利用句子语法信息和单词依赖。在利用语法信息的基础上,集成依赖标签本身的信息,可更准确地捕捉单词之间的关系,有效地解决长距离非临近的词的匹配问题。对抗训练属于数据增强技术的一种,可以在模型训练中动态地从以前标记的数据创建新的训练数据,且能够通过扰动神经网络的手段训练,提高对恶意样本的抵抗能力,增强神经网络的健壮性与稳定性。同时,对抗训练也是一种正则化方法,可以解决过拟合问题,提升模型泛化能力。(2)本文提出结合Mixup与关系图注意网络的模型(RGAT-Mixup)。使用Mixup技术结合关系图注意网络进行方面级文本情感分析。Mixup技术是数据增强方法中扩展较小数据集的有效工具,其可用于匹配深度学习模型所需的标记数据量,在有限数据量情况下提升模型性能。采用Mixup结合关系图注意网络有助于减少模型开发的成本,解决标记数据数量不足的问题,同时可保证模型性能。本文提出的模型,在Sem Eval 2014-Task4 Restaurant、Sem Eval 2014-Task4Laptop和Twitter评论数据集中进行了实验验证。实验结果表明,本文的方法可有效地提高方面级情感判断的准确性和神经网络的稳定性。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2022.001186
{DOI}: 10.27459/d.cnki.gynfc.2022.001186
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本挖掘的学术论文创新力评价研究
{Author}: 沈超
{Tertiary Author}: 邱均平
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 创新力评价指标;指标体系;公开同行评审;文本挖掘;情感分析;熵值法
{Abstract}: 随着开放获取运动的开展,学术论文全文、审稿人意见等资料越来越容易被获取,这些文本资料中蕴含着大量的有用信息,可以为学术论文创新力评价提供新的视角和方法。同时,随着自然语言处理技术的不断成熟,其应用领域也在不断扩大,越来越多的领域都在使用自然语言处理技术来完成特定的研究或工作,在评价计量学领域中,自然语言处理技术的应用也成为了研究的重点和热点。本文借助文本挖掘技术,从审稿人的评论文本中,挖掘出有关创新力的内容,运用机器学习模型和“投票原则”,构造一个基于评论文本创新力情感分析的学术论文创新力评价指标。然后结合对学术论文本身的主题创新力测度值和Open Review网站上对论文的总评分,对构建的指标进行合理性检验。最后构建了融合上述构建指标的学术创新力评价指标体系,并运用熵值法对指标进行赋权,并综合评价学术论文的创新力。本文的研究结果将审稿人的非结构化、非定量化的评论文本转化为定量的创新力评价指标,能够更加直观地向大众展现学术论文地创新力情况,为完善学术论文创新力评价指标体系建设提供了参考,能够帮助实现学术论文创新力评价的公平性、科学性、时效性,提高具有高创新力的学术论文的利用率,增强科技成果转化能力,助力国家创新驱动发展战略的实施。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.000460
{DOI}: 10.27075/d.cnki.ghzdc.2022.000460
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言的家用机器人任务理解研究
{Author}: 陈旭东
{Tertiary Author}: 田国会
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 家用机器人;任务理解;语义解析;任务规划;本体知识库
{Abstract}: 随着语音识别技术的日益成熟,自然语言交互已然成为主流的人机交互方式。家用机器人对自然语言形式任务的正确理解对于提升其智能化服务水平具有重要意义。目前家用机器人在执行任务时只能理解预先设定的简单指令,而缺乏对复杂、抽象的多任务指令的理解能力。因此,本文提出了一种两阶段的任务理解方法,首先把用户指令按照语义划分为多个框架,即框架语义,从而提高对多任务指令的处理能力;然后将框架语义转换为规划目标,经任务规划生成机器人的原子动作序列,从而实现对复杂、抽象任务的理解。本文的具体工作如下:(1)构建了融合依存句法的多意图识别和槽填充联合模型,以意图为框架主题,槽位作为框架元素,将多任务指令解析为框架语义。采用改进的Tree-LSTM对句子的依存句法树编码,并与词向量拼接,实现了特征融合。在BiLSTM基础上融合了注意力机制,提取句子中的关键语义信息,用于多意图识别。利用图注意力网络将多个意图融入到槽填充过程,对槽位预测起到了约束作用。实验结果表明,本文构建联合模型可以有效提高框架语义识别的准确率。(2)以智能空间为背景,基于本体技术构建了集用户、机器人和环境信息于一体的知识库,实现了对复杂家庭环境的知识化表征。依据本体知识库的层级结构树,将其解析为字典形式,便于知识的查询和利用。针对框架语义中物品描述与本体库中物品实例名不一致的问题,采用了一种基于语义相似度的物品实例查询算法。利用本体知识库获取任务指令中缺失的信息,为任务规划提供先验知识。(3)设计了基于PDDL的规划问题自主生成机制,实现了框架语义到机器人原子动作序列的自动转换。使用PDDL领域描述对机器人任务执行能力和环境状态进行抽象化表示,根据本体知识库中获取的环境先验知识确定规划的初始状态,建立框架语义主题和规划目标之间的映射规则,实现了 PDDL问题描述的自主生成,并利用任务规划器对其进行分析求解,获得机器人的动作执行序列。(4)基于Unity3D软件构建了家用机器人任务理解仿真系统,实现了对任务理解方法的验证。搭建了复杂的模拟家庭环境,共包含120类常见的家庭物品和四种家庭场景。基于C#脚本和Unity相关组件设计了四个功能模块,分别用于用户交互,本体知识库同步更新、任务规划和路径规划。同时设计了任务理解与执行仿真实验,实验结果表明,本文提出的任务理解方法可以有效地对复杂的多任务指令进行解析,提高了机器人的对任务的认知能力。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.004449
{DOI}: 10.27272/d.cnki.gshdu.2022.004449
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 电力变压器缺陷文本信息数据挖掘研究
{Author}: 周晓童
{Tertiary Author}: 陈青
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 电力变压器缺陷记录;自然语言处理;文本数据挖掘;缺陷记录分类定级;知识图谱
{Abstract}: 随着国民经济水平的日益提升,对于电力系统运行的安全性、稳定性、可靠性等提出了更高的要求。各类电力设备在工作过程中可能出现各种缺陷,如果无法及时发现和消除缺陷,将危及系统正常运行。其中,变压器作为输变电系统的关键环节,其健康稳定运行对电力供应至关重要。但是实际运行中的许多变压器,由于运行年限较长,会出现老化、漏油等缺陷,因而需要进行常规巡检。电力设备缺陷记录是由运维人员在巡检过程中对于出现缺陷情况的电力设备的记录和描述,充分挖掘电力设备缺陷记录中的信息,可以对电力设备缺陷进行准确的分类与统计,帮助运维人员定位缺陷部位、判断缺陷类型,并根据已有的缺陷记录参考可以实施的消缺方法,有利于设备缺陷的快速消除,提高电力系统运行的可靠性。同时为电力行业的智能辅助决策研究提供补充。随着电力大数据这一概念的提出和自然语言处理技术的进步,各类结构化数据逐渐得到充分的挖掘,但由于电力缺陷文本是由运维人员手工记录,属于非结构化信息,目前还并未得到充分的利用。对缺陷文本的分类统计工作往往由人工完成,受限于分类人员的知识和经验,分类往往具有主观性,且效率较低。采用智能文本分类方法对缺陷文本进行分类统计,提高了分类的效率,节省了人工出力,还能够提升缺陷分类的准确性。此外,在对缺陷进行分类定级和消缺处理后,将已有的缺陷记录存储进知识图谱数据库,在新增缺陷时,可以在知识图谱数据库中检索历史缺陷记录中的相似情景或同一缺陷部件,从而借鉴已有案例,参考曾经的处理方法做出消缺安排,有助于帮助经验不足的运维人员做出正确判断。同时,知识图谱数据库将知识中的关键信息抽取出来进行展示,可以直观展现某一部件的历史缺陷情况及消缺方法,对于电力工作人员学习和把握电力设备缺陷知识具有重要指导作用。此外,知识图谱数据库还可以对新增缺陷记录进行检错处理,筛出错误或表述不清的缺陷记录,输出规范化表达,有助于电力大数据的规范化管理。因此,本文以电力变压器缺陷文本为研究对象,采用自然语言处理方法对其进行预处理、文本分类和知识图谱实现,实现了缺陷记录的准确分类、可视化以及错误检索,具体工作及成果如下:1.针对电力变压器缺陷文本为非结构化数据这一问题,在分析大量缺陷文本的基础上,运用自然语言处理技术对其进行一系列处理。采用基于隐马尔科夫模型的jieba分词工具对其进行分词、去停用词操作,将大段非结构化文本转化为关键词的形式。然后采用分布式表示对关键词进行向量化处理,将词语训练为计算机可以理解的分布式词向量,并基于Python软件进行了实现。2.由于当前电力缺陷文本分类往往由人工完成,不仅浪费时间和精力,更容易受分类人员主观判断和经验的影响。因此本文构建了缺陷自动分类定级模型,能够准确提取缺陷描述文本全局特征和局部特征,根据文本描述对缺陷进行准确的分类定级。采用南方电网公司2808条电力变压器缺陷记录进行训练与测试,引入了评价指标对分类效果进行计算,证明了分类模型的有效性。3.当前缺陷记录以文字的形式记录在缺陷记录表中,文字记录无法直观的体现缺陷位置的结构情况、对应的缺陷情况以及消缺方法。本文基于Neo4j软件构建了电力变压器缺陷记录知识图谱,将变压器缺陷记录经知识抽取、知识融合、知识加工后,以图数据库的形式存储,既提取了变压器内部结构和部件之间的关联关系,又直观的表现出了各部件实体与缺陷情况之间的对应关系,在某一部件出现缺陷时,可以直接搜索到其数据库中已有的历史缺陷情况描述及对应消缺方法,进而充分挖掘历史信息,为检修人员提供参考。此外,考虑到缺陷记录由手工记录,可能会出现漏记或错记,本文提出了一种图搜索的缺陷记录检错方法,对缺陷实体缺失、缺陷情况缺失等多种错误情况进行过滤,并输出完整准确的规范化表达。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.000661
{DOI}: 10.27272/d.cnki.gshdu.2022.000661
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识增强的预训练语言模型研究
{Author}: 蔡泽锐
{Tertiary Author}: 何晓丰
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;预训练;语言模型;知识增强
{Abstract}: 通用深度预训练语言模型在大规模无监督信息的语料库上利用精心设计的自监督预训练任务进行训练,它在下游数据集上只需要简单的微调就能够打破之前模型的最好成绩,给自然语言处理领域带来了跨越式的发展。然而,尽管上述模型能够在很多下游任务上具有良好的表现,在一些特定领域任务和强知识驱动型任务上,它们的表现并不能令人满意,还有很大的提升空间。随着近来大规模知识图谱的构建和发展,现有的一些工作提出了利用外部知识去增强预训练语言模型,对于知识增强预训练语言模型的研究有望实现逼近具有人类水平的人工智能,有很高的学术价值和现实意义。然而目前的工作缺少对异质多源知识图谱的利用,也很少关注知识图谱中的结构化信息,对知识图谱的挖掘程度尚且不够。同时,从模型吸收和利用外部知识的情况看,目前还没有工作考虑过模型是否真正理解注入的知识,这会使得注入的知识没有办法按照原本预想的方式生效,降低效果的同时无法如我们所愿构造更鲁棒高效的人工智能。因此,本文为解决这些问题,做了包含如下内容的主要工作:1.基于图神经网络的多源知识融合。多源知识融合重点在于能够将多个知识图谱的异质知识进行有效融合和表示。本文提出基于图神经网络的多源知识融合,首先对各个相互异质的知识图谱分别构建同质图实现对他们各自的表示,然后进行图融合形成一张统一的异质图,之后通过混合图注意力机制提升各个节点的表示,再将高质量的整图表示通过位置特定的门控机制融合回预训练语言模型中,减少了知识噪声的引入。整体最终实现了高效的多源知识融合和表示,为模型利用这些多源异质知识进行综合以及推理做好了基础工作。2.基于知识上下文的结构化信息利用。知识图谱中的结构化信息可以粗略地理解为围绕一个目标实体由其周围邻居关系构成的结构信息。本文提出知识上下文的概念,进一步利用结构化信息对输入文本中实体表示的进行增强。本文提出了基于实体-邻居的混合注意力以及知识上下文建模的预训练任务帮助将预训练语言模型产生的实体表示信息传入到其周围邻居实体中,并反过来通过聚合周围邻居实体的表示去增强中心目标实体的表示,促进不同实体通过共同邻居交流信息,以此为表示较差的低频实体提供额外的全局知识上下文。3.基于双向映射预训练的知识理解增强。目前知识增强预训练语言模型的相关工作忽视了模型对于注入知识的理解。本文提出了双向映射提升知识理解的预训练任务。通过训练模型从文本到实体的转化能力和反过来从实体到文本的转化能力,让模型能够将相关实体文本转化为知识嵌入空间的对应实体,进行综合推理后再转化回自然语言的文本表示输出,实现了对注入知识的掌握和利用,大大提高了模型在相关任务上的表现。本文的主要贡献点均设置了大量的实验和相应分析,有效证明了提出模型和机制的合理性、可靠性和有效性,进一步推动了相关研究的发展。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.002380
{DOI}: 10.27149/d.cnki.ghdsu.2022.002380
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向嵌入式设计需求的形式化建模与验证
{Author}: 冯劲草
{Tertiary Author}: 蒲戈光
{Publisher}: 华东师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 形式化方法;需求建模;需求确认与验证
{Abstract}: 随着大量软件在工业界的广泛应用,越来越多的嵌入式系统的核心控制软件逐渐走向数字化控制的道路。随着计算机硬件性能的逐渐提升,人们期待用计算机去解决的问题越来越困难,这也导致现代工业控制软件日益庞大与复杂。在这种情况下,如何在安全攸关系统中保障系统的安全性显得愈加重要。工业界和学术界都认为对软件开发的起始点对系统需求进行形式化分析与验证是保障嵌入式系统软件可靠性的一个重要手段,然而,如何在工业界的大型软件项目中应用形式化方法仍然是一个亟待解决的难题。工程师在生产实践中应用形式化方法时,仍缺少自动化的工程性方法来高效地选择和建立更加精准的需求模型与性质,且缺少严谨的方法论去确认和验证所建立的需求模型。为了解决上述问题,本文针对形式化方法在工业界中的应用进行了研究和探索,其主要的研究内容和贡献如下:·设计了一个领域专用的轻量级需求建模语言AASRDL在特定嵌入式领域中,通用的建模语言学习曲线陡峭,学习成本巨大,无法满足工程师快速建模的需求,为了解决这一难题,通过总结相应的嵌入式领域特征,本文设计了一个轻量级领域专用的需求建模语言AASRDL,用于需求规约的快速构建。同时,本文还提供了一个模板来引导构建形式化需求模型;·提出了一种基于NLP的需求规约自动生成方法为了解决工程师难以熟练使用形式化语言描述待验证的安全性质问题,提出了一个可以将自然语言描述的性质转化为需求规约的方法。通过分析安全需求的性质描述特征,提出了一个安全需求的语义模型,使用句法切块技术和依存关系分析技术进行安全需求中的信息抽取并将其存储在语义模型中,并最终根据目标语言翻译成相对应的需求规约;·提出了一个系统性工程方法FREPA提出了一个系统性的可以指导工业界在嵌入式领域中进行形式化需求建模和确认验证的方法FREPA;该系统性的方法主要包括在嵌入式系统中如航空航天系统进行系统需求模型的构建、确认和验证操作,主要分析技术包括基于图标的需求审查、模型模拟执行、基于MC/DC覆盖准则的测试用例自动生成、性质验证;·支撑工具及其应用本文开发了基于FREPA方法的支撑工具,该工具可以实现需求建模和确认验证的自动化操作,并在相应的实际项目中进行了实验和验证。目前为止,本文所提出的方法已经成功地被应用于七个航天飞行器和两个航空发动机控制系统的软件开发过程中。实验表明本文的方法论及其支撑工具工具能够在实际项目中进行有效的形式化建模和确认验证。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.004041
{DOI}: 10.27149/d.cnki.ghdsu.2022.004041
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的慢性病诊断问答系统研究与实现
{Author}: 曹朝阳
{Tertiary Author}: 倪林
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 问答系统;慢性病;知识图谱;命名实体识别
{Abstract}: 随着我国社会节奏的日趋加快与人们生活压力的不断增加,由各种慢性疾病引起的健康问题已成为人们不容忽略的重大威胁。伴随着“健康中国2030”规划的提出,如何更好地进行慢性病防治工作成为了当下研究的热点。近年来,互联网的快速发展掀起了信息技术的革命浪潮,医疗百科网站、在线问诊医生等网络平台层出不穷,丰富了人们获取医疗知识的渠道。然而,这些平台在给人们带来便利的同时也存在着诸多挑战,比如网站大而繁杂,搜索功能过于单一,在线问诊平台沟通效率低下,非即时类平台不能及时返回用户答案,而即时类平台又由于患者的不确定问诊时间存在资源的浪费。因此,基于上述问题,本文设计并开发出一套自助诊断问答系统,将其在慢性病领域的应用作为切入点,重点研究问答中的命名实体识别技术和慢性病知识图谱的构建技术,并利用研究的成果完成问答系统的搭建,使其满足患者的问诊需求。本文主要研究内容如下:(1)针对传统命名实体识别模型的不足进行改进,提出了结合注意力机制的字词级栅格状命名实体识别模型,通过在公开数据集上进行实验对比验证所改进模型的有效性。(2)建立慢性病领域知识图谱,通过爬虫技术对相关的权威医疗网站进行数据获取,并利用知识融合技术对其他来源的知识进行整合,最终得到较为完整的慢性病知识图谱,将其利用图数据库进行存储,方便后续系统对答案的检索。(3)采用标准的软件设计架构设计并开发出一套慢性病诊断问答系统。其中,采用(1)内容中构建出来的命名实体识别模型对问题进行实体抽取,采用(2)内容中构建出来的知识图谱为问答系统提供数据支持,采用前端开发语言与网页应用框架完成系统的搭建。最后对所开发系统进行功能与性能的测试,从而验证系统的可用性与实用性。综合上述内容,本文完成了一套完整的基于知识图谱的慢性病诊断问答系统,可以对用户问题做到较为准确与高效的应答,一定程度上缓解了医疗机构的压力。同时,本课题也为其他领域的问答系统研究提供了可参考思路与方法,具有实际意义与应用价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.001591
{DOI}: 10.27517/d.cnki.gzkju.2022.001591
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于领域知识图谱的问答技术研究
{Author}: 张瑞星
{Tertiary Author}: 王俊义
{Publisher}: 内蒙古大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 槽位继承;BERT;领域知识图谱;问答系统;深度学习;实体识别
{Abstract}: 用户检索信息的需求随着步入大数据时代也在逐日增加,传统检索方式无法快速有效的解决问题,交互问答这种更加高效、智能的检索方式符合当今社会对于信息高效获取的需求趋势。为推进智慧医疗建设的政策,更为方便快捷地对某些疾病相关知识的查询从而达到自我辅助医疗问诊的目的,本文通过构建医疗知识图谱作为数据支撑,并以医疗知识图谱问答技术为切入点进行研究。(1)研究医学领域知识图谱的构建。采用爬虫技术提取医学相关半结构化网页为数据源,通过数据处理后定义医学实体、关系和属性,存入Neo4j图数据库。(2)研究基于知识图谱的问答方法。本文针对标注训练语料不足的问题,设计了两种分别适用于扩充医学实体识别和问句意图文本分类语料的自动标注生成算法,增强了模型训练的效果;针对中文词汇切分对问句语义影响的问题,引入预训练模型BERT构建基于字符的Bert-Bi LSTM-CRF的实体识别模型和Bert-Text CNN的问句意图分类模型,有效提升了实体识别和问句语义解析性能,从而提高了问答性能;设计构建语义槽位模板实现从问句意图转化为知识图谱答案检索语句的方法。(3)基于医疗领域知识图谱问答原型系统的设计与实现。整合以上研究工作,实现基于槽位继承的交互式问答和对医疗知识的可视化展示。实现用户对医疗知识的查询,满足用户对自我辅助问诊的需求。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2022.001075
{DOI}: 10.27224/d.cnki.gnmdu.2022.001075
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于迁移学习的任务型对话系统关键技术研究
{Author}: 覃立波
{Tertiary Author}: 车万翔
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度学习;任务型对话系统;迁移学习;对话语言理解;自然语言处理
{Abstract}: 对话系统是指以人机对话形式提供信息或服务的系统,越来越受到学术界和工业界广泛的关注。目前,对话系统从功能上可以大致分为四大类:任务型对话系统、闲聊型对话系统、知识问答系统以及推荐系统。本文重点研究任务型对话系统,它能够帮助人们完成一些垂直领域的服务,例如查话费、酒店预订和订机票等,具有很高的理论意义和实用价值。近年来,任务型对话系统的研究主要分为两个流派:流水线任务型对话系统和端到端任务型对话系统。其中流水线任务型对话系统主要由对话语言理解模块、对话状态跟踪模块、对话策略学习模块和自然语言生成模块组成,并需要通过各个子模块协同工作一起生成对话系统回复。而端到端任务型对话系统则可以直接通过一个统一的序列到序列模型生成对话系统的回复。对话语言理解模块为流水线任务型对话系统中的第一个组件,它主要负责提取用户的语义表示,并为后续模块生成最终系统回复提供基础,因此它是流水线任务型对话系统中最核心的模块之一。随着深度学习和预训练模型的发展,不管是流水线系统还是端到端任务型对话系统都取得了突飞猛进的发展。然而在真实应用中,它们仍然面临着一个巨大的挑战:数据稀缺。现有的对话模型依赖大量高质量的标注数据进行训练,导致难以泛化到数据稀缺的场景。同时,不同于其它传统的自然语言处理任务,对话领域的数据标注往往需要专家的大量先验知识,进一步增加了大规模的任务型对话系统标注数据获得的难度。而且,在真实应用中,当对话系统扩展到不同的任务、不同的语言与不同的领域的时候,都会面临数据稀缺的问题。于是,如何在数据稀缺的低资源场景中构建性能良好的的任务型对话系统中是一个非常有价值的研究课题。为此,本文探索了迁移学习在任务型对话系统中的应用:即利用迁移学习技术实现从数据充足的源端迁移知识到数据不足的目标端来缓解任务型对话系统中数据稀缺的问题。具体来说,本文以流水线任务型对话系统中的对话语言理解模块和端到端任务型对话系统为切入点,分别从跨任务,跨领域,跨语言迁移进行了详细研究:1.(跨任务迁移)基于堆栈传播的跨任务对话语言理解:针对现有跨任务对话语言理解模型对意图识别和槽位填充任务进行隐式联合建模而导致的意图信息迁移不充分问题,本文提出一个基于堆栈传播的跨任务对话语言理解框架。具体而言,本文首先提出一个堆栈传播框架来显式引入意图信息。同时,为了缓解意图信息引入导致的错误级联问题,本文进一步提出单词级别的意图识别,能够为每个单词提供单词级别的意图信息。本文提出的框架不仅在标准数据集上取得了当时的最优性能,也提高了对话语言理解联合模型的可解释性。并且,当在数据特别稀缺的场景中(5%的训练数据),基于堆栈传播的框架能够大幅度超越前人工作的性能(19.8%的提升),极大的缓解了跨任务中数据不足的问题。2.(跨任务迁移)基于协同交互Transformer的跨任务对话语言理解:针对现有对话语言理解模型仅建模从意图信息到槽位填充的信息迁移的局限,本文提出了一种协同交互Transformer的框架来考虑意图识别和槽位之间的相互影响。不同于传统Transformer中的自注意机制,本文提出了一个协同交互注意力模块,从而能在两个相关任务之间建立双向连接。并且,本文进一步改进了前馈神经网络层来更好地融合两个任务的交互。本文提出的双向交互模型能够在低资源场景下(5%的训练数据)取得超越前人单向交互模型26.7%的性能,极大地缓解了对话语言理解任务中真实部署中的冷启动问题。3.(跨语言迁移)基于编码转换与对比学习的跨语言对话语言理解:针对现有对话语言理解模块在跨语言场景下的弱泛化性,本文首先提出基于编码转换的跨语言对话语言理解框架,能够通过在编码转换的数据上微调预训练语言模型来隐式对齐多语言预训练模型在不同语言上的表示空间。并且,本文进一步提出对比学习来显式对齐不同语言上的表示。具体而言,对比学习可以显式拉近同一句子在不同语言上的表示(正例),推远不同句子在不同语言上的表示(负例)。本文提出的框架在不需要目标语言数据的零样本跨语言对话语言理解任务上取得了当时的最优性能,极大地促进了任务型对话系统的全球化发展。4.(跨领域迁移)基于动态聚合网络的跨领域端到端任务型对话系统:针对现有端到端任务型对话系统难以泛化到一些低资源新领域的问题,本文提出一个基于动态聚合网络的跨领域端到端任务型对话系统,该网络不仅能够显式融合领域共享和领域私有的特征,还能自动学习不同领域的相关性用以捕获不同领域之间的细粒度关系。本文提出的模型能够取得当时最优的性能。当在数据特别稀缺的场景(5%的训练数据),本文提出的模型能够获得优于前人最佳模型13.9%的性能,极大地提高了模型在跨领域场景的泛化能力。综上所述,本文针对任务型对话系统中标注数据不足的问题,以流水线任型对话系统中的对话语言理解和端到端任务型对话系统为切入点,深入研究了跨任务迁移、跨领域迁移和跨语言迁移三种迁移技术,显著缓解了数据稀缺问题,以及提高了模型在跨任务,跨语言以及跨领域场景下的泛化能力。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.000322
{DOI}: 10.27061/d.cnki.ghgdu.2022.000322
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像到文本：基于双向LSTM和注意力机制的图像字幕技术研究
{Author}: Rashid Khan
{Tertiary Author}: 叶中付
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像字幕;计算机视觉;自然语言处理;基于双向长短时记忆;Proposed Moth Flame Optimization;门控循环单元;注意机制;Inception v3;Resnet-152
{Abstract}: 图像字幕技术是对图像进行描述的一种方式。该技术要求准确获取图像中的重要对象与其自身属性,理解对象间的相互关系,最终形成在语法和语义上均合理的自然语言描述。图像描述对人类来说毫不费力,然而试图使用人工智能技术复现却是一项极具挑战性的任务,因为它需要综合使用自然语言处理(NLP)和计算机视觉(CV)领域的相关技术。这项研究尝试使得计算机以最自然的方式理解和传达对视觉世界的感知,势必会有力促进人工智能技术的发展。图像字幕技术通常由图像编码器和语言解码器两个部分组成。编码器通常由卷积神经网络(CNN)构成,而解码器通常由长短时记忆网络(LS TM)构成。先前关于图像字幕技术的研究通过在神经网络中引入众多的LSTM和CNN模块以及注意力机制,获得相关且准确的生成字幕结果和对应模型,但是模型的泛化能力不强,在大量数据集上仍未能实现高性能目标,效率和准确率有待提高。本研究旨在通过优化神经网络模块,提出一种泛化能力强的基于双向LSTM和注意力机制的图像字幕自动生成模型。
首先,本研究提出了一个优化的BLSTM网络架构,用于提高图像字幕生成和分类的准确性。我们提出了一种Proposed Moth Flame Optimization(PMFO)优化算法,该算法使用基于相关性的对数螺旋更新方式以增强传统BLSTM网络的逻辑提取能力。我们使用Inception v3模型用于提取图像特征,适当调整训练的轮次,在元启发式模型下进行训练。并在基准数据集(如Flicker8k、Flicker30K、VizWiz和MS COCO数据集)上对该模型的性能进行了评估,使用了 CIDEr、BLEU、SPICE和ROUGH等通用指标。评估结果分析证明,BLSTM在字幕生成方面的性能优于现有的方法。
其次,本文提出了一种新颖的基于注意力机制的序列到序列的网络架构。该架构通过与传统的编码器-解码器模型相结合,利用基于注意力机制的方式生成图像字幕。编码器特征提取网络选用ResNet-152,用以生成输入图像的融合特征,接着将这些特征嵌入固定尺度的向量中。解码器使用LSTM并引入注意力机制有选择地聚焦到在图像的指定部分。在MS COCO和Flickr8k基准数据集上的实验表明,与基准结果相比,该模型具有一定的优势。
最后,本文设计了一个端到端的图像字幕生成系统。该系统使用预训练的CNN从图像中提取特征,使用注意力机制融合这些特征,最后使用递归神经网络(RNN)生成字幕。为了完整表达图像属性,我们使用了多个预训练的CNN提取特征向量作为编码器。此外,我们选择门控递归单元(GRU)作为解码器来构造描述句。为了提高性能,我们将Bahdanau注意力模型与GRU相结合,专注于图像的特定部分,并在MS COCO数据集上实验,取得了与最先进的方法相当的性能。
总体上,本文提出了三个新颖的图像字幕生成框架,实验论证了它们优越的性能,间接表明了计算机视觉与自然语言之间存在的紧密关联,我们也希望将这些技术扩展应用到其他领域。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.002009
{DOI}: 10.27517/d.cnki.gzkju.2022.002009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向安卓移动应用的推荐问题研究
{Author}: 郜山权
{Tertiary Author}: 刘磊
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 安卓移动应用;API推荐;功能推荐;应用产品推荐
{Abstract}: 近年来,移动应用已经渗透到人们生活与工作的方方面面。无论是简单的通讯和娱乐,还是像银行转账、网上付费和电子商务这样敏感的活动,人们都倾向于在他们的指尖完成。为了满足人们的需求,各种类型的移动应用的数量急剧增长,而移动应用的普及也带来了巨大的经济效益。与传统软件相比,移动应用更加重视用户,可以说移动应用是一类以用户为中心的软件系统。作为移动应用生态圈中两个重要的角色,软件开发者和应用商店需要完成好各自的任务,以保证产品和市场的用户数量,从而维持乃至扩大产品与市场的利益。就移动应用的开发者而言,他们不仅要在产品开发阶段实现规划好的功能而且需要在移动应用迭代时对产品所具有的功能进行拓展。在此过程中,开发者面临两个关键的问题:在开发和迭代应用时,哪些API可以支持产品的功能实现;以及在应用迭代时,应将哪些功能添加到产品中。此外,面对数以百万计的产品,移动应用商店的一个重要任务是为用户推荐适合他们的产品。随着移动应用的功能变得越来越强大,应用商店不应该再只考虑功能和流行度等传统的推荐要素,产品的隐私安全性也需要在推荐过程中被重视起来。针对这些问题,本文基于自然语言处理、数据挖掘和深度学习等技术进行相关研究并提出方法为安卓移动应用开发者推荐API信息和功能信息,以及帮助安卓移动应用商店为用户推荐合适的软件产品。需要指出的是,本文所提出的方法是针对安卓移动应用的,但是其解决问题的思想同样适用于其它类型的应用,如苹果商店中的应用。本文的主要研究内容如下:(1)为了帮助移动应用开发者在实现产品功能时获取到合适的API以提高产品开发和迭代的效率,从而能够尽早地抢占市场用户,本文通过总结移动应用商店中现有产品的API使用经验获取可重用知识,并基于获取的知识从功能级别为开发者推荐合适的API。首先,以UI(User Interface)组件为桥梁建立功能和API之间的映射关系。然后,对从产品UI中获取到的功能进行总结以建立一个功能框架,并且基于功能和API之间的映射关系为框架中的节点构建API知识。最后,根据查询功能的关键词以及表达形式识别其在框架中对应的节点,并且将节点的API知识以推荐列表的形式展示给开发者以帮助他们有效地使用推荐信息。(2)为了帮助移动应用开发者拓展产品所具有的功能,本文将UI页面作为信息挖掘的数据单元为功能之间建立关系,并且基于这些关系捕获应用相比于与其相似的产品缺少的关键功能,进而将这些功能推荐给应用开发者。首先,利用UI测试工具为移动应用收集UI页面,并给出方法挖掘这些页面中的功能信息。然后,通过对比UI页面中的功能信息,识别与被分析应用功能相似的产品。最后,通过挖掘被分析应用和它的相似产品的UI页面来建立功能之间的关系,并且基于获取到的关系为被分析产品的UI页面推荐合适的功能,即遗漏掉的关键功能。(3)为了帮助移动应用开发者拓展产品所具有的功能,本文还通过挖掘评论来获取用户的功能需求并将其推荐给应用开发者。首先,以人工的方式总结了相关的分类要素,并且基于这些要素训练一个评论分类器将评论分类为包含用户需求的评论和其它评论。然后,定义了两类抽取规则(基于关键词的语义规则和语法规则)从包含用户需求的评论中抽取功能信息。最后,以用户的关注度为参考要素评估从评论中得到的功能的推荐价值,并且基于现有产品的开发经验明确这些功能适合添加到的位置,从而帮助应用开发者更好地使用推荐信息。(4)为了帮助移动应用商店为用户推荐适合他们的产品,本文综合考虑隐私安全和产品功能提出了一个个性化的应用产品推荐方法。首先,利用现有方法挖掘移动应用的描述文本中的功能并将它们总结成可以用来描述更高粒度的功能信息的“方面”。其次,将应用的评论与得到的“方面”进行关联,并且通过挖掘关联成功的评论中的用户观点来评估产品在各个“方面”的完成质量。再次,基于应用在各个“方面”的完成质量对它们进行聚类,并且通过对比同一个簇中的产品的敏感权限使用情况进行安全分析。最后,根据产品下载历史推测用户对于各个功能“方面”的偏好程度并且将获取的结果与用户对于隐私安全的重视程度结合在一起,综合考虑安全和功能两个维度信息,完成产品的推荐工作。综上所述,本文针对安卓移动应用的API使用、功能拓展以及产品推荐这三个问题,基于自然语言处理、数据挖掘和深度学习等技术进行研究并且给出方法推荐(API和功能)信息与应用,旨在为开发者和移动应用商店提供帮助。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.000384
{DOI}: 10.27162/d.cnki.gjlin.2022.000384
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 零样本跨语言序列标注关键技术研究
{Author}: 梁世宁
{Tertiary Author}: 左万利
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 跨语言;序列标注;知识蒸馏;对比学习;预训练
{Abstract}: 随着从经济全球化到文化全球化的发展,人们希望可以随时随地获取世界各地的信息以促进生产生活。在全球化交流中,文字是人类记录和表达信息的首要形式,信息交融的过程必然会受到文字语言的影响。因此,如何有效地处理多语言文字信息是学术界和工业界当前面临的重要问题。近年来,深度学习技术深刻地影响了自然语言处理的发展进程和研究方式。基于深度学习的方法通常需要大规模的参数和数据来获得良好的性能,而这在多语言场景中是受限的。对于多语言自然语言处理任务,首先,低资源语言训练数据通常是稀缺的,其次,为每种语言维护多个模型显著增加了研究和应用的复杂度。因此,跨语言自然语言处理应运而生,其核心思想是通过模型和数据,将知识从源语言(高资源)迁移到目标语言(低资源),从而解决数据缺失、系统复杂和目标语言性能等问题。序列标注作为自然语言处理的基础任务和重要内容,旨在从非结构化文本数据中提取特定信息,是众多下游任务的关键前提,在跨语言自然语言处理中也有着同样的价值。本文以跨语言序列标注为研究内容,围绕零样本学习对现有方法总结归纳,针对存在的问题提出了相应的解决方案,具体研究工作如下:1.基于强化学习和知识蒸馏的跨语言命名实体识别。深度神经网络模型已被广泛用于序列标注任务,然而大部分方法仅适用于少数高资源语言。实际上,世界上大多数语言的序列标注有标签数据有限,甚至仅有无标签数据。面对这个挑战,跨语言序列标注早期依赖于源语言训练数据和翻译数据。为了利用在真实场景中相对容易收集的目标语言无标签数据,现有研究提出了一种基于半监督知识蒸馏的方法,通过目标语言无标签数据将知识从教师模型迁移到学生模型,缺点是学生模型模仿了教师模型所有的预测行为。针对以上缺点,从数据角度,本文提出了一种用于跨语言命名实体识别的基于强化学习和半监督学习的知识蒸馏方法。该知识蒸馏过程可以多轮迭代,并基于强化学习自适应地选择蒸馏中使用的无标签数据。实验结果表明,本文提出的方法可以针对不同语言模型的不同迭代动态地选择蒸馏样本,实现对目标语言大规模无标签数据的高效利用,性能显著优于基线方法,达到甚至高于多源语言知识蒸馏方法的水平。2.基于标签语义和对比学习的跨语言口语理解。预训练多语言模型虽然在零样本跨语言任务上展示了良好的性能,但各语言之间的表示对齐并不完善,导致部分目标语言上的模型迁移性能不理想。考虑到利用翻译数据微调模型会受到机器翻译的错误和可用性的影响,现有研究提出了一种仅依赖双语词典对源语言训练数据进行多语言语码转换的方法,通过构建下游任务的混合语言数据对齐多语言模型的表示。该方法局限于仅基于数据增强隐式地进行表示对齐,忽略了语义信息。针对以上问题,从模型角度,本文提出了一种用于跨语言口语理解的标签感知的自监督多层级对比学习方法。首先,本文利用槽类型集合,在标签感知模型中实现以其为锚点的跨语言知识迁移。其次,为了充分利用口语理解内在的语义层次,即话语-槽-词结构,本文提出了一个多层级对比学习框架。在上述三个层级,分别显式构建了“源语言话语-语码转换话语”、“源语言槽值-语码转换槽值”和“词的槽标签-槽值的词”的对比学习范式。实验结果表明,本文提出的方法在零样本跨语言口语理解中通过标签语义信息构建了不同层级上的对比学习,从语义角度优化了跨语言表示,与多语言动态语码转换方法相比,显著提高了性能。3.基于预训练和校准网络的跨语言序列标注。在跨语言分类任务上,现有工作的目标语言零样本迁移与源语言或目标语言监督训练之间的性能差距是可以接受的。但是,在跨语言序列标注任务上的差距十分可观,导致模型难以达到实用要求。因此,本文从任务角度,对零样本跨语言序列标注模型的结果进行分析,得出结论为一个主要性能障碍是模型预测中的边界错误。在目标语言上,零样本跨语言序列标注模型虽然可以有效地定位标注目标的局部上下文,但难以精确给出目标片段的边界。为了解决这个瓶颈,本文提出了一个两阶段跨语言序列标注框架。第一步中,基础模块采用序列标注模型来生成初始答案,第二步中,校准模块基于基础模块的输入输出以机器阅读理解的方式细化初始答案的边界。为了解决低资源语言缺乏训练数据的挑战,本文设计了一种基于自监督和弱监督的短语边界恢复任务,以增强校准模块的多语言边界检测能力。实验结果表明,本文提出的方法对多个零样本跨语言序列标注任务的多个基线都有明显提升,即使是在预训练任务没有覆盖的语言上也有很好的效果。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.000318
{DOI}: 10.27162/d.cnki.gjlin.2022.000318
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 电力科技知识驱动的专家匹配选择与优化分配模型研究
{Author}: 王其清
{Tertiary Author}: 李存斌
{Publisher}: 华北电力大学(北京)
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 电力科技;知识图谱;自然语言处理;评审专家;匹配选择;优化分配
{Abstract}: 电力科技研究高质量、多样化的咨询评审需求同相对滞后的科技知识管理、专家遴选方式上存在矛盾。一方面,科技创新是电力系统转型升级的重要支撑,“双碳”背景下的新型电力系统建设给电力科技高质量创新提出了新要求,同时随着能源与数字技术的深度融合,电力科技研究呈现出多学科、多领域交叉的趋势,为科技咨询带来更加多样化的需求;另一方面,面对电力科技咨询专家库规模的不断扩大,专家知识却没有得到有效挖掘、组织和管理,导致专家研究领域和方向描述不精准,传统的专家遴选方式已很难满足咨询评审需要。为缓解二者之间的矛盾,本文研究电力科技知识驱动的专家匹配选择与优化分配模型,主要研究内容如下:(1)构建基于预训练语言模型的电力科技文本特征表示。为了克服电力科技文本专业化、跨学科特点给知识获取带来的挑战,本文在收集和处理大量电力科技文本的基础上采用掩码语言模型预训练得到电力科技领域语言模型,使用人工参与标注的电力科技术语分类数据集微调所得模型并验证其对于电力科技领域文本特征表示的有效性,提高下游文本分析任务的效果。(2)构建面向专家优选的电力科技知识图谱。为了实现专家领域知识的高效组织和管理,本文从局部和全局两个维度界定实体关系类型,藉此建立面向专家优选的电力科技知识图谱。针对局部类型,构建基于规则语义分析的实体关系抽取模型,从专家成果语料中提取术语关键词并根据其功用形成成果-术语关系;针对全局类型,提出基于对比学习的电力科技术语远程监督实体关系抽取模型,使用领域语言模型和实体描述信息编码提升模型性能。(3)构建电力科技知识驱动的专家匹配选择模型。为了建立专家研究领域或方向的特征描述并为待评审项目匹配领域相关的候选专家,本文提出基于内容过滤的专家匹配选择模型,模型使用术语位置信息和背景信息提升专家特征向量表示效果,而为了融入电力科技知识图谱结构信息和专家-术语交互信息,进一步提出基于知识图谱嵌入的专家匹配选择模型,利用TransD和图注意力网络训练得到专家、术语图嵌入向量,提升专家匹配选择的准确性。(4)构建电力科技知识驱动的专家优化分配模型。为了从领域匹配的候选专家中挑选出适合项目评审的专家,需要考虑专家权威度和业务目标约束的影响。本文提出基于IF-AHP-DEMATEL和云模型的电力科技专家权威度评估模型,从主要业绩、主要获奖、个人能力三方面指标量化专家综合影响力;提出多项目评审场景下专家多目标优化分配问题,设计改进NSGA-Ⅱ算法对问题进行求解,提升了结果的多样性和收敛性,通过主客观组合赋权TOPSIS方法生成考虑决策人员偏好的评审专家分配方案。本文围绕电力科技评审专家优选问题开展研究,主要成果包括:(1)预训练得到适用于电力科技文本特征表示的领域语言模型;(2)从局部和全局两方面抽取实体关系并形成电力科技知识图谱,其中全局实体关系蕴含了专家-术语实体间的高阶关联信息;(3)综合利用知识图谱邻域结构、专家-术语交互和科技术语背景等信息得到专家研究领域的特征表示,实现专家精准匹配选择;(4)完成多项目复杂评审场景下考虑匹配度、权威度、业务约束的评审专家多目标优化分配建模,并设计优化决策算法求解得到专家分配方案。研究成果可为电力科技专家优选提供理论与实践支撑,为电力科技知识管理提供借鉴,有利于提高电力科技项目管理效率,同时对于其他科研领域的评审专家优选问题也具有参考意义。
{URL}: https://link.cnki.net/doi/10.27140/d.cnki.ghbbu.2022.000134
{DOI}: 10.27140/d.cnki.ghbbu.2022.000134
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像描述生成中的若干关键技术研究
{Author}: 周愿恩
{Tertiary Author}: 汪萌
{Publisher}: 合肥工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像描述生成;局部对齐;紧凑双向结构;速度与质量均衡;计算资源友好型
{Abstract}: 随着计算技术的高速发展和大规模数据集的提出,深度学习技术分别在计算机视觉和自然语言处理两个单模态领域上取得了突破性的成果。然而真实世界中的问题通常涉及多模态信息,因此研究者们在先前基础上开始聚焦于计算机视觉和自然语言处理的交叉领域。近年来,联合视觉和语言的相关任务成为研究热点,其中图像描述生成任务是提出最早,同时也是最基础和最重要的任务之一。图像描述生成任务要求计算机能准确且流畅地用自然语言描述图像中的内容。由于其具有的理论和实用价值,该任务自从被提出就受到了国内外学界和工业界的广泛关注。从2015年开始,基于深度学习的编码解码框架开始在研究社区中流行,并一直蓬勃发展至今,同时也取得了令人印象深刻的结果。然而该任务上的研究依然存在以下问题:第一,大多数现有方法专注于生成和图像全局语义匹配的描述性语言,而忽略了生成过程中的局部匹配,进而影响了系统的可解释性和可靠性;第二,大多数现有方法选择从左到右地生成描述语言,这种方法虽然直观,但是不能利用更丰富的双向语言信息和约束;第三,在加速图像描述生成的运行方面,现有方法没有很好地达到速度、生成质量及训练方式简易性三者间的平衡;第四,现有的基于视觉语言预训练的图像描述生成模型虽然很大程度上提升了生成描述的质量,但是它们需要消耗庞大的计算资源,并有被大公司垄断的趋势。这给图像描述生成的研究设置了无形的壁垒。为此,本文针对上述图像描述生成中的问题开展了一系列的研究,主要的研究内容如下:1.提出了一种用于增强图像描述生成模型局部对齐的弱监督方法。本文先提出了一种词性增强的图文匹配模型,然后利用蒸馏学习得到该模型内部更准确的图文局部对齐关系,并将其作为图像描述生成模型中视觉注意力模块的显式监督信号来改善图像描述生成模型的局部对齐。最后本文还探索了将图文匹配分数作为强化学习的奖励来隐式地改善局部对齐性。实验表明该方法能够有效地提升图像描述生成模型的局部对齐准确度和可解释性。2.提出了一种用于增强图像描述生成约束和信息利用的紧凑双向模型。本文提出了一种可以利用双向语言信息和约束的紧凑双向图像描述生成模型。具体来说,本文利用单个图像描述生成模型同时处理句子的正向和反向生成,并且可选择性地允许双向信息交互,最后从正向和反向中选择概率最高的描述作为输出。本文还将常规单流强化学习在此架构下扩展到了双向版本。实验表明这种结构能够利用双向上下文为图像描述生成提供更好的约束,同时能够自然地实现句子级别的集成且可并行执行,并达到了先进的性能。3.提出了一种用于兼顾图像描述生成速度、质量及训练简易性的方法。本文引入了一种半自动回归的结构。在该结构下,组内单词是以完全并行的方式生成,组间仍然保持原有的自动回归生成方式。这种方法可以通过调节组的大小来控制速度与质量间的均衡,并且可以直接继承原有自动回归生成的训练方式。本文进一步利用句子级别的奖励分数,通过强化学习缓解了局部并行导致的不连贯性。实验表明该方法很好地兼顾了图像描述生成速度、质量及训练简易性。4.提出了一种基于预训练的计算资源友好型的图像描述生成替代模型。本文站在大规模预训练的语言模型和视觉模型的肩膀上,基于‘选择交互转换’的设计原则,设计了两个高效的小连接网络连接它们用于图像描述生成。实验表明提出的模型可以获得与当前最好的生成式视觉语言预训练模型相当的性能,与此同时它消耗更少的资源,收敛得更快,使该领域的研究更加开放。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000074
{DOI}: 10.27101/d.cnki.ghfgu.2022.000074
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 弗雷格量词理论研究
{Author}: 郑甲平
{Tertiary Author}: 张燕京
{Publisher}: 河北大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 弗雷格;量词;现代逻辑;逻辑分析;逻辑主义
{Abstract}: 量词是现代逻辑中的一个基础和核心概念。现代逻辑对于量词的普遍处理始于弗雷格,他把握住量词的本质,全面、系统地探讨量词的性质和特征,首次建立起具有现代逻辑意义的量词理论。从横向看,弗雷格对量词进行逻辑刻画和哲学分析。作为弗雷格整个理论体系的基础部分,量词理论在弗雷格的数学哲学和语言哲学中发挥着重要的作用。从纵向看,弗雷格关于量词理论的研究不仅解决了传统量词理论中存在的许多问题,而且极大地推动了当代量词理论的发展,使得逻辑量词的研究随着现代逻辑的发展不断地深入。在弗雷格事业的开端,为数学提供坚实可靠的基础,即从逻辑推导出全部数学是他的行动纲领和目标。为了实现这种被称为逻辑主义的纲领,弗雷格意识到首先需要做的是构建形式化的人工语言。其原因主要在于,基于自然语言的传统逻辑具有较弱的语言处理能力,诸如传统逻辑不能准确、有效地刻画包含关系词、个体词以及多个量词的语句等。传统逻辑关于量词的研究不仅为弗雷格量词理论的建立提供深刻的理论背景,也充分显示出其理论构建具有的合理性和必要性。正是基于这种原因,弗雷格建立起能够表达和处理更具普遍性问题的量词理论。逻辑上,弗雷格表明逻辑学是追求真的普遍性的科学,而全称量词是其所构建的逻辑系统中表达普遍性的装置。弗雷格主张取消传统逻辑中语句的主谓区分,将函数-自变元理论看作是逻辑结构分析的主要方法。运用这种方法,弗雷格对量词这一现代逻辑的基础概念进行阐释。从句法上看,弗雷格对量词和量化命题的符号表达、逻辑性质等进行刻画,提出不同于传统逻辑的对当方阵,并且对包含多个量词的复杂命题进行表达和分析。从语义上看,“真”是弗雷格进行语义解释的核心概念;量词的涵义是思想的一部分,量词的意谓是其所限定的个体域;量词的语义解释实际上是对包含量词的句子的真值条件的确定。在弗雷格看来,逻辑对真的追求就是从涵义推进到意谓。哲学上,弗雷格不仅区分出概念和对象,而且区分出第一层概念和第二层概念。概念是其值总是真值的函数,以对象为自变元的概念是第一层概念,以第一层概念为自变元的概念是第二层概念。弗雷格对包含全称量词和存在量词的句子结构进行分析,并对与两个量词相关的哲学问题进行探讨。其一,普遍性的表达体现在句子的假言结构和不确定的成分之中,二者相结合起到表达普遍性的作用。全称量词的使用所得到的不是关于个体事物的认识,而是关于普遍性的认识。其二,“存在”一词的理解应与存在量词相结合。存在是概念的性质,存在量词表达一个第二层概念。“存在”是一个量词而不是谓词,因此上帝存在的本体论证明不成立。弗雷格的量词理论是一种具有普遍性的逻辑分析工具,它不仅是其数学哲学的基础,也是其语言哲学的基础。弗雷格的数学哲学主要解决的问题是为数学建立可靠坚实的逻辑基础。弗雷格的具体措施为:依据逻辑概念定义算术概念,依据逻辑公理定义算术公理,由此推导出所需的算术定理,从而实现他的逻辑主义构想。量词理论是弗雷格在进行逻辑主义研究的过程中创立的推理工具,之后量词理论又被应用于逻辑主义的具体实现过程。弗雷格语言哲学的根本任务就是通过对语言进行逻辑分析,以解决与本体论和认识论相关的哲学问题。以量词理论为核心的现代逻辑促使哲学领域中“语言转向”的发生,由此弗雷格创立出语言哲学这一新的哲学分支。弗雷格语言哲学的主要内容是意义理论,通过对句子涵义和意谓的分析,达到对语言意义的说明,从而使得人们能够更为接近语言和世界的关系这个语言哲学的根本问题。弗雷格对量词的认识有着广泛而深刻的现代逻辑语境。随着现代逻辑的不断发展,弗雷格的量词理论成为一个重要的研究课题。基于弗雷格量词理论的经典量词理论,自形成之日起,就有许多人主张对它进行扩展或者修正。当代量词理论的发展主要分为两个方向,即对经典量词理论的扩展和对经典量词理论的变异。作为经典量词理论的组成部分,弗雷格的量词理论尽管并不完善,但仍然发挥着它应有的作用。以广义量词和二阶量词为例可以清楚地看出,弗雷格的量词理论对于当代逻辑量词的研究,乃至对于现代逻辑和现代哲学的发展都具有重要的理论意义。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2022.000039
{DOI}: 10.27103/d.cnki.ghebu.2022.000039
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合先验知识的藏汉神经机器翻译研究
{Author}: 周毛先
{Tertiary Author}: 才让加
{Publisher}: 青海师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 藏汉机器翻译;先验知识;神经机器翻译;低资源;词向量;统计方法;词性标注
{Abstract}: 随着计算机技术在各行各业应用的逐渐普及和深入,全球经济加速一体化以及不同国家、地区间的交流频繁化,通过人工方式进行翻译不论是从时间上还是成本上都不再适应当今社会飞速增长的翻译需求现状,人们转而将目光投向机器翻译方法,这使得机器翻译迎来了一个全新的发展机遇。近几年深度学习方法的出现使得人工智能快速发展,神经机器翻译(Neural Machine Translation)取代过去的统计机器翻译方法成为机器翻译的新一代研究方向。神经网络翻译模型获得高质量翻译结果依赖于大规模的双语训练语料,研究表明,在资源不足的情况下,神经机器翻译的性能显著下降;而藏文由于数字化资源稀缺,目前只有小规模的藏汉双语平行语料库来训练翻译模型。对此,本文提出融合先验知识的方法,能在一定程度上改善藏汉双语语料匮乏引起的问题,提高藏汉机器翻译质量。本文具体对如何融合以下四种不同类型的先验知识进行了研究,主要研究内容与创新点如下:1.融合词向量的藏文句子相似度研究:针对目前关于藏文句子的相似度计算方法研究较少且现有方法精度较低的问题,本文提出一种融合词向量的藏文句子相似度计算方法,首先通过Skip-gram模型和CBOW模型对500M大规模藏文单语语料库训练得到两种藏文词向量,然后据此计算藏文句子向量,最后设计实现了两种基于表层信息的藏文句子相似度计算方法——基于词向量与欧几里得距离和基于词向量与Jaccard相似度的计算方法——来计算藏文句子的相似度,通过对比实验表明基于Skip-gram词向量与Jaccard相似度的藏文句子相似度计算方法能够得到85.6%的准确率,优于其他组合方式。2.融合域外模型的藏汉神经机器翻译领域自适应方法研究:针对目前鲜有高效训练针对不同领域的藏汉神经机器翻译模型方法的研究,本文提出一种基于混合微调的藏汉领域自适应方法,首先使用20万句对的藏汉通用平行语料库训练一个藏汉通用翻译模型,然后通过领域自适应方法以此模型作为父模型进行混合微调,分别利用5万句对的藏汉政府公文平行语料库和一万五千句对的藏汉自然科学平行语料库,在此基础上训练得到政府公文、自然科学两个特定领域的藏汉机器翻译模型,实验证明在低资源条件下该方法能够在域外模型的基础上快速有效地训练出域内翻译模型,且整体表现优于域外模型,在各自领域测试集上的BLEU值相比通用模型提升到19.03和12.15。3.融合词性特征的藏汉神经机器翻译方法研究:为了在有限的语料基础上利用更多的外部信息得到最佳的翻译性能,本文通过引入藏文词性特征,即在训练过程中加入源端藏文词性标注(POS)作为输入特征,在Transformer注意力机制的编码器-解码器体系结构中泛化了编码器的嵌入层,以支持嵌入除词汇特征外的词性特征信息。通过对比合并、连接两种不同的嵌入方式,实验验证了连接方法对翻译效果的提升更为明显,BLEU值提升了3.99。4.融合统计方法的藏汉神经机器翻译方法研究:针对藏汉统计机器翻译中词对齐结果效果较好,而藏汉神经机器翻译模型中的对齐信息与之存在显著差异的问题,本文提出一种融合统计方法的藏汉神经机器翻译方法,首先使用统计机器翻译方法生成藏汉平行语料的双向对称词对齐信息,然后在Transformer模型训练过程中使用该词对齐信息监督藏汉神经机器翻译模型的训练过程,使模型达到更为准确的翻译和对齐效果。实验表明在低资源环境下,该方法使BLEU值提升了1.7。综上,本文试图通过引入除常规神经机器翻译所需的双语平行语料库之外的先验知识,如藏文单语语料库、域外模型、藏文词性标注信息、藏汉词对齐信息,来解决目前藏汉机器翻译存在的一些问题。实验表明先验知识的融合在一定程度上能够提高藏汉机器翻译质量。本文也为未来进一步在藏汉机器翻译中更好地引入更多丰富的先验知识打下基础,对将来相关研究工作有一定的参考价值。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2022.000712
{DOI}: 10.27778/d.cnki.gqhzy.2022.000712
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: Python在图书情报学的应用与扩散研究
{Author}: 孟文静
{Tertiary Author}: 宋歌
{Publisher}: 东南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: Python;工具视角;知识单元;应用扩散;学科发展
{Abstract}: 一个学科的发展是与研究工具的出现与应用相辅相成的,当新的研究工具进入某一学科,就意味着学科的领域范围和深度发生了变化。研究工具的发展与应用是对科研生态演变的回应,通过对研究工具的使用分析,可以比较客观且真实地揭示学科发展的历程和动向,以及研究领域、研究问题的变化。由于已有研究主要集中在对图书情报领域常用软件的考察,对于Python的研究还很少,深入到研究主题、反映学科发展的探索较为缺乏。而Python伴随了数据密集型研究范式在图书情报学科的萌发、演进过程。在这种情况下,图书情报学科对Python软件包的选择、引入与使用、创新,以及利用Python进行了哪些研究,研究主题发生了怎样的变化都值得深入探讨。因此,本研究以Python作为工具视角的切入点,通过分析该工具在图书情报学科的应用演进及特征,以管中窥豹的方式揭示图书情报学科在变革中的发展进程及未来方向,同时为本学科软件工具的开发提供需求参照,也为学者选择适合的软件包及其应用组合提供参考。本研究基于工具视角,从应用扩散、应用网络和应用领域三个维度对SSCI和CSSCI来源期刊展开Python软件包的应用与扩散分析。鉴于国内外Python软件包引用的不规范性及软件包数量的不可胜数,采用全文检索结合人工标注法可解决数据采集难题。首先,本研究基于文献全文所使用的工具实体的应用情况对工具扩散概况进行了梳理,以把握软件包及其研究的整体发展脉络。以软件包的功能为基础将软件包划分为11个类别,并提取热门软件包,以便探知图书情报学科软件包应用特征。其次,以揭示工具实体的关联关系为目的构建软件包组合应用网络,刨析Python怎样被使用的问题。最后,以主题领域网络揭示Python知识架构及其领域变迁,分析国际与国内的工具知识架构差异,并根据时序演化预测未来研究方向。经过研究发现,通过以Python为例的分析可知工具视角的研究对于学科发展具有现实意义。Python中的软件包作为其他学科的工具,被图书情报学科所借用,这实际已经对学科发展产生影响,已经引起了学科边界的拓展。不限于某种工具,从更广泛的意义来说,挖掘研究工具的应用特征能够从工具视角探析学科变革、现状及态势,对于促进学科发展至关重要,如研究范式转型,研究方法与技术的更迭,研究热点的变迁和趋向,研究领域新生及新研究问题的出现,明确学科发展历程中的关键事件及时间节点等,并可通过分析演变动因,评估学科发展动态,明晰学科前沿,预测未来发展方向。总之,工具视角下的学科发展及动向分析,有助于学科发展规划,前瞻性研究布局,促发新的研究领域等工作的开展。
{URL}: https://link.cnki.net/doi/10.27014/d.cnki.gdnau.2022.000915
{DOI}: 10.27014/d.cnki.gdnau.2022.000915
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于自然语言处理及知识图谱的搜索系统设计与实现
{Author}: 陈杨
{Tertiary Author}: 肖创柏
{Publisher}: 北京工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 搜索引擎;知识图谱;语义搜索;三元组抽取
{Abstract}: 各企业在生产运营过程中会产生大量的数据,这些企业内部数据需要通过企业级数据治理平台来进行数据管理和数据搜索。而当前大多数企业级搜索引擎都是基于关键词匹配进行信息检索,无法形成与用户之间良好的交互,也无法理解用户输入的查询语句的意图。针对上述问题,本课题设计开发了基于自然语言处理技术及知识图谱的企业级搜索系统,能够一定程度上理解用户输入语句的语义,使搜索引擎实现知识层面的语义搜索。本文的主要研究工作和创新点如下:1.根据现有企业级搜索系统所存在问题和本系统的目标,从功能性和非功能性的角度对系统进行了全面需求分析。功能性方面,系统针对企业级数据需要实现数据处理、数据索引、知识图谱构建和信息检索;非功能性方面,系统需具有扩展性、稳定性、用户友好性等特性。对系统进行了总体架构设计,对系统的各个功能模块进行了详细的设计。2.对知识图谱构建方法进行了研究。制定了适于企业级数据的知识图谱构建方案,研究了三元组抽取方法。分别基于Bert-base预训练模型和Ro BERTa预训练模型进行了三元组抽取实验,并对结果进行了对比,基于Ro BERTa训练出的三元组抽取模型效果更优。本系统实现了基于Ro BERTa模型的三元组抽取方法,作为知识图谱构建的前置工作。围绕三元组抽取设计开发了知识管理功能,用于对数据进行打标、训练模型、数据审核、知识抽取及数据存储,进而实现知识图谱构建。3.对基于知识图谱的语义搜索方法进行了研究。首先研究了基于问句模板匹配的方法,并进行了设计与实现。接着研究了对此方法的改进,提出了“关系匹配”方法。介绍了此方法所用到的语义匹配技术和实现方式,对此方法与“问句模板匹配”方法进行了对比,并对此方法进行了实现。根据分析,本文提出的“关系匹配”方法更加容易获得用户的搜索意图。4.围绕对系统的需求分析,对系统进行了设计,并对系统的各个模块进行了具体的实现。基于三元组抽取方法,实现了将企业数据按类型或领域构建知识图谱的核心功能。通过知识图谱的语义表示能力,实现了本文提出的“关系匹配”方法,使系统一定程度上实现了对用户所输入的查询语句的意图识别,进而实现了基于知识图谱的语义搜索功能。
{URL}: https://link.cnki.net/doi/10.26935/d.cnki.gbjgu.2022.000170
{DOI}: 10.26935/d.cnki.gbjgu.2022.000170
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文档的工程建设安全管理知识图谱构建和应用
{Author}: 吴浪韬
{Tertiary Author}: 胡振中
{Publisher}: 清华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 信息抽取;知识图谱;自然语言处理;合规性检查;智能问答
{Abstract}: AEC(Architecture,Engineering&Construction,建筑、工程和施工)行业是典型的知识敏感型和风险敏感性行业,其在工程建设过程中高度依赖于国家规范、行业标准、集团内部规定等强制性文件,这给工程建设管理中包括项目管理条例编制、交底方案审查、施工报告验收等多个必要工作带来了较大的困难,因为这些工作所涉及的知识要点繁多且相互关联复杂,同时具体的合规性要求也因行业不断发展和规范不断细化而越发难以被人力所掌握。另一发面,提高行业的KM(Knowledge Management,知识管理)水平被认为有显著意义,而目前又已经有较多工作从领域规范性文本出发并展开研究,因为规范性文本包含了大量AEC相关的显性知识。因此,可以从这些方向出发,探索上述工程建设管理中典型问题的解决方案,提高工程建设管理的效率和质量。然而,目前相关研究仍然面临两个方面的不足:一是所处理的数据和验证的规模均较小,二是涉及的特征还较为单一。这两点都导致目前的相关研究面临泛用性和可靠性方面的问题。为处理上述问题,本研究首先收集了307MB的大规模规范性文本数据,并从多个粒度进行了复杂度降级和丰富的特征分析工作,以支持从规范性文本数据中批量化获取结构化信息。然后,本研究对工程建设管理的基本体系进行梳理,并以工程建设管理知识元对象视角作为切入点,生成了拥有20万节点和200万条边的大规模知识图谱,用于为相关知识要点及其语义关联的快速检索提供支撑。在此基础上,本研究进一步提出语义化的知识检索、评估、理解和应用全流程,并在工程建设安全管理条例的校核和高指向性的语义化安全知识问答两个方面实现具体的功能应用。最后,本研究对所提出的技术路线以及相应数据积累进行了平台化整合,完成了“特征→知识→应用→平台”完整流程。实例验证表明,本研究所构造的知识图谱总体质量较好,提出的工程建设安全管理条例的自动校核方法也获得63%的F1指标,已经可以在一定程度上支持相关的工作需求。总体上,本研究所提出的技术路线和相应数据积累提高了工程建设管理的自动化水平,并具有较大的应用前景。
{URL}: https://link.cnki.net/doi/10.27266/d.cnki.gqhau.2022.000105
{DOI}: 10.27266/d.cnki.gqhau.2022.000105
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数据挖掘和可视化的快递行业研究
{Author}: 吕极然
{Tertiary Author}: 熊巍
{Publisher}: 对外经济贸易大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 快递企业;快递用户需求;快递用户满意度;数据挖掘;文本挖掘
{Abstract}: 中国社会经历着日新月异的发展变化,交通基础设施建设日趋完善,移动互联网成为新的基础设施,电子商务异军突起,网络购物成为人们日常生活的新选择,这些变化推动着快递行业迅速发展。本文从用户角度分析研究快递行业,因为用户需求驱动快递行业往智能化、高效化、精细化方向发展,用户对快递服务的满意度评价则直观反映了快递行业所处的发展阶段。本文参考贝恩B2B价值要素模型和用户动机分析Censydiam模型,构建用户需求快递企业指标,提取快递行业服务模式、新技术应用关键词,并分析快递行业发展现状;在用户满意度方面,参考企业服务质量SERVQUAL模型和物流服务质量LSQ模型标准,并结合快递服务国家标准,构建出本文的用户满意度快递指标。本文利用互联网公开的大数据,利用数据挖掘和自然语言处理领域的新技术,对快递行业的用户需求、用户满意度进行挖掘研究并进行可视化呈现。从黑猫投诉平台、上市快递企业官网新闻、国家邮政局官方网站数据、新浪微博等多个渠道,得到EMS、顺丰、申通、中通、圆通、韵达六家国内知名快递企业相关数据。利用关键词识别、词语聚类、语义计算、情感分析等技术,对文本数据进行分析,对本文提出的用户需求快递企业指标和用户快递满意度指标进行验证,实现了基于数据挖掘与可视化技术的快递行业研究。
{URL}: https://link.cnki.net/doi/10.27015/d.cnki.gdwju.2022.000285
{DOI}: 10.27015/d.cnki.gdwju.2022.000285
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 新高考政策下高考志愿推荐研究与实现
{Author}: 孙钦英
{Tertiary Author}: 刘行兵
{Publisher}: 河南师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 新高考政策;高考志愿推荐;专业分类;混合推荐
{Abstract}: 高考新政策的实行,标志着我国高考制度进入了新的阶段。新高考模式在志愿设置、填报规则和志愿录取等方面都发生了较大变化。在考试科目上,取消了文理分科的方式,采取“3+3”选考的形式;在高考志愿填报方面,由采用“院校+专业”志愿模式转变为“专业+院校”模式。志愿填报方式的转变不仅增加了对考生选科的要求,而且提升了考生的志愿填报数量。这些变化在扩宽学生选择权的同时,也增加了志愿填报的复杂度。大量的志愿信息使得考生在志愿填报时难以做出选择,造成“高分掉档”、“录取非所想”等现象。因此,本研究在新高考政策的背景下,以新高考志愿推荐为中心,围绕专业分类、专业分数线预测与志愿推荐等问题展开研究,设计并开发了一套在新高考政策下为考生进行个性化志愿推荐的系统。论文的主要研究内容如下:(1)构建一种基于特征加权的多标签K近邻(Multi-label K-Nearest Neighbor Based on Feature Weighting,WML-KNN)分类模型,实现了专业多标签分类。通过梳理霍兰德职业兴趣理论,使用文本分析技术,将职业兴趣与高校专业相关联,实现基于职业兴趣类型的高校专业分类。考生通过职业兴趣测试可以得到其职业兴趣类型,利用考生的兴趣类型为其进行相关专业推荐,有助于考生明确未来的专业选择方向,为志愿选择迷茫的考生,在专业方向选择上提供初步参考。实验结果表明,该分类模型与ML-KNN、BR、LP和CC算法相比,在专业数据集上Hamming loss值分别减少了1.69%、3.1%、5.8%和4.45%,Macro-F1值分别提升了4.38%、4.8%、6.24和7.24%,依据分类产生的专业推荐也比较符合用户的职业兴趣倾向。(2)建立一种基于模糊C均值聚类的岭回归(Ridge Regression Based on Fuzzy CMeans Clustering,FCM-RR)预测模型,实现了专业录取分数线预测。综合考虑影响院校专业录取分数线的各种因素,采用模糊C均值聚类算法和岭回归算法,实现了专业录取分数线预测;并且在此基础上,利用正态分布函数对院校专业的录取概率进行计算,实现了专业录取梯度设置。该预测模型有效地结合了院校专业评价信息、历史录取信息和用户分数,通过对专业录取分数的预测,可以帮助考生进行志愿填报。通过实例证明,该模型具有良好的预估能力,提高了院校专业分数线的预测精度,该模型的误差低于其他5种预测方法,预测效果比RR模型的RMSE值降低了4.9546、MAE值降低了3.0545,专业梯度的设置也符合高考志愿梯度划分规则。(3)构建了一种基于多元信息的新高考志愿混合推荐模型。基于与志愿相关的多元信息,采用混合推荐的方法实现新高考志愿的个性化推荐。本研究结合基于实例和基于约束的推荐方法,综合利用用户职业兴趣、专业录取概率、选科及其个性化需求,通过混合推荐算法,为考生提供一个满足个性化需求的志愿表单。通过实例证明,该方法具备可行性,志愿推荐结果也能满足志愿填报规则和用户的个性化需求。(4)设计并实现了一个新高考志愿个性化推荐系统。结合本课题研究成果,使用PHP语言,为考生提供了一个智能化新高考志愿服务平台。该平台实现了信息的综合检索、信息交流、兴趣测试、专业推荐、志愿模拟和个性化志愿推荐等功能,满足了用户志愿填报的需求。该平台在2021年被推广使用,目前用户量达到1500余人。
{URL}: https://link.cnki.net/doi/10.27118/d.cnki.ghesu.2022.000270
{DOI}: 10.27118/d.cnki.ghesu.2022.000270
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的不同信息渠道投资者情绪指标构建及其对股票预测能力研究
{Author}: 李凯旻
{Tertiary Author}: 王满;尤苏蓉
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 投资者情绪指标;Fin-BERT模型;情感分析;半衰期配权法;深度学习
{Abstract}: 20世纪80年代行为金融理论悄然兴起,传统的资本资产定价模型(CAPM)和有效市场假说(EMH)的权威地位开始受到动摇。行为金融理论认为,内在价值并不是决定市场价格的唯一因素,很大程度上投资者的心理与行为也在影响着市场价格的变化。相较于国外,中国股票市场的投资者构成比较复杂,并且投资者受到信息的来源广泛。来自不同渠道的信息影响着投资者对股票市场的期望和决策,造成股票市场的波动。因此,正确的度量投资者情绪不仅有助于监管部门对市场的监控,还能帮助投资者进行投资决策。迄今为止,许多学者开始注重于如何从文本数据中挖掘投资者情绪,从而建立投资者情绪指标。以往的研究中,在数据维度方面,往往只针对单一的信息渠道进行研究,但是投资者接收信息的渠道是多元的,随着互联网的发展产生的海量的文本数据,新闻,评论和研报文本都会对投资者产生不同的情绪引导;在文本情感分析方面,目前BERT模型在文本情感任务上取得不错的表现,但仍有提升空间,可以从训练方式和模型结构方面进一步优化构建适于金融文本的Fin-BERT模型来提升对文本的语义学习能力;在指标构建方面,现有研究没有考虑信息的影响程度和持续性特点,实际上不同渠道的信息对投资者的影响程度是不同的,并且可能在后续一段时间内影响着投资者的判断和决策。基于上述背景,本文综合考虑不同渠道的信息,使用新闻报道,股吧评论和研究报告分别度量宏观信息,散户投资者和专业机构对股票市场的投资者情绪,能够全面量化市场情绪。首先,针对新闻,评论和研报的特点,设计了特殊化的数据预处理方法,并建立了不同的情感分析模型。对于新闻和评论,构造了适合于金融文本的Fin-BERT情感分析模型;对于研报,采用语义规则模型提取文本情绪。然后,本文考虑了信息对投资者的影响程度和持续性,利用半衰期配权法结合文本阅读量和机构排名等信息,分别对新闻,评论和研报文本构建日度的投资者情绪指标。最后,为了探究本文所构建的投资者情绪指标的有效性,利用格兰杰因果检验从统计意义上验证了其与股票收益率之间的因果关系;并将投资者情绪指标作为输入因子使用LSTM模型探究了其对收益率的预测能力,结合DM检验从预测能力方面证明了基于多信息渠道的投资者情绪指标能够显著提高预测能力。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.000102
{DOI}: 10.27012/d.cnki.gdhuu.2022.000102
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人工智能的财经新闻与股票指数相关性研究
{Author}: 陈若新
{Tertiary Author}: 水丽淑
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 股票指数;财经新闻;人工智能
{Abstract}: 随着互联网的飞速发展,以及近年来人工智能的兴起,尤其是其分支自然语言处理技术的大规模应用,金融从业者能够利用海量的财经新闻去对股市波动进行预测和分析。在这种大背景下,使用人工智能相关的新技术对财经新闻与股价趋势的关系进行分析就十分有意义。本文实证使用人工智能相关技术及工具对财经新闻进行量化,并借助人工智能相关算法,通过量化好的财经新闻去预测股票指数涨跌,从而揭示财经新闻与股市之间蕴藏的规律,以此帮助投资者更好地做出决策。本文通过使用股票指数的涨跌标注相关新闻文本数据。分别标注四组数据并且设置相关的四组独立实验。将数据集划分为测试集和训练集,使用训练集训练人工智能模型,并分别在验证集上进行验证,得到相关实验数据。之后根据实验数据分析当日英文新闻与当日和次日道琼斯指数涨跌的相关性以及当日中文新闻与当日和次日上证斯指数涨跌的相关性。根据分析的结果,财经新闻预测股票指数涨跌的准确程度较高,证明了财经新闻与股票指数的涨跌间存在较强的相关关系,且财经新闻与股票指数上涨和下跌间相关的程度并不一致,而且实验结论表明了股票指数对于财经新闻有明显的反应滞后,股票指数的涨跌对于前一日的新闻反应更为敏感。本文的研究成果可以在一定的程度上丰富该领域的研究,具体很强的实践意义以及创新性,并且从学术理论的角度拓宽了新闻媒体报道对金融市场影响的研究思路。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.000443
{DOI}: 10.27204/d.cnki.glzhu.2022.000443
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于情感分析的电影知识图谱推荐和主题研究
{Author}: 杨培琛
{Tertiary Author}: 莫赞
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 情感分析;知识图谱推荐;主题挖掘;电影领域
{Abstract}: 在全球信息化的影响下,电影文化产业持续发展,一方面为社会效益的增长作出巨大贡献,另一方面也在各国文化交流中承担着文化交流的载体作用。随着移动互联网技术的发展,许多在线影视平台快速兴起,掀起一场在线影视革命。由于数据传输技术的突破,越来越多的电影资源能够在线上被传播和共享,大量的电影信息能够在一个终端里快速呈现在用户面前。但与此同时,网络电影数量剧增导致的“信息过载”问题存在于各平台之中,在迎面而来的海量电影里用户往往不知所措,无法快速选择感兴趣的电影。而电影推荐系统能够分析出用户喜欢的电影并主动推荐,不仅节省了用户查找影片信息的时间,而且也能够让用户对推荐系统产生依赖性,提高用户忠诚度。因此,为了改善电影“信息过载”问题,本论文以电影为研究的主要对象,以电影的情感为主要切入点,以Kaggle网站中的IMDB电影数据集为数据基础,综合LSTM模型和KGCN模型提出基于情感分析的电影知识图谱推荐模型KGCN-S,一方面将KGCN-S模型与其他三个知识图谱推荐模型进行性能对比,结果表明KGCN-S模型在AUC、ACC、F1和召回率四个指标上都表现最好;另一方面,根据情感偏向概率对情感进行二分类、三分类和五分类,并分别构建知识图谱,再运用KGCN-S模型进行运算,计算出每一个样本数据的准确率,通过统计检验的方法发现三类情感特征和五类情感特征的样本在KGCN-S模型上的ACC显著优于两类情感特征的样本。此外,为了探究观众喜爱的电影主题,本论文还从情感和评分两个维度对电影数据集进行分类,再进行LDA主题挖掘,挖掘出不同情感和评分下的多个电影主题,从中总结出用户更喜欢的电影主题。通过对上述结果的分析,本论文总结出以下结论:1.情感和情感丰富度对提升电影知识图谱推荐性能有明显作用;2.对于纪录片,用户更容易给予好评;而对于恐怖片,用户更容易给予差评;3.用户更喜欢日常生活中难以接触和想象到的相关主题;4.对于日常生活中容易触及和想象到的相关主题,用户更希望从电影中观看到与主题情感相反的故事。本论文所进行的研究改善了电影“信息过载”问题,丰富了电影知识图谱体系,提升了电影知识图谱推荐性能,总结了用户所喜欢电影的主题特点,最后根据研究得出的结论给电影推荐平台和电影创作方提供具有一定可行性的建议。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001003
{DOI}: 10.27029/d.cnki.ggdgu.2022.001003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于度量学习的小样本关系分类方法研究
{Author}: 张潆心
{Tertiary Author}: 彭涛
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 关系分类;小样本学习;度量学习;原型网络;关系孪生网络
{Abstract}: 面对生活中来自各行各业的海量数据,如何从中有效地获取关键性的精简信息成为了人们的迫切需求,计算机进行信息处理研究的目标正是将获取到的这类非结构化数据进一步处理,转换成计算机可存储应用的结构化数据。关系分类作为自然语言处理中的一项重要问题,用来对句子中实体对之间的语义关系进行分类,通过对标记数据的训练学习,将非结构化数据中抽取的信息进行结构化处理。传统的分类方法以特征向量和核函数作为基础,随着深度学习的不断发展,基于深度学习的方法逐渐成为了关系分类任务中的主流方式。为减轻有监督学习中人工标记数据的负担,衍生了远程监督的学习方式。但真实场景中的关系呈长尾分布,因此需要大规模数据支撑的分类方式难以解决长尾问题。针对这样的问题在本文中进行了小样本学习的关系分类方法研究,通过对已知关系中少量样本的学习,实现对未知关系类别的分类。基于度量的方法以其简单高效的方式在小样本学习中获得了优异的效果,因此在本文中对基于度量学习的小样本关系分类任务进行了进一步的研究。本文以度量学习中的原型网络为基础解决样本匮乏的问题,以词嵌入和位置嵌入组合的方式构建词向量,结合卷积神经网络结构提取实例特征,在支持集的各类别中计算原型中心作为类别代表,通过度量查询实例和各类别原型中心的距离实现分类。为了降低支持集中特殊数据对原型中心计算造成的偏差,同时考虑不同查询实例在进行分类时对支持集训练的影响,在本文提出的模型中加入了关系孪生网络结构,计算支持实例和查询实例的相似性分数,通过二者的相似度分配支持实例权重,并将原型中心的计算方式由传统的均值计算调整为各类别中支持实例的加权和。在模型中还加入了交叉融合层,对查询实例和原型中心的语义信息进行结合,得到在彼此影响下更具有针对性的特征向量,提高各类别对于查询实例的区分性。在训练的优化部分,以原型网络中对查询实例到各类别原型中心距离的优化为基础,加入了针对支持实例之间距离的优化,以缩小同类别中支持实例之间的距离、扩大不同类别间支持实例之间的距离为目标,提高了类别中实例聚合度的同时,也提高了类别间的分散度。实验结果表明,在几种小样本学习设置下与基线模型进行对比,本文提出的模型都提高了关系分类的准确率,说明了本文提出模型在关系分类任务上能取得更好的效果。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.002909
{DOI}: 10.27162/d.cnki.gjlin.2022.002909
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于BERT预训练模型的功能肽预测问题特征提取算法研究
{Author}: 张亚琪
{Tertiary Author}: 周丰丰
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: HLA-I结合肽预测;自然语言处理;BERT模型;功能肽预测;特征选择;特征降维
{Abstract}: 随着后基因组时代的到来,大量蛋白质序列的出现给研究人员带来了新的机遇和挑战,将计算机科学引入生物信息学领域成为一种必然,这种新颖的生物信息学研究方法给“数据”带来了无限可能。功能肽在人体生命活动的调节中发挥重要作用,不同类型的功能肽的预测问题已经成为生物信息学中的热点研究问题之一。人类白细胞抗原(HLA)是一种存在于大多数人体细胞表面的分子,在免疫系统抵抗外来细胞入侵和调节免疫反应中发挥重要作用,T细胞抗原受体(TCR)可以识别癌细胞表面的HLA-肽复合物,并利用有毒的T淋巴细胞破坏这些癌细胞,因此准确预测HLA-I等位基因和肿瘤抗原肽的结合会促进癌症免疫疗法的快速发展。本文提出了一种基于BERT预训练语言模型的功能肽的特征提取算法。针对目前I类HLA(HLA-I)分子与抗原肽的结合预测研究中,氨基酸序列的特征构造算法依赖传统序列评分函数而导致的特征单一问题,为突破使用经典机器学习算法构造氨基酸序列特征的局限性,本研究中将自然语言处理领域的特征构造技术迁移至功能肽的预测问题。类似于文本语言是由固定字母表所定义的,蛋白质序列通常由20种不同的常见氨基酸组合形成,从组成和信息完备性的角度来看,蛋白质语言和自然语言间存在某种共性。本文中,将功能肽的氨基酸序列视作自然语言的句子,将每个氨基酸视作自然语言的字母,利用蛋白质语言和自然语言间的共性,从多个维度提取功能肽序列的潜在特征,从而创新功能肽预测问题的研究思路。本文以HLA-I等位基因与肿瘤抗原肽的结合预测任务为例,基于预测模型的不同适用范围角度,提出了等位基因泛特异性模型Prot HLAI和等位基因特异性模型HLAB。等位基因泛特异性模型Prot HLAI的特征提取模块采用了Prot Bert模型结合Bi LSTM模型和注意力机制的级联网络结构,实验中使用了26个独立的子数据集,对Prot HLAI和其它八种预测工具的性能进行对比。结果显示,本算法在其中的16个子数据集上均有最优的性能表现,且在所有预测工具中是性能表现最稳定的。等位基因特异性模型HLAB采用了Prot Bert模型结合Bi LSTM模型的级联网络结构构造特征提取模块,HLAB模型覆盖了共360个不同的特异性分类任务,与其他八种预测工具进行性能对比的结果显示,HLAB模型可以在90%的预测任务中取得最优的分类性能。Prot HLAI模型和HLAB模型的实验结果证明:1.本文提出的基于BERT的功能肽特征提取算法可以在不同的预测任务中达到该问题领域最先进的性能。2.BERT结合其他模型的级联特征提取模型是可以更有效的对BERT模型提取的特征进一步“加工”,从而得到更契合实际下游任务的特征提取算法。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.002934
{DOI}: 10.27162/d.cnki.gjlin.2022.002934
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于小样本学习和终身学习的因果关系抽取
{Author}: 张志远
{Tertiary Author}: 左万利
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;因果关系抽取;小样本学习;终身学习
{Abstract}: 因果关系抽取是自然语言处理中关系抽取任务中的一类任务。关系抽取是信息抽取的一个重要子领域,关系抽取主要目的是负责识别各种文本中的实体关系。而因果关系抽取,是实体关系中的原因结果关系,本文对文本中的因果关系进行抽取,这有助于提高各种下游自然语言处理任务的效率。并且可以结合知识图谱等相关技术,通过建立因果关系网络,应用到各个领域中。起初人们通过人工构建因果关系模式进行因果关系抽取,这种方法耗时耗力,并不能适应现在信息的爆炸增长。随着深度学习技术的不断成熟,各种神经网络模型的兴起,让因果关系抽取方法有了更多的可能。在进行因果关系抽取的任务时,总会面临数据量小,数据差异大的问题,同时让机器具有智能避不开从小数据上进行泛化学习,以及持续不断的学习。在这种需求下,人们提出了小样本学习和终身学习方法,这是机器向人靠近的一步。通过小样本学习,可以解决因果关系数据量少,难以较好的训练模型的问题。而结合终身学习,也可以解决每次训练都是来自不同领域的数据,互相之间因果形式差异大的问题。本文的创新点是通过结合小样本学习和终身学习提出了一种因果关系抽取模型,用来获取少量标注数据的因果关系数据集上的因果关系,并通过终身学习进行模型能力的提高,来获取更好的因果关系抽取效果。本文在四个数据集上进行实验其中两个是小数据集(Causal TB,Event Story Line)两个是大数据集(Sem Eval2010-task8,Sem Eval2020-task2),以验证本文模型中小样本学习模型的效果。实验结果表明了小样本学习的必要性,在小数据集上我们有40%左右的提升,虽然效果仍比不上在大数据集上的因果关系抽取效果。同时本文通过对几个主流的神经网络模型进行对比试验,并将小样本模型替换为这些主流模型进行对比实验,本文的模型对比LSTM,BiLSTM,CRF,Transformer,Bert模型在大数据集和小数据集上均有不同的提升,这证明终身学习是有效的,能进行更好的因果关系抽取。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.003195
{DOI}: 10.27162/d.cnki.gjlin.2022.003195
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多任务学习的自动人格检测方法研究
{Author}: 陈杭婷
{Tertiary Author}: 徐昊
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人格检测;文本分类;深度学习;自然语言处理;多任务学习;Longformer
{Abstract}: 近些年来,随着大数据等信息技术的发展,泛在感知数据和图形处理器等计算平台的完善,人工智能技术的发展得以急速推进。人工智能是计算机科学的一个分支,它企图生产出一种和人一样思考并能做出反应的智能机器。人格是一个人的情感,行为及其动机和其思想模式等特征的结合,它表明个人的偏好,影响着个人的决定。因此针对人格的自动化检测可以视为对人的意识、思维等信息进行模拟,在社交文本挖掘中具有重要意义,并已经逐渐成为人工智能情感计算领域的一个重要的子课题。自动人格检测是指借助人工智能领域的自然语言处理相关技术,从社交文本中挖掘发帖人的潜在人格特质,其中最为流行的方法是借助外部领域词典提取特征关键词,并借助下游机器学习方法进行人格分类。鉴于在线社交文本的飞速增长,且基于特征的方法需要大量的人工标注、可迁移性较差。所以,基于深度学习的自动人格检测方法具有更广泛的应用前景。然而,现有的基于深度学习的人格检测模型依旧存在两个局限性。首先,它们只提取了潜在人格对应的关键词,而缺乏对发帖人情绪信息和心理学特质的分析。其次,由于在线社交文本的数量较多,导致文本序列较长,因此一些方法无法建模超长上下文,导致发帖中许多关键语义信息被忽略。为了解决上述问题,本文提出了一种新的结合情感和语义特征的多标签人格检测模型。本文主要进行了以下研究工作:1、我们提出了一个结合情感分类与人格检测的多任务框架,通过外部情感分析模型自动对文档进行情感标注,利用情感与人格之间的关联性提升人格检测的效果。该框架基于Longformer预训练语言模型,借助self-attention机制充分捕捉超长文本数据的上下文语言特征。2、在此基础上,我们利用自动情绪标注的结果对文档数据进行增强。通过将不同发帖的情感程度进行排序,使得Longformer更好地捕捉发帖之间的情感关联,进一步提升了多任务检测的效果。本文模型可以自动对社交媒体文本进行人格检测,帮助各种社交软件进行用户信息挖掘。本文在两个公开的MBTI和Big Five数据集上进行训练,使用F1作为评价指标,实验结果表明该模型在人格检测方面优于最先进的技术。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.006809
{DOI}: 10.27162/d.cnki.gjlin.2022.006809
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于循环神经网络的智能医学问答系统的研究与实现
{Author}: 侯雪淞
{Tertiary Author}: 冯勇
{Publisher}: 辽宁大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智能医学问答;循环神经网络;BERT;文本分类;图数据库;命名体识别
{Abstract}: 随着人类社会进入互联网时代,人们生活的方方面面都与网络密切相关。截止至2021年6月,我国网民人数已达到10.11亿。在如今数据量庞大的信息时代,人们对查找信息的速度、效率有了更高的要求。为提高信息检索效率,智能问答系统应运而生。现有的医学问答系统大多采用医生在线问诊,存在患者需要等待一定的时间、与医生沟通不及时、问诊价格昂贵、医生资源有限等问题。当前面向医学领域的智能问答系统在提取医学实体时存在提取缺失、系统后端缺少医学实体审核的过程,导致数据库中医学数据与非医学数据相互混杂,问答效率大大降低,在智能医学问答领域未取得较好效果。线下就诊存在知名医院的专家号一号难求、排队时间占据就诊时间的75%以上、患者对应挂科室模糊不清等问题。2020年初,由于新型冠状病毒肺炎疫情的爆发,医院对患者的就医做出了更为严格的规定,这就导致了患者就医更加困难。在这种情况下,人们更加希望通过专业高效智能的医学问答平台查询自己的病症,寻求治疗方法。因此,构建一个面向医学领域的智能问答系统刻不容缓。随着深度学习技术的发展,将深度学习方法与医学问答系统相结合,利用深度学习方法对医学数据进行快速准确地提取与分类,形成面向医学领域的纯净数据库,以此提高问答效率,解决人工问诊造成的问答效率较低、问诊等待时间长等问题。为了缓解就医压力,满足用户对线上就医的需求,本文开发了一个基于循环神经网络的智能医学问答系统。针对现有医学问答系统解析自然语言能力较差,以及系统后端缺少对医学实体审核的问题。本文在问答系统后端数据处理部分使用基于BERT-Bi LSTM-CRF的医学实体识别模型对非结构化医学数据进行医学实体识别。本文在系统后端增加医学文本分类模块用于对医学实体审核,在该模块中使用本文提出的基于BERT-RNN的医学文本分类模型将医学文本数据与非医学文本数据进行分类。为了提高模型分类的准确率与速度,使用本文提出的mean＿relu激活函数取代RNN原有的激活函数,并对RNN网络结构进行调整,以此实现对医学数据的高效分类。由于医学词语存在特殊性,同一个词语在句中不同的位置可能代表不同的疾病名称。因此,上述两种模型的词向量转化部分均使用BERT实现,通过BERT词向量转化方法融合句子中字向量、文本向量和位置向量信息,使得词向量不仅学得了该词本身所具有的所有语义信息,还可以学得句子中其他词与该词的关系。这样便使医学问答系统从根源上获得更加准确的医学数据表达,有利于系统功能的实现。最后,通过将本文提出的BERT-RNN医学文本分类模型与现有的BERT-LSTM文本分类模型在相同数据集、相同迭代次数下进行分类准确率与分类速度的对比,可以得到本文提出的BERT-RNN医学文本分类模型在分类准确率上可达到91.2%,相较于B ERT-LSTM文本分类模型在分类准确率上提升了5.9%。分类速度上,在同样迭代10000次的情况下,本文提出的BERT-RNN医学文本分类模型分类速度为30m46s,相较于BERT-LSTM文本分类模型,分类速度提升了1m45s。本文首先对面向医学领域的智能问答系统进行需求分析,根据系统需求分析确定了本文所设计的系统采取B/S体系架构。在此基础上对系统的总体框架、总体功能结构、系统所涉及的数据库进行了设计。最后对系统开发框架、运行系统所需的软硬件环境进行相应的配置。搭建好系统所需环境后,实现系统所具备的功能。通过测试验证了系统的功能和性能达到了预期效果,系统能够实现设计中的各项功能,各个模块均达到理想状态。基于循环神经网络开发的智能医学问答系统可以实时回答用户提出的问题、提高医学资源的利用率以及问答的准确率、满足用户对医学问答系统的需求。故此,本文开发的基于循环神经网络的智能医学问答系统具有良好的应用前景。
{URL}: https://link.cnki.net/doi/10.27209/d.cnki.glniu.2022.001563
{DOI}: 10.27209/d.cnki.glniu.2022.001563
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于助老服务机器人的目标检测与动作识别研究
{Author}: 赖嘉骏
{Tertiary Author}: 张学习
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;服务机器人;目标检测;人体姿态估计;动作识别
{Abstract}: 应《国家中长期科学和技术发展规划纲要(2006-2020年)》,服务机器人目前正处于快速上升阶段,而机器人的感知赋能因此逐渐成为一个研究热点。当前的服务机器人若要完成最基本的功能,主要的感知需求在于视觉算法的应用。针对家庭场景下的服务机器人,本论文基于深度学习网络设计了一个包含多个视觉任务,可应用在服务机器人上的视觉系统,并且以中国机器人大赛-助老服务机器人赛项作为落地场景,进行相应的介绍以及功能测试。本文主要进行了以下工作:1)以助老服务机器人比赛的规则为基础,针对该场景,设计并建立了一个可扩展的助老服务机器人基本架构及其子功能模块接入的模式。2)针对部署在服务机器人端的情况,对比目前流行的基于深度学习的特征提取模型以及目标检测模型,从而确定所采用的人体检测的基础模型。为加强家庭场景下的实际应用效果,对实际应用场景的图像数据进行标注,生成本任务所用模型训练数据,加强人体检测的效果。针对该场景下的误检情况,提出一个快速的解决方案。3)针对基于单帧图像的模型(目标检测模型)无法充分利用视频的时序的问题,本文基于人体检测的结果进行人体姿态估计的任务推理,并且根据人体姿态估计任务所得人体关键点热图进行堆叠,引入多帧图像之间的联系,输入至动作识别模型中,通过推理最终得出人体动作的分类。4)从边缘端深度学习网络部署的角度出发,设计了一个整合上述任务的软件系统,完成从摄像头信息输入到最终结果,包括:人体检测、人体姿态估计、动作识别、行动轨迹跟踪,输出的整个流程,并且根据硬件特性进行相应的系统设计。本文针对助老服务机器人及其应用场景,进行了相应的视觉模块研究,包括目标检测、人体姿态估计及动作识别,并根据这些视觉模块,在一个适用于边缘AI计算的终端设备上进行相应系统的研发及部署。最终结果显示,该系统取得了良好的视觉识别效果,在助老服务机器人比赛上,取得了优异的成绩。此外,该系统具有很好的实用性,对于相似的场景能够做到快速的应用部署。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001080
{DOI}: 10.27029/d.cnki.ggdgu.2022.001080
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Unity3D的应急桌面演练系统研究
{Author}: 李星宇
{Tertiary Author}: 刘志勤;孟思齐
{Publisher}: 西南科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 应急演练;自然语言处理;文本相似度;游戏引擎
{Abstract}: 我国是世界上突发事件灾害最为严重的国家之一,灾害种类多、分布地域广、发生频率高,容易造成严重的经济损失和人员伤亡。近年来,自然灾害、事故灾难等突发事件频发,对各级政府、企事业单位应急处置能力提出严峻考验。应急演练是应急工作的重要手段,能有效提升应急处置能力,检验应急预案的合理性和可行性。根据组织形式的不同,可分为桌面演练、实战演练。现代场景下,由于实战演练存在设置困难、领域有限、耗费资源、难以重复等局限,桌面演练凭借其组织简单、可重复开展等优点脱颖而出,外加虚拟仿真技术的快速发展,能不受空间、时间限制再现事故场景,推动桌面演练应用范围更加广泛。桌面演练的特点是“纸上谈兵”,通过演练“沙盘”考查参演人员对应急预案掌握情况和应急处置能力。目前,应急桌面演练系统已经有很多设计方案,但充分使用自然语言处理工具,验证参演人员决策正确性及效率结果的系统较少;演练评估更多依靠专家组人工评估,存在较强的主观性;演练流程多趋于线性发展,没有将参演人员表现情况同演练过程变化相结合,难以实现科学的态势推演。针对应急桌面演练系统设计存在的局限,本课题从演练目的、人员组成、实际案例等方面分析了系统的功能需求,按照“信息收集、方案设计、人员演练、过程评估”的演练工作流程,将桌面演练系统的结构分为信息处理、方案设计、管理调度、演练评估等4个部分,提出了桌面演练系统的整体设计方案。其次,提出了应急案例的结构化处理方法和演练方案的图状结构设计。通过收集应急案例文本,分析应急案例的信息属性组成,将事件流程细化为“1个主题事件+N个过程事件+1个结束事件”的过程链,得到突发事件之间的关联性和风险熵。在此基础上,设计图状结构的应急演练方案,实现演练流程的可变性。随后,针对传统演练评估存在的局限,提出基于文本相似度的演练评估方法。以关键词、关键句匹配为核心,评估参演人员针对突发事件情景提出的处置措施和标准措施之间的文本相似度,文本相似度越高代表演练情况越好,并作为评估结果决定演练流程走向,为分支推理提供客观支撑依据。最后,使用Unity3D游戏引擎,以大面积停电事件为主题,设计了场景、事件、人物等虚拟模型,构建了人机交互、协同交互、网络交互等交互内容,并分析了系统设计存在的不足,对后续工作提出了一些建议。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2022.000953
{DOI}: 10.27415/d.cnki.gxngc.2022.000953
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练模型的医疗命名实体识别方法研究
{Author}: 李明璇
{Tertiary Author}: 管仁初
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 命名实体识别;BERT;词汇增强;多任务学习
{Abstract}: 我国作为人口大国,医疗资源是关系民生的关键所在。随着互联网技术的发展,越来越多的学者将计算机技术应用于医疗领域的研究中。利用命名实体识别技术提取医疗文本实体,构建医疗相关知识图谱,能有效提升医疗水平与效率。本文对命名实体识别方法展开研究,提出了两种基于预训练模型的命名实体识别模型,并将它们应用于医疗领域实体识别中,旨在提升医疗领域实体识别的准确率。本文首先基于BERT-BiLSTM-CRF模型展开研究,这是一种以BERT预训练模型作为编码器得到文本的字级向量表示,之后通过双向LSTM模型学习句子双向的时序信息,最后结合基于统计概率的条件随机场获取数据间更深层次的关系,从而得到更为准确的预测模型。虽然BERT在文本表示上效果优异,但在中文命名实体识别中,其输入仍是字级向量表示,而中文文本中,词汇才是表达含义的最小单元,输入字级向量虽然可以避免输入词级向量时由分词标准不同而产生的噪声,但却浪费了拥有更多信息的中文词汇。综上,本文首先提出了一种基于Tag Embedding和Simple Lexicon词汇增强与字词信息融合的预训练模型,该模型于不同的网络层级引入了两种信息增强的方式,以对中文中词汇信息加以利用。其中,基于Tag Embedding和Simple Lexicon的词汇增强方法作用于词嵌入层中,该方法将句子按不同维度进行划分,能够获取更为丰富的文本表示。基于字词信息融合的词汇增强方法作用于BERT编码输出层,将文本的词界信息融入到经编码后表达更为丰富的文本表示中,增加其所包含信息量。该模型在中药说明书数据集上取得了较为理想的效果。随后,本文对该模型展开分析与讨论,找出了其中不足:虽然引入分词向量增加了字级向量的信息丰富度,但遇到了与直接对模型输入词级向量所带来的类似问题,即受到不同的分词标准与参差不齐的分词质量的影响,直接引入词级向量会为模型带来噪声。基于此问题,我们提出了基于对抗学习与网络共享的多任务预训练模型,该模型引入多任务联合学习,将命名实体识别作为主任务,中文分词任务作为副任务进行训练。通过共享编码层以及门控神经网络来为命名实体识别任务进行信息增强,同时引入对抗学习模块,去除共享信息中由于中文分词任务的特异性所带来的噪声,提升模型鲁棒性。对比基线模型RoBERTa-wwm-ext-base,该模型在CMe EE数据集上的F1分值有所提升。同时对比基于Tag Embedding和Simple Lexicon词汇增强与字词信息融合的预训练模型,该模型效果更优。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.006334
{DOI}: 10.27162/d.cnki.gjlin.2022.006334
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Rasa的领域对话系统的实现与优化
{Author}: 刘宇杰
{Tertiary Author}: 宋晖;龚飞华
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 任务型对话系统;Rasa框架;对话管理;自然语言理解
{Abstract}: 对话系统指通过自然语言与用户进行对话的系统。对话系统通常嵌入在应用系统中,提供对话式的客服、内容搜索等服务,为用户带来更加智能的体验。企业服务管理云平台是为政府管理机构汇集企业信息,以便更好地为企业提供服务的平台。为了便捷地了解辖区内企业信息,需要为平台提供一个智能检索工具。为此本文基于Rasa多轮对话框架,针对企业信息设计实现了智能检索助手,实现了基于语音问答的企业信息查询统计功能。同时对Rasa框架的功能组件进行算法优化和功能改进,提高了对话服务质量。本文的主要工作如下:面向企业信息的智能检索助手由查询APP、多轮对话服务和数据查询接口三部分组成。本文基于企业服务领域常用对话数据集,使用Rasa框架,通过数据构建、数据增强、动作定义和组件配置等步骤搭建多轮对话服务,实现了意图分类、实体识别、多轮对话管理和动作反馈等功能;数据查询接口完成多轮对话服务与企业信息数据库之间的交互;查询APP为用户提供对话交互应用。智能检索助手已上线部署,能稳定提供服务。针对Rasa框架中功能组件存在的对话质量不高的问题,本文分析了原因,提出了相应的算法优化和功能改进方法。针对自然语言理解模块实体识别正确率较低的问题,本文使用BERT+CRF模型取代原有的CRF模型提高实体识别准确率;针对指代词识别问题,使用了基于规则模板的方法改进了指代词的识别;针对实体识别后的公司名称匹配问题,使用基于最短编辑距离的拼音相似度和余弦相似度联合计算候选词和匹配词相似度的方法,提高公司名称的识别准确率;针对对话管理模块动作预测准确率较低的问题,本文进行了LSTM、GRU、GRU+Attention以及MLP模型的对比实验,选择效果最好的MLP模型替换了原有的LSTM模型,提高了动作预测准确率。本文为企业服务管理云平台设计实现了智能对话系统,为平台管理者提供更为便捷的企业信息查询服务。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.001769
{DOI}: 10.27012/d.cnki.gdhuu.2022.001769
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于医生合作关系的医疗大数据挖掘和分析
{Author}: 杜鹏林
{Tertiary Author}: 杨晓君
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 关系网图;社区发现;知识图谱;问答系统
{Abstract}: 由于互联网、大数据分析、人工智能等技术高速发展,各行各业的数据信息量呈现出直线增长态势,而医学资源作为海量互联网信息中的关键一员也出现“爆炸式”的增长速度,使得用户和使用者难以在海量的医疗信息中快速地找到自己所需要的指导和引导信息,这也是“信息爆炸”和“信息过载”的网络医学中所显示出的最大劣势。基于上述所发现的问题,本研究以大夫、药物、患者为重点研究对象,以大数据分析-信息咨询-知识管理为主线,从医生建议、医疗辅助、患者问答等一系列问题出发,综合使用了大数据挖掘、机器学习和人工智能等理论,构建了医生合作关系网络图,并提出了基于聚类的医生合作关系社区发现算法,建立了基于疾病信息的知识图谱,设计了基于医学知识图谱的智能问答,通过发掘医生合作内部的关联关系,从而更好地服务和引导医师内部的医生协作,辅助医师更高效精确地处理病人的医疗上的问题,运用知识图谱技术高效整理海量的医疗信息,建立交互式智能医学问答系统用于辅助用户完成初步自诊,目标是为了提高医疗保健服务质量,合理配置和利用医学网络资源,在一定程度上缓减医务人员的治疗压力,进一步提高医疗服务与品质。因此本文的研究重点是利用大数据挖掘和机器学习等算法深度发掘有关病情、用药、病人以及专家等医疗信息,以医生为研究对象,首先建立医生合作关系网,通过聚类的社区发现算法对形成的医生合作关系的复杂网络进行社区划分,然后对处于同一集合中的医生构建医疗小组,并根据其所划分的社区进行医生专家推荐。其次是通过疾病数据来构建知识图谱,最后建立交互式智能医疗问答系统用于辅助患者进行初步的自诊。本文首先通过网络爬虫技术从多源的医疗信息平台中获取医疗信息,并将不同医疗平台中获取的医疗信息内容进行校验、融合和整理,然后利用并查集算法整合数据,建立了基于原始的医生合作关系网络。提出了并行化的Louvain算法,接下来是从并行Louvain算法、Louvain算法、GN算法和谱聚类等四种聚类方法选出最适合的社区发现算法的策略,将原始网络划分成若干子社区,子社区内的医生间关联程度更高。使用Gephi可视化软件将医生合作关系网络可视化,并把子社区中度值最大的医生标记出来,作为患者所需的推荐医生。其次是对获得医疗数据进行知识抽取、知识融合以及知识存储等步骤构建医疗知识图谱。然后针对用户提出的自然语言组成的问题通过采用Aho-Corasick自动机算法来抽取用户问题中的实体,利用基于特征词的分类方法对用户问题的意图进行分类,将实体和意图解析成Cypher语句,在医疗知识图谱中进行知识寻找,并反馈答案给患者。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001499
{DOI}: 10.27029/d.cnki.ggdgu.2022.001499
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地质灾害文本实体关系抽取研究
{Author}: 周榆婷
{Tertiary Author}: 陈建平
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 地质灾害文本;实体关系抽取;命名实体识别;依存句法分析
{Abstract}: 地质灾害文本实体关系抽取任务旨在自动从大规模非结构化文本中提取知识三元组,是一项代表性的自然语言处理技术在地质领域的应用,对地质灾害应急处理方案制定具有重要的意义。为了实现地质灾害文本的结构化,机器不但要准确识别文本中的实体边界,还要结合地质领域特点准确判断实体对的关系。本文围绕地质灾害文本信息结构化进行了系统的研究,调研了国内外三元组知识抽取技术及地质大数据服务现状。目前,该任务的解决方案以流水线方法为主,将关系抽取和实体识别视作两个独立的子任务。借助中文预训练模型发展的强劲势头,实体关系抽取任务的性能大幅提高。但在地质灾害文本的应用还存在一些问题,如实体漏抽错抽、实体边界模糊、错误传播等问题。针对这些问题,在依存句法分析和深度学习的基础上,本文主要工作如下:1、针对地质灾害文本中实体边界模糊的问题,提出一种基于核心动词链的实体关系抽取方法。该方法首先使用依存句法分析技术,提取句子的核心动词,并以核心动词作为三元组的关系词,根据依存关系向前查找三元组的主实体和尾实体。并设计了缺省成分补全模块,充分利用词性和依存关系捕捉实体边界。在自建地质灾害数据集和COAE2016数据集上核心动词抽取F值平均为95.45%,三元组抽取的F值平均为82.70%。2、针对流水线方法容易导致错误传播的问题,提出一种基于多特征融合的Transformer-CRF方法用于地质灾害实体关系的联合抽取。为了充分提取语义特征,融合了句子的稀疏特征和稠密特征作为特征表示。为了提高联合抽取模型的性能,设计了实体标注方法和抽取规则,将实体的位置信息添加到标签内,提高了实体识别的准确度。设计了双层Transformer对句子进行上下文编码,充分利用语义联系。在自建地质灾害数据集上,基于多特征融合的Transformer-CRF实体关系联合抽取模型在命名实体识别的F值达到了74.68%,关系抽取的F值达到了62.31%。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001241
{DOI}: 10.27029/d.cnki.ggdgu.2022.001241
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 主观题自动评分方法的研究
{Author}: 张展鑫
{Tertiary Author}: 陈平华
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 主观题;自动评分;相似度;BERT
{Abstract}: 主观题自动评分即通过建立一个评分模型对待评的学生答案进行机器自动评分,一般可分为针对简答题等附有参考答案题型的主观题自动评分以及针对作文等无参考答案题型的主观题自动评分,本文研究的是前者。随着互联网、人工智能技术的发展,各行各业都兴起了智能化,教育行业也不例外,越来越多人开始关注智能阅卷的相关研究,主观题自动评分是智能阅卷中的一项重要环节。主观题目前都是由人工进行批改,消耗了大量的精力,并且会由于批改人的主观因素导致出现分数误差,丧失了公平性,因此对主观题自动评分方法进行研究具有重要的意义。目前,主观题自动评分方法主要有基于相似度和基于机器学习/深度学习的主观题自动评分方法,前者无需标注数据进行训练即可进行评分,实用性强;后者能理解更复杂的语义,学习到评分规则。这两类方法均有重要的研究价值,但均存在一些问题:基于相似度的主观题自动评分方法考虑特征单一、忽视待评答案与参考答案的得分点句子匹配;基于机器学习/深度学习的主观题自动评分方法没有充分考虑待评答案和参考答案的交互信息特征问题,这些问题都影响了评分准确率。针对这些问题,本文完成了如下研究工作:1、针对基于相似度的主观题自动评分方法存在相似度特征提取单一、忽视待评答案与参考答案的得分点匹配情况的问题,提出一种基于相似度融合的主观题自动评分方法,即结合关键词相似度和句子语义相似度计算出得分点匹配相似度,然后通过评分公式进行评分。首先使用Text Rank算法提取待评答案和参考答案中每个句子的关键词,并根据《同义词词林》以及相关公式计算句子之间的关键词相似度;然后将待评答案和参考答案的每个句子进行匹配,计算句子之间的语义相似度后结合关键词相似度计算得分点匹配相似度;最后根据评分公式计算分数。在相关的数据集上的实验结果证明方法的有效性。2、传统的基于机器学习/深度学习的主观题自动评分方法往往只考虑待评答案单一的文本特征,忽略了待评答案和参考答案的交互信息,为此本文提出一种基于BERT与互注意力机制的主观题自动评分方法。BERT模型采用了Transformer双向编码器,具有十分优秀的语义特征提取能力,本文使用BERT模型分别提取待评答案和参考答案的语义特征,在此基础上引入互注意力机制提取待评答案和参考答案的交互信息,最后将融入了互注意力的向量输入到预测层进行评分,并且对数据集采取了数据增强策略。在数据集上进行的实验表明该方法提高了评分的准确率,同时也验证了对数据集进行数据增强扩充后,可以有效提高评分效果。3、收集了某中学的考试数据,并整理成中文主观题自动评分数据集,用于验证本文所提方法的有效性和准确性。4、设计并实现一个中文主观题自动评分系统,系统能对上传的考生待评答案进行自动评分,证明了本文提出的方法切实可行。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001866
{DOI}: 10.27029/d.cnki.ggdgu.2022.001866
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的多标签司法文本分类算法研究
{Author}: 郭绮雯
{Tertiary Author}: 王勇
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多标签文本分类;注意力机制;深度学习;标签相关性;标签语义
{Abstract}: 互联网的蓬勃发展推动各行各业都产生翻天覆地的变化,司法领域也同样如此。司法文本数量的快速增长促使着更高效的分类技术出现,这有助于对司法资源的合理利用。一篇司法文本可以同时属于多个类别,这就涉及到了多标签分类问题。传统的方法往往着重关注待分类的文档,导致标签语义信息利用不足、标签关联性挖掘不充分,同时,没有考虑到不同标签侧重关注的文本内容不同。针对上述的问题,本文提出了一种基于注意力机制的多标签文本分类算法模型,通过引入标签的语义信息、捕获标签之间的高阶相关性,并结合注意力机制,为每个标签学习蕴含语义信息、关联性信息的特定文档表示,实现了标签信息与文档信息之间的交互,从而获取更丰富、更全面的文本特征并用于最终的分类。首先,对于司法文本以及标签语义信息,本文均采用先进的BERT预训练语言模型获取各自的词嵌入表示,通过将它们表示在同一个向量空间中,从而建立了司法文本以及标签语义信息之间潜在的语义关联。相比静态文本表征方法,BERT模型可以通过双向Transformer编码器获取具备上下文信息的动态文本表征,因此能有效解决一词多义的问题。接着,在标签关联性提取模块中构建标签共存图,使用结构深度网络嵌入方法对标签共存图的全局结构以及局部结构进行建模,从而挖掘了标签之间高阶相关性。随后,在全局上下文特征提取层中,通过Bi GRU对司法文本向量进行特征提取,并将提取到的文本特征输入到标签语义信息注意力(Label Semantic Information Attention,LSIA)模块以及标签关联性注意力(Label Correlation Attention,LCA)模块中。LSIA和LCA均采用了注意力机制,聚焦特征中的关键信息,分别捕获到标签语义信息感知的文本特征以及标签关联性感知的文本特征。并在双重注意力特征融合层对LSIA模块和LCA模块得到的特征采用向量拼接的方式进行融合,为每个标签学习到蕴含了语义信息以及关联性信息的特定文本表征,最大程度地保留了标签携带的先验知识,并建立了标签与文档之间的交互。最后,将融合后的特征输入到标签输出模块中,通过全连接层以及Sigmoid激活函数,完成最终的多标签分类。本文在Multi-CAIL2018数据集上开展了实验,包括:消融实验、特征融合方式实验以及对比实验,从而对本文提出的模型的总体性能以及LSIA模块、LCA模块、特征融合方式的有效性进行验证。实验结果表明,本文提出的模型在微平均F1值、宏平均F1值以及综合F1值上分别达到了94.32%、31.13%以及62.73%,均优于基准模型,由此证明了本文提出模型的有效性。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.001491
{DOI}: 10.27029/d.cnki.ggdgu.2022.001491
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱增强BERT模型的方法研究
{Author}: 卢嘉荣
{Tertiary Author}: 肖红
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;知识图谱;知识增强;增量学习;梯度优化
{Abstract}: 近年间得益于强大的硬件计算性能和深度学习的蓬勃发展,以BERT为代表的自然语言模型陆续登上舞台,其在GLUE、SQu AD和RACE等自然语言处理测试任务集上取得了SOTA的优异成绩。与此同时,在通用领域上取得优异成绩的BERT模型却因受限于预训练过程中的语料规模,训练过程中缺少专业领域的事实知识,导致其准确度性能在专业领域中受到限制。目前已有学者提出知识增强型BERT模型,通过引入外部专业知识改善模型在不同领域下游任务中的知识缺失问题,取得比原始BERT模型更高的准确率。但由于知识增强型BERT通过引入大规模外部知识对模型进行增强,导致模型对计算资源需求和训练时间急剧攀升。并且通过向BERT模型引入外源知识的提升其知识认知水平的同时,也存在对引入外源知识学习不充分的问题,在此过程中信息噪音也会影响模型的稳定性与泛化能力。针对上述提出的问题,本文主要研究的是快速引入外源知识的知识增强方法和增强模型事实知识认知和泛化能力的知识增强方法。首先,本文研究了学术界中利用知识图谱对BERT模型进行知识增强的技术实现,并提出基于文本关联语料生成的知识增强方法。文中通过公式对文本关联语料生成方法进行描述,并在时间复杂度上推理证明其对比传统方法具有明显速度优势。然后设置实验对基于文本关联语料生成方法的BERT模型进行准确率性能测试,并与其他相关模型方法进行比较。实验结果表明该方法能在引入外源知识的同时,充分降低为BERT模型引入外源知识的计算资源代价,分别在知识引入与训练阶段平均减少了53.5%与37.4%的计算耗时。其次,为进一步提升BERT模型利用外源知识的能力及减少其训练过程中的过拟合现象,本文提出使用增量学习任务d EA及梯度优化算法Child Tuning F对模型进行调整。d EA任务通过利用原有的BERT模型任务及结构,联合外源知识库提供的知识实体对模型进行增量学习训练。同时,通过修改优化器对模型训练过程实现梯度计算的优化操作,该优化算法在理论推算上证明了其可有效的提升模型的泛化能力。最后在实验中验证了联合增量学习与梯度优化的知识增强方法能有效的进一步提升模型的精度性能,在实验中准确率对比BERT平均提高1.87%,同时减缓了模型在下游任务的小规模数据中过拟合现象。最后,在项目实例中应用BERT模型构建了智能问答系统的核心模块,通过知识图谱提供的外源知识和前述的两种知识增强方法对BERT模型进行知识增强,强化其在专业领域的知识认知能力,提升了其在专业领域任务上的准确率性能。随后在专业领域数据集中进行实验验证,经实验证明两种方法知识增强后的BERT模型较原始版本提升10.07%的准确率性能,最后在真实场景中验证智能问答系统的有效性。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.002364
{DOI}: 10.27029/d.cnki.ggdgu.2022.002364
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 优良食味水稻品种籽粒蛋白质合成与累积特征及其对氮素和光照条件的响应
{Author}: 陆丹丹
{Tertiary Author}: 张祖建
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 水稻;蛋白质;氨基酸;食味品质;氮素;弱光
{Abstract}: 食味品质是稻米重要的品质性状,直接影响稻米的消费市场。较多研究表明稻米食味品质与籽粒蛋白质含量、植株氮素代谢密切相关,但相关机制研究并不深入。蛋白质是水稻籽粒的第二大组成部分,其合成与积累受众多基因调控,容易受外界环境影响,而且蛋白质合成与积累机制及其与稻米食味品质的关系相对复杂。为了解水稻籽粒蛋白质合成与积累特征,分析其籽粒蛋白质积累对稻米食味品质的影响机制,本研究选取了食味差异明显的常规粳稻和杂交稻品种,分析其蒸煮食味品质、蛋白质及其组分特征和植株氮代谢在不同类型水稻品种之间的差异,解析优良食味水稻品种蛋白质合成与积累的特征。此外,设置结实期氮素水平和弱光处理,观察不同食味水稻品种籽粒蛋白质合成与积累对关键环境条件的响应差异,进一步探讨优良食味水稻品种蛋白质合成与积累对蒸煮食味品质的影响。主要研究结果如下:1.稻米的食味值在不同类型水稻品种间有较大差异,与食味值较低的品种相比,食味值较高的品种籽粒蛋白质含量低、直链淀粉含量适中、崩解值较高、消减值较小(多为负值)。再结合实际消费中的品质表现,在本试验中,初步认定常规粳稻武育粳3号、农垦57为优良食味水稻品种,淮稻5号和武运粳24号为食味较差水稻品种;认定杂交稻丰优香占为优良食味水稻品种,甬优2640为一般品种,扬两优6号和汕优63为食味较差水稻品种。2.稻米蛋白组分在供试品种间存在差异,常规粳稻中优良食味水稻品种的清蛋白、球蛋白、醇溶蛋白含量较低,杂交稻中优良食味水稻品种的醇溶蛋白、谷蛋白含量较低。抽穗后10天至40天优良食味水稻品种籽粒蛋白质积累水平均低于食味较差水稻品种,最终精米蛋白质含量相对较低。灌浆结实期优良食味水稻品种游离氨基酸含量较低,且精米中游离氨基酸含量显著低于食味较差水稻品种;优良食味水稻品种上、下部籽粒游离氨基酸含量差异较小,而食味较差水稻品种上、下部籽粒氨基酸含量差异较大。优良食味水稻品种籽粒氮代谢酶活性较低,茎鞘转运的氮素相对较少,籽粒对氮素吸收利用较少。3.随着氮素供应量增加,供试水稻品种蒸煮食味品质均变差,籽粒蛋白质及各组分含量明显上升,谷氨酰胺合成酶(GS)、谷草转氨酶(GOT)、谷丙转氨酶(GPT)活性增强,茎鞘转运氮素增多。在常规粳稻品种中,醇溶蛋白与食味值呈显著负相关;在杂交稻品种中,醇溶蛋白、谷蛋白与食味值呈极显著负相关。优良食味水稻品种表现出较好的耐肥性,高氮条件下其蒸煮食味品质相对较好,蛋白组分增幅均相对较小,籽粒仍表现较低水平的蛋白质积累,籽粒游离氨基酸含量、氮代谢酶活性较低,茎鞘转运氮素相对较少。4.弱光胁迫下,供试水稻品种蒸煮食味品质变差,籽粒蛋白质及其组分含量显著上升,籽粒游离氨基酸含量降低,谷氨酰胺合成酶(GS)活性下降,谷草转氨酶(GOT)、谷丙转氨酶(GPT)活性上升,茎鞘氮素转运量、转运率上升,穗部氮素输入绝对量降低。优良食味水稻品种相较于食味较差水稻品种表现出更好的耐弱光胁迫特性,具体表现为蒸煮食味品质受弱光影响较小,蛋白组分增幅相对较小,籽粒游离氨基酸含量、蛋白质积累水平、氮代谢酶活性较低。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2022.000286
{DOI}: 10.27441/d.cnki.gyzdu.2022.000286
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于空间关系挖掘的遥感影像场景语义理解
{Author}: 陈瑞贤
{Tertiary Author}: 李彦胜
{Publisher}: 武汉大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 遥感影像场景语义理解;空间关系挖掘;多标签分类;图像自然语言描述;场景图生成
{Abstract}: 在高分辨率遥感影像时代,发展精准化和智能化的遥感影像场景语义理解技术有利于高效提取和挖掘遥感影像信息,为各个应用领域提供高质量知识服务。近年来,在深度学习技术的支撑下,许多遥感影像场景语义理解任务都得到一定发展,比如基础的遥感影像场景分类任务和语义程度更高的遥感影像场景自然语言描述任务。遥感影像场景语义理解需要结合影像内要素的视觉和空间关系信息进行综合分析,而目前基于深度学习的方法往往只是在像素的层面上融合空间上下文信息而忽视对影像目标要素空间关系信息的建模和挖掘。在计算机视觉领域已有用图结构数据表示图像内容以挖掘图像内要素空间关系信息的研究基础。场景图是这类研究的重要成果,旨在通过图的节点和边表示图像的目标和关系,是更具语义性和表达能力的结构化图像表示形式。随着人们对遥感影像场景语义理解需求的不断增大,遥感影像场景图生成作为一种前沿的遥感影像场景语义理解任务逐渐引起学者们关注。但由于在遥感领域的相关数据集稀缺以及方法不成熟等问题,遥感影像场景图生成任务还处于起步阶段。为了全面研究遥感影像场景语义理解,本文具体对遥感影像场景多标签分类、遥感影像场景自然语言描述和遥感影像场景图生成三个层次的任务开展研究。考虑到现有技术在对遥感影像场景内目标要素空间关系的建模和表达上存在不足,本文结合前沿的深度学习技术,尤其基于图的空间关系挖掘技术,提出对各层次遥感影像场景语义理解任务的解决方法。本文的主要研究内容和贡献总结如下:(1)对于遥感影像场景多标签分类任务,提出了联合卷积神经网络和图神经网络的遥感影像场景多标签分类方法。该方法利用了图结构数据对影像场景的视觉要素和关系进行建模,结合卷积神经网络对影像视觉要素的感知能力以及图神经网络对要素空间关系的挖掘能力综合完成遥感影像场景多标签分类。在公开数据集上的实验结果表明该方法具有更高的精度,相比于AL-RN-CNN方法,F1分数和F2分数在UCM multi-label数据集上的分别提升了0.7%和1.5%,在AID multi-label数据集上分别提升了0.5%和0.9%。(2)对于遥感影像场景自然语言描述任务,提出了联合图神经网络和长短期记忆网络的遥感影像场景自然语言描述方法。该方法在编码器-解码器结构下基于影像的图结构表示和图神经网络空间关系学习形成细粒度编码特征,结合长短期记忆网络对特征序列进行解码完成遥感影像场景自然语言描述。在公开数据集上的实验结果表明该结合空间关系信息挖掘的编码器设计具有有效性,相比于Attention方法,平均指标在UCM-captions数据集上提升了0.015,在Sydneycaptions数据集上提升了0.013,在RSICD数据集上提升了0.092。(3)对于遥感影像场景图生成任务,提出知识图谱引导的大幅面遥感影像场景图生成方法。在目标检测和关系预测框架下,通过知识图谱先验知识的指导和多类型特征融合学习实现大幅面遥感影像场景图生成。另外,鉴于目前遥感领域缺乏相关数据集,构建了一个大幅面遥感影像场景图数据集,为该研究提供数据支撑。在新构建数据集上的实验结果表明该方法能提升大幅面遥感影像场景图生成的效果,相比于FREQ方法,在关系分类、场景图分类和场景图生成任务上的前1500三元组召回率分别提升了5.2%、6.1%和2.9%,前1500三元组平均召回率分别提升了12%、11.1%和4.4%。本文基于空间关系挖掘对遥感影像场景语义理解进行了系统的研究以提升对遥感影像场景语义层面的理解水平。对于遥感影像场景多标签分类以及遥感影像场景自然语言描述这类已有一定研究基础的任务提出了创新性的解决思路和方法以进一步提升性能。对于遥感影像场景图生成这一前沿任务进行了探索性工作并提出了面向大幅面遥感影像场景图生成的解决办法。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2022.000264
{DOI}: 10.27379/d.cnki.gwhdu.2022.000264
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文本挖掘的投资者情绪指标在量化择时策略中的应用
{Author}: 黄雅诗
{Tertiary Author}: 赵学礼
{Publisher}: 河北工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 投资者情绪;量化择时;机器学习;文本挖掘
{Abstract}: 以大数据、人工智能为代表的信息通信技术革新促使经济社会发生深刻变化,催生了以新兴技术为依托的金融新业态。量化投资作为金融业态数字化发展的明珠,凭借技术进步和策略革新的双重驱动,规模迅速扩张,收益来源也日渐丰富。兼具实时性与多元性的另类数据正在成为越来越多投资者制定投资策略中的重要部分。本文采集东方财富上证指数股吧604.23万条文本数据,借助机器学习技术挖掘网络文本中蕴含的投资者情绪信息,构造日频投资者情绪指标。相较于传统量价财务指标构建的投资者情绪变量,本文构建的文本投资者情绪指标具备连续性好、更新频率高、信息充分等特点,经过了择时有效性的检验。在传统基本面指标和技术面指标基础上,引入本文构造的基于网络文本的投资者情绪变量,构建含三大维度日频择时指标体系。通过基于随机森林量化择时模型对市场价格进行拓展窗口的滚动预测,以上证指数作为资产标的构建多空资产组合,实证检验了我国网络文本中蕴含的投资者情绪信息在量化择时策略中的有效性。研究结果表明,纳入文本情感变量的量化择时组合,获取超过业绩基准的超额收益,显著降低组合回撤,样本外预测准确率达78.52%。此外,实证结果显示了网络文本情绪指标在量化择时能力上的稳定性,回测周期内,我国市场经历牛熊转换完整的经济周期,投资者情绪历年重要性程度均值为4.19%,投资者情绪择时指标的重要性程度在4.05%至4.27%范围内小幅波动,体现出跨越经济周期的平稳性,同时从量化择时模型的核心参数和交易成本出发,进一步验证了基于网络文本的投资者情绪因子的择时稳健性。理论层面,本文构造了基于文本的高频投资者情绪指标,克服了主流投资者情绪指标存在的更新频率低、时滞性等问题,捕捉投资者情绪变化更具敏感性和实效性,有助于推动投资者情绪理论研究纵深发展。实践层面,通过提取行之有效的情绪投资因子,并将其纳入择时指标体系,借助量化交易手段获得超额收益,为投资者提供新的投资思路。在原有的基本面和技术面分析的投资模型基础上,增加网络文本情感分析的维度,拓宽了金融领域的信息来源和投资收益来源,同时为机器学习和人工智能等新兴技术提供了金融应用的场景。
{URL}: https://link.cnki.net/doi/10.27105/d.cnki.ghbgu.2022.000252
{DOI}: 10.27105/d.cnki.ghbgu.2022.000252
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 专利知识智能提取与融合创新过程模型研究
{Author}: 王洪祥
{Tertiary Author}: 张鹏
{Publisher}: 河北工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 专利知识;功能模型;功能结构;智能提取;功能相似度算法;水面垃圾清洁系统
{Abstract}: 专利中蕴含大量技术创新知识,在产品创新过程中发挥着重要作用。然而大量专利知识繁杂且无序造成了其提取及应用困难,严重影响企业创新设计效率。针对这一问题,论文首先综合功能模型和功能结构两者优势,将繁杂无序的专利知识采用基于Python的自然语言处理技术(Natural Language Processing,NLP)进行智能提取,并应用功能模型和功能结构进行规范化表达。其次采用基于语义相似的功能相似度计算方法将专利知识规范化表达结果进行排序,获取与待设计产品功能相似度较高的专利,之后利用设计过程复杂性理论(Design-Centric Complexity,DCC)和TRIZ工具对其进行问题分析及解决。再次将功能相似度较高的专利进行融合,得到新产品的设计方案,并使用层次分析法评价设计方案。最终建立专利知识智能提取与融合创新过程模型。论文的主要研究工作包括以下内容:1.专利知识智能提取过程。首先根据功能模型和功能结构的构建过程,分析出两者之间的区别与联系;其次根据用户需求和新产品功能分析过程,检索相关专利作为智能提取的知识源;最后结合功能模型和功能结构,提出了一种基于Python的自然语言处理技术智能提取专利知识的方法。2.专利知识功能相似度排序与融合创新过程。首先利用语义相似的方法计算新产品功能和专利中功能的相似度大小,之后根据功能相似度大小进行排序,获取与待设计产品功能相似度较高的专利;其次对获取的专利进行问题分析及解决,然后将问题解决后的专利进行融合,进而得到产品创新设计方案;最后利用层次分析法对设计方案进行评价,实现专利知识功能相似度排序与融合创新设计。3.水面垃圾清洁系统的创新设计。应用上述研究成果对水面垃圾清洁系统进行创新设计。首先根据用户需求进行功能分解,建立出其功能结构;其次根据功能需求获取待提取的专利集,将专利知识智能提取,并以功能模型和功能结构的形式进行规范化表达,之后利用基于语义相似的功能相似度算法对提取出的专利进行排序;接下来利用DCC理论对系统进行复杂性分析并采用TRIZ工具降低系统中存在的复杂性,随后将问题解决之后的相似专利进行融合及评价,得到水面垃圾清洁系统的创新设计方案;最后根据设计方案完成了水面垃圾清洁系统的机械结构和软硬件的详细设计,从而验证了论文研究方法的有效性和可行性。
{URL}: https://link.cnki.net/doi/10.27105/d.cnki.ghbgu.2022.000121
{DOI}: 10.27105/d.cnki.ghbgu.2022.000121
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于迁移学习和集成学习的医疗文本分类方法研究
{Author}: 郑承宇
{Tertiary Author}: 王新
{Publisher}: 云南民族大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: ALBERT模型;迁移学习;集成学习;文本分类;中文健康问句
{Abstract}: 中文健康问句作为一种特定形式的医疗文本,具有复杂的医学专业术语和大量的缩略词语等特点,以及自然语言普遍存在的同义词、反义词和一词多义等现象,在文本处理过程中,面临类别标签和层级关系复杂、有效标注数据样本较少、不同问句文本之间语义相似度高等问题,这使得针对该特定医学领域的文本分类任务更具挑战性。本文主要探索在特定目标领域中文小样本上的最佳学习模型,利用预训练语言模型通用和强大的泛化能力,基于ALBERT基准模型框架,提出了一种基于迁移学习和集成学习的医疗文本分类方法,并提供了两种变体模型:TLCM模型和TCLA模型,主要工作及创新点如下。(1)引入在通用领域表现较好的ALBERT预训练语言模型进行动态词向量表征,通过模型微调技术调整ALBERT模型的Embedding输入层结构、多层双向Transformer结构以及下游分类子任务的网络结构,其中,Embedding输入层采用迁移学习方法将健康问句描述文本以字级别进行输入进行字向量表示。(2)迁移ALBERT模型内部原始的多层双向Transformer结构,并将训练后的输出向量与CNN结构、Bi-LSTM结构以及Attention注意力机制等多个混合神经网络模块相结合进行监督式集成训练,分别提出了TLCM和TCLA模型两种框架进一步提取文本的局部信息特征和全局结构信息特征构造分类器。(3)在下游任务中,构建了一类多标签分类子任务,设计了两个具有完全连接结构的多层感知器构造文本多标签分类器,利用交叉熵机制和sigmoid激活函数对文本的上下文表示生成标签,实现中文健康问句描述文本的主题分类。实验结果表明,在中文健康问句的多标签分类任务上,本文提出的TLCM模型和TCLA模型在Precision、Recall、Micro＿F1等各项评测指标中均达到了91%左右,具有良好的性能表现,能较好地解决传统文本分类算法对医疗文本语义理解不足、类别标签单一、分类精度较低的问题。相比传统word2vec静态词向量表示,预训练语言模型的引入使得算法性能得到显著提升,在医学文本信息挖掘领域展现出了较高的发展前景。
{URL}: https://link.cnki.net/doi/10.27457/d.cnki.gymzc.2022.000042
{DOI}: 10.27457/d.cnki.gymzc.2022.000042
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度强化学习的医学报告自动生成方法研究
{Author}: 徐文婷
{Tertiary Author}: 许铮铧
{Publisher}: 河北工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 胸片;医学报告生成;强化学习;注意力机制
{Abstract}: 医学影像报告自动生成是医学影像分析中的最重要的任务之一。近年来,医学影像已成为疾病诊断中最常用的医学检查方法。放射科医生在影像检查后写出对应的段落式的描述报告。这些报告描述医学影像中相应的重要医学发现,并强调异常与病变的大小和位置。而由于患者数量众多以及经验丰富的放射科医生的短缺,放射科医生工作负荷极大。因此,能够自动生成高质量的医学影像报告极具研究意义。近年来,随着深度学习的发展,当前主流的医学报告自动生成算法主要是基于卷积神经网络-循环神经网络结构的深度学习网络。然而这些方法仍然存在以下问题:(1)使用强化学习以直接对评估指标进行优化的医学报告生成方法由于只采用一到两个评估指标作为奖励导致优化目标不全面;(2)当前使用的注意力机制大多为低阶单维的注意力机制,导致医学报告生成过程中影像相关区域与文本无法对齐;(3)影像报告的长文本特性导致在预测过程中极易产生重复词,从而影响生成报告的可读性。受这些工作启发,本文提出了一种基于深度强化学习的医学报告自动生成算法,和一种基于M-linear注意力机制与重复性惩罚机制的医学报告自动生成算法。本文的主要研究工作包括以下几个方面:(1)针对现有的基于强化学习的医学报告生成工作无法对模型进行全面的优化问题,本文提出了一种基于混合奖励的强化学习算法,通过对自然语言处理的评估指标进行组合并搜索出一个最优权重进行直接优化,以实现对模型全面的优化;(2)针对现有工作中使用的低阶单维的注意力机制医学导致报告生成过程中影像相关区域与文本无法对齐的问题,本文提出了一种多维高阶的注意力机制,以实现对输入图像中的重要相关特征以及图像与报告之间的重要关联信息的自适应捕捉;(3)针对由于医学报告的长文本而导致的生成报告时容易产生的重复词问题,本文提出了一种重复性惩罚机制,以增强生成文本的可读性。本文在IU X-Ray和MIMIC-CXR两个胸片报告数据集上进行了大量实验,实验证明:(1)所提出的混合奖励强化学习算法相较于前沿的医学报告生成模型在多个评估指标上获得了很好的表现提升;(2)所提出的注意力机制进一步提升了模型的表现;(3)所提出的重复性惩罚机制的添加获得了最高的评估分数。实验表明所提出的这几方面改进对于实现更好的医学报告生成性能都是有效且必要的。
{URL}: https://link.cnki.net/doi/10.27105/d.cnki.ghbgu.2022.000572
{DOI}: 10.27105/d.cnki.ghbgu.2022.000572
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合知识图谱和多模态的文本分类研究
{Author}: 姚克
{Tertiary Author}: 李金铭;景丽
{Publisher}: 河南财经政法大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;知识图谱;多模态;文本分类;Bert
{Abstract}: 文本分类是对数字文本信息按照一定的分类体系或标准进行自动分类标记的一种方法,常用于垃圾邮件处理、情感分析、主题分类、意图识别等自然语言处理领域。目前常用的方法是基于深度学习的文本分类方法,此类方法是基于单模态数据所驱动的统计学习方法,缺乏对数据的真实理解能力,鲁棒性较差,单模态的信息也难以有效分析互联网中越来越丰富的多模态化数据。针对此问题,本文采用两种策略来提高分类能力:(1)为文本分类模型引入多模态信息,旨在利用多模态信息之间的互补性,弥补单模态信息的局限性。(2)为文本分类模型引入知识图谱实体信息,旨在利用知识图谱的结构化知识,为模型提供额外的知识信息,让模型拥有理解与联想能力,提高模型的泛化能力。基于上述两种策略,本文构建了融合知识图谱和多模态的文本分类模型,主要的研究内容如下:(1)单模态信息的特征表示提取研究。根据不同模态的特点,分别使用不同的特征提取方法,对于文本模态使用Bert提取特征;对于图像模态使用改进的Res Net模型,获取蕴含位置信息的图像特征;对于知识图谱实体模态,通过实体链接提取文本中包含的实体,通过对比分析选用实体表示学习作为实体特征表示方法。(2)多模态信息融合的研究。通过在早期融合中引入自注意力机制,使模型能够学习不同模态对分类结果的重要程度,充分利用多模态信息之间的互补作用;通过实验与分析论证了早期融合与晚期融合的效果差异,得出了早期融合效果更好的结论。本文分别在MM-IMDB、Twitter15&17和MVSA-Multi三个数据集上进行了对比实验、消融实验以及泛化能分析实验,实验结果显示,本文的模型在分类性能上均优于其他模型,这说明引入了多模态信息和知识图谱实体信息的文本分类模型具有更好的分类性能,鲁棒性和泛化能力也较强。
{URL}: https://link.cnki.net/doi/10.27113/d.cnki.ghncc.2022.000768
{DOI}: 10.27113/d.cnki.ghncc.2022.000768
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的小麦病虫害问答系统的研究与应用
{Author}: 王芳
{Tertiary Author}: 王永梅;王国梁
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 小麦病虫害;知识图谱;问答系统;BiLSTM-CRF;BERT
{Abstract}: 小麦作为我国的主要粮食作物,种植面积大,经济效益高,病虫害的发生将直接影响到小麦的高品质高质量,造成一定的经济损失。本文根据小麦病虫害领域数据多源异构的特点,利用知识图谱组织小麦病虫害领域知识,采用深度学习模型分析自然语言问句信息,设计并实现了基于知识图谱的小麦病虫害问答系统。本文的主要研究工作如下:(1)构建了小麦病虫害知识图谱。本文通过对小麦病虫害领域的数据进行分析,自上而下构建了小麦病虫害知识图谱。首先定义了小麦病虫害的10类实体和8种实体之间的关系,设计了小麦病虫害知识图谱的概念模式。本文采用BIOES对数据进行序列标注,提出了基于Bi LSTM-CRF的方法识别小麦病虫害实体信息。通过调节实验参数,Bi LSTM-CRF模型的F1值达到了88%,在小麦病虫害实体识别上的效果较好。最后根据实体标签结果抽取了小麦病虫害三元组数据,使用Neo4j图数据库对小麦病虫害数据进行存储和展示。(2)提出了基于BERT的小麦病虫害问答方法。由于目前暂时没有公开的小麦病虫害的高质量问句文本数据集,所以本文通过手工构建了小麦病虫害问句集。根据小麦病虫害知识图谱的概念模式,定义了8类小麦病虫害问句类别。基于BERT预训练语言模型对小麦病虫害问句进行了问句意图分类,实验表明使用BERT模型的问句分类的准确性达到了97%。针对小麦病虫害问句实体识别问题,采用Bi LSTM-CRF模型识别问句中的实体,F1值达到了95.86%。最后通过小麦病虫害问句实体和问句类别构成问句三元组,使用Cypher语句在小麦病虫害知识图谱中查询用户提出的问题,并将其转化为自然语言的形式呈现给用户。(3)开发了基于知识图谱的小麦病虫害问答系统。本文的问答系统主要是以存储在Neo4j图数据库中的小麦病虫害知识图谱作为数据来源,使用深度学习模型实现小麦病虫害的知识问答功能,对小麦病虫害防治有重要指导意义。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2022.000461
{DOI}: 10.26919/d.cnki.gannu.2022.000461
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的农作物病虫害问答系统设计与实现
{Author}: 钱学霖
{Tertiary Author}: 马新明;李勇
{Publisher}: 河南农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 农作物;病虫害;知识图谱;问答系统;自然语言处理
{Abstract}: 我国病虫害年平均发生面积在4.60～5.08亿hm2,对各类农作物的生产产生巨大影响。因此,掌握病虫害防控知识,实现科学防控,对作物的产量和品质形成具有重要影响,为解决知识传播中的低效失真和手段落后问题,需要构建精准、高效、快捷的病虫害防治问答系统。本研究在收集农作物病虫害数据基础上,结合知识本体构建农作物病虫害知识图谱,利用自然语言处理技术,将病虫害知识的问题理解任务转化为问句模板分类任务,采用多种机器学习自然语言处理模型,实现病虫害问题分类,最后集成病虫害问答模型,实现病虫害问答系统。主要研究结果与结论如下:1.农作物病虫害知识图谱的构建。根据农作物病虫害专业知识特点,采用自顶向下的构建模式,结合农作物病虫害知识结构,设计了5层病虫害知识本体,确定了病虫害知识的领域和范围。依据病虫害知识特征,构建实体、关系和属性三元组知识框架,实现了麦类、玉米、水稻、棉麻、油料、糖、烟等12类作物,1065种病虫害知识图谱,包括农作物病虫害实体6594个,关系7044条,三元组6994个;设计出11类问题模板,构造了155916条、132类自然语言问句。2.基于自然语言处理的问答模型构建。基于农作物病虫害知识图谱,利用Han LP中文自然语言处理工具,进行农作物病虫害命名实体识别,形成了1114个农作物病虫害词典;利用自然语言处理技术,设计了基于朴素贝叶斯（Naive Bayes Classifier,NBC）、基于转换器的双向编码表征量（Bidirectional Encoder Representation from Transformers,BERT）和文本卷积神经网络（Text Convolutional Neural Network,Text CNN）农作物病虫害问答模型并测试,结果表明,NBC、BERT和BERT+Text CNN模型准确率分别达到96.8%、93.0%和99.6%,其中NBC最为稳定,精确率、召回率和F1值都在95%以上,最优模型为BERT+Text CNN,精确率、召回率和F1值都在99.5%以上,说明基于机器学习实现问题分类,利用知识图谱实现农作物病虫害知识匹配是可行的。3.农作物病虫害问答系统设计与实现。基于病虫害知识图谱,结合构建的农作物病虫害问答模型,利用Web Service和Flask框架技术,设计了三层农作物病虫害问答系统架构,构建了基于知识图谱的农作物病虫害问答系统,实现了农作物知识图谱、问答模型和问答服务的集成,结合命名实体识别技术,实现了农作物病虫害知识的精准推荐。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2022.000295
{DOI}: 10.27117/d.cnki.ghenu.2022.000295
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的问答系统研究与构建
{Author}: 强成宇
{Tertiary Author}: 李晓戈
{Publisher}: 西安邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 问答系统;实体消歧;图神经网络;知识图谱;自然语言处理
{Abstract}: 由于网络上数据量的快速增长,从海量数据中获取用户需要的信息成为一项十分困难的工作,因此近年来可以准确查询答案的问答系统备受关注。同时随着知识图谱的发展,为问答系统提供了新的技术支持,其特有的三元组结构完美的契合了问答系统的查询逻辑。因此,本文将研究方向聚焦于基于知识图谱的问答系统上。知识图谱问答(KGQA)的交互可以归结为用自然语言从知识库中查找答案并返回的过程,然而这并不是一项简单的任务,如何识别问句的实体指称项、如何准确无歧义的链接实体,以及如何完成答案的查找,这些都充满了挑战。通过阅读大量文献,调研了国内外基于知识图谱问答的发展动态,研究了深度学习,特别是图神经网络和注意力机制在知识图谱问答中的应用,本文设计实现了一个基于知识图谱的问答系统。首先通过问题实体识别模型(Bert-Transformer-CRF)与实体消歧模型(Bert-Tf-Idf-GAT)来实现对自然语言问题的理解,再通过基于查询子图的答案排序模型(Bert-RCNN-Self-Attention)来实现答案的查询,最后通过CCKS2019与NLPCC2018数据集验证了上述模型与问答系统的有效性。对其中涉及到的问题理解及答案排序进行了深入研究,具体的研究成果包括以下两个方面:(1)问题理解是基于知识图谱问答的重要组成部分,本文利用实体链接技术解决该问题,具体分为问题实体识别与实体消歧两个子任务。问题实体识别一般作为序列标注问题来处理,在“01”标注法进行标注的基础上,本文首先刻画问题特征的文本向量通过拼接字符向量、位置向量和句向量得出,其次,经过Bert编码后,利用Transformer学习各个字符之间的上下文序列特征,最终通过链式CRF序列化标记出问题中的实体指称项;实体消歧是将问题实体识别出的实体指称项准确无歧义的链接到知识图谱的目标实体上。在通过信息抽取与融入关键词将含有半结构化数据的知识库构建为全局知识图谱的基础上,首先,利用Bert预训练模型对问题中的实体指称项进行嵌入融合,其次,使用图注意力神经网络对全局知识图谱中候选实体节点进行加权聚合表征,最后,计算实体指称与各候选实体的特征相似度以实现实体消歧。实验结果表明,在两个数据集上本文模型都取得了很好的效果。(2)本文将答案查询视为问句与候选答案三元组的相似度排序问题。在经过问题理解生成的查询子图基础上,本文通过Bert-RCNN-Self-Attention来判别知识图谱中相应实体是否为问题的答案。首先在原有问答数据集的基础上引入外部知识增加训练语料,同时基于Bert的句向量表示方法得到问句与候选三元组的向量表示,其次,将拼接得到的特征向量作为RCNN的网络输入,充分关注两段文本之间不同维度的语义特征,并结合自注意力机制,对各个候选三元组向量进行加权变换,最终通过打分排序实现答案的查询。通过在NLPCC2018问答数据集的实验结果表明,较之前主流的端到端问答模型在准确率上有了进一步的提高。
{URL}: https://link.cnki.net/doi/10.27712/d.cnki.gxayd.2022.000008
{DOI}: 10.27712/d.cnki.gxayd.2022.000008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向危险化学品的知识图谱构建研究
{Author}: 程钊
{Tertiary Author}: 邹凌;陈观林
{Publisher}: 常州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 危险化学品;知识图谱;自然语言处理;随机梯度下降;命名实体识别
{Abstract}: 化学工业作为基石产业在推动我国的经济发展中具有重要的作用,但化学化工事故的频发,也造成了巨大财产损失和人身伤害。因此,采用自然语言处理和知识图谱实现风险可视化,从而减少甚至避免事故的发生。现今关于危险化学品的数据集及相关研究较少,使得从网络上的非结构化文本中抽取知识并构建知识图谱存在很大的困难。本文基于深度学习对此问题进行研究,具体如下:首先,爬取目标危险化学品的数据,获取描述危险化学品风险信息的语句。根据所获语句的特性,将关系作为一种实体,采用命名实体识别技术,实现合并命名实体识别和关系抽取的目的。同时,设计出符合本研究所需要的标注工具,构建危险化学品风险信息数据集。为提升模型的收敛速度,本文优化了平均随机梯度下降算法(Averaged Stochastic Gradient Descent,ASGD),得到了参数回滚平均随机梯度下降算法(Parameter Rollback Averaged Stochastic Gradient Descent,PR-ASGD)。针对平均随机梯度下降算法在语言模型中需要微调获取更优解和跳出局部最优解能力弱的问题,利用参数回滚方法动态调整模型训练中的学习步长,以增大算法跳出局部最优解的概率,得到更优解,并加速模型收敛。为快速识别出风险信息语句中的实体,本文提出一种基于PR-ASGD与BERT(Bidirectional Encoder Representation from Transformers)的模型。采用PR-ASGD算法使得模型有跳出局部最优解的能力;利用预训练模型BERT获取信息量更为丰富的词向量,并在双向长短期记忆网络(Bidirectional Long Short-Term Memory,Bi LSTM)层后结合自注意力机制层,更深层次的挖掘字符间的语义信息。然后利用该模型对风险信息语句进行信息抽取,获得相应风险信息数据。最后本文构建含有风险信息的危险化学品知识图谱,并设计了知识图谱可视化查询系统。实验结果表明,在Penn Treebank数据集上使用PRASGD算法,AWD-LSTM(Averaged Stochastic Gradient Descent WeightDropped Long Short-Term Memory)模型困惑度为56.26,AWD-LSTM-Mo S(Mixture of Softmaxes)模型困惑度为53.57,对比原模型分别降低1.03%和0.87%;在CLUENER数据集、MSRA数据集、Weibo NER数据集上使用PR-ASGD算法,F1值分别为70.90%、90.54%、56.20%,相较于使用ASGD算法F1值提高了0.4%、0.35%、1.58%;提出的模型在自建的数据集中精确率、召回率、F1值分别为94.03%、95.11%、94.57%,相较其他模型效果更佳。基于危险化学品知识图谱搭建的可视化查询系统,清楚的展示各个实体间的关联关系信息,使人们在查询危险化学品相关性质时结果能够更加直观生动。
{URL}: https://link.cnki.net/doi/10.27739/d.cnki.gjsgy.2022.000395
{DOI}: 10.27739/d.cnki.gjsgy.2022.000395
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 初中人工智能课程体验式学习活动设计与实践
{Author}: 党志华
{Tertiary Author}: 张筱兰
{Publisher}: 西北师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人工智能课程;体验式学习理论;学习活动设计
{Abstract}: 随着科技的不断进步,人工智能正以超乎想象的速度改变着世界,为教育尤其是基础教育改革带来了全新的机遇与挑战。我国高度重视人工智能科技人才的培养工作,颁布多个人工智能教育相关的文件,中央电化教育馆深入研究和探索,于2021年11月发布了《中小学人工智能技术与工程素养框架》,为当前人工智能教育教学起到参考作用。对于初中生来说,不仅需要亲身体验参与人工智能技术和生活应用场景,更需要在体验中理解人工智能技术的基本原理,尝试利用人工智能技术解决实际问题。但目前初中生对于人工智能技术的学习仅仅停留在浅层的体验学习中,对人工智能及相关技术的原理一无所知。因此,利用体验式学习活动能促进学习者深度理解人工智能知识,进而思考如何利用人工智能解决问题。基于此,本研究在人工智能教育发展的时代背景下展开,旨在落实初中人工智能课程教学实践案例,为初中人工智能课程改革提供新思路。笔者通过对L市120名人工智能教师进行问卷调查和访谈结果得出当前人工智能课程教学中普遍存在的问题,在体验式学习理论和活动理论的指导下,结合初中阶段人工智能课程的特点,提炼出体验式学习活动的设计原则及要素,从而构建了人工智能课程体验式学习活动设计框架,致力于解决当前人工智能课程教学中的问题。在此基础上,以“智能语音技术”和“自然语言处理技术”为本研究案例,从教师创设情境,学生体验感知;教师引导探究,学生探究原理;教师组织讨论,学生归纳概括;教师布置任务,学生编程实践;教师任务反馈,学生领悟内化五个体验式学习阶段展开两轮行动研究,并在每一轮教学实践中对学生学习行为数据进行分析和反思,从而优化体验式学习活动设计,最终通过学习单、课堂观察量表、学生作品评价表、学习体验量表和师生访谈从学生的认知、行为、情感体验验证了学生的学习效果。实践表明,经过优化后的体验式学习活动设计初见成效,在学生认知方面,学生能够更深入的了解和体验人工智能知识,掌握人工智能技术原理,达成预期目标;在学生行为方面,大部分学生可以在操作中熟练应用知识并完成编程作品,培养了其自主探究问题及小组交流协作能力;在学生情感体验方面,学生的学习体验感有了较为明显的提升。最后,总结不足与展望,希望后续本研究构建的体验式学习活动设计框架可以为初中人工智能课程教学提供一定的理论参考和实践借鉴。
{URL}: https://link.cnki.net/doi/10.27410/d.cnki.gxbfu.2022.002009
{DOI}: 10.27410/d.cnki.gxbfu.2022.002009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度迁移学习的电力知识图谱智能问答
{Author}: 曲克童
{Tertiary Author}: 李建彬
{Publisher}: 华北电力大学(北京)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 电力知识图谱问答;深度学习;自然语言处理;TEBC-Net算法;NTBC-net算法;迁移学习
{Abstract}: 电力人工智能作为电力系统与人工智能融合形成的专用人工智能,是支撑新一代电力系统的重要手段。自然语言处理是电力人工智能领域中重要的一部分,其发展方向之一是构建调控、运检等电力领域知识图谱,形成新一代电力智能问答系统。随着知识图谱在各领域的广泛应用,基于知识图谱的问答成为了一个重要的研究领域。因此,构建以电力知识图谱为基础的智能问答系统意义重大,将其应用于电力客服、故障诊断等应用中,可以使人工智能真正与电力行业相融合,为人们提供便利。传统电力知识图谱问答方法存在诸多问题:传统模板匹配方法不灵活,过于依赖模板;传统语义相似度方法,对长问句进行相似度匹配时误差较大;传统信息检索方法,准确度不够,且缺乏可解释性;同时,传统方法均利用深度学习提高性能,而数据依赖是此类方法存在的问题。针对传统方法存在的问题,论文设计了一种电力知识图谱问答算法,在充分利用传统方法各自优势的同时,通过有效结合,交叉互补,弥补各传统方法单独使用时的不足。针对论文提出的电力知识图谱问答算法中,关系提取、电力分词以及头实体检测三项关键子任务,设计了两个算法及三个模型以解决对应任务。首先,设计了一次性对问句文本的局部特征、全局特征以及重要性特征进行编码的 Transformer Encoder-BiLSTM-CNN Net(TEBC-Net)算法。在关系提取及头实体检测任务中设计并使用基于TEBC-Net算法的关系提取模型及头实体检测模型。其次,设计了 Number optimization Transformer encoder-BiLSTM-CRF net(NTBC-net)算法,该算法在TEBC-Net算法对三大特征进行编码的基础上,针对电力文本中数字信息十分重要这一特征,设计了数字上下文强化编码算法对数字信息进行强化编码。在电力分词任务中设计并使用基于NTBC-net算法的电力分词模型。通过实验验证了在关系提取、电力分词以及头实体检测任务中,论文设计的基于两个核心算法的三大模型在各自任务评价指标上的表现都强于相应对比模型。同时,在设计模型时,将迁移学习引入模型设计,对数据进行预处理,解决了训练数据不足,深度学习对大数据的依赖问题。综上,论文通过对关系提取、电力分词及头实体检测三个关键子任务上性能的提升,进而提升论文设计的电力知识图谱问答算法的整体性能。
{URL}: https://link.cnki.net/doi/10.27140/d.cnki.ghbbu.2022.000572
{DOI}: 10.27140/d.cnki.ghbbu.2022.000572
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多头自注意力机制的电网故障诊断
{Author}: 郑钰川
{Tertiary Author}: 张旭
{Publisher}: 华北电力大学(北京)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 故障诊断;告警信息文本;多头自注意力机制;Transformer模型;BERT模型
{Abstract}: 为实现碳达峰、碳中和的目标,我国传统电力系统正在向以新能源为主体的新型电力系统转型升级,给电网的调控运行带来了新的挑战。智能化的电网故障诊断对提高故障诊断速度,及时切除故障,恢复电网正常供电有着重要意义。但是现有的电网故障诊断方法大多依赖专家经验和诊断规则,缺乏自主学习推理故障信息的能力,难以满足现阶段正在转型的复杂电力系统,也难以适用于多变的实际工程现场。针对上述问题,本文分析了电网告警信息文本特征,研究了多头自注意力机制,提出一种基于谷歌Transformer模型的电网故障诊断方法。此方法利用多头自注意力机制,自主提取告警信息文本的表述特征,不依赖人工设计诊断规则,实现端到端的电网故障设备识别和故障情况诊断。算例结果表明,所提方法能在电网发生复杂故障情况下识别故障设备,但是由于Transformer模型特征提取深度有限,对于拒动开关的识别准确率较低,也无法准确输出拒动开关的名称。针对上述所提方法的不足,本文分析研究告警信息的时序特性和数量特性,引入时序权重函数对多头自注意力机制进行改进,提出一种基于计及时序特性的改进BERT模型的电网故障诊断方法。所提方法使用引入时序权重函数的多头自注意力机制,赋予每条告警信号时间属性和时序权重,提高模型对故障发生短时间内的关键信息的注意力。所提方法通过改进了多头自注意力机制的BERT(Bidirectional Encoder Representations from Transformers)模型,不依赖电网拓扑结构和EMS基础参数库,自学习设备和开关间的关联关系,挖掘开关元件的命名规则,推理得出拒动开关的名称。算例结果表明,所提方法能够准确自动输出拒动事件中的拒动开关名称,在诊断速度和准确性上都有明显优势。
{URL}: https://link.cnki.net/doi/10.27140/d.cnki.ghbbu.2022.000348
{DOI}: 10.27140/d.cnki.ghbbu.2022.000348
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于电商产品评论的图形化数据分析系统设计
{Author}: 高聪
{Tertiary Author}: 熊杰;柯欢
{Publisher}: 长江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 商品评论;情感倾向分析;系统设计与实现;BERT-BiLSTM
{Abstract}: 电商产品评论数据是用户进行网上购物时重要的参考依据,而在单个商品评论数据量普遍较大且好评比例极高的现状下,想要快速的从评论数据中获取商品整体有效的信息,则需要对商品评论数据进一步的加工处理以及分析。商品评论数据中蕴含的情感倾向,是商品能否满足用户需要的重要信息。目前文本情感倾向分析相关研究已有了较大进展,但是大多是基于预先获取的文本数据进行训练与分析,这并不满足普通用户对商品评论数据分析的需要,所以本文设计了一种通过搭积木即可获取评论数据的方式,并与BERT-Bi LSTM融合模型以及情感词典相结合,实现了可简单快捷获取商品评论数据并进行文本情感分析的图形化数据分析系统。本文通过系统的需求分析、架构设计、具体实现、系统测试四个步骤,设计实现了一个图形化评论数据分析系统。该系统从功能上分为三大模块:数据模块,情感分析模块,操作及展示模块。(1)数据模块,设计并实现了实时评论数据获取、数据清洗、数据存储,提供两种实时评论获取方式,一种是直接输入商品链接获取商品评论数据,另一种是通过组合预先定义好的图形爬取模块实现数据爬取。(2)情感分析模块,包括情感词提取分析以及情感倾向模型构建与分析。本文通过整合多种主流情感词典对评论数据进行情感词抽取,并对结果进行图表分析展示。情感倾向分析模型采用了BERT-Bi LSTM模型对评论数据进行情感倾向二分类,并与其他多个模型进行对比实验,验证了该模型在文本情感二分类中的优越性。(3)操作及展示模块,接受用户操作指令,并将评论数据分析结果以情感词词云、柱状图以及评论数据分类列表等形式展示。最后通过对系统的功能以及性能测试,验证了各个模块均能正常运行并协调工作,证实了本系统在实时评论数据获取上的高效性、在情感倾向分析上的准确性。
{URL}: https://link.cnki.net/doi/10.26981/d.cnki.gjhsc.2022.000371
{DOI}: 10.26981/d.cnki.gjhsc.2022.000371
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于在线评论的智能家居企业竞争对手情报分析
{Author}: 申学文
{Tertiary Author}: 支凤稳
{Publisher}: 河北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 在线评论;智能家居;竞争对手情报
{Abstract}: 互联网的高度发展,使得物联网进入大众视野。众多企业纷纷推出各自的智能家居产品,为用户生活带来了便利,它们的快速发展催生出激烈的竞争环境,如何从数多智能家居企业中脱颖而出、获取竞争对手情报成为企业应当关注的重要问题。在线评论作为公开数据源之一,受到不少竞争情报领域学者关注,而竞争对手作为竞争情报重要因素,其情报分析对于企业维持竞争优势,提高竞争力有着不可忽视的作用。本研究基于在线评论、竞争情报等相关概念及理论,结合波特模型建立出利用在线评论实现竞争对手情报分析的框架,界定竞争对手情报的研究范畴,逐步完成竞争对手识别、竞争对手实力分析、差异化策略分析、竞争对手反应预测以及竞合行为规避分析。研究结论包括以下内容:(1)竞争对手识别。研究完成对在线评论的对比意见抓取之后,通过一般性行处理进行数据清洗,又采用关键词抽取,识别出格力、华为、小米等十二个竞争品牌,选定其中一个作为后续竞争对手情报分析对象。(2)竞争对手实力分析。美的和格力分别拥有大家电、小家电等多系列产品,研发广度和深度存在明显差别。美的重视产品研发广度,格力则重视产品研发深度。在大家电方面,格力主打空调产品,美的虽各个产品均表现良好,但缺乏一定的特色。在小家电方面,两者均有厨房系列、浴室系列、居室系列和取暖系列,美的研发重点是厨房系列,格力则是居室系列。(3)竞争对手差异化策略分析。从研究维度、产品品类、侧重点来看,二者具有明显的不同,推测出它们采取的竞争策略为差异化策略。在大小家电领域,各个系列下子系列产品也存在差异,美的产品功能组合种类多样,为不同用户群体提供相应服务,格力产品功能富多样化,用户可选择机会较少,不能满足多用户群体需求。(4)竞争对手反应预测。根据前述两品牌实力分析结果,可以将分析指标分为研发和营销两方面,发现它们会选择在各自擅长的领域进行深度发展,以便维持存在竞争优势的产品地位,保持良好的竞争力,同时对产品价格进行一定调整,比如打折、促销、人物宣传等,力求满足多用户群体需求。(5)竞合规避行为分析。发现两品牌会针对不同领域选择不同的发展模式,大家电领域,它们会充分发挥各自的优势,因差异化策略的实施,会促使它们在各自的劣势产品上达成一定合作,从而呈现出竞争中合作的复合关系。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2022.000223
{DOI}: 10.27103/d.cnki.ghebu.2022.000223
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的古诗词意境分析
{Author}: 张永平
{Tertiary Author}: 李宇
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 古诗词;自然语言处理;文本分类;情感分析
{Abstract}: 中国古典诗词是中华文化宝库中的宝藏,而且还蕴含着中华民族的精神,是我国古代人民智慧的结晶。学习古诗词不仅可以了解历史文化,增强民族自豪感,而且还可以丰富人的精神世界。目前古诗词的研究工作大部分是依赖文学相关工作者的人力研究。二十一世纪以来,随着计算机硬件水平的高速发展,机器学习与深度学习迎来又一春,同时自然语言处理技术也受到更多人的关注,其也被应用在诸多领域中,如语言翻译、信息检索、自动问答等,且均有不俗的表现。本文尝试将自然语言处理应用于古诗词分析领域,使用不同的算法分析古诗词的意境,包括诗词的主题与情感等。本文的研究方法是先对开源数据集的进行处理,并对数据集中原有的诗词数据进行清洗、补充,最终将数据集用于词向量模型以及算法模型的训练。在对古诗词进行意境识别前,首先选定古诗词分词工具,对比多种分词工具如THULAC、Jieba、甲言等,比较其在古诗词分词方面的表现。使用Word2Vec工具结合分词结果训练词向量模型,在古诗词的主题分类方面,将问题转化为文本分类问题,本文对比多种文本分类算法,总结其在古诗词主题分类问题上的准确率;使用基于Attention机制的Bi LSTM模型,对古诗词的情感进行分析。除此之外,本文还使用图数据库构建古诗词知识图谱,将古诗词信息进行串联,同时也可用于信息检索。最终将模型集成至古诗词意境分析系统中,可供用户输入诗词,并得到该诗词的意境分析结果,同时也可以根据相关信息检索其他诗词。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.002220
{DOI}: 10.26944/d.cnki.gbfju.2022.002220
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向城轨列车故障的知识图谱构建方法研究
{Author}: 曲佳
{Tertiary Author}: 宿帅
{Publisher}: 北京交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 列车故障文本;知识图谱;对抗训练;图神经网络
{Abstract}: 城市轨道交通系统庞大复杂,子系统、设备数量巨大,当系统正常时,自动化水平很高。一旦在运营中突发故障,传统故障处置仅通过人工处置的方式使其恢复正常运行,处置过程存在异常处置操作繁多、故障处置相关人员缺乏足够的处置经验以及信息处理自动化水平低等问题,在很大程度上影响了城市轨道交通的服务质量。与此同时,城市轨道交通运营公司从故障现场收集了大量珍贵的列车故障记录数据,其中详细描述了有关列车故障的发生和发展过程,包括故障现象、位置、处置方式和影响等重要信息。但这些数据通常只备案留存,没有作为文本分析使用,且目前针对这些数据缺乏有效的分析方法。基于以上故障处置现状,本文以城市轨道交通历史列车故障的非结构化文本记录数据为研究对象,研究列车故障知识图谱的构建方法,深入挖掘故障事件的关键要素以及各要素的关联关系,为城市轨道交通的故障处置相关人员提供辅助支持,以应对日益复杂的城市轨道交通突发故障事件,提升故障处置效率。本文的研究工作主要包括:(1)根据列车故障文本的描述特点,结合专家知识,定义了列车故障的实体类型和关系类型。针对轨道交通领域缺乏训练语料的现状,参照公开领域知识图谱的标准数据集,构建了适用于实体抽取的列车故障实体标注数据集、适用于知识表示的列车故障知识表示数据集以及适用于知识推理的列车故障知识推理数据集。同时借助Neo4j(一种高性能图形数据库)对列车故障知识图谱进行存储并可视化。(2)针对列车故障文本的语言描述结构不规范和列车故障实体的边界不清晰问题,提出了一种结合对抗训练和基于网格结构(Lattice)的长短期记忆网络的词汇增强列车故障实体抽取方法。基于构建的数据集对方法进行验证,证明了该实体抽取方法的有效性。(3)针对采用离散化符号表示的列车故障知识三元组难以应用神经网络进行进一步分析的问题,提出了一种基于知识图谱注意力网络模型的列车故障知识表示方法。基于构建的数据集对方法进行验证,证明了该知识表示方法的有效性。(4)针对列车故障知识图谱可能存在知识不完备,存在隐含的规律性知识和语义联系的问题,提出了一种基于关系图卷积神经网络模型的列车故障知识推理方法。基于构建的数据集对方法进行验证,补全了列车故障知识图谱,证明了该知识推理方法的有效性。研究结果表明,通过本文提出的城市轨道交通列车故障知识图谱构建方法,可以得到较为完善、直观且便于存储与挖掘的列车故障知识图谱。
{URL}: https://link.cnki.net/doi/10.26944/d.cnki.gbfju.2022.002788
{DOI}: 10.26944/d.cnki.gbfju.2022.002788
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Text-to-SQL问答系统的设计与实现
{Author}: 宁泽楠
{Tertiary Author}: 于洪志
{Publisher}: 西北民族大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: Text-to-SQL;CSpider;语义增强模型;字序列模型;BERT
{Abstract}: 随着人工智能技术的发展,将自然语言转化为结构化查询语言的任务得到了学术界的广泛关注,因为它向非专业用户提供了数据库查询的接口,大大降低了用户查询数据的学习成本,不但可以提高查询效率,而且也能提高人们的生活效率,具有较高的研究价值。目前,中文的自然语言转化为结构化查询语言任务面临诸多挑战,第一,在中文数据集的研究方面,其SQL语句的预测准确率较低,还存在很大的优化空间;第二,中文的表达中存在众多的同义词,如何准确的做到自然语言问句同数据库列名之间的映射,是该任务面临的主要挑战。本文以CSpider中文数据集为研究对象,该数据集将SQL语句分为简单、中等、困难三种预测难度。本文根据中文字和词的不同表达形式,分为基于词的Text-to-SQL的研究和基于字的Text-to-SQL的研究。主要工作如下:(1)构建了融合词性和依存句法特征的词序列语义增强模型基于词的研究方面,本文对原始数据采用了新的分词方法,分词效果显示更贴近用户日常生活的语义理解。同时在词向量方面,为了增强模型对语义的理解,在原有词向量中加入了词性特征向量和依存句法特征向量,实验结果表明,加入词性特征后对实验的KEYWORD和AND\OR子任务提升明显,对于中等难度的SQL语句来说,提升了15%和7.8%。对困难难度的SQL语句来说,提升了12.2%和13.8%。(2)构建了基于BERT的字序列模型基于字的研究方面,本文利用BERT模型作为编码器编码,训练完成后的字的向量同时也包含词的语义特征。除此之外,为了增强自然语言问句与数据库表的列名之间的语义关系,将自然语言问句和数据库列名做拼接组成句对送到BERT多语言模型中来生成向量,实验结果表明在将数据库列名作为BERT模型的输入序列后,对于该任务的各项子任务来说,其准确率、召回率和F1值都上升了5%左右,对于WHERE子任务上升了10%左右。最终对于SQL语句的整体准确率,其简单难度、中等难度和困难难度分别提高了3.6%、4.4%、1.2%。(3)搭建了基于Text-to-SQL的问答系统原型以CSpider数据集作为系统的数据库,搭建基于Text-to-SQL技术的系统,为用户提供航空公司信息、高校信息、图书信息等多个领域的数据转换接口,同时包含辅助用户提问和相关信息反馈的功能,来提升用户使用体验。
{URL}: https://link.cnki.net/doi/10.27408/d.cnki.gxmzc.2022.000448
{DOI}: 10.27408/d.cnki.gxmzc.2022.000448
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于对比学习的用户文本聚类模型研究
{Author}: 汤旭东
{Tertiary Author}: 张伟
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 无监督学习;对比学习;文本聚类;用户文本挖掘;同名消歧
{Abstract}: 大规模文本数据在丰富人们信息生活的同时也对如何更好地管理它们,挖掘其价值提出了挑战。聚类分析作为一种无监督学习方法,提供了一种不依赖标注信息,仅依靠数据本身的特征来识别数据分布模式的方案。文本聚类是自然语言处理的一个重要分支,已经有了一些成功的应用。例如,它可以把问答平台、社交媒体上用户发布的大量文本自动归入不同的主题,从而减轻平台的负担;可以将文献数据库中作者名存在歧义的论文自动划分为不同作者的发表集合,等等。本文利用不同的数据增广方式结合对比学习缓解文本聚类中数据稀疏的问题,针对两个场景可利用的额外信息设计了文本聚类框架,具体说来:针对用户生成内容平台(UGC)的文本,文本的作者(ID)通常是公开的。本文从统计特征出发,验证了每个作者只关注有限的话题类别,并发布相关话题下的文本的假设,说明了对用户文本聚类时考虑作者的合理性。并基于这样的观察,提出了用户文本聚类框架CAT。CAT从文本表征和聚类目标函数两个方面考虑作者的影响力。其中目标函数以对比学习的形式,结合深度表示学习技术,增广的数据来源于聚类级别的注意力表示融合以及作者的表征,在连续空间进行,在用户文本聚类场景下解决了前人工作中对文本进行词替换以增广数据导致的文本中心词丢失的情况。在有作者(ID)的数据上CAT的表现大大超过了其他考虑和不考虑作者的文本聚类模型,说明了考虑作者角色在用户生成文本聚类上的益处和所提出方法的有效性。针对文献管理平台的无监督论文作者同名消歧问题,本文首次提出端到端的基于异质网络的对比聚类框架HINCC。以论文之间共同作者,共同机构、引用关系等建立论文信息异质网络,通过节点自遮掩和基于边的遮掩两种视图(View)作为数据增广方式,应用对比学习结合异质图神经网络编码器,使得节点周围不同类型邻居的信息充分交互融合构成节点表征,并且邻居信息相似的节点表征更接近;同时利用聚类生成的伪标签参与对比学习中负样本的动态筛选,减少了同类别负样本带来的性能衰减问题。在三个不同的论文同名消歧数据集上证明了所提出方法的有效性。综上所述,本文从不同文本聚类场景可利用的额外聚类线索出发,构建针对性的数据增广方式,探索了应用对比学习引导这些生成的正负例表征对聚类的增益的能力,并在多个公开数据集上验证了所提出方法的有效性。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.001645
{DOI}: 10.27149/d.cnki.ghdsu.2022.001645
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 新闻长文本检索方法的设计与实现
{Author}: 刘绍涛
{Tertiary Author}: 汤羽
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: BERT;多模型混合;文本向量化;长文本检索
{Abstract}: 在这个互联网信息爆炸的时代,人们对信息的获取、处理以及其他应用的一系列需求有着跨越式的发展,人们可以从众多途径得到自身所需的新闻等长文本信息,而这些日益增加的长文本数据也会造成信息过载,检索困难等一系列问题。而现有传统的关键字检索或短文本检索的检索逻辑是通过输入关键字与数据库中的文本数据所形成的倒排索引进行Top-N匹配最终得出相应结果,面对长文本字段检索、大体量数据量下的新闻长文本场景,其搜索效果不尽人意。为解决上述问题,本文提出并实现了一种将文本向量化技术与向量检索相结合的解决方案从而应用到新闻长文本检索场景当中。在前期调研阶段,本文通过分析现有文本检索技术的不足之处,发现传统的关键词检索和语义检索只是将文本简单的划分为段,逐段进行检索,检索结果依然存在检索不准确、相关度不高等缺点。因此基于上述问题,本文针对算法架构部分进行重新设计,并结合相应的应用场景验证本文所提出的算法架构的有效性,此外结合数据处理流程以及检索需求设计并实现相关的检索系统,从而完善相应的解决方案。第一,构建新闻长文本数据集。通过构建采集系统,使用爬虫采集互联网新闻,对入库的数据进行数据预处理,剔除无用的脏数据,以适应新闻长文本的检索。第二,创新性的引入文本向量化技术。通过采用预训练模型将新闻长文本转化为数值向量的手段,达到文本向量化的效果,并通过向量检索技术检索这些向量,进而达到检索新闻长文本的目的。第三,多模型混合。针对文本向量化的特点,以BERT模型为基础,混合Ro BERT、Distil BERT、XLNet模型,使文本向量化能够在新闻长文本检索任务中得以适用。本文通过结合多模型混合技术,达到了提高新闻长文本检索效率的效果。之后将该新闻长文本检索方法融入到系统当中,完成了一个集新闻长文本采集、新闻长文本检索功能于一体的复合新闻长文本检索系统。最后设计多组实验以及系统测试验证该方案的有效性。在实验中将混合模型与多个单模型进行对比,证明了模型的有效性,并对相关部分进行了合理的验证,并对实验结果进行分析,得出本文模型能够在新闻长文本检索方法表现出比较好效果的结论。在系统测试中完成了包括用户管理新闻长文本检索、数据管理、爬虫配置和前后端交互等内容的测试。得到了一个功能较为健全、使用方便的新闻长文本检索系统。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003485
{DOI}: 10.27005/d.cnki.gdzku.2022.003485
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于ACE2活性的牡蛎ACE抑制肽研究
{Author}: 刘维维
{Tertiary Author}: 曹敏杰
{Publisher}: 集美大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: ACE2;ACE抑制肽;作用机制;人脐静脉内皮细胞;细胞转运
{Abstract}: 高血压是严重危害人类健康的常见慢性病之一,对于高血压的防治是近年来的研究热点。食源性血管紧张素转化酶（Angiotensin-converting Enzyme,ACE）抑制肽因其安全温和的特点,成为了高血压防治的重要研究对象。但是,对ACE抑制肽的研究通常仅以ACE的抑制活性为指标进行筛选和鉴定,随着血管紧张素转化酶2（Angiotensin-converting Enzyme 2,ACE2）在血压调控中的作用逐渐被人们熟知,ACE抑制肽是否会对ACE2的活性产生影响值得进一步探究。本研究首先以猪肾脏为原材料,制备工具酶ACE2。以太平洋牡蛎（Crassostrea gigas）为原料,制备酶解产物并从中分离纯化ACE抑制肽。最后,探究了ACE抑制肽的酶解稳定性和吸收稳定性以及抑制肽的作用机制。首先,利用免疫印迹法（Western blot）进行分析,结果显示猪不同组织间ACE2的含量差异较大,猪肾脏中含量最高。在此基础上,以猪肾脏为材料,通过酸沉淀、硫酸铵盐析,结合多种柱层析方法对ACE2进行分离纯化。结果表明,ACE2分子量约为98 kDa,纯化倍数为149.8,得率为0.1%。对ACE2进行质谱鉴定,得到41个肽段,与猪ACE2的氨基酸序列高度一致。ACE2为金属蛋白酶,最适pH为7.0,最适温度为40℃。Zn2+能激活其活性,而Cu2+、Fe3+和Cd2+对ACE2的活性有抑制作用。圆二色谱分析发现,ACE2的热变性温度为67.5℃。PAS染色结果显示猪ACE2为糖蛋白。其次,以太平洋牡蛎为原料制备牡蛎肽。对牡蛎肽进行抗氧化性、DPP-Ⅳ抑制活性和ACE抑制活性的检测,结果显示,牡蛎肽的ACE抑制活性最为突出。因此,以ACE和ACE2为靶标酶,利用Superdex TM peptide 10/300 GL凝胶过滤柱和高效液相色谱从中分离纯化ACE抑制肽。对分离后的组分进行质谱鉴定,并经BIOPEP和分子对接对多肽进行筛选,得到了四条多肽PGY、IDN、GPT和GGSL。对ACE2的活性测定结果显示,PGY和IDN对ACE2的活性无影响,而GPT和GGSL对ACE2的活性有抑制作用,因此GPT和GGSL未用于进一步研究。PGY和IDN对ACE的IC50分别为1.0 mmol/L和2.1 mmol/L,抑制模式分别为混合性抑制和竞争性抑制,且均具备ACE酶切稳定性。PGY的体外抑制活性最强,故选择PGY和牡蛎肽粉为研究对象,建立HUVECs细胞模型探究其对高血压相关基因的影响。结果显示,三肽PGY和牡蛎肽粉均能通过下调AngⅡ/NOX2/ROS通路减少细胞内活性氧（Reactive Oxygen Species,ROS）的累积并降低ET-1的表达量。Caco-2细胞模型结果显示,PGY在小肠上皮细胞转运吸收中稳定性较差,因而在实际利用中应对其进行修饰或包埋,以提高其生物利用率。本研究从猪肾脏中获得了天然ACE2,为牡蛎ACE抑制肽的筛选和制备增加了靶标酶,为ACE抑制肽的功能活性研究提供了工具。牡蛎ACE抑制肽的制备及其作用机制的研究,为牡蛎源海洋功能性产品开发提供了理论基础。
{URL}: https://link.cnki.net/doi/10.27720/d.cnki.gjmdx.2022.000204
{DOI}: 10.27720/d.cnki.gjmdx.2022.000204
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于SAO的技术脉络知识图谱构建
{Author}: 张然
{Tertiary Author}: 谷俊
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: SAO结构;光刻技术;专利分析
{Abstract}: 在新科技革命时期,研究技术脉络对于国家和企业的发展都有实际意义。如何快速地对技术脉络进行识别已经成为了目前备受瞩目的热点。虽然一些文本分析法已经成为广大学者普遍应用的方法,但这些传统方法过多地依赖专家初步研究,并且暂未在技术文献的语义关系上获得明显的进展。本文将德温特专利数据库作为检索渠道,以集成电路中光刻工艺技术作为研究数据,咨询集成电路相关专家确定数据库的检索式,利用爬虫技术共从德温特专利数据库爬取出3747条数据,接着对数据进行清洗,最终获得3715条有效数据,并选取摘要字段用于后续研究。随机选择300条数据用Doccano对数据进行标注,按照8:2的比例,将数据分为训练集和测试集,使用BERT+LSTM模型,BERT+Bi LSTM模型,BERT+Bi LSTM+CRF模型分别对数据集进行训练。最终BERT+Bi LSTM+CRF模型的综合评分最高,因此用该模型对剩余数据的实体进行预测,将所得结果进行整理得出专利的SAO结构,存入Neo4j数据库中,得到光刻技术专利的功能实现关系和用途的知识图谱,最后建立了一个知识图谱的检索系统,方便挖掘知识图谱的信息,有利于企业和学者针对目前的专利情况开展更深入、先进的研究。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2022.001052
{DOI}: 10.27312/d.cnki.gshsu.2022.001052
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 视觉语言多模态融合方法研究与实现
{Author}: 于书苹
{Tertiary Author}: 罗光春
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视觉语言对齐;强化学习;因果推理;自监督学习
{Abstract}: 视觉语言导航是涉及视觉信息和语言信息的复杂多模态任务,导航智能体遵循语言指令引导,在视觉环境中移动,以到达指定目的地。视觉语言导航可以帮助机器人实现许多有价值的应用,如“室内家务”、“自动物流”及“消防救援”等。现有基于Transformer的视觉语言导航方法显著地提升可见环境的性能表现,但仍然存在不可见环境泛化表现不佳的问题。本文聚焦于提升导航智能体在不可见环境的泛化能力,对视觉语言导航方法展开研究,主要从策略网络架构和奖励设计机制两个角度对导航智能体模型进行改进,具体研究内容主要有以下几点:1.基于因果注意力的视觉语言对齐针对数据偏差误导模型学习虚假相关性、削弱泛化能力的问题,提出基于因果注意力的视觉语言对齐方法。该方法包括1)视觉语言对齐子网络。通过因果注意力Transformer单元,挖掘环境全景视觉和自然语言指令与导航动作之间的因果关系,推理符合因果效应的导航动作,提升模型的泛化能力。2)门控更新子网络。通过门控机制筛选关键时刻信息,为导航决策提供历史信息。该方法在公开数据集R2R和仿真平台Mattport3D上测试验证,与现有的基线模型相比,可见环境的准确率SR提升2.15%,不可见环境的准确率提升2.07%。2.基于自监督辅助任务的内在奖励生成针对视觉语言导航任务中环境反馈奖励模糊、无法为视觉语言对齐提供有效的监督信息的问题,提出基于自监督辅助任务的内在奖励生成方法。通过构造三种适用于Transformer为策略网络的自监督辅助任务,促进模型自发地归纳环境语义信息和导航决策机理,生成不依赖外部监督标签的内在奖励,为智能体提供额外训练信号,提升模型的学习速率和泛化能力。相较于现有基线模型,该方法在公开数据集R2R上可见环境和不可见环境的准确率SR分别提升5.58%和1.28%。3.室内视觉语言导航系统针对现实场景对于视觉语言导航的应用需求,设计系统总体架构和相关功能模块,结合Vue、Flask、Pymysql等开发框架,构建室内视觉语言导航系统。并调用本文提出的两种视觉语言导航方法实现导航功能。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.001661
{DOI}: 10.27005/d.cnki.gdzku.2022.001661
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的药物—靶蛋白相互作用预测研究
{Author}: 郑婕
{Tertiary Author}: 肖绚
{Publisher}: 景德镇陶瓷大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 药物-靶蛋白相互作用;深度学习;Word2vec模型;BERT模型
{Abstract}: 药物-靶蛋白相互作用(DTIs)的研究在基因组时代的药物发现和发展过程中起着至关重要的作用。用计算机预测DTIs能加速先导药物的发现,能弥补用单一湿式实验来确定所有可能关系耗时和昂贵的缺点。虽然近年来基于最新的智能算法提出了许多先进的DTIs预测器,但在实际应用中还需要进一步研究、改进。本文采用以药物、靶蛋白序列为输入来判别DTIs,通过大量实验研究了基于深度学习算法的药物、靶蛋白表征方法与相互作用特征提取方法,主要内容如下:1)构建了名为“i CDI-W2v Com”的药物-离子通道靶蛋白预测器。离子通道是第二大药物靶标家族,如果离子通道功能出现障碍可导致多种疾病,比如阿尔茨海默病、癫痫、偏头痛和II型糖尿病。许多基于离子通道序列的预测器被开发出来,但预测结果并不令人满意,而且大多数预测器没有提供网页服务器。在“i CDI-W2v Com”预测器中,药物化合物的特征由SMILE-Word2vec、FP2-Word2vec、SMILE-Node2vec和ECFP四种特征表示法组成的1184D向量表示;离子通道由通过Word2vec编码的64D向量组成,相比先前工作,本文实验发现先用氨基酸的AAindex指数编码单词(三个连续氨基酸的组合)能获得更好的词向量表征;最后使用Light GBM作为决策模型。i CDI-W2v Com通过5折叠交叉验证获得的准确率和AUC分别为91.95%和97.21%,预测结果优于在该数据集上实验的其他预测器。基于“i CDI-W2v Com”我们建立了一个用户友好的网页服务器,网址为:http://121.36.221.79/icdiw2v/。2)基于BERT模型构建了泛化性能良好的“DTI-BERT”预测器。新一代大规模预训练模型为序列表征提供了更为出色的模型框架,这也为提高基于序列的DTIs判别准确率带来了突破机遇。对于靶标蛋白,我们使用经过预训练的BERT模型生成靶蛋白的表征矩阵,此方法能深度挖掘序列信息、提取出更多模式特征;对于药物分子,在试验了许多先进特征提取算法的基础上,发现基于小波变换从药物分子指纹中提取信息效果最好;两种分子的特征向量被拼接到一起,然后送入BRL模块(数据处理、映射模块)和CNN模块进一步提取DTIs的相互作用特征。在神经网络的训练中,为了提升正负样本的辨识度,采用了对比损失函数和交叉熵函数对模型的参数进行优化。“DTI-BERT”模型在GPCRs、离子通道、酶和核受体的DITs识别上获得了良好的准确率,分别达到90.1%,94.7%,94.9%和89%。为了尽可能方便实验科学家们使用,我们发布了一个用户友好的网站:http://121.36.221.79/dtibert/,提出的方法也可用于预测其他药物-蛋白相互作用。
{URL}: https://link.cnki.net/doi/10.27191/d.cnki.gjdtc.2022.000390
{DOI}: 10.27191/d.cnki.gjdtc.2022.000390
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 赶黄草花和叶中黄酮的分离纯化、组分分析及生物活性研究
{Author}: 罗婷
{Tertiary Author}: 姜建国
{Publisher}: 华南理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 赶黄草;黄酮;提取纯化;肝损伤保护;抗炎
{Abstract}: 赶黄草（Penthorum chinense Pursh）,又名扯根菜,是虎耳草科扯根菜属植物,其富含黄酮类、萜类、多酚类、木脂素类、有机酸类等活性成分。现代药理学研究表明,赶黄草具有抗氧化、护肝利胆、抗病毒、抗肿瘤、抗炎、降血脂等多种生物活性。目前鲜有针对赶黄草不同地上部分的活性物质的对比研究,因此本文以赶黄草花总黄酮（H-Fla）、赶黄草叶总黄酮（Y-Fla）为研究对象,对其进行了提取工艺优化、组分鉴定及生物活性探究,具体如下:（1）以黄酮得率为指标优化了赶黄草花、叶黄酮的热浸提工艺,得到赶黄草花黄酮最佳提取工艺为:浸提温度71℃、乙醇浓度38.59%、料液比1:21.39（g/m L）,最佳提取率为2.12%;赶黄草叶黄酮的最佳提取工艺为:浸提温度65℃、乙醇浓度50.23%、料液比1:15.74（g/m L）,最佳提取率为1.86%。在最优条件下提取赶黄草花、叶粗黄酮,经石油醚除杂、大孔树脂纯化进一步得到黄酮含量分别为94.14%、91.01%的H-Fla和Y-Fla。（2）通过UPLC-MS/MS对H-Fla和Y-Fla进行了组分分析,在H-Fla中鉴定分析出了槲皮素、乔松素、二氢玫瑰苷、癸二酸二丁酯、γ-亚麻酸乙酯、油酰乙醇胺、二苯甲酮等物质,而Y-Fla鉴定出的组分有槲皮素、阿福豆甙、山奈酚、2,2'-亚甲基双-（4-甲基-6-叔丁基苯酚）、皮质酮、薯蓣皂苷元、硬脂酸等。（3）对H-Fla和Y-Fla的抗氧化、抗肿瘤、抗光老化及胞外降糖活性进行了初步评估。首先,发现H-Fla和Y-Fla在不同评价体系中抗氧化效果存在差异:Y-Fla的总还原力强于H-Fla,而H-Fla则表现出更强的ABTS+·、DPPH·清除能力,而二者的铁离子还原能力和·OH、O2-清除能力都显著弱于阳性对照VC。其次,H-Fla和Y-Fla也能显著抑制α-葡萄糖苷酶活力,最高抑制率分别可达78.97%和91.89%。此外,H-Fla和Y-Fla对Hep G2细胞的抑制作用甚至超过阳性对照5-氟尿嘧啶,但对MDA-MB-231乳腺癌细胞无抑制效果;最后,H-Fla和Y-Fla具有抗光老化活性,中浓度下就能使UV辐照损伤的Haca T细胞存活率提高至90%。（4）分别通过酒精诱导的酒精性肝损伤模型、过氧化氢诱导的氧化损伤模型及游离脂肪酸（FFA）诱导的肝脂变性模型,对比研究了H-Fla、Y-Fla对不同类型肝细胞损伤的保护作用及机制。结果表明:在酒精性肝细胞损伤模型中,H-Fla和Y-Fla能显著提高细胞存活率、降低胞内MDA含量、显著抑制GOT、GPT外溢,但二者对于两种肝酶活力的影响有所差异。此外,细胞凋亡情况表明H-Fla比Y-Fla更能有效抑制酒精损伤导致的细胞凋亡。基因测定结果进一步证明H-Fla和Y-Fla能通过抑制P53的过表达、提高介导线粒体凋亡通路的两个关键蛋白Bcl-2/Bax的比值、干扰Caspase 3的级联激活,从而抑制酒精损伤导致的肝细胞凋亡,与此同时,H-Fla和Y-Fla还能通过激活Nrf2介导的抗氧化通路以抵御酒精导致的氧化应激。在过氧化氢损伤模型中,H-Fla和Y-Fla均能呈剂量依赖地提高L02细胞存活率,且H-Fla的保护效果优于Y-Fla。H-Fla和Y-Fla能有效降低过氧化氢诱导的肝细胞GOT、GPT和LDH三种酶外溢,还能通过提升SOD、CAT活力来逆转氧化氢导致的细胞氧化应激水平升高。此外,H-Fla和Y-Fla可有效抑制过氧化氢导致的肝细胞线粒体膜电位下降。在肝脂变性模型中,H-Fla和Y-Fla均能有效抑制L02细胞脂肪过度累积,且各浓度剂量组H-Fla降低TG累积量的效果均优于Y-Fla。二者均能通过提高SOD活力和谷胱甘肽含量从而显著降低肝脂变性细胞的氧化应激损伤,并从基因水平证实了H-Fla、Y-Fla能通过激活L02细胞的Nrf2/ARE通路抵御氧化应激,从而发挥对肝脂变性保护作用;同时还能通过促进PPARα/ACOX1/CPT-1脂代谢通路基因表达改善脂肪代谢,从而抑制FFA诱导的L02细胞脂质过度累积。（5）基于LPS诱导的RAW264.7细胞炎症模型探究了H-Fla和Y-Fla的抗炎活性,发现H-Fla和Y-Fla能显著抑制巨噬细胞释放NO,且高浓度样品组的作用效果显著强于地塞米松。细胞形态观察结果表明,H-Fla和Y-Fla均能缓解LPS导致的细胞出现伪足、形态不规则等现象。Elisa和RT-qPCR测定结果表明,H-Fla和Y-Fla能显著抑制细胞释放炎症因子IL-1β、IL-6和TNF-ɑ,并下调炎症细胞中IL-6,IL-1β,iNOS和TNF-αmRNA的过度表达,从而有效抑制炎症的发生。
{URL}: https://link.cnki.net/doi/10.27151/d.cnki.ghnlu.2022.004480
{DOI}: 10.27151/d.cnki.ghnlu.2022.004480
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 藏文律诗自动生成研究
{Author}: 色差甲
{Tertiary Author}: 才让加
{Publisher}: 青海师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 藏文律诗自动生成;藏文预训练语言模型;自动评价指标
{Abstract}: 自然语言生成是自然语言处理的重要研究领域之一。中文古诗自动生成方法的研究始于上世纪末,并因其丰富的研究价值,近年来逐渐成为自然语言生成领域的研究热点之一。同样,藏文律诗具有修辞丰富、喜用词藻、形式规范、语言华丽、韵律动听等特征,并在当代藏文教学中,同藏文文法一样,被列为必修基础课之一,从而成为研究藏语自然语言生成方法的理想切入点。在理论研究方面,该任务有助于探索人类写作过程转化为可计算的自动创造过程,同时对其他生成任务具有参考价值和启发意义;在应用价值方面,该任务在智能教育、文学研究、辅助作诗等方面有着广泛的应用场景。目前,藏文律诗自动生成研究尚处于起步阶段,现有方法生成的诗作存在上下文不连贯、主题飘逸、趋于雷同等问题。针对上述不足,该文的主要研究内容和贡献如下:1.从藏文电子书籍及网页中共收集、整理了含有46.55亿字符的藏文文本语料,其主题包括文学、自传、诗歌、格言、散文和新闻等。然后通过藏文律诗抽取算法获取了131.3万首律诗,并对每一首藏文律诗随机抽取1到4个关键词,为训练生成模型提供数据支撑。2.在基于端到端的生成模型基础上提出三种不同的生成方式,分别是逐行生成方式、半首生成方式和整首生成方式。与由多个模块组合的基线模型相比,虽然该方法中仅用一个生成模块,并且由该模型完成生成一首完整的藏文律诗,但是会降低模型之间的错误积累问题。通过从语言建模能力和生成结果多样性方面评测表明,该方法有效提升藏文律诗的生成质量和上下文连贯性。3.提出一种结合文本数据增强方法的藏文预训练语言模型。在藏文文本增强方法中,将采用基于音节混淆子集和基于上下文的增强方法,并以此取代音节(词)被随机替换或用特殊符号替换的数据增强方法。与这种随机增强方法相比,该方法不仅能降低特殊符号的使用率,而且增强的句子具有更强的逼真性,即更接近真实文本中出现过的音节误用、语法错误以及语义差错的句子。该模型在藏文文本分类和命名实体识别等五个下游任务中均取得显著效果。4.提出一种基于预训练及控制码法的藏文律诗生成方法。在藏文预训练语言模型上进行微调后生成质量显著提升,引入控制码法后在很大程度上确保了扣题程度,并且关键词在生成诗作中的平均覆盖率居高。此外,在生成诗作中不仅提高词汇的丰富性,而且生成结果的多样化方面也明显提升。经测试表明,基于预训练及控制码法的生成方法显著优于已有的方法。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2022.000765
{DOI}: 10.27778/d.cnki.gqhzy.2022.000765
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本连贯性方法研究
{Author}: 崔白云
{Tertiary Author}: 张仲非;李英明
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 文本连贯性评估;句子排序;深度学习;句子关系理解;模型加速
{Abstract}: 文本连贯性研究在文本生成和文本质量评估等自然语言处理领域发挥着重要的作用。近些年来,随着互联网技术和社交媒体的迅猛发展,文本数据的数量呈指数级爆炸增长。然而,文本数据的来源众多,有的是人工撰写的,也有的是计算机自动生成的,文章的质量参差不齐,不通顺连贯的文章会引发歧义并影响可读性。因此,如何有效地对文本的连贯性进行建模和评估,从而让多语句的文本在逻辑上和语义上更加有意义,对于提升文章的质量至关重要。文本连贯性研究的两个核心要素包括了句子内容的理解和句间关系的挖掘,本文相应地提出四个研究点:针对每个句子,本文高效地提取句子特征,准确地捕捉句子的含义。针对句子之间的关系,本文避免模型受到句子输入顺序的影响,稳定可靠地学习句子之间关联信息;本文还利用预训练语言模型的优势获得句子间的相对顺序信息,从而有效地挖掘所有句子的依赖关系;本文也显著降低关系建模时的计算成本,以建立更加实用的连贯性模型。围绕上述内容,论文形成了“两个核心要素—四个研究点”的连贯性研究框架,通过设计一系列新颖的端到端的深度学习模型对文本连贯性进行全面的建模,同时提高网络的性能和计算效率。论文的主要贡献如下:1.为了在文本连贯性评估中更高效地捕捉每个句子的特征,本文提出了以卷积神经网络为基础的连贯性评估方法。模型创新地采用卷积神经网络学习句子分布式表达,有效地提取出句中重要的语言学特征。同时,本文还考虑了句子之间的关联信息,通过计算相邻句子向量的相似性来学习上下文内容与结构,从而对文本连贯性进行多方面的考量。本方法不需要复杂的预处理操作,更简单方便。模型在连贯性鉴别式任务实验上获得了最佳结果。2.为了防止句子排序模型在理解文本内容时受到错误的句子输入顺序的干扰,本文提出了以自注意力机制为基础的句子排序方法。该方法首次将自注意力机制引入排序模型中,利用自注意力函数分析句子间的语义关联并挖掘逻辑结构,捕捉全局依赖信息,有效地避免网络在为所有句子构建表示时受到句子输入顺序的影响,更加稳定可靠。本方法在句子排序任务和连贯性鉴别式任务的实验上都证明了其优异的性能。3.为了在句子排序时获得更准确的句子相对顺序信息与深层次的语义关联,本文提出了以预训练模型为基础的关系增强型句子排序方法。此方法充分利用预训练语言模型的优势,挖掘句子对的语义内容与逻辑关系,精准地预测句子之间的相对顺序。本文将此重要的信息同时融入编码器与解码器之中,从而全面地增强整个网络的连贯性建模能力。实验显示本方法取得了最出色的句子顺序预测结果。4.为了克服先前的句子排序工作存在的计算成本大、运行时间长的问题,本文提出了基于模型加速的高效关系型句子排序方法。该方法首次将语言模型加速思想和排序任务相结合,设计了轻量化的分解-融合型语言模型结构,采用分解和信息共享策略快速捕捉句子间相对关系,并引入多种知识蒸馏技术作为监督信息,使模型保持出色性能的同时显著地提高计算效率。本方法在三个连贯性任务的实验上展现了其优越性和通用性。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001118
{DOI}: 10.27461/d.cnki.gzjdx.2022.001118
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的航行通告特征提取与可视化研究
{Author}: 曾纪炜
{Tertiary Author}: 赖欣
{Publisher}: 中国民用航空飞行学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 航行通告(NOTAM);知识图谱(KG);时空RDFs模型;自然语言处理(NPL);词嵌入(Word Embedding);知识关联可视化;空间可视化
{Abstract}: 根据国际民航组织对航空情报领域发展要求,航空情报领域在未来十年,将完成航空情报服务(Aeronautical Information Service,AIS)向航空情报管理(Aeronautical Information Management,AIM)变革。航空情报产品中蕴含了大量的航空事件间的关联及规律,为了进一步提高航空情报服务质量,就必须从庞大的航空情报数据本身中挖掘其独有的价值。因此,全面深入研究航空情报产品的数据间知识规律,提取航空情报产品的特征信息,构建中国民用航空情报产品数据集,展示航空情报产品间的知识关联,对航空事件进行及时判断及事后分析的同时,为更进一步实现航空情报产品数据重组再利用和对未来发展的预测应用奠定基础。本文主要围绕基于知识图谱的航行通告情报集构建及可视化应用技术两方面开展研究。在知识图谱航行通告情报集构建中,本文首先介绍了构建知识图谱的流程及构建航行通告知识图谱的相关技术方法;其次以航行通告为研究对象,研究了知识表示与建模的相关技术方法,结合航行通告的时空性特征,改进传统的资源描述框架模型,构建了新的航行通告时空资源描述框架模型;最后本文根据新构建的航行通告时空资源描述框架模型,研究了航行通告特征信息知识提取的映射规则,提出了一套符合航行通告特征信息提取的流程及技术方法,并实例验证该技术流程方法的可行性及有效性。在基于知识图谱的航行通告知识关联可视化应用方面,本文主要实现两种可视化应用。其一为基于图数据库的航行通告知识图谱知识关联可视化,本文首先研究了知识图谱可视化的相关技术及数据存储结构;其次结合海量航行通告的数据特征,提出了基于Neo4j图数据库节点链接图技术进行知识存储;最后实现了航行通告知识图谱知识关联可视化。其二为地理信息系统的航行通告地理空间可视化,本文首先研究了地理信息系统与航行通告特征信息之间进行地理信息可视化的可能性、数据结构及相关技术方法;其次编写了航行通告XML文本规则;最后基于地理信息系统,实现了航行通告的地理空间可视化应用。
{URL}: https://link.cnki.net/doi/10.27722/d.cnki.gzgmh.2022.000058
{DOI}: 10.27722/d.cnki.gzgmh.2022.000058
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的轴承故障诊断研究
{Author}: 马泽娟
{Tertiary Author}: 王惠中
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 轴承故障诊断;短时傅里叶变换;卷积神经网络;变分自编码器;迁移学习
{Abstract}: 电机在人类的日常生产生活中占据着非常重要的地位。若电机在运行当中出现故障,就会对人身安全及财产安全构成威胁。传统的故障诊断方法在进行特征提取时会因为人为的干预,使得诊断效果不佳,所以要在电机发生故障之前将其排除,对电机的定期检修改为预知检修,以此来减少电机故障带来的损失。因此,对电机进行故障诊断在国民生产生活中具有深远的意义。近年来,深度学习模型被广泛应用于故障诊断领域。针对收集到的原始振动信号非线性、不平稳以及故障状态存在标注稀缺性等问题,重点对卷积神经网络模型以及自编码器模型进行研究,并对这两种模型的理论与算法进行阐述,以解决传统方法在上述问题中存在的局限性。针对采集到的原始振动信号具有非线性、不平稳的问题以及特征提取时维数较高的问题,本研究采用一种将改进的卷积神经网络与短时傅里叶变换相结合的方法来对轴承进行故障诊断。通过对比选择Adam算法和学习率是0.05的网络模型来进行训练,并得到该模型在故障分类结果中的准确率与损失率。利用混淆矩阵和t-SNE降维技术的可视化能够进一步直观的了解到整个分类的结果。在Python的仿真实验中,证明了该方法可以提高轴承故障诊断的准确率。并通过与其他方法的对比说明了该方法的优越性。针对轴承的故障状态存在标注稀缺性的问题,本研究采用一种将迁移学习和变分自编码器相结合的方法来对轴承进行故障诊断。对采集到的振动信号经傅里叶变换得到频域信息,再将得到的频域信息划分为源域数据集和目标域数据集。源域数据集用来训练网络模型得到参数,并通过参数更新来反映源域向目标域的迁移,以实现目标域分类器,得到故障诊断的分类结果。在Python的仿真实验中,证明了该方法的有效性与可行性,并通过与其他方法的对比说明了该方法的优越性。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2022.000662
{DOI}: 10.27206/d.cnki.ggsgu.2022.000662
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的检索式对话系统研究
{Author}: 顾佳宸
{Tertiary Author}: 凌震华
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自然语言理解;检索式对话系统;回复选择;个性化对话;融合背景知识对话;多方对话
{Abstract}: 人工智能是一门研究如何赋予计算机类人智能的学科,涵盖图像处理、语音处理、自然语言处理等多项技术,其中自然语言处理架起了人类与机器之间语言沟通的桥梁。为了方便人类与机器进行自然且沉浸式的语言交互,科学家们致力于构建诸如 Apple Siri、Google Now、Microsoft Cortana 和 Amazon Alexa 等智能对话系统或社交聊天机器人,这也是人工智能领域长期关注的关键任务之一。构建对话系统的基本问题是如何实现计算机理解对话历史的语义,并预测出下一句合理且自然的回复。其中一条主流技术途径是从给定的回复候选集合中选择最合理的回复,采用该技术途径的对话系统被称为检索式对话系统。检索式对话系统又可以根据应用场景的不同,细分为个性化对话、融合背景知识对话以及多方对话等多个子任务。此外,随着深度学习技术的兴起,构建检索式对话系统的方法也由传统的基于规则和统计的方法向基于神经网络模型学习的方法过渡。然而,现阶段基于深度学习的检索式对话系统往往存在对特定应用场景考虑不足的问题,例如,难以有效地获取对话历史和回复候选之间的复杂语义匹配信息,没有对于对话者的一致性个性进行明确的长期记忆,缺乏对话相应的背景知识依托,难以建模多方对话中复杂的语句和对话者之间的交互等,这些都影响了最终回复选择的准确性。
因此,本文围绕基于深度学习的检索式对话系统,在多轮对话、个性化对话、融合背景知识对话和多方对话等方面开展研究工作,具体包括:
首先,研究了面向多轮对话的检索式对话系统。针对现有研究缺乏对对话历史与回复候选进行句级语义匹配的问题,提出了细粒度句级交互匹配回复选择模型,从对话历史中选择与回复候选最相关的信息,并对回复进行句级分解,将对话历史与回复候选中任意两个语句之间的句间距离先验信息融入到匹配过程;进一步提出了在预训练语言模型中融合说话人表征和领域自适应的回复选择模型预训练方法,实现了在预训练语言模型中体现说话人交替改变的这一对话属性,提升了预训练模型在对话领域的表征能力。以上研究在四个公开的多轮对话回复选择数据集上提升了回复选择的召回率,取得了当时的最优性能。
其次,研究了基于对话者画像的个性化对话系统。针对现有研究只关注回复者自身画像而忽略对话搭档画像这一问题,基于是否考虑画像和语境之间,以及画像和回复之间的交互,提出了四种基于对话者画像的个性化回复选择画像融合策略,并应用于三种不同类型的模型,该研究在一个公开的基于对话者画像的对话回复选择数据集上验证了回复者自身和对话搭档画像对于个性化回复选择的影响。另一方面,针对缺少预先定义的对话者画像所引起的个性化对话系统冷启动问题,提出了基于早期对话文本搜索近似画像的对话者画像检测方法,构建了一个对话者画像检测数据集,并验证了在对话者画像没有预先给定时,通过细粒度匹配方法检索近似的对话者画像的有效性。
再次,研究了融合背景知识的检索式对话系统。以直接建模背景知识和回复候选之间的语义匹配关系为目标,提出了双向交互匹配回复选择模型,同时进行对话历史和回复候选之间,以及背景知识和回复候选之间语义表征的交互匹配;针对对话历史和背景知识之间相互独立且存在冗余信息,同时单次交互也只能获取浅层匹配特征的问题,提出了基于背景知识过滤的迭代匹配回复选择模型,该模型预先建立对话历史和背景知识之间的交互感知机制,并对背景知识进行有效筛选,随后再通过迭代式交互匹配去获取对话历史和回复候选之间,以及背景知识和回复候选之间的深层匹配信息。以上研究在两个公开的融合背景知识的对话回复选择数据集上提升了回复选择的召回率,取得了当时的最优性能。
最后,研究了面向多方对话的检索式对话系统。多方对话中含有丰富的对话者之间、语句之间,以及对话者与语句之间的交互关系,同时多方对话涉及的说话人识别、接收者预测,以及回复选择等任务间也存在天然的互补关系。因此,本文提出了基于多任务自监督学习的多方对话建模方法,围绕“谁对谁说了什么”这一多方对话中的核心问题,设计了多个自监督学习任务,实现了模型计算出语义更丰富的对话者表征和语句表征,加深了模型对多方对话的理解,增强了模型在多个下游任务的泛化性。以上研究在两个公开的多方对话数据集上提升了说话人识别、回复选择,以及接收者预测任务的准确率和召回率,取得了当时的最优性能。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2022.001698
{DOI}: 10.27517/d.cnki.gzkju.2022.001698
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于IPV6的校园信息问答系统设计与实现
{Author}: 李奕霖
{Tertiary Author}: 周艳平
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 校园信息问答;IPV6;知识库构建;文本相似度匹配
{Abstract}: 随着科技的突飞猛进,将人工智能融入教育全场景的应用日渐增多,“人工智能+教育”的产品应用有着很大的提升空间。校园信息问答系统是“人工智能+教育”的应用产品之一,用来服务于师生在海量信息中快速捕捉到自己所需要的答案,满足日常信息咨询需求。同时IPV6技术是大势所趋,本文实现了一个基于IPV6的校园信息问答系统,符合时代的发展方向,本课题具有广泛的研究价值和应用前景。本文将研究开发基于IPV6的校园信息问答系统,对其运用到的关键技术做了深入研究,主要工作如下:(1)针对校园信息自动构建知识库。获得校园问答对的基础是要有相关领域的数据信息,本文使用python语言结合爬虫技术爬取了校园数据信息,得到校园信息的源知识。然后使用“BERT+Uni LM”的方式构建Seq2Seq模型,实现端到端的从源知识中构建问答对,最终得到校园领域常见问题的问答知识库。通过实验证明,本文自动构建校园知识库的方法在实际应用中准确率较高,是高效可行的。(2)文本相似度匹配方法。提出一种基于孪生网络和字词向量结合的文本相似度匹配方法,采用字词向量结合的BERT+Wo BERT模型解决了传统模型难以关注到中文文本语义语法信息的问题,通过孪生网络和PCA算法探索多种融合方式以及降维降噪对相似度匹配结果的影响,然后通过Softmax进行二分类,最终在数据集上取得了较好的相似度匹配结果。(3)设计并实现一个基于IPV6的校园信息问答系统。基于本文研究成果,利用现有的开发工具和框架将其运用到问答系统中并实现可视化。使用Django框架开启服务实现在IPV6下的访问,开发了系统的前端界面、用户登录提问、后端匹配模型的调用以及数据库的增删改查等功能。测试与分析结果表明,基于自建的校园问答知识库,本文开发的校园问答系统运行稳定,在回答率和回答准确率上都得到了满意的效果。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2022.000660
{DOI}: 10.27264/d.cnki.gqdhc.2022.000660
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 桥梁检测领域知识图谱问答关键技术研究
{Author}: 杨小霞
{Tertiary Author}: 杨建喜
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 桥梁检测;知识图谱;问答系统;BERT;层级交叉注意力机制
{Abstract}: 随着人工智能的迅速发展,以大数据知识工程、自然语言处理和深度神经网络等为基础的新型信息技术受到了国内外多个行业领域的密切关注,知识图谱作为大数据知识工程的核心技术得到广泛应用,其下游任务知识图谱问答也已在多个行业领域进行了有益探索。目前,桥梁工程领域信息化建设正处于起步阶段,桥梁管理养护过程中也已积累了大规模的桥梁检测数据,为桥梁管养的数字化发展奠定了数据基础。结合知识图谱和智能问答关键技术,开展桥梁检测领域知识图谱构建和知识图谱问答研究,对辅助桥梁管理养护,加速桥梁工程信息化建设具有重要意义和深远影响。因此,针对桥梁管养实际业务场景中的交互式细粒度知识问答服务不足问题,本文开展了桥梁检测领域知识图谱问答关键技术研究。(1)针对桥梁检测领域知识图谱和问答语料缺乏问题,提出了一种适应该领域特性的知识图谱及问答语料构建方法技术路线。首先,采用OWL本体语言对该领域概念、属性及公理约束进行了形式化语义建模。然后,采用多任务联合学习模型对细粒度信息进行抽取,并将融合后的实例数据存储在Neo4j图数据库中,实现知识图谱化表示。在此基础上,选择了该领域知识图谱中154座桥梁的25103个相关知识三元组,构建了一个包含桥梁基本信息、损伤病害、技术状况等问题类型的桥梁检测知识图谱问答语料库,初步满足了桥梁检测知识图谱问答任务的实验数据需求。所提联合学习模型在桥梁检测领域命名实体识别、关系抽取任务中的F1值分别为93.28%、74.00%。(2)面向桥梁检测这一限定问题域场景下的实际问答需求,提出了一种基于问题分类的模板匹配式桥梁检测知识图谱问答方法。该方法选用BERT模型进行字符级嵌入,采用朴素贝叶斯分类算法进行问题分类。根据抽取到的主题实体对问题分类后所匹配到的问题模板进行实例化,并生成相对应的Cypher结构化查询。最终以自然语言短文本形式返回问题答案,实现桥梁检测领域细粒度结构化信息的交互式问答。实验结果表明,基于问题分类的模板匹配式知识图谱问答方法能够较好地回答细粒度桥梁检测问题,问题模板匹配的精确率、召回率和F1值分别为87.16%、76.70%和81.60%。(3)针对桥梁检测问句向量化表征与知识三元组嵌入的语义相似度计算问题,提出了一种融合BERT和层级交叉注意力机制的桥梁检测知识图谱问答模型。首先,BERT预训练语言模型和静态领域词典用作桥梁检测问答对的嵌入层,以提取多粒度特征。其次,使用Bi LSTM神经网络深度提取问题的上下文特征以找到主题实体。最后,层级交叉注意力机制实现了桥梁检测问句和知识三元组之间的信息交互,并从浅层词汇和深层语义两个维度计算问题和候选答案间的语义相似度。所提模型在NLPCC问答数据集和桥梁检测问答语料上都取得了优异的性能,其0)(62)0)1值分别为84.25%、86.95%。综上所述,以桥梁智能化管养为问题导向,结合知识图谱与智能问答技术,构建了桥梁检测领域知识图谱和问答语料。以此作为数据支撑,分别提出了适应于桥梁检测领域的模板匹配式知识图谱问答方法和信息检索式知识图谱问答模型。同时解决了桥梁检测问句的结构化查询转化问题以及问答对语义相似度计算问题,达到了预期目标。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2022.000534
{DOI}: 10.27671/d.cnki.gcjtc.2022.000534
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地缘政治风险对能源价格波动的影响研究
{Author}: 覃韵
{Tertiary Author}: 洪开荣
{Publisher}: 中南大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 地缘政治风险;能源价格波动;能源收益率;能源波动率;分位数回归模型;分位数对分位数模型;分位数因果检验
{Abstract}: 能源是全球经济增长的源动力,是保障国民经济和社会发展的重要战略资源。鉴于能源在经济发展中的地位,能源价格稳定已成为许多国家密切关注的关键问题。然而,由于能源具有稀缺性、重要战略性、供需空间分离和需求价格弹性小等特点,能源价格极易受到地缘政治风险的影响。地缘政治风险被认为是一种极端风险,会降低能源生产国的产量,造成能源供应不足,引起未来能源供需产生预期差异,影响能源价格波动。同时,随着能源的金融属性不断加深,地缘政治风险成为了投资决策最重要的决定因素之一,会引起投资者恐慌,造成非理性行为出现,最终影响能源价格波动。
为了探究地缘政治风险对能源(原油、天然气、取暖油)价格波动的影响,首先对于能源价格波动理论模型以及地缘政治风险的溢出效应进行理论研究,从理论上分析了地缘政治风险对能源价格波动的直接效应和间接传导;并从能源收益率和波动率层面来研究能源价格波动,采用QR模型、QQ模型以及分位数因果检验,实证分析了不同市场条件和不同风险水平下,地缘政治风险对能源收益率和波动率的非对称性影响,不同类别地缘政治风险对能源收益率和波动率的异质性影响,以及地缘政治风险影响能源收益率和波动率的传导机制,最终找到地缘政治风险影响下能源价格稳定的实现路径。
主要的研究结论包括:(1)不同的市场条件和风险水平下,地缘政治风险对能源收益率的影响存在非对称性。地缘政治风险对原油收益率具有抑制作用,并主要集中在熊市;高或低风险水平下,地缘政治风险会导致能源收益率出现极大或极小值。(2)不同的市场条件和风险水平下,地缘政治风险对能源波动率的影响具有非对称性。地缘政治风险对原油波动率有促进作用,并出现在所有市场之中;地缘政治风险对天然气波动率有抑制作用,并集中在正常市场和牛市;在牛市中,低水平的地缘政治风险会对能源波动率产生抑制作用,高水平的地缘政治风险则产生促进作用,且这些区域内存在极值。(3)不同类别的地缘政治风险对能源价格波动的影响存在异质性。地缘政治行为对原油收益率的抑制作用出现在熊市;而地缘政治威胁对原油波动率以及地缘政治行为对取暖油波动率有促进作用,且存在于不同市场之中;在熊市和牛市中,不同风险水平的地缘政治威胁和高水平的地缘政治行为对能源收益率和波动率的影响是不稳定的。(4)通过不同渠道,地缘政治风险的影响被传导到能源价格波动之中。在供需渠道下,地缘政治风险增加了能源收益率,并降低了能源波动率;在不确定性渠道下,地缘政治风险通过经济政策不确定性降低了取暖油波动率,通过市场不确定性增加了能源波动率,并导致原油和取暖油收益率产生变动;在金融市场渠道下,地缘政治风险通过利率增加了天然气波动率,通过汇率降低了原油和天然气的收益率以及波动率,通过黄金引起了能源收益率上升,并且,这些渠道的传导作用出现在不同市场条件下。
本文的主要贡献有:(1)鉴于原油、天然气和取暖油代表能源,而收益率和波动率反映价格波动,从能源收益率和波动率两个层面,系统分析了地缘政治风险对能源价格波动的整体影响。(2)将市场划分为熊市、正常市场和牛市,风险水平划分为低水平、中等水平和高水平,构建地缘政治风险影响能源价格波动的非线性框架,为深入探究地缘政治风险的影响,提供了新的思路与分析工具。(3)地缘政治风险通过不同传导渠道间接影响能源价格波动,依据地缘政治风险间接影响能源价格波动的传导机制分析,阐明了地缘政治风险是如何影响能源价格波动的,进一步加深了对于能源价格波动规律的认识。
图65幅,表76个,参考文献261篇
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2022.006144
{DOI}: 10.27661/d.cnki.gzhnu.2022.006144
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自回归语言模型框架下的钢琴音乐生成与相似度计算研究
{Author}: 张昕然
{Tertiary Author}: 俞峰;孙茂松
{Publisher}: 中央音乐学院
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 自回归语言模型;钢琴音乐生成;钢琴音乐相似度计算
{Abstract}: 近年来,音乐人工智能技术不断发展,基于语言模型的技术路线受到广泛关注,已成为本领域的研究重点。本文围绕自回归语言模型的两个典型应用,针对符号钢琴音乐的生成任务和相似度计算任务开展研究。首先,针对自回归语言模型生成任务的多样性采样问题开展研究。研究了退化样本的概率轨迹,提出基于高频词扰动提升多样性的技术路线,并提出了两种采样算法。第一,提出了四分位逆概率加权采样算法,通过四分位方式确定高频词集合,通过逆概率加权方式抑制高频词的概率;英文文本生成实验表明,所提出算法可以在不影响通顺性的情况下提升生成样本的多样性。第二,针对可控多样性生成问题,提出高频词随机扰动的采样算法,通过显式参数控制随机化扰动的范围,进而控制多样性提升的大小;围绕中文歌词生成问题验证了算法的性能,同时还提出基于中文分词的词表构建方案和中文歌词预训练语言模型;实验结果表明,通过控制高频词随机化的范围,可以实现对生成歌词多样性和新颖性的控制,实现可控多样性的歌词生成任务。搭建并部署了端到端的中文歌词生成系统。其次,针对带有演奏信息的符号钢琴音乐生成问题开展研究。针对音乐词表构建问题,提出了基于词表聚合的钢琴音乐词表构建方法。分析了钢琴音乐语言模型与自然语言模型的区别,针对钢琴音乐语言模型的特点提出了可控演奏信息的钢琴音乐生成方法,通过使用矢量参数对不同类型的演奏信息进行控制,实现了面向钢琴音乐演奏信息的可控生成。实验结果表明,所提出的方法能够弥补传统算法生成钢琴音乐多样性不足的问题,并实现对钢琴音乐演奏信息的控制。通过案例分析揭示了所提出方法对生成钢琴音乐风格的影响。再次,针对符号钢琴音乐相似度计算问题开展研究。以音乐序列表示与语言模型的嵌入校准作为技术路线,通过嵌入校准方法,从语言模型的音乐符号表示计算出音乐序列表示,并利用数据集的客观信息构建自动评测方案,寻找最优嵌入校准方法的组合。利用嵌入空间的结构指标和聚类实验对嵌入校准技术进行了分析。实验结果表明,该方法能在不依赖人工标注和模型修改的情况下大幅度提升符号钢琴音乐的相似度指标。通过嵌入空间的结构分析、聚类指标以及可视化结果揭示了嵌入校准技术对嵌入空间的影响,并通过谱例分析揭示了最优嵌入校准技术的内涵。
{URL}: https://link.cnki.net/doi/10.27669/d.cnki.gzhyc.2022.000027
{DOI}: 10.27669/d.cnki.gzhyc.2022.000027
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于中文医药知识图谱的智能问答方法研究
{Author}: 苗蕾
{Tertiary Author}: 姬红兵
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;健康医疗;问答系统;意图识别;语义相似度
{Abstract}: 随着计算机技术与信息检索技术的快速发展,互联网已成为人们获取医疗健康知识的主要途径之一,这些知识通常以非结构化或半结构化的形式存在,并且规模庞大、信息良莠不齐。利用传统搜索引擎难以有效获取所需的医学知识,从而制约了医学信息化的发展。因此,如何从海量数据中准确并自动化地提取出用户所需的医学知识成为了医疗信息化领域的研究热点。问答系统是信息检索系统的一种高级形式,它能减少用户在信息检索中的时间消耗,且检索准确度高于传统搜索引擎。近年来,由于知识图谱在知识挖掘、知识分析、知识间关系描述等方面具有天然优势,基于知识图谱的问答系统已成为主流的智能问答方法。然而,当前的中文医药知识图谱存在数量少、规模小、质量低等问题,并且基于中文医药知识图谱的问答方法鲜有研究,急需利用获取的可靠数据构建高质量的图谱,提出并实现基于图谱的问答技术,以满足用户在医疗健康方面的多样化需求。
本文主要围绕基于中文医药知识图谱的问答方法进行研究,针对中文医药知识图谱不易构建、基于知识图谱的问答系统在多意图场景下问答准确率较低以及问答系统的扩展性欠佳等问题,给出了具体的解决方案。主要研究内容如下:
(1)针对现有中文医药知识图谱多为手动构建,更新困难,缺乏新型冠状病毒肺炎等新型疾病医药知识的问题,提出了一种中文医药知识图谱的自动化构建方法。该方法采用自底向上的设计方式,首先,利用爬虫技术自动采集国内垂直医药网站中的结构化和半结构化数据、新冠疫情的实时数据,以及相关医学权威报告中的非结构化数据,并对采集的所有数据进行清洗和人工纠错,制作了中文医药知识图谱数据集。然后,基于该数据集对医药领域的多源数据进行知识表示和融合,根据生成的三元组构建中文医药知识图谱。最后,基于neo4j图数据库实现了对中文医药知识图谱的存储、查询和更新。
(2)针对基于模板匹配的问答方法受限于预先设定好的规则与模板,难以正确理解用户意图,以及基于深度学习的问答系统无法识别单句中多个意图的问题,提出了一种基于意图识别和模板匹配的混合问答方法,包括多意图识别、问句解析以及答案生成三个阶段。在多意图识别阶段,提出了一种基于特征词匹配和BERT-text CNN的联合意图识别方法。实验结果表明,所提方法不仅解决了传统问答系统对规则和模板的依赖,同时解决了深度学习框架下的问答系统对单个句子中多个意图的识别问题,有效提高了问答准确率,在单意图和多意图场景下均有较好的效果。在问句解析和答案生成阶段,采用传统的模板匹配方法,从而在保证模型准确率的同时,提高了模型的整体效率。
(3)针对基于意图识别与模板匹配的混合问答方法需要预先设定好意图种类导致扩展性差,并且问答结果依赖特征词库质量和意图识别效果的问题,提出了一种基于语义相似度匹配的问答方法。该方法将复杂的问答任务转化为匹配检索任务,通过句子相似性得分精确匹配到意图,提高了模型的准确性和扩展性。在语义匹配的召回阶段,改进了传统的BM25检索算法,并将其与Bool算法结合进行粗粒度的召回;在语义匹配的排序阶段,使用Sim BERT模型作为编码器,根据句子中的深层语义信息进行细粒度的排序。实验结果表明,所提方法在提高单一匹配模型的准确率,以及保证模型召回率的同时,能够减少神经网络输入的参数量,提高模型的计算效率。
目前,垂直知识图谱构建流程尚无统一标准,本文提出的中文医药知识图谱自动化构建方法为构建垂直知识图谱提供了一种新的解决思路。基于中文医药知识图谱实现的智能问答,可以加强人们对新冠肺炎等疾病的了解和预防,辅助医生做出更科学的诊断,有效简化流程,提升效率。这在当今我国正在加紧实施健康中国战略的时代背景下,具有重要的意义和价值。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.000406
{DOI}: 10.27389/d.cnki.gxadu.2022.000406
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习对新冠疫情初期微博评论的情绪分类研究
{Author}: 林岩
{Tertiary Author}: 李维德
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;新型冠状病毒;微博评论;情感分类;迁移学习;BERT模型;双向LSTM模型;注意力机制
{Abstract}: 情感分类是自然语言处理领域较为热门的任务之一,而对舆论相关话题的评论内容进行情感分析有利于把控舆论走向、维护社会稳定。本文在新型冠状病毒疫情的背景下,使用在新浪微博平台上抓取的2020年1月1日至2020年2月20日新冠疫情爆发初期共10万条评论数据进行情感分类。在数据处理阶段,对数据进行了重新人工标注,并使用多种数据清洗方法对数据进行去噪;在模型搭建部分,综合使用迁移学习方法,基于多个深度神经网络模型搭建了一个分类效果较好的情感分类模型。该模型使用动态预训练模型Bidirectional Encoder Representations from Transformers(BERT)进行初步特征提取以及词向量编码,并在此基础上使用双向Long-Short Term Memory(LSTM)模型和注意力机制模型提取文本的上下文信息以及重要信息,将其输出向量与BERT模型classification(cls)位置的输出向量拼接后输入全连接层进行情感分类。实验结果显示,相较于基准模型BERT拼接Convolutional Neural Networks for Text(Text CNN)和BERT拼接Deep Pyramid Convolutional Neural Networks(DPCNN),本文搭建的模型在新冠疫情初期的微博评论数据上的情感分类准确率达到85.54%,Macro-F1达到0.8543,对与新冠疫情相关的微博评论数据有较好的情感特征提取能力,并且适合于三分类情感任务。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.000638
{DOI}: 10.27204/d.cnki.glzhu.2022.000638
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于核心素养的高中函数单调性教学的实践研究
{Author}: 严爽安
{Tertiary Author}: 崔利宏
{Publisher}: 辽宁师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 数学核心素养;函数单调性;数学抽象;逻辑推理;教学设计
{Abstract}: 随着我国基础教育改革的不断深入,新课程标准更注重强调培养学生学科核心素养的重要性。2017年国家颁布的新课程标准中,数学学科核心素养正式出现在其中,并且对高中函数单调性教学提出了更高更全面的要求,要求教师在数学教学中提升学生对函数单调性的学习能力,以及在教学过程中对学生的学科核心素养进行全方位的培养。本文首先采用文献研究法,查阅了大量相关的参考文献,分析了数学核心素养和函数单调性教学的研究现状,然后对函数单调性教学的相关要素进行研究,对函数单调性教材内容的编排和学生对于函数单调性学习内容具备的知识基础和思维基础进行了分析,最后得到数学学科核心素养在函数单调性教学具体体现为:直观想象、数学抽象、逻辑推理和数学运算。其次采用行动研究法,在高中课程标准和教学用书等指导下,以及实习期间在学校的课堂教学观摩,并与学校的数学教师交流教学经验,研究得到如何在函数单调性教学中培养学科核心素养的教学策略,并以此为依据展开教学设计。最后采用实验研究法,笔者选取了大连市某高级中学高一年级的学生作为实验对象,教授内容为高中数学人教B版必修一3.1.2节单调性的定义与证明,选取两个班采用不同的教学方式进行授课,并通过对数据进行统计分析,得到基于核心素养的教学方式比传统概念教学方式的教学效果更好,对学生的成绩有显著的提升。总之,高中数学教师要注重学科核心素养的培养,在函数单调性教学中考虑改变传统的概念教学方式,合理设置教学环节,在教学活动中体现出对学科核心素养的培养,加强学生对函数单调性学习内容的认识和掌握,不断提高学生对数学的认识和理解,提升学生的数学素养。
{URL}: https://link.cnki.net/doi/10.27212/d.cnki.glnsu.2022.000693
{DOI}: 10.27212/d.cnki.glnsu.2022.000693
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自然风景题材黑白木刻的形式语言研究
{Author}: 杨苑怡
{Tertiary Author}: 王军
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然风景题材;黑白木刻;形式语言
{Abstract}: 自然风景题材是美术创作中的重要题材之一,画家通过审美体验,对题材进行构思,寄情于景,能反映出人与自然环境的关系。自新中国成立后发展至今,我国的整个社会环境与自然环境出现了巨大的改变,为自然风景题材的黑白木刻版画的发展奠定了一定基础。自该时期以来,自然风景题材的黑白木刻版画多为歌颂大自然的变化为内容,主要从描绘社会主义新时期的美好生活,祖国的蓬勃发展以及大好河山面貌代替了抗日救亡时期的宣传教育作用,自然风景题材的黑白木刻版画作品见证祖国的大好河山风貌和祖国蒸蒸日上的发展。本文以建国后至2010年为研究背景,以自然风景题材的版画家、自然风景木刻版画作品为研究对象。第一章阐述黑白木刻版画与自然风景题材的黑白木刻版画的发展以及自然风景题材版画家群体的出现;第二章阐述自然风景题材的特征,从多维度的视觉空间表达和鲜明而强烈的自我主观表现进行分析;第三章分析代表性的自然风景题材的版画家并从意境美、自然美、形式美阐释自然风景题材的美学价值;第四章分析研究笔者的绘画创作,通过自身对自然风景题材的理解,用黑白木刻的表现形式来呈现自然风景题材的木刻版画,丰富该题材的形式语言,从而进一步丰富该题材的创作研究与社会认可度,提高自身的艺术素养。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.000055
{DOI}: 10.27036/d.cnki.ggxsu.2022.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的中文商品评论情感分析
{Author}: 章魁
{Tertiary Author}: 任福继;刘军
{Publisher}: 合肥工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 商品评论;情感分析;长短时记忆网络(LSTM);BERT;注意力机制
{Abstract}: 伴随着互联网技术的快速发展,网络购物已经逐渐成为了人们生活中不可或缺的一部分,国内网上购物平台的兴起也进一步导致中文商品评论文本数据的大量产生,这些评论文本数据中往往包含着大量的情感信息,因此如何分析应用这些信息无论对于企业、个人还是国家都有着重要的研究意义。本文在首先介绍了中文商品评论情感分析的研究背景和意义、国内外研究现状和相关的理论基础知识后,着重研究中文商品评论的情感分析。本文的主要研究工作包括如下:本文首先阐述了在以往的研究中,很多学者仅仅关注评论文本中词语与词语之间的上下文信息,而忽略对于有价值的中文商品评论文本句子与句子之间也存在的丰富的语义和上下文信息,因此本文提出了一种基于分层的双向长短时记忆神经网络(Hierarchical Bi-LSTM)和注意机制相结合的方法用于中文商品评论情感分析。其次本文基于Word2vec词嵌入技术无法解决词语的多义性等局限性的考虑,结合了目前流行的BERT预训练模型技术,提出了将BERT预训练模型用于中文文本的词向量表示,从而实现了在词向量技术上提升中文商品评论情感分析的性能。最后在本文的实验部分中,首先收集到用于实验的电商平台语料数据集作为本文的研究对象,经由预处理之后,使用BERT预训练语言模型处理评论文本获得词向量表示,然后应用Hierarchical Bi-LSTM模型分别从句子和单词中提取语义和上下文特征信息,再利用softmax获取到商品评论的三分类的情感分类结果。通过实验的结果表明,本文所提出的方法在中文商品评论的情感分析上,相比于传统的情感分析方法实现了更为理想的效果。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000504
{DOI}: 10.27101/d.cnki.ghfgu.2022.000504
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像描述生成算法研究
{Author}: 刘明星
{Tertiary Author}: 陈海光
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像描述;Transformer;双解码器;注意力机制;主题生成模型
{Abstract}: 图像描述(Image Captioning)任务是指计算机为给定输入的图像自动生成简洁合理的、符合人类阅读习惯的自然语言描述,即从图像中获取目标物体及各自之间的潜在关联,并使用人类能读懂的自然语言完整地表述出来,是计算机视觉和自然语言处理领域共同要面临的技术挑战。近年来,随着深度神经网络的兴起,图像描述生成技术发展迅速,图像描述生成模型已经历过多次变革,从早期将图像描述问题转为分割成多个领域的问题单独去研究到如今基于端到端的模型结构,深度神经网络的引入极大提升了模型的性能。当前图像描述生成的工作已经在新闻媒体、医疗辅助、智能教育等许多领域扮演着越来越重要的角色。本论文针对图像描述生成任务中的准确性问题以及生成描述文本的完整性问题开展了研究工作,总结当前图像描述生成实现工作的研究现状,并提出了基于Transformer模型和双解码器架构的图像描述生成方法,论文所做的主要工作如下:(1)采用基于视觉Transformer的图像特征提取模型,视觉Transformer模型是完全基于自注意力机制搭建的模型,近年来在计算机视觉领域崭露头角,基于视觉Transformer模型在目标检测、图像分割等多种图像基础任务中取得了比较优异的性能。因此本文选择利用视觉Transformer模型来提取图像的视觉特征;(2)采用了基于关键词的语言文本生成模型,即从描述文本中提取出关键词作为该模型的主题词输入,通过预训练语料库搭建背景网络,生成补充主题词信息,这样模型在生成描述文本时,就可以有更多的依赖信息,因此可以生成更全面地表达图像中的特征信息的描述文本;(3)基于(1)和(2),提出了基于双解码器的图像描述生成模型;在经典编码器-解码器架构中添加一个解码器,该解码器结构嵌入主题文本生成模型,从上一解码器中提取出关键词,并且添加了直接来自编码器中图像特征信息的注意力权重,融合两个解码器的输出作为对输入图像的最终描述文本。本论文在MSCOCO Caption2014 test上测试了模型的性能,通过对比实验证明了相较于基线模型和其他图像描述算法,基于视觉Transformer模型和双解码器架构的图像描述生成模型的自动评估指标(包括BLEU1,BLEU4,METEOR,CIDEr,ROUGE＿L,SPICE)可以保持和同类模型相近的性能,同时进行人工评分测试中,和人工标注的描述句子仅差0.01,证明本论文提出模型生成的描述文本保持了比较高的准确度;同时对于图像描述的全面性,本论文模型的解码器结构中嵌入了主题文本生成模型,可以生成较长的描述文本,对图像的描述也更全面完整。综上,实验结果符合论文预期。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2022.001408
{DOI}: 10.27312/d.cnki.gshsu.2022.001408
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 斯捷潘诺夫符号学思想的引进与诠释
{Author}: 王蕾
{Tertiary Author}: 李洪儒
{Publisher}: 黑龙江大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 斯捷潘诺夫;普通符号学;观念符号学;观念进化序列
{Abstract}: 斯捷潘诺夫的符号学思想涉及领域宽广,横跨普通符号学和专门符号学两大板块,具有丰富的研究价值。系统、深入引进与批判性诠释这座思想宝库,可以给我国符号学理论和应用提供新的经验和视角。斯捷潘诺夫的符号学思想主要由普通符号学、观念符号学、语言符号学和文艺符号学4部分构成。其中,普通符号学与观念符号学是本文的研究重点。研究由理论引进、诠释和批判性思考构成,将介绍、评述、批判性分析相结合,在引进其思想的同时,不仅系统梳理和思考其思想的特点,而且竭力发现其思想的可发展性。在理论的引进和诠释方面。斯捷潘诺夫普通符号学通过类比语言符号系统和其他符号系统,揭示抽象的语言关系在其他符号系统中的体现方式,并且据此形成一般符号学规律。研究采用结构主义符号学的术语体系,展现皮尔斯符号学体系式的泛符号性特征,同时还引入人这一认知主体。观念符号学是斯捷潘诺夫开创的一个文化符号学流派。其创新之处包括历时方法的运用、物质与精神的统一、符号学方法的引入以及“观念的进化符号性序列”概念等。观念承载的文化信息会随时代变迁而不断进化、累积,能指和所指这对术语对于厘清文化信息的传承、演变大有裨益。在批判性思考方面。斯捷潘诺夫的符号学思想具有明显的人类中心主义和语言中心论特征;将文化因素纳入符号学,实施系统、有效研究,则凸显出其积极的开拓精神,具有超时代性;当然,斯捷潘诺夫符号学思想并非完美无缺,依然存在着继续发展的空间。
{URL}: https://link.cnki.net/doi/10.27123/d.cnki.ghlju.2022.000024
{DOI}: 10.27123/d.cnki.ghlju.2022.000024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 数学自然语言处理中新定义的理解及其应用研究
{Author}: 闸明恺
{Tertiary Author}: 符红光
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 中文自然语言处理;初等数学;新定义问题;未登录词
{Abstract}: 自然语言处理(Natural Language Process,NLP)是一种让计算机尝试学会理解和处理人类口语或书面语的计算机技术。它与基于语言理解的语言学相关,在人工智能领域中占据了重要的地位,是众多科研学者研究的方向之一。中文初等数学自然语言处理作为中文NLP的一个垂直领域,一方面有着相当规范化的语言结构;另一方面属于中文名词与英文数学符号组合而成的中英文混合语言,对文本解析的准确度有着严格的要求。目前,初等数学中基于新的定义构造新词的新定义问题已成为教学的重点和难点。而且在数学文本中,有些词语可能并不在规范的数学词库中。在自然语言处理中,上述两种词语统称为新定义的未登录词。新定义的未登录词因为属于词库之外的词语,具有新的含义,对其的自然语言处理比一般NLP的实现难度更大。所以,如何在初等数学领域中完成新定义的理解及其应用研究,是本文的主要目的。本文研究内容主要包括以下两点:1.基于初等数学文本中英文混合的特点,本文采用实体二元组和关系三元组的知识表示方法,利用知识图谱与哈工大的LTP模型实现了一个自然语言处理模型Math NER。在新定义问题方面,采用了“看找代解”四步法设计了新定义解析模块接口来理解和解决新定义问题。最终的Math NER模型可以实现包含新定义问题在内的初等数学文本的自然语言理解,具有解析时间短、纠错性良好的特点,在有关的新定义测试集上获得了83.3%的前端理解准确率和64.8%的后端解题分值,且第三方测试中解决包含新定义问题的压轴数列题的效果比起原项目提升了100%。2.在发现未登录词方面,本文设计了一种基于深度学习的序列标注模型Math Seq和基于文本的信息熵原理的无监督模型Word Extract。两个模型可以主动地发现未登录词以达到扩充词库的目的,具有召回率高和可迁移性强的特点,在有关数据集上分别获取了785个和1280个未登录词。同时本文将Math Seq模型与Math NER模型进行了融合,在新定义测试集中发现了35.7%的未登录词以及报告了70%的错误分词,进一步提升了MathNER模型的泛化能力和解析效果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000579
{DOI}: 10.27005/d.cnki.gdzku.2022.000579
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的实体关系补全方法研究及应用
{Author}: 孙朝阳
{Tertiary Author}: 符红光
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;知识图谱补全;知识表示;初等数学
{Abstract}: 随着互联网技术的迭代更新,越来越多的数据被存储于云服务器和个人终端设备上,不论是图片、视频、音频或是文本数据都是非结构化的,因此它们不能很好的被计算机识别或使用。知识图谱以结构化的形式保存数据,让计算机可以有效地应用这些数据,目前知识图谱在搜索引擎、问答系统、知识推理等领域已经成为了不可或缺的技术。但是知识图谱的构建与维护是一个漫长的工作,需要相关领域内的专家们不断地完善。因此知识图谱补全成为该领域的热门研究方向,它致力于预测缺失的实体与关系,自动完善知识图谱的结构,使其在下游应用中更好的发挥作用。它可以减少大量的人工标注工作,是现在知识图谱构建里一项重要的技术。本文基于初等数学自然语言理解系统,该系统的工作是将非结构化的数学题目理解为结构化的三元组表示。此系统因为设计以及实现上的限制导致了此过程存在知识表示上的缺失问题,因此,本文针对这些问题提出了两种知识图谱补全方法,目的是完善该系统对数学文本题目的知识表示。综上所述,本文的工作主要包含以下几个方面:(1)分析了初等数学自然语言理解系统中存在的知识表示缺失问题,主要存在两方面的知识无法抽取,第一个是文本题目中未提及的隐含实体无法抽取,第二个是关系标注数据集规模以及相似度阈值过高导致的正确关系无法被抽取。(2)提出了基于规则的实体自动补全方法,主要针对隐含实体进行补全。定义了实体补全规则的标准,设计了一个根据规则进行实体补全的框架,实现了对规则的解析以及三元组的自动生成。(3)提出了基于深度学习的关系自动补全方法,主要针对缺失的关系进行补全。设计并训练了一个深度学习模型,在该模型中,引入外部的实体嵌入向量增强实体表示。使用标注好的题目三元组样本训练模型,并将训练好的模型应用于数学知识图谱的补全任务中。(4)构建了融合实体自动补全方法与关系自动补全方法的知识图谱补全模块,应用于初等数学自然语言理解系统中,分别测试了两种补全方法补全的三元组正确率,其中实体自动补全方法的正确率在93%左右,关系自动补全方法的正确率在75%左右,该模块使整体系统的解题通过率提高了30%左右。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.002303
{DOI}: 10.27005/d.cnki.gdzku.2022.002303
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识库的多模态问答任务构建与算法研究
{Author}: 雷越城
{Tertiary Author}: 任亚洲
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识库构建;多模态知识库问答;动作序列规划;动作序列预测;深度学习
{Abstract}: 将智能代理植入到智能设备中,从而辅助人类完成日常活动的思路,逐渐成为许多科研工作者和研发公司竞相角逐的热门领域。智能代理的核心是要以知识库为“大脑”,以智能系统为“躯体”,当智能代理运作的时候,通过“大脑”的思考以后,去驱动“躯体”执行相应的动作。因此,要让智能体充分发挥作用,要从知识库和智能系统两方面同时研究。虽然以自然语言为基础的传统知识库已经相对成熟,但是人类日常生活的世界是非常复杂的,仅仅使用文本语言信息,很难描述完整的人类生活,所以逐渐出现了把视觉,语音等信息融入传统知识库中,形成了多模态知识库的研究思路。本文基于Charades日常活动数据集,借鉴已有研究工作的思想,继续对多模态知识库进行扩展,并设计相应的智能问答任务和算法,去验证和解释知识库的有效性。文本的主要贡献和创新点可以归纳为以下两部分:本文创新性地将高质量活动意图添加到多模态知识库中,用于改进多模态智能问答任务。已有使用Charades数据集构建的多模态知识库HD-MKB,仅仅使用算法自动抽取了动作流序列,其中存在不少视频的动作流序列不正确的情况。因此本文利用亚马逊AMT平台进行知识众包去修正不正确的动作流序列。此外考虑到完整视频中人物的意图对于智能设备辅助老人完成一系列动作的指引作用,通过招募高水平人类专家对数据集中的视频进行意图标注,并将人物的意图作为知识存放到多模态知识库中,形成知识库HD-MKB2。最后针对本文构建的智能问答任务,通过众包对测试集的标准答案进行标注,将结果用于问答任务测试集的构建。本文大胆尝试,针对上述构建的多模态知识库,设计了回答未来动作序列的智能问答任务,其任务形式为给定部分初始视频片段和人物的意图,要求问答系统基于知识库回答视频中人物未来的动作序列,问答形式分别为单选和多选,选项由一个原始视频的动作序列和五个由对抗匹配算法生成的干扰动作序列构成。接着根据测试集的标注结果,构建基准测试集。最后设计了基于生成的两种基线模型:2StagePlanning和Forecasting,通过实验对比在是否使用知识库情况下,问答系统的效果表现,解释和证明基于知识库的多模态智能问答方法的有效性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004157
{DOI}: 10.27005/d.cnki.gdzku.2022.004157
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的时间序列数据异常检测方法的研究
{Author}: 张宁
{Tertiary Author}: 袁杰
{Publisher}: 中央民族大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;时间序列异常检测;掩蔽模型;自编码器
{Abstract}: 随着数字化的持续发展,各行各业都积累了大量的数据,对这些数据的有效利用可以带来价值,其中时间序列作为数据的一种表现形式而广泛存在,如企业为了提供稳定服务或者安全原因而监控和收集的各种性能指标数据。时间序列异常检测作为数据序列分析的一个任务也得到了大量关注,如企业智能化运维系统能力中就包含异常检测这一关键组成部分,并且随着深度学习技术的发展,更多的数据加上更强大的模型,都为时间序列异常检测带来了更好的表现。虽然深度学习技术的应用促进了时间序列异常检测的发展,但目前的研究仍然存在一些难点与不足。时间序列异常检测问题的困难本质上是时间序列数据本身的复杂性与多样性造成的,如时间序列数据的时序依赖性、类别不均衡、难以有效获取标签等问题。在实际的异常检测应用中,异常出现的比例很小,因此大多数研究都聚焦于学习数据的正常模式,其中常用的就是基于预测的模型。针对上述问题,本文通过借鉴自然语言处理和计算机视觉领域最新的掩蔽建模方法,提出了一种掩蔽卷积自编码器模型,该模型属于自监督表示学习范式。不同于基于预测的模型,它通过对输入数据进行随机掩蔽然后仅对掩蔽部分进行重建来学习数据的正常模式。本文通过在两个公共数据集的实验证明,本文提出的模型具备较好的检测效果,并且引入的时间信息编码也在一定程度上提高了模型的性能,同时发现该模型即使在掩蔽率很高的情况下依然能够保持性能,甚至有所提高,进一步证明了模型的有效性。
{URL}: https://link.cnki.net/doi/10.27667/d.cnki.gzymu.2022.000247
{DOI}: 10.27667/d.cnki.gzymu.2022.000247
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向文本的方面级情感分类研究及系统实现
{Author}: 李佳洲
{Tertiary Author}: 刘瑶
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 方面级情感分类;小样本;隐式情感;有监督对比学习;提示学习
{Abstract}: 互联网的快速发展带来了大量的文本信息,分析文本中的情感信息,对舆情监控和电子商务上有重要意义。传统的情感分类只能得到文本整体的情感倾向,无法探究背后的情感对象和原因。方面级情感分类,可以更细致地分析文本在不同方面的情感倾向,从而提取出更准确和更细粒度的文本情感倾向。本论文针对小样本、跨方面和隐式情感识别场景下的情感分类需要,提出了一种基于多阶段训练的方面级情感分类框架,在该框架内设计了两个新的预训练任务,并分别采用推断模式和提示学习技术对分类模型进行了训练,从而提高了模型在不同场景下预测的准确性和有效性。本论文的主要研究内容如下:(1)利用神经网络预训练思想,设计了基于情感词掩码和基于有监督对比学习两个预训练阶段。情感词掩码预训练,加强了文本特征中的情感属性的识别,提高了模型对隐式情感的识别能力。有监督对比学习训练,能够让模型学习到方面词的标签描述和文本之间的关系,让模型不再局限于特定的方面,另外模型只需要少量样本就能学习到方面词和文本的关系,满足了小样本和跨方面场景下的识别需要。(2)为了提高分类模型的准确性,设计了两种训练调优阶段,并在此基础使用了两种分类模型和其融合模型BERT-MERGE。基于推断模式的分类模型BERT-NLI将方面级情感分类任务,转化为推断标签描述和文本语义是否一致的任务,结合之前的有监督对比学习预训练,能够提高模型在小样本场景下的分类能力。基于提示学习的分类模型BERT-LM通过构造提示模板,将方面级情感分类任务转化为掩码词预测任务,结合之前的情感掩码词预训练,不仅能适用于小样本场景,还提高了模型对隐式情感的识别能力。(3)设计了一个方面级情感分类系统,该系统集成了BERT-NLI和BERT-LM两个模型,实现了用户管理、评论文本的爬取、文本的方面级情感标注、方面级情感分类模型的训练、方面级情感分类模型的预测这五个主要功能模块。本论文通过对系统进行的功能与性能测试,验证了系统具有较好的可用性和健壮性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003189
{DOI}: 10.27005/d.cnki.gdzku.2022.003189
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的文本分类理论研究与分析
{Author}: 贺喜
{Tertiary Author}: 李建平
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 自然语言处理;文本分类;深度学习;注意力机制
{Abstract}: 作为NLP领域中基础同时又非常重要的任务,文本分类在用户画像、问答系统和机器翻译等领域有着非常广泛的使用场景。本文主要以深度学习方法为基础,通过深入分析注意力机制并从国内外研究现状出发,提出了两种文本分类模型。本文第一个模型提出了一种融合了固定权重合成注意力和随机初始化合成注意力的方法来获取丰富的文本表示,同时使用自适应的文本融合策略从这两种文本表示中抽取更有价值的特征信息,从而获得表达能力更强的文本表示。在传统注意力计算模块中,为了计算单词与单词之间的联系也就是注意力联系矩阵,通常的做法是计算单词之间耗时又占用很大内存的点积操作。本文使用的合成注意力矩阵使用简单的前馈层传播而不是点积操作,在这基础上又分别使用了固定权重合成注意力和随机初始化合成注意力这两种注意力联系矩阵的计算方法。固定权重合成注意力注意到了一致的全局语义信息,而随机初始化合成注意力则直接在计算量更少的基础上学习了基于任务同时跨实例的对齐方式。再使用自适应文本融合策略根据实际需要从两种文本表示中提取到了更关键的特征信息,得到了语义更加丰富的文本表示,对后续的文本分类模块起到了很大的帮助。通过与基准模型做对比试验表明该模型取得了很好的效果。本文第二个模型主要使用协作注意力机制来获取文本表示,同时使用Highway网络来帮助模型进行训练。传统的多头注意力计算将输入映射到不同高维子空间,分别计算注意力后统一拼接并合并这些注意力头的所有信息。然而这些多头注意力获取的文本信息很大程度上存在一定的冗余,通过使用协作注意力使得所有注意力头共享一部分权重矩阵,同时使得各个注意力头捕捉自身独有信息。使用混合矩阵使得整合注意力头的时候使其保持相对独立,而且这种做法的好处是可以通过调整混合矩阵维度来压缩或者扩展不同注意力头能够抽取到的矩阵信息。因为模型网络层次较深,所以使用Highway网络对训练中梯度回流困难的问题做了一定程度的优化。通过与基准模型做对比试验表明该模型取得了很好的效果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003697
{DOI}: 10.27005/d.cnki.gdzku.2022.003697
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向云ERP生态社区的知识库检索生成式智能问答方法研究
{Author}: 黄明彤
{Tertiary Author}: 廖伟智
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 云ERP生态社区;智能问答;知识库检索问答;生成式问答;文本分类
{Abstract}: 在云服务模式下,云ERP提供商、供应链上的各类用户群、开发者和软件开发商等主体、业务、数据及其关系等形成了云ERP生态圈。依托生态圈打造各方交流、开放、共享和合作的云ERP生态社区是云ERP发展的重要内容和趋势。其中,云ERP服务咨询是生态运行服务的关键环节,是生态社区所有个体和组织灵活、快捷的交流和分享的重要保障。但现有的咨询服务方式对用户专业知识要求高、检索效率低,不能及时、方便、有效的为各类客户提供服务。考虑到云ERP生态社区在时间和空间维度上的领域数据众多,因此结合大规模的客服会话数据和知识库,打造专业的智能客服成为迫切需求和主要任务。为此,本文以金蝶云ERP生态社区中的客服数据和知识库为数据支撑,重点研究面向生态社区在线咨询与技术服务的智能问答技术。主要内容如下:(1)针对单一流程不利于同类问题的快速解决的问题,研究并提出了面向云ERP生态社区的知识库检索生成式智能问答总体技术方案。(2)针对云ERP生态社区文本数据敏感性高、噪声大、专业性强等特点,完成了数据预处理,包括数据脱敏、清洗去噪、分词、去停用词、文本向量化等。(3)针对问题未有效分类且问答流程不易控制等问题,提出了基于BERTText CNN的问题分类控制方法,并通过在6个不同领域数据集上的实验,其中在云ERP领域问题分类上的F1值达97.35%,验证了该方法的有效性。(4)针对问题检索准确率和效率较低等问题,提出基于BERT-CRF-SMI的知识库检索问答方法。该方法包括基于BERT-CRF的问题实体识别模型和BERT-SMI问题属性相似度匹配模型。该方法可对基于知识库问题进行精准的回复,通过在中文知识库数据集上的实验,在知识库问答上的F1值达94.82%,验证了本方法的有效性。(5)针对难以回答知识库外问题和问答灵活性不高等问题,提出了基于GPT2的生成式问答模型,有效回答了知识库外问题并提高了问答灵活性,并在云ERP客服数据上进行了实验,其BLEU值达19.51%,验证了该方法的有效性。(6)为了验证和测试面向云ERP生态社区知识库检索生成式问答方法的可用性和交互性,本文设计和开发了智能问答工具系统,提问者可通过该工具系统实现问答咨询。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003699
{DOI}: 10.27005/d.cnki.gdzku.2022.003699
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多主体参与下共性技术合作研发机制研究
{Author}: 刘思漫
{Tertiary Author}: 郑月龙
{Publisher}: 重庆工商大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 共性技术;多主体合作;研发策略;博弈论
{Abstract}: 随着新一轮科技革命与产业变革蓬勃兴起,科技创新已成为世界各国谋取经济发展内生动力和产业竞争优势的关键抓手,各国纷纷加大对新技术的研发投资和战略布局。共性技术作为一种平台型的技术,可应用于同产业和跨产业的多个领域,为后续大量互补技术持续创新铺平道路。诸如人工智能、5G、大数据和区块链技术等关键共性技术的创新和突破,将助力各国在新一轮科技革命与产业变革大背景下占据前沿科技和新兴产业国际竞争的制高点。然而共性技术介于基础研究和应用开发之间,处于竞争前阶段,其研发过程具有投资周期性长、具有持续投入性、知识外溢性及收益水平不确定性等特征,研发主体往往难以单独完成共性技术研发工作。多主体合作研发有利于实现共性技术价值共创,整合优势资源、共担研发风险,成为解决我国关键共性技术研发难题的重要途径。为此,本文以“企业为主体、市场为导向、充分发挥政府支持作用”为指导,以“政产学研”多主体合作为组织形式,在共性技术供给-扩散全过程视角下探究多主体参与下的共性技术合作研发机制。首先通过构建博弈模型研究考虑多主体参与的共性技术研发模式比较与选择、各模式下主体收益与研发决策的影响因素及政府作用机理,揭示“政产学研”多主体合作研发的关键因素;通过解析关键影响因素,进一步以政产学研合研发作为共性技术研发主体,引入信息技术支持下研发努力水平可监测时费用支付结构,基于不同支付结构将多主体合作研发模式划分为过程导向与产出导向两种情形,研究信息技术支持下的共性技术多主体合作研发机制;同时把握共性技术供给-扩散各环节的不可分割性,在技术链视角下探讨纵向视角下共性技术上下游如何协调公平关切与领导权配置,以实现共性技术供给与扩散环节的纵向合作,优化共性技术上下游知识技术溢出、收益分配等问题。经过研究得出以下主要结论:(1)多主体合作研发的关键影响因素为学研方引入难度、主体间的协同度、上下游企业间的利益分配以及政府补贴支持,当学研方引入难度较小,学研方与企业间合作协同度、政府支持效率越大,及上下游企业间的利润分配系数较小时,“政产学研合作研发模式”是共性技术研发的最优选择模式;(2)政府对共性技术研发的知识技术支持效益(产出弹性增量)对共性技术合作研发模式选择及研发收益具有至关重要的影响,产出弹性增量较小时,产出导向情形下企业与学研方研发努力水平和研发收益大于过程导向情形,此时产出导向情形为合作研发的最优模式选择;若监控成本系数与学研方努力成本系数比值较大,则过程导向情形下研发努力水平和研发收益更高;(3)公平关切行为会降低共性技术研发整体效率与研发利润,公平关切水平越高,企业倾向于制定更高的价格;而不同权力结构会导致技术链上下游企业间不平等的利益分配,权力均衡模式下共性技术研发努力水平及技术链总利润均高于“领导-跟随”模式。最后,基于研究结论对研发主体及政府提出一些具有建设性和实用性的建议,为多主体参与下共性技术合作研发和政府支持提供理论依据和政策建议。
{URL}: https://link.cnki.net/doi/10.27713/d.cnki.gcqgs.2022.000318
{DOI}: 10.27713/d.cnki.gcqgs.2022.000318
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 问答系统中的文本检索技术研究
{Author}: 李春昂
{Tertiary Author}: 甘涛
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 问答系统;文本检索;语义匹配;FAQ问答系统
{Abstract}: 随着互联网和数字化技术的发展,网络上的信息越来越多、数据规模越来越大,传统的人工团队难以应对用户各种实时性的数据需求。为此智能问答系统应运而生,近年成为自然语言处理领域的一个研究热点。文本检索是智能问答系统的关键组成部分,其主要任务是搜索相似文本,如何进行高精度的语义匹配和相似文本检索是关键问题。本文通过对问答系统中的文本检索技术进行调研,分析了现有工作的不足,提出了相应的改进方法,论文的主要贡献如下:1.在语义匹配方面,现有模型通常基于当前输入样本建模,对其他维度信息挖掘不充分,导致在某些场景下语义匹配不准确。针对上述问题,本文提出了一种基于多维度信息融合的语义匹配模型。在信息提取层,该模型从词维度、语义维度和知识维度挖掘了与文本对相关的信息特征,在特征融合层,通过设计合适的特征融合方法来计算综合性的匹配相似度。实验结果验证了本文模型挖掘的信息特征的有效性,结果表明本文模型取得了较当前主流模型更好的性能,相对基线BERT模型的F1值提升了4%左右。2.在相似文本检索方面,针对检索阶段传统方法缺乏语义层面的信息以及排序阶段考虑信息维度不充分的问题,本文提出了一种基于多维度信息融合的相似文本检索算法。该算法在检索阶段结合了稀疏向量空间模型和密集检索,在排序阶段使用本文提出的基于多维度信息融合的语义匹配模型。实验结果验证了检索或排序阶段更好的性能会提升整个文本检索的准确率,结果表明本文算法的性能明显优于基线方法,相对基线方法BM25+BERT在P@1指标上提升了7%左右。3.设计并实现了一个面向银行业务的FAQ问答系统。该系统基于本文提出的相似文本检索算法,使用分布式微服务的架构搭建,具有人机对话和知识库管理等核心功能。通过接口测试验证了系统核心功能的可用性,通过压力测试验证了系统的可靠性。最终通过搭建前端页面演示了该系统能够实时、准确地回答用户的问题,能够简洁方便地管理知识库的数据。本文提出了基于多维度信息融合的语义匹配模型和相似文本检索算法,获得了比基线方法更优的性能。在此基础上设计和实现了一个面向银行业务的FAQ问答系统,并测试了系统的核心功能及稳定性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.001983
{DOI}: 10.27005/d.cnki.gdzku.2022.001983
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 多源短文本语义分析与立场检测方法设计与实现
{Author}: 李知微
{Tertiary Author}: 刘玓
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 立场检测;自然语言处理;DistilBERT模型;TextCNN
{Abstract}: 随着互联网社交论坛中在线内容的激增,立场检测作为情感分析的一个重要子问题,得到了越来越多的关注与应用。与此同时,针对立场检测的研究也面临了较多挑战,比如静态词嵌入技术对文本上下文语义理解不充分和模型速率较慢等问题。现有的立场检测模型往往只针对单一语言或单一来源的数据集展开研究,也很少有研究者考虑模型的训练及预测速率。为解决上述问题,本文提出了基于DBMPT的立场检测模型,实现了具有立场检测功能模块的论坛舆情分析系统。本文具体完成的工作如下:1.针对领域预训练任务与立场检测监督任务,分别构建出包含微博、推特和ENVY论坛三个不同来源的语料库,以验证DBMPT模型的多源支持性。其中,微博与推特的语料来源于立场检测公开数据集;ENVY论坛的语料来源于本文自建的ENVY论坛立场检测数据集,该数据集由ENVY论坛中的原始话题评论,经数据获取、数据清洗、制定立场倾向标注规范和人工标签标注四个阶段得到。2.提出基于Distil BERT-Multilingual-Pre Trained-Text CNN（简称DBMPT）的多源短文本立场检测模型,该模型支持语种不同的多个论坛的评论短文本进行立场检测。其中,短文本是指论坛中的评论,相较于新闻长文本,评论短文本更加口语化。DBMPT模型采用对BERT模型进行知识蒸馏后的Distil BERT模型作为算法基础;然后对Distil BERT的多语言拓展模型Distil BERT-Multilingual进行基于MLM任务的评论短文本领域预训练,得到DBMP动态词向量表征模型,解决了以往的立场检测模型只支持单一语言和对评论短文本领域语义理解能力不足的问题;其次,基于DBMP词表征模型添加Text CNN网络,提高了模型对词向量的特征抽取能力,一定程度上缩小了由于模型压缩造成的Distil BERT与BERT在（62）与准确率之间的差距。最终,在微博、推特和ENVY论坛这三组不同来源的立场检测数据集上分别进行了对比实验,证明了DBMPT立场检测模型的准确性、高效性和多源支持性。3.设计并实现了一个论坛舆情分析系统,包括对论坛中话题与用户数据的分析整合,以及目标话题下评论短文本的立场检测功能。其中,立场检测功能为本系统的核心功能模块,该模块的算法基础为DBMPT模型,DBMPT的高效性也在系统测试中得到了体现。本系统的论坛画像和立场检测模块均已应用于实际项目中。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.004271
{DOI}: 10.27005/d.cnki.gdzku.2022.004271
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识图谱的健康体检知识问答应用研究
{Author}: 吴丹
{Tertiary Author}: 周作建
{Publisher}: 南京中医药大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;健康体检;Neo4j图数据库;自动问答;自然语言处理
{Abstract}: 健康是生活中最受人们关注的问题之一。当前经济飞速发展,生活水平不断提高,各种不良的生活习惯也随之产生,这导致健康问题日益突出。定时进行健康体检有利于帮助了解情况,保持生命的健康活动。随着信息时代的到来,网络上的健康信息也越来越丰富,越来越多的人通过互联网搜索关心的健康问题。但目前网站上各类健康信息鱼龙混杂,主观性较强,缺乏一定的针对性,现有健康体检信息系统缺乏给用户提出个性化的中医健康服务方案;其次,人们对健康的追求也逐渐提高,已由疾病治疗转变治疗预防。知识图谱可以捕捉各个领域的零散及杂乱的数据并以接近于人类的认知思维对这些数据进行组织和理解,为网络上海量复杂的医疗数据提供管理和使用。基于此,本文设计并开发了基于知识图谱的健康体检知识问答系统,有助于患者在海量的健康信息中获取的个性化健康体检服务。本文主要研究内容如下:(1)基于自然语言处理技术构建健康体检知识图谱。本文基于某中医院体检中心的中医四诊数据,采用自顶向下的方法构建知识图谱。首先,采用自然语言处理技术对体检中心的中医四诊数据及网络爬取的中医症状、证候、方剂、药物等数据进行处理,采用基于RI+Word2vec+BiLSTM的方法作为命名实体识别算法识别健康体检相关数据的实体、实体之间的关系及实体包含的属性,然后将定义好的三元组存储在Neo4j图数据库中构建健康体检知识图谱,其中知识图谱包含7类实体,8种实体关系。(2)构建基于知识图谱的健康体检知识问答模型。首先对提问者的提问进行语义解析,使用SVM非线性支持向量机分类器对用户提出的问句进行分类,进行用户意图识别,通过问句分析让系统理解问句的语义,然后使用Neo4j图数据库自带的cypher语句查询功能去检索问句的答案。健康体检知识问答结果分别采用基于规则模板匹配与基于相似度匹配,并将精确率、召回率与F1值作为评价指标评估两种算法的效果,实验证明基于相似度匹配的知识问答效果最好。(3)设计并开发健康体检知识问答web网页,采用智能问答的形式实现健康体检后续服务。利用Flask框架作为web应用程序框架包装健康服务,通过浏览器访问的形式将健康体检知识问答服务可视化,从而实现人机交互的功能,为用户提供健康的相关知识问答服务。
{URL}: https://link.cnki.net/doi/10.27253/d.cnki.gnjzu.2022.000656
{DOI}: 10.27253/d.cnki.gnjzu.2022.000656
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于大规模预训练模型的情感分析问题研究
{Author}: 杜纯宁
{Tertiary Author}: 王敬宇
{Publisher}: 北京邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 情感分析;大规模预训练模型;领域适应;图卷积神经网络;对比学习
{Abstract}: 文本情感分析旨在利用信息技术挖掘文本背后所表达的情感与态度,是自然语言处理中重要的任务。情感分析能够分析文本背后对于商业商品、社会实践、机构、公共话题的看法与态度,有着重要的科研价值与社会价值。近年来,大规模预训练模型成为自然语言处理中的里程碑式创新,其能产生结合上下文的词表征,同时通过大规模无监督预训练存储了大量的语义知识。在情感分析相关的诸多任务中,大规模预训练模型均明显地提高了准确率,但仍然存在领域自适应、语法知识缺失、句子级文本表征不足等诸多问题。本文针对这些问题进行深入研究,提出了对应的创新性解决方案,论文的主要贡献如下:(1)基于大规模预训练模型的跨领域情感分析。大规模预训练模型是通过大量的、无标签的通用日常语言来预训练的,对于其他领域如文本评论数据领域具有领域知识差异。同时预训练模型也缺乏跨领域情感分析中所需的辨别领域知识的能力。为了解决这个问题,本工作提出了领域辨别预训练任务与情感增强预训练,通过无监督的后训练的过程,为大规模预训练模型融入领域感知与情感知识。结合对抗训练,本文的方法在多个数据集上取得研究当时一流水平。(2)基于图卷积神经网络的语法增强模型。细粒度情感分析要求对文本中的不同实体进行情感倾向性判断,很多情况下,同一句文本中含有多个目标实体,其对应的情感词也可能会有不同的极性。在这种情况下,语言的语法结构信息能够帮助模型定位实体所对应的情感词,具有重大意义。然而,现有的大规模预训练模型与预训练任务缺少对于语法知识的建模,为此,本工作提出了基于图卷积神经网络的语法增强模型,以字符作为节点,根据句法依存树转化成的邻接矩阵,为预训练模型引入了句法限制以及长距离依赖信息。除此之外,本文还设计了针对语法类型的门机制,实现了语法结构与类型的双感知。多个数据集上的实验表明本文方法达到了研究当时一流水平。(3)基于对比学习的句子级表征预训练。在现有的大规模预训练过程中,字符级别的预训练占主导地位,句子级别的预训练仅仅在语言连贯性层面,不足以生成具有内容辨别力的句子级特征。为了解决这一问题,本文根据用户点击的新闻文本数据,设计了用户行为协同规则,对于内容相似与不相似的正负样本,在句子级别上进行了对比学习预训练。特征可视化实验表明,经过大规模对比学习预训练后,预训练模型对于不同类型的新闻文本实现了很好的区分,产生了具有内容辨别力的句子表征。在新闻推荐任务中,本文提出的模型很好地对用户的新闻兴趣和情感倾向进行建模,达到了研究当时的一流水平。(4)基于胶囊网络的细粒度情感分析模型。细粒度情感分析旨在分析文本中不同实体目标的情感倾向,最大的挑战是多种不同情感倾向的实体目标混在同一句文本中,情感特征互相重叠与干扰。为了解决这一问题,本文引入了胶囊网络,通过向量化神经元输出以及聚类式的动态路由算法,实现了对于不同实体的情感特征的聚类。除此之外,本文为基于EM算法的动态路由过程引入了交叉注意力机制,构建了实体目标与主体文本之间的语义关系。多个数据集上的实验表明,我们的方法超过了基线模型,达到了研究当时的一流水平。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2022.000201
{DOI}: 10.26969/d.cnki.gbydu.2022.000201
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 小规模数据集下的半监督学习研究与应用
{Author}: 杨楠
{Tertiary Author}: 何钦铭
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 半监督学习;小规模数据;自然语言处理;主动学习
{Abstract}: 在实际应用中,训练智能模型所需要的标注数据往往具有很高的获取代价,而另一方面,现实场景中的无标注数据又可以轻而易举地获得。因此,仅使用少量标注数据并同时利用未标注数据的半监督学习具有重大的实际意义。相较于需要足量规模训练数据、侧重于处理复杂数据形式的深度学习半监督方法,小规模数据集下的半监督学习方法凭借其训练速度快、标注需求量低、适用范围广的特点,在现实诸多领域具有应用价值。例如许多在线试题平台的评测题库具有基于章节或知识点的初步划分,但随着其近些年如火如荼地发展,许多章节下的题目数量已然达到成百上千规模,臃肿的题库逐渐令选题的老师与做题的学生焦头烂额,急需进一步细分以提升平台用户的使用体验。而在本文的另一个应用,物联网下的智慧农业领域中,由于系统采集的数据维度较低、易于模型分析,使用小规模数据集下的半监督学习方法可以凭借更少的人力标注数据就地训练模型,取代目前普遍的直接调用专家资源库的智慧决策模式,做到因地制宜。针对半监督场景下标注数据不足的特性,本文通过调整训练集构建、对无标注数据进行样本判别以及融入主动学习策略的措施,对训练数据集进行动态优化,使其更好地用以机器学习的模型训练,并以此取得更好的半监督学习性能。与此同时,本文还将方法实际应用于在线教育以及智慧农业领域,进行了实验与测试。本文的主要贡献有:1)基于小规模数据场景下的标注训练数据以及无标注数据集,提出了一种基于动态训练集构建的半监督训练方法DDC,利用无标注数据信息对训练数据集进行优化,提升半监督学习性能;2)针对无标注数据样本的分类情况,在DDC的基础上,提出了一种引入样本判别机制的半监督训练方法SD-DDC,并将其应用于智慧农业领域,实现了智能灌溉技术因地制宜的智慧决策;3)针对在线教育领域的交互优势,在SD-DDC的基础上,提出了一种结合主动学习策略的半监督训练方法ASD-DDC,并将其应用于在线教育领域,实现了在少量的专家人力参与下,在线试题评测平台题库的题目子类自动划分流程。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.000068
{DOI}: 10.27461/d.cnki.gzjdx.2022.000068
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于文献相似性网络节点属性的论文重要性评价模型的构建及评估
{Author}: 潘现伟
{Tertiary Author}: 崔雷
{Publisher}: 中国医科大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 论文评价;文献相似性网络;复杂网络分析;Doc2Vec算法;机器学习
{Abstract}: 目的:科研评价和数据分析是卫生事业管理领域的重要研究方向之一,目前科研评价相关研究主要集中在科学学和信息学领域,从卫生事业管理角度进行的科研评价研究较少。学术论文评价是科研评价的基础,存在于多个科学研究活动中,比较重要的应用是在科研机构、团队和个体的科研绩效评价中,在科研资源分配、科研奖励、职务升迁等决策中同样占有重要地位,是科研管理和评价的刚需。传统的学术论文评价多采用引文计量的方式,但是引文表现的是论文的影响力,属于论文的外部特征,而且存在学科引用行为的差异、自引和他引的区分以及时间上的滞后性等问题,尤其通过期刊影响因子来代替单篇论文质量的做法,使得论文评价在实践中广受诟病。学术论文学术水平和创新贡献是科研管理和评价的重中之重,论文评价的本质应该是对论文内容价值的评价,由学术论文的自身内容和所处环境共同决定。论文内容是学术论文的根本属性,基于论文内容这一根本属性进行的评价才能客观真实地反映论文本身的价值。基于学术论文内容的评价研究分为定量评价和定性评价,而目前存在的基于内容的评价方法忽视了论文在整个科学体系中的作用,即个体对于整体的贡献程度,而论文重要性的评价更多的意义在于该论文在科学发展进程中所起的作用,因此应该寻找能够从科学整体性上揭示论文重要性的可行性方法,从系统科学的角度对学术论文的质量进行系统评价。文献网络的论文节点对于网络整个结构的意义与一篇论文对于整个学科结构的意义存在某种程度的契合,为我们从文献网络的角度评价一篇论文在整个学科中的重要性提供了新的思路,而通过构建文献网络,从网络的整体结构评价一篇论文的重要程度的相关研究还不够系统。本研究的目的是通过构建文献相似性网络,从网络的整体角度根据节点属性评价论文的重要性,从而构建论文重要性评价模型,探讨从文献网络的角度评价论文质量的可行性,以期为从系统科学的角度评价论文质量提供新的思路和方法。方法:根据ESI学科分类体系选择八个医学相关学科,下载Pub Med数据库和Web of Science数据库中的文献,形成八个学科文献数据集,根据文献是否被Faculty Opinions数据库收录将每个数据集中的文献标记为F1000论文和非F1000论文两个类别,以此作为数据集中重要论文和普通论文的分类标准。采用三种文献网络构建方法对八个学科文献数据集进行三种文献网络建模:利用R语言编程实现基于文献主题词和分类号层级关系的语义相似性文献网络的构建;利用Python编程语言实现基于Doc2Vec算法的内容相似性文献网络的构建;利用Bicomb2.0和VBA编程语言实现基于文献参考文献共现频次的文献耦合网络的构建。根据三种文献相似性网络的相似性分值分布情况,对语义相似性文献网络和内容相似性文献网络的阈值进行设定,语义相似性文献网络阈值设置为0、0.05、0.1、0.15、0.2、0.25、0.3、0.4和0.5,内容相似性文献网络阈值设置为0、0.1、0.2、0.3、0.4和0.5,文献耦合网络不设阈值的限制。基于复杂网络分析法,利用Gephi网络可视化软件对三种文献相似性网络的整体属性和节点属性进行计算,获得三种文献相似性网络的基本属性数据。在每个文献相似性网络中存在两种节点:F1000论文节点和非F1000论文节点,探讨这两类论文在节点属性上是否存在差异,哪些指标存在差异,对各个网络中的两类节点的属性进行了统计学差异性检验,检验方法为独立样本t检验,据此筛选出具有差异性的节点属性作为区分两类节点的评价指标。在基于筛选出的评价指标构建论文重要性评价模型的过程中,我们采用四种机器学习的算法,分别是贝叶斯分类算法、BP神经网络算法、懒惰分类算法和随机森林算法,对三种类型的文献相似性网络节点数据集进行论文重要性评价模型的构建。从论文重要性评价模型识别F1000论文和非F1000论文的精度、查准率、查全率、F-值、AUC、PRC面积等六个指标评价模型的性能优劣,探索适用于论文重要性评价的文献网络类型和机器学习算法。结果:利用三种文献网络构建算法计算八个学科文献数据集中的文献相似性,我们针对每个学科分别构建出语义相似性文献网络、内容相似性文献网络和文献耦合网络。三种文献相似性网络在相似性分值的分布形态和网络拓扑结构上存在差异,语义相似性文献网络和文献耦合网络的相似性分值存在较高比例的极低值,内容相似性文献网络的相似性分值呈正态分布,相似性分值在[0.198-0.26]区间的比例最高。语义相似性文献网络和内容相似性文献网络在阈值为0时的网络拓扑结构不清晰,所有节点紧紧连接成一个大的团簇,需要提高相似性分值的阈值使网络的拓扑结构更为清晰,文献耦合网络的网络拓扑结构比较清晰。通过设定阈值,最终我们得到八个学科不同阈值不同类型文献相似性网络共128个,以及这些网络的整体属性和节点属性。在F1000论文和非F1000论文两类节点的属性差异性t检验中,我们筛选出具有五个及以上差异性指标的有效网络38个,以及具有差异性的节点属性指标共十个:权威值、特征向量中心性、度、三角形数目、调和接近中心性、加权度、Page Rank、接近中心性、度变异系数和聚类系数。对三种文献网络的节点数据集进行机器学习构建出四种论文重要性评价模型。三种文献网络节点数据集中F1000论文比例非常低,在4%-7%之间。基于信息增益理论对不同类型文献网络的指标重要性进行排序,结果发现,三种类型文献网络的指标重要性排序情况不同,而Page Rank指标在三种类型文献相似性网络的重要节点识别中能力均较强,其次是度变异系数。四种论文评价模型的混淆矩阵中,贝叶斯分类器识别F1000论文数量最多,语义相似性文献网络、内容相似性文献网络和文献耦合网络识别出的F1000论文数量分别是143篇、41篇和81篇,查全率分别为0.126、0.129和0.345。BP神经网络算法识别出的F1000论文数量最少。从论文评价模型的评估指标来看,贝叶斯分类器、BP神经网络、KStar和随机森林算法训练的论文评价模型平均精度分别是88.08%、94.60%、92.66%和94.51%,在F1000分类中,三种类型文献相似性网络在四种算法上的AUC均值分别是0.633、0.679、0.636和0.673,PRC面积均值分别是0.092、0.118、0.097和0.122。从文献相似性网络的类型角度分析,内容相似性文献网络在F1000分类中精度最高,四种分类算法平均精度为94.60%,文献耦合网络在AUC和PRC面积两个指标中表现最好,四种分类算法平均AUC和平均PRC面积分别是0.707和0.145。结论:通过构建文献相似性网络,根据两类节点属性的统计学差异筛选评价论文重要性的指标,利用机器学习算法构建论文重要性评价模型的方法是可行的。同一类型文献相似性网络中,八个学科在网络结构和识别重要节点的能力上存在差异,文献相似性网络的平均距离越小,识别重要节点的能力越强。三种文献相似性网络构建的论文重要性评价模型性能差异较小,内容相似性文献网络和文献耦合网络构建的论文重要性评价模型性能略优于语义相似性文献网络。在构建论文重要性评价模型的机器学习算法上,随机森林算法表现最好,其次是BP神经网络算法,贝叶斯分类算法和KStar算法的表现略差,但是后两者在识别F1000论文的数量中表现较好。
{URL}: https://link.cnki.net/doi/10.27652/d.cnki.gzyku.2022.000302
{DOI}: 10.27652/d.cnki.gzyku.2022.000302
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于医学文献的抑郁症知识图谱构建及应用研究
{Author}: 张玉峰
{Tertiary Author}: 李泽鹏
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;抑郁症;药物发现;知识图谱嵌入;问答系统
{Abstract}: 抑郁症是一种常见的精神疾病,具有潜伏周期长、致残率高、死亡率高、复发率高等特点,在世界范围内构成了严重的健康问题。因此,越来越多的研究人员将目光转移到了抑郁症的研究上,并希望借助开放领域的医学知识来促进抑郁症的研究。而开放领域的医学知识最主要、最直观的来源就是生物医学文献。关于抑郁症的生物医学文献数量庞大且杂乱无章,这无疑会增加生物医学研究人员和医务工作者获取抑郁症相关知识的负担,从而阻碍了抑郁症的研究。知识图谱技术是实现机器认知智能和推动各行业智能化发展的关键技术,作为下一代人工智能的基石,知识图谱技术吸引了来自学术界和工业界的广泛关注。近年来,知识图谱领域涌现出了大量的理论与技术研究成果,将知识图谱技术与各行业进行深度融合已经成为了一个重要趋势。因此,本文将抑郁症与知识图谱相结合开展了研究工作,以期能够为抑郁症的病理研究及治疗方法的研究提供辅助作用。本文的研究内容主要分为三个部分,第一部分是抑郁症知识图谱的构建部分,该部分的工作是以医学网站PubMed上的抑郁症相关的生物医学文献为主要数据源,采用自底向上的方式进行了知识图谱的构建,并针对构建过程中涉及的知识获取、知识表示、知识融合、知识存储等关键技术展开了研究。最终,构建出了一个质量较高的带权重的抑郁症知识图谱——DKG,该知识图谱中包含136364个三元组,其中实体数量为37112,关系种类为30。第二部分为基于知识图谱嵌入的药物发现研究,这一部分在DKG的基础上,以知识图谱的结构信息和语义信息为出发点,将知识图谱嵌入方法应用到了药物发现领域的药物重定向任务中,并通过实验验证了该方法的有效性。第三部分为基于抑郁症知识图谱的智能问答系统设计与实现,该部分以DKG为数据支撑,采用基于模板的KBQA方法,然后进行了系统需求分析和设计,最终使用Java语言和SpringBoot框架实现了一个面向抑郁症的智能问答系统Depression automatic Q&A System,经过测试发现该问答系统能够有效地回答70%以上的问题。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.003338
{DOI}: 10.27204/d.cnki.glzhu.2022.003338
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的甘肃旅游评论文本的情感分析研究
{Author}: 丰利军
{Tertiary Author}: 刘岳巍
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 情感分析;深度学习;注意力机制;BiLSTM;ERNIE
{Abstract}: 随着通信技术的高速发展,互联网逐渐成为各种信息的载体。旅游门户网站也成为了游客发表旅游景点评论的主要平台,网站中的信息成为众多旅游者参考的重要依据。因此,如何从游客的评论中挖掘出关键信息,从而识别出情感倾向,以便提升游客服务质量,具有重要的意义。传统的情感分析方法过度依赖人工构建的情感词典和人工选择特征,这会花费巨大的人力物力。为了提高模型精度,提升工作效率,本文基于深度学习的方法在甘肃省的6个5A级景区的评论文本数据集上进行了情感分析研究。第一,利用BiLSTM模型融合注意力机制对该数据集进行情感分析,能够充分挖掘语句中的深层信息,并克服长期遗忘的问题。第二,利用中文预训练模型ERNIE融合BiLSTM模型对该数据集进行情感分析,能够获取到语句中的隐含信息,并能够进一步获取上下文的信息。实验结果表明,第一,相较于SVM、CNN等常用的机器学习模型,验证了BiLSTM模型融合注意力机制可以使得情感分析效果得到一定的提升。第二,相较于LSTM、BERT等加入对比的模型,本文构建的ERNIE-BiLSTM模型的情感分析效果得到了大幅提升。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.000619
{DOI}: 10.27204/d.cnki.glzhu.2022.000619
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数据挖掘的医疗分析系统研究
{Author}: 郑经纬
{Tertiary Author}: 余厉阳
{Publisher}: 杭州电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 知识图谱;命名实体识别;意图分类;疾病预测
{Abstract}: 随着社会的发展,人们的生活水平显著提高,对医疗健康越来越重视。同时,国家根据时代背景提出了智慧医疗政策。为了解决当今社会医疗资源分布不均,部分地区的人们就医困难等问题,本文以数据挖掘为基础,研究并实现了在线医疗分析平台,具备精简的前端用户交互界面。论文的主要工作包括:(1)构建一定规模的中文医学知识图谱。本文从开源知识图谱、在线医疗健康网站和少部分医学文献中提取疾病数据源,并对其进行融合得到最终的数据源,存入图形数据库中。在系统运行中定时读取待更新的疾病数据文件,自动扩充知识图谱规模。(2)创建用于模型训练的中文医疗问句。本文以图谱实体为基础,套用自定义的模板和数据增强策略生成大量问句,并结合从在线医疗健康网站获得的问答对得到大量中文医疗问句。将医疗问句打上标签得到命名实体识别数据集和意图分类数据集。意图分类数据集在各类别下均匀分布。(3)设计医疗分析系统的后台数据分析算法。本文使用语句分析算法和疾病预测算法结合的后台数据分析架构。在语句分析中,BERT模型作为嵌入层,训练BERT-LSTM-CRF和BERT-CNN模型分别作为命名实体识别和意图分类模型。实验证明在自建的数据集和公开数据集上,使用BERT为嵌入层的方式与其他主流模型对比,准确率最高。在疾病预测中,用融合模型来分析疾病特征,与其他模型对比准确率最高。(4)本文搭建了一套基于数据挖掘的在线医疗分析平台,数据库中有12337条疾病信息,包含常见的疾病。在实际场景下进行测试,本系统的召回率和准确率分别达到94.1%和75.3%,查询的响应时间均低于1s,基本满足用户获取医疗信息的需求。
{URL}: https://link.cnki.net/doi/10.27075/d.cnki.ghzdc.2022.000179
{DOI}: 10.27075/d.cnki.ghzdc.2022.000179
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于transformer和LSTM模型的汉语词义消歧
{Author}: 罗干
{Tertiary Author}: 张春祥
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 词义消歧;有监督;transformer模型;注意力机制;LSTM模型
{Abstract}: 词义消歧是自然语言处理领域的一个常见问题。词义消歧问题的目的是从歧义词的多个词义列表中识别正确的词义,消歧模型往往需要根据目标词汇的上下文来作为判断依据。词义消歧影响到自然语言处理中很多任务的性能,包括机器翻译、文章分类、情感分析、语音识别等。消岐准确率不高是自然语言处理领域急需解决的问题。为了解决消歧准确率较低的问题,本文使用transformer模型、LSTM模型、注意力机制来构建消歧网络。在用语料训练深度学习模型之前,必须对数据进行预处理。即使用向量化工具把语料转化为词向量,具体过程是把词汇映射到一个向量空间,具有相同上下文环境的词汇可能具有相近的向量距离。本文采用有监督的方式训练模型。文章首先介绍了词义消歧的应用背景和使用场景,以及国内外学者在消歧领域的研究趋势,阐述了他们提出的算法和框架。接着描述了语料的准备和预处理过程,包括向量化工具的使用、语料的分词、特征的标注等。详细分析了transformer模型处理词义消歧的原理,包括transformer模型的结构,数据在模型中的计算过程、分类过程等。然后介绍了序列化模型LSTM处理词义消歧的原理,对LSTM网络的各种门结构进行数学解析。同时介绍了改进版的结构BiLSTM。为了提高LSTM网络的消歧能力,本文在LSTM网络中引入了单层注意力机制。最后将transformer网络和LSTM网络融合来处理词义消歧,transformer是一种基于多头注意力机制的多层网络,可以看作是对单层注意力机制的扩展。融合模型可以充分利用LSTM网络的长短期依赖特性和transformer网络的并行处理机制。实验使用有标注的语料训练融合模型,模型通过对分类结果做损失计算,然后借助优化器对损失进行梯度下降来优化模型参数。最后使用测试语料测试优化好的模型。实验结果表明本文提出的消歧方法比单个深度学习模型更好。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2022.000437
{DOI}: 10.27063/d.cnki.ghlgu.2022.000437
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 地方政府债务风险评价与预警系统研究
{Author}: 张帅
{Tertiary Author}: 郑海超
{Publisher}: 西南财经大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 地方政府债务风险;债务风险多指标评价体系;债务风险指数;债务风险预警系统;机器学习
{Abstract}: 管理和预防地方政府债务风险是一个全球性话题。在中国,由于存在诸如隐性债务、债务积压、借新还旧、不同省份经济发展和财政表现不均衡等问题,使得我国的地方政府债务问题更加复杂。因此,在本文中,我们建立了一套能够全面有效地评价地方政府债务风险的多指标评价体系,帮助地方政府科学地评估自身债务状况,并建立了一套基于机器学习的地方政府债务风险预警系统,帮助地方政府提前判断债务风险可能的发展趋势,防患于未然。本文的主要内容和研究方法如下:(1)在本文中,我们发现过往研究中采用的地方政府债务风险评价指标债务率,并不能有效反映地方政府债务风险状况。因此,我们提出了一个全面且有效的债务风险多指标评价体系,从地方政府的债务状况和财政表现两个方面出发,进一步引入若干二级指标,通过标准化和指标融合,构建了地方政府债务风险指数。根据债务风险指数,我们界定了地方政府债务风险等级,进而对我国地方政府债务风险进行描述性统计和可视化操作。我们发现地方政府债务风险有显著的区域特征,内陆省份的中风险和高风险样本数量明显高于东部沿海省份及直辖市。除此之外,我们还发现了地方政府债务风险的发展有明显随时间增长的趋势,在2014年之后,这种增长趋势尤其明显,这说明管理和预防地方政府债务风险已经达到了刻不容缓的地步。我们进一步对本文的多指标评价体系进行有效性拓展分析,我们发现与传统评价指标债务率相比,本文构建的基于债务风险指数的地方政府债务风险多指标评价体系能够有效地识别更多的潜在高风险样本,并更早地对债务状况的恶化进行响应。(2)我们进一步引入机器学习来构建地方政府债务风险预警系统。我们将债务风险多指标评价体系中划定的风险等级作为预警系统的被解释变量,通过对过往文献的阅读,我们又从四个方面广泛收集债务风险预警系统所需的解释变量,即地方政府债务画像、地方政府财政画像、地方经济发展画像、国家宏观经济画像,并最终得到了共计38个解释变量。我们使用过去三年的解释变量对下一年的地方政府债务风险等级进行预测,在尝试了多种机器学习模型后,我们发现随机森林的预测表现最好,整体预测准确率达到了92%。在有效性拓展分析中,我们将本文构建的地方政府债务风险预警系统与基于传统评价指标所构建的债务风险预警系统进行比较,我们发现本文构建的预警系统有着更好的预测效果。(3)最后,我们计算随机森林的特征重要性评分,并展示和解读特征重要性最高的10个解释变量,进而根据这些模型贡献度高的风险因子对未来的地方政府债务风险管理有侧重地提出建议,帮助地方政府有针对性地解决债务问题。与此同时,我们还使用自然语言处理技术,对地方政府审计结果公告进行文本分析,通过对高频词汇的回溯,我们总结了地方政府债务管理、财政收支管理的共性问题和改善举措。基于以上研究内容,本文的主要贡献如下:(1)通过建立地方政府债务风险多指标评价体系,我们解决了传统评价指标债务率无法有效评估地方政府债务风险的问题。同时,我们为地方政府提供了一个全面有效的评价体系,来帮助地方政府科学地认识自身债务状况,进而更好地进行债务管理。(2)本文弥补了有关地方政府债务风险预警的研究缺口。通过创造性地引入机器学习来搭建预警系统,我们可以较为准确地预判未来地方政府的债务风险发展趋势,从而帮助地方政府及时地进行债务管理和风险管理,防患于未然。(3)本文利用机器学习的特征重要性,对债务风险因子进行横向比较,从而帮助地方政府有侧重地进行债务管理。与此同时,我们使用自然语言处理技术对地方政府审计报告进行文本分析,找出债务共性问题和改善举措。本文也是使用计算机技术来探索和解决经济问题的一次重要尝试,这为未来相关领域的学者提供了新的研究思路和工具。
{URL}: https://link.cnki.net/doi/10.27412/d.cnki.gxncu.2022.001938
{DOI}: 10.27412/d.cnki.gxncu.2022.001938
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于农业知识图谱的问答系统设计与研究
{Author}: 周辉
{Tertiary Author}: 朱轮
{Publisher}: 常州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 农业知识图谱;命名实体识别;问句分类;知识问答系统
{Abstract}: 随着农业现代化进程的推进,基于农业领域的知识服务体系成为农业信息化研究的热点问题。传统的信息获取方式以搜索引擎为主,搜索引擎返回大量网页链接,答案高度分散并且呈现多源异构的特点,无法迅速且准确地为农业相关工作者提供知识服务,用户体验感差。领域知识图谱的发展为特定领域内的知识问答提供了高质量的知识库基础。本文基于构建的农业知识图谱,对农业知识问答系统进行研究。主要研究内容如下:(1)构建农业领域知识图谱。本文首先使用Scrapy框架进行web农业文本数据的爬取,实现了农业领域数据的规模化采集。随后根据处理后数据的特征对知识图谱进行存储方案设计。最后利用Cypher语句将结构化的实体数据存入Neo4j知识图谱中,构建了数据质量高、覆盖面广、层次分明的农业领域知识图谱。(2)研究基于知识图谱的问答算法。基于已构建的知识图谱将本文的问答算法划分为命名实体识别和问句分类两个子任务。在实体关系类查询任务中,提出一种联合多特征的PBERT-BiLSTM-CRF模型对农业实体进行识别。集合农业文字的特殊性,添加字本身和部首偏旁的自定义联合多特征进行实验,最后与其他模型通过实验对比,结果表明,本文联合多特征的PBERT-BiLSTM-CRF模型在命名实体识别任务中有更好的效果。针对用户输入的症状类问题,本文使用了基于BiSLTM的自注意力分类模型。此模型给嵌入带来了一种简单的方式,可以看到句子的哪些特定部分被编码到嵌入中。通过与其他神经网络模型使用处理后的同一数据进行分类实验,结果表明,本文的问句分类模型能对用户的农业症状类问题进行准确的分类。问句分类扩大了问答系统的作用范围,提高了本文基于知识图谱的农业问答系统的价值。(3)设计并实现了基于知识图谱的i农-知识问答系统。通过系统需求分析、系统设计和系统测试,当用户输入农业领域病虫害以及农药相关的自然语言问题时,能够准确地给出相应的文本答案并且实现了知识图谱相应实体关系的可视化。
{URL}: https://link.cnki.net/doi/10.27739/d.cnki.gjsgy.2022.000365
{DOI}: 10.27739/d.cnki.gjsgy.2022.000365
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的中文语法纠错研究
{Author}: 冯雅
{Tertiary Author}: 黄继风
{Publisher}: 上海师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 语法纠错;Transformer;UniLM;BERT;注意力机制;预训练
{Abstract}: 在互联网时代,全世界每时每刻都要产生海量的文本数据,其中夹杂许多错误信息,如果不经过校对处理,这些错误数据将会对后续工作产生很大的影响。常规的人工校对已经无法跟上当今文本产生的速度,随着深度学习和自然语言处理技术的发展,学术界以及工业界纷纷开展文本纠错研究。文本错误可以分成浅层和深层,拼写错误和标点错误属于前者,语法错误属于后者。浅层错误可以通过规则和语言模型纠正,而传统的基于机器学习的校正方法面对深层错误的表现不尽人意,可见深层次的语法纠错是目前文本纠错技术的核心与难点。为此,目前文本纠错研究主要方向是基于深度学习,利用神经网络模型进行大规模语法纠错任务训练。本文首先介绍并总结了文本纠错研究现状,然后在现有的基于深度学习的中文文本自动纠错方法基础上,针对语法纠错,提出一种可行的中文语法纠错方法。本文的主要工作如下:(1)阐述了文本自动纠错技术的研究背景及意义,对中英文文本纠错研究进展进行分析和总结,并介绍了相关工作。(2)针对中文语法纠错,提出一种基于UniLM模型框架的纠错模型,以字为粒度,使用预训练模型参数初始化模型,在特定的语料训练下对模型进行微调训练(fine tune)。(3)搭建基于UniLM+CRF模型框架,实现中文文本语法错误标注任务,标注出文本中可能存在的语法错误。(4)搭建基于UniLM的seq2seq模型框架,实现中文文本语法纠错任务,对文本中可能存在的语法错误进行纠正。(5)对语料数据进行预处理,本文使用NLPCC 2018共享任务2—语法纠错(Grammatical Error Correction,GEC)提供的公开数据集,对其进行清洗、去噪、切分、去除停用词等操作,提高数据集的质量,帮助提高模型训练精度。(6)提出一种基于编辑操作集合的生成语法错误标注任务样本标签方法,为标注任务训练样本提供标签数据。其中,语法错误被分成:S(替换)、R(冗余)、M(缺失)、W(乱序)四类,按照类别对文本中的语法错误进行标注。(7)对实验结果进行分析与总结,采用Precision、Recall、F值指标评估模型性能,本文使用公开的Max Match(M2)记分器计算相应评估指标。
{URL}: https://link.cnki.net/doi/10.27312/d.cnki.gshsu.2022.000464
{DOI}: 10.27312/d.cnki.gshsu.2022.000464
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的格萨尔史诗命名实体识别关键技术研究
{Author}: 环科尤
{Tertiary Author}: 华却才让
{Publisher}: 青海师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;格萨尔史诗;特定领域命名实体识别;BERT
{Abstract}: 语言与文字是最善于发掘人类智慧的知识,是古老文明的典藏,也是当今自然语言处理和知识图谱的核心资源,而自然语言处理和知识图谱是人工智能得以实现的关键,是人工智能皇冠上的明珠。突破自然语言处理和知识图谱,会大幅推动人工智能在学术界和工业界等很多领域的广泛关注与应用。近年来,在大数据和深度学习的支撑下,自然语言处理和知识图谱技术迅猛发展,而人类迫切需要从这些浩如烟海的数据中快速准确地获取自己想要的信息或挖掘有价值的知识元素,因此命名实体识别技术应运而生。英、汉等语言的命名实体识别取得了丰厚成果,并得到了广泛应用。但藏文命名实体识别研究处于初步阶段,仅有十年历程,研究藏文命名实体识别对自动发现藏文的语言特点及用深度学习技术研究藏语言具有重要的理论意义和广泛的应用价值。针对藏文信息处理技术中现阶段需要亟待解决的特定领域命名实体识别问题,本文收集并整理了藏文文献中命名实体尤为丰富的格萨尔史诗作为实验语料,制定了格萨尔史诗命名实体标注规范,设计了格萨尔史诗命名实体识别可视化系统。在此基础上,本文围绕如何设计与实现用深度学习技术和史诗的语言特征相结合来提高藏文命名实体识别性能,逐步研究了基于深度学习的格萨尔史诗实体抽取方法、实体边界算法、以及《四部降魔史》实体自动标注及对比分析等四个方面。主要工作包括:(1)格萨尔史诗数据预处理针对藏文特定领域命名实体语料缺乏问题,分析了格萨尔史诗的语言特点,并选择格萨尔史诗作为语料数据,提出了以藏文音节为基本单元的数据预处理方法。为完善藏文命名实体规范化,研究了藏文命名实体的构成规律,并对格萨尔史诗命名实体的特征进行分析和归纳,制定了六种格萨尔史诗命名实体类型,包括人名、地名、组织机构名、神兽坐骑、武器铠甲和生活用具,该规范基本涵盖了格萨尔史诗中具有意义的实体或实体指代项的命名实体。(2)基于深度学习的格萨尔史诗命名实体识别技术针对格萨尔史诗的命名实体特征及其识别难点,设计了格萨尔史诗实体抽取的后处理任务和音节级别的实体边界识别算法,并采用了基于BERT模型的命名实体识别方法、基于双向LSTM-CRF模型的命名实体识别方法、以及为解决格萨尔史诗及藏文命名实体识别中存在的音节向量表征过于单一化问题,提出了融合BERT音节嵌入的双向LSTM-CRF方法,该方法能够从格萨尔史诗语料库中学习音节、词语、语言模型等不同层次的知识,有助于进行命名实体识别和分析。(3)实验分析与系统实现针对明确评价模型的识别性能,在同一数据集上试验了基于藏文音节为基本单元的经典的四种实体抽取模型,分别为TS-BILSTM-CRF、TS-BILSTM、以及BERT-BILSTM和BERT-BILSTM-CRF。经实验表明,双向LSTM-CRF和BERT藏文音节嵌入相结合后,比BERT-BILSTM提高了2.75个百分点、比TS-BILSTM-CRF提高了6.12个百分点、比TS-BILSTM提高了13.92个百分点。验证了融合BERT音节嵌入和双向LSTM-CRF的格萨尔史诗命名实体识别方法能够有效地提升识别性能且优于现有的实体识别模型。为更进一步展现实验的识别效果,设计了格萨尔史诗命名实体识别系统,系统的主要功能分别为句子级别的文本切分、音节级别的文本表示、命名实体识别、以及实体种类及次数统计分析。(4)实体自动标注及对比分析针对人工语料标注的耗时耗力问题,提出了根据训练数据特征来标注目标语料的实体自动标注方法,进而为体现格萨尔史诗的命名实体用词特征、分布分析和数量统计等特征,设计与实现了可视化系统进行实体对比分析,并引出格萨尔史诗的标点句与实体比率是3:1,涉及史诗的完整句子和实体数量相等,体现出格萨尔史诗是藏文文献中命名实体尤为丰富的数据集,从而归纳了格萨尔史诗在命名实体识别层面的不同之处以及演变规律,展现了命名实体是史诗的魅力之一。总之,本文首次开展了藏文特定领域命名实体识别的关键技术的研究工作,其中针对藏文命名实体识别面临的挑战和格萨尔史诗的特点,深入研究了格萨尔史诗命名实体语料库构建、实体获取、类型分类、实体边界算法、可视化系统实现、实体自动标注与对比分析等。在研究中取得了有意义的结论和研究成果,使得格萨尔史诗命名实体识别的性能达到可用水平,为藏文上游任务提供了基础支撑服务。希望本研究能够对藏文自然语言处理和知识图谱领域有所裨益。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2022.000638
{DOI}: 10.27778/d.cnki.gqhzy.2022.000638
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于预训练语言模型的中文文本摘要生成研究
{Author}: 朱祺航
{Tertiary Author}: 胡枫;李琳
{Publisher}: 青海师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 中文文本摘要生成;神经网络;注意力机制;预训练语言模型
{Abstract}: 随着信息化时代的到来,更多的人依靠网络获得所需要的资讯,比如用户点评、新闻报道、博客等各类社交媒体,但这种文本资料中存在着巨大的冗余数据,如何对这些文本资源进行处理就变得尤为关键。如果纯靠人工对每个文本资源进行分析然后生成文本摘要,需要花费大量的资源,甚至是一件几乎不可能完成的任务。自然语言处理领域的自动文本摘要技术为解决这个问题提供了思路。预训练语言模型通过训练大规模的语料库使其学习到语言的通用规律,再通过具体的下游任务相关语料进行训练使其符合下游任务要求。本文通过分析各预训练语言模型的特点,将其运用于中文文本摘要生成任务上,主要研究内容如下:(1)构建基于Seq2Seq结构并结合指针生成网络和强化学习的中文文本摘要基线模型。目前基于Seq2Seq结构的中文文本摘要模型还存在着暴露偏差的问题,导致其文本摘要模型表现效果欠佳。本文设计实现了基于Seq2Seq结构并结合指针生成网络和强化学习(PGN+RL)中文文本摘要模型。将传统语言模型的损失函数与强化学习的损失函数进行加权,减少暴露偏差带来的问题。实验表明,本文构建的PGN+RL文本摘要模型能有效提升模型生成质量,并将其作为本文的基线模型。(2)构建基于各预训练语言模型的中文文本摘要。通过对多个预训练语言模型进行研究,本文将各预训练语言模型应用到中文文本摘要生成任务中。在LCSTS数据集上进行实验并生成摘要实例进行对比,实验结果表明基于GPT-2与Uni LM的中文文本摘要模型与基线模型相比表现较好,基于BERT与ERNIE-GEN的中文文本摘要模型生成摘要的结果表现较差。(3)构建基于GPT-2改进的中文文本摘要模型。通过在编码阶段和数据预处理阶段对GPT-2预训练语言模型进行改进,提高GPT-2预训练语言模型在中文文本摘要生成任务上的性能。与基线模型以及其他预训练语言模型在数据集LCSTS上对比,实验表明本文的改进模型在ROUGE评分上达到最佳,通过对比模型生成摘要实例,表明本文的改进模型在生成摘要的可读性、连贯性以及包含句子完整性上表现更好,验证了针对模型改进的有效性。最后对比各模型在新的中文文本摘要数据集NLPCC上的表现,进一步验证本文提出的模型具有一定的泛化能力。综上说明了本文针对GPT-2预训练语言模型进行改进能够使其更好地应用于文本摘要任务中,并能进一步提升模型生成摘要质量。
{URL}: https://link.cnki.net/doi/10.27778/d.cnki.gqhzy.2022.000771
{DOI}: 10.27778/d.cnki.gqhzy.2022.000771
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于强化学习的多轮交互医疗辅助问诊系统研究
{Author}: 胡佳慧
{Tertiary Author}: 施寒潇
{Publisher}: 浙江工商大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 强化学习;自然语言理解;多轮交互;辅助问诊
{Abstract}: 近年来,随着人工智能的加速发展和国民医疗需求的增长,国家越来越重视“互联网+医疗健康”的发展和技术创新,而新冠肺炎的爆发,传统的线下就医方式受到影响,民众逐渐接受通过互联网进行线上问诊,这一现象更推进了智能医疗的发展。目前,越来越多的科研人员从事该领域的研究,利用深度强化学习、知识图谱等人工智能技术与医疗诊断系统进行结合,致力于构建一个智能医疗辅助问诊系统,但该系统不同于一问一答的问答系统,如何在多轮对话中提高对用户症状的收集以及对最后病情的诊断是一个重要的研究方向。因此,本文设计了一个基于强化学习的多轮交互医疗辅助问诊系统,具体研究工作包括以下几个方面:第一,本文在第一届智能对话诊疗评测比赛(CCL2021)提供的任务一数据的基础上,构建了适用于命名实体识别和症状实体识别的高质量数据集,并设计了基于实体的症状识别模型(AEBC),该模型首先使用双向长短时记忆网络+条件随机场模型(Bi-LSTM+CRF)识别用户输入语句中的症状实体,然后将识别出的实体转化为平均词向量作为输入,以此判断该症状是否存在,从而实现对话系统的自然语言理解环节。实验证明,本文构建的高质量数据集能优化模型性能,且AEBC模型相较于其他模型性能更优。第二,本文利用CCL2021提供的任务三数据,设计了基于强化学习的疾病诊断模型(DPDS),该模型在症状召回环节,引用外部知识构建的贝叶斯网络获取疾病与症状之间的关系,而在疾病诊断环节,除了引用概率网络图,还增加了疾病六分类模型,提高模型的疾病准确率。实验证明,该模型比简单的强化学习模型更具鲁棒性,拥有比基线模型更佳的性能,能更全面地获取用户的隐性症状,更准确地判断用户可能患上的疾病。第三,融合前两个模型,设计并实现了基于多轮交互的医疗辅助问诊系统,该系统采用Flask这一网络框架技术,在实际运行中,能与用户进行多轮互动,不断获取用户的症状信息,从而给出最大概率疾病的判断。
{URL}: https://link.cnki.net/doi/10.27462/d.cnki.ghzhc.2022.000385
{DOI}: 10.27462/d.cnki.ghzhc.2022.000385
{Database Provider}: CNKI

 