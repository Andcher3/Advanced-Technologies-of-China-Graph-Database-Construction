{Reference Type}: Journal Article
{Title}: 基于机器视觉的农业车辆及机器人导航技术研究进展
{Author}: 张少侠;闫建伟;蒙超;石国照;吴锦涛
{Author Address}: 贵州大学机械工程学院;
{Journal}: 计算机工程与应用
{Pages}: 1-16
{Keywords}: 农业车辆;农业机器人;机器视觉;视觉导航;图像处理;导航路径提取;导航线拟合
{Abstract}: 随着智能驾驶技术的发展，农业车辆和机器人自主导航技术成为当前研究热点，搭载机器视觉导航系统的农业车辆及机器人也广泛应用在农业生产任务中，但在复杂农业环境中的应用仍存在问题。为此，对农业视觉导航技术进行总结，首先详细论述了视觉导航图像采集技术，其次对基于图像分割和作物特征点检测的导航路径提取方法进行讨论，分析了两种导航路径提取方法共同涉及到的导航线拟合方法，最后讨论了农业车辆及机器人视觉导航当前所面临的挑战和未来发展趋势，可为农业车辆及机器人视觉导航相关研究提供参考。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20250213.0920.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的公交客流检测算法
{Author}: 武慧荣;张敬宜;郭春敏
{Author Address}: 东北林业大学土木与交通学院;
{Journal}: 控制与决策
{Pages}: 1-11
{Keywords}: 交通运输规划与管理;公交客流;深度学习;目标检测;计算机视觉;边缘部署
{Abstract}: 针对公交客流检测因忽略边缘计算而导致的数据处理延迟和准确性问题,基于“云-边-端协同架构”提出一种实时且轻量级的公交客流检测算法BPF-DETR.首先,采用RT-DETR-r18作为基线算法以提高实时处理能力;其次,引入轻量级iRMB模块更新ResNet-18作为特征提取主干,通过倒置残差结构充分学习乘客目标的长距离特征交互以及小目标的局部特征交互,在提高轻量性和精度的同时增强算法的边缘适用性;再次,引入ASF架构中的SSFF模块和TFE模块构建多尺度特征融合模块MSFM,进一步提升算法在多尺度和复杂环境下的检测精度;最后,为了验证算法有效性,采用基于ROI的图像拼接方法,提高数据集的代表性与多样性,构建公交客流监控数据集进行训练验证.实验结果表明, BPF-DETR的mAP@0.5为96.4%,模型大小为32.6MB,均优于目前主流的YOLO系列模型,相较于基线算法, mAP@0.5提升了1.1%,模型大小下降16%,满足公交客流检测准确率及边缘部署轻量化要求.
{ISBN/ISSN}: 1001-0920
{Notes}: 21-1124/TP
{URL}: https://link.cnki.net/doi/10.13195/j.kzyjc.2024.1245
{DOI}: 10.13195/j.kzyjc.2024.1245
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能垃圾分类系统的设计
{Author}: 张彭程
{Author Address}: 南京航空航天大学金城学院;
{Journal}: 中国新技术新产品
{Year}: 2025
{Volume}: 
{Issue}: 02
{Pages}: 32-34
{Keywords}: 卷积神经网络;图像识别;垃圾分类
{Abstract}: 为了有效处理废弃物，本文设计、制作了垃圾分类的硬件设备，包括K210模板、摄像头、电路以及4个舵机，4个舵机分别连接厨余垃圾、有害垃圾和其他垃圾。针对垃圾数据集较少的问题，本文采用基于VGG16的卷积神经网络算法，在自建的垃圾数据集上进行训练和测试。结果显示，利用该方法可以准确识别垃圾种类，平均准确率为93%。
{ISBN/ISSN}: 1673-9957
{Notes}: 11-5601/T
{URL}: https://link.cnki.net/doi/10.13612/j.cnki.cntp.2025.02.041
{DOI}: 10.13612/j.cnki.cntp.2025.02.041
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向计算机视觉应用的扩散模型综述
{Author}: 韩烜宇;王安志;杨成帮;唐洁亮
{Author Address}: 贵州师范大学大数据与计算机科学学院;
{Journal}: 贵州师范大学学报(自然科学版)
{Year}: 2025
{Volume}: 43
{Issue}: 01
{Pages}: 115-128
{Keywords}: 扩散模型;计算机视觉;目标检测;目标分割
{Abstract}: 作为一种强大的生成模型，扩散模型在深度学习领域引起了广泛关注，成为当前的研究热点。受扩散模型在图像生成任务中取得巨大成功的启发，一些开创性的工作开始研究如何将扩散模型用于视觉领域的其他重要方向，并取得了显著的成果。对扩散模型的视觉应用进行梳理、分析与总结。首先阐述了3种主流扩散模型的原理：去噪扩散概率模型、基于分数的生成模型与随机微分方程的生成模型。其次，进一步分析了基于扩散模型改进与优化的相关衍生模型。并系统梳理扩散模型在视觉领域的重要应用研究进展。最后，总结了扩散模型在视觉应用中存在的问题，对其未来发展方向进行展望。
{ISBN/ISSN}: 1004-5570
{Notes}: 52-5006/N
{URL}: https://link.cnki.net/doi/10.16614/j.gznuj.zrb.2025.01.012
{DOI}: 10.16614/j.gznuj.zrb.2025.01.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 扩散模型在计算机视觉领域的研究现状
{Author}: 管凤旭;张涵宇;路斯棋;赖海涛;杜雪;郑岩
{Author Address}: 哈尔滨工程大学智能科学与工程学院;
{Journal}: 智能系统学报
{Pages}: 1-18
{Keywords}: 扩散模型;去噪扩散概率模型;分数扩散模型;深度学习;计算机视觉;图像生成;生成模型;生成对抗网络
{Abstract}: 扩散模型是受分子热力学启发而来的一类新的生成模型，具有训练稳定、对模型设置依赖性弱等优点。近年来，扩散模型被广泛应用于各项任务，并且取得了相比于以往生成模型更多样、更高质量的结果。目前，扩散模型已成为计算机视觉领域热门的基准方法。为更好地促进扩散模型在计算机视觉领域的发展，对扩散模型进行综述：首先对比了扩散模型与其他生成模型的优劣，介绍了扩散模型的数学原理；随后，从扩散模型存在的普遍问题出发，介绍了相关学者近年来所做的改进工作，以及扩散模型在多种视觉任务上的应用实例；最后，探讨了扩散模型存在的问题，并提出了一些未来可能的发展趋势。
{ISBN/ISSN}: 1673-4785
{Notes}: 23-1538/TP
{URL}: https://link.cnki.net/urlid/23.1538.TP.20250108.0933.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 钢结构作业场景下起重机与工人的空间碰撞监测
{Author}: 王晓哲;金新翔;林啸;罗柱邦;郭红领;蓝荣香
{Author Address}: 西安华润置地发展有限公司;清华大学建设管理系;琅安建设管理咨询(上海)有限公司;
{Journal}: 清华大学学报(自然科学版)
{Year}: 2025
{Volume}: 65
{Issue}: 01
{Pages}: 45-52
{Keywords}: 钢结构施工;人机碰撞风险;工人定位;计算机视觉
{Abstract}: 起重机吊装是钢结构施工的重要环节，但相关安全事故频发，亟需有效的防范措施。该研究通过定位和测距等传感器实现了对起重机位置与姿态的实时监测，并结合起重机的作业特点，对其工作空间进行了危险等级划分。采用YOLO11-OBB模型和透视变换方法对施工现场工人的位置进行实时定位，并将起重机和工人的工作空间信息实时集成于三维平台，实现了两者碰撞风险的实时监测。测试结果表明：所提出方法的中、高风险的监测精度分别为±2.600 m和±2.611 m,工人定位方法在20 m范围内的平均绝对误差、平均相对误差和均方根误差分别为67.44 mm、 4.32%和86.16 mm。针对西安某项目开展的为期9个月的实地监测表明，该方法有效提升了施工现场的安全警示能力，减少了工人进入起重机高风险区域的次数。
{ISBN/ISSN}: 1000-0054
{Notes}: 11-2223/N
{URL}: https://link.cnki.net/doi/10.16511/j.cnki.qhdxxb.2025.22.009
{DOI}: 10.16511/j.cnki.qhdxxb.2025.22.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的人体动作质量评价研究综述
{Author}: 沈媛媛;张燕明;沈燕飞
{Author Address}: 北京体育大学体育工程学院;中国科学院自动化研究所模式识别国家重点实验室;
{Journal}: 自动化学报
{Year}: 2025
{Volume}: 51
{Issue}: 02
{Pages}: 404-426
{Keywords}: 动作质量;评价;计算机视觉;信息获取;特征表示;损失函数
{Abstract}: 基于视觉的人体动作质量评价利用计算机视觉相关技术自动分析个体运动完成情况,并为其提供相应的动作质量评价结果.这已成为运动科学和人工智能交叉领域的一个热点研究问题,在竞技体育、运动员选材、健身锻炼、运动康复等领域具有深远的理论研究意义和很强的实用价值.本文将从数据获取及标注、动作特征表示、动作质量评价3个方面对涉及到的技术进行回顾分析,对相关方法进行分类,并比较分析不同方法在AQA-7、JIGSAWS、EPIC-Skills 2018三个数据集上的性能.最后讨论未来可能的研究方向.
{ISBN/ISSN}: 0254-4156
{Notes}: 11-2109/TP
{URL}: https://link.cnki.net/doi/10.16383/j.aas.c230551
{DOI}: 10.16383/j.aas.c230551
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的凸轮轴表面缺陷检测实验研究
{Author}: 张新娜;吴兆中;王栋;赵锦国;卢唯辰
{Author Address}: 中国计量大学机电工程学院;中国计量大学现代科技学院;中国计量大学工程训练中心;浙江高和精密机械有限公司;
{Journal}: 机电工程
{Pages}: 1-12
{Keywords}: 检测精度;凸轮轴轮廓曲线;齿轮齿顶缺陷检测算法;图像分段采集策略;特征强化;图像分割
{Abstract}: 目前在凸轮轴表面缺陷人工目视检测方面存在的精度差、效率低的问题，为此，对凸轮轴表面缺陷检测技术进行了研究，搭建了基于机器视觉的的凸轮轴表面缺陷检测系统，提出了一种基于凸轮轮廓曲线的图像分段采集策略，针对凸轮和齿轮分别设计了缺陷检测算法，对检测准确率及系统运行稳定性进行了实验研究。首先，结合凸轮轮廓曲线确定了一种图像分段采集策略，改善了因凸轮厚度较大和形状不规则造成图像部分区域无效的问题，获得了图像采集的最佳角度与次数；然后，采用形态学梯度，强化了凸轮亮度不均图像缺陷特征，结合Canny算子进行了缺陷检测，提出了一种基于像素补充的凸轮边界缺陷识别算法；最后，设计了一种基于齿顶尺寸关系和仿射变换的齿轮齿顶提取方法，通过形态学开操作弱化了齿顶内部纹理，通过固定阈值分割了齿轮齿顶表面缺陷；搭建了检测系统硬件平台，对凸轮轴表面缺陷检测进行了实验及结果分析。研究结果表明：系统运行流畅，各工位检测准确率最低达98.11%，平均检测时间为11.09 s，缺陷分类准确率为96%。该凸轮轴表面缺陷检测系统满足了凸轮轴产线在线检测的需求，有效提升了其检测效率与准确率。
{ISBN/ISSN}: 1001-4551
{Notes}: 33-1088/TH
{URL}: https://link.cnki.net/urlid/33.1088.TH.20241125.1137.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 卷积神经网络在车牌识别中的应用实现
{Author}: 陈明洋;代红;王思彤;陈禹含
{Author Address}: 辽宁科技大学;
{Journal}: 无线互联科技
{Year}: 2024
{Volume}: 21
{Issue}: 22
{Pages}: 62-64
{Keywords}: 卷积神经网络;车牌识别;机器视觉
{Abstract}: 随着交通管理、智慧城市等领域的快速发展，车牌识别技术逐渐成为一种关键技术。卷积神经网络作为一种强大的图像处理和特征提取方法，被广泛应用于车牌识别领域。文章采用机器学习、字符分割等技术以提高车牌识别的高效性和准确性。系统涵盖了多种情况下的车牌图像并对图片进行精密的预处理。在车牌分类识别方面，文章除了运用字符分割与关键字识别技术，还设计了具有针对性的卷积神经网络模型，对其进行训练并在多组对比实验后，对模型的识别准确率进行评估。结果表明：卷积神经网络具有较好的识别准确率和一定的实用性和价值性，可应用于智能停车场的车辆识别。
{ISBN/ISSN}: 1672-6944
{Notes}: 32-1675/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwLauJcuPhSXBLBsodAPYPSzYn1l1a942B-0Ukc3vDNgthgaHp-9L5gaoIef-_NjRNr3qq1d4mUiH9CoQ0srQT3DwZoPMo3026zeNkm4MhUFAir4ydoGQN0R3LCVvy-xbbptmMJaheVp-FVfG7b21s8hMOMGIK-DezhuyiLejz_NUJ2iVSpGJw_7qBRLOlU58c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉图像处理技术应用方法分析
{Author}: 韩晶
{Author Address}: 长春教育学院;
{Journal}: 中国新通信
{Year}: 2024
{Volume}: 26
{Issue}: 22
{Pages}: 74-76
{Keywords}: 计算机;视觉;图像
{Abstract}: 本文简要介绍了计算机视觉图像技术的应用范围，即视频图像分析、目标区域安防检测等，并从果蔬成熟度检测、自动驾驶检测两个方面，开展了计算机视觉图像技术的应用实践分析，以期展现计算机视觉技术的应用价值。
{ISBN/ISSN}: 1673-4866
{Notes}: 11-5402/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxkt7TXbdrre_Lug7sDE2LsMp5sRbWDB-nrKmGTMtr1eqgteL7U5q512Upl09ntW-kJ1TskYvga3oZGeGqvPgqcZ0wEps7h12X0vvseCxbKsxXfuMpVI79Pj86E8dRP3jCP9xasu8GwUX2zuEJ4WFceeKQxCiMgZbLke94dad9pZ06FsFeQnlicWCDIjneXN5A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉辅助避障的导盲手杖设计
{Author}: 曹钰;刘玫;刘景行;王远
{Author Address}: 吉林大学仪器科学与电气工程学院;
{Journal}: 集成电路与嵌入式系统
{Year}: 2025
{Volume}: 25
{Issue}: 03
{Pages}: 9-14
{Keywords}: 机器视觉;人工神经网络;导盲手杖;图像处理;OpenMV
{Abstract}: 视障人群的出行及日常活动普遍依赖导盲犬、导盲手杖或他人帮扶等方式，但随着经济发展，城市规划变得越来越密集，城市布局和道路规划的复杂度也逐渐增加，上述方法已经不能够保障视障人士的出行及日常生活安全，因此加强对视障群体的关注力度、提高其生活质量是我们亟待解决的问题。本设计着眼于机器视觉对彩色信息和深度图像的去噪、滤波、目标标定等处理，加以机器学习训练，实现图像的色彩识别、常见障碍物识别及距离测量功能，将分析结果转换为音频信号并通过语音输出给用户，给予一定行进建议，致力于为视障人士提供避障服务，降低在行走过程中因无法提前预测的障碍物对出行造成的负面影响。
{ISBN/ISSN}: 2097-4191
{Notes}: 10-1910/V
{URL}: https://link.cnki.net/doi/10.20193/j.ices2097-4191.2024.0051
{DOI}: 10.20193/j.ices2097-4191.2024.0051
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5的带钢表面缺陷检测
{Author}: 杨威;杨俊;许聪源
{Author Address}: 浙江理工大学计算机科学与技术学院;嘉兴大学信息科学与工程学院;
{Journal}: 计量学报
{Year}: 2024
{Volume}: 45
{Issue}: 11
{Pages}: 1671-1680
{Keywords}: 机器视觉;带钢表面缺陷检测;YOLOv5;多尺度融合;损失函数
{Abstract}: 针对带钢表面缺陷检测方法存在检测精度低和检测速度慢的问题，提出一种基于改进YOLOv5的带钢表面缺陷检测方法。首先，采用内容感知特征重组CARAFE作为多尺度特征融合的上采样算子，构建具有通道缩放的自适应空间特征融合CS-ASFF结构，以增强多尺度特征融合并控制模型复杂度。其次，在模型的卷积层和跨层级结构引入GSConv和VoVGSCSP模块，以减小计算量并提高检测精度。最后，采用Focal-GIOU Loss作为损失函数来解决带钢缺陷图像中难易样本不平衡的问题，并提升模型对复杂数据的适应能力。实验结果表明，在NEU-DET数据集上该方法达到了80.6%的均值平均精度(PmAP),计算量为14.8 GFLOPs。与YOLOv5相比，PmAP提高了4.3%且计算量减少了6.33%。与当前主流目标检测网络相比，在更低的计算量下该方法具有最高的检测精度，能够满足真实工业场景下的带钢表面缺陷实时检测。
{ISBN/ISSN}: 1000-1158
{Notes}: 11-1864/TB
{URL}: https://link.cnki.net/urlid/11.1864.TB.20241108.1551.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOX的自然环境下辣椒果实检测方法
{Author}: 李旭;刘青;匡敏球;潘建东;刘大为;向阳;吴艳华;谢方平
{Author Address}: 湖南农业大学机电工程学院;智能农机装备湖南省重点实验室;浙江大学生物系统工程与食品科学学院;长沙县多莱农业科技有限公司;
{Journal}: 农业工程学报
{Year}: 2024
{Volume}: 40
{Issue}: 21
{Pages}: 119-126
{Keywords}: 农业;机器视觉;YOLOX;辣椒;自然环境;果实检测
{Abstract}: 针对不同光照、枝叶遮挡和果实遮挡条件下模型适应能力差和检测精度较低的问题，该研究提出了一种基于YOLOX的改进辣椒果实检测模型YOLOX＿Pepper。首先，在YOLOX特征融合网络中添加融合高效通道CA(coordinate attention)注意力机制，提升不同光照条件下模型捕捉辣椒果实关键特征的能力；其次，将主干网络特征聚合模块中的卷积模块替换为可变形卷积DCNv2(deformable convnets v2)，提升了模型对不同遮挡情况下辣椒多样几何特征的感知能力。试验结果表明，改进的YOLOX＿Pepper模型平均检测精度为93.30%，与Faster R-CNN、YOLOv5、YOLOv7以及YOLOX相比，分别提高了3.99、1.58、3.19和2.84个百分点，F1分数为96%。改进的YOLOX＿Pepper模型对自然环境不同光照和遮挡条件的辣椒果实均能进行准确快速的检测。该方法可为辣椒智能化生产提供技术基础。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.S.20241101.1029.036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于多模态深度学习的实时交互系统设计
{Author}: 李晓峰;张银慧;李子阳;张文泉
{Author Address}: 天津仁爱学院信息与智能工程学院;
{Journal}: 机械设计
{Year}: 2024
{Volume}: 41
{Issue}: S2
{Pages}: 200-204
{Keywords}: 人机交互;手势识别;多模态深度学习;计算机视觉;卷积神经网络
{Abstract}: 人机交互系统中，计算机视觉技术和深度学习算法常用来实现手势分割、特征提取和分类识别等。系统由本地终端和云端服务器组成，本地终端采集常用手势图像，利用亮度信息和方向梯度直方图（Histogram of Oriented Gradients,HOG）等多模态特征建立训练数据集；云端服务器基于Nvidia Jetson Nano B01 AI平台以迁移学习方式进行卷积神经网络（Convolutional Neural Network,CNN）训练；利用边缘计算技术将手势图像预处理和特征提取等任务放在本地完成，降低对服务器算力依赖。测试结果表明，系统平均处理和延时在2 s左右，满足普通的实时交互需求；CNN模型对45种手势的整体预测精确率为0.99；手势识别结果在本地实现图像-文本-语音转换，增强了交互的便利性和效率；用户数据在本地存储既保证了安全，也拓展了系统的应用场景。
{ISBN/ISSN}: 1001-2354
{Notes}: 12-1120/TH
{URL}: https://link.cnki.net/doi/10.13841/j.cnki.jxsj.2024.s2.034
{DOI}: 10.13841/j.cnki.jxsj.2024.s2.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 语义信息处理方式分类的车道线检测技术研究综述
{Author}: 洪书颖;张东霖
{Author Address}: 江南大学人工智能与计算机学院;江苏省模式识别计算智能工程实验室;科技部中英人工智能联合实验室;
{Journal}: 计算机工程与应用
{Year}: 2025
{Volume}: 61
{Issue}: 05
{Pages}: 1-17
{Keywords}: 车道线检测;语义信息;自动驾驶;深度学习;计算机视觉
{Abstract}: 随着自动驾驶技术的迅猛发展，车道线检测作为其关键组成部分，引起了广泛关注，并在智能交通系统中展现出巨大的应用潜力。然而，在应对复杂环境挑战时，传统车道线检测技术往往难以提供足够的识别精度。回顾车道线检测技术的发展轨迹，系统性地梳理了84种先进算法，并创新性地根据语义处理方式划分为四类别：语义分割辅助类、语义信息融合类、语义信息增强类和语义关系建模类。通过深入剖析算法的技术特点和优势，揭示了当前车道线检测技术所面临的主要局限。最后，对未来车道线检测技术的发展方向提出见解，特别是在语义信息利用方面，指出了潜在的研究方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20241015.1739.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 激光雷达与机器视觉融合的海面目标检测方法
{Author}: 徐洪斌;李立刚;贺则昊;李可染;郝东鹏;戴永寿
{Author Address}: 中国石油大学(华东),海洋与空间信息学院;中国石油大学(华东),控制科学与工程学院;
{Journal}: 电光与控制
{Year}: 2024
{Volume}: 31
{Issue}: 12
{Pages}: 98-105
{Keywords}: 无人船;目标检测;激光雷达;YOLOv7-tiny;注意力机制;可变形卷积
{Abstract}: 针对近岸复杂环境和目标部分遮挡条件下海面目标检测易出现目标漏检和虚警的问题，提出了一种激光雷达与机器视觉融合的海面目标检测方法。首先，设计了一种基于注意力机制与可变形卷积的特征提取模块，提高YOLOv7-tiny网络对海面障碍物目标特征的提取能力，从而降低近岸复杂背景干扰导致的漏检率和虚警率；然后，将激光雷达聚类结果和改进的YOLOv7-tiny网络模型预测结果进行融合，降低目标部分遮挡导致的漏检率；最后，在海面目标检测图像数据集上进行实验验证，结果表明，与原YOLOv7-tiny网络模型相比，改进YOLOv7-tiny网络模型的mAP提升了3.8个百分点，在目标部分遮挡场景下用实船实验数据进行验证，与NMS算法相比，所提融合方法的漏检率降低了6.9个百分点，验证了所提方法能够在近岸复杂环境和目标部分遮挡场景下，降低海面目标检测的漏检率和虚警率。
{ISBN/ISSN}: 1671-637X
{Notes}: 41-1227/TN
{URL}: https://link.cnki.net/urlid/41.1227.tn.20241011.1436.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 可见光红外跨模态行人重识别方法综述
{Author}: 范慧杰;郁航;赵颖畅;唐延东
{Author Address}: 中国科学院沈阳自动化研究所机器人学国家重点实验室;沈阳化工大学信息工程学院;沈阳理工大学自动化与电气工程学院;
{Journal}: 信息与控制
{Year}: 2025
{Volume}: 54
{Issue}: 01
{Pages}: 50-65
{Keywords}: 跨模态行人重识别;计算机视觉;无监督;辅助模型
{Abstract}: 可见光红外跨模态行人重识别技术因不受夜间限制，可实现全天候监控而受到广泛关注。本文希望通过分析现有可见光红外跨模态行人重识别研究方法及其适用场景、算法优缺点来帮助研究人员根据研究需求找到合适的解决方案。同时，寻找该领域难点和困境，以此探讨可见光红外跨模态行人重识别未来方向。首先介绍行人重识别的概念，回顾发展历程，介绍可见光红外跨模态行人重识别的意义；其后将可见光红外跨模态行人重识别研究方法分为基本方法、辅助模型方法、无监督方法、基于视频的方法，并对每种方法的适用场景、优缺点和未来研究方法展开分析；再对当前可见光红外跨模态行人重识别的评价指标以及现有数据集进行介绍，并对每种数据集的优劣进行分析；最后讨论了可见光红外跨模态行人重识别未来发展。
{ISBN/ISSN}: 1002-0411
{Notes}: 21-1138/TP
{URL}: https://link.cnki.net/doi/10.13976/j.cnki.xk.2024.4041
{DOI}: 10.13976/j.cnki.xk.2024.4041
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 苹果成熟度机器视觉无损检测方法研究
{Author}: 刘志刚;王丽娟;喜冠南;彭超华
{Author Address}: 南通科技职业学院;
{Journal}: 机械设计与制造
{Year}: 2025
{Volume}: 
{Issue}: 02
{Pages}: 358-362
{Keywords}: 苹果;成熟度;机器视觉;颜色信息;无损检测
{Abstract}: 我国是世界上数一数二的水果生产大国，人民对水果及果制品的品质等级要求越来越高。因此水果零售业如何科学、快速、准确地对水果进行等级评定，果制品加工业如何分筛最佳成熟度的果品制作果汁、果酱等果制品都是后熟型水果采后处理至关重要的环节。为了建立基于机器视觉的苹果成熟度无损检测方法，首先设计确立了用于检测和判定苹果成熟度的机器视觉检测系统，研究了苹果表面颜色信息的描述方法，通过比较和分析，发现宜采用RGB颜色模型对苹果彩色图形进行检测进而判别成熟度；提出了利用苹果果实的表面颜色信息，预测可溶性固形物来预测成熟度的新方法，参照农业国标GB/T10651-2008要求，可溶性固形物T>11%，判定成熟，判定为成熟后再根据主色红色占比Ra进行准确分级：红色占比Ra在45%（包含）以下，判定为不成熟；在（45～50）%（包含）范围内，判定为四级；在（50～65）%（包含）范围内，判定为三级；在（65～80）%（包含）范围内，判定为二级；在80%以上，判定为一级；利用训练完成的成熟度预测模型对250个苹果样本进行了成熟度判别，随机选取10组试验结果，数据显示预测的苹果可溶性固形物含量和实验测得的可溶性固形物含量误差不超过±0.2%。表明利用机器视觉识别苹果表皮颜色信息预测可溶性固溶物进而判别成熟度是可行的，具有通用性与推广性。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20240905.002
{DOI}: 10.19356/j.cnki.1001-3997.20240905.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV的手势识别技术在机电系统人机交互中的应用与研究
{Author}: 谢强;张华梅;王宇才
{Author Address}: 洁禹通(广西)环保技术有限公司;
{Journal}: 轻工科技
{Year}: 2024
{Volume}: 40
{Issue}: 05
{Pages}: 119-121+159
{Keywords}: 手势识别;OpenCV;人机交互;机电系统人机交互;自动化控制
{Abstract}: 在当今工业自动化和智能制造的背景下，手势识别作为一种非接触式的人机交互技术，正逐渐成为机电一体化领域研究的热点。随着计算机视觉技术的不断进步，特别是OpenCV这一开源计算机视觉库的广泛应用，手势识别的准确性和实时性得到了显著提升，为机电系统的智能化控制提供了新的可能性。本文基于OpenCV开展手势识别技术的研究，介绍手势识别的基本原理和OpenCV的相关功能，阐述手势识别处理的流程，包括图像输入、预处理、手部检测、关键点提取、特征分析和手势分类。本文展示该技术在机电系统人机交互中的应用潜力，并通过实验验证系统的有效性。结果表明，该系统能够准确识别多种手势，为机电系统的智能控制提供一种新的交互手段，为相关领域的研究者提供宝贵的参考。
{ISBN/ISSN}: 2095-3518
{Notes}: 45-1385/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzuO_7pi4kjxa2dI2kmB96JRIWq-d_XZuc9nz71IEaRIcJqjqeG4NyJWyceSEKiUQ4qS3cwPh9SOpNghreTU4K4wB8D9ilJsE60dVyaq4k2ccnTeHoXmjt70-f9CoiMJqMcTtvROQkreRdf-6LK3MgaMA4VAwz1mATSCPJvrSH_7g5vH9qJZ27tV_tZdsNoRIs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的域泛化行人重识别方法研究
{Author}: 靳通
{Tertiary Author}: 张国庆
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 域泛化;自然语言监督;行人重识别;深度学习
{Abstract}: 行人重识别技术,作为计算机视觉领域的一大研究焦点,其主要目标是通过分析多摄像头网络在不同时间和地点捕获的行人图像,以判断是否指向同一个体。该技术在跨越摄像头进行行人追踪、增强监控系统的综合性能,以及在辅助刑侦调查等多个领域,展现出极高的实用价值。然而,在实际应用行人重识别技术时,模型对数据分布的敏感性成为一个显著问题。一旦模型遭遇与训练数据分布不一致的新信息,其表现往往会大幅下滑,这一问题严重制约了该技术的广泛推广。为解决此难题,域泛化模型应时而生。这类模型致力于提升模型对域不变特征的学习能力,确保在面对多样化的数据分布时,模型性能依然稳健。现有的域泛化方法主要集中于通过设计不同的模型架构来提升泛化能力,却忽视了如何选择最合适的源域以实现最佳性能。为了达到最优的迁移效果,往往需要逐一尝试不同的源域,这不仅耗时而且效率低下,还会导致方法在实际场景中使用困难。另外,当前普遍采用的域泛化方法通常依赖于带标签的源域数据进行训练。当处理无标签数据时,需借助聚类算法生成伪标签,但这一过程往往伴随着标签噪声、类别不平衡、过拟合和参数敏感性等一系列问题,这些问题共同导致了模型的泛化性能不佳。为了提升域泛化在行人重识别领域的性能和实用性,本文针对以上问题进行了以下研究:(1)针对现有域适应方法在选取最佳源域方面存在的不足,本文提出了一种新颖的无监督领域自适应方法。该方法基于特征统计分析,通过精确计算特征的平均值和方差来量化不同域之间的差异,并以此作为关键指标来筛选出最优的源域。通过将这一差异最小化作为优化目标,我们有效地避免了源域与目标域之间过大的差异所引发的模型负迁移现象。此外,本方法采用动量更新策略来维护目标域特征库,从而有效遏制了训练过程中特征快速变化所导致的模型稳定性问题。在自然图像数据集和行人数据集上的实验验证了本方法在性能上的优越表现。(2)针对现有无监督域泛化方法对伪标签算法的依赖以及训练速度慢、效果不佳的问题,本文提出了一种基于文本描述的域泛化行人重识别方法。该方法采用基于Transformer的图像描述网络,为每张行人图像生成描述信息,以此作为监督信号,有效解决了源域信息缺乏标签的挑战。本文进一步构建了一个图像-文本双分支网络结构,通过对比学习策略,缩小文本描述与行人图像之间的距离,通过利用文本信息作为中间模态,减少了视角和光照变化等因素导致的域间差异,从而显著提升了模型的泛化能力。得益于文本描述的噪声低、能够有效捕捉关键特征等优势。本方法仅需一个epoch的训练即可达到良好的性能。在多个基准数据集上的实验分析证实,本方法在Rank-1指标上相较于其他方法展现了更为优异的性能表现。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2024.002045
{DOI}: 10.27248/d.cnki.gnjqc.2024.002045
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习的实例分割技术研究进展
{Author}: 孙鹏;孙传聪;徐要要;邹田甜;吴翠杨;甄珍
{Author Address}: 山东药品食品职业学院医疗器械系;
{Journal}: 机电工程技术
{Year}: 2024
{Volume}: 53
{Issue}: 08
{Pages}: 1-6
{Keywords}: 计算机视觉;实例分割;深度学习;图像分割;评价指标
{Abstract}: 近年来，深度学习在计算机视觉领域中的应用成效显著，新的深度学习方法和深度神经网络模型不断涌现，算法性能被不断刷新，基于深度学习的图像实例分割方法取得了跨越性进展，已成为处理图像的有力工具。为更好地促进深度学习实例分割算法的研究发展，对该领域的研究进展做了系统的梳理总结。首先，根据图像实例分割方法的过程和特征，分别从两阶段和单阶段的角度介绍对基于深度学习的图像实例分割研究进展；随之，介绍常用的评价指标；最后，结合实例分析分割技术当下存在的不足，提出可行的解决方案，并展望了实例分割技术的发展未来。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxNTr35T1O6k_0VyYkNUM7IbbqgD6ND-I-XIKStSNJ32g2ulzWvYEBnv0Za7YDMLoWvdQ0XuU2asBk5htZsl5P2Xna1U0fxe2DVV4GXQoYajBfIqT5GHerWSN4CgTLgSBMAKzbPnB41S4dzUa60SBFT-joxrezl9wMy_y0A6HqG9me_fjI28XQT9na1nkIdwXY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉算法支持下的图像处理技术分析
{Author}: 潘婉
{Author Address}: 郑州工业应用技术学院;
{Journal}: 数字通信世界
{Year}: 2024
{Volume}: 
{Issue}: 08
{Pages}: 86-88
{Keywords}: 计算机;视觉算法;图像处理;畸变校正
{Abstract}: 随着技术进步，计算机视觉算法已经深入图像处理技术的各个领域，其支持下的图像处理技术不仅在学术研究中占据重要地位，同时也在工业、医疗、安全等实际应用中发挥着至关重要的作用。该文通过概述了计算机视觉算法和图像处理技术的特点，系统分析了图像畸变矫正与增强技术，以期充分发挥计算机视觉算法在提高图像质量、增强系统性能以及拓宽技术应用范围方面的影响力。
{ISBN/ISSN}: 1672-7274
{Notes}: 11-5154/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy43NeU4OgdPQa0JSzGn06OZoiN0i0tF5nwTad0q3QPDi-bW5CUjAM3iyZXq0pxRTURT-ClOgK4vlb2GWVJFaJq2nrmr8GucjEPhDyrh5vy-_00B9s3uznlXhPVSG5_qH8GTX--UVb9wBUrs8D_NvjeaMWNiHSFMC6eOkiQjy4FxUy5-iYVisazpHBbDVj0-sE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多网络融合的人体姿态估计研究
{Author}: 高菲
{Tertiary Author}: 费继友
{Publisher}: 大连交通大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 人体姿态估计;人体语义分割;多网络融合;复杂背景干扰;小尺寸人物
{Abstract}: 人体姿态估计技术应用十分广泛,尤其在机械工程的智能视觉领域,如协作机器人、自动驾驶、公共安全、运动员训练、医疗诊断以及元宇宙等。随着深度学习技术的不断进步,人体关键点检测效果得到了显著提升。然而,深度神经网络运算量较大,算法实时性依然不够高;人体具有柔韧性和灵活性,对幅度变化较大的动作和多人交互场景,算法效率较低;在遮挡、小尺寸人物和复杂背景干扰等情况下,姿态估计精度大幅下降,甚至检测失败,鲁棒性较差。这些亟待解决的问题对人体姿态估计技术构成挑战。本文针对当前人体姿态估计技术存在的推理速度慢、检测效率低、鲁棒性差等核心问题,以解决复杂背景干扰和小尺寸人物姿态难以准确估计两大问题为目标,从轻量型网络设计、网络效率提升、高精度网络设计和多网络融合四个方面展开研究工作:针对目前深度神经网络推理速度慢的问题,提出基于骨干网络的轻量型快速人体姿态估计技术。将骨干网络所提取的特征图直接输入姿态估计网络,节省开销,提高运行速度。采用热图估计技术实现关键点检测,通过矢量热图和二分图最大匹配算法求解关键点最优分组。根据后接模型微调骨干网络参数,使其更适用于多网络融合。基于剪枝技术设计轻量型网络,减少计算量和参数,进一步降低运行时间,提高网络的实时性和可靠性。与应用广泛的高效单网络技术Open Pose对比,人均运行时间从105ms降至46ms,实现了更快速的训练和部署。针对现有姿态估计技术人体关键点检测效率低,对于柔韧性大的动作和多人关键点分组出错率高的问题,提出了基于自注意力机制的高效人体姿态估计技术。引入概率图模型提高二分图匹配准确率。基于部位置信图构造关键点高斯热图,并执行非极大值抑制获得候选身体部位,提高关键点检测准确率。基于部位亲和力场对图像域内肢体位置和方向进行编码,并使用二分图最大匹配匈牙利算法对人体姿态准确识别跟踪。引入自注意力机制对特征图进行权重赋予以提升感受野,使模型更高效获得全局几何特征,与高效单网络技术Open Pose对比,效率从0.62平均精度/ms提升至1.39平均精度/ms,提升了124.19%。针对语义分割网络人体边缘分割精度不够高,对复杂背景干扰图像的人体语义分割效果不理想的问题,提出基于空洞空间金字塔的生成式高精度人体语义分割技术。利用空洞空间金字塔的多种膨胀率对特征图进行重采样,多尺度捕获对象,更好地理解图像语义,提升模型对于不同尺寸目标检测的适应性。通过生成对抗网络增强关键点和肢干样本生成,增强数据集特征,提高模型的泛化能力和鲁棒性;还原高分辨率图像,提高小尺寸人物分割准确率;对抗学习人体潜在结构,有效区分高低置信度的预测,提高人体边缘分割准确率。在主流公开数据集上与最先进的技术PSPNet对比,像素准确率指标值从80.88提升为81.08,平均交并比指标值从44.94提升为45.44,取得了更优的人体语义分割结果。针对复杂背景干扰和小尺寸人物姿态估计精度低、效果差、甚至检测不到等挑战问题,提出多网络融合人体姿态估计技术Seg Pose,将骨干网络、两阶段自注意力姿态估计网络、改进语义分割网络、生成对抗网络、改进残差网络和多尺度判别网络进行融合,并行执行人体语义分割和姿态估计任务。引入编/解码器,统一图像尺寸,减少多网络融合模型参数,增加非线性变换,提高自适应性。引入改进残差网络增加网络深度,提高模型表达能力,解决多网络融合内部协变量偏移带来的训练困难问题。设计多尺度判别网络,求解分割结果与正确标注之间的最小差值,实时反馈给网络调参,使网络更快地找到最优输出结果,加速多网络融合模型收敛。在主流公开数据集上与当前最先进的多网络融合技术Detectron2对比,人均运行时间从76ms降低为66ms;效率从0.87平均精度/ms提升至1.098平均精度/ms,提升了26.21%;平均精度指标值从66.3提升至72.5,取得了更优的姿态估计结果。最终,有效解决了复杂背景干扰问题,并能够检测到更小尺寸的人物姿态,增强了网络的鲁棒性。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2024.000012
{DOI}: 10.26990/d.cnki.gsltc.2024.000012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉与深度学习技术在烟叶生产上的研究进展
{Author}: 邢卓冉;丁松爽;张凯;马明;郭文龙;刘旭东;时向东
{Author Address}: 河南农业大学,烟草行业烟草栽培重点实验室;河南农业大学烟草学院;中国烟草总公司郑州烟草研究院;湖南省烟草公司永州市公司;湖南省烟草公司怀化市公司麻阳苗族自治县分公司;
{Journal}: 中国农业科技导报(中英文)
{Year}: 2025
{Volume}: 27
{Issue}: 01
{Pages}: 96-106
{Keywords}: 计算机视觉;深度学习;卷积神经网络;烟草;应用
{Abstract}: 计算机视觉与深度学习技术在众多场景（如物体识别，图像分类）取得了显著进展，近年来这项技术在烟叶生产中展现出广泛的应用空间与发展潜力。综述了计算机视觉与深度学习技术在烟叶生产上的应用现状，重点讨论了其在解决烟叶病害识别、烟叶采收调制、烟叶分级等问题方面的方法。通过分析不同的算法及其在烟叶生产关键阶段的运用，并考虑这项技术在烟叶生产领域所面临的挑战与发展方向，为智能化烟叶生产提供理论支持和参考。
{ISBN/ISSN}: 1008-0864
{Notes}: 11-3900/S
{URL}: https://link.cnki.net/doi/10.13304/j.nykjdb.2023.0379
{DOI}: 10.13304/j.nykjdb.2023.0379
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 果蔬分拣设备研究现状及发展趋势
{Author}: 柳军;孔杰;皮杰;周成钢
{Author Address}: 江苏大学农业工程学院;江苏省农业科学院农业设施与装备研究所;
{Journal}: 中国农机化学报
{Year}: 2024
{Volume}: 45
{Issue}: 08
{Pages}: 120-125
{Keywords}: 果蔬分拣设备;发展趋势;机器视觉;近红外光谱;机械臂
{Abstract}: 果蔬商品化产后处理能力较低导致我国的果蔬在国际市场上核心竞争力不足，其中后处理最主要的步骤就是果蔬分拣，而果蔬分拣设备能够有效的提高分拣效率，解放劳动力。分别从市场和科研两方面阐述国内外果蔬分拣设备的现状，分析现有果蔬分拣设备存在的问题，讨论未来果蔬分拣的研究趋势，提出人工智能与机器视觉相结合的果蔬外部品质分拣技术和近红外光谱分析的内部品质分拣技术将是近期的研究热点，同时对易损果蔬采后分拣场景提出一种机械臂抓取式分拣设备方案，为后期解决娇嫩易损、精品果蔬的分拣问题提供参考。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2024.08.018
{DOI}: 10.13733/j.jcam.issn.2095-5553.2024.08.018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属外观缺陷检测研究综述
{Author}: 张海峰;芦新春;李升;陈书法;杨进;张鑫;孟凡昌
{Author Address}: 江苏海洋大学机械工程学院;
{Journal}: 今日制造与升级
{Year}: 2024
{Volume}: 
{Issue}: 07
{Pages}: 29-33
{Keywords}: 机器视觉;缺陷检测;图像处理;深度学习
{Abstract}: 随着技术发展，缺陷检测技术逐渐由基于传统图像处理技术演化成基于深度学习的缺陷检测技术，两种方法各有优缺点，也都有值得借鉴的地方。文章调研机器视觉发展相关文献，列举不同时期机器视觉研究者的检测方法，并进行综述。通过列举国外机器视觉发展路程与国内视觉检测应用实例，对今后缺陷检测领域发展提出展望，希望为后续研究提供一定参考。
{ISBN/ISSN}: 2095-6932
{Notes}: 10-1196/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwAkNlzzbcHxndlLB7_cVI2zB0YE9mzTZPVbUwpMGGjX_3EPRsTTQ4DZx1hQHQPetrS2wnplIRCA3Gs51TtJhmCYvMJI-MPZDtc_l9-71LzgeZKyBVpS5bqi-g5DRwKF32XUK6E7VsmkBYNv1fzQl9aW7tn_zR90gOIWIuTaBHwK9kOZw1iNhv56km-U_-JvVo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Mask R-CNN的笼养死鸭识别方法
{Author}: 柏宗春;吕胤春;朱一星;马肄恒;段恩泽
{Author Address}: 江苏省农业科学院农业设施与装备研究所;农业农村部长江中下游设施农业工程重点实验室;江苏大学农业工程学院;
{Journal}: 农业机械学报
{Year}: 2024
{Volume}: 55
{Issue}: 07
{Pages}: 305-314
{Keywords}: 机器视觉;笼养肉鸭;死鸭识别;Mask R-CNN
{Abstract}: 针对规模化笼养肉鸭舍内死鸭识别采用人工作业方式时，存在作业效率低、劳动强度大、养殖成本高等问题，以层叠式笼养肉鸭为研究对象，提出了一种基于深度学习的笼养死鸭识别方法。为了采集数据，首先面向立体层叠式养殖环境设计了一款适用于肉鸭舍的自主巡检装备。针对笼养肉鸭舍铁丝网遮挡严重的问题，基于机器视觉对笼网进行修复，基于OpenCV对图像进行增强处理。构建了一种基于Mask R-CNN的死鸭识别模型，采用Swin Transformer对模型进行优化，解决了Mask R-CNN网络缺乏整合全局信息能力的问题。对比分析了SOLO v2、Mask R-CNN和Mask R-CNN+Swin Transformer模型识别笼内死鸭准确率。实验结果表明，在平均精度均值为90%的条件下，Mask R-CNN+Swin Transformer模型对笼内死鸭总体识别准确率可达95.8%,在自主巡检装备上的检测效果优于其他主流的目标检测算法。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz145zq2NS2xoSWPv5HxLWXytgy7bz9kL4RSZSMNh4V29U2Xry6o0qUe-VWcQWDBbJl7PZPYAW7wFkPnM9dNEBRwbZ8DRpxQ-5GJQx74Zs4Oon-ldyJW3CTywFp4yYIjg7Szrp2-KsDEJ8KsRQezj7Bq3sfCXt68Rc0rBDsv7Q2L1pekrTDz0M4rVv3pUdVU4s=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的二维单人姿态估计综述
{Author}: 苏妍妍;邱志良;李帼;陆声链;陈明
{Author Address}: 广西师范大学教育区块链与智能技术教育部重点实验室;广西师范大学计算机科学与工程学院;
{Journal}: 计算机工程与应用
{Year}: 2024
{Volume}: 60
{Issue}: 21
{Pages}: 18-37
{Keywords}: 二维人体姿态估计;单人姿态估计;深度学习;关键点检测;计算机视觉
{Abstract}: 人体姿态估计是计算机视觉领域的一项关键技术，它通过检测人体关键点以识别人体姿态。随着深度学习的快速发展，其已成为人体姿态估计的主流技术并取得了显著进展。围绕单人姿态估计问题，从数据预处理、网络架构设计、监督学习方法以及后处理技术四个维度对基于深度学习的单人姿态估计研究进行回顾，同时探讨关键点表征的新方式及Transformer模型在该领域的应用，此外还介绍了常用的数据集和性能估计指标，深入讨论当前单人姿态估计领域的挑战和发展方向。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.tp.20240723.1318.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 陶瓷领域人工智能图像处理的研究进展
{Author}: 聂宇;查琪乐;李成文;章义来;李超;彭永康;李娟;许艳娜;符锐;张宽骥;倪成林
{Author Address}: 景德镇陶瓷大学江西省陶瓷企业信息化工程技术研究中心;广东松发陶瓷股份有限公司;景德镇陶瓷大学信息工程学院;景德镇陶瓷大学科学技术处;景德镇陶瓷大学管理与经济学院;
{Journal}: 陶瓷学报
{Year}: 2024
{Volume}: 45
{Issue}: 04
{Pages}: 670-688
{Keywords}: 陶瓷图像处理;机器视觉;人工智能;陶瓷生产
{Abstract}: 大数据与人工智能技术持续的深化发展及其在陶瓷领域的广泛应用，推动了产业的创新进程和效率的显著提升。本文综述了近年来陶瓷图像智能处理方面的重要研究进展，涵盖了图像修复、质量检测、图像识别、图像检索等多方面关键技术的应用，揭示了人工智能技术如何提升陶瓷设计创新和生产过程的质量。此外，细致分析了智能图像处理技术在优化制造工艺、提高生产效率以及促进陶瓷艺术与文化遗产保护等方面的应用。最后，展望了未来大语言模型如何在陶瓷领域中开拓前沿的创新路径，成为推动行业进步的关键力量。
{ISBN/ISSN}: 2095-784X
{Notes}: 36-1205/TS
{URL}: https://link.cnki.net/doi/10.13957/j.cnki.tcxb.2024.04.004
{DOI}: 10.13957/j.cnki.tcxb.2024.04.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉与混合测量技术的结构裂缝识别方法
{Author}: 李泽伟;杨永清;廖曼;谢明志;刘雨;黄胜前
{Author Address}: 西南交通大学土木工程学院;西南交通大学桥梁智能与绿色建造全国重点实验室;
{Journal}: 西南交通大学学报
{Pages}: 1-12
{Keywords}: 裂缝识别;裂缝测量;YOLOv8;UNet;超分辨图像
{Abstract}: 混凝土表面裂缝的检测为桥梁结构的运维提供了关键的技术资料与决策要素。然而，裂缝识别作为结构裂缝检测的重要步骤，存在裂缝目标识别与裂缝信息提取集成度不高的问题。为此，提出一种基于计算机视觉与混合测量技术的结构裂缝识别方法。首先，利用YOLOv8目标识别算法，实现了结构裂缝的快速识别与定位。并基于稠密的深度反向投影网络（D-DBPN）和UNet网络构建SR-UNet裂缝分割模型。引入边界损失对原有的损失函数进行改进，降低正负样本不平衡的影响，实现了像素级裂缝提取。在裂缝分割结果的处理方面，结合连通域去噪、边缘检测等形态学技术，采用基于最短距离法与正交骨架法的混合方法对裂缝进行像素宽度测量。研究利用LabelImg软件制作了包含3123张裂缝图像的识别定位数据集进行模型训练与测试。研究结果表明，YOLOv8模型在裂缝测试集上的准确率为83.41%、召回率为84.93%和F1分数为84%；裂缝像素宽度混合测量方法的拟裂缝宽度测量结果与人工识别方法基本一致，相对误差低于7.1%；本文方法能够实现裂缝识别定位、裂缝分割和像素宽度测量的一体化处理，对于桥梁裂缝检测的发展具有较强的研究价值与应用前景。
{ISBN/ISSN}: 0258-2724
{Notes}: 51-1277/U
{URL}: https://link.cnki.net/urlid/51.1277.U.20240712.1344.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的数字图像处理系统设计与实现
{Author}: 陈欣
{Author Address}: 重庆移通学院通信与信息工程学院;
{Journal}: 科技创新与应用
{Year}: 2024
{Volume}: 14
{Issue}: 21
{Pages}: 52-55
{Keywords}: 机器视觉;数字图像处理系统;系统设计;精度;摄像机
{Abstract}: 图像技术在计算机技术的发展推动下，被广泛应用于各个领域，且呈现出良好的应用效果。基于机器视觉的数字图像处理系统，已经成为现代科学和技术中不可缺少的工具。该文以此为出发点，探究基于机器视觉的数字图像处理系统设计方案，并思考系统的实际应用价值。
{ISBN/ISSN}: 2095-2945
{Notes}: 23-1581/G3
{URL}: https://link.cnki.net/doi/10.19981/j.CN23-1581/G3.2024.21.013
{DOI}: 10.19981/j.CN23-1581/G3.2024.21.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水果外观品质检测研究进展
{Author}: 马跃;张文强;牛宽;常君瑞;徐亭;于新海
{Author Address}: 河套学院机电工程系;中国农业大学工学院;
{Journal}: 食品安全质量检测学报
{Year}: 2024
{Volume}: 15
{Issue}: 13
{Pages}: 177-185
{Keywords}: 机器视觉;水果分级;品质检测
{Abstract}: 水果中富含多种营养成分,随着经济和社会生活水平的提高,高品质水果越来越受人们的青睐,其外观品质已经成为影响消费者采购的重要因素。早期我国主要依赖人工对水果进行分级,效率和准确率较低,成本和工人劳动强度较大。近年来随着机器视觉技术的不断发展,大量的学者将视觉技术应用到水果外观品质的检测中,这种技术具有无损坏、低成本、高效率和操作方便等优点。本文结合国内外学者的研究成果,梳理了机器视觉在水果外观颜色、形状、大小、缺陷和纹理检测中的应用,着重介绍了缺陷提取和分类器对水果识别算法的研究进展,分析了传统视觉分级、机器学习和深度学习的应用特点,提出了机器视觉技术存在的问题并对未来发展趋势进行了展望,以期为水果外观品质检测研究提供参考与借鉴。
{ISBN/ISSN}: 2095-0381
{Notes}: 11-5956/TS
{URL}: https://link.cnki.net/doi/10.19812/j.cnki.jfsq11-5956/ts.20240304008
{DOI}: 10.19812/j.cnki.jfsq11-5956/ts.20240304008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进DeepLabV3+的丘陵田间道路图像分割方法研究
{Author}: 李法霖;石军锋;梁新成;李云伍;刘鹏;陈欣
{Author Address}: 西南大学工程技术学院;
{Journal}: 西南大学学报(自然科学版)
{Year}: 2024
{Volume}: 46
{Issue}: 08
{Pages}: 172-183
{Keywords}: 丘陵道路;机器视觉;场景识别;语义分割;神经网络
{Abstract}: 为解决丘陵地区智能农机装备因道路狭窄、路况复杂导致道路信息提取精度低和推理速度慢等问题，以丘陵田间道路作为研究对象制作数据集，提出一种基于改进DeepLabV3+的丘陵田间道路图像分割方法.首先在编码器模块中使用轻量化的主干网络G＿Ghost＿RegNetX＿4.0GF提取图像特征，保证精度并减小模型参数数量.再采用轻量级的空洞空间金字塔池化模块，将不同尺度特征融合.试验结果表明，改进模型的平均交并比和推理速度分别为87.6%及116.08 f/s,与当前主流图像分割网络FCN、 DeepLabV3及PSPNet相比，MIoU分别提升了0.8%, 2.2%, 1%,推理速度分别为对比网络的1.33, 1.83, 1.76倍.所提模型的参数总量为14.41×10～6,浮点计算量为49.34×10～9,模型参数及计算量大幅减小.改进后的算法具有较高的检测精度和推理速度，有利于解决智能农机装备在丘陵田间道路上行驶的自主导航问题.
{ISBN/ISSN}: 1673-9868
{Notes}: 50-1189/N
{URL}: https://link.cnki.net/doi/10.13718/j.cnki.xdzk.2024.08.016
{DOI}: 10.13718/j.cnki.xdzk.2024.08.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的采摘机械臂控制系统设计
{Author}: 马琰
{Author Address}: 无锡工艺职业技术学院信息中心;
{Journal}: 农机化研究
{Year}: 2024
{Volume}: 46
{Issue}: 12
{Pages}: 208-212
{Keywords}: 采摘机械臂;计算机视觉;卷积神经网络;迁移学习
{Abstract}: 为了提高机械臂采摘的效率及增强安全自主性，提出了一种基于改进卷积神经网络和迁移学习的计算机图像识别模型。首先，建立了由可采摘与不可采摘图像组成的样本数据集，将每幅图像的像素设置为256×256;然后，构建基于改进卷积神经网络和迁移学习的计算机图像识别模型，并将自动编码机网络结构与卷积神经网络运算方法相结合，利用自动编码机网络结构具有编码和解码的环节，通过卷积神经网络运算方式构建出一种改进的卷积神经网络；通过卷积层挖掘图片信息中具有采摘信息的特征，同时消除随机环境对图片的干扰，解码部分能够对特征图像进行上采样并判断是否应该进行采摘与采摘姿势；最后，将构建网络模型与迁移学习相结合进行实验，分析迁移学习方法、数据集样本大小、网络参数对实验结果的影响。结果表明：采摘机械臂识别模型整体识别率更高，能够构建出效率更高、鲁棒性更强的采摘控制系统。
{ISBN/ISSN}: 1003-188X
{Notes}: 23-1233/S
{URL}: https://link.cnki.net/doi/10.13427/j.cnki.njyi.2024.12.020
{DOI}: 10.13427/j.cnki.njyi.2024.12.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的食品瓶罐包装缺陷检测研究进展
{Author}: 陈卫东;刘超;王莹;范冰冰
{Author Address}: 河南工业大学信息科学与工程学院;粮食储运国家工程研究中心;
{Journal}: 粮油食品科技
{Year}: 2024
{Volume}: 32
{Issue}: 04
{Pages}: 185-191
{Keywords}: 机器视觉;包装缺陷检测;图像处理;深度学习
{Abstract}: 根据近年文献资料，介绍了机器视觉技术在食品瓶罐包装缺陷检测上的应用和发展，概述瓶罐包装缺陷检测系统的硬件结构和检测流程；梳理并分析基于图像处理技术和基于深度学习方法在食品瓶罐包装缺陷检测领域取得的研究成果，探讨分类网络模型和目标检测网络模型两种技术在该领域的优势和不足，并对未来的发展进行了展望，为智能瓶罐包装检测的创新和发展提供参考。
{ISBN/ISSN}: 1007-7561
{Notes}: 11-3863/TS
{URL}: https://link.cnki.net/doi/10.16210/j.cnki.1007-7561.2024.04.023
{DOI}: 10.16210/j.cnki.1007-7561.2024.04.023
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的减速机齿轮轴装配及控制系统研究
{Author}: 张春晖
{Tertiary Author}: 李淑娟
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 齿轮轴;机器视觉;机械手;PLC
{Abstract}: 智能产线是现代制造业的核心组成部分,它集成先进的自动化技术、信息技术和人工智能技术,实现生产过程的智能化、柔性化和高效化。智能产线的设计初衷是为满足企业的生产需求,其操作复杂、技术性强,往往需要专业的技术人员进行操作和维护。这种专业性和复杂性使得智能产线对于大多数学生来说,学习门槛较高,难以直接上手操作。齿轮轴是电动机、发电机、减速机等机械装置中广泛应用的零件,用于支撑和传动的机械装置。特别在减速机中,齿轮传动占比达到70%以上。目前的装配过程大部分采用人工加机械工具如吊车等辅助进行装配,劳动强度大,生产效率低,装配一致性较低。随着智能制造与自动化装配技术的快速发展,传统的人工装配手段已无法满足现代制造业对于高精度、高效率、高自动化的要求。论文以西安理工大学智能制造工程专业智能产线实验室的减速机装配背景,设计减速机智能装配产线方案,并提出基于机器视觉的齿轮轴自动装配及控制系统。具体研究内容如下:(1)考虑齿轮轴识别与装配检测需求,设计齿轮轴装配系统模型、齿轮轴识别与控制系统主要装配硬件模块设计。电控采用PLC作为主控制器,PC作为数据处理端,利用基于机器视觉的目标识别与定位技术,结合自动化装配技术,搭建一种基于机器视觉的减速机齿轮轴自动装配系统。(2)齿轮轴的位置信息采用基于YOLOv8的目标检测算法。设计基于改进SAM模型和Imgaug数据增强的齿轮轴数据构建方法。齿轮轴数据集采用人工标注和数据半自动标注结合技术构建齿轮轴数据集,共计1158张图像。在此数据集基础上完成算法的训练与验证,平均检测速度为43.6ms,齿轮轴目标识别率为98%。最大定位误差为0.45,满足齿轮轴检测于定位需求。(3)减速机齿轮轴装配控制系统采用PLC控制齿轮轴自动化装配产线、机械手实现齿轮轴的自动化抓取与装配。并进行视觉相机的参数标定、机械手的运动学建模、电气接线与控制柜布局设计、齿轮轴控制流程设计和人机交互界面设计。通过PLC编程实现机械手的精确运动控制和气动夹爪的协同工作。设计减速机齿轮轴产线控制系统子程序,包括产量统计子程序、系统初始化程序、传送带电机控制程序、安全门控制程序、装配控制系统电路设计等。同时为实现人机交互的教学目的,编写人机交互界面。本文完成对齿轮轴装配系统搭建和相关电气控制接线,对人机交互界面进行验证,并进行齿轮轴自动化装配实验。齿轮轴自动装配成功率为98.9%。装配结果检出成功率为96%以上,装配结果平均检出率为97.25%。装配平均效率为10.49秒/台,验证了仿真结果的准确性。在长时间工作的情况下,系统报警与故障处理功能可靠,能够及时处理和解决产线运行过程中出现的各种问题,保证产线的稳定和学生的人身安全。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000527
{DOI}: 10.27398/d.cnki.gxalu.2024.000527
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的弱监督图像语义分割方法研究
{Author}: 董莹
{Tertiary Author}: 赵明华
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 弱监督语义分割;显著性图;注意力机制;Vision Transformer;自对应蒸馏
{Abstract}: 语义分割是一项重要的计算机视觉任务,其目标是将图像中的每个像素分配到对应的语义类别,从而实现对图像像素级别的理解和分割。该任务在许多领域都有广泛的应用,包括但不限于自动驾驶、医疗诊断和农业灌溉。但由于全监督语义分割所需的像素级别标注信息会造成人力成本及时间成本的极大浪费,因此人们开始研究弱监督语义分割。弱监督语义分割是在缺乏精确像素级标注的情况下,通过合理利用其他形式的标注信息,实现对图像语义信息的有效分割。目前,弱监督语义分割实现流程一般为:首先根据分类网络与类别标签生成类别激活图,然后将类别激活图转化为伪标签,进一步训练全监督语义分割网络进而得到分割结果。但由于分类任务与分割任务存在本质区别,导致通过分类网络生成的类激活图只能激活最具有判别性的区域,因此,为了实现分割精度的提升,改善类激活图质量是最关键的一步。具体来说,存在两个方面的挑战:(1)类别标签仅含有类别信息而不包括位置信息导致类激活图激活区域不完整、不准确;(2)两阶段弱监督方法复现难度大,效率低。基于以上问题,本文在公共数据集PASCAL VOC 2012和MS COCO上,结合显著性图和Transformer 网络展开研究,旨在突破弱监督语义分割任务存在的难点与挑战。具体研究概括如下:(1)针对类别标签标注信息有限所导致的类激活图不完整、不准确问题,本文提出了基于显著性图与注意力机制的弱监督语义分割方法。该方法利用显著性图作为辅助监督信息,提供目标对象标注边界并结合图像级标签提供的类别信息,利用特征融合策略和注意力机制来增强类激活图的细节纹理信息进而提升语义分割性能。通过在两个公共数据集进行实验验证,并与其他先进的弱监督方法比较,实验结果表明:本文提出的方法可以有效提高类激活图的准确性并且使其具有完整的边界,在丰富语义信息同时保留纹理信息;在定量方面提高了语义分割的精度。(2)针对弱监督语义分割两阶段方法难以复现、效率低且类激活图不完整等问题,本文提出一种基于Vision Transformer与自对应蒸馏机制的端到端弱监督语义分割方法。该方法构建了自对应蒸馏网络,通过约束仿射变换后的类激活图与原图的类激活图含有相同的语义标签,使类激活图激活的目标区域更加完整。此外,利用Vision Transformer网络作为主干特征提取网络实现端到端的分割,提升最终分割精度的同时提高运行速度。通过在PASCAL VOC 2012数据集验证,并与其他先进的两阶段和端到端弱监督方法比较,实验结果表明:所提出方法可以实现与多阶段方法相媲美的分割精度,同时运行速度也得到了提升。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001033
{DOI}: 10.27398/d.cnki.gxalu.2024.001033
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于目标运动与外观特征的多目标跟踪算法研究
{Author}: 刘前花
{Tertiary Author}: 黑新宏;赵金伟
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 多目标跟踪;轨迹混淆;轨迹断裂;遮挡;轨迹丢失
{Abstract}: 随着社会的发展和科技的进步,智能监控、自动驾驶、无人机配送等领域对于多目标跟踪的需求日益增加,多目标跟踪算法在计算机视觉和人工智能领域,逐渐成为备受关注的应用热点之一。同时,面对社会需求、技术攻关和科学探索等方面不断增长的严峻挑战,现有多目标跟踪算法存在无法解决复杂场景中目标被其他物体遮挡或遮蔽而导致目标轨迹混淆、轨迹断裂,以及跟踪过程中目标长时间消失导致跟踪丢失等问题,导致准确的目标检测和跟踪变得困难。因此,本文总结并分析了多目标跟踪任务中遇到的三个挑战,并针对这些挑战提出了对应的解决方案,具体研究内容如下:(1)针对多目标跟踪算法跟踪过程中因目标相互接近导致其轨迹混淆的问题,即算法错误地将一个目标的身份标记为另一目标,本文提出了基于重匹配机制的多目标跟踪算法。该算法将第一次匹配过程中未匹配成功的高分检测框再次利用,与低分检测框一起参与第二次匹配,以提高高分检测框的成功匹配机率。这种策略可以增加高分检测框匹配的可能性,并且为高分检测框提供多种匹配机制,以降低漏检率。最后,通过实验验证了本算法在解决轨迹混淆问题方面的有效性。此外,通过在Mot17和Mot20标准数据集上与众多先进算法进行对比实验验证了该算法的跟踪性能。(2)针对多目标跟踪算法匹配过程中因目标被遮挡导致其轨迹断裂的问题,即被遮挡的目标被初始化一个新的轨迹,本文提出了基于特征匹配与校正的多目标跟踪算法。该算法提取第一次未匹配成功轨迹的预测框与低分检测框的嵌入特征以增强特征区分能力,并计算嵌入特征间的相似度。针对长时间未匹配成功的轨迹的预测框的特征可信度下降的问题,提出了基于未匹配时长的可信度计算方法,并用该可信度校正相似度,以强化同一目标在不同帧之间的连贯性,从而减少目标被遮挡导致其轨迹断裂的问题。最后,通过实验验证了本算法在解决轨迹断裂问题方面的显著优势。此外,该算法在Mot17和Mot20标准数据集上与多个先进算法进行对比实验验证了该算法的跟踪性能。(3)针对多目标跟踪算法跟踪过程中目标长时间消失导致跟踪丢失的问题,即当监测对象因遮挡或短暂离开视野等原因而从画面消失且未在一段时间内重新出现,导致跟踪算法无法继续准确定位和跟踪该对象。本文提出了基于动态目标匹配策略的多目标跟踪算法。该算法综合考虑了短期关联内IOU交并比的重要性和长期关联中特征匹配的关键性,针对剩余的检测框与轨迹,通过基于gate机制的动态目标匹配策略实时更新gate值,从而灵活地调整检测框与轨迹之间的关联方式,达到更为准确的跟踪匹配。最后,通过实验验证了本算法在解决长时间消失导致跟踪丢失问题方面的优势。此外,该算法在Mot17和Mot20标准数据集上与多个先进算法进行对比实验验证了该算法的跟踪性能。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.001178
{DOI}: 10.27398/d.cnki.gxalu.2024.001178
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的灌区水面漂浮物检测方法研究与应用
{Author}: 刘中胜
{Tertiary Author}: 李军怀;吴波
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 水面漂浮物;深度学习;水域分割;目标检测;灌区监测
{Abstract}: 随着工农业的快速发展,水资源的污染问题日益凸显,灌区作为农业生产的重要组成部分,其水资源的保护和管理显得尤为重要。现有监测方法主要是通过图像识别方法来实现灌区水域环境智能化、自动化监测。然而,水面环境的多变性使其图像通常表现出光照不均、阴影遮挡和噪音干扰等特点,增大了对水面漂浮物的检测难度。本研究针对灌区环境保护中水面漂浮物检测遇到的问题,提出一种基于深度学习的水域分割以及水面漂浮物检测方法,并将其应用于灌区水域监测平台中。主要研究内容如下:
(1)针对河岸农田植被、阴影遮挡和阳光反射等环境因素之间的边界像素相似性导致的水域边界模糊的问题,本文提出了一种结合边缘特征的双分支结构水域分割方法。主体采用了双分支下采样结构,并设计了交换注意力机制对空间细节分支特征和语义分支特征进行融合,保证模型推理速度的同时提高分割性能。此外,使用传统的边缘检测算法辅助训练,在特征细化模块中加入更多的边缘数据以融合边缘特征,在不降低推理速度的前提下,有效地增强了特征表示。该方法在自制数据集上的实验结果表明,平均交并比(mean Intersection over Union,m Io U)和边界均方根误差(Root Mean Square Error,RMSE)分别达到了96.1%和0.78。
(2)针对灌区水面环境监测场景中边缘设备计算能力不足,实时高效运行目标检测模型存在困难,本文对YOLOv5n模型进行轻量化改进,提出一种基于Mobile Vi T的轻量化水面漂浮物检测方法。首先,在特征提取阶段中利用对边缘设备友好的Mobile Vi Tv3模块捕获全局和局部信息;然后,在颈部网络中借鉴双向金字塔结构(Bi-directional Feature Pyramid Network,Bi FPN)思想改进特征融合过程,提高多尺度语义特征的利用率,减少了不同尺度特征融合之间的冲突,并且采用轻量化的GSConv(Ghost Shuffle Conv)结构代替传统的卷积以减少模型参数;最后,利用了一个带有动态聚焦机制的边界框回归损失函数,提高模型的收敛速度和检测精度。在本文自建数据集上进行一系列的对比实验,改进算法的平均精度(mean Average Precision,m AP)达到84.5%,比YOLOv5n模型提高了5.9%精度的同时参数量和计算复杂度分别降低了21.3%和11.4%。
(3)基于上述研究,将本文设计的模型部署在边缘设备,开发了一套智慧灌区监测平台,实现基于边缘计算的灌区水域污染物智能监测。该平台采用微服务架构,保证了系统的可扩展性和高可用性。同时,平台能够实时监测和分析数据,为灌区管理者提供直观的操作界面和决策支持,实现了灌区的智能化管理。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2024.000221
{DOI}: 10.27398/d.cnki.gxalu.2024.000221
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于嵌入式机器视觉的流水线分拣机器人设计
{Author}: 刘建文;沈瑞琳;马世登;林瑾
{Author Address}: 广东东软学院;
{Journal}: 计算技术与自动化
{Year}: 2024
{Volume}: 43
{Issue}: 02
{Pages}: 17-23
{Keywords}: 流水线分拣机器人;深度学习;机器视觉;嵌入式系统
{Abstract}: 针对传统流水线上人工错误率高、速度慢和人工成本高的问题，设计了一种深度学习的流水线智能分拣机器人来缓解流水线的压力。该机器人采用分层结构设计，上位机采用Jetson Nano来完成机器人的图像采集、识别和处理，下位机由STM32G0作为主控，通过舵机和电机实现机器人的功能控制。同时上位机与下位机之间进行有效的数据交互，实现了机器人的抓取和分拣协调工作。在实验测试中，该机器人能够通过学习样本实现自动分拣不同类型的对象，并且能够精确识别。该流水线分拣机器人融入了计算机视觉与嵌入式系统，不仅使分拣机器人结构更紧凑，而且有利于提高社会生产力水平，具有良好的应用前景。
{ISBN/ISSN}: 1003-6199
{Notes}: 43-1138/TP
{URL}: https://link.cnki.net/doi/10.16339/j.cnki.jsjsyzdh.202402003
{DOI}: 10.16339/j.cnki.jsjsyzdh.202402003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的导盲杖设计
{Author}: 高勇;陈凯文;张城;黄淼
{Author Address}: 重庆移通学院通信与信息工程学院;
{Journal}: 河南科技
{Year}: 2024
{Volume}: 51
{Issue}: 12
{Pages}: 24-29
{Keywords}: 图像识别;卷积神经网络;智能导盲杖;模块化设计
{Abstract}: 【目的】为了满足视障人士多方面的实际出行需求，设计了一款基于机器视觉的导盲杖。【方法】该系统整体为模块化设计，采用了STM32F407VET6单片机和边缘智能计算K210芯片为核心。其机器视觉功能是利用神经网络和YOLOv2算法训练建立起模型，并对摄像头拍摄到的实时图像进行检测而实现的。系统自身具备陀螺仪姿态角度测量功能，通过判断系统旋转角度是否达到设定阈值，以此来判断使用者是否有摔倒迹象；系统还具有GPS定位功能，在突发情况下系统会通过串口发送AT指令控制GSM模块向紧急联络人发送位置信息。【结果】该系统各个功能经模拟测试，其机器视觉功能检测的正确率达到99%以上；姿态角度测量误差维持在1°以内；GPS和GSM功能可以定位并发送短信息。【结论】该系统的功能可满足视障人士基本的实际出行需要。此外，图像检测模型的建立，可为今后训练模型以检测更多物体，完善机器视觉功能，应对更多实际出行的情况。
{ISBN/ISSN}: 1003-5168
{Notes}: 41-1081/T
{URL}: https://link.cnki.net/doi/10.19968/j.cnki.hnkj.1003-5168.2024.12.005
{DOI}: 10.19968/j.cnki.hnkj.1003-5168.2024.12.005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂道路场景下的交通目标检测和分割的研究
{Author}: 夏文俊
{Tertiary Author}: 李其朋
{Publisher}: 浙江科技大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 深度卷积神经网络;目标检测;实例分割;YOLO;自动驾驶
{Abstract}: 自动驾驶是集成机器视觉、传感器融合和人工智能等方法以实现车辆自主行驶功能的技术。它可以提升驾驶体验、减少交通拥堵、保障道路安全和提升交通效率等。环境感知系统为自动驾驶汽车的决策规划和控制系统提供必要的场景环境信息,是支撑自动驾驶的关键技术保障。随着深度学习的快速发展,深度卷积神经网络以其强大的特征提取能力、高效的运算方式、轻量化的网络和端到端的简易训练方式在包括自动驾驶在内的各个领域得到了广泛的应用,其中基于深度卷积神经网络的目标检测和实例分割在自动驾驶的环境感知领域中扮演着越来越重要的角色。本文针对自动驾驶在复杂道路场景下的目标检测和实例分割任务进行深入研究,并提出了:(1)一种基于锚边框的一阶段的交通目标检测方法本文针对在自动驾驶环境中车载移动平台算力资源有限、小目标检测精度低、漏检率高及检测实时性较差的问题提出了一种改进YOLOV5-S的单阶段目标检测算法TTD-YOLO(Traffic Target Detection-YOLO),该算法主要在四个方面进行了改进:通过使用改进的M-ELAN模块提升模型的多尺度特征提取性能;在网络结构中添加3D注意力机制SimAM来让网络能够高效率的学习重要的特征信息;在保证模型复杂度的条件下,通过调节骨干网络和特征融合结构中CSPLayer模块的输出通道数和堆叠次数将骨干网络和特征融合结构部分的参数比例调整为接近1:1,据实验证明在不改变网络结构的情况下,提升特征融合结构部分的参数比例有助于提升检测精度;将边界框损失函数替换为EIoU损失,加速网络收敛。与基准模型相比,本文提出的模型参数量降低了8.6%,平均精度(mAP@.5:.95)提高了2.5%,在相同实验平台下的推理速度提高了4.8%。(2)一种遵从自顶向下范式的交通实例分割方法复杂道路场景下的交通目标的实例分割是自动驾驶领域最具挑战性的任务之一。实例分割采用实例感知掩码来分割具有边界的对象,不同于目标检测的包围框定位和语义分割的类别感知掩码,实例分割不仅需要准确分辨每个类别下的每个物体,还需要对这些目标物体进行更精确的分割定位,相比于目标检测和语义分割更加困难。尽管实例分割有着明显的优势,但针对复杂道路场景下的实例分割方法仍然有待发现。本文基于YOLOV5-7.0提出一种针对复杂道路场景下的交通目标分割的高效的实例分割方法TTIS-YOLO。本文的主要工作如下:提出一种MECSP(Multiscale Efficient Cross Stage Partial Network)模块,该结构具有更少的参数、更好的跨层信息交流和特征表示能力;提出一种高效的双向跨尺度连接(Efficient Bidirectional Cross Scale Connection)优化方法,让网络在不丢失原有信息的情况下进行更细致高效的特征融合,细化掩码流;使用WIoU损失作为定位和分割损失函数,通过动态分配梯度增益的策略有效提高模型的定位性能。与基线模型相比,本文提出的方法提升了分割精度,最终平均精度的值为27%,且模型参数量减少了35.4%,推理速度提升18.9%。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2024.000288
{DOI}: 10.27840/d.cnki.gzjkj.2024.000288
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV和YOLOv5的车道线检测与识别
{Author}: 卢嫚;朱世博
{Author Address}: 西安工程大学电子信息学院;
{Journal}: 国外电子测量技术
{Year}: 2024
{Volume}: 43
{Issue}: 06
{Pages}: 134-142
{Keywords}: 车道线检测与识别;目标识别;OpenCV;Canny算子;YOLOv5
{Abstract}: 为更加快速、准确识别汽车行驶区域并区分车道，实现无人驾驶，提出一种结合视觉OpenCV算法和改进YOLOv5算法的目标检测跟踪模型进行车道线检测的方法。在图像预处理阶段，首先读取视频图像，把每一帧RGB图像转为灰度图，通过Canny算子对图像的边缘轮廓进行提取，然后绘制车道线的掩码区域，并与边缘检测结合，采用ROI技术提取感兴趣区域，最后进行概率霍夫变换和最小二乘拟合，将得到的直线绘制到原图像中，最终对每一帧处理后的图像进行输出。目标识别模块采用卷积神经网络(convolutional neural network, CNN)深度学习方法及YOLOv5算法进行目标识别处理。实验结果表明，所提检测算法能够实现准确的车道线检测，实时性和准确性比传统算法高很多，且该方法具有良好的鲁棒性。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2305844
{DOI}: 10.19652/j.cnki.femt.2305844
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于电子鼻和机器视觉的鱼肉新鲜度检测研究
{Author}: 袁也;周博;吴泽玮
{Author Address}: 盐城工学院机械工程学院;
{Journal}: 食品与发酵工业
{Year}: 2024
{Volume}: 50
{Issue}: 24
{Pages}: 313-320
{Keywords}: 鱼肉新鲜度;电子鼻;机器视觉;数据融合;神经网络
{Abstract}: 为了提升鱼肉新鲜度检测的准确率，该研究采用了电子鼻、机器视觉和多数据融合技术快速地检测冷藏鱼肉的新鲜度。挥发性盐基氮含量与新鲜度密切相关且易于测量，因此被选定作为鱼肉新鲜度的指标；用机器视觉和电子鼻获取样品的图像和气味信息。应用反向传播神经网络、卷积神经网络(convolutional neural network, CNN)和卷积神经网络-门控循环单元-注意力(CNN-GRU-Attention)3种模型对鱼肉新鲜度进行3分类和7分类预测。结果表明，3分类和7分类实验中，3种模型利用电子鼻数据进行分类的效果均优于机器视觉方法。此外，对原始数据进行融合后，3个模型的分类准确率均有提升。特别是基于CNN-GRU-Attention模型的多感官数据融合方法在本次研究中效果最优，其在测试集上的准确率分别达97.61%和90.48%。研究结果表明，采用多感知检测技术结合CNN-GRU-Attention预测模型能够有效地提高鱼肉新鲜度检测的准确性。
{ISBN/ISSN}: 0253-990X
{Notes}: 11-1802/TS
{URL}: https://link.cnki.net/doi/10.13995/j.cnki.11-1802/ts.039633
{DOI}: 10.13995/j.cnki.11-1802/ts.039633
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 恶劣光照下注意力嵌入的图像增强方法研究
{Author}: 尚晓可
{Tertiary Author}: 张韶岷;丁彧
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 恶劣成像条件;图像增强;曝光校正与融合;注意力机制;深度神经网络
{Abstract}: 恶劣光照条件下(曝光不足、曝光过度、暗光环境等)获取的图像往往存在低对比度、强噪声、颜色失真等一系列视觉降质问题,给人类及各种计算机视觉系统精确感知复杂环境带来了严峻挑战。因此,在恶劣光照条件下实现高质量图像增强,是全天候场景下视觉感知与认知的基础性关键问题,目前已经成为人工智能、计算机视觉、多媒体等领域的研究热点。近年来,以神经网络为代表的深度学习技术极大地推动了人工智能相关领域的发展,基于神经网络的图像增强技术也随之大量涌现。然而,现有的图像增强方法难以使用统一方式对恶劣光照条件下不同的降质因素和数据类型进行有效处理;依赖手工的图像增强网络结构设计以及训练数据构建方式在真实恶劣光照条件下面临严峻挑战;图像增强过程中还缺乏对高层视觉语义和感知目标的充分考虑与有效建模。本文针对既有图像增强方法存在的上述问题,以模拟人类视觉系统“注意力”现象的注意力学习机制为核心技术手段,开展图像增强方法研究,主要贡献点总结如下:1.面向曝光校正与融合的图像增强方法:针对恶劣成像条件下存在的曝光不足(欠曝光)、曝光过度(过曝光)等多种不同图像降质因素,提出了基于频域注意力学习机制的图像曝光校正增强方法。首先基于Transformer网络在频域空间设计了全局注意力模块与动态选择网络,实现了图像全局特征高效提取并进行多频段动态选择。进一步,将该频域计算模块与拉普拉斯金字塔图像分解策略结合,构建了降质图像的多尺度频域特征联合增强模型。最后,通过引入基于卷积的融合模块,成功将该方法扩展应用于多幅不同曝光图像的融合增强。2.图像增强的网络结构搜索与训练数据生成:首先针对手工设计网络模型依赖大量复杂工程化调优技巧的局限,提出了面向图像增强的网络结构搜索(自动设计)方法。构建了结合注意力机制与Retinex原理的图像增强基础网络模型。针对该模型中涉及的光照优化、注意力生成、噪声去除三个模块构建了层次化的联合搜索空间以及计算时延约束的搜索策略,实现了轻量化与高效率的网络结构自动设计。进一步,提出了深度图引导的暗光图像生成方法,解决了恶劣成像条件下难以获取高质量监督数据(降质-清晰图像对)的图像增强训练挑战。3.有机结合视觉语义的图像增强方法:针对现有图像增强方法难以充分利用视觉语义等高层信息的问题,首先设计了结合注意力机制的渐进式图像增强残差网络模型,通过引入预训练的图像显著性特征提取网络作为注意力生成模块,实现了基于显著性特征的语义注意力引导图像增强。进一步,为图像增强与语义理解两类不同视觉任务分别设计了图像结构补偿与上下文语义补全的注意力模块,在此基础上设计了两阶段的联合训练损失函数,最终构建了有机结合图像增强与语义理解目标的视觉感知协同学习策略。本研究以注意力学习机制为核心技术手段,提出了面向恶劣光照条件的图像增强系列方法。研究工作不仅有效解决了真实复杂场景下视觉感知的可视效果提升难题,也为人工智能、计算机视觉等相关领域提供了新的算法研究思路。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2024.000299
{DOI}: 10.27461/d.cnki.gzjdx.2024.000299
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的工业缺陷检测模型研究
{Author}: 李兆国
{Tertiary Author}: 姜雪松
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 工业缺陷检测;深度学习;一阶段模型;特征提取;特征融合
{Abstract}: 在工业生产制造过程中,缺陷检测扮演着至关重要的角色。缺陷检测任务涵盖了定位缺陷位置和识别缺陷类别两个方面。工业缺陷通常具有复杂的特征纹理,并且缺陷类别多样(如裂缝、划痕等),这无疑增加了检测任务的难度和挑战性。使用人工进行缺陷检测难以分辨缺陷类别,并且检测成本较高。而基于传统机器学习的缺陷检测方法依赖于人为设计特征,难以胜任复杂场景下的缺陷检测任务。随着深度学习技术的快速发展,基于深度学习的工业缺陷检测模型得到广泛研究。基于卷积神经网络的深度学习模型具有强大的特征映射能力,能够更有效地表达缺陷特征。
本文进行基于深度学习的工业缺陷检测技术研究,旨在实现检测精度更高、鲁棒性更强、泛化性更好的模型。首先,本文提出了一种轻量级的一阶段工业缺陷检测模型。该模型实现了具有竞争力的检测效果,但是该模型未对微小缺陷检测及多尺度缺陷检测做出针对性改进。因此,本文针对微小工业缺陷检测,以PCB缺陷检测为例,提出了一种基于微小缺陷融合网络的PCB缺陷检测模型。其次,本文针对多尺度缺陷检测,以钢铁缺陷检测为例,提出了一种基于多尺度特征提取的钢铁缺陷检测模型。最后,本文完成了工业缺陷检测系统的设计与实现。本文的具体研究内容如下:
(1)针对工业缺陷检测模型存在的特征提取及特征融合能力不足等问题,提出了一种轻量级的一阶段工业缺陷检测模型。首先,本研究设计了具有双分支的解耦头结构,解决耦合头可能引发的空间错位问题,并促进模型训练。其次,设计了具有更强非线性结构的Bottleneck模块,以提升模型提取缺陷特征的能力。最后,引入了注意力增强特征融合模块,通过可学习权重的自适应加权特征融合,增强了模型的特征融合效果。在三个公开的缺陷检测数据集,即Deep PCB数据集、NEU-DET数据集和NRSD-MN数据集上进行了实验。实验结果表明,所提出的模型取得了具有竞争力的检测结果。
(2)针对现有模型在微小缺陷检测方面存在较高漏检率的问题,以PCB缺陷检测为例,提出了一种基于微小缺陷融合网络的PCB缺陷检测模型。首先,本研究设计了高效微小缺陷融合网络,以增强模型对PCB缺陷位置的感知能力。其次,本研究在模型的头部网络中引入了一个微小缺陷检测头,该检测头利用分辨率更大的特征图中更清晰的位置信息来检测PCB的微小缺陷。通过在PCB缺陷检测数据集(Deep PCB)上进行的实验,证明了所提出模型的有效性。
(3)针对工业缺陷检测易受到多尺度缺陷及缺陷复杂纹理影响的问题,以钢铁缺陷检测为例,提出了一种基于多尺度特征提取的钢铁缺陷检测模型。首先,为了提高模型的特征提取能力,设计了多尺度特征提取模块。然后,引入了一种高效的特征融合模块,通过将模型主干网络的特征添加到颈部网络,优化了模型的特征融合过程。其次,本文通过减少原Bottleneck模块中的归一化层和激活函数,减轻了模型对数据的过度拟合。最后,加深了模型的主干网络,进一步增强了模型的特征提取能力。通过在钢铁缺陷检测数据集(NEU-DET)上进行的实验,验证了本文提出的模型在钢铁缺陷检测方面取得了良好的效果。
(4)本文利用Py Qt5等技术设计并实现了工业缺陷检测系统。该系统的主界面共包含四个区域,包括待检测区、检测结果区、详细信息区、用户操作区。系统具备模型权重文件选择功能,可满足不同的使用需求。此外,所设计的系统还实现了多种检测模式,包括图片检测、视频检测和基于摄像头的实时检测,具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000307
{DOI}: 10.27278/d.cnki.gsdqc.2024.000307
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的道路车辆检测算法的研究
{Author}: 芦山
{Tertiary Author}: 刘丽娟;周宏伟
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 目标检测;YOLOv5;低照度;解耦头;GhostNet
{Abstract}: 在计算机视觉领域,道路车辆检测是一项关键的任务,目标是从图像或视频中识别出道路上的车辆。这个任务在自动驾驶、交通监控以及智能交通系统等多个领域都有广泛的应用。在光线不充足情况下进行车辆检测会导致许多车辆目标被忽略,增加了许多交通事故的风险。因此,对于低照度的车辆检测算法研究尤为重要。在智慧交通中,低照度的道路车辆检测对于城市的交通管理和安全监控等方面也至关重要,因此,研究在光线不充足的情况下的车辆检测具有重要的意义和广泛的应用前景。针对低照度车辆检测场景中可能存在的一系列问题,本文对其中两部分进行研究,其一是问了有效缓解低照度场景下存在的检测效果差、误检和漏检等情况;其二是为了缓解检测效率低下的问题,并设计和实现了一个车辆检测系统。本文提出了两种改进的低照度目标检测方法,并设计和实现了一种针对低照度场景的车辆检测系统。具体而言,本文的研究工作主要围绕以下几个方面展开:(1)提出了基于YOLOv5-CDT的低光照环境下的车辆检测算法,该算法通过引入注意力机制CBAM来增强网络特征提取能力。针对上采样这一步骤上,本文使用了转置卷积来代替原始的最邻近插值法进行上采样操作。此外,为了缓解分类和定位任务在根本目标上的冲突,本文引入了YOLOX中的解耦头,并对其进行轻量化的处理。在损失函数方面,本文采用EIo U代替CIo U,进一步提升了精度。最后在自制的夜间车辆数据集上进行了验证,其中m AP@0.5提升了5.3%,m AP@0.5:0.95提升了4.1%,验证了算法的可行性。(2)提出了基于YOLO-GGS的轻量级检测算法。首先,使用多尺度MSR算法对数据进行预处理,增强黑夜图片的表现力,以降低漏检率。接下来,采用Ghost Net轻量级网络对主干网络进行重构,以增强模型的特征提取能力,在颈部使用轻量化GSConv替换原始卷积,增加精确度,并且减少模型复杂度。最后,在公开数据集Ex Dark以及自制数据集上进行实验,结果表明YOLO-GGS算法的可行性。(3)基于上述算法,本文设计和实现了一种基于Py Qt5的黑天车辆检测系统。该系统能够在光线不充足的条件下实现车辆监控和识别,兼顾了高精确度和高效率,满足现实场景中应用的使用需求。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2024.000377
{DOI}: 10.26990/d.cnki.gsltc.2024.000377
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的苹果外部品质检测与分级研究
{Author}: 仇德凯
{Tertiary Author}: 胡栋
{Publisher}: 浙江农林大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 苹果;外部品质;图像处理;机器视觉;深度学习
{Abstract}: 苹果品质分类对于提高苹果的商业价值尤为重要。目前,运用机器视觉并结合深度学习进行苹果质量分类的研究已经很多。但是,这些研究都主要集中在品种、外部损伤和颜色的分类上,对苹果果形,即畸形程度的研究还很少。本研究基于机器视觉技术,探讨了卷积神经网络对苹果果径、颜色和畸形特征进行分类的可行性。主要研究内容和结论如下:
(1)本研究搭建了一套机器视觉系统用于动态采集苹果多角度图像,并对系统进行了校正以及确定图像采集的方式。该系统相较于传统机器视觉系统多了一个旋转台,用于在采集图像时使苹果能够均匀地旋转,对系统硬件进行了优选和布置,并对软件控制部分进行了研究。然后对已搭建的系统进行校正,使用棋盘格对系统进行了相机标定,通过实验发现经过相机标定方法进行校正前后的图片提取出的硬币以及多个特氟龙球的直径误差均在0.5 mm以内,符合国家要求的苹果果径误差范围,所以后续不要进行相机标定;接着通过使用麦克白色卡进行了颜色校正,发现校正前的最大色差值为20.9,校正后为13.4,校正后的图像色彩更接近真实颜色,所以后续需要对苹果图像进行颜色校正。接着,本研究采用四个形状不同的洛川苹果,通过12种不同的采集方式对苹果进行图像采集,最终本研究选取了图像尽可能少且苹果最大直径误差在0.5 mm以内的方式,即8°/张的拍摄方式对苹果进行图像采集。
(2)本研究确定使用合适的图像处理方法提取出每个苹果果径最大的图像用于建立数据集,并使用SVM分级方法对苹果进行分级建模。通过实验确定了图像灰度化使用加权平均法,图像去噪使用高斯滤波去噪,并使用图像二值化、形态学降噪等方法可以很好的去除苹果图像的背景,最后使用最小外接矩形的方法对苹果每张图像进行了最大果径的提取,可以精确地提取出每个苹果果径最大的图片。然后采集了1000个苹果图像用于对苹果颜色和畸形特征建立数据集,对数据集中的图像使用HOG特征提取方法提取特征值,随后使用SVM方法对苹果颜色和畸形特征进行分级建模,并选择了效果最佳的多项式作为核函数,最终其在训练集和测试集的分类准确率分别达到了91.3%和89.0%。
(3)对苹果果径、颜色和畸形特征建立深度学习分级模型。对苹果果径分级建立了一个包含5个卷积层和1个全连接层地轻量级卷积神经网络模型,对该模型中的激活函数、学习率和批大小这三个超参数进行了优选,最终确定以Re LU作为核函数,学习率设置为0.001,批大小设置为128,该模型在验证集和测试集上准确度都达到了98%以上,数据表明该模型可以较好地完成苹果果径分级任务。然后使用VGG16、Goog Le Net和Alex Net这三种经典卷积神经网络模型对苹果颜色和畸形特征进行三分类,通过实验发现使用VGG16进行分类的结果最好,达到92.29%。条红苹果、片红苹果和畸形苹果的召回率分别为96.9%、96.9%和82.7%。然后在VGG16模型上进行了消融实验,VGG16模型中的卷积块都是模型特征提取部分的重要组成部分。使用VGG16对200个苹果进行了预测,预测准确率为90.5%。
{URL}: https://link.cnki.net/doi/10.27756/d.cnki.gzjlx.2024.000176
{DOI}: 10.27756/d.cnki.gzjlx.2024.000176
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于扩散模型的小目标检测算法的研究与实现
{Author}: 张倩鸽
{Tertiary Author}: 马华东
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 小目标检测;扩散模型;多阶段特征融合;瓶颈注意力机制
{Abstract}: 在计算机视觉领域中,目标检测占据着至关重要的位置,它对于自动驾驶、无人机检测以及机器人视觉的推动起着至关重要的作用。目前,目标检测方面已经取得了大量的研究成果。然而,小目标的检测仍面临着一系列挑战,比如信息量少、易被噪声干扰、收敛速度慢等,这使得它们难以被准确检测。针对小目标检测这一难题,本文提出了一个基于扩散模型的小目标检测算法,主要贡献如下:针对小目标信息量少的问题,本文设计了多阶段特征融合机制,从更细微的层次上合并了特征图的信息。此外,通过在扩散模型的骨干网络中加入门控卷积单元,增强了对小尺寸目标检测点的感知能力,有效缓解了对小目标的漏检和误检。针对小目标容易被背景噪声干扰的问题,本文在扩散模型的瓶颈部分引入注意力机制,专注于筛选出关键的特征信息,提高了模型对基础特征的关注力。针对小目标损失函数收敛速度慢的问题,本文提出了 VIoU损失函数,通过重新设定惩罚指数并考虑回归向量的角度差异,实现了对小目标更准确的定位与回归。本文通过对比实验和消融分析,结果表明了基于扩散模型的算法相较于现有方法在准确率上具备优势。此外,本文还基于上述算法实现了一个小目标检测原型系统,以验证本文方法的有效性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2024.002436
{DOI}: 10.26969/d.cnki.gbydu.2024.002436
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5的田间复杂环境障碍物检测
{Author}: 杨昊霖;王其欢;李华彪;耿端阳;武继达;姚艳春
{Author Address}: 山东理工大学农业工程与食品科学学院;
{Journal}: 中国农机化学报
{Year}: 2024
{Volume}: 45
{Issue}: 06
{Pages}: 216-222+256+2
{Keywords}: 农业机器人;农田障碍物检测;改进YOLOv5;图像处理;机器视觉
{Abstract}: 为实现田间复杂环境下农业机器人自主导航作业过程中障碍物快速检测，提出一种基于改进YOLOv5的田间复杂环境下障碍物检测方法。建立包含农业机械、人、羊三类目标障碍物共计6 766张图片的农田障碍物数据集；通过k-means聚类算法生成最佳先验锚框尺寸；引入CBAM卷积块注意力模块，抑制目标障碍物周围复杂环境的干扰，增强目标显著度；增加一个检测头，跨层级连接主干特征，增强多尺度特征表达能力，缓解标注对象尺度方差带来的负面影响；使用Ghost卷积替换Neck层中普通卷积，减少模型参数，降低模型复杂度。改进后的模型比YOLOv5s基准模型检测精度提高2.3%,召回率提高3.1%,精确率提高1.9%,参数量降低7%左右，为无人农业机械自主作业过程中导航避障的研究提供技术参考。
{ISBN/ISSN}: 2095-5553
{Notes}: 32-1837/S
{URL}: https://link.cnki.net/doi/10.13733/j.jcam.issn.2095-5553.2024.06.032
{DOI}: 10.13733/j.jcam.issn.2095-5553.2024.06.032
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 移动机器人的视觉检测与目标跟踪技术研究
{Author}: 苏庆森
{Tertiary Author}: 张艳芳
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 移动机器人;视觉检测;目标跟踪;YOLOv5
{Abstract}: 随着人工智能技术的快速发展,移动机器人在工业物流领域的需求不断增长,具有视觉感知和目标跟踪性能的移动机器人应用场景越来越广泛。然而在实际应用中,存在目标遮挡、尺度变化等因素导致的检测性能不高,以及目标快速移动等造成的跟踪鲁棒性差问题。本文基于深度学习的视觉检测技术,通过优化网络结构,提高目标检测性能,并在此基础上对目标跟踪算法进行研究,利用基于ROS的Turtle Bot移动机器人进行算法移植和实验分析,实现移动机器人高精度目标识别和稳定跟踪。主要研究工作如下:
(1)针对目标尺度变化、遮挡以及小目标分辨率低造成的误检、漏检等问题,对基于深度学习技术的检测算法进行了研究,在YOLOv5s的基础上增加小目标检测层,丰富特征信息,增强多尺度检测能力。基于Bi FPN网络结构,对YOLOv5s的特征融合进行改进。通过将主干网络中的浅层特征融入到检测层的深层特征,实现横向跨尺度融合方式,增强检测层中的目标信息,进一步提高检测性能。通过引入Soft＿NMS后处理方法改进YOLOv5s,利用DIo U算法改进Soft＿NMS的衰减方式,计算目标与被遮挡目标之间的重叠率,有效解决目标之间的遮挡问题。通过公开数据集进行模型训练,m AP.5和m AP.5.95相对于原始网络模型分别提升1.5%和6.1%,平均精度达到88%。
(2)针对传统跟踪算法的尺度适应性、跟踪鲁棒性等问题,对四种常用的相关滤波跟踪算法进行了研究,通过数据集进行了对比实验,验证算法的跟踪性能。针对目标遮挡或者模板漂移造成的目标丢失问题,引入目标丢失判别方法,提出了一种基于改进YOLOv5s模型的ECO-HC重检测跟踪方法,实现目标丢失后重新跟踪的功能,提高目标跟踪的稳定性和鲁棒性。
(3)利用Turtlebot2移动机器人和Kinect v2深度相机搭建硬件平台,将改进后的视觉检测与目标跟踪算法部署到Turtlebot2移动机器人。在ROS框架下设计系统的控制策略,通过室内室外真实环境进行实验验证,实现移动机器人的稳定跟随,验证了算法的有效性。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2024.000777
{DOI}: 10.27278/d.cnki.gsdqc.2024.000777
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于元学习的大规模小样本图像目标分类方法研究
{Author}: 朱俊杰
{Tertiary Author}: 易晓东
{Publisher}: 军事科学院
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 大规模小样本学习;元学习;对比学习;提示微调;多模态学习;数据增强;算法库
{Abstract}: 小样本图像目标分类研究旨在基于少量标注样例实现对新类别的快速辨识。这一研究在自然图像目标识别、遥感场景分类以及电子信号检测等诸多应用领域发挥着重要的作用。综述现有小样本学习研究方法,我们发现已有方法主要聚焦于小规模目标类别(通常不超过十类)图像分类任务,其在目标类别规模较大场景下分类精度往往较低。然而,特别是在军事应用场景中,随着新式装备和作战样式的快速发展,由伪装目标和新目标构成的新类别数量也在急剧增长。面向实际任务需求,如何在大规模目标类别条件下实现高性能的小样本图像分类,构成了本文的研究关键。在本文中,我们将对目标类别规模达到数十甚至百量级的小样本学习任务进行界定,称之为大规模小样本学习任务。元学习的核心旨在基于多个相关任务学习通用知识,从而增强模型对新类别的泛化能力。基于元学习的小样本学习方法能够显著降低对大量新类标注数据的依赖。然而,在大规模目标类别条件下,元学习小样本方法的有效性尚未得到充分的研究和验证。本文聚焦大规模小样本图像目标分类科学问题,针对大规模小样本条件下大模型难微调、特征易混淆、语义信息利用不充分、数据多样性不足四大挑战,分别从模型、学习框架、模态、数据四个方面着手,提出了基于元学习提示微调的小样本学习模型、基于对比元学习的小样本学习框架、基于多模态元学习的小样本学习方法、基于马赛克元学习的小样本数据增强方法四项关键技术。此外,为了实现关键技术的集成及面向实际场景的应用验证,本文设计实现一个小样本学习算法库系统。本文的主要创新点概括如下:(1)针对小样本条件下大模型难微调挑战,提出一种结合提示微调和元学习的新型小样本学习模型。在应对小样本条件下的过拟合问题时,传统元学习方法往往依赖于基于低参数量浅层网络的模型架构。然而,随着类别规模的扩大,这种低参数模型因其表示能力的局限性,难以避免分类性能的损失。近年来,预训练大模型研究取得了显著进展,如何在少量数据的基础上实现大模型的微调,并降低在大规模分类任务中的过拟合风险,构成了本工作的研究挑战。为此,本工作提出了一种基于提示微调和元学习的小样本学习模型MVP。与传统小样本学习模型在微调过程中需要更新骨干网络所有参数的做法不同,MVP仅更新少量的新增提示参数,并保持骨干网络的冻结。其中,提示参数内嵌在MVP骨干网络每一层的输入空间中,仅占总参数量的1%。经过元学习训练过程,MVP实现了提示参数的最优初始化,使得面向新任务的微调过程得以缩减到少量的几个梯度更新步骤。此外,MVP还具有低存储需求的特点,面向不同场景只需存储少量的提示参数,为航侦遥感卫星等微小终端的模型部署创造了有利条件。公共数据集的实验结果表明,MVP有效克服了面向大规模小样本任务的模型过拟合问题,达到了先进的性能表现。(2)针对大规模目标类别间特征易混淆挑战,提出一种结合对比学习和元学习的新型小样本学习框架。特征混淆问题是由不同类图像间相似度高及同类图像风格多样共同导致的。在元学习小样本方法研究中,类别原型的表示常受到特征混淆问题的干扰。尤其在类别规模较大的任务中,这一问题对模型分类性能的影响尤为显著。为了增强类别原型表示的鲁棒性并减少特征混淆问题的影响,本工作设计了一种基于对比学习与元学习的小样本学习框架CMF。具体而言,CMF构建在本文提出的平滑近似三元对比学习结构之上,该结构是对经典三元对比学习结构的优化重构。基于平滑学习理论,我们提升了三元对比学习函数在反向传播过程中的计算效率。CMF框架包含两个核心组件:查询相关原型表示组件QPC和原型正则化组件PPC。这一框架的设计具有模型无关性,使得其组件能够灵活地融入基于度量的元学习模型中。通过这种组合,新模型能够利用QPC实现图像特征与类别原型之间的距离优化,并借助PPC实现不同类别原型之间的距离优化。综上所述,通过组合CMF框架与元学习模型,我们能够优化类别边界的表示,从而有效减少特征混淆对分类性能的影响。在四个公共数据集的结果表明,基于CMF的元学习小样本模型展现出了卓越的性能,达到了先进的水平。(3)针对图像分类模型语义信息不足挑战,提出一种结合多模态学习和元学习的新型小样本学习方法。在小样本学习领域,实现图像与文本信息的一致性建模与高效利用一直是研究的重点挑战。小样本图像分类方法的实现主要依赖图像特征的提取与表示,而文本信息多以离散类别标签形式存在,往往未能得到有效利用。针对这一问题,本工作提出了一种结合多模态学习和元学习的小样本学习方法MMP,旨在实现文本信息的充分利用,以提升大规模小样本条件下模型分类性能。具体而言,该方法以对比多模态预训练模型为基础进行设计。为了实现多模态预训练模型的微调,传统方法通常采用成对的“图像—文本”数据作为模型输入,其优化目标是实现这些成对数据的特征对齐。为了优化小样本条件下的微调性能,MMP设计了“一对多”的多元视觉语义信息建模,其优化目标在于实现图像与多段文本描述之间的特征对齐。据此,MMP能够学习图像特征的多维度语义描述,从而在小样本条件下显著增强模型的推理能力。此外,通过将MMP与元学习训练框架相结合,我们进一步提升了模型在新类分类任务中的泛化能力。在公共数据集上的实验结果表明,MMP在大规模小样本图像目标分类任务中取得了显著的性能提升,达到了该领域的前沿水平。(4)针对小样本条件下数据多样性不足的挑战,提出一种结合马赛克原理和元学习的小样本数据增强方法。在小样本条件下,仅依赖少量几张样本图像构建的类别原型表示,其鲁棒性明显不足。因此,通过数据增强方法提升样本多样性,成为提高小样本学习模型性能的关键。特别地,数据增强还是元学习训练和微调过程的关键角色,元学习模型的性能精度和计算效率与所采用的数据增强方法密切相关。然而,目前大多数数据增强方法主要针对通用任务和卷积网络设计,鲜有专门考虑Transformer网络的结构特点。为了提升基于视觉Transformer网络的小样本学习模型的性能效率,本工作提出了一种结合马赛克原理和元学习的小样本数据增强方法RPR。马赛克原理在数据增强方法设计中有着广泛的应用,其核心思想是通过将其他图像块按比例混合到当前图像中,从而增强图像的多样性。在RPR方法的具体实现中,我们充分利用了Transformer网络的图像块编码器,实现了图像块的切分和编码,避免了构建新增模块的需要。与传统的数据增强方法相比,RPR方法显著优化了元学习数据增强过程的计算效率。在将RPR数据增强应用于本文提出的MVP及MMP模型的实验中,结果表明,相较于其他先进的数据增强方法,RPR方法在大规模小样本图像目标分类任务中展现出了卓越的性能提升。(5)为了集成本文提出的算法模型,设计并实现一种小样本学习算法库系统。实现前沿创新算法面向实际应用场景的快速部署具有重要的意义。目前创新算法的发展日新月异,但作战流程和场景的复杂性制约了算法模型的快速部署。为了实现前沿创新算法面向小样本实际任务的快速应用,本文提出了一种小样本学习算法库系统设计和实现方法。该算法库解耦了创新算法与应用场景的直接联系,应用算法则专注于对实际任务的适配。通过统一的算法库接口,创新算法与应用算法实现了骨干网络共享,基于创新算法预训练的骨干网络可实现对应用算法的赋能。此外,通过复用算法库的数据处理组件、模型组件、分布式并行计算组件,基于统一接口构建和注册的新算法能够进一步增强算法库系统的功能及新场景适应性。基于算法库系统,本文实现了创新算法及其他应用算法的集成,并实现了在自然图像目标识别、遥感场景分类、电子信号检测等多个实际场景的应用验证。
{URL}: https://link.cnki.net/doi/10.27193/d.cnki.gjsky.2024.000055
{DOI}: 10.27193/d.cnki.gjsky.2024.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 水下机器视觉的鱼类目标检测算法研究
{Author}: 郑世健
{Tertiary Author}: 王儒敬;刘知贵
{Publisher}: 西南科技大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 计算机视觉;深度学习;水下鱼类目标检测;水下图像增强;高密度目标检测与计数
{Abstract}: 我国是传统的渔业大国,渔业对国民经济和人民生活都有着重要影响。近年来,随着社会经济的发展和人口老龄化等问题的出现,渔业养殖产量虽然持续增长,但从业人员数量却呈现出负相关性。这一趋势暴露出渔业行业面临的人力资源短缺问题,迫使渔业市场需要尽快转型升级,建立现代化渔业体系。在此背景下,利用机器视觉的水下鱼类目标检测技术成为推动现代渔业建设的关键研究方向之一。随着深度学习技术在通用目标检测领域的快速发展,研究者将深度学习技术应用于水下鱼类检测领域,克服了传统机器学习技术在性能和泛化能力上的局限性。然而,受水下环境特殊性和鱼类本身特性的影响,获取的鱼类数据具有混合退化、多样性等问题,为检测算法精度带来巨大挑战。因此,本文在探讨水下鱼类图像特征信息基础上,结合机器视觉算法的理论研究及其实际应用,提出基于水下机器视觉鱼类目标检测算法。具体研究内容如下:
1.针对水下环境中光散射和吸收导致的图像质量混合退化问题,提出了可学习全频域Transformer水下图像增强方法。该算法利用可逆卷积的信息保留和重建优势,将图像不同频率特征表示进行彻底分离。通过采用可学习的交互Transformer进行建模,解决了不同频率增强特征信息的独立性和稀疏性表征问题,同时利用空频双鉴别器进一步提高了生成图像的质量和逼真度。多个数据集实验结果表明,本文方法能够获得同期最优结果性能。
2.针对水下图像混合退化频域解耦方法中存在的先验假设限制,提出了一个分治网络的水下图像增强算法。该算法采用轴注意机制将不同的区域/通道特征组合成单一流结构,提升了图像纹理特征信息的表征和全面性。同时,通过自适应三维查找表方法调整水下图像不同颜色域特征表示,有效提升了模型的颜色特征表示效果。多个数据集实验结果表明,该算法展现了出色的模型精度,同时也显著提升了模型的实用性和适用性。
3.针对水下鱼类数据集存在复杂跨场景(跨域)的问题,提出了一种基于数据划分的鱼类目标检测训练方案。首先详细分析了不同增强数据(不同域)对水下鱼类目标检测器的影响,探究了数据分布如何影响鱼类目标检测。其次借助图像质量评价指标构建了数据划分模型,能够有效选择对水下鱼类目标检测有利的数据。最后构建了UFD2022多类别水下鱼类数据集用于验证该方法的有效性。大量的实验表明,提出的基于数据划分的鱼类目标检测训练方案能够有效提升检测器性能。
4.针对上述的数据划分方案导致训练样本减少和特征信息降低的问题,提出了一种基于严重退化特征先验知识学习的水下鱼类目标检测网络算法。该算法主要包括两个核心设计:基于Prompt的退化特征学习模块和两阶段训练方案。基于Prompt的退化特征学习模块是利用图像间幅频特征关系构建,能够充分学习和转移有利鱼类目标检测的图像特征表示。两阶段训练方案通过灵活调整训练流程方式提升了检测器对水下鱼类检测任务的适用性。在UFD2022数据集上,将提出的方法与Cascade RCNN(resnet50)和Cascade RCNN(resnext101)基线进行了比较,得到的AP、AP50和AP75指标分别提高了2.4%、2.8%和2.6%,2.5%、3.8%和2%。通过对比数据表明,提出的方法能够更完整和丰富地提取目标信息,在复杂水下场景中具有更好的适用性。
5.针对高密度鱼类图像存在目标尺度变化、分布不均的“多样性”问题,提出了一种自适应密度引导的高密度鱼群目标检测与计数网络。首先,设计了一个类U-Net网络提取多层特征,缓解了鱼类尺度和形变的问题。其次,利用CNN和Transformer构建了密度引导自适应选择模块,双架构网络可以充分进行块间的信息交换,有效缓解鱼类密度分布不均匀问题。最后,构建了SHUFD和RHUFD高密度数据集用于验证该方法的有效性。在SHUFD和RHUFD数据集上,提出方法的MAE和RMSE指标比最先进方法(CUT)分别提高了3.4%和11.4%,6.4%和4.4%。对比数据表明,提出的方法能够取得良好效果。
{URL}: https://link.cnki.net/doi/10.27415/d.cnki.gxngc.2024.000174
{DOI}: 10.27415/d.cnki.gxngc.2024.000174
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的车辆及行人检测算法研究
{Author}: 蓝天鸿
{Tertiary Author}: 佘学兵;刘萍
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 目标检测;YOLOv8;车辆检测;行人检测;注意力机制
{Abstract}: 车辆与行人的检测在自动驾驶技术中起到至关重要的作用。然而,当前智能交通系统运行在资源受限的设备上,仍然面临速度、准确性、模型大小以及小目标检测的问题。为此,本文基于YOLOv8模型深入探索并改进了针对车辆及行人检测算法。最终模型YOLOv8n-DDL在显著减小参数量与浮点运算数的同时,实现了m AP(Mean Average Precision)值的提升。本文主要工作如下:(1)为了提高模型在车辆及行人检测中的准确性与精度,本文提出了基于动态卷积注意力的车辆及行人检测模型。首先对于CNN只关注局部而忽略全局信息的问题,本文引入可变形大核卷积注意力模块,并将模型中的可变形卷积改进至v3版本。其次,对于数据集中存在多尺度变化与远距离小目标问题,将YOLOv8中的检测头改进为动态检测头,并相应的将其中的可变形卷积v2版本改进至v3版本。同时本文注意到数据集BDD100K中分类不平衡的情况,并对YOLOv8中的分类损失函数进行了改进。最后对改进得到的模型YOLOv8nDD在BDD100K中进行消融实验,验证了各模块的有效性,结果显示该模型在m AP50精度和m AP50-95精度上分别提升了1.6%和1.4%。(2)为了更好地适应自动驾驶中边缘设备的应用需求,本文在YOLOv8nDD的基础上提出了基于CSPPC轻量化的车辆及行人检测模型。首先本文基于轻量化算子部分卷积设计了两个CSPPC模块。随后本文针对高度重叠与小目标问题,使用Inner-Io U对WIo U与CIo U损失函数进行改进。在模块对比实验中,将改进的C2f＿Faster Block与两个轻量化模块对比,通过替换YOLOv8所有C2f模块,CSPPC-A与CSPPC-B模块参数量相较于C2f＿Faster Block模块多降低了约18.2w(万)参数量。通过损失函数、模块与其替换位置的对比实验,最终使用较优的配合CSPPC-B与Inner-WIo U对模型轻量化得到YOLOv8n-DDL。实验结果表明,相较于YOLOv8n模型,所提模型在减小了40w参数量与6亿浮点运算数的同时,还实现了1.66%的m AP值提升;相较于YOLOv8n-DD模型,所提模型在保持精度略微提升的同时,参数量减少了42.3w(万),浮点运算数减少了7亿,从而验证了所提轻量化模块与损失函数的有效性。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2024.001780
{DOI}: 10.27232/d.cnki.gnchu.2024.001780
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv7-tiny的复杂环境下朱鹮目标检测算法研究
{Author}: 黄俊霖
{Tertiary Author}: 张鹏超
{Publisher}: 陕西理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 朱鹮;复杂环境;目标检测;YOLOv7-tiny;轻量化
{Abstract}: 朱鹮作为濒危物种之一,利用目标检测技术对其种群监护具有重要意义。现有技术在检测朱鹮过程中,由于遮挡和天气环境影响导致算法对朱鹮个体识别精度不高。当前YOLOv7-tiny算法在鸟类识别领域已有广泛应用。本文基于YOLOv7-tiny探究了一种复杂环境下高精度朱鹮检测算法,并采用轻量化方法进行优化,从而降低算法在实际应用中的硬件需求。工作内容包括:
（1）针对YOLOv7-tiny算法在复杂环境下检测精度不高的问题,设计一种高精度朱鹮检测算法。通过构建高效混合注意力机制（E-SEWSA）,将E-SEWSA嵌入到轻量高效层聚合网络（T-ELAN）中并借鉴密集残差网络重构该模块,提高模型检测精度的同时避免模型过度注意导致的梯度爆炸;利用CARAFE特征感知模块代替PAN+FPN结构中的上采样模块,提升了网络特征聚合部分的上下文信息融合能力,从而提高模型检测精度。通过实验验证,预测锚框的重叠度阈值取0.5时得到的平均检测精度(m AP@0.5)在自建朱鹮数据集与COCO数据集上改进算法较YOLOv7-tiny算法分别提升10.2%与7.8%。验证了改进方法的有效性。
（2）针对改进后算法模型参数量与每秒浮点运算量（FLOPs）相对较大的问题,优化算法结构并进行模型压缩。设计了Inv-Res BL模块与Inv-Res M模块并利用上述模块重构算法结构,利用性能感知近似的全局通道剪枝算法对改进模型进一步压缩,大幅降低模型的参数量与FLOPs;将剪枝模型进行微调与知识蒸馏,回调了模型的检测精度。在自建朱鹮数据集上进行实验验证,改进算法在模型参数量与FLOPs上,较YOLOv7-tiny分别降低约50%与48.5%,且m AP@0.5提升4.9%,满足轻量型设备搭载需求及检测性能需求。
（3）设计并实现了一个基于Jetson Nano的朱鹮检测系统。系统包括输入选择模块、检测指标模块、超参数设置模块以及检测效果展示模块。将YOLOv7-tiny模型及本文算法模型搭载到系统进行实验,结果表明,相比YOLOv7-tiny模型,本文模型运行速度高出一倍,且m AP@0.5达到86.5%。验证本文算法在实际应用中的可行性。
{URL}: https://link.cnki.net/doi/10.27733/d.cnki.gsxlg.2024.000113
{DOI}: 10.27733/d.cnki.gsxlg.2024.000113
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进DeepLabV3+的柑橘分割算法研究
{Author}: 张家俊
{Tertiary Author}: 张鹏超;杨益民
{Publisher}: 陕西理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 柑橘分割;注意力机制;轻量化;深度学习
{Abstract}: 语义分割是采摘机器人进行目标分割的关键技术。现有分割算法在对柑橘遮挡等复杂情况下的图像进行分割时,存在分割边缘不够细化,算法参数量较大等问题,导致无法高效地完成柑橘分割任务。目前Deep Lab V3+算法在农作物分割领域已被广泛应用。因此,本文基于Deep Lab V3+算法对柑橘的分割进行了深入研究,根据柑橘特征对网络的分割精度和轻量化进行改进,并将算法搭建在移动端进行验证。研究内容如下:
(1)设计一种基于Deep Lab V3+的多尺度注意力机制的柑橘分割算法。针对在柑橘目标遮挡等复杂环境下分割精度低的问题,添加一种卷积注意力模块(CBAM),并在该模块中引入多层感知机结构和关系建模机制,解决了网络梯度消失和梯度爆炸问题;设计一种融合多通道注意力机制方法,解决了Deep Lab V3+网络特征融合和空间信息关联问题,提高了网络性能和分割准确度。
(2)设计一种基于Deep Lab V3+的轻量化柑橘分割算法。针对多尺度注意力机制在分割柑橘时参数量较大的问题,选取Mobilenet V2网络对Deep Lab V3+网络中的主干网络Xception进行重构,并对Deep Lab V3+网络结构和ASPP模块的空洞率进行调整,减少了轻量化网络带来的精度损失问题;使用低秩分解技术对该网络的卷积层和全连接层进行模型压缩,解决了在资源受限设备上的部署问题,提高了网络的泛化能力。
(3)设计一种柑橘智能分割系统并在开源视觉平台进行算法验证。选用Jetson nano开发板和Pyqt分别为系统硬件和软件支持,该系统包括选取图片、开始分割和保存图片三个模块,通过两个窗口展示分割前后的效果;选用深度相机Realsense对柑橘图片进行采集,在Ubuntu系统下进行环境配置和算法搭建,对单一目标柑橘和不同程度遮挡目标柑橘进行了分割。
本文将改进后的Deep Lab V3+网络在柑橘数据集上进行实验,结果表明,平均交并比(Mio U)和像素准确率(MPA)分别达到了96.6%和98.0%,模型参数量相比于原有模型降低了88.33%。
{URL}: https://link.cnki.net/doi/10.27733/d.cnki.gsxlg.2024.000066
{DOI}: 10.27733/d.cnki.gsxlg.2024.000066
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的医学病理图像多分类研究
{Author}: 杜发文
{Tertiary Author}: 牛屹
{Publisher}: 山东师范大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 医学图像多分类;特征融合;卷积神经网络;Transformer;区域增强
{Abstract}: 医学图像分类是医学图像处理中一个至关重要的领域,是辅助诊断、检测和治疗的不可或缺手段。随着人工智能的飞速发展,利用以深度学习为基础的计算机视觉技术辅助疾病诊断已成为一个热门研究领域。由于医学图像包含的信息更为复杂、不同组织形态结构相似,现有的基于深度学习的医学图像分类研究仅针对正常组织和癌症组织进行二元分类。然而,对癌变组织细胞亚型进一步分类往往具有更加重要的临床价值,这同时也要求深度学习模型具有更强的特征识别能力。因此,本论文以深度学习算法为基础,提出了特征融合和区域特征信息增强的策略来提高模型的特征提取能力和性能表现。该类模型被应用到医学病理图像多分类的任务中,从而学习不同组织细胞亚型之间的一致信息和差异信息。本研究的主要工作如下:
(1)基于卷积神经网络(Convolutional Neural Network,CNN)和Transformer的医学图像多分类模型设计与实现。为了对结构相似的多种组织细胞亚型分类,增强模型的特征识别和提取能力,本研究提出了一种基于CNN和Transformer的医学图像多分类模型。基于CNN网络模型提取局部信息和Transformer网络架构提取全局信息,通过将两类信息多次特征融合,使模型学习到了全局高级语义特征和局部细节语义特征,增强了网络模型的特征表示,从而帮助模型完成精准、端到端的医学图像多分类任务。该模型选择准确性、精确度、F1分数和召回率等评价指标,在乳腺癌的公共数据集和肺腺癌私有数据集上进行了对比实验和消融实验,实验结果证明所提出的模型在模型参数与现有技术相当的情况下,表现出更加优异的性能。据调查研究所知,这是首次根据肺腺癌癌变组织的分化程度进一步对癌变组织亚型进行五分类的模型。
(2)基于CNN区域增强的医学图像多分类模型设计与实现。为了进一步探究不同组织细胞亚型的一致信息和差异信息,更加平衡、高效的提取各组织细胞亚型之间的特征信息,本研究提出了一种基于CNN区域增强的医学图像多分类模型。该模型设计使用平衡特征金字塔方法,实现从低级到高级的特征信息的汇总,得到全局信息;之后,通过构建二元掩码裁剪原始图像并输入到主干网络,得到更为精细的局部特征信息,以此来均衡语义特征强化模型的特征提取能力。基于CNN区域增强的医学图像多分类模型为医学图像多分类任务提供了一个自动化工具,有助于学习不同组织细胞亚型之间的特征信息,有效提高模型的鲁棒性。
综上,本论文描述了医学图像多分类任务的意义及难点,提出了基于CNN和Transformer以及基于CNN区域增强的医学图像多分类模型。该研究对模型进行了广泛的实验评估,验证了模型的有效性。实验部分说明了基于CNN和Transformer的多分类模型以及基于CNN区域增强的医学图像多分类模型的可行性,为基于深度学习的医学图像多分类的研究奠定了一定的基础。
{URL}: https://link.cnki.net/doi/10.27280/d.cnki.gsdsu.2024.000741
{DOI}: 10.27280/d.cnki.gsdsu.2024.000741
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于知识蒸馏的轻量级玉米叶病检测算法研究
{Author}: 胡艳鑫
{Tertiary Author}: 刘钢;赵冲
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 玉米叶病检测;目标检测;模型轻量化;知识蒸馏
{Abstract}: 玉米是世界上最重要的农作物之一,在其种植生产过程中,有效检测叶病是确保玉米健康生长的关键环节,对促进玉米产量增加有着重要意义。在玉米叶病检测方法中,传统的机器学习检测算法依赖于人工特征提取,特征表达能力存在一定的局限性且效率低。深度学习的检测算法是端到端的,不需要人工特征提取,提高了效率和检测精度,其应用在计算资源受限的玉米叶病现场检测中,还存在模型参数多和计算复杂度高的问题;通过模型轻量化技术后,虽然降低了模型参数和计算复杂度,还存在着检测精度低的问题。
针对在计算资源受限情况下,深度学习检测算法存在参数量多和计算复杂度高的问题,提出一种改进的基于YOLOv8的轻量级目标检测算法。主要包括两个方法,通过改进主干网络,在保证特征提取能力的同时降低算法参数量和计算复杂度;通过改进颈部网络,丰富语义信息的交互,加快特征融合速度。改进后的算法有效地控制了模型参数量大小,具备更快的运行速度和更低的资源消耗。
针对轻量化后检测算法导致检测精度下降的问题,提出一种结合基于特征和logits的改进的知识蒸馏方法。在不额外增加模型参数和计算复杂度的前提下,从教师模型中转移中间层和输出层的关键知识到学生模型中,有效提升算法的检测精度。
本文提出的基于知识蒸馏的轻量级玉米叶病检测算法,即包含改进的YOLOv8轻量级目标检测算法、基于特征和logits的改进的知识蒸馏方法。通过在真实农田环境中采集的图像和从Plant Village数据库中获取的玉米叶病图像上的实验,验证了提出的算法能降低模型参数量和计算复杂度,并提升了检测精度,为玉米叶病的准确检测提供一种可靠的轻量级技术方法;又通过在Pascal VOC公共数据集上的实验,进一步验证了所提算法具有一定的泛化性。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2024.000244
{DOI}: 10.27805/d.cnki.gccgy.2024.000244
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的焊缝表面缺陷检测方法研究
{Author}: 李鑫
{Tertiary Author}: 杨宏韬;张鹏
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 自动焊接;焊缝点云;缺陷分割;特征提取;缺陷识别
{Abstract}: 随着自动化焊接技术在现代焊接工艺中占据重要地位,焊缝缺陷检测技术也成为了自动化焊接质量的有力保障。通过及时发现潜在的焊缝表面缺陷,为焊缝表面缺陷的打磨、填充等修复工艺提供了关键的支撑和基础。本文基于面结构光视觉传感器搭建了焊缝表面缺陷检测系统,以平板对接焊缝为主要研究对象,通过面结构光相机采集焊缝点云数据,以工业机器人为支撑平台带动视觉装置运动,并通过一系列的点云数据处理算法完成对焊缝表面缺陷的特征提取和类型识别,具体的研究内容如下:
针对焊缝点云数据中存在大量离群点、冗余点的问题,采用了统计滤波和体素降采样的方法,在保证原有焊缝表面形貌特征不被破坏的基础上,降低了焊缝点云数据处理的干扰量,增强了后续点云焊缝处理算法的计算效率。
针对焊道点云的分割过程中,采用传统的点云分割算法出现欠分割和过分割导致焊道点云的分割性能指标过低的问题,提出了一种基于法线微分算子改进的最小平方中值拟合的分割方法,该方法通过求取点云数据的法线微分算子来提取焊道与母材连接处的点云,通过两次拟合分割实现焊道点云的提取,经实验验证,分割精确率能够达到97.58%。同时,针对传统的区域生长方法在缺陷提取上的提取误差过大的问题,提出了一种基于二次聚类的缺陷提取方法,在原有区域生长算法的基础上,对缺陷点云进行曲率差和欧式距离差的二次聚类,最终通过实验验证,对不同缺陷的提取的精度最高能够达到97.48%。
针对焊缝表面缺陷分类方法展开研究。分析了不同焊缝表面缺陷之间在几何特征和形貌特征上的区别,研究了焊缝表面缺陷的几何特征和形貌特征求取方法。针对传统分类识别方法基于焊缝表面缺陷特征数据集分类识别精度不足的问题,提出了一种基于粒子群优化的Ada Boost集成分类算法,通过建立集成分类器、输入焊缝表面缺陷训练集进行训练,最终经过测试集中的数据验证,分类器识别准确率能够达到98.33%,满足对焊缝表面缺陷识别的精度要求。
针对焊缝表面缺陷检测系统进行研发。对面结构光相机的参数和数据特征进行了分析,通过手眼标定实现了面结构光相机与工业机器人的互联。通过QT软件设计工具,完成了焊缝点云数据的采集、预处理算法与缺陷点云的分割、特征提取和识别算法的可视化集成,最终实验结果验证了本文所研发算法的有效性和系统的可行性,满足系统能够采集回焊缝点云并正确输出焊缝表面缺陷类型的要求。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2024.000942
{DOI}: 10.27805/d.cnki.gccgy.2024.000942
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer和CNN的医学图像分割方法研究
{Author}: 邢帅杰
{Tertiary Author}: 冯云丛;冯丛娜
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 医学图像分割;卷积神经网络;Transformer;注意力机制
{Abstract}: 医学图像能够清晰的反映人体内部的组织结构,是医生针对患者作出正确诊断的重要基础。医学图像分割是医学图像分析领域的一个重要分支,通过医学图像分割,医生可以检查出息肉、肿瘤等疾病的生长程度,从而制定出进一步的诊断、预防和治疗方案。目前,许多研究方法使用卷积神经网络和Transformer来实现自动医学图像分割,但受到病灶区域的大小、颜色、形状等方面的影响,分割效果相比于手动分割依然会存在着一些不足,例如边界不清晰、细小的病灶区域无法准确识别等。针对以上问题,本文提出了两种新的医学图像分割方法,在许多数据集上的分割结果表现较好。
第一,提出了一种基于金字塔池化Transformer(P2T)和反向注意力机制的分割方法——P2TNet。首先,该方法使用金字塔池化Transformer作为提取特征的主干网络,相比于其他基于CNN的方法,P2T拥有着更为强大的特征提取能力。其次,本算法引入了级联部分解码器(CPD),它抛弃了低级特征转向于聚合高级特征来生成一个全局特征图用以引导之后的反向注意力模块。最后,搭建了两组反向注意力模块(RA)来挖掘低层特征中的边界信息,并加强与息肉区域之间的联系,从而对息肉进行准确地分割。
第二,提出了一种基于多尺度通道注意力(MSCA)、卷积神经网络和金字塔池化Transformer的分层混合模型——MS-P2T。首先,对于CNN来说,它们可以很好的提取局部信息,但由于其狭小的感受野,无法有效地捕获全局语义特征,完成全局上下文建模。其次,对于Transformer来说,它们可以很好地对远程依赖关系进行建模,但却忽略了相当一部分的局部详细信息,并且还忽略了通道注意力。因此,为了弥补和利用CNN和Transformer的缺点和优点,本算法将MSCA、CNN、P2T相结合,将它们高效地整合在一个混合Transformer块内,搭建了一个分层混合Transformer的U型网络,实现从局部到全局的多粒度特征表达。MS-P2T采用分层方式对不同组件进行融合,真正实现了卷积神经网络与Transformer两者优点的协同。
本文所提出的两种分割方法均围绕金字塔池化Transformer编码器展开,充分利用了CNN与Transformer两者各自的优势,将其用以医学图像分割任务。在八个公开医学图像数据集上的对比实验结果表明本文所提方法在各个数据集上都表现较好,这验证了本文的所提方法具有良好的泛化性,并且大部分评价指标得分都优于其他方法,表明所提两种方法在医学图像分割任务中拥有着较为优秀的性能。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2024.000358
{DOI}: 10.27805/d.cnki.gccgy.2024.000358
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的电力作业人员行为分析研究现状与展望
{Author}: 闫云凤;陈汐;金浩远;齐冬莲;储海东;汪金维
{Author Address}: 浙江大学电气工程学院;浙江大学海南研究院;香港大学计算机科学学院;国家电网有限公司;浙江天衡五维电子科技有限公司;
{Journal}: 高电压技术
{Year}: 2024
{Volume}: 50
{Issue}: 05
{Pages}: 1842-1854
{Keywords}: 行为分析;视觉理解;电力监控;目标检测;姿态估计;视频跟踪;行为预测
{Abstract}: 电力作业人员的有效监管是保障电力安全生产的基础。该文对电力视频中作业人员的行为识别研究进行了归类总结，涵盖静态行为分析(穿戴分析、动作分析和组合分析)和动态行为分析(复杂动作、时序行为和行为预测等)；详细综述了电力作业行为分析中的核心算法模块，包括目标检测、姿态估计和视频跟踪等；论述了电力作业行为识别在算法高效性、鲁棒性、灵活性等方面所面临的应用难点和挑战，并展望了电力作业行为智能监控领域的未来发展方向，特别强调了在软硬件结合、通用大模型、生成式人工智能方面进行技术创新和改进所蕴含的潜在机会。
{ISBN/ISSN}: 1003-6520
{Notes}: 42-1239/TM
{URL}: https://link.cnki.net/doi/10.13336/j.1003-6520.hve.20240404
{DOI}: 10.13336/j.1003-6520.hve.20240404
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 人工智能背景下“机器视觉”课程教学改革与探索
{Author}: 张智浩;沈谋全;朱文俊
{Author Address}: 南京工业大学电气工程与控制科学学院;
{Journal}: 工业和信息化教育
{Year}: 2024
{Volume}: 
{Issue}: 05
{Pages}: 19-23
{Keywords}: 机器视觉;人工智能;教学改革
{Abstract}: 人工智能技术推动了新一轮的产业变革，我国对智能机器人和智能制造领域人才需求旺盛，“机器视觉”课程也逐渐成为自动化类专业的核心专业课程。目前高校课程教学存在教学内容缺乏前沿性、理论与实践分离和教学方式单一等问题，无法适应人工智能背景下新型人才培养需求。为此，笔者尝试从教学内容、教学方式等方面进行探索，提出了切实可行的“机器视觉”课程改革方向与策略。
{ISBN/ISSN}: 2095-5065
{Notes}: 10-1101/G4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyaV4mkTEjPEuHPqi4WyRh-XMTk8fpUXxvtt7jbX7kxhddw1ZuZC3OO80ZOfm07nFLE88mmu0zVbatOKY_VGof7XZ_AMkVQ6v8IrxM5bQz5tDLP2nTYu6B_UCL7_oJ3wP-TtfiUuyuj7FElfkOux5I-HfaViTATVNX8xVU3QOgAl4tAzTU1tqfivTczE9VtxAk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和YOLOv5的油菜角果表型参数分析
{Author}: 陈威;朱怡航;顾清;林宝刚;张小斌
{Author Address}: 浙江农林大学数学与计算机科学学院;浙江省农业科学院数字农业研究所;浙江省农业科学院作物与核技术利用研究所;
{Journal}: 浙江农业学报
{Year}: 2024
{Volume}: 36
{Issue}: 06
{Pages}: 1379-1388
{Keywords}: 油菜角果;表型;图像处理;籽粒计数
{Abstract}: 为了更加高效和准确地获取油菜角果表型参数，在图像处理技术和深度学习算法的基础上，以迎春一号油菜角果为实验材料，综合考虑油菜育种对角果外观表型参数的需求，提出了一种基于机器视觉的油菜角果表型分析方法：利用图像处理技术实现了油菜角果的柄喙长度、果身长度、果身宽度、弦长、弧长、面积等外观表型性状的提取，使用YOLOv5对单角果籽粒进行无损计数。对角果实物及标定物进行测量验证，结果表明，图像分析出的角果表型指标与人工实际测量值无显著性差异（P>0.05）,决定系数（R2）均大于0.96,均方根误差（root mean square error, RMSE）均小于3 mm,平均绝对值误差（mean absolute error, MAE）均小于2.80 mm,平均绝对百分比误差（mean absolute percentage error, MAPE）均不超过4%。标定物直径最大RMSE为0.3 mm, MAE均小于0.28 mm, MAPE均小于2.00%,面积指标最大RMSE为12.09 mm2, MAE均小于11.56 mm2,MAPE均小于5%。YOLOv5识别出的籽粒数与实际值无显著性差异（P>0.05）,R2为0.987,RMSE为0.68粒，MAE为0.27粒，MAPE为1%。该研究的油菜角果表型分析方法操作简单、成本较低，能有效地减少人工测量的误差，提高获取表型信息的可靠性和油菜育种工作的效率，为油菜表型信息的定量化分析提供了一定的参考。
{ISBN/ISSN}: 1004-1524
{Notes}: 33-1151/S
{URL}: https://link.cnki.net/urlid/33.1151.S.20240523.0840.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的医学图像分割技术研究
{Author}: 张云楚
{Tertiary Author}: 董建飞
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 医学高光谱图像;卷积神经网络;注意力机制;图像分割
{Abstract}: 医学图像分割作为医学图像分析中的关键环节,其核心目标在于将复杂的医学图像细致划分成多个特定区域,以便精确识别诸如器官、组织或肿瘤等解剖结构。然而,由于医学图像的复杂性和多样性,分割任务往往充满挑战。近年来,随着深度学习技术的发展,医学图像分割取得了显著的进步。与传统的图像处理和特征提取方法相比,深度学习通过训练神经网络学习高层次的特征,展现出卓越性能。自从注意力机制被引入机器翻译领域以来,它已成为神经网络研究中的热点。注意力机制通过学习输入序列中的全局依赖性,具备全局感受野,能够在网络中建模全局特征,从而捕获更为全面的信息。注意力机制已被证明可以提高医学图像分割的准确性,然而,现有的基于自注意力机制的网络往往模型复杂,同时,传统的空间和通道增强方法缺乏全局视野,另一方面,现有的通道注意力机制缺乏针对高光谱图像分割任务的针对性优化。因此,针对上述问题,本文基于神经网络图像分割的最新发展,提出了三个结合了注意力机制的深度神经网络。本文主要研究内容如下:1.传统的级联U-Net虽能通过堆叠多个U-Net网络融合特性以提升性能,但此举亦导致了参数剧增与计算复杂度的大幅提升。为解决此问题,本研究提出了2K折网络(2K-Fold-Net)这一级联U-Net的泛化结构。当K=1时,此结构即为原始U-Net;随着K值的增加,该网络能在维持参数恒定的前提下,显著增强基于U-Net架构网络的性能。进一步地,本研究以K=2的4-Fold-Net为基础,融入MultiRes模块及CFE、SFE、AFE三种注意力机制,设计出Enhanced-Feature-4-Fold-Net,简称EF3-Net。MultiRes模块的引入拓宽了模型的感受野,三种注意力机制的细致应用弥补了网络编码与解码阶段特征图间可能存在的语义层级差异。提出的EF3-Net在四个具有挑战性的灰度和彩色医学图像分割数据集中相比U-Net实现了 6.85%至15.4%的mIoU指标提升,这一显著进步验证了注意力机制对于提升神经网络分割灰度和彩色医学图像的精度的可行性,并为相关注意力机制模块在网络中的结合策略提供了有力支持。2.为了解决上述EF3-Net计算复杂度高、缺少全局视野的局限性,本研究创新性地设计了一种基于多层感知器的新型注意力机制。通过两个不同遍历方向的多层感知器遍历整个特征图。该机制不仅强化了网络的全局特征提取能力,提升网络性能,还保持了网络的紧凑结构与低计算复杂度。此外,本研究还对EF3-Net进行了宏观设计的优化,包括采用大内核尺寸卷积层、双线性插值和加法融合,提出了 MLP-Attention Enhanced-Feature-four-fold-Net,简称 MAEF-Net。这些改进措施提升了网络的性能,相比于EF3-Net在四个具有挑战性的数据集中取得了约3%的mIoU提升,训练和推理时间分别显著减少了 24.8%和30.8%,同时在性能上超越了对比的先进通用网络以及各数据集专用模型。3.高光谱图像波段众多,各波段灰度值分布差异显著,有效信息的提取尤为复杂。针对此问题,本研究首先提出了一种专为高光谱图像设计的二分支U-Net图像预处理网络HM-UNet。该网络基于直方图匹配方法进行训练,能有效处理数据集中各波段图像灰度值分布差异较大的问题。此外,本研究还设计了一种新型光谱注意力模块,利用1×1逐深度卷积与余弦退火学习率策略,显著增强了高光谱数据的可用性和可解释性。基于训练后光谱注意力模块赋予的权值,筛选出高权重波段减少网络的输入波段,网络的训练和推理时间分别降低了 25.5%和40%。最后,本研究针对显微高光谱图像在胆管癌组织病理学检查中的应用,基于上述提出的EF3-Net和MAEF-Net,并结合光谱注意力模块、改进的AFE模块及多重损失函数训练策略,提出了专为显微高光谱胆管癌图像分割设计的Spectral Attention based Hyperspectral Image Segmentation Net,简称 SAHIS-Net。该网络在显微高光谱胆管癌图像分割任务中实现了最先进的61.40%mIoU指标,为胆管癌诊断技术的改进开辟了新的有效途径。综上所述,本文致力于研究不同注意力机制在灰度和彩色以及高光谱医学图像分割任务中的运用,并提出了三个针对不同任务的医学图像分割网络。这些网络在不同的医学图像分割数据集中表现出优异的分割结果,对神经网络在医学图像中的实际运用具有积极意义,同时也对其他计算机视觉领域具有借鉴意义。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2024.000204
{DOI}: 10.27517/d.cnki.gzkju.2024.000204
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机人工智能在作物病害识别与防治中的应用
{Author}: 于冠杰
{Author Address}: 新乡开放大学;
{Journal}: 分子植物育种
{Year}: 2024
{Volume}: 22
{Issue}: 12
{Pages}: 4146-4151
{Keywords}: 计算机人工智能;作物病害识别;防治;深度学习;可持续发展
{Abstract}: 本研究系统综述了当前计算机人工智能技术在作物病害领域的应用研究，主要涵盖了深度学习、图像处理和机器学习等方面。通过分析传统方法在作物病害识别中的局限性，强调了引入计算机人工智能技术的迫切性。同时，本研究详细介绍了计算机人工智能技术在作物病害检测和防治中的手段，如卷积神经网络(CNN)，并对当前研究中存在的不足之处进行了深入剖析，包括算法泛化能力、数据质量和社会接受度等方面。通过对当前研究的全面分析，我们认为计算机人工智能技术在作物病害防治中有着非常广阔的应用前景，进一步的研究应更加注重跨学科研究、技术实际应用、数据隐私保护以及可持续发展等方面。
{ISBN/ISSN}: 1672-416X
{Notes}: 46-1068/S
{URL}: https://link.cnki.net/doi/10.13271/j.mpb.022.004146
{DOI}: 10.13271/j.mpb.022.004146
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能制造实践平台应用研究
{Author}: 宋忠东;刘翠莲
{Author Address}: 兰州现代职业学院;
{Journal}: 科技创新与应用
{Year}: 2024
{Volume}: 14
{Issue}: 13
{Pages}: 22-25
{Keywords}: 机器视觉;智能制造;视觉标定算法;智能控制;实践平台
{Abstract}: 随着信息技术和数字技术的快速发展，新一轮的工业科技革命蓬勃兴起。多年来，我国一直被誉为“世界工厂”，制造业稳居世界第一。然而，随着经济结构转型和产业结构不断深化调整，我国的经济逐渐朝着多元结构、多重挑战、高中速增长的方向发展。智能制造成为制造业发展的新方向，特别是《中国制造2025》制造强国战略的推行实施后，坚持创新驱动、智能化转型已经成为我国制造业发展的主要目标，该文结合机器视觉技术的概念及系统组成，阐述基于机器视觉的智能制造实践平台的应用设计，分析基于机器视觉的智能制造系统的优势，并探讨未来的发展趋势，旨在为相关人士提供借鉴和参考。
{ISBN/ISSN}: 2095-2945
{Notes}: 23-1581/G3
{URL}: https://link.cnki.net/doi/10.19981/j.CN23-1581/G3.2024.13.006
{DOI}: 10.19981/j.CN23-1581/G3.2024.13.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在珍稀野生动物疾病监测与预警中的应用现状及展望
{Author}: 郑泽林;黄霖宇
{Author Address}: 四川大学电子信息学院;
{Journal}: 动物医学进展
{Year}: 2024
{Volume}: 45
{Issue}: 05
{Pages}: 118-125
{Keywords}: 计算机视觉技术;疾病监测与预警;珍稀野生动物
{Abstract}: 珍稀野生动物是指生活在自然环境中、具有独特生物学特征和高度濒危的动物，其疾病监测与预警不仅关系到动物福利和物种保护，也影响到生态系统平衡和人类健康。计算机视觉技术是人工智能领域的一个分支，它使计算机能够模拟人类视觉系统，从而理解和解析图像和视频数据。珍稀野生动物疾病监测与预警需要一个能够进行图像识别、模式识别和人工智能算法的高科技系统，该系统包括图像采集、数据预处理、特征提取、疾病识别模型、实时监测与预警等关键组成部分，可被用于大熊猫、金丝猴、东北虎等珍稀野生动物的疾病监测与预警，及时发现其疾病或异常行为，迅速采取救治措施。论文对计算机视觉技术及其在珍稀野生动物疾病监测与预警中的应用现状及存在的问题进行了分析，并对其未来发展趋势做出展望。
{ISBN/ISSN}: 1007-5038
{Notes}: 61-1306/S
{URL}: https://link.cnki.net/doi/10.16437/j.cnki.1007-5038.2024.05.011
{DOI}: 10.16437/j.cnki.1007-5038.2024.05.011
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 关键特征感知与增强的医学图像分割方法研究
{Author}: 高艳
{Tertiary Author}: 车翔玖
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 医学图像分割;关键特征感知;特征增强;归纳偏置能力
{Abstract}: 基于卷积神经网络(Convolutional Neural Network,CNN)的图像分割技术实现了对图像中不同对象或特定区域的分割。已有的基于CNN的图像分割技术大多在常规目标和具有清晰边界的目标上表现良好,但对于小目标或者具有模糊边界的目标,其表现仍有不足。这在医学图像分割任务中尤为明显,仍然存在一些问题需要解决。首先,基于CNN的方法在处理边缘线条模糊的目标时,或者在挖掘小目标的特征时存在不足;其次,面对医学图像复杂背景和目标边界模糊的情况存在分割精度不高的问题;此外,基于CNN的分割方法缺乏全局建模的能力,对许多目标的分割表现不佳。针对上述问题,本文提出了三个关键特征感知与增强的方法。具体工作如下:
针对目标边缘线条模糊或者对小物体特征挖掘不充分的问题,本文提出了对敏感特征感知的方法(Sensitive Feature Selection Module,SFSM),提升了对目标关键特征的感知能力。该方法通过分析每层上一阶段卷积层的特征,进而学习该层特征图同一位置不同通道上每个像素的分布特征。利用这些分布特征对不同通道的像素进行重新加权,从而提升网络在特征提取过程中对物体边界和小物体像素特征的感知能力。进而,将SFSM获得的信息与原始特征相结合,进一步改进特征表示以获得更精确的分割结果。本文将SFSM集成到FCN、Deep Labv3系列和Double U-Net网络框架中,并在皮肤病医学图像数据集ISIC等进行了验证。实验结果表明,将SFSM嵌入到Double U-Net中,在ISIC数据集上获得了0.16%的精度提升,由此证明SFSM能够有效提高网络的分割性能。
针对在处理医学图像复杂背景和边界模糊的目标存在分割精度不高的问题,本文提出了增强特征提取能力的方法(Enhanced Feature Extraction Network,EFEN),从而提升网络对关键特征的感知能力。该方法基于U-Net设计了特征再提取的结构来增强特征提取能力。此外,在解码过程中,该方法使用位置编码和交叉注意机制对跳跃连接进行改进以减少噪声等信息的干扰。通过嵌入位置信息,可以获取目标之间的绝对信息和相对信息。同时,利用交叉注意机制强化有用信息,弱化无关信息。该网络能够准确感知每个跳跃连接的关键特征,使解码过程中的特征表现更为清晰,从而减少了医学图像中模糊信息对目标边界的影响。在CVC-Clinic DB、ISIC的task1和Data Science Bowl challenge数据集上的实验表明,EFEN优于U-Net和一些常用方法。例如,与U-Net相比,本方法在CVC-Clinic DB和ISIC上关于DSC指标分别获得了5.23%和2.46%的改进。与Double U-Net相比,本方法在CVC-Clinic DB和ISIC上关于DSC指标分别获得了0.65%和0.3%的改进。
针对在医学图像分割任务中基于CNN的方法归纳偏置能力强,但缺乏全局建模能力,基于Transformer的方法全局特征提取能力强,但归纳偏置能力不足的问题。本文提出了将CNN和Transformer相结合的Swin-IBNet方法。Swin-IBNet有效的平衡了局部特征提取能力和全局特征提取能力,实现了二者的优势互补。该方法的解码部分采用了Swin-Unet的解码器。Swin-IBNet的编码器由本文设计的特征融合模块FFB(Feature Fusion Block)和新颖的多尺度特征聚合模块MSFA(Multi-Scale Feature Aggregation)实现信息的交互。本方法在Synapse、ISIC和自动心脏诊断挑战(ACDC)的公共数据集上进行了验证。实验结果表明,Swin-IBNet优于Swin-Unet和几种常用的方法。特别是在Synapse数据集上,Swin-IBNet获得的DSC值比Swin-Unet高出3.45%。此外SwinIBNet关于指标HD获得了17.46,表现出了与真实形状更高的相似度。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2024.000623
{DOI}: 10.27162/d.cnki.gjlin.2024.000623
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 耦合计算机视觉及高精度雨洪数值模拟的城市内涝实时减灾研究
{Author}: 鄢琳
{Tertiary Author}: 荣宏伟
{Publisher}: 广州大学
{Type of Work}: 博士
{Year}: 2024
{Keywords}: 地面排水设施;计算机视觉;水文水动力模型;内涝风险评估;实时减灾
{Abstract}: 近年来,随着全球气候变暖和城市化进程的加快,城市内涝已成为严重影响社会生产和居民生活的突出问题之一。城市排水基础设施的稳定运行是降低城市内涝影响和保障城市排水安全的重要基础。然而,当前城市地面排水设施运维主要依靠人工巡检的方式,巡检效率低且易发生设施漏检、错检问题,导致暴雨时经常出现雨水口堵塞、雨水口树叶遮挡、排放口排水不畅等排水设施运行失效现象,城市排水设施丧失应有的排水能力,无法及时排除地面积水,引发城市内涝。同时,暴雨发生后,防汛人员无法实时掌握排水设施的运行情况,不能准确评估内涝风险等级,导致防汛资源分配不均,风险处置不及时,严重威胁居民财产安全,影响社会正常运转。
针对以上问题,本论文采用学科交叉的思路开展耦合计算机视觉及高精度雨洪数值模拟的城市内涝实时减灾技术研究,首先在暴雨发生前,一方面通过基于计算机视觉识别技术,实现排水设施状态智能识别,全面提升城市排水设施日常的运行效率;另一方面需要因地制宜地做好城市内涝风险评估,提升内涝灾害预防和控制的能力。其次在暴雨发生后,通过开展一、二维水文水动力模拟,实时模拟排水设施设施运行情况,耦合排水设施状态智能识别技术,快速识别出排水设施运行风险区域,科学评估内涝风险等级,高效合理地分配防汛资源,实现内涝实时减灾。本论文得到主要结论如下:
(1)针对国内外尚未有公开的城市地面排水设施标注数据集,基于传统行业标准的地面排水设施缺陷分类,结合视觉特征采用YOLOV7目标检测算法,优化缺陷分类,模型迭代优化图像标注,数据增强扩充图像数据集等方式提升地面排水设施数据集质量,最终构建了一套以检查井、雨水口、排放口3类地面排水设施类型,15类设施缺陷状态的地面排水设施图像样本数据集,数据集总量34367张,为排水设施缺陷目标状态智能识别提供数据基础。
(2)首次构建适用于地面排水设施的目标检测器,通过利用YOLO系列的9种检测算法对排水设施缺陷目标的检测性能测试,YOLOV7目标检测算法在召回率(Recall为0.837)和模型检测精度(m AP50为0.872)有明显的优势,且能充分满足排水设施缺陷实时检测的性能要求(FPS为294.118),并通过在主干网络融合SE注意力模块进一步提升模型检测性能,m AP50提升了1.03%,召回率(Recall)提升了1.69%,FPS提升了3.03%,综合分析选择YOLOV7+SE作为排水设施缺陷目标检测器,为排水设施实时智能巡检提供了算法支撑。
(3)引入一种基于视频流检测的排水设施目标跟踪及空间匹配分析算法,选取YOLOV7+SE作为缺陷目标检测器,采用Bo T-SORT目标跟踪算法,YOLOV7+SE输出的缺陷检测成果作为Bo T-SORT算法的输入,实现连续多帧图像排水设施缺陷目标检测的集成,通过限定半径最邻近的空间匹配算法,实现目标跟踪算法的输出结果与地面排水设施GIS数据的匹配,开发一套排水设施缺陷实时检测系统,实现车载视频实时上传,系统实时缺陷检测,缺陷与设施GIS数据实时匹配,进一步推进排水设施智能巡检替代人工巡检。
(4)基于SWMM和TELEMAC-2D模型建立城市内涝水文水动力一、二维耦合模型,实现一维管网和二维地表漫流模型的耦合,模拟分析特定降雨条件下的区域内涝情景;建立城市内涝灾害风险评估指标体系,覆盖灾害、暴露度和脆弱性三个维度,涵盖物理机制及统计机制两个层次,共计12个指标;提出一种新的耦合K-means聚类及改进投影寻踪的权重计算方法,基于指标数据连续性特征进行投影寻踪的分层应用,以期获得更加科学准确的指标权重;将上述方法综合应用于江苏宿迁区域,实现城市内涝风险的科学评估。
(5)基于历史监测数据及未来排水设施状态组合的监测情景,构建特定降雨情景下的三阶段实时监测结果,以遮挡率作为排水设施堵塞及遮挡程度的判定指标,给出不同排水设施的淤堵程度;针对排水设施状态实时监测情景,提出城市内涝风险模拟实时推演方法,采用水文水动力一、二维耦合模型模拟区域淹没情景及内涝风险;考虑经济人口分布规律、不同阶段监测情景及内涝风险识别结果,提出双阶段实时减灾策略,从重点区域、边缘区域及全片区三个空间范围,基于重点道路风险正(负)值比率及综合减灾效益指标,分析不同实时减灾策略对城市内涝减灾效益的影响。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2024.000029
{DOI}: 10.27040/d.cnki.ggzdu.2024.000029
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的花卉种类识别
{Author}: 陈杰
{Tertiary Author}: 崔艳荣
{Publisher}: 长江大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 花卉识别;YOLOv5;深度学习;轻量化模型;GhostNet
{Abstract}: 我国的花卉种植历史悠久,花卉种类丰富,同时拥有千亿级别的花卉零售市场规模,庞大的花卉消费市场对花卉栽培提出了很高的要求。花卉识别是花卉栽培过程中的一项重要环节,传统的花卉识别方法往往依托于专业人士进行人工判断,通过对比观察花卉的颜色、纹理、形状等特征信息进行识别,其结果受主观因素影响较大,识别效率不高。随着卷积神经网络在图像识别领域大放异彩,将卷积神经网络技术运用到花卉识别研究中是近几年这一领域的主流方向。传统深度卷积神经网络在花卉识别任务上识别准确率较高,但模型往往存在计算量大、参数量高、部署困难等问题。因此,本文分别设计了两种轻量级花卉识别模型,并在自建的花卉数据集上进行相应实验,实验结果表明本文所提出的花卉识别模型在保证识别准确率的前提下,实现了轻量化的目的。本文的主要工作如下:(1)针对已有的花卉识别模型复杂程度高,计算量大的现状,提出了一种基于轻量化卷积方式与迁移学习方法的花卉识别模型。利用在Image Net1k数据集上训练得到的预训练权重进行迁移学习,以加快模型的训练速度。引入深度可分离卷积和h-swish损失函数对原模型骨干网络的特征提取部分进行重构,以降低原模型的计算量与参数量,提升模型的推理速度。(2)针对模型轻量化过程中所造成的精度损失,保证模型的识别准确率,提出了一种基于Ghost模块与混合注意力机制的花卉识别模型。通过引入轻量化结构Ghost模块与Ghost瓶颈结构,对原有骨干网络进行重构,降低模型的复杂程度,同时为提升模型对花卉特征的提取与融合能力,在骨干网络尾部引入轻量级混合注意力机制SA模块,通过组合通道注意力与空间注意力,对输入图像的特征信息进行增强,以提升模型的识别准确率。(3)本文在五类花卉数据集上对以上两个模型进行消融实验和对比实验,消融实验结果表明了所引入的一系列模块在模型轻量化上的有效性。对比实验结果显示,相较于主流图像识别模型,本文所提出的两种模型在识别准确率基本相当的情况下,在计算量、参数量、模型大小、推理时间等四项指标上均获得了较好的效果,实现了速度与精度的平衡。
{URL}: https://link.cnki.net/doi/10.26981/d.cnki.gjhsc.2024.000485
{DOI}: 10.26981/d.cnki.gjhsc.2024.000485
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的道路表面缺陷检测方法研究及系统设计
{Author}: 刘旭
{Tertiary Author}: 陈里里
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 道路表面缺陷检测;计算机视觉;目标检测;深度学习;模型剪枝
{Abstract}: 作为最基础的交通基础设施之一,道路对交通运输以及城市发展至关重要。随着我国道路里程数的不断增加,对道路的养护需求也与日俱增。作为道路状态最真实的反映,道路表面缺陷检测一直都是道路维护和状态监测的重要环节,对于保障道路畅通和道路安全有着重要意义。目前道路表面缺陷检测主要采用基于人工视觉的半自动化检测方法,这种方法检测效率低、周期长且检测结果易受人为主观因素影响。计算机视觉技术能快速、准确的获取路面信息,在道路表面缺陷检测方面有着传统方法无法比拟的优势,可以对道路表面缺陷精准识别。
本文致力于对道路表面缺陷的精准检测。以道路中存在的裂缝、坑洞、裂纹缺陷为研究对象,采用基于深度学习噪声去除算法对图像中包含的微小噪声进行抑制。针对道路表面缺陷分布随机、类型多变的特点,进行了基于深度学习目标检测算法的道路表面缺陷识别研究,旨在设计出能够快速、准确的对真实路面中的缺陷精准识别的模型。具体的研究工作包括以下三个方面:
(1)首先根据道路表面缺陷检测任务需求,设计了图像采集设备并完成相应的硬件选型。然后,利用选型设备进行道路表面缺陷图像采集。针对道路表面缺陷图像中存在的潜在噪声,使用噪声估计方法进行噪声情况评估,再利用基于深度学习和基于自适应滤波器的滤波方法对其进行噪声抑制。最后,进行滤波结果可视化分析与对比。
(2)分析了YOLOV8模型的结构与特点,并基于该结构构建用于道路表面缺陷检测的模型。在该模型中使用构建的动态Transformer特征增强模块和双重注意力引导的特征筛选模块,用于提高模型对不规则缺陷的感知能力和背景噪声抑制能力。此外,还使用AFPN替换原有的特征融合结构,并重新设计了损失函数,以进一步提高模型对道路表面缺陷的检测性能。实验结果表明,构建的模型在道路表面缺陷检测任务上具有优异的检测能力,能够快速、精准的对路面存在的缺陷进行识别。
(3)研究了道路表面缺陷检测模型的轻量化。首先,对构建的道路表面缺陷模型进行分析,选择适合该模型的模型压缩策略,即模型剪枝。接着,采用不同的剪枝方法进行剪枝操作,以减少模型复杂度。然后,使用m AP、GFLOPs、Params和FPS对剪枝后的模型进行综合评价,选择最优的剪枝算法。最后,基于Py Qt设计了道路表面缺陷检测系统并将剪枝后的模型进行部署,用于道路表面缺陷检测。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2024.000544
{DOI}: 10.27671/d.cnki.gcjtc.2024.000544
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Faster RCNN的瓷砖表面缺陷检测算法
{Author}: 王建国;孙付仲;苑子龙;孙殿富
{Author Address}: 南京工业大学机械与动力工程学院;
{Journal}: 南京工业大学学报(自然科学版)
{Year}: 2025
{Volume}: 47
{Issue}: 01
{Pages}: 49-55
{Keywords}: 缺陷检测;机器视觉;Faster RCNN;深度学习;CBAMM;ASFF
{Abstract}: 瓷砖作为生产生活中的必需品，受各种生产因素影响会产生不同的表面缺陷。目前，该缺陷主要靠人工检测，因此带来检测效率低、劳动强度大等难题。针对瓷砖表面的多种缺陷，提出了一种基于机器视觉的快速卷积神经网络(Faster RCNN)改进算法。首先，针对训练过程中存在的过拟合问题，对原始数据集进行预处理，扩充数据集容量；其次，在Faster RCNN算法主干特征提取网络中添加卷积块注意力混合模块(CBAMM)机制，对瑕疵缺陷进行自主学习并加强对图像深层特征的提取；最后，为保证瓷砖图像中小瑕疵特征的提取，在获得的Proposal建议框上提出自适应空间特征融合(ASFF)算法。结果表明：改进Faster RCNN算法对各类缺陷检测精度均能达到97.2%以上，相较于原始算法，该模型检测精度提升了3.5%,可以更精确地检测瓷砖瑕疵，有利于提高企业的经济效益。
{ISBN/ISSN}: 1671-7627
{Notes}: 32-1670/N
{URL}: https://link.cnki.net/urlid/32.1670.n.20240424.1604.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的植物病害识别方法综述
{Author}: 于明;郭志永;王岩
{Author Address}: 河北工业大学人工智能与数据科学学院;天津商业大学信息工程学院;
{Journal}: 科学技术与工程
{Year}: 2024
{Volume}: 24
{Issue}: 12
{Pages}: 4811-4823
{Keywords}: 植物病害识别;计算机视觉;卷积神经网络;特征提取;注意力机制
{Abstract}: 病害识别是计算机视觉技术在农业领域的重要应用之一，对及时发现和早期预防植物病害起着关键作用。近年来，随着病害识别方法的不断演进，病害识别性能有了显著提高，但自然条件下病害特征提取困难、病害严重程度难以区分等问题依然存在。为了在现有方法的基础上进一步探索病害识别的新思路，先是针对不同识别目标，分析病害识别和病害严重程度识别的研究现状。然后从视觉特征类型和学习方式两个角度对植物病害识别方法进行全面的比较与研究，指出深度模型是当前植物病害识别的主流方法，融合多源信息和结合不同的机器学习方式是改进植物病害识别的重要手段，并将不同识别方法在主流数据集上的性能进行对比和分析。最后对未来发展方向进行展望。
{ISBN/ISSN}: 1671-1815
{Notes}: 11-4688/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw6rIDwlTcu1y9i6IZpY0rQXdAQkk4eOW43YZZiuuYL2rfTOjboKvSTjKCzP2bmKg9fQjnSmbeaRbNt_1kzt2BtP57FAhAU-BONbiy3geD_ho1HVgCP8qNErd3DCZp35jbsRGvtXEs0ZDCcEVlkodQWPbJCDdEkVGZtYyUwtTwcc-C9Q-PgE8uu7Aypi3xj0PA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向电力无人机巡检图像分析处理的自动化深度学习系统：架构设计与关键技术
{Author}: 李道兴;王晓辉;李黎;季知祥
{Author Address}: 中国电力科学研究院有限公司;
{Journal}: 电力信息与通信技术
{Year}: 2024
{Volume}: 22
{Issue}: 04
{Pages}: 38-54
{Keywords}: 输电线路巡检;深度学习;自动化训练;图像分析处理
{Abstract}: 当前电力无人机巡检图像处理模型存在适用范围小、研发成本高、研发周期长等问题，文章提出一种面向无人机巡检图像分析处理的自动化深度学习系统，明确该系统设计的泛化性、可拓展性、自动化三要素，综述与三要素密切相关的技术进展，设计系统架构，构建原型系统。实验表明，在绝缘子自爆识别和鸟巢识别2项电力无人机巡检图像分析处理上，系统自动化构建的模型全类平均精度分别可达91.36%和86.13%，表明系统设计理念合理且系统架构可行。
{ISBN/ISSN}: 2095-641X
{Notes}: 10-1164/TK
{URL}: https://link.cnki.net/doi/10.16543/j.2095-641x.electric.power.ict.2024.04.05
{DOI}: 10.16543/j.2095-641x.electric.power.ict.2024.04.05
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于扩展卡尔曼滤波与机器视觉融合的道路侧向坡度估计
{Author}: 严运兵;岳铭浩;李海玮
{Author Address}: 武汉科技大学汽车与交通工程学院;
{Journal}: 汽车工程
{Year}: 2024
{Volume}: 46
{Issue}: 04
{Pages}: 605-616+625
{Keywords}: 侧向坡度;坡度估计;扩展卡尔曼滤波;机器视觉;数据融合
{Abstract}: 为解决现有算法难以准确估计前方道路侧向坡度的问题，提出了一种基于扩展卡尔曼滤波（EKF）与机器视觉（VB）融合的道路侧向坡度估计方法。首先，建立含有侧向坡度的车辆2自由度模型，通过EKF估计出侧向坡度与车辆侧倾角的叠加态，由侧向加速度乘以适当增益解耦出车辆侧倾角，得到EKF道路侧向坡度估计值；其次，通过视觉成像原理分析二维图像中道路侧向坡度与图像中相关参数的几何关系，得到VB道路侧向坡度估计值；最后，通过数据融合得到最终的道路侧向坡度估计值，使估计结果冗余互补。仿真和实车试验结果表明，该融合算法能够适用于道路侧向坡度变化的坡道，并显著提高了估计精度。
{ISBN/ISSN}: 1000-680X
{Notes}: 11-2221/U
{URL}: https://link.cnki.net/doi/10.19562/j.chinasae.qcgc.2024.04.006
{DOI}: 10.19562/j.chinasae.qcgc.2024.04.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和卷积神经网络的无人化智能装卸研究
{Author}: 陶加贵;韩飞;汪伦;赵恒
{Author Address}: 国网江苏省电力有限公司电力科学研究院;国网江苏省电力有限公司;
{Journal}: 自动化技术与应用
{Year}: 2024
{Volume}: 43
{Issue}: 04
{Pages}: 26-30
{Keywords}: 机器视觉;卷积神经网络;无人化;智能装卸;机器人;张氏标定法
{Abstract}: 利用机器人可以大批量、不间断作业的优势，设计基于机器视觉和卷积神经网络的无人化智能装卸方法。使用机器视觉系统采集无人化智能装卸机器人装卸时的图像数据，通过自适应卷积神经网络的无人化智能装卸图像识别方法获得待装卸物体，将其在图像坐标系下的坐标值运用张氏标定法转化为机器人坐标系下的坐标值，根据转化结果采用快速扩展随机树算法驱动机器人运动到坐标位置，实现待装卸物体的无人化智能装卸。实验结果表明：该方法能识别出全部待装卸物体；标定所得重投影误差值小，无人化智能装卸机器人运动路径短，并能有效避开所有障碍物，能高效、精准地装卸全部待装卸物体。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2024)04-0026-05
{DOI}: 10.20033/j.1003-7241.(2024)04-0026-05
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉中的图像识别与处理技术分析
{Author}: 庄俊
{Author Address}: 常州市高级职业技术学校;
{Journal}: 电子技术
{Year}: 2024
{Volume}: 53
{Issue}: 04
{Pages}: 332-333
{Keywords}: 计算机视觉;图像识别;图像处理
{Abstract}: 阐述计算机视觉在图像识别与处理中的应用现状及优势，介绍基于计算机视觉的图像分割技术、物体识别与跟踪技术、图像恢复与增强技术，以及在图像识别与处理中的优势与应用案例。
{ISBN/ISSN}: 1000-0755
{Notes}: 31-1323/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxkmmkTbduQBNVt3GN3BSNTR_kluxXkoH_7PJ4b1UOsiEkDNoN7-2ZvhBjlmkiKLdmkZBgkvaw4XRviwPzaUDNEo0U4eUonrx0gONzx-9Ji5IHs2BAao4WneOj2Kk5rIXGQcM4xODO2fR6GtGqDmzKeJvthp2EgAURc0dw6iJKNmBSsGCtH0ZenVI0HSkIofNo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的小型零件圆度测量
{Author}: 丁哲文;张瑞;朱振伟;赵华东;刘丙康
{Author Address}: 郑州大学机械与动力工程学院;河南省智能制造研究院;
{Journal}: 组合机床与自动化加工技术
{Year}: 2024
{Volume}: 
{Issue}: 04
{Pages}: 171-174+180
{Keywords}: 机器视觉;圆度误差;边缘检测;最小区域法;小型零件
{Abstract}: 针对小型零件圆度误差测量效率低、精度不稳定等问题，提出了一种基于机器视觉的小型零件圆度测量方法。通过建立机器视觉检测平台，获得零件图像。经过预处理后，通过Canny算子结合8领域扩张算法划定感兴趣区域，采用多项式插值亚像素边缘检测算法获得边缘坐标；然后，利用改进区域搜索算法确定准圆心，并通过最小区域法的几何结构找出最小区域圆心，从而计算圆度误差。实验结果表明，圆度误差的测量重复精度为8.1μm,能够实现小型零件的非接触测量。
{ISBN/ISSN}: 1001-2265
{Notes}: 21-1132/TG
{URL}: https://link.cnki.net/doi/10.13462/j.cnki.mmtamt.2024.04.036
{DOI}: 10.13462/j.cnki.mmtamt.2024.04.036
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv8的目标检测方法研究
{Author}: 邵宗翼
{Tertiary Author}: 李睿
{Publisher}: 兰州理工大学
{Type of Work}: 硕士
{Year}: 2024
{Keywords}: 目标检测;卷积神经网络;YOLOv8;高阶空间交互;结构重参数化
{Abstract}: 目标检测是计算机视觉的一个重要任务,其主要目的是在图像中定位和识别不同的物体。目标检测的应用场景非常广泛,如人脸识别,自动驾驶,医学影像分析等。一阶段目标检测器YOLO系列是最具代表性的一类,其优点是速度快、准确率高,可以实现端到端的训练和推理。YOLOv8模型在目标检测任务中取得了相当优秀的表现,但该模型仍然存在一些不足之处,例如特征提取网络性能不强,对小目标和密集目标的检测效果不理想,对不同尺度和形状的目标的适应性不够好,且模型泛化能力有待提高。为了解决上述问题,提出了基于改进YOLOv8的目标检测方法,主要包括以下创新内容:(1)提出了一种改进的分类网络结构。该网络中卷积模块借助高阶空间交互和结构重参数化进行了重新设计。使用两次空间交互操作使得特征提取能力相较于普通卷积模块有所提升,且在推理阶段能够将卷积部分的分支结构重参数化为单一分支提升推理速度。模块即插即用,应用于图像分类任务中取得了较为优秀的结果,在mini-Image Net数据集上取得了84.3%的TOP-1精度,相较于基线模型提高了0.4%。改进模块能提取出丰富和多尺度的特征,能够进一步为后续的目标检测提供有效的信息。对比实验结果表明,该模型对于检测精度有较为明显的提升,且对于模型推理速度方面有所提高。(2)提出一种改进的YOLOv8目标检测器。将所提出的分类任务网络中主要卷积模块应用于YOLOv8模型的同时,在YOLOv8颈部加入可变型卷积v3和坐标卷积。可变型卷积可以动态地调整卷积核的大小和形状,以适应不同的目标,从而提高检测的精度和鲁棒性。且该卷积方式能够根据输入的特征图的尺度和目标的数量,自适应地选择合适的卷积核,从而减少计算量和参数量,提升目标检测器性能。坐标卷积可以在卷积核中加入坐标信息,从而增强卷积核对目标位置的敏感度,提高回归的精度。模型使用了一种改进的交并比函数——Wise-Io U,通过该交并比函数对YOLOv8损失函数进行优化。Wise-Io U是一种基于分布的交并比函数,该交并比可以根据目标的概率分布,计算出目标的期望交并比和方差交并比并自动地给予不同的权重,从而反映出目标的不确定性和多样性避免小目标和密集目标被忽略或者过分惩罚。(3)改进后模型在通用数据集Microsoft COCO上达到了39.1%的m AP,相较原模型提高了约2%。而模型计算量则降低了0.6GFLOPs下降幅度约7%。改进后模型在保持高精度的基础上推理速度有一定程度提升。且模型泛化性能优秀,不进行有针对性改动的情况下在多种应用场景数据集中综合表现最佳。
{URL}: https://link.cnki.net/doi/10.27206/d.cnki.ggsgu.2024.000290
{DOI}: 10.27206/d.cnki.ggsgu.2024.000290
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的番茄分选实验台系统设计
{Author}: 马博;李丹;代丹丹;李川江;胡昊天
{Author Address}: 新疆工程学院机电工程学院;航天科技控股集团股份有限公司;
{Journal}: 南方农机
{Year}: 2024
{Volume}: 55
{Issue}: 07
{Pages}: 35-37+49
{Keywords}: 番茄分选;机器视觉;实验台;LabVIEW;缺陷检测
{Abstract}: 【目的】解决番茄加工企业人工分选原料效率低、质量不稳定等问题。【方法】提出一种基于机器视觉技术的实验台系统，以番茄的自动化分选为目的，运用图像处理技术，采用缺陷检测的方法，将不合格番茄上的虫洞、霉斑、青背及黄晕等问题视作缺陷进行识别。该系统以自动分选单元为载体，使用CCD工业相机采集图像，基于LabVIEW软件设计上位机的视觉识别软件，并通过串行通信接口将识别结果发送至下位机控制分选单元完成分选。【结果】仿真结果表明，该实验台系统能够准确地识别缺陷番茄并剔除，系统性能稳定，为进一步开发番茄在线智能分选系统提供了理论基础和实践依据。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxRGYQ7qLIvXCdZS5x8xp7JNkaa1BgIRGOD17sY1k3ffaW-UslvPPQTTJeJzVL8W6RxaP4EKaKvfmifg3Z8kVhzySnGBqQsPA3ECpZCWk4mkK7pRh42Mt-nOIhwvLBaObYfi267J1NuTT5FIOPcNksZT1pXmqOyYSPGy6yR31Oho6H-3BLBGfolAYXqSdf8clE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进SSD算法的紫外像增强器视场瑕疵检测方法
{Author}: 丁习文;程宏昌;袁渊;苏悦
{Author Address}: 昆明物理研究所;微光夜视技术重点实验室;
{Journal}: 兵工学报
{Year}: 2024
{Volume}: 45
{Issue}: 12
{Pages}: 4350-4363
{Keywords}: 紫外像增强器;视场瑕疵检测;机器视觉;深度学习
{Abstract}: 紫外像增强器视场瑕疵是影响器件成像效果的重要因素之一。针对视场瑕疵样本数量少和视场图像显示差异大的问题，采取相应的数据增强策略，并在单发多框检测(Single Shot multibox Detector, SSD)算法的基础上，添加特征金字塔网络(Feature Pyramid Network, FPN),以解决多尺度特征难以有效识别与融合的问题。同时引入卷积注意力模块(Convolutional Block Attention Module, CBAM)去进一步加强网络对小瑕疵目标信息的关注，并抑制噪声干扰。试验结果表明：在自建的数据集上，添加了FPN和CBAM的SSD(Feature Pyramid Network-Convolutional Block Attention Module-Single Shot Multibox Detector, FPN-CBAM-SSD)算法在视场瑕疵实际检测效果方面更优于SSD算法。对于亮点、暗斑、条纹状、亮斑和暗点这5类瑕疵，其平均精准度分别提高了19.76%、22.84%、29.56%、34.55%和38.14%。FPN-CBAM-SSD算法能够满足实际应用需求，适应更加复杂的视场情况，可视为一种有效的紫外像增强器视场瑕疵检测新型方法。
{ISBN/ISSN}: 1000-1093
{Notes}: 11-2176/TJ
{URL}: https://link.cnki.net/urlid/11.2176.TJ.20240326.1128.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的变速器齿轮表面缺陷检测研究
{Author}: 罗山;廖瑞;郑彬
{Author Address}: 攀枝花学院电气信息工程学院;攀枝花学院智能制造学院;
{Journal}: 制造业自动化
{Year}: 2024
{Volume}: 46
{Issue}: 03
{Pages}: 130-133+166
{Keywords}: 变速器齿轮;表面缺陷检测;机器视觉;Halcon
{Abstract}: 针对人工检测变速器齿轮表面缺陷存在可靠性差、效率低、不能满足批量生产的问题，开展齿轮表面缺陷自动检测的研究。以汽车变速器齿轮为检测对象，首先搭建机器视觉齿轮表面缺陷检测系统，采集齿轮缺陷图像样本，对采集的齿轮图像进行去噪、增强等预处理；然后采用改进的Scharr边缘检测算法提取齿轮边缘；最后获取感兴趣区域的坐标信息，寻找齿轮外圆的边缘点，计算齿轮的边缘点之间的距离，从而实现齿轮缺陷的精确定位。实验结果表明：该系统可准确检测出齿轮表面缺陷所在位置，可靠性和稳定性良好，检测效率高，为机器视觉齿轮缺陷检测技术的应用提供了思路。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyD4J2-d5BnmNCTZ9DrstbiKl9HTifmxqw7hZpXZQca8OvrUC7N4lGZ_dpkFaktwuxkq4-jA34xsCy39POvWSzBO377z4phTMResSo7bx5cDMs3h7o0oxZ4y9oZgWFIR5bgcHk_kokjwhY-LzToS6B7hH_1AZdImfKXOYB44DX-Lq8vhOh1A3dgQWkNfb8Xt70=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于FPGA的视觉处理系统设计
{Author}: 任志墨;张文昌;李贞逸;张倩
{Author Address}: 北京机科国创轻量化科学研究院有限公司;先进成形技术与装备国家重点实验室;
{Journal}: 制造业自动化
{Year}: 2024
{Volume}: 46
{Issue}: 03
{Pages}: 186-189
{Keywords}: 现场可编辑门阵列;机器视觉;图像预处理;嵌入式;结构光
{Abstract}: 为提高视觉定位系统的运算速度并降低成本与功耗，设计了一种基于FPGA(Field Programmable Gate Array，现场可编程门阵列)的图像采集处理系统。首先以OV5640相机作为图像采集器件，使用DDR3存储器对每帧图像进行缓存。其次基于FPGA流水线计算与并行处理特性，设计图像预处理模块，完成对初始图像的灰度化、中值滤波、二值化及膨胀腐蚀处理。然后将处理后图像传输至LCD显示屏完成实时显示工作。最后通过二维定位实验表明视觉系统平均定位误差为0.224mm，视觉算法延迟为3.48μs，能够快速准确地完成视觉定位工作，为视觉系统基于FPGA平台的开发应用提供了参考。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzMKo2BMcRwRRNwDSyIRegYOSLusFFnv_DGYBeAnuEtKbZYRrAbHj5-DVwhQcWAABmypNxN_z_9TtcM41uReXes2sI_Q-sjaJXaQcCOCcse7FFqSsS9eFzpvTn5RJDQeJ1ISwL2hMFM4Uh5y9pSwPVFvlA87utiCCbuUDmzjacWhGiF3-BzZb6dm5pgHcHdMxo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 30年来基于计算机视觉的农业科技研究综述——以CNKI文献关键词词频分析为技术方法
{Author}: 巢品;冯祥胜
{Author Address}: 南昌工程学院信息工程学院;
{Journal}: 南方农机
{Year}: 2024
{Volume}: 55
{Issue}: 06
{Pages}: 24-28+35
{Keywords}: 农业科技;计算机视觉;关键词;词频分析
{Abstract}: 【目的】计算机视觉技术被广泛应用于天文学、地质学、气象学、军事科学、医学、工农业生产等诸多领域，对我国农业科技及农业发展意义重大。【方法】以关键词词频分析为技术方法，筛选1993—2022年CNKI农业科技专辑中篇名含“计算机视觉”的文献，对获取的393条文献进行计量学分析，并综述国内30年来基于计算机视觉的农业科技研究成果、热点及发展态势。【结果】基于计算机视觉的农业科技研究高频关键词分布较为广泛，现有研究热点较多，研究领域、研究方法、研究技术等都在不断丰富和拓展。【结论】本研究可为后续农业科技方向的研究提供一定参考或借鉴，但还需不断探索基于计算机视觉的农业科技研究中的内在发展逻辑与深层理论关系。
{ISBN/ISSN}: 1672-3872
{Notes}: 36-1239/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwwFJZiOtvCloB6ZHZXQokhSnUEn44-T0RC-Vb6bQqovoWeply9Besa9QFh27IIs-jL8aq94NTGNxZA5Q4SUgowc6TXXxuZEZ_nyYvw8dpV-G0UK3GTaJBpgM_14kLra8-ZAS6k-w2ewdyqg72DfNLFmR2BXKhjR3F02-26ClDjysDjqZngT1NI-J-DQVLUMiw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像处理中基于深度学习的图像语义分割综述
{Author}: 陈惠民
{Author Address}: 湖北大学网络空间安全学院;
{Journal}: 科技资讯
{Year}: 2024
{Volume}: 22
{Issue}: 06
{Pages}: 10-13
{Keywords}: 图像处理;语义分割;计算机视觉;人工智能;深度神经网络
{Abstract}: 图像语义分割（Semantic Segmentation）是计算机视觉领域的研究热点，图像语义分割不仅能预测一幅图像中的不同类别，同时还能定位不同语义类别的位置，具有重要的研究意义和应用价值。这些方法被用于人工智能当中，应用于无人驾驶、遥感影像检测、医疗影像等研究领域。全卷积神经网络的快速崛起推动了图像语义分割领域的发展，二者的融合取得了显著的成就。主要从语义分割的介绍出发，对近几年的代表性工作进行了阐述，并对未来的研究方向进行展望。
{ISBN/ISSN}: 1672-3791
{Notes}: 11-5042/N
{URL}: https://link.cnki.net/doi/10.16661/j.cnki.1672-3791.2311-5042-5346
{DOI}: 10.16661/j.cnki.1672-3791.2311-5042-5346
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 工业机器人单目视觉装配系统研究
{Author}: 王新;郭俊
{Author Address}: 内蒙古农业大学职业技术学院;内蒙古机电职业技术学院;
{Journal}: 机械设计与制造
{Year}: 2024
{Volume}: 
{Issue}: 06
{Pages}: 342-347
{Keywords}: 机器视觉;单目视觉;工业机器人;图像处理;位姿估计
{Abstract}: 为了解决传统机器人只能通过示教或离线编程固定执行点到点装配任务的问题，进行了视觉引导的工业机器人装配方面的研究。首先对工业机器人视觉装配过程建立数学模型并标定，然后研究了基于机器视觉的零件位姿估计方法，针对法兰盘类金属零件弱纹理及无角点特征的位姿估计问题，提出了一种基于自身特征和外部标记辅助的单目视觉位姿计算方法。最后搭建了工业机器人单目视觉装配实验平台验证该位姿计算方法的可行性。实验结果表明，该系统能够实现对法兰盘类零件的定位和装配，最小位置误差为2.07mm，最小姿态误差0.13。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20240318.002
{DOI}: 10.19356/j.cnki.1001-3997.20240318.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于对抗注意力机制的水下遮挡目标检测算法
{Author}: 罗偲;李凯扬;吴吉花;任鹏
{Author Address}: 中国石油大学(华东)海洋与空间信息学院;
{Journal}: 计算机工程
{Year}: 2024
{Volume}: 50
{Issue}: 10
{Pages}: 313-321
{Keywords}: 机器视觉;水下目标检测;对抗样本;损失函数;SE-ResNet50网络;特征融合
{Abstract}: 水下环境复杂，遮挡目标信息缺失严重而难以提取到足够的特征信息，导致水下遮挡目标易被漏检。为解决该问题，提出一种基于对抗注意力机制的水下目标检测算法。以Faster R-CNN算法为框架，提出基于空间注意力机制的对抗生成遮挡样本网络(AOGN)。AOGN与Faster R-CNN网络相互竞争，通过三阶段训练过程，在不增加推理负担的情况下学习生成检测网络难以正确区分的样本，提高Faster R-CNN网络对水下遮挡目标的检测精度。使用Focal loss增加困难样本的损失比重，解决水下数据集难易样本不平衡的问题。在此基础上，为获得更丰富的水下目标特征信息，使用SE-ResNet50代替VGG16作为骨干网络，通过残差网络和SE模块的结合获得更有效、更丰富的水下目标信息，提高对检测目标的特征提取能力，同时加入多条ROIpooling支路实现多尺度特征融合，增加特征的丰富性。实验结果表明，该算法在URPC数据集和水下垃圾数据集上分别取得了73.76%和86.85%的平均精度均值(mAP),遮挡目标漏检率分别达到2%和7%,相较于其他检测算法能够有效提升检测性能。
{ISBN/ISSN}: 1000-3428
{Notes}: 31-1289/TP
{URL}: https://link.cnki.net/doi/10.19678/j.issn.1000-3428.0068279
{DOI}: 10.19678/j.issn.1000-3428.0068279
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的电子元件表面缺陷检测算法
{Author}: 任学龙
{Author Address}: 俐玛光电科技(北京)有限公司;
{Journal}: 科学技术创新
{Year}: 2024
{Issue}: 06
{Pages}: 116-119
{Keywords}: 计算机视觉;电子;元件;表面;缺陷;检测;算法
{Abstract}: 为了优化电子元件表面缺陷检测效果，提升缺陷检测率，实现自动、快速、准确的检测目标，引入计算机视觉，提出了一种全新的电子元件表面缺陷检测算法。首先，拍摄电子元件表面图像，对图像进行滤波处理，消除原始图像中多余的噪声；其次，基于阈值分割原理，将电子元件图像划分成若干个区域，从各个区域中提取与元件表面缺陷相关的特征，初步检测电子元件表面缺陷；在此基础上，基于计算机视觉技术，设计电子元件表面缺陷检测算法，进一步精确检测元件表面是否存在缺陷。实验结果表明，提出的检测算法应用后，6种不同类型的电子元件表面缺陷检测率均较高，检测能力更强，准确性和可靠性优势显著。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyAYwuCd3B2pxQxNUZny9y7quWHJ8VVEof1bXpnXY6cs2gboRw4TiqJZkvsHcVBlfweE91q2hB5QlrKIyBbergKh3mTfSzAbeyQXxj-rZHjmlWCbolsEffP5SN4i3J9RsZLe0gqQIb9mdg9_XiWmg-EmPKS52sSxYcIiGmUlfsTarYYFUDq-78lu_0_jKXCxiU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv8和多元特征的对虾发病检测方法
{Author}: 许瑞峰;王瑶华;丁文勇;於俊琦;闫茂仓;陈琛
{Author Address}: 中国浙江省海洋水产养殖研究所;上海海洋大学水产与生命学院;浙江省近岸水域生物资源开发与保护重点实验室;温州市海洋生物遗传育种重点实验室;
{Journal}: 智慧农业(中英文)
{Year}: 2024
{Volume}: 6
{Issue}: 02
{Pages}: 62-71
{Keywords}: 对虾病害;计算机视觉;YOLOv8;Farneback光流法;灰度共生矩阵;支持向量机
{Abstract}: [目的/意义]对虾病害严重危害对虾养殖业。针对对虾病害发病快、死亡率高等特点,高密度的工厂化养殖等模式需要一种高效率对虾发病检测方法替代传统人工检查方法,实现对虾发病的及时预警。[方法]提出一种基于改进YOLOv8 (You Only Look Once)和多元特征的对虾发病检测方法。首先利用改进YOLOv8网络从对虾夜间水面红外图像中进行前景提取,再利用Farneback光流法和灰度共生矩阵(Gray Level Co-occurrence Matrix,GLCM)提取对虾视频片段的运动特征与图像纹理特征,利用提取到的特征参数构建训练数据集,训练支持向量机(Support Vector Machine,SVM)作为分类器用于检测对虾视频片段,实现对正常与发病的对虾视频片段的检测分类。[结果和讨论]训练好的SVM分类器在300个测试样本上的表现为检测准确率平均值为83%,检测效果达到设计要求。检测误差主要是将发病片段错误地检测为正常片段。该误差主要受水面对虾数量和视频影响。[结论]本研究实现了对对虾发病的检测,提供了一种基于计算机视觉的检测方法。但受条件限制,仅在工厂化养殖环境下进行了实验,尚不能适用于多种养殖环境,仍有改进空间。
{ISBN/ISSN}: 2096-8094
{Notes}: 10-1681/S
{URL}: https://link.cnki.net/urlid/10.1681.S.20240228.1734.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的元器件分拣系统设计
{Author}: 李健伟;冼灿娇;王瑞镱;严晓媚;蓝妙飞;杨丰源
{Author Address}: 广西民族师范学院;
{Journal}: 电子制作
{Year}: 2024
{Volume}: 32
{Issue}: 05
{Pages}: 42-45
{Keywords}: 机器视觉;机器学习;电子元器件分拣
{Abstract}: 随着教育行业的兴起与发展，在众多高校中，电子专业课程的实验室和关于电子的社团在元器件管理方面会存在一些问题，比如元器件的存储存在不同型号元器件混合在一起该如何去解决的问题。在目前，元器件存储分拣通常需要花费大量的人力和时间。近年来，世界智能化程度越来越高，我们可以通过智能机器视觉来代替人工去识别大量的元器件混合场景，以提高分拣效率，降低传统分拣时间精力浪费的问题，减少重复枯燥的分拣工作。本系统主要针对传统元器件分拣方法准确率和效率低等问题，设计一个基于机器视觉的元器件分拣系统，可以广泛应用于数电实验室和社团元器件混合等多种需要进行元器件分拣分类识别的应用场景，具有较高的准确率和实时性，克服了人工分拣工作效率和正确率较低的问题。
{ISBN/ISSN}: 1006-5059
{Notes}: 11-3571/TN
{URL}: https://link.cnki.net/doi/10.16589/j.cnki.cn11-3571/tn.2024.05.010
{DOI}: 10.16589/j.cnki.cn11-3571/tn.2024.05.010
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的裂纹鸡蛋分拣系统设计
{Author}: 郭建军;杨霖;张恩威;刘双印;李俊勇;姚赵忠;谢彩健
{Author Address}: 仲恺农业工程学院信息科学与技术学院;广州东文环境技术有限公司;广州顺生生物科技有限公司;
{Journal}: 现代农业装备
{Year}: 2024
{Volume}: 45
{Issue}: 01
{Pages}: 45-52
{Keywords}: 机器视觉;裂纹特征;检测系统;图像预处理;分类识别
{Abstract}: 本文综合研究了鸡蛋分拣系统设计方法,基于机器视觉技术,对分拣系统硬件选型及布局、鸡蛋图像信息采集、鸡蛋图像预处理与特征提取等各个阶段所需要的技术进行选用,设计了裂纹鸡蛋视觉模块,结合分拣设备组成裂纹鸡蛋分拣系统。该系统可有效实现对裂纹鸡蛋的分拣,提高鸡蛋裂纹的检出效率。最后探讨了该分拣系统设计上存在的问题,并指出未来改进的方向及研究的重点。
{ISBN/ISSN}: 1673-2154
{Notes}: 44-1616/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxOPxtXYqegX8D4iUS5bSMn8Jf37-Va3oE3KO_ORWPGsk--heJ2K0ukG3hLLjDjujoeon30Y1vkuFSR_fE5f1ejlkYj9PaytYRPRZWUxoI6OGNtzN9XzdtwarD-gpVmcWrHea9MI-EiyzcQdPFTcGd5pOWjQxJW--TqO3_LEfgV1jMMsceOO9FLslDTg76bcXs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的茶叶品种识别研究
{Author}: 江会权
{Author Address}: 浙江农林大学;
{Journal}: 福建茶叶
{Year}: 2024
{Volume}: 46
{Issue}: 02
{Pages}: 25-27
{Keywords}: 茶叶识别;机器视觉;嫩芽识别
{Abstract}: 在人们的日常生活中，茶叶扮演着不可或缺的角色，在出口商品中，茶叶也是一种不可或缺的存在。随着社会经济的发展，人们越来越重视茶叶的健康性以及功能性等特点，从而促进了我国茶叶产业的不断发展壮大，尤其是茶叶产业的深加工产品更是成为市场上炙手可热的话题。名优茶因其精湛的工艺和卓越的品质而备受推崇，深受人们的青睐。因此，名优茶采摘技术的发展一直备受关注。然而，尽管名优茶的采摘仍处于手工采摘的阶段，但由于低效率的采摘工作无法扩大生产，因此需要研究一套全自动设备和理论，以解决茶叶嫩芽的识别和定位这一最为关键和困难的问题。因此如何准确地进行茶树芽叶识辨与精确定位，已成为当前亟待解决的难题之一。在考虑综合名优茶采摘的具体环境和近年来目标识别的相关进展的基础上，我们运用机器视觉相关理论，着重研究了芽叶的识别和定位问题。通过一系列图像预处理和颜色空间变换处理，我们成功建立了茶叶嫩芽的外形特征子集；利用mask矩阵的应用特征，实现了对嫩芽和老叶的鉴别，并自动完成了分割过程；基于张正友相机标定方法，运用改进的RANSAC算法进行特征匹配，最终实现了嫩芽的三维坐标提取和精确定位。实验表明，该方法能够准确地将茶叶嫩芽从背景中分离出来，并且较好地保持其形状轮廓不发生改变。
{ISBN/ISSN}: 1005-2291
{Notes}: 35-1111/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxuu70Fw6zUWV51DISJDbJUKqx7FlgQM7vaSqTKVBWf8S9pHM-qPWQfPYvWPmy3ZWUCpAA7nPpaH5OGkhJhSGLYjLWOEnSPLjGY-hIHnfpp6nMf9iUSr8cEaDvd-_kooTFkirPTr_0M1CJ2k1alRd-gGcgxciuzDeOom5UBa_54wkEq3vOXsGttDNAJYPlaGLY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的救援机器人自动避障技术研究
{Author}: 包子涵;李龙海;刘丽丽;孙伟;邱天宇;芮哲立;胡江;芮文翰
{Author Address}: 徐州工程学院机电工程学院;徐州工程学院电气与控制工程学院;
{Journal}: 机械制造与自动化
{Year}: 2024
{Volume}: 53
{Issue}: 01
{Pages}: 202-208
{Keywords}: 救援机器人;自动避障;非局部均值算法;图像降噪;小波变换;边缘检测
{Abstract}: 针对矿山救援机器人易受粉尘、光线昏暗等因素影响，导致其自动避障能力下降问题，研究一种基于机器视觉的救援机器人自动避障策略，可以实现在复杂环境下的有效避障。设计一种基于改进非局部均值滤波和多尺度B样条小波变换的机器视觉算法，以获得更高质量图像并精确获得障碍物边缘，确保救援机器人自主识别并避开障碍物。仿真结果表明：该算法相比传统算法在图像降噪和边缘检测上均体现出优越性。
{ISBN/ISSN}: 1671-5276
{Notes}: 32-1643/TH
{URL}: https://link.cnki.net/doi/10.19344/j.cnki.issn1671-5276.2024.01.041
{DOI}: 10.19344/j.cnki.issn1671-5276.2024.01.041
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于FPGA和机器视觉的多元特征模式水果分拣系统
{Author}: 赵放之;段升顺;吴俊
{Author Address}: 东南大学电子科学与工程学院;
{Journal}: 电子器件
{Year}: 2024
{Volume}: 47
{Issue}: 01
{Pages}: 248-254
{Keywords}: FPGA;机器视觉;多元特征识别模式;分拣系统;图像识别;机械臂;远程控制
{Abstract}: 水果自动分拣系统可以解放重复性人力劳动，提高工作效率，消除主观因素，提高工作科学化客观化。然而，目前水果分拣系统成本较高，尚无法大规模应用。因此，在FPGA平台上设计了基于多元特征机器视觉的低成本边缘式水果分拣系统。根据多元特征识别模式ZWM，定义了多元特征向量集和识别模式向量集等概念，进而建立了水果多元特征识别体系，可实现水果分类和水果分级识别。之后，通过将识别参数转化为舵机控制信息，机械臂可将识别出的水果搬运到指定位置，达到自动智能分拣效果。进而该系统可结合云端平台，通过手机实现分拣的远程控制。所提出的基于多元特征的低成本水果分拣系统，能够实现完成物品分类和分级融合分拣，可推动水果智能分拣系统的发展。
{ISBN/ISSN}: 1005-9490
{Notes}: 32-1416/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzr-Yi4eR_5yAm4kOYqpwLzD-5APaUCPpIwdIjy21oEIb6uzGmbw5IaCvuonGIp-Of3OEK8KscJ5TP-4iRi9tnvCjYqhPIdiyVS1i_6UXU6FgU6XU8mXO6gGdPjIOpcW2xwPg7Jsz7bUk2_zuWf4fZANdf6X8PpUADkQ-b0MvcuuK8suzf0cUsJo6Vn5_sDx5I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的生产线智能分拣系统设计
{Author}: 陈玉洁;黄龙亮;王海军;王成
{Author Address}: 贵州装备制造职业学院;
{Journal}: 自动化应用
{Year}: 2024
{Volume}: 65
{Issue}: 03
{Pages}: 36-38+42
{Keywords}: 机器视觉;生产线;智能分拣系统
{Abstract}: 以机器视觉技术为基础，从软硬件设计2个角度探讨生产线智能分拣系统研究设计工作。结果表明，该系统的分拣成功率指标较高，运行效率突出，具有潜在的应用价值。
{ISBN/ISSN}: 1674-778X
{Notes}: 50-1201/TP
{URL}: https://link.cnki.net/doi/10.19769/j.zdhy.2024.03.012
{DOI}: 10.19769/j.zdhy.2024.03.012
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于RGB图像的三维人手姿态估计技术综述
{Author}: 肖一;刘越
{Author Address}: 北京理工大学光电学院;
{Journal}: 计算机辅助设计与图形学学报
{Year}: 2024
{Volume}: 36
{Issue}: 02
{Pages}: 161-172
{Keywords}: 三维人手姿态估计;深度学习;计算机视觉;RGB图像
{Abstract}: 鉴于RGB相机在虚拟现实头盔等移动计算设备中的普遍性,基于RGB图像的三维人手姿态估计技术具有广阔的应用前景和研究价值,近年来已成为计算机视觉领域的一个研究热点.得益于深度学习技术的快速发展,与之相关的三维人手姿态估计算法层出不穷.文中回顾和总结了三维人手姿态估计技术.首先简述了三维人手姿态估计的相关工作,指出了其当前面临的挑战;然后梳理了基于RGB图像的三维人手姿态估计算法,对现有的基于参数模型方法和非参数模型方法进行了讨论,分析了每类算法包含的技术方法以及优缺点;之后总结了相关的三维手数据集与评价标准,并比较了每类算法在常用数据集上的表现;最后探讨了该技术的发展前景.
{ISBN/ISSN}: 1003-9775
{Notes}: 11-2925/TP
{URL}: https://link.cnki.net/urlid/11.2925.TP.20240206.1009.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合机器视觉与高精度定位的高速公路疲劳驾驶行为检测方法
{Author}: 孙健;唐旭;徐永能;苗梦格
{Author Address}: 江苏宁杭高速公路有限公司;南京理工大学自动化学院;中国电子科技集团公司第二十八研究所;
{Journal}: 交通运输研究
{Year}: 2023
{Volume}: 9
{Issue}: 06
{Pages}: 78-87+118
{Keywords}: 交通安全;人脸识别;疲劳驾驶;数据融合;高精度定位;疲劳驾驶检测
{Abstract}: 为提高高速公路场景下疲劳驾驶检测的准确率，降低在驾驶员面部易受遮挡、光线复杂的驾驶舱内的疲劳驾驶检测的误判率，提出一种兼顾检测精度与实时性、结合高精度定位与机器视觉的高速公路疲劳驾驶行为检测方法。首先，使用多任务卷积神经网络与FaceNet算法实现驾驶员身份识别，运用改进的实用面部特征点检测器（Practical Facial Landmark Detector, PFLD）算法检测人脸关键点。然后，考虑视频设备工作状态不稳定对疲劳驾驶行为识别产生干扰的场景，基于行驶车辆的轨迹数据，提出纵向位移波动斜率（Slope of Longitudinal Displacement Fluctuation, SLDF），以弥补单一视频设备检测易受光线、遮挡等干扰因素影响的缺陷。随后，使用SLDF指标和3个面部疲劳特征识别疲劳驾驶，并在传统支持向量机（Support Vector Machines, SVM）中加入量子粒子群优化算法，提升SVM分类准确度和缩短运算时间。最后，为验证模型性能进行实车试验，结果表明，复杂场景下疲劳驾驶识别准确率达86.8%，计算时间为3.017 s，与现有其他数据融合算法相比，改进后的SVM分类准确度和运算效率均有提升。融合轨迹、人脸面部多维度、多源的信息有效提高了该系统识别疲劳驾驶的检测精度及其工作的鲁棒性，可为后续高速公路场景下的疲劳特征的检测提供有力支持。
{ISBN/ISSN}: 2095-9931
{Notes}: 10-1323/U
{URL}: https://link.cnki.net/doi/10.16503/j.cnki.2095-9931.2023.06.008
{DOI}: 10.16503/j.cnki.2095-9931.2023.06.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种面向机器视觉感知的暗光图像增强网络
{Author}: 冯欣;王思平;张智先;焦晓宁;薛明龙
{Author Address}: 重庆理工大学计算机科学与工程学院;南京大学计算机软件新技术国家重点实验室;
{Journal}: 计算机应用研究
{Year}: 2024
{Volume}: 41
{Issue}: 06
{Pages}: 1910-1915
{Keywords}: 低光图像增强;机器视觉;RAW图像;ISP处理
{Abstract}: 低光照等恶劣环境下的目标检测一直都是难点，低光照和多雾因素往往会导致图像出现可视度低、噪声大等情况，严重干扰目标检测的检测精度。针对上述问题，提出了一个面向机器视觉感知的低光图像增强网络MVP-Net,并与YOLOv3目标检测网络整合，构建了端到端的增强检测框架MVP-YOLO。MVP-Net采用了逆映射网络技术，将常规RGB图像转换为伪RAW图像特征空间，并提出了伪ISP增强网络DOISP进行图像增强。MVP-Net旨在发挥RAW图像在目标检测中的潜在优势，同时克服其在直接应用时所面临的限制。模型在多个真实场景暗光数据上取得了优于先前工作效果并且能够适应多种不同架构的检测器。其端到端检测框mAP(50%)指标达到了78.3%,比YOLO检测器提高了1.85%。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2023.08.0404
{DOI}: 10.19734/j.issn.1001-3695.2023.08.0404
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种基于生成对抗架构的目标检测增强算法
{Author}: 张昀;黄橙;施健;张玉瑶;黄经纬;于舒娟;黄丽亚
{Author Address}: 南京邮电大学电子与光学工程学院、柔性电子(未来技术)学院;
{Journal}: 计算机学报
{Year}: 2024
{Volume}: 47
{Issue}: 03
{Pages}: 647-661
{Keywords}: 计算机视觉;目标检测;生成对抗训练;特征提取;分类预测
{Abstract}: 目标检测网络的性能往往受制于特征提取网络的深度,而网络参数的大量增加只能带来检测系统性能的少量提升,同时需要引进许多额外的网络细节设计,这些都会导致训练难度的增加.本文提出了一种基于生成对抗训练的目标检测方法,它以减少特征分布的EM距离(Wasserstein距离)为训练目标.具体来说,我们将检测网络从整个架构中提取出来,并对特征提取网络进行深入的对抗性训练.实验证明,本文提出的架构进一步提高了网络的特征提取能力,并且没有导致参数的增加.在MS COCO 2017数据集上,本文的架构将基于ResNet101的CenterNet网络性能从36.1%mAP提高到37.2%mAP,将基于Hourglass-104的mAP从42.2%提高到43.0%.
{ISBN/ISSN}: 0254-4164
{Notes}: 11-1826/TP
{URL}: https://link.cnki.net/urlid/11.1826.TP.20240108.1631.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的实例分割边界框回归方法研究
{Author}: 刘桂霞;吴彦博;李文辉;王天昊
{Author Address}: 吉林大学计算机科学与技术学院;哈尔滨工程大学船舶工程学院;
{Journal}: 哈尔滨工程大学学报
{Year}: 2024
{Volume}: 45
{Issue}: 03
{Pages}: 474-479+614
{Keywords}: 计算机视觉;深度学习;卷积神经网络;实例分割;Mask R-CNN;边界框回归;KL散度;高斯分布
{Abstract}: 针对实例分割任务中图像中可能出现相互遮挡或边缘模糊导致边界框定位不准确的问题，本文提出了一种新的边界框回归损失函数。将边界框位置预测转化为估计定位置信度随位置变化的概率分布；考虑坐标点间存在联系，提出一种面积差计算方法；为了证明此方法可以很好地应用于先检测后分割的实例分割模型，本文使用Mask R-CNN作为基线。实验结果表明：在边界框检测及实例分割任务中，本文方法的精度优于其他方法，对于小物体的检测与分割效果更显著，训练和评估速度也更快。
{ISBN/ISSN}: 1006-7043
{Notes}: 23-1390/U
{URL}: https://link.cnki.net/urlid/23.1390.U.20240108.1530.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与光谱融合的柑橘品质无损检测分级系统设计与试验
{Author}: 文韬;代兴勇;李浪;刘豪
{Author Address}: 中南林业科技大学机电工程学院;
{Journal}: 江苏大学学报(自然科学版)
{Year}: 2024
{Volume}: 45
{Issue}: 01
{Pages}: 38-45
{Keywords}: 柑橘;无损检测;机器视觉;近红外光谱;分级
{Abstract}: 针对柑橘果径、着色率和内部糖度3项关键品质指标，基于双锥滚子式果杯传输线设计了一套柑橘综合品质无损检测分级系统，该系统主要包括喂料部分、机器视觉检测模块、近红外光谱检测模块和分级执行部分.机器视觉检测模块采用单相机拍摄不断翻滚的柑橘视频来获取大量不同姿态的柑橘图像，并进行轮廓提取，以单个柑橘所有帧图像的最小外接圆直径的平均值计算果径，以每一帧图像得到的其二维黄色占比的平均值作为全表面着色率.在近红外光谱检测模块中设计了透射式光路，采集柑橘透射率光谱，并按在线检测时柑橘出现的两种高频姿态建立了混合姿态糖度检测模型，对比不同预处理方法下的建模结果，选取应用效果较优的多元散射校正(MSC)后建立的偏最小二乘法(PLS)模型.在线试验结果表明：果径检测的最大绝对误差为-1.42 mm,着色率检测的最大绝对误差为0.048,糖度检测结果的相关系数为0.817,均方根误差为0.658%.内外品质的联合检测分级按判别树决策方法确定了3种品质的联合分级方式，在分选速度为5个/s时，综合分级的平均准确率可达到91.16%,该检测分级系统整体结构简单，对于类球形水果具有较强的适用性，在产业化应用上有很大的潜力.
{ISBN/ISSN}: 1671-7775
{Notes}: 32-1668/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxiL-jy8oAUaO6KGe8dZCkAZmSy86HY7uKVocm_5nh3ruUiLU9gumPX8EKdLrvIfreutQAecC024-CkraifEZ9dvJdE51JYwGI7_WjPGBQOeApIa4uB0Mwy___PvH2DUoJAjDpL721SnBVlJaEaH0c93ssCE-CFFCcRgOQiZZVIeCHYl0OI5dm1RXW9VlFKWiE=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器学习的铆钉缺陷检测技术
{Author}: 王慧;舒琪;蒋朝根
{Author Address}: 西南交通大学信息科学与技术学院;
{Journal}: 计算机应用与软件
{Year}: 2023
{Volume}: 40
{Issue}: 12
{Pages}: 114-118+208
{Keywords}: 铆钉缺陷检测;机器视觉;目标检测;Faster-RCNN
{Abstract}: 针对传统铆钉缺陷检测中由于人工操作使得检测速度慢，并且结果会引入人为误差的问题，设计出一套基于Faster-RCNN为目标检测算法，以TensorFlow为深度学习框架的铆钉缺陷检测系统。利用LabelImage标注工具进行标注，将数据集转换为Pascial VOC 2012格式。迭代4万次的VGG-16训练模型在1 008幅测试集进行测试，实验结果表明：平均准确率为97.37%,平均精确率为93.9%,平均召回率86.48%。
{ISBN/ISSN}: 1000-386X
{Notes}: 31-1260/TP
{URL}: https://link.cnki.net/urlid/31.1260.TP.20231228.1632.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和改进YOLOv5s的鲫病害轻量级无损检测模型
{Author}: 陈科;周勇;薛明洋;朱松明;赵建;蔡海莺;叶章颖
{Author Address}: 浙江科技学院生物与化学工程学院;浙江大学生物系统工程与食品科学学院;中国水产科学研究院长江水产研究所;浙江大学海洋研究院;
{Journal}: 水生生物学报
{Year}: 2024
{Volume}: 48
{Issue}: 07
{Pages}: 1141-1148
{Keywords}: 水产养殖;鲫病害;无损检测;改进YOLOv5s;轻量级
{Abstract}: 以鲫(Carassius auratus)常见病害为例,从实际生产角度出发,提出了一种基于机器视觉和改进YOLOv5s的鲫病害轻量级无损检测模型,可实现鲫鱼体多种病害的同步无损快速检测。首先,通过利用ShuffleNetV2替换YOLOv5s主干网络,对模型进行轻量化改进;在此基础上,耦合一种基于卷积块的注意力机制[Convolutional block attention module (CBAM)]提高模型精准度;最后,结合空洞空间卷积池化金字塔[Atrous spatial pyramid pooling (ASPP)]提升模型鲁棒性。通过在自制鲫病害数据集上测试可知,文章所提出模型病害检测精确率可达92.0%,模型体积仅为14400 kb,优于当前相关主流模型(最高精确率为83.6%,最小体积为15750 kb),为水产养殖鱼类病害无损快速检测提供了技术支撑。
{ISBN/ISSN}: 1000-3207
{Notes}: 42-1230/Q
{URL}: https://link.cnki.net/urlid/42.1230.Q.20240329.1558.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的燃气PE管道焊缝缺陷检测
{Author}: 彭惠奎;陈芊一;韩露;田裕鹏
{Author Address}: 南京航空航天大学自动化学院;
{Journal}: 半导体光电
{Year}: 2023
{Volume}: 44
{Issue}: 06
{Pages}: 942-949
{Keywords}: 燃气PE管道焊缝;机器视觉;深度学习;YOLOv5;坐标注意力机制;DeepLabv3+
{Abstract}: 为了解决人工与传统数字图像处理方法进行燃气PE管道焊缝缺陷识别时面临的效率低、漏检率高、评片效果不佳等问题，提出了基于深度学习算法的燃气PE管道焊缝缺陷智能检测方法，实现从输入燃气PE管道焊缝DR检测图像到输出缺陷种类及其测量值的精细化测量。首先，在宏观区域层面采用YOLOv5网络预提取缺陷区域，减少与缺陷相似的非目标区域的干扰，并设计了融合坐标注意力机制(CA)与加权双向特征金字塔网络(BiFPN)的CA-BiFPN模块，以提高对小目标缺陷检测能力，其最终的缺陷识别定位平均精确度为95.1%。然后，在微观边界层面采用语义分割算法Deeplabv3+,实现像素级别的缺陷分割，缺陷分割平均像素准确率为91.25%、平均交并比值为85.52%。最后，在几何特征层面采用最小外接矩形法计算其实际尺寸大小，其平均相对误差为5.47%。结果表明该检测方法可实现燃气PE管缺陷高效率、高精度、智能化检测。
{ISBN/ISSN}: 1001-5868
{Notes}: 50-1092/TN
{URL}: https://link.cnki.net/doi/10.16818/j.issn1001-5868.2023091103
{DOI}: 10.16818/j.issn1001-5868.2023091103
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合机器视觉与性能分析的运营盾构隧道结构安全状态评价
{Author}: 周鸣亮;汪长松;黄宏伟;程文;邵华;张东明
{Author Address}: 同济大学土木工程学院地下建筑与工程系;同济大学,岩土及地下工程教育部重点实验室;同济大学,上海自主智能无人系统科学中心;上海地铁维护保障有限公司;
{Journal}: 应用基础与工程科学学报
{Year}: 2023
{Volume}: 31
{Issue}: 06
{Pages}: 1461-1476
{Keywords}: 盾构隧道;机器视觉;深度学习;结构病害识别;结构安全评价
{Abstract}: 在地铁盾构隧道运维过程中，隧道结构变形和衬砌表观病害是常见的两大类结构安全状态评价指标.为了平衡专家评价的主观性和物理力学模型的客观性，提出了融合机器视觉结构病害检测信息和不同病害下结构性能分析的隧道安全状态评价方法，基于隧道工程专家对于不同分类病害权重比例的评估，同时综合了位置、面积、体积等细化指标对于各项病害的加权影响.该评价方法以移动激光扫描获取的三维点云作为数据基础，通过椭圆拟合计算出盾构隧道横断面的收敛变形值、椭圆度以及环间错台值，采用提出的深度学习模型对衬砌表观的渗漏水和剥落病害进行自动化识别和量化，基于有限元数值模拟分析量化了渗漏水以及剥落病害在不同位置的安全状态权重，并通过信息熵法确定了横向收敛变形以及椭圆度两种病害的权重，得到了隧道结构安全状态评价公式.最后采用无监督机器学习Kmeans++聚类算法得到了安全状态分级的阈值，现场实例验证结果表明，提出的评价方法在效率、客观、全面性等方面均体现了一定的优越性，能够为盾构隧道维保部门制定运维决策提供参考.
{ISBN/ISSN}: 1005-0930
{Notes}: 11-3242/TB
{URL}: https://link.cnki.net/doi/10.16058/j.issn.1005-0930.2023.06.007
{DOI}: 10.16058/j.issn.1005-0930.2023.06.007
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉、百度AI与深度学习的晶圆缺陷检测方法研究
{Author}: 岳宗平;段朝磊;杨洋
{Author Address}: 河南机电职业学院智能工程学院;河南大学纳米材料工程研究中心;
{Journal}: 山东工业技术
{Year}: 2023
{Volume}: 
{Issue}: 06
{Pages}: 18-27
{Keywords}: 晶圆;机器视觉;缺陷检测;百度AI开放平台;YOLOv5
{Abstract}: 针对晶圆制造过程中的缺陷对芯片的影响越来越严重，缺陷检测技术在整个半导体工艺流程中至关重要。本文研究了晶圆片在检测速度、检测环境克服能力和检测模型等方面的缺陷检测分析，通过采用机器视觉、百度AI和深度学习技术，以寻找最优技术为检测设备开发奠定基础。实验结果表明，机器视觉技术只能针对特定的应用场景，对特征复杂的晶圆和缺陷检测困难；基于AI技术的检测模型识别准确率可达预期值，但检测置信度较低，无法满足设备开发需求；而基于深度学习技术能有效检测出各种缺陷，算法效果好，检测速度快，符合检测设备开发要求。
{ISBN/ISSN}: 1006-7523
{Notes}: 37-1222/T
{URL}: https://link.cnki.net/doi/10.16640/j.cnki.37-1222/t.2023.06.003
{DOI}: 10.16640/j.cnki.37-1222/t.2023.06.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉技术的分拣系统设计分析
{Author}: 陈志佳
{Author Address}: 广州市工贸技师学院;
{Journal}: 上海包装
{Year}: 2023
{Volume}: 
{Issue}: 12
{Pages}: 9-11
{Keywords}: 机器视觉;分拣系统;机械臂
{Abstract}: 随着我国信息技术发展水平的不断提升，应用智能技术打造的智能分拣系统已经成为生产体系改革的重要成果。从机器视觉技术应用的角度出发，围绕分拣系统的具体总体设计方案、软硬件设计方案以及系统运用平台和流程展开探讨，以期为新时期智能分拣体系的技术体系创新提供借鉴与参考。
{ISBN/ISSN}: 1005-9423
{Notes}: 31-1207/TB
{URL}: https://link.cnki.net/doi/10.19446/j.cnki.1005-9423.2023.12.003
{DOI}: 10.19446/j.cnki.1005-9423.2023.12.003
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: SAR图像中船舶目标检测方法研究
{Author}: 索之玲
{Tertiary Author}: 赵永波
{Publisher}: 西安电子科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 船舶目标检测;SAR图像;锚框拼贴数据增强;注意力网络;轻量化;自监督
{Abstract}: 监测和识别海洋船舶对于管理渔业、打击走私活动、保护海洋资源以及维护国家安全至关重要。合成孔径雷达(Synthetic Aperture Radar,SAR)作为一种卓越的遥感技术,因其无论昼夜或任何天气条件下均能进行成像的能力而在船舶探测领域中扮演了重要角色。在SAR技术的应用中,先进的信号处理和成像技术的融合显著提升了其在灾害监测、环境评估和军事侦察等关键领域的作用,极大增强了其在海洋船舶检测方面的实际价值和效能。最新的船舶目标检测进展涵盖了基于深度学习的模型,这些模型在SAR图像的自动监测中展现了出色的效果。
尽管如此,当前的SAR图像船舶检测模型面临多个挑战,例如船舶目标密度低、学习样本不充分、目标尺度变化大、小目标难以检测、复杂背景噪声干扰大以及船舶目标检测效率不高等。为了改善这些问题,本文深入研究并提出了提升基于深度学习SAR图像中船舶目标检测性能的方法,包括以下四个方面的研究成果:
(1)针对SAR图像船舶目标密度低和学习样本不充分的问题,提出了一种基于锚框拼贴数据增强的船舶目标检测方法等。首先,该方法以单阶段全卷积目标检测网络为基础构建了船舶目标检测网络,实现了端到端的船舶目标检测;其次,通过轻量级的特征金字塔网络、轻量级检测头和自适应空间特征融合模块改进网络,并设计边界框粘贴策略对数据集进行数据增强;最后,在合成孔径雷达船舶检测数据集上达到了96.3%的平均精度值,验证了提出方法的有效性。
(2)对于图像尺度变化大和复杂的背景噪声带来的挑战,本文提出了一种基于多层注意力网络的船舶目标检测方法。首先,该方法以残差网络Res Net50为主干网络的更快的基于区域的卷积神经网络构建船舶目标检测基线网络;其次,提出多层通道注意力模块和多层空间注意力模块,构成多层注意力模块,以提取图像中辨别性船舶特征;最后,实验结果表明本章方法在不同数据集、不同主干网络上均取得较好性能,具有较好的通用性。
(3)为了解决船舶目标检测效率低的问题,提出了一种基于多尺度掩码特征蒸馏的轻量化船舶目标检测方法。该方法通过多尺度特征学习、特征归一化、特征掩码等操作构造多尺度掩码特征蒸馏的轻量化船舶目标检测方法。大量消融实验和对比实验结果表明,该方法能够在减少模型参数量的同时,具有与大模型相当的精度,有利于实时船舶目标检测任务。
(4)对于复杂背景和多尺度船舶目标的检测挑战,提出了一种融合自监督学习和改进特征金字塔网络的目标检测算法。首先,采用自监督特征提取模块从SAR图像中提取低维隐层特征,并将提取的特征分解为目标感知表征和背景干扰表征,并利用对比损失函数加强二者的区分度;接着,自注意力机制被引入以指导检测网络更有效地提取信息;最后,改进的特征金字塔结合空洞卷积模块和全局注意力机制,优化了多尺度特征的融合和信息利用。实验结果充分证明了该算法在处理复杂场景下SAR图像目标检测中的有效性和优越性。
本文提出的基于SAR图像的船舶目标检测方法,缓解了现有船舶目标检测任务中存在的学习样本不充分、目标尺度变化大且小目标难以检测、存在背景噪声干扰和检测效率低的问题,能够在兼顾推理速度的情况下取得较高的检测效果,有助于提高实时的船舶监测能力。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2023.000196
{DOI}: 10.27389/d.cnki.gxadu.2023.000196
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的林火烟雾识别算法研究及FPGA实现
{Author}: 刘小韬
{Tertiary Author}: 段金英;姚王永
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: FPGA;YOLOv5s;硬件加速;森林火灾
{Abstract}: 近年来,全球气温上升导致森林火灾频繁发生,已经严重威胁到了地球生态环境与人类生命安全,实时准确的检测森林火灾对消防救援争取宝贵时间具有极大的意义。传统的森林火灾检测主要依靠人工值守、无人机巡视、卫星遥感图像识别等方式,检测效率不高且耗费成本较大,随着计算机视觉技术的发展,使用目标检测算法进行森林火灾监护得到了广泛的应用,此方法不仅可以提高森林火灾检测效率,也大大节约了人力物力。本文通过对比当前主流目标检测算法,选取了检测速度快、实时性好的YOLO算法作为原始算法,在此基础上面向森林火灾检测进行针对性算法改进。硬件实现方面选用嵌入式设备FPGA,利用FPGA并行开发的特点与ARM架构芯片处理器的性能特点进行软硬件协同算法加速,搭建了一个同时具备高检测精度与高实时性的低功耗森林火灾检测系统。本文主要工作有以下两个方面:
(1)对原始算法YOLOv5s网络结构进行研究,提出了四点改进策略。针对森林发生火灾初期形成烟雾小且不明显的问题,使用增加P2小目标检测层的方式来增强模型对小目标的检测能力;针对森林火灾发生时环境复杂使模型检测精准度下降的问题,本文提出了引入空间通道双注意力CBAM模块来提升模型检测性能,降低漏检、误检情况的发生;通过多做一次池化的方式改进SPP层结构来增加主干特征对信息的敏感度,增强模型对尺寸差异大的烟雾图像检测效果,并将SPP层最大池化核尺寸改为适应FPGA部署的7×7,得到改进模型YOLOv5s-PCS;在对其激活函数进行近似处理后进行模型训练,通过大量消融实验和对比实验分析改进模型的性能。
(2)将YOLOv5s-PCS模型部署至ZYNQ Ultra Scale+MPSoc架构的FPGA计算平台进行算法加速。在Vivado软件中以DPU IP为核心设计数字硬件电路;使用Peta Linux工具构建Linux嵌入式系统,利用Vitis AI开发软件对上板模型进行量化编译,并为系统设计图片和视频两种数据加载方式,最终通过SD卡将做好的系统与镜像文件移植到ZCU104开发平台,完成林火烟雾检测系统的部署。实验结果表明,基于FPGA的林火烟雾识别系统获得了91.1%的m AP＿0.5和27.9FPS的检测速率,检测精度较GPU部署端损失1.3%。与CPU和GPU相比,FPGA部署系统检测速率约为CPU的2.4倍,单张图像消耗功率仅为GPU的九分之一,能效比为Intel i7-10700的23倍和RTX 3050的8.6倍,说明了使用FPGA部署方式的林火烟雾识别系统可以在低功耗的情况下,实时精准的进行森林火灾识别。通过与其他嵌入式系统进行对比,证明了本文基于FPGA的嵌入式系统的综合性能好,具有极强的实用性。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2023.000008
{DOI}: 10.27831/d.cnki.gxjxy.2023.000008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的红枣分拣系统研究
{Author}: 许贵强
{Tertiary Author}: 王德文;李娜
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 红枣分拣系统;机器视觉;ResNet152
{Abstract}: 我国红枣市场规模庞大,近年来红枣种植面积和产量呈现快速增长,然而,红枣产业的发展主要受到红枣分拣技术的限制。目前国内的红枣分拣设备只能实现红枣大小分级,无法对红枣表面病虫害进行识别,很难满足红枣市场的需求。
针对上述问题,本文以本地红枣为例,结合国家林业局红枣质量标准和本地企业标准,制定了本文系统的红枣分级标准。设计了一种基于机器视觉的红枣分拣系统,该系统分为上料部分、分拣部分和图像处理部分。主要研究内容及结论如下:
(1)单排、单道以及单个定序上料的上料部分结构设计。根据红枣尺寸与效果对比,设计了梯形上料滑道,之后对红枣在上料滑道上进行受力分析,确定了上料滑道与水平面的夹角为30°;考虑到图像采集的方式,设计可实现掉落式图像采集的喂果辊,通过在喂果辊中增加圆周滑道,调节红枣进入图像采集室的位姿,采用EDEM仿真得到了上料速度0.32m/s时,红枣图像采集位姿准确率为88%。
(2)图像采集室与分拣部分的设计。根据图像采集的要求设计了各硬件安装位置,根据工作距离、视野范围及曝光选择了相机和镜头等主要部分;通过对市场现有的机构进行对比,选用异形同步带与喷气式相结合的剔除方案,根据本地红枣尺寸,对分拣机构的同步带及挡板进行了尺寸设计,计算剔除次品红枣所需的气压为0.339Mpa和系统运行电机的功率为10.75W,然后根据所得的数据进行选型,利用PWM模块与PID控制算法,通过维普小型电机和驱动器控制皮带轮来调节转速,从而控制整个系统的运行速度,并通过ADAMS仿真,验证了整个机构的合理性。
(3)图像识别算法的选择与模型优化。通过采集4000张红枣图像并对其进行样本分析,确定了以深度学习与传统的图像处理算法相结合的方式进行图像处理操作,通过数据增强、灰度化和二值化等处理后,用Canny算子分割红枣区域图像,引入等效圆分级对得到红枣品级指标。对得到的红枣图像进行数据标注后,导入Matlab软件中进行模型的性能对比,最终选用Res Net152模型来进行后续操作,并对模型进行了Mini-batch和网络结构的优化,提高了模型的效率与泛化能力。
(4)搭建实验台并对各品级的红枣进行A、B两组实验,通过观察不同速度下的红枣识别准确率,得到下料速度为0.16m/s,分拣速率为4颗/s时系统可达到97%的识别准确率。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2023.000111
{DOI}: 10.27831/d.cnki.gxjxy.2023.000111
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 综掘系统视觉处理技术研究现状及发展趋势
{Author}: 杜雨馨;张贺;王树臣;张建化
{Author Address}: 徐州工程学院电气与控制工程学院;中为(江苏)城建设计有限公司;
{Journal}: 工矿自动化
{Year}: 2023
{Volume}: 49
{Issue}: 11
{Pages}: 22-38+75
{Keywords}: 煤炭开采;综掘系统;视觉处理技术;机器视觉;视觉检测与定位;安全监测与事故预防;综掘装备自动化
{Abstract}: 机器视觉技术具有非接触测量、获取信息量大、数据处理能力强等优点，将其应用于综掘工作面，对于提高综掘工作效率、保障人员设备安全、减少事故发生具有重要意义。综述了近年来视觉处理技术在煤矿综掘系统中的具体应用与发展情况，依据综掘工作面的任务分工，结合具体实际案例，重点分析了机器视觉技术在视觉检测与定位、安全监测与事故预防、装备自动化与智能化等方面的应用。通过分析不同应用场景中各类视觉检测系统的结构与检测原理，明确了视觉处理技术在综掘工作面工程应用中的技术性能、工作流程及优缺点。分析了视觉技术在综掘工作面应用中存在的挑战，包括环境适应性问题、成像视野范围较窄、智能算法的鲁棒性和可靠性尚待提高等。指出多传感器信息融合技术、设备群协同控制技术与数字孪生驱动远程监控技术是基于机器视觉的煤矿智能化装备体系未来需要重点发展的新方向。
{ISBN/ISSN}: 1671-251X
{Notes}: 32-1627/TP
{URL}: https://link.cnki.net/doi/10.13272/j.issn.1671-251x.2023090042
{DOI}: 10.13272/j.issn.1671-251x.2023090042
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的产品表面瑕疵检测算法
{Author}: 樊易飞;高成;吴政;刘永鑫
{Author Address}: 沈阳工业大学化工过程自动化学院;
{Journal}: 自动化技术与应用
{Year}: 2023
{Volume}: 42
{Issue}: 11
{Pages}: 5-8
{Keywords}: 区段;瑕疵检测;机器视觉;总面积瑕疵检测法
{Abstract}: 在自动化生产中产品的表面异物瑕疵影响其质量、外观，如何准确、快速、高效的检测和识别出表面异物瑕疵至关重要。为提升产品表面异物瑕疵的检测效率，提出一种区段瑕疵检测算法。对区段瑕疵检测原理进行说明，设置最佳的检测方式，采用基于PLC+工控机的控制方式，设计总体机械方案，采用总面积瑕疵检测法，依托CV-X系列视觉系统，对杯子异物进行有效检测。为验证检测算法的有效性，将机器视觉检测与人工检测作对比，实验结果表明机器视觉检测具有更好的准确性和快速性，有效提升杯子异物检测效率。
{ISBN/ISSN}: 1003-7241
{Notes}: 23-1474/TP
{URL}: https://link.cnki.net/doi/10.20033/j.1003-7241.(2023)11-0005-04
{DOI}: 10.20033/j.1003-7241.(2023)11-0005-04
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 深度人脸伪造生成及检测方法综述
{Tertiary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会论文集
{Author}: 李鑫;徐冰心;徐成;刘宏哲
{Author Address}: 北京联合大学北京市信息服务重点实验室;北京联合大学机器人学院脑与认知智能北京实验室;
{Secondary Title}: 中国计算机用户协会网络应用分会2023年第二十七届网络新技术与应用年会
{Place Published}: 中国江苏镇江
{Subsidiary Author}: 中国计算机用户协会网络应用分会
{Year}: 2023
{Pages}: 5
{Keywords}: 深度人脸伪造;人脸伪造检测;深度生成技术;计算机视觉;研究综述
{Abstract}: 深度学习和计算机视觉的发展,尤其是生成对抗网络(GANs)和扩散模型的涌现,给人们的生活带来了诸多便利。然而,这些技术也促使了各种深度伪造信息的产生,在金融、政治和新闻等领域形成了诸多威胁。面对深度伪造生成和检测方法的快速迭代,加强对其相关技术的全面理解,对进一步预防其负面效应具有重要意义。通过回顾深度人脸伪造领域的研究背景和各类伪造生成及检测方法,文中提供了对现有工具和相关方法的全面概述和详细分析。具体来说,针对每一类深度伪造,文中探讨了与之相关的具有代表性的生成与检测技术和公共数据集。此外,文中还讨论了该领域目前存在的各种问题,并列举了未来的发展方向。这项工作有望帮助读者理解深度人脸伪造生成及检测技术的发展现状,促进该领域各项研究的不断深入,以应对日益具有挑战性的深度伪造问题。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.055280
{DOI}: 10.26914/c.cnkihy.2023.055280
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO v5的水稻主要害虫识别方法
{Author}: 吴子炜;夏芳;陆林峰;张盛军;周素茵
{Author Address}: 浙江农林大学数学与计算机科学学院;浙江农林大学经济管理学院;浙江省农业农村大数据发展中心;浙江托普云农科技股份有限公司;
{Journal}: 江苏农业科学
{Year}: 2023
{Volume}: 51
{Issue}: 21
{Pages}: 218-224
{Keywords}: 水稻害虫;害虫识别;机器视觉;轻量化;深度学习
{Abstract}: 准确识别害虫是水稻田间害虫防控的基础，针对现有水稻害虫识别方法精度不高、计算量与参数量较大等问题，提出一种轻量模块以及相应改进YOLO v5模型的方法。为了在满足精度的前提下减小模型参数量，构建的轻量模块使用多个深度可分离卷积减小计算消耗，并通过通道洗牌将特征通道重组提高学习能力，同时将该模块引入YOLO v5模型中进行轻量化改进。为提高模型的泛用性，除选取公开数据集IP102中的水稻害虫图片外，通过二化螟性诱设备采集二化螟图像丰富研究数据。结果表明，所提出的轻量化模块能够有效减轻模型的体积、优化训练并提升模型的识别精度，改进后的模型参数量仅为原模型的一半，对14类害虫的平均识别精度相较原模型提高3.2百分点，拥有一定的实际应用能力。所提出的轻量模块及轻量化改进模型能够实现对水稻害虫高精度及高效率的识别，可为水稻病虫害防控数字化、智能化发展提供技术支持。
{ISBN/ISSN}: 1002-1302
{Notes}: 32-1214/S
{URL}: https://link.cnki.net/doi/10.15889/j.issn.1002-1302.2023.21.033
{DOI}: 10.15889/j.issn.1002-1302.2023.21.033
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的腰背痛患者痧象图片处理和分析研究
{Author}: 姜荣荣;杨涛;徐桂华
{Author Address}: 南京中医药大学;
{Journal}: 中华中医药学刊
{Year}: 2024
{Volume}: 42
{Issue}: 05
{Pages}: 13-16+263-264
{Keywords}: 计算机视觉;腰背痛;刮痧;痧象特征
{Abstract}: 目的 提出痧象图片处理和分析的思路和方法，为痧象数字化研究提供参考。方法 以计算机视觉技术为基础，以腰背痛患者背部痧象处理和分析为目标，提出痧象图片预处理、特征提取和筛选、痧象分析等系列方法，并进行实验验证。结果 痧象预处理方法能够实现原始图像颜色校正和背部区域精准分割；特征提取方法提取了腰背痛患者94个痧象颜色和纹理特征，筛选得到20个关键特征；痧象分析方法能够找到与不同证候相关的关键特征。结论 利用计算机视觉方法能够较好地完成痧象图片的预处理、特征识别和提取、痧象分析和理解，可以为痧象数字化和客观化研究提供支撑。
{ISBN/ISSN}: 1673-7717
{Notes}: 21-1546/R
{URL}: https://link.cnki.net/doi/10.13193/j.issn.1673-7717.2024.05.003
{DOI}: 10.13193/j.issn.1673-7717.2024.05.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的表面缺陷检测关键技术
{Author}: 吴绍锋;白云娇
{Author Address}: 重庆人文科技学院机电与信息工程学院;
{Journal}: 农业技术与装备
{Year}: 2023
{Volume}: 
{Issue}: 10
{Pages}: 66-69
{Keywords}: 机器视觉;表面缺陷;正交变换;检测技术;制造业
{Abstract}: 通过总结近几年表面缺陷检测技术研究成果，从机器视觉系统，利用Matlab软件对钢材表面裂纹缺陷进行傅里叶变换及小波变换去噪技术，探讨了基于机器视觉的表面缺陷检测关键技术，以期达到可靠、高效地检测零件表面缺陷的目的，进而提高产品质量。
{ISBN/ISSN}: 1673-887X
{Notes}: 14-1343/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxBwvGfHlaPPMjRdMcj-YYJcXkABeZ5RSFd6JtCPT0hEG9LGdRkp8cz4freW975kUhhaThGtb0Fmt0--eA37dtQyP5WdU4VFFvj2kHNG8d44_5suTFovbmKeV3zsu6il0NMGsgF0l4lUWQ3IVHWC4GYG8Du5iS2_qGkJcBLwPfDEjaR3z-b29oKkbMxvno_Fvg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的快递面单识别系统
{Author}: 曹泽
{Tertiary Author}: 陈松乐
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: Swin-Transformer;Deformable Detr;霍夫变换;仿射变换;条形码识别
{Abstract}: 近年来,随着国内电商经济的快速发展,作为电商重要支撑的快递产业持续保持高速增长,快递企业需要不断地提高生产的智能化、自动化水平以满足业务发展的需要。快递面单检测与识别是实现快递企业智能化、自动化的重要环节。通过扫描快递面单上的条形码信息,可以快速准确地将快递包裹与用户的信息进行匹配,实现快递包裹的自动化出入库处理。本文设计了一种基于深度学习Transformer的快递面单识别系统,该系统分为条形码定位和条形码解码两个部分。条形码定位部分使用Swin-Transformer提取快递面单不同层级的特征图,然后将特征图输入Deformable Detr中进行特征融合和解码,从而得到条形码在快递面单中的包围盒。该算法使用Transformer网络结构进行特征提取、特征融合与目标解码,充分利用了Transformer的全局感知能力与较强的通用建模能力。同时,该算法属于一阶段目标检测算法,能够进行端到端的训练并实现了网络参数的联合优化。条形码解码部分包含水平旋转和解码。其中,水平旋转算法使用霍夫变换检测条形码中的直线,并进而计算条形码的倾斜角度,然后使用仿射变换旋转条形码至水平位置。本文采用形态学方法对条形码图像进行处理,提高了霍夫变换检测的性能。对于旋转至水平位置的条形码,本文采用Open CV实现了Code-128解码,从而获得条形码对应的快递单号。基于条形码定位和解码算法,本文设计并实现了基于Android平台的快递面单扫码系统,用户可以使用手持设备进行快递面单的扫码,并进而实现出入库操作。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000973
{DOI}: 10.27251/d.cnki.gnjdc.2023.000973
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去雾算法研究
{Author}: 杨忆
{Tertiary Author}: 何涛
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去雾;平滑扩张卷积;残差密集块;特征注意力;自校准卷积
{Abstract}: 随着科技的发展计算机视觉系统越发融入人们的日常生活中,无论是大街小巷随处可见的人脸识别快捷收银系统,还是道路上具备大量摄像头的新能源汽车,它们都使用大量的计算机视觉系统。这些计算机视觉系统部署于真实环境中,与实验室中理想环境不同它们会受到各种各样的负面影响。各种负面影响中较为常见的是雾霾天气带来的,此等环境下计算机视觉系统拍摄的图像会存在各种问题,如图像整体呈现发灰发白的现象。这导致图像出现对比度下降、色彩饱和度变差、包含信息减少等问题,这些问题增加后续高级计算机视觉处理任务如目标检测、图像分类、语义分割的难度,因此如何有效将有雾模糊的退化图像还原成无雾清晰图片即图像去雾技术尤为重要。机器学习以及深度学习的出现给图像去雾领域带来另外一种可能性,传统图像去雾算法正被慢慢取代。早期基于深度学习的去雾算法并未完全脱离传统图像去雾算法的经典理论,但存在去雾效果不明显,过于依赖先验条件等问题,后续算法则基于卷积神经网络不依赖先验条件直接端到端的输出无雾图像,但也存在颜色失真、去雾不彻底的问题,本文针对这些问题,进行不同需求向的图像去雾算法研究。本文主要研究内容如下:1)针对大气散射模型和网格伪影问题,提出一种基于平滑扩张卷积和门控机制的图像去雾方法,该去雾方法不依赖大气散射模型,可以根据输入的有雾模糊退化图像直接恢复出清晰无雾图像。具体来说,提出一种基于平滑扩张卷积残差块,该残差块即可以通过平滑扩张卷积提升任务效果,也能通过平滑扩张卷积改善扩张卷积存在的网格伪影问题。同时,提出基于均方误差损失函数和感知损失函数的综合损失函数对去雾网络进行训练,以获得更好的去雾效果。实验结果表明,该方法在公开的合成雾图数据集上取得良好的去雾效果,恢复出的图像干净清晰,细节保存良好。2)针对卷积层输出信息利用不充分和多尺度特征估计融合时出现性能瓶颈的问题,提出一种基于残差密集块的多尺度去雾网络。具体来说,参考常用于语义分割的Grid Net,将其作为网络主体架构,利用残差密集块的将前一个残差密集块的输出和当前残差密集块中每一层卷积层的输出都直接连接到所有后续层,这样的操作既可以保留网络的前馈特性,又可以提取网络局部密集特征。同时,提出基于通道式注意力的特征融合方式以提升网络的去雾效果。通过仿真实验证明,该去雾方法可以更有效的去除有雾退化模糊图像中的雾,并输出视觉效果更贴合真实清晰图像。3)针对卷积神经网络感受野和注意力问题,提出一种基于自校准卷积和特征注意力的图像去雾算法。该算法引入自校准卷积,在不增添额外参数的情况下,将一个标准卷积操作拆分成多个小卷积操作,扩大去雾网络的感受野,提升网络的去雾效果。利用特征注意力模块中的通道注意力和像素注意力机制使得网络更加关注浓雾区域像素和重要的通道信息,进而提升去雾效果。经仿真实验验证,该去雾方法可有效的完成去雾任务,不破坏图像中原有信息,输出的无雾图像更加高质量。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001967
{DOI}: 10.27251/d.cnki.gnjdc.2023.001967
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的轻量化实时目标检测方法研究
{Author}: 施惠民
{Tertiary Author}: 周全
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像目标检测;轻量级网络;卷积神经网络;注意力机制;实时目标检测
{Abstract}: 图像目标检测是计算机视觉领域中一项基础且富有挑战的任务,其目标旨在检测出覆盖感兴趣区域的最小边框,并同时赋予该边框对应的语义标签。近年来,随着深度学习的发展,目标检测器的性能得到了极大的提升。尽管这些检测器取得了巨大的进步,但是它们大多数包含了成百甚至上千的卷积层和特征通道,其模型大小和执行效率对于真实世界需要实时推理的应用,譬如自动驾驶、机器视觉来说是不可接受的。为了适应真实世界的应用,许多轻量化实时目标检测器被提出,它们通常采用单分支骨干网结构,包含少量的卷积层和连续的下采样操作,这使得其高分辨率定位细节粗糙且不准确,这对于目标的定位是不利的。另一方面,由于轻量化网络的模型容量有限,不擅长建模全局关系。此外,为了获得更快的推理速度,现有的轻量化模型倾向于在检测器的颈部和检测头使用简单的架构,但是这种做法忽略了不同特征之间的关系。为了应对上述问题,本文进行了以下研究:(1)针对轻量化检测器在网络浅层的快速下采样策略而导致高分辨率细节提取不充分的问题,提出了一种包含轻量化自注意力的双路径网络(DPNet),以进行高效的目标检测。DPNet使用双路径骨干网架构,骨干网拥有两条平行的双分辨率路径,其中低分辨率路径提取语义信息,高分辨率路径保留定位细节,两种特征都对目标检测十分重要。此外,为了改善模型的容量和特征表达能力,一个单输入单输出的轻量化自注意力模块(LSAM)被设计并嵌入在骨干网中。在MS COCO 2017的实验结果表明,DPNet在检测精度和执行效率间取得了令人满意的平衡。(2)针对轻量化检测器的全局建模能力弱的问题,提出了En-DPNet。En-DPNet在DPNetS的基础上将LSAM改进为轻量化自联系模块(LSCM)。LSCM在空间注意力中使用更大的池化窗口来保存空间细节,探索像素-区域的关系;在通道注意力中维持相对更多的特征通道,探索通道-子通道的关系。此外,DPNet在检测器的颈部网络采取了常见的FPN架构,使用双线性插值和元素加来进行多尺度特征融合,忽略了多尺度特征之间的关系,这推动本文将LSCM扩展为多输入版本的轻量化交叉联系模块(LCCM),用来融合不同卷积层的跨尺度特征。实验结果表明,在320×320的输入图像大小下,En-DPNet在MS COCO 2017 test-dev取得了29.6%AP,在Pascal VOC测试集上取得了79.2%m AP,推理速度分别为164FPS和196FPS,仅有约2.5M模型大小和1.0GFLOPs。(3)针对检测头中分类和回归两个任务缺乏信息交互,且两个任务需求特征不一致的问题,提出了Eh-DPNet。Eh-DPNet在En-DPNet的基础上设计了交互注意力模块(IAM)来增强两个任务间的特征交互。在检测头中,IAM在通道与空间维度分别对分类分支与回归分支的特征进行建模,生成各自任务所需特征的同时,还加强了任务间的信息交互。实验结果表明,在320×320的输入图像大小下,Eh-DPNet在MS COCO 2017 test-dev取得了30.4%AP,仅有约2.75M模型大小和1.06GFLOPs,推理速度为161 FPS。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001984
{DOI}: 10.27251/d.cnki.gnjdc.2023.001984
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的室内外人类行为检测方法研究
{Author}: 何正燃
{Tertiary Author}: 桂冠
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人类行为检测;深度学习;计算机视觉;WiFi信号;YOLOv5
{Abstract}: 人类行为检测可以广泛应用于各种普适计算应用中,在室外场景中可以通过目标检测等方式进行不同任务需求的行人闯入检测;室内场景下也可以作为一种新型的人机交互来执行智能医疗监控诸如智慧家居或者老年人跌倒检测,或者可以通过识别人类行为来应用于交互式体感游戏等。而随着深度学习的兴起和广泛应用,人类行为检测的实时性和准确性也都有了大幅度的提高。大多数传统的人类行为检测系统使用佩戴式传感器进行检测和识别。尽管随着技术的发展,传感器的尺寸变得更小,数据收集变得更有效,但基于传感器的检测系统仍然面临着部署的限制。特别是随着传感范围和规模的不断增加,部署和维护大规模传感系统的成本也会急剧增加。因此,无设备的被动人类行为检测逐渐成为研究的主流方向。现阶段无设备的被动人类行为检测方法主要分为两类,分别为基于计算机视觉的被动检测和基于射频指纹信号的被动检测。基于计算机视觉的被动检测采用摄像头作为采集工具,通过采集到的图像信息进行人类行为的检测,通常应用于室外行人检测以及人脸识别等领域。而基于射频指纹信号的被动检测采用射频信号作为感知主体(常用蓝牙、Wi Fi等射频信号),通常应用于室内等需要保证隐私场景中的人类行为检测。本文针对室外和室内两类场景,分别使用基于计算机视觉的方法以及基于Wi Fi信号的方法实现人类行为检测的任务目标。室外场景当中,本文通过对道路摄像头拍摄的行人图像进行标签处理和图像预处理等工作,之后利用修改后的YOLOv5s网络对其进行目标检测的训练以及测试,该算法利用了YOLO算法单阶段检测的优势,输入待检测图片即可输出预测结果。此外针对边缘设备部署问题,本文也对YOLOv5算法进行了轻量化改进,主要通过网络稀疏化、BN层优化、关键层剪枝以及算法微调等方法,显著降低最终算法的模型大小,满足边缘设备部署占用内存小、精度高的需求。室内场景当中,本文通过两类公开的CSI信号数据集,并对信号数据进行数据清洗等预处理方法,之后采用自定义的深度学习网络算法进行训练和测试,该算法利用了卷积神经网络进行信号空间特征提取,利用长短时记忆网络进行信号时间特征提取,最后进行特征融合并引入注意力机制提高算法的鲁棒性和泛化能力。研究结果表明,本文所提出的修改后YOLOv5s算法在行人检测方面明显优于同类算法,具有88.65%的m AP性能,并且经过轻量化以后,占用内存仅为原模型的八分之一,显著降低了内存占用率,更适合边缘设备的部署;本文所提出的基于时空特征融合的Wi Fi被动检测方法在识别精度上达到了97%以上,与其他网络算法相比也具有显著的优势。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000310
{DOI}: 10.27251/d.cnki.gnjdc.2023.000310
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于EfficientNet的行人重识别及目标识别研究
{Author}: 林嘉
{Tertiary Author}: 吴晓富
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;行人重识别;目标检测;卷积神经网络;嵌入式
{Abstract}: 近年来,深度学习在计算机视觉领域的应用取得了突破性的进展,其中行人重识别和目标检测任务都成效显著。一般而言,行人重识别和目标检测实际任务都需要考虑模型体积的问题,以适应实际场景的部署约束。EfficientNet是一类卷积神经网络模型,其采用了复合缩放技术,可以针对网络深度、宽度和分辨率进行独立优化,具有性能高、模型体积小等特点。本文基于EfficientNet主干网模型对行人重识别和目标检测进行研究和应用,主要工作如下:1)针对行人重识别领域中现存SOTA(State-Of-The-Art)方案模型体积大的问题,提出了一种基于EfficientNet的行人重识别网络模型EPRI-Net。该模型吸收了特征金字塔技术的特征融合思想,具有模型体积小且性能优异的特点。实验表明,在典型行人重识别数据集Market1501上,所提出的EPRI-Net达到了90.2%的mAP以及96.1%的Rank-1。2)针对实际轮船检测场景下的行人检测任务,提出了一种基于EfficientNet的小规模行人目标检测模型——EPRI-Det。EPRI-Det是在EPRI-Net的基础上进行设计,其关键特色是通过特征金字塔分支用于检测行人目标的位置与类别。实验表明,EPRI-Det在船员数据集上的mAP为73.2%,略低于Yolov5s的75.6%,但模型参量为4M,大幅低于Yolov5s的7.2M。3)针对实际轮船船员的安全衣帽穿戴任务,对EPRI-Det进行落地应用,部署到瑞芯微嵌入式平台上进行推理测试,提出了一套基于EPRI-Det的船员安全衣帽穿戴嵌入式目标检测方案。实验表明,该方案训练后的mAP为56.2%,部署到嵌入式平台后,单张图片的推理时间为470ms左右。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001014
{DOI}: 10.27251/d.cnki.gnjdc.2023.001014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于无监督学习多流特征建模的低光照图像增强与去噪算法研究
{Author}: 王英凡
{Tertiary Author}: 韩光
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 低光照图像增强;生成对抗网络;多流特征建模;多尺度特征融合
{Abstract}: 低光照图像是指由于光照不足或环境较暗等原因造成的,图像存在亮度较低,细节不清晰,色彩失真和噪声增加等问题。这些问题导致低光照图像的可视化效果差,且对于一些后期的视觉任务,如目标检测、人脸识别、医学图像诊断等,也会造成很大的影响。通过低光照图像增强算法,可以改善图像的质量和视觉效果,使图像更加清晰和明亮。这些算法可以通过提高图像的对比度、减少噪声和增强细节等方式来实现。低光照图像增强在许多应用领域具有广泛的应用,例如计算机视觉、医学成像、安防监控、无人机影像等,所以对低光照图像增强算法的研究仍具有重要的意义。针对已有的低光照图像增强算法存在的问题,本文主要的研究工作如下。1.设计了新颖的基于无监督学习多流特征建模的低光照图像增强与去噪算法,让输入的低光照图像经过多条支路的增强,以此来提取低光照图像的全局和局部特征,充分地挖掘图像的空间信息和表观特征,使得增强后的图像不仅细节信息丰富,还能实现去噪和去伪影。2.在生成网络阶段中创新性地采用了Swin Transformer Block作为低光照图像的全局特征提取器,它的移位窗口机制能在网络参数量较少的情况下对输入图像进行长距离的特征依赖建模,很好地提取到图像颜色、纹理及形状等特征,实现抑制噪声和伪影。在局部特征建模中,还新增了多尺度的图像和特征融合分支,它允许在U-Net内使来自不同尺度的信息进行交流,进而控制不同尺度图像上局部区域的曝光度。3.在判别网络中,加入了深-浅层特征聚合模块来增强网络的判别能力,它利用改进的自适应特征融合机制,通过学习空间滤波器矛盾信息来抑制不一致性,实现浅层表征信息和深层语义信息的相互指导,以此来控制生成网络使其生成的图像更加自然,提高对于人眼的视觉体验。通过引入上述三项创新工作,本文所提出的基于无监督学习多流特征建模的低光照图像增强与去噪算法在低光照图像增强性能上取得了显著的改善。在多个公共数据集的测试实验中,与已有的一些先进低光照增强算法相比,所提出的方法均取得了更优的表现。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000558
{DOI}: 10.27251/d.cnki.gnjdc.2023.000558
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于姿态估计的人体运动分析及边缘计算平台实现
{Author}: 沈恒
{Tertiary Author}: 干宗良
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;姿态估计;人体运动分析;热红外成像;边缘设备
{Abstract}: 计算机视觉技术已广泛应用于社会生活的各个领域。在这些领域中,人体姿态估计的应用尤其引人关注,成为计算机视觉工程研究的重要方向之一。例如,基于个体的专业运动评估、行为康复监测和人机交互等。目前,如何设计低复杂度的人体运动行为分析算法是重要的应用研究内容。此外,考虑到个人隐私,基于红外成像的人体运动分析也逐渐成为研究关注点之一。本文以Jetson Xavier nx边缘计算平台为计算载体,深入研究轻量级面向实时的深度神经网络,分别在可见光成像和红外成像两种环境下,构建了基于姿态估计技术的轻量级人体运动分析算法,以满足上述场景下的应用需求。本文主要工作和创新点如下:(1)提出了一种基于深度学习姿态估计的人体运动姿势分析算法,算法由两部分组成,即姿态估计神经网络和人体运动分析后处理算法。在姿态估计网络中首先设计双分支下采样结构增加姿态估计网络感受野的同时减少浮点运算数来提高检测效率;其次在网络特征提取主干部分后构建增强特征提取模块,其目的是对提取到的人体深度特征信息进行整合和增强,提升复杂环境下的检测精度。人体运动分析后处理算法的设计结合了人体运动学并充分考虑不同运动自身的特性,负责映射姿态估计网络得到的关键骨骼点位置与人体运动时肢体状态之间的关系,此外,本文在算法中增加了阈值判定系统,有效避免了环境中形状似人物体带来的干扰,最后将上述算法部署于移动边缘设备中,加速人体运动分析处理过程。实验结果表明,本文姿态估计算法在人体常见运动分析任务中表现优异,其检测精度达到90.9%,检测速度达到77.6FPS(Frames Per Second),同时具备较好的抗干扰能力。因此,该算法能够在实际环境中准确且实时地完成任务。(2)提出了一种针对热红外成像的人体运动分析算法。将算法从可见光成像推广到红外成像有两个主要的难点:一是红外成像在镜面环境下具有回波现象,导致红外成像中会出现多个与本体特征十分相似的红外倒影(本文简称伪影),针对这一干扰,本文设计了一个双阶段轻量神经网络预先检测红外人体伪影位置,然后使用图像掩膜技术排除该区域,将该算法作为干扰预处理部分放入姿态估计网络前端。二是红外人体成像容易与环境物体混淆而出现误检现象,针对这一问题,本文在姿态估计网络中添加了包含注意力机制的浅层特征提取模块,使得检测结果更加精确。其次对网络减枝,保留了大尺度和中等尺度的特征融合部分,提高了检测效率。最后,本文将算法部署于边缘计算平台,并验证其在红外成像下的可行性。实验结果显示,本文算法的检测精度为90.7%,检测速度达到83.3FPS,满足了实际环境中红外人体常见运动分析对效率和精度的要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.001071
{DOI}: 10.27251/d.cnki.gnjdc.2023.001071
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向无人机巡检的机器视觉语义分割技术研究
{Author}: 石亦巍
{Tertiary Author}: 张晖
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 无人机巡检;机器视觉;语义分割;UNet;DeepLabV3+
{Abstract}: 随着物联网的蓬勃发展,产业数字化和智能化取得了重大进展,深刻改变了产业技术体系。在产业构想落地过程中,无人机巡检发挥了重要作用。无人机巡检感知决策手段多样,机器视觉语义分割技术可以获得像素级别的目标分类信息,为感知决策过程提供全面准确的数据支持,是其中最为重要的手段之一。由于无人机巡检所得遥感图像中的物体通常具有形态多样、尺度差异较大以及边缘模糊等特点,现有语义分割算法在此类图像上表现不佳。为实现对无人机巡检复杂场景下目标的精准检测,本文针对无人机遥感图像提出两种语义分割算法。主要工作如下:一、首先对无人机巡检技术、机器视觉技术、语义分割技术进行概述。然后对卷积神经网络、语义分割网络、语义分割评价指标进行了详细介绍。二、提出成像原理赋能的无人机巡检枯草语义分割检测算法。首先针对无人机遥感图像中枯草颜色畸变问题,提出基于成像原理的枯草颜色校正算法,对图像中枯草区域颜色进行校正,并将颜色校正图像补充进后续UNet网络,为网络提供更为有效的输入信息;然后提出通道注意力特征融合模块,替换基础UNet网络跳跃连接中的通道拼接操作,融合不同语义层次的枯草特征信息,强化对枯草检测作用更大的特征,提高UNet网络对于枯草分割的准确性。实验结果表明,所提算法较好的完成了对园林巡检场景下无人机遥感图像中枯草的分割检测。三、提出基于自适应边缘特征的无人机巡检多目标语义分割算法。首先针对物体边缘分割不准的问题,提出多尺度多形状边缘特征自适应融合提取算法,对不同尺度、不同形状的边缘特征图自适应地进行融合加权,再补充进后续Deep Lab V3+网络,为网络提供有效的边缘信息,提高物体边缘分割的准确性;然后提出感受野融合空洞空间金字塔池化模块,对具有不同感受野的分支进行加权融合,增强网络的多尺度特征提取能力,提高Deep Lab V3+网络在多尺度物体并存环境下的无人机遥感图像上分割的准确性。实验结果表明,所提算法较好的完成了对复杂巡检场景下无人机遥感图像的精准分割。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2023.000589
{DOI}: 10.27251/d.cnki.gnjdc.2023.000589
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人抓取系统的研究
{Author}: 李杨;郭浩泽
{Author Address}: 临汾职业技术学院;
{Journal}: 机电工程技术
{Year}: 2023
{Volume}: 52
{Issue}: 10
{Pages}: 192-195
{Keywords}: 工业机器人;机器视觉;智能抓取系统
{Abstract}: 针对工业机器人快速自主识别和抓取目标工件的需求，将机器视觉应用到工业机器人抓取系统设计中。首先，针对系统进行了选型，基于FANUC工业机器人和VM软件开发平台搭建了机器人抓取系统，确定了基于单目视觉的机器人抓取系统的整体方案。其次，建立了视觉获取图像与目标工件快速定位抓取之间的关系，实现了目标工件的提取、形状识别与定位。最后，为了证明该抓取系统的可行性及准确性，进行了静态抓取实验，并取得了较好的实验效果。实验表明，该基于单目视觉搭建的工业机器人抓取系统能在自动化生产线中快速进行目标识别及抓取，有效地提高了生产效率。
{ISBN/ISSN}: 1009-9492
{Notes}: 44-1522/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwQfKPw34-l5fvgQ23k4UaTUoF03eVDoCqA_HDXYvr0SRVwuK6-Y7FgNRhMqRBY0d-uWOsV5xw02qTOdu0MBhkcfwnzaWQUWpdp1wiNxg_NEQgA3R4mx7yoe_zHarJDMlvOABDTUdGK4Yb_Ef7xXkfHD_4mkGRUvykbnUOqRM-hBCt7p1TL0Omi_sWqhAxwCYs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像分割和深度学习的人造板表面缺陷检测
{Author}: 杨凡;杨博凯;李荣荣
{Author Address}: 南京林业大学家居与工业设计学院;
{Journal}: 浙江农林大学学报
{Year}: 2024
{Volume}: 41
{Issue}: 01
{Pages}: 176-182
{Keywords}: 缺陷检测;机器视觉;图像分割;深度学习;板式定制家具
{Abstract}: 【目的】针对板式家具零件表面缺陷人工检测过程存在的检测效率低、准确率低、检测结果无法数字化存储等问题，提出了一种基于图像分割和深度学习算法的饰面人造板表面缺陷的检测方法。【方法】利用工业相机采集人造板图像，构建缺陷数据集，采用全局阈值和局部动态阈值算法分割表面缺陷与图像截取，通过将ReLU6非线性激活函数替代ReLU函数，并引入倒残差结构的方法，优化MobileNetv 2深度学习网络，进行缺陷识别与分类。【结果】该方法对饰面人造板表面崩边和划痕缺陷的检测精确率分别达到了93.1%和97.5%，召回率分别为95.3%和97.6%，单张板件平均检测用时为163 ms。【结论】本研究提出的方法具有较高精度与稳定性，可解决传统人工检测方法的准确率低、效率低等问题，为家具板材表面缺陷的自动化检测提供新思路。图6表3参21
{ISBN/ISSN}: 2095-0756
{Notes}: 33-1370/S
{URL}: https://link.cnki.net/urlid/33.1370.S.20231018.1452.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在陶瓷表面缺陷检测方面的研究进展
{Author}: 周曼;吴天钊;代宝鑫;许新统;孔令兵;梁立新
{Author Address}: 深圳技术大学新材料与新能源学院;深圳大学应用技术学院;深圳技术大学集成电路与光电芯片学院;深圳技术大学,大数据与互联网学院;
{Journal}: 陶瓷学报
{Year}: 2023
{Volume}: 44
{Issue}: 05
{Pages}: 874-884
{Keywords}: 深度学习;材料科学与工程;机器视觉;陶瓷表面缺陷检测
{Abstract}: 针对陶瓷表面缺陷检测问题，深度学习算法是近年来研究的热点之一。通过建立合适的数据集、合适的网络模型和算法，可以实现对陶瓷表面缺陷的自动检测和分类。目前，常用的深度学习表面缺陷检测算法包括卷积神经网络(Convolutional Neural Network,CNN)、循环神经网络(Recurrent Neural Network,RNN)和多层感知器(Multilayer Perceptron,MLP)等。其中，基于YOLOv5算法的陶瓷缺陷检测方法是近期较为先进的一种方法，它具有较高的检测精度和实时性，能够准确地检测和识别陶瓷表面的各种缺陷，通过优化网络结构和损失函数，还可以进一步提高算法的性能；基于CSS算法的陶瓷缺陷检测方法提出使用图像分割的方法来分割陶瓷缺陷样本，并对分割后的样本集图像做二值化处理，突出缺陷的位置和大小。综述了陶瓷与深度学习相结合在材料表面缺陷检测方面的研究进展，并介绍了基于深度学习算法的陶瓷缺陷检测方法，以及详细综述了基于YOLOv5和基于CSS的陶瓷表面缺陷检测算法过程。
{ISBN/ISSN}: 2095-784X
{Notes}: 36-1205/TS
{URL}: https://link.cnki.net/doi/10.13957/j.cnki.tcxb.2023.05.04
{DOI}: 10.13957/j.cnki.tcxb.2023.05.04
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 电阻率测井成像图井壁裂缝智能识别与分割方法
{Author}: 夏文鹤;朱喆昊;韩玉娇;杨燚恺;林永学;吴雄军
{Author Address}: 西南石油大学电气信息学院;中国石化石油工程技术研究院;
{Journal}: 石油地球物理勘探
{Year}: 2023
{Volume}: 58
{Issue}: 05
{Pages}: 1042-1052
{Keywords}: 电阻率成像测井;井壁裂缝智能识别与分割;计算机视觉;多尺度特征融合;注意力机制
{Abstract}: 目前测井图像裂缝识别、处理过程工作量巨大，人工识别主观性强、稳定性差，为此，提出将计算机视觉技术和深度学习框架引入测井成像图分析解读领域，构建新型裂缝形态智能识别网络模型，实现了电阻率测井成像图中井壁裂缝区域的智能识别与分割标注。首先，通过多尺度空洞卷积结合注意力机制提取电阻率测井井壁成像图中浅层和深层特征，并将深、浅层特征进行多尺度融合，形成更具表征能力的新特征。然后，根据该特征进行像素点二分类，完成每个像素点的前景、背景类型识别，若干个前景分类的像素点对应裂缝区域的轮廓。多尺度特征融合模型从微观角度充分保留了裂缝区域图像轮廓细节，裂缝区域关联像素点识别分类准确率接近80%。最后，进一步借鉴人眼视觉相似度评价体系，从宏观角度设计裂缝轮廓智能识别性能评价算法。评价结果表明，当视觉相似度感受评级为Ⅱ级时，训练集和测试集图像中与人工识别结果基本一致的裂缝区域分别达到81.3%和80.0%，说明所提方法可替代人工解释完成裂缝的识别和标注工作，能大幅减少图像分析工作量，细致勾勒出裂缝区域轮廓线。同时，有利于及时、迅速地判断井筒、井壁稳定性，为后续裂缝区域的智能定量评价、计算提供技术支撑。
{ISBN/ISSN}: 1000-7210
{Notes}: 13-1095/TE
{URL}: https://link.cnki.net/doi/10.13810/j.cnki.issn.1000-7210.2023.05.002
{DOI}: 10.13810/j.cnki.issn.1000-7210.2023.05.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的印刷品表面划痕缺陷检测
{Author}: 左才;张勇斌;齐元胜;李星炎;王煜川
{Author Address}: 北京印刷学院机电工程学院;
{Journal}: 印刷与数字媒体技术研究
{Year}: 2023
{Volume}: 
{Issue}: 05
{Pages}: 42-48
{Keywords}: 机器视觉;缺陷检测;印刷品;Canny边缘检测算子;表面划痕
{Abstract}: 针对包装印刷品表面缺陷问题，本研究提出了一种基于机器视觉的印刷品表面划痕缺陷检测方法。首先，通过CCD相机获取印刷品表面待检测图像，对加权平均法、平均值法和最大值法3种图像预处理方法进行对比分析，发现加权值法获得的灰度化效果最优，因此选用加权值法对待检测图像进行灰度化处理。在图像去噪方面采用高斯滤波进行有效处理，然后采用图像二值化和Canny边缘检测算子对预处理后的图像进行缺陷特征的分割和提取，最终利用傅里叶快速变换进行图像配准。通过实验验证，该缺陷检测准确率可达98.7%，相对于其他缺陷检测方法，本研究所提出的方法在便捷性和精准性方面均具有一定的优势，可以实现印刷品表面划痕缺陷的快速检测。
{ISBN/ISSN}: 2097-2474
{Notes}: 10-1886/TS
{URL}: https://link.cnki.net/doi/10.19370/j.cnki.cn10-1886/ts.2023.05.004
{DOI}: 10.19370/j.cnki.cn10-1886/ts.2023.05.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的无人水果售卖系统
{Author}: 王伯群;石昭宇;闫亚威;王慕宇;孙策;杨文博;王忠巍
{Author Address}: 哈尔滨工程大学动力与能源工程学院;
{Journal}: 现代电子技术
{Year}: 2023
{Volume}: 46
{Issue}: 19
{Pages}: 75-82
{Keywords}: 计算机视觉;机器学习;回归预测;人机交互;无人售卖;嵌入式;大数据;Linux
{Abstract}: 针对水果线下销售结算环节存在的人工成本高、操作流程复杂、结算效率低等问题，设计一种以机器视觉、机器学习等人工智能技术为支撑的无人水果售卖系统。该设备利用OpenCV开源函数库处理水果图像，在DSP端调用图像分析算法加快图像预处理速度；使用支持向量机构建水果分类模型，实现售卖系统自主快速识别功能；建立水果轮廓面积-重量回归模型，并设计质量残差分配算法，实现多种水果质量预测功能，创新多种水果同时称重模式；提供人机交互界面，整合水果种类、重量、价格、收款码等售卖信息，实现系统和用户之间高效交互。该无人水果售卖系统融合人工智能技术，实现了“识别称重结算”一体化、全流程无人化，可降低人工成本，简化结算流程，缩短结算时间。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2023.19.015
{DOI}: 10.16652/j.issn.1004-373x.2023.19.015
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的农作物病害识别研究进展
{Author}: 麻剑钧;刘晓慈;金龙新;熊伟;易森林;封春芳;刘阳;夏先亮
{Author Address}: 湖南省农业农村信息中心;衡阳县优质农产品开发中心;湖南省农业信息与工程研究所;常宁市洋泉镇农业综合服务中心;衡南县三塘镇农业综合服务中心;常宁市农业技术推广中心;
{Journal}: 湖南农业科学
{Year}: 2023
{Volume}: 
{Issue}: 09
{Pages}: 97-100
{Keywords}: 病害识别;卷积神经网络;机器学习;模型部署;综述
{Abstract}: 基于机器视觉的农作物病害识别是近年来农业领域备受关注的研究方向。该识别技术旨在通过图像处理自动检测和识别农作物受到的病害，以便及时发现农作物病害，尽早防治。回顾了传统病虫害识别的机器学习方法；介绍了自动特征提取的深度学习方法，并从病害分类、病害检测和病害分割3个方面阐述了深度学习方法在农作物病害识别中的的应用研究进展；讨论了基于机器视觉的农作物病害识别技术目前面临的挑战，例如大规模数据集的获取不易、数据不平衡和模型部署难等；最后对机器视觉在农作物病害识别领域应用的未来发展方向进行了展望。
{ISBN/ISSN}: 1006-060X
{Notes}: 43-1099/S
{URL}: https://link.cnki.net/doi/10.16498/j.cnki.hnnykx.2023.009.020
{DOI}: 10.16498/j.cnki.hnnykx.2023.009.020
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水面巡航清洁机器人
{Author}: 陈桥;邓卉彤;向冠名;李昂
{Author Address}: 湖南工程学院计算科学与电子学院;
{Journal}: 湖南工程学院学报(自然科学版)
{Year}: 2023
{Volume}: 33
{Issue}: 03
{Pages}: 44-50
{Keywords}: 水面垃圾清理机器人;机器视觉;OPENCV
{Abstract}: 针对小面积水域垃圾漂浮物打捞方式落后以及人工清理效率不足等问题，提出一种基于OPENCV机器视觉的水面巡航清洁机器人.机器人以STM32F103ZET6为控制器，采用边缘识别Sobel算子进行距离控制和航线规划，LBP级联分类器进行目标检测，联动推杆机构和摆动捕捞机构进行垃圾回收，以双无刷电机作为水中动力结构.机器人支持移动终端远程控制，搭载姿态模块进行侧翻预警，航行状态下目标识别率能达到86%以上.系统响应速度快，具有较好的抗干扰能力，对水域清洁维护具有重要意义.
{ISBN/ISSN}: 1671-119X
{Notes}: 43-1356/N
{URL}: https://link.cnki.net/doi/10.15987/j.cnki.hgbjbz.2023.03.013
{DOI}: 10.15987/j.cnki.hgbjbz.2023.03.013
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉在智能饮水机中的应用研究
{Author}: 吴雪良
{Author Address}: 佛山市云米电器科技有限公司;
{Journal}: 日用电器
{Year}: 2023
{Volume}: 
{Issue}: 09
{Pages}: 81-83+106
{Keywords}: 机器视觉;饮水机;智能
{Abstract}: 常规饮水机定量出水功能对杯子规格要求比较高，难以满足用户个性化的需求。随着机器视觉技术的发展，使得家电更加智能化。本文将机器视觉技术与饮水机相结合，通过对图像灰度值分类，设定不同的分割阈值，有效地提高不同种类杯子的杯口识别率。并根据图像中提取杯口轮廓和水位轮廓，设定阈值使其能够自动停水，避免了水资源的浪费，同时提高用户的智能化使用体验。
{ISBN/ISSN}: 1673-6079
{Notes}: 44-1628/TM
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwnS74ReI-Hh33ks9bR-JdN1eTTWT9irUtPBzujqdsYpuY14HxiMO9KLStQJVRQPlRGApSIoX-DoMQJi6AM8Y2Bi7RMhM1FolDTDXzsiVxExzZ0HS3B7ziuuMoSqsC3HXrz_5kwx2rHKu-vb1AQtzu3i9C9LQWtIZUopAlDsaBblOyJP_oIoJB0QMQ26BEg2PQ=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人工智能技术的学生课堂学习行为监测系统设计
{Author}: 刘晓
{Author Address}: 广西机电职业技术学院;
{Journal}: 中国新通信
{Year}: 2023
{Volume}: 25
{Issue}: 18
{Pages}: 65-67
{Keywords}: 人工智能;学生课堂学习行为;监测系统;行为识别;计算机视觉
{Abstract}: 人脸识别技术作为当前计算机视觉中的研究热点，被广泛应用在各个领域。计算机技术的发展和智能设备的普及，反而让高校学生旷课、上课迟到、课堂学习精力不集中等问题加重。而现有的学生课堂学习行为管理方式以及行为监测技术在应用课堂学习环境中应用时，受易遮挡、学生人体姿态多样等问题的影响，无法充分满足对学生课堂学习行为进行监测的要求。为了解决这一问题，本文结合人工智能技术提出了一种学生课堂学习行为监测系统的设计方案，该系统能够实现个性化无痕监测，且对学生课堂学习没有任何影响。具体来说，该监测系统的设计主要包含了注册模块、摄像模块、存储模块、数据处理中心、体型检测模块、学生行为轨迹合成模块以及课堂行为识别模块等。经验证明，该系统的设计，能够高效、智能地实现对学生课堂学习行为进行监测。
{ISBN/ISSN}: 1673-4866
{Notes}: 11-5402/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy61UaJSGd5aotdo2nvZCIF7ESn5gQXlMfWIn9IGp1k5Ze2xSJp63WE2jMwZQYMkjBBPb-hG2BQ9fsVVcekhXtKM1u8uySMH7o0PXthdOfPn05EIzw_BlnBT7cGE5Tb_N06n8GOz5Xq0fDK9V86WtZtzD_XOWI6xCMAEAhcl7a6VxHcK1KBXQXxhx3-1U2uWMc=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向边缘特征的实时模板匹配方法
{Author}: 王世勇;乾国康;李迪;张舞杰
{Author Address}: 华南理工大学机械与汽车工程学院;
{Journal}: 华南理工大学学报(自然科学版)
{Year}: 2023
{Volume}: 51
{Issue}: 09
{Pages}: 1-10
{Keywords}: 机器视觉;模板匹配;边缘特征;图像金字塔;视觉点胶
{Abstract}: 模板匹配是机器视觉领域的一项共性关键技术，目前基于边缘特征的模板匹配方法存在搜索时间长、在复杂环境下匹配准确率低等问题。为了在保证鲁棒性的同时提升实时性，提出了一种面向边缘特征的实时模板匹配方法。首先，在模板创建阶段，提出了一种新型边缘稀疏方法，通过置信评分机制筛选出模板中不变性强的边缘点，在保留模板关键特征的同时降低模板信息冗余，进而保证稳定性并提升计算效率。其次，在基于金字塔搜索的图像匹配阶段，提出了一种顶层提前筛选方法，采用归一化曼哈顿距离作为限制条件在顶层搜索结果中排除错误目标位姿，以加快后续各层的搜索速度。构建了5种工况不同的数据集，对所提模板匹配方法进行了对比验证，并将其应用于面向自由平面位姿的快速视觉点胶工艺。实验结果表明，所提模板匹配方法在显著提升匹配速度的同时能够保证高准确率，并且能够有效克服光照、旋转、缺陷、多目标、遮挡等干扰因素，满足机器视觉场景中对图像匹配的鲁棒性和实时性要求。
{ISBN/ISSN}: 1000-565X
{Notes}: 44-1251/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxHM6hpDapByIbH0_nA1VX16S_FoizKAqpMO1ERhpfQQ5fTnd9G11m4WO9fH0LuK22O9oJ6LlNNfgmW6AWsW4Je7qLyaXR4fbpYBu9WtgutYr-kdoGELK_NnxmhAShOQuzedKFPYexlxYziVqQgeF--x-zZVMIRhZMB8vztHB3zZv4cUh8cvkvHMg0kfp9HHyM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉技术的柑橘果实成熟度分选研究
{Author}: 邹伟
{Author Address}: 湖南财经工业职业技术学院;
{Journal}: 农业与技术
{Year}: 2023
{Volume}: 43
{Issue}: 17
{Pages}: 41-44
{Keywords}: 机器视觉;柑橘;颜色检测;成熟度分级
{Abstract}: 柑橘品质区分的重要指标之一就是柑橘果实的成熟度，本文对柑橘的成熟度分选技术进行了研究。与柑橘成熟度相关的重要指标则是柑橘表面颜色，本项目利用机器视觉技术，研究了机器视觉技术对柑橘表皮颜色的识别研究。通过相机采集柑橘的RGB图像，对柑橘图像的RGB颜色空间模型转换为HSV颜色空间模型，分别获取HSV 3个通道的ndarray数据，按H(色调)、S(饱和度)、V(亮度)3个通道分别计算颜色直方图，发现H通道能很好地反映柑橘的成熟度，通过判断H通道颜色直方图最高峰值(像素数目最多)对应的bins色调值所处的区间来判断柑橘成熟度的等级，一等柑橘色度峰值对应的bins色调值区间为10°～25°,二等柑橘色度峰值对应的bins色调值区间为25°～40°,三等柑橘色度峰值对应的bins色调值区间为40°～55°,四等柑橘色度峰值对应的bins色调值为大于55°。根据被检测柑橘的峰值对应的色调值区间进行条件判断，输出柑橘颜色的等级，以此来判断柑橘的成熟度。研究结果表明，基于机器视觉技术的检测手段对柑橘成熟度的检测准确度达到90%以上，能很好地对柑橘品质进行区分。该研究成果可为水果品质自动化分级技术提供技术支撑。
{ISBN/ISSN}: 1671-962X
{Notes}: 22-1159/S
{URL}: https://link.cnki.net/doi/10.19754/j.nyyjs.20230915011
{DOI}: 10.19754/j.nyyjs.20230915011
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能台灯的设计与实现
{Author}: 林君萍
{Author Address}: 福建船政交通职业学院;
{Journal}: 长江信息通信
{Year}: 2023
{Volume}: 36
{Issue}: 09
{Pages}: 235-237
{Keywords}: 近视;智能台灯;图像处理;人脸识别;坐姿监控
{Abstract}: 青少年近视防控问题已上升为国家战略，为了有效的预防青少年近视，促进青少年健康成长，设计一款能够科学预防与控制近视的智能台灯显得十分必要。目前市面上大多数智能台灯主要包含学习机功能、调节亮度，远程控制开关等功能，对防控近视并没有起到实质性的干预作用。针对这些不足文章提出一款以中小学生标准尺寸的学习桌椅为基础的智能台灯，以STM32H750VBT6单片机作为主控芯片，结合Open MVh7摄像头，主要采用图像采集、图像处理和人脸识别技术，实现坐姿监控、语音提示、亮度自动调节等功能。通过以上功能可以实时监控并提醒青少年改变不良坐姿，有效预防近视的发生。
{ISBN/ISSN}: 2096-9759
{Notes}: 42-1914/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzGFIfwbw1Yr9nv9GkAFW2bOlez--uFFKbJXSxTjVpd-StOF_QfMO1ZgFvf8n5YeD4hFiljarSWKbBPRqjjVRegQy_iGlPIzq4bTOk3-oAbDCF8rpFsYBSYmVr9hHSw_rEGzDpQgrWrgx0pkBtgYhQmot2qrxrWl7czq9sgOYb9MllF4hIdU4ujRazhj8Eokxk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在生猪健康监测中的应用研究进展
{Author}: 蔡文涛;李子圣;韩建宁;杨凯
{Author Address}: 中北大学信息与通信工程学院;
{Journal}: 黑龙江畜牧兽医
{Year}: 2023
{Volume}: 
{Issue}: 24
{Pages}: 22-30
{Keywords}: 计算机视觉;智能养殖;图像处理;异常检测;目标提取;行为识别;生长预测;疾病诊断
{Abstract}: 生猪视觉及其附属信息对生猪健康状态的判别具有重要意义，不仅可以实时反映生猪的生长情况，同样也是生猪疾病诊断和治疗的重要依据。随着图像处理和机器学习技术的不断发展，具有无损害性、高效性、低成本、自动化和实时性的计算机视觉技术已逐渐在规模生猪养殖场中普及。笔者总结了国内外近20年来关于计算机视觉技术在生猪健康养殖中具有代表性的研究工作，在描述计算机视觉系统基本概念和基本组成的基础上，回顾了计算机视觉技术在生猪目标提取、身份识别、运动监测、行为识别、体重估计和病变区域检测中的应用及算法，并对基于计算机视觉测量的生猪疾病诊断、生长预测与精确饲养等综合应用现状进行了分析讨论，以评估计算机视觉技术在生猪养殖领域的总体应用情况和存在的问题，旨在为计算机视觉技术在生猪健康养殖中的研究和发展提供借鉴。
{ISBN/ISSN}: 1004-7034
{Notes}: 23-1205/S
{URL}: https://link.cnki.net/doi/10.13881/j.cnki.hljxmsy.2023.04.0090
{DOI}: 10.13881/j.cnki.hljxmsy.2023.04.0090
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进Canny算法的边缘检测技术应用及发展趋势
{Author}: 汪宗洋;王煜;朱硕
{Author Address}: 江苏集萃深度感知技术研究所有限公司;南京信息工程大学电子与信息工程学院;无锡学院电子信息工程学院;
{Journal}: 信息通信技术与政策
{Year}: 2023
{Volume}: 49
{Issue}: 08
{Pages}: 90-96
{Keywords}: Canny;边缘检测;图像分割;计算机视觉
{Abstract}: Canny算法是边缘检测中常用的算法之一，Canny算法经过有效改进，可快速、高效地完成对图像边缘位置的准确识别，因此在计算机视觉、图像分析等领域发挥着较为重要的作用。基于边缘检测的概念及过程，着重介绍了Canny算法的各种改进方法，根据不同的改进方式对Canny算法进行分类与总结，并对改进前后的边缘提取结果进行了对比分析；阐述了改进Canny算法的应用与发展前景，总结了目前所面临的问题以及进一步的研究内容。
{ISBN/ISSN}: 2096-5931
{Notes}: 10-1576/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy1oHtIF2U-VC7cq3r53ikJJrZ0pK12YgedXdqXh6nJxR9GPyUy1yYm0as1asb194PH0nosx3IhldbHQKEKr8En051RMM-1kLchrGs-T0pKmoNo2_Q_obqC4EwvldLebi89FfObKl9n4KnU5CH9M7YK5PxUN45WiT4Jh2ydlQTZp81A_l3EbTyhrCrBoucGrqk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人体姿态估计的泳池溺水检测算法
{Author}: 于中阳;杨文辉
{Author Address}: 上海旺链信息科技有限公司;
{Journal}: 科技创新与应用
{Year}: 2023
{Volume}: 13
{Issue}: 23
{Pages}: 66-70+74
{Keywords}: 溺水检测;姿态估计;OpenPose;关键点距离;相似性
{Abstract}: 泳池溺水事故频发，基于计算机视觉的泳池防溺水技术可以有效预防溺水事故的发生。当前的基于计算机视觉的泳池防溺水技术大多利用目标检测算法研究游泳者的头部、人体与水面的位置关系，人为设置溺水判定规则，主观因素太强，模型参数过多且难以确定，准确率有待提高。该文提出一种基于人体姿态估计的泳池溺水检测算法，利用人体姿态估计模型OpenPose对游泳者的图像进行人体关键点标记，构建人体关键点距离向量集合，通过比较游泳者的关键点距离向量与溺水状态的关键点距离向量的相似性判断溺水行为。实验结果表明，该文提出的基于人体姿态估计的泳池溺水检测算法的准确率为95%，精确率为85%，召回率为89.47%，可以有效地检测出溺水游泳者。
{ISBN/ISSN}: 2095-2945
{Notes}: 23-1581/G3
{URL}: https://link.cnki.net/doi/10.19981/j.CN23-1581/G3.2023.23.015
{DOI}: 10.19981/j.CN23-1581/G3.2023.23.015
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 被动式红外成像气体目标智能检测算法及量化研究进展
{Author}: 王琦;潘夏童;邢明玮;孙云龙;赵勇
{Author Address}: 东北大学信息科学与工程学院;东北大学流程工业综合自动化国家重点实验室;东北大学秦皇岛分校控制工程学院;
{Journal}: 控制与决策
{Year}: 2023
{Volume}: 38
{Issue}: 08
{Pages}: 2265-2282
{Keywords}: 气体泄漏检测;被动式红外成像;计算机视觉;柱密度;路径浓度;泄漏率
{Abstract}: 在“双碳目标”、安全发展的时代背景下,工业气体泄漏检测因牵涉经济资源、生态环境、生产安全而成为国内外普遍关注的重要问题.气体被动式红外成像因其动态直观、可进行非接触式大范围遥测的特点而被视为检测泄漏的有效工具.在这一技术中,气体目标智能化检测及泄漏量化是两个核心的研究热点问题,且在未来一段相当长的时间内仍会是两项挑战.鉴于此,针对这两方面的研究进行综述.首先,分析基于被动式红外成像气体检测技术的原理,探究影响成像检测结果的关键因素及其作用形式;其次,将气体智能化检测算法按图像识别、视频分类、目标检测、图像分割等不同计算机视觉任务予以分类整理;再次,分别介绍气体量化任务中柱密度、路径浓度、泄漏率三者的测量方法,并重点强调不确定性分析对量化结果的重要性;最后,对气体智能化检测及量化研究中存在的问题提供一些潜在的解决方案,并展望了气体被动式红外成像技术未来的研究方向.
{ISBN/ISSN}: 1001-0920
{Notes}: 21-1124/TP
{URL}: https://link.cnki.net/doi/10.13195/j.kzyjc.2023.0325
{DOI}: 10.13195/j.kzyjc.2023.0325
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的鱼类低氧胁迫行为检测与跟踪算法
{Author}: 李道亮;姜国旗;杨建安;白羽;谢琰;王承国
{Author Address}: 中国农业大学国家数字渔业创新中心;中国农业大学信息与电气工程学院;中国农业大学烟台研究院;
{Journal}: 农业机械学报
{Year}: 2023
{Volume}: 54
{Issue}: 10
{Pages}: 399-406
{Keywords}: 加州鲈鱼;胁迫行为;目标检测;多目标跟踪
{Abstract}: 为了能准确检测、跟踪加州鲈鱼因水中溶解氧含量低产生的胁迫行为，本文构建了一种改进的YOLO v5与DeepSORT组合网络算法。在算法方面提出2个改进方案：在原YOLO v5的Backbone和Neck中分别加入2个基于移位窗口的自注意力Swin Transformer模块，提升了网络对目标特征信息的提取能力，以此提升原模型的检测效果；采用Warmup和Cosine Annealing结合的学习率策略，使多目标跟踪算法DeepSORT前期收敛速度更快、更稳定。实验结果表明，在目标检测方面，相对于原YOLO v5,改进的YOLO v5的mAP@0.5、mAP@0.5:0.95和召回率分别提升1.9、1.3、0.8个百分点，在不完全遮挡情况下，改进的算法表现出更好的检测效果。在目标跟踪方面，DeepSORT算法的MOTA、MOTP和IDF1分别提升4.0、0.7、10.7个百分点，并且加州鲈鱼在遮挡前后的ID切换频率得到明显抑制。改进的YOLO v5与DeepSORT跟踪算法更适合于检测、跟踪加州鲈鱼的低氧胁迫行为，能够为加州鲈鱼的养殖提供技术支持。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://link.cnki.net/urlid/11.1964.s.20230731.1439.014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目结构光相机的机器人视觉定位系统开发
{Author}: 滕嘉林
{Tertiary Author}: 董辉跃;朱明华
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 移动机器人系统;手眼标定;李代数;机器视觉;Socket
{Abstract}: 随着船舶领域的快速发展,其对大型装备的需求日益迫切。现有某大型船舶长筒段状工件,在其开孔加工时人工参与较多,为提高其加工过程中的自动化水平,保障加工精度与效率,使用移动机器人系统替代传统的人工操作。由于加工时移动机器人系统需带动机器人运动至不同加工区域,导致机器人底座频繁与工件发生相对位姿变换,因此在机器人执行开孔轨迹前需完成工件坐标系测量,进而实现工件定位。针对该实际需求,本文开发一套基于双目结构光相机的机器人视觉定位系统,通过手眼标定技术与机器视觉技术实现工件坐标系测量,为移动机器人系统的工件定位提供理论与实践支撑,本文的主要内容及创新点如下:
(1)根据定位系统需求,确定软硬件选型,构建以双目结构光相机为视觉测量设备的手眼系统。完成定位系统手眼标定、工件坐标系测量的方案设计。
(2)设计基于AX=XB模型的手眼标定算法流程并提出基于李代数左扰动模型的手眼标定求解算法。采用棋盘格角点提取技术与机器人输出间接计算相机、机器人位姿变换矩阵作为模型的输入。分别研究基于转轴转角、四元数与李代数的三种求解算法,提出基于李代数左扰动模型的手眼标定算法,该算法将模型中旋转部分全部映射至李代数,并通过基于李代数左扰动模型的优化算法求解。通过手眼标定实验验证上述算法流程具备可行性,实验表明本文算法在求解精度及棋盘格角点坐标系转换精度上略优。
(3)设计基于机器视觉的工件坐标系测量算法流程。先后完成基于多边形轮廓拟合的等分线与肋位线交点测量、基于最小外接矩的等分线与肋骨交点测量、二维码提取测量的图像处理算法流程设计,最后通过基于奇异值分解(Singular Value Decomposition,简称SVD)的刚体位姿变换求解算法计算工件坐标系。通过工件坐标系测量实验验证该算法流程具备可行性。
(4)实现定位系统总体架构并进行集成实验。通过基于Socket通信的数据传输格式设计、机器人自动化测量程序开发与上位机集成操作程序开发,实现定位系统功能的封装与集成。使用上位机集成操作程序进行手眼标定与工件坐标系测量实验,实验表明手眼标定后棋盘格角点的坐标系转换误差小于0.5 mm,工件坐标系测量后视觉基准点的坐标系转换误差最大值为0.89 mm,测量过程中上位机集成操作程序操作连贯,对软硬件控制集成性较高,在提高某大型船舶数字化制造水平方面具备实际应用价值。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.001367
{DOI}: 10.27461/d.cnki.gzjdx.2023.001367
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的圆形垫圈尺寸测量系统设计
{Author}: 张炳星;高军伟;王建冲;刘佳浩
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 工具技术
{Year}: 2023
{Volume}: 57
{Issue}: 07
{Pages}: 141-145
{Keywords}: 机器视觉;尺寸测量;边缘检测;亚像素边缘;最小二乘法
{Abstract}: 针对传统工业检测中人工测量工件尺寸存在效率低、精度差等问题，设计了基于机器视觉的圆形垫圈尺寸测量系统。在MATLAB软件中对CCD相机进行尺寸标定，对采集的图像进行灰度处理，使用改进后的Canny自适应迭代阈值算法对图像进行边缘检测，对边缘坐标进行双线性插值并提取亚像素边缘坐标，根据最小二乘法对亚像素边缘坐标进行圆拟合，得到工件内径与外径尺寸。实验结果表明，本系统的测量精度可达到±0.02mm,可应用于圆形工件的视觉测量。
{ISBN/ISSN}: 1000-7008
{Notes}: 51-1271/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxkfFk2ZqhNSF1wis3mw3lCXMlD62koPAzXjBCF3aQDiTCTsDxWOolDSsOhQIosTA9OW1grJLLcIu0hpFTS14FHjK4ixp3RTp1zawj_2Qjs8jqxu94Tzq_My783KC96GDY9zD0cGT4ngJzCgDCXokbU9emrzhAl8FdjQ13ttIhjlBCsGdAYBgPp4IyE01Fsodg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像超分辨率算法研究
{Author}: 张铂溱
{Tertiary Author}: 唐延东;高成
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;超分辨率;卷积神经网络;残差网络
{Abstract}: 图像分辨率是用于评估图像中蕴含细节信息丰富程度的性能参数,代表了成像系统所能真实反映对象细节信息的能力。与低分辨率图像相比较,高分辨率图像一般含有较大的像素密度、较多的纹理细节信息和较高的可信赖度,在卫星遥感、视频监控、医学影像等领域具有较高的应用价值。图像超分辨率重建技术作为提升图像分辨率的有效手段,具有效率高、成本低和应用广泛等优点,一直是图像处理领域和计算机视觉任务中的热点研究课题。本文主要研究了残差网络结构、注意力机制和生成对抗网络等方法在图像超分辨率领域中的应用,提出了两种图像超分辨率重建算法,在一定程度上解决了梯度消失问题和模型训练不稳定问题,提高了重建图像的质量。针对传统的神经网络在图像超分辨率重建过程中大多仅使用图像的空间域信息,生成的图像容易丢失重要细节信息等问题,本文在对现有基于深度学习的图像超分辨率算法的研究基础上,提出一种基于深度残差注意力机制的超分辨率重建算法。本文首先结合局部残差学习和全局残差学习构建了一个深度残差网络。本文提出的网络不仅能够充分发掘图像的内部特征,而且能够减轻网络退化现象。针对这一残差网络,本文将改进后的通道注意力机制网络添加到局部残差网络中,加强了神经网络对高频特征信息的提取能力,减少了梯度消失现象,提高了信息传递效率。针对重建部分,本文使用了不同尺度的卷积核对图像进行特征提取,通过获取多个尺度上的图像特征信息,重建出了具有丰富纹理细节信息的高分辨率图像。本文在对现有基于生成对抗网络的图像超分辨率算法的研究基础上,分别对生成网络和判别网络进行了改进。在生成器网络中,本文引入了残差密集模块和改进后的通道注意力机制,目的是让生成网络生成的图像与原始图像更加相近,并且使神经网络对图像中的高频信息更加关注。在判别器网络中,本文使用相对判别网络代替标准判别网络,让神经网络输出真实图像比虚假图像具有更真实的概率,分析和改进了神经网络中的激活函数,使网络学习到的纹理细节更加细致。为了验证算法的有效性,将本文提出的两种方法分别与选取的图像超分辨率经典算法进行了对比实验。实验结果表示,经过本文方法重建出的图像更清晰,细节纹理更真实,重构效果相较于对比算法获得了更好的客观评价指标和主观视觉效果。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2023.000133
{DOI}: 10.27322/d.cnki.gsgyu.2023.000133
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的静态手势识别实验设计
{Author}: 白煜;李香萍;张雨菡
{Author Address}: 天津大学电气自动化与信息工程学院;
{Journal}: 实验技术与管理
{Year}: 2023
{Volume}: 40
{Issue}: 06
{Pages}: 187-191+198
{Keywords}: 机器视觉;卷积神经网络;支持向量机;手势识别
{Abstract}: 该文面向本科实践教学，以静态手势识别为目标，利用机器学习开发了机器视觉实验项目。在实验的算法设计部分，分别利用支持向量机和卷积神经网络实现了两种手势识别算法。文中详细介绍了两种手势识别算法的原理、特点和流程。在实验的算法验证部分，详细介绍了利用Python语言、编译环境和数据集实现算法仿真的方法。仿真结果显示，两种算法均可有效识别多种静态手势。该实验项目包括任务分析、算法设计、算法优化、编程实现、结果分析等环节。通过本实验的训练，有助于提升本科生在智能图像处理领域的实践能力。
{ISBN/ISSN}: 1002-4956
{Notes}: 11-2034/T
{URL}: https://link.cnki.net/doi/10.16791/j.cnki.sjg.2023.06.029
{DOI}: 10.16791/j.cnki.sjg.2023.06.029
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的细粒度图像分类方法研究
{Author}: 杜小龙
{Tertiary Author}: 黄树成
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 细粒度图像分类;无监督学习;区域定位;循环注意力;渐进式训练
{Abstract}: 细粒度图像分类是指在区分出基本类别的基础上,进行更详细的子类划分,如区分鸟的种类、车的款式、飞机的型号等。细粒度图像分类在现实中具有较高的研究价值和深远的应用前景,因而成为计算机视觉领域的研究热点。然而,现阶段的细粒度图像分类研究依然面临一些挑战。比如:子类别之间的差异往往非常微妙,导致类别间的鉴别性区域难以被准确定位;物体的姿态变化与视觉变化,导致对图像中有效特征的提取工作较难开展。针对这两个问题,本文基于深度学习,构建了一个细粒度图像分类模型,该模型包括基于无监督学习的鉴别性区域定位方法、基于循环注意力的细粒度特征提取方法。模型有效解决了鉴别性区域难以定位和图像有效特征难以提取的问题。模型在CUB-200-2011、FGVC-Aircraft以及Stanford Cars数据集上进行了实验,实验结果表明,该模型与现有先进方法相比具有明显优势。本文的主要贡献如下:(1)提出了一种基于无监督学习的鉴别性区域定位方法(Discriminant Region Location Method Based on Unsupervised Learning,DRLU)。首先,方法中的区域检测器利用了细粒度图像数据集中所有图像的宏观相似性,以便在预先训练的深度卷积神经网络的特征空间中挖掘重复出现的鉴别性区域。其次,本文设计了一种目标函数确保鉴别性区域的局部性和唯一性。最后,在区域检测器嵌入了基于相关分数的置信度,使定位模型能够估计每个区域的可见度。在CUB-200-2011和Stanford Cars两个细粒度图像数据集上进行大量实验,对比现有先进方法,该方法具有明显优势。(2)提出了一种基于循环注意力的细粒度特征提取方法(Fine-grained Feature Extraction Method Based on Recurrent Attention,FERA)。该方法包含的循环注意力模块(Recurrent Attention Module,RAM)通过生成注意力掩膜定位物体的关键区域,从而提取鉴别性特征。其中,注意力掩膜是根据RAM接收到的特征图和前一个RAM生成的注意力状态融合共同产生。通过将RAM嵌入深度卷积神经网络可以有效地提取不同尺度的鉴别性特征。本文在CUB-200-2011、FGVC-Aircraft以及Stanford Cars三个细粒度图像数据集上进行了大量实验,与现有先进方法对比,该方法具有明显优势。(3)结合上述两种方法,本文构建了一种基于DRLU与FERA的细粒度图像分类模型(DRLU and FERA,DAF)。该模型包含DRLU模块和FERA模块:DRLU模块定位细粒度图像的鉴别性区域,FERA模块提取细粒度图像中的有效特征。此外,本文引入渐进式训练对分类模型参数进行调整,保证每个阶段的参数尽可能达到最优。本文在CUB-200-2011、FGVC-Aircraft以及Stanford Cars三个细粒度图像数据集上,进行大量实验,对比现有先进方法,该模型具有明显优势。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2023.000640
{DOI}: 10.27171/d.cnki.ghdcc.2023.000640
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的交通目标识别技术研究
{Author}: 皇甫俊逸
{Tertiary Author}: 孟乔
{Publisher}: 青海大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智能交通;计算机视觉;YOLOv5;多属性分类;目标检测
{Abstract}: 随着城市化的快速发展和人口增长,道路交通流量不断增加,交通问题日益凸显,交通管理和安全监管任务越来越繁重。交通目标识别技术已经成为辅助交通管理和保障交通安全的重要手段,基于视觉的目标识别技术以成本低廉、高效率、信息丰富度高以及识别范围广等优点受到人们广泛的关注。为了满足精细化的交通管理需求、提高交通安全、改善交通拥堵状况、以及提高交通管理的效率和水平,本文就交通目标分类、检测以及跟踪三个任务场景展开研究,主要研究内容和创新如下:
1.针对多标签、细粒度的交通目标分类问题,本文提出一种基于CFP和半监督数据扩充的多属性分类网络。该网络首先使用目标框压缩技术解决了YOLOv5中多个属性框相互抑制、置信度低等问题;其次改进了FPN结构,在特征金字塔顶层使用EVCBlock融合层间特征;再使用半监督学习方法进行数据集扩充,通过mosaics数据增强提高模型的鲁棒性和泛化能力。最后在河湟杯比赛数据集上验证了本文多属性分类网络分类性能,并与传统分类算法和改进前YOLOv5算法进行对比分析。
2.针对复杂交通环境下的目标检测问题,本文提出一种基于Ghost Net与注意力机制的YOLOv5交通目标实时检测模型。该模型采用基于遗传算法的K-means聚类方法获取适用于交通目标检测的最佳预选框;使用轻量的Ghost卷积提取目标特征,并构建基于CSP结构的C3Ghost模块,大幅度压缩模型参数量,降低计算成本,提高计算速度;在特征融合层添加Transformer Block和CBAM注意力模块,来探索模型特征提取潜力以及为模型在密集对象的场景中寻找注意力区域;最后在UA-DETRAC数据集上进行消融实验和综合性能评价。
3.针对交通多目标跟踪问题,本文构建了一个基于Deep Sort的YOLOV5交通目标跟踪系统。系统包括YOLOv5目标检测、卡尔曼滤波预测与级联匹配、基于IOU匹配、Deep Sort矩阵更新和处理。在UA-DETRAC数据集验证了该交通多目标跟踪系统的有效性。
{URL}: https://link.cnki.net/doi/10.27740/d.cnki.gqhdx.2023.000280
{DOI}: 10.27740/d.cnki.gqhdx.2023.000280
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低光照图像增强算法研究及硬件实现
{Author}: 李宇航
{Tertiary Author}: 乔世杰;田泽
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 低光照图像增强;深度可分离卷积;通道注意力特征融合;Zynq-7020
{Abstract}: 在光照不足、光照不均匀以及背光等环境下,采集的图像存在亮度不足、缺失细节信息以及噪声干扰等图像退化问题,这些图像不仅降低了人们的视觉感受,还会严重影响目标识别追踪、智能辅助驾驶等计算机视觉任务系统的性能。低光照图像增强目的是对光照不足的低质量图像进行处理,恢复图像的亮度、对比度以及细节纹理信息,使图像质量得到明显提升。本文针对低光照图像增强算法研究中遇到的缺少对比的正常光照图像以及网络参数量过大的问题,在基于自正则化的低光照图像增强算法的基础上进行改进优化,其网络结构基于U-Net网络,利用多尺度通道注意力特征融合模块,结合深度可分离卷积在保证算法精度取得有效提升的同时能够明显降低网络模型的参数量。在本文的网络结构中,对主干网络中编码器和解码器部分对应层的特征图进行多尺度通道注意力特征融合,将底层特征和高层特征进行融合之后,使得网络能够保留更多的高分辨率信息,能够更好的恢复图像中包含的细节信息,提升恢复后图像质量。本文将改进之后的算法在SCIE数据集上进行模型训练和测试,实验结果表明本文算法与自正则化算法相比参数量仅有12.6MB,并且恢复后的图像在峰值信噪比和结构相似度两个评价指标分别提升了 0.19和0.004。然后在LOL数据集上测试本文算法的泛化能力,并与不同算法进行效果比较,通过峰值信噪比和结构相似度两个评价指标进行客观对比,证明了本文算法改进的有效性。本文基于ZYNQ-7020开发平台对改进后的通道注意力特征融合图像增强网络进行硬件部署,首先对训练后网络模型的权重偏执参数进行INT8量化,然后根据网络结构与运算过程进行了软硬件划分,硬件设计在PL端完成卷积、池化、双线性插值、激活函数等模块的运算,软件设计在PS端通过寄存器配置设计,对PL端的运算和数据交互进行调度与控制,并完成多尺度通道注意力特征融合模块运算。最后在ZYNQ-7020开发平台上进行验证测试,系统时钟频率为100MHz时,整体算法推理耗时仅为1.57s,功耗为4.85W。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000668
{DOI}: 10.27398/d.cnki.gxalu.2023.000668
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轴类零件在线智能测量系统研究
{Author}: 张航
{Tertiary Author}: 高峰
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;轴类零件在线测量;边缘检测;几何要素智能测量;测量系统开发
{Abstract}: 轴类零件是变速箱中的关键部件之一,其加工精度会直接影响变速箱的传动精度、性能和使用寿命,因此在加工完毕后必须严格按照工艺文件设计要求对轴类零件进行测量,合格后才能进行后续的工序环节。在大批量生产背景下,轴类零件在线测量系统需具有高精度、高效率、自动化及智能化等特点。本文围绕轴类零件加工尺寸在线测量问题,基于机器视觉技术进行轴类零件在线智能测量系统开发。本文的主要研究内容如下:根据所获取的零件图像特点,运用形态学闭运算和双边滤波对图像进行预处理,以保证边缘的连续性与完整性,也消除了由于毛刺或毛絮等引起的伪边缘对检测精度的干扰;采用最大类间方差法自适应确定Canny算子双阈值用于在线采集的不同图像的边缘检测,利用其高鲁棒性的特点完成轴类零件图像的整像素边缘的初定位;据此,进行基于泰勒多项式拟合的Steger亚像素边缘检测,解决了在图像全图上遍历卷积而导致的运算量大、检测效率低的问题;通过设计的标准二值图像和标准量棒图像考核边缘检测算法的定位精度,并统计分析算法的执行效率。通过与Canny-Zernike矩算法和Canny-Franklin矩算法的检测结果对比,本文所提出的Canny-Steger算法定位精度高、检测速度快,可有效提高零件图像ROI的边缘检测精度和效率,快速提供测量项几何要素数据点集,具有工程应用价值。为了提高大批量生产背景下轴类零件在线测量过程的自动化与智能化,结合零件生产工艺提出轴类零件在线智能测量整体框架。通过对测量系统的需求分析进行了测量系统的总体架构设计,按照测量系统测量精度、节拍等设计测量系统结构、控制系统、视觉系统,确定测量动作流程以保证获取高质量的图像。根据CAD工艺图纸的DXF底层数据格式设计了轴类零件的工艺信息解析流程,提取零件轮廓、尺寸公差等数据;提出凸包点PCA分析+NDT+改进ICP的配准方法实现图像边缘点集与DXF轮廓点集配准从而确定测量项在图像中的参考点,在参考点邻域划分测量区域即可实现工序中几何要素的自动测量。测量系统标定后进行径向和轴向测量精度和重复性精度的实验。通过零件生产过程中测量数据的SPC分析及建立加工机床和测量设备的闭环系统来实现生产过程中的质量控制,保证零件高质量持续加工生产。基于.NET平台使用C#语言按照分层模块化设计开发测量系统软件,主要包括控制交互、图像采集处理、信息管理、质量控制等模块。建立轴类零件在线智能测量系统对轴类零件大批量、无人化100%测量的生产线自动化数字化智能化具有理论与应用价值。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000191
{DOI}: 10.27398/d.cnki.gxalu.2023.000191
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的刀具测量系统软件开发
{Author}: 武登晖
{Tertiary Author}: 李艳;张涛
{Publisher}: 西安理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 刀具测量;几何尺寸;轮廓误差;亚像素;配准
{Abstract}: 金属刀具作为切削过程用于去除工件加工余量的工装,在出厂和加工前需对其进行质量检测,对刀时还需获取其几何参数。对刀具进行准确且高效的测量能够以更低的制造成本获得更高的加工效率以及更好的产品质量。考虑到目前机械接触式和光学投影式等传统刀具测量方式已无法满足现代飞速发展的制造业对效率和精度的要求,本文展开基于机器视觉测量技术的刀具几何参数和轮廓误差检测方法研究。本文的主要研究内容如下:相机标定优化方法研究。首先,建立相机成像模型、推导成像坐标系转换关系及确认待标定参数,分析得出传统张氏标定方法存在容易陷入局部最优导致标定精度变差的缺点。其次,为提升相机标定精度,使用张氏标定法对相机进行标定获取初始相机内外参数。基于成像模型建立适应度函数,引入混沌粒子群算法对初始参数进行优化。最终,通过计算优化前后的重投影误差,表明本文方法提高了相机标定精度,同时应用优化后得到的相机参数纠正图像存在的畸变。刀具几何参数的测量方法研究。针对刀具几何参数的测量,提出一种刀具几何参数测量方法。首先,采用导向滤波器去除图像中的噪声,使用Canny算子获取像素级边缘点集。其次,应用八邻域轮廓跟踪算法将离散的边缘有序化,在像素级边缘的基础上采用基于Sigmoid函数拟合的亚像素边缘检测算法,进一步细分边缘获取亚像素边缘点集。最后,根据先分割再识别融合的思想,基于Ramer多边形逼近轮廓分割算法将边缘点集分割为直线段和圆弧段,同时引入Tukey权重函数降低可能存在的离群点在拟合过程中的干扰。刀具轮廓误差的检测方法研究。针对刀具轮廓误差的检测,提出一种刀具轮廓误差检测方法。首先,经滤波、像素级、亚像素级等图像处理算法获取刀具的待测轮廓点集。其次,根据先粗后精的配准思想,基于SC-ICP的点集配准算法将待测轮廓与设计轮廓配准对齐。最终,为提高粗配准的效率,引入轮廓密度改进传统形状上下文算法(SC)使其可自适应轮廓点集的数目进行样本点采样,避免样本点过于稀疏或过于稠密情况的发生。刀具视觉测量系统开发。首先,针对测量系统进行需求分析及总体设计,研究DXF文件的底层特性后设计一种图元信息解析算法,实现系统CAD图纸读取功能以及制造刀具标准轮廓,同时使用叶根铣刀CAD图纸验证算法稳定性;为提高系统测量效率,基于Hu不变矩描述刀具刃部轮廓之间的相似度,实现几何尺寸测量前的刃形自动识别功能,同时开展相似度试验以验证该方法的有效性及稳定性。其次,分析系统工作涉及到的数据交互,对系统数据库进行概念结构设计及数据表设计。最后,开发刀具测量系统软件,实现几何尺寸测量、轮廓误差检测、自动刃型识别、CAD图纸预览、用户管理、测量数据及工件库查询等功能。
{URL}: https://link.cnki.net/doi/10.27398/d.cnki.gxalu.2023.000554
{DOI}: 10.27398/d.cnki.gxalu.2023.000554
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的芯片引脚缺陷检测与分拣系统
{Author}: 王建冲;高军伟
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 仪表技术与传感器
{Year}: 2023
{Volume}: 
{Issue}: 06
{Pages}: 56-63
{Keywords}: 机器视觉;改进Canny边缘检测;萤火虫BP神经网络;缺陷检测;机械臂分拣
{Abstract}: 针对传统工业中芯片的引脚缺陷检测及分拣精度低、实时性差的问题，设计了基于机器视觉的芯片引脚缺陷检测与分拣系统。系统以对SOP芯片的引脚缺陷检测、目标定位、抓取放置为任务，通过MATLAB处理芯片图像，采用改进的Canny和Hough变换实现引脚的边缘检测与连接，采用Blob分析与萤火虫BP神经网络相结合的方法实现芯片引脚的缺陷检测，然后求取芯片的形心作为定位参考坐标，结合三自由度机械臂，使用标准的D-H法建立机械臂运动学模型，并根据芯片的定位坐标通过运动学逆解计算出每个连杆需要转动的角度，转化为步进值后通过串口通信方式发送给Arduino,然后由Arduino完成对机械臂的控制，实现芯片的分拣。测试结果表明，系统达到了设计要求，具有一定的应用性。
{ISBN/ISSN}: 1002-1841
{Notes}: 21-1154/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvygdAbfrZ0Dp8-Hodj-waWtHQLZY25ngjUHJDSer5W-EiQT8z_6R_UhmzMf7_aTiU5nsNx6no6_6TqBMRueBwsHbtsN6pCnyAHD_NnGVlWYSkWzhujMjAGqg5inGpZFVC8eggOEiCAQoRs-xegszzNw_eai_O4maNbk8MYjaK8DwPt-aL5bmcFrb6VnDzVAqo0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的焊缝坡口自动识别与定位技术研究
{Author}: 李茂勇
{Tertiary Author}: 黄继强;杨拴岐
{Publisher}: 北京石油化工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 焊缝识别;焊缝定位;焊接机器人;机器视觉
{Abstract}: 自动化和智能化焊接机器人技术已经成为现代工业制造过程中必不可少的一部分。当前的部分焊接机器人主要通过线激光主动视觉传感器与传统图像算法配合的方式进行焊缝跟踪,在跟踪前需要通过人工引导机器人到达工件附近,降低了机器人焊接的自动化程度。为此,本文提出了一种基于视觉的焊缝坡口自动识别与定位机器人系统,引入深度相机,并配合基于深度学习的焊缝坡口识别与定位算法,无需人工干预便可识别和定位焊缝,从而提升了机器人焊接自动化水平,为柔性加工机器人焊接提供了技术支撑。具体的研究工作如下:(1)对系统各部分坐标系进行了研究。首先对系统各坐标系进行定义,完成了各坐标系的基础理论、公式推导,然后完成了相机标定、手眼标定、TCP(Tool Center Point)标定等坐标关系标定,将坐标转换为机器人基坐标系下,得到坐标的统一表示,为后面设计焊缝坡口识别方法、定位方法奠定了基础。(2)研究设计了一套焊缝坡口识别算法。研究了YOLOv5算法,对YOLOv5算法进行改进,在其网络中引入了一种简单轻量且几乎不带来额外计算量的Coordinate attention注意力机制来提升对复杂环境中的焊缝坡口的提取。结果表明,改进之前m AP为82.3%,改进之后达到90.8%,较改进之前提升显著。通过改进后的YOLOv5算法对焊缝坡口实时检测帧率达到20 FPS,满足实际生产中焊缝坡口检测的要求。(3)研究设计了一套先“粗”后“精”的焊缝坡口定位算法。将识别算法与深度相机测距算法进行融合,计算得到焊缝坡口在机器人坐标系下坐标,导引机器人接近焊缝,完成对焊缝坡口的粗定位。精定位通过激光位移传感器提取焊缝坡口表面三维点云,并进行直通滤波的ROI提取、高斯滤波法的离群点去除、RANSAC直线分割、最小二乘法直线拟合、直线相交点计算等步骤对焊缝特征点进行提取,所有特征点形成焊缝轨迹完成焊缝精定位。(4)基于系统方案以及实验室条件完成实验硬件选择,根据系统内容进行上位机软件系统设计,并完成上位机界面开发。通过搭建的基于视觉的焊缝坡口自动识别与定位机器人系统,以对接焊缝坡口以及角接焊缝坡口作为对象对方法可行性、算法精度及系统性能进行了实验研究。结果表明,对接焊缝坡口特征点X、Y方向上定位误差在0.3 mm内,Z方向上的误差在0.5 mm内;角接焊缝坡口特征点X、Y、Z方向上定位误差均在0.3 mm内,可以满足焊接机器人对焊缝识别定位的工作需求。
{URL}: https://link.cnki.net/doi/10.27849/d.cnki.gshyj.2023.000046
{DOI}: 10.27849/d.cnki.gshyj.2023.000046
{Database Provider}: CNKI

{Reference Type}: Conference Proceedings
{Title}: 人工智能在计算机视觉中的创新应用：深度学习和自动特征识别的新趋势与挑战
{Tertiary Title}: 第七届创新教育学术会议论文集
{Author}: 王秀燕
{Author Address}: 滨州职业学院;
{Secondary Title}: 第七届创新教育学术会议
{Place Published}: 中国山西太原
{Subsidiary Author}: 山西省中大教育研究院
{Year}: 2023
{Pages}: 2
{Keywords}: 人工智能;计算机视觉;深度学习;自动特征识别
{Abstract}: 本论文探讨了人工智能在计算机视觉中的创新应用,着重关注了深度学习和自动特征识别的新趋势与挑战。首先介绍了人工智能与计算机视觉的结合背景和意义,以及论文的研究目的。接着详细阐述了深度学习在计算机视觉中的应用,包括图像识别、目标检测、图像分割和语义分析,并提供了虚拟场景中深度学习的实践案例。然后,探讨了自动特征识别在计算机视觉中的应用,涵盖了目标跟踪和人脸识别领域,并讨论了相关的隐私和安全问题。接下来,分析了深度学习与自动特征识别的新趋势,以及强化学习在计算机视觉中的发展方向。随后,讨论了数据质量与数量、模型复杂性与计算资源以及隐私与安全性等方面的挑战,并提出了相应的解决方案。最后,对人工智能在计算机视觉中的创新应用进行总结,并展望了深度学习和自动特征识别在未来的发展方向。
{URL}: https://link.cnki.net/doi/10.26914/c.cnkihy.2023.025947
{DOI}: 10.26914/c.cnkihy.2023.025947
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于面部与人体行为特征的驾驶员疲劳检测研究
{Author}: 张天策
{Tertiary Author}: 李泰国;孙明明
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 驾驶员疲劳检测;面部倒立摆模型;人体姿态;Stacking多模型融合
{Abstract}: 由驾驶员疲劳驾驶引发的交通事故逐年增加,而准确判断驾驶员的疲劳状态并做出提醒,一定程度上可以减少由驾驶员疲劳引起的交通事故,降低车祸的发生率。现有的疲劳检测方法由于其单一的特征信息,在实际使用场景下的预测能力易受到驾驶员驾驶动作的影响。为了满足疲劳检测对鲁棒性的要求,本文依据驾驶员驾驶时的面部信息,头部姿态及人体姿态,建立多个与疲劳相关的特征表示,将多类型疲劳特征作为输入,通过多模型融合的方法将疲劳特征融合后进行分类,以达到对驾驶员疲劳状态的检测。研究的主要工作如下:(1)提出了一种基于面部倒立摆模型与信息熵的驾驶员疲劳检测方法。首先采用面部关键点检测模型(Practical Facial Landmark Detector,PFLD)提取驾驶员面部108个关键点坐标并计算表示头部姿态的俯仰角(pitch)、偏航角(yaw)、滚动角(roll);以关键点坐标为输入建立面部倒立摆模型并计算其连杆系统的动能和势能;将倒立摆模型的动能,势能以及头部姿态数据作为疲劳特征,利用滑动窗口计算一段时间内的疲劳特征的信息熵值;最后基于长短时记忆网络模型(Long-short Term Memory,LSTM)对信息熵进行分类,实现对驾驶员疲劳状态的分类预测。(2)提出了一种基于人体姿态模型与离散程度的疲劳检测方法。将人体姿态基线网络(Simple Baselines)中的骨干残差网络(Res Net)置换为移动网络(Mobile Net-V1),再进行反卷积处理。从视频序列中提取驾驶员的人体姿态信息,建立并计算多个与疲劳相关的特征,利用滑动窗口计算基于人体姿态疲劳特征的离散程度,通过这种处理将时序因素引入疲劳预测的过程,最后将离散程度作为分类器的输入用来识别驾驶员疲劳状态分类预测。(3)基于改进的堆叠(Stacking)多模型融合分类方法,将面部,头部及人体姿态三类疲劳特征作为输入,进行最终的驾驶员疲劳检测。考虑到各分类器对数据分析与训练原理的差异,在Stacking多模型融合中将多个机器学习算法作为基分类器以发挥各个模型优势。并在融合分类的过程中将数据集加权融合,与单独特征疲劳检测算法相比,多模型融合能够从不同类型的疲劳特征中更加有效地提取驾驶员疲劳状态信息,并在使用场景中比较准确的检测驾驶员疲劳状态。通过模拟驾驶采集的数据集进行验证,在对基于面部与头部姿态信息的疲劳特征分类的准确率达到了94.17%;对基于人体姿态的疲劳特征分类的准确率为95.21%;将所有的疲劳特征作为Stacking多模型融合的输入,最终在结合了多个特征信息后其分类结果提高至97.26%。分类结果的提高进一步说明了本文设计的基于多特征融合的疲劳检测方法可以很好的融合驾驶员的多个疲劳特征信息,提出的方法能够有效地提高对驾驶员疲劳状态的检测水平,具有重要的理论意义和工程应用价值。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2023.001004
{DOI}: 10.27205/d.cnki.gltec.2023.001004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的昆虫检测与识别技术研究
{Author}: 夏明磊
{Tertiary Author}: 宫妍;任迪
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;深度学习;目标检测;卷积神经网络;yolov5s;yolov7
{Abstract}: 昆虫害的存在给食品行业带来了巨大的挑战,尤其在食品加工厂房中,它们不仅破坏了食物的安全性,还给消费者带来了极大的风险。这些挑战不仅仅体现在食物的安全性上,更体现在维护食品原材料的安全性上,以及如何针对性的给出防治意见。随着计算机视觉技术的发展,利用传统神经网络和深度学习方法来实现对各种物体的快速、准确的自动识别。例如,我们通过对采集到的昆虫的图片制作成数据集,并使用计算机视觉中的技术来实现对昆虫的快速、准确的分类。本文主要工作如下;(1)进行硬件的选型和图像采集系统的搭建,通过对比光源,摄像头,镜头,捕蚊灯等硬件的优势和劣势,选择出最适合本文的硬件设施并搭建图像采集系统。(2)本文通过图像采集系统进行数据集的获取,利用图像采集系统可以收集到在食品加工厂房中的昆虫的图片,这些图片不仅可以反映出真实的环境,而且还可以提供实用的信息。使用labelImg来标注这些图片,建立可供深度学习网络训练的数据集。(3)分别使用当前性能较好的深度学习网络yolov5s,yolov7进行训练,对yolov5s,yolov7这俩种模型进行改进,通过分析实验结果选择出比较好的那一个模型。yolov5s模型的改进;通过对yolov5s模型添加CA注意力机制模块旨在增强网络学习特征的表达能力,用BoT3作为主干网络,用来减少参数并提高网络的推理速度,将CIOU损失函数改为SIOU,来增加模型对于小目标的注意力。yolov7模型的改进;将模型的激活函数改为FReLU,解决了激活函数中的空间不敏感问题,使规则(普通)的卷积也具备捕获复杂的视觉布局能力,使模型具备像素级建模的能力。将主干网络替换为CNeB模块来提高模型的推理速度和鲁棒性。(4)通过实验对比证明,改进后的网络模型能更好地识别昆虫,准确率和识别速度得到大幅提升并符合期待值,而且所占的存储空间更小,泛化性能良好,模型的性能、识别速度和准确率不仅优于原始网络,更优于传统机器学习算法。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2023.000527
{DOI}: 10.27787/d.cnki.ghrbs.2023.000527
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的手写数字成绩单识别系统设计
{Author}: 吕传富
{Tertiary Author}: 王强;邓然
{Publisher}: 大连交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像预处理;Conformer;注意力机制;迁移学习;手写数字识别系统
{Abstract}: 在当今的教学过程中,学生纸质版成绩单手写数字的自动识别与存储是学校教学管理规范化建设的关键内容。为了方便教学,教师将学生的部分考核成绩(如课堂平时成绩、实验成绩、论文考核成绩)先手写在纸质成绩单上,然后再录入计算机中转化成电子版。纸质成绩单的自动识别可以有效减少教师的工作量,降低成绩录入出错的概率,提高工作效率。本文针对纸质成绩单手写数字自动识别系统的相关技术进行研究,主要内容包括成绩单图像预处理方法研究、手写数字识别模型设计和成绩单自动识别系统实现三个方面。
(1)针对采集到的纸质成绩单图像的预处理,本文采用边缘检测、倾斜校正和裁剪等方法,解决了图像倾斜、干扰等问题;采用图像增强、轮廓检测、骨架提取与分割和图像形态学处理等方法,解决了手写数字目标区域分割、框线去除、手写数字粘连等问题。
(2)针对手写数字识别问题,提出了基于特征注意力的Conformer手写数字识别模型。在特征学习部分,采用特征专注机制,在卷积得到的特征图展成token向量的过程中,使用可分离卷积和掩码向量,去除无用的特征向量,提高了计算效率。在编码器部分,采用多头稀疏自注意力机制,降低了模型时间复杂度,进一步提高了计算效率。为了提高模型对不同风格手写体数字识别准确率,设计了可再训练模块,能够训练出适用于该用户手写数字风格的模型。
(3)采用基于Python语言的Pytorch深度学习框架、PyQt5工具、My SQL数据库和Web框架设计了纸质成绩单手写数字自动识别系统,该系统具有手写数字自动识别、修改识别结果、直观分数统计展示、学生自主查询平时成绩、模型参数可再训练等功能。
{URL}: https://link.cnki.net/doi/10.26990/d.cnki.gsltc.2023.000250
{DOI}: 10.26990/d.cnki.gsltc.2023.000250
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低光图像增强方法研究
{Author}: 崔恒帅
{Tertiary Author}: 李晋江
{Publisher}: 山东工商学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 低光图像增强;注意力机制;Transformer;卷积神经网络
{Abstract}: 低光图像增强任务一直是计算机视觉领域中的一个重要研究分支。在光线不足和背光条件下拍摄的图像具有低亮度、低对比度的特点,并伴随着不同程度的退化现象(噪声、颜色失衡)。简单的增强图像对比度会使得隐藏的噪声和色彩失真充分暴露,影响人们主观视觉感受和其它应用场景的性能。近年来,许多研究人员从不同的角度展开了对低光图像增强的研究,但是增强的图像往往存在曝光不均、强噪声、颜色失衡以及细节丢失等现象。因此,为解决该问题,本文利用深度学习的方法展开了对低光图像增强任务的相关研究。本文的研究工作分为以下几个部分:(1)提出一种渐进式双分支网络(Progressive Dual-Branch Network,PDBNet)用于低光图像增强。利用反相图和低光图像之间的混合相关性和特征互补性,设计一个协助恢复模块(Assisted Recovery Module,ARM)。通过级联多个协助恢复模块渐进式提取不同尺度下的特征信息。考虑到网络的执行效率和参数量,使用深度可分离卷积和非对称的协助恢复模块提高模型计算效率。为了减少增强图像对比度所带来的退化现象,引入大核注意力(Large Kernel Attention,LKA)块使得网络强调隐藏的低光信息区域,有效抑制噪声和改善颜色失衡的现象。为了有效融合反相图和低光图之间的特征信息,设计注意力融合块(Attention Fusion Block,AFB)。该模块能够有效获取全局特征信息,重新编码通道之间的语义依赖性。最后,设计了融合重建模块(Fusion Reconstruction Module,FRM)进一步细化特征信息,增强网络之间的信息流动性。在公开的低光图像数据集中经过充足的定性和定量实验可知,本文方法比其它先进的低光图像增强方法具有更好的视觉质量和指标评价分数。(2)通过结合卷积神经网络的局部空间感知和Transformer的全局空间感知的优势,提出了双阶段感知增强Transformer(Two-stage Perceptual Enhancement Transformer,TPET)网络用于低光图像增强。该方法总体分为特征提取阶段和细节融合两个阶段。首先,在特征提取阶段,由Transformer组成的编码器进行全局特征提取,并扩大感受野。由于Transformer缺少捕捉局部特征能力,引入感知增强模块(Perception Enhancement Module,PEM)提高局部和全局特征信息交互。其次,在每层对应的编码块和解码块之间,引入特征融合块(Feature Fusion Block,FFB)弥补不同尺度下的特征信息,提高特征的可重用性和增强网络的稳定性。此外,在两个阶段之间,通过引入自校准模块(Self-Calibration Module,SCM)重新分配局部信息特征和提高网络监督能力。在细节融合阶段,为了进一步保留图像的纹理特征细节,设计了细节增强单元(Detail Enhancement Unit,DEU)用于恢复高分辨率的增强图像。通过定性比较和定量分析,在主观视觉效果和客观指标数值上优于其它低光图像增强方法。
{URL}: https://link.cnki.net/doi/10.27903/d.cnki.gsdsg.2023.000047
{DOI}: 10.27903/d.cnki.gsdsg.2023.000047
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的路边垃圾分类系统
{Author}: 党宏社;李俊达;郭琴;张选德;曾浩
{Author Address}: 陕西科技大学电气与控制工程学院;西安西瑞控制技术股份有限公司;陕西科技大学电子信息与人工智能学院;
{Journal}: 传感器与微系统
{Year}: 2023
{Volume}: 42
{Issue}: 06
{Pages}: 82-85+89
{Keywords}: 路边垃圾分类;图像识别;注意力模块
{Abstract}: 基于机器视觉技术设计制作了路边垃圾分类系统，主要包括硬件电路和垃圾识别模型。改进了现有多注意力模块，使模型更轻量化，采用H-Swish激活函数提高识别准确率，然后在公开的华为垃圾分类比赛数据集上进行仿真实验。结果表明：该方法识别准确率达到87.35%。针对自建数据集数据量少、过拟合严重的问题，采用迁移学习的方法，将在华为数据集上训练完成的模型参数进行迁移，在自建数据集上继续训练。最后，将模型部署到树莓派4B上，在制作的实物平台上进行测试。结果表明：该系统平均一次回收需要2 s，可以有效地进行路边垃圾识别分类。
{ISBN/ISSN}: 2096-2436
{Notes}: 23-1537/TN
{URL}: https://link.cnki.net/doi/10.13873/J.1000-9787(2023)06-0082-04
{DOI}: 10.13873/J.1000-9787(2023)06-0082-04
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: YOLO算法在小目标检测应用中的研究与改进
{Author}: 王婉婷
{Tertiary Author}: 王庆
{Publisher}: 齐鲁工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小目标检测;多尺度特征融合;接受域模块;注意力机制
{Abstract}: 作为人工智能领域最有前景的其中一个分支,深度学习能够有效提取图像的深层次抽象特征。结合了深度学习的目标检测算法在计算机视觉领域有极大地突破并且效果显著。然而,目前主流的目标检测算法对于小目标的检测结果却差强人意。由于小目标存在分辨率较小、所携带的信息量少且易受到背景信息干扰等问题,网络在对其进行特征提取时会导致其信息丢失,因此小目标检测是当前计算机视觉领域面临的关键挑战之一。YOLOv5采用的路径聚合网络(Path Aggregation Network,PAN)虽然能有效缓解多尺度目标的语义信息丢失的问题,但仍然无法完全恢复目标已经丢失的空间位置信息。因此,针对以上问题,本以YOLOv5算法为基准,对其网络结构进行优化改进,以提升算法对小目标的灵敏度和检测效果,具体工作如下:针对目标物体尺寸较小的特点,本文以YOLOv5的颈部网络结构为切入点,研究多尺度特征融合结构对小目标检测性能的影响并加以改进。为了保留小目标更多的浅层细节和位置信息,本文在原来的3尺度特征层的基础上额外增加了一层更高分辨率(160×160)的特征融合层,从而有效利用更小目标的空间位置信息和语义信息,提高了模型小目标的检测能力。为解决深度网络在不断卷积和下采样的过程中造成的目标特征信息的丢失问题,本文对接受域模块的原理进行深入研究并进一步改进,通过扩展特征图的感受野来获取原始图像上小目标的语义信息,增强网络对浅层特征图中物体的语义信息的提取能力,从而降低算法对小目标的漏检情况。并将本文改进的E-RFs模块嵌入模型的颈部网络中来查看小目标特征增强的能力变化。针对图像背景复杂的信息对小目标造成干扰的问题,本文在YOLOv5的颈部网络中引入了CBAM注意力机制模块。该模块集成了通道信息和空间信息,使网络能够独立区分不同特征映射通道之间的相关性和有效性。另外,将CBAM模块添加在模型颈部的每个拼接模块后面。通过在特征融合阶段引入注意力机制来增强深层特征信息的表达,从而提升网络检测小目标的能力。本文结合上述三种方法对原始YOLOv5模型进行重构得到提出的用于检测小目标的E-YOLOv5模型。具体地,首先改进多尺度特征融合结构,增加了一个更高分辨率的检测层后,在将改进的E-RFs模块嵌入到该模型合适的位置,最后在颈部网络端引入CBAM注意力机制模块。本文基于Vis Drone-DET2018数据集对E-YOLOv5模型进行了验证实验,实验结果表明,改进模型的m AP值提高了7.05%,验证了本文改进模型的有效性。
{URL}: https://link.cnki.net/doi/10.27278/d.cnki.gsdqc.2023.000615
{DOI}: 10.27278/d.cnki.gsdqc.2023.000615
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer上下文信息融合的医学图像分割算法研究与实现
{Author}: 叶依桐
{Tertiary Author}: 黄小红
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: Transformer;注意力机制;多尺度上下文信息;局部上下文信息
{Abstract}: 近几年来,注意力机制和Transformer架构的出现极大程度地解决了计算机视觉领域的全局上下文信息提取问题。在此背景下,许多基于Transformer架构的医学图像分割算法被提出并应用,然而它们仍存在不能在全局上下文信息提取的优势上,很好地提取并融合面向多尺度特征图和多尺度分割目标的多尺度上下文信息,且充分提取局部上下文信息的问题。针对上述问题,本文提出基于Transformer上下文信息融合的医学图像分割算法——通道分块Transformer模型,解决当前研究中基于Transformer的医学图像分割算法在多尺度上下文信息、局部上下文信息两方面存在的不足。通过通道分块Transformer模型的整体架构,提取和融合面向多尺度特征图的多尺度上下文信息;在模型的编码器和解码器中应用通道分块自注意力模块,提取和融合面向多尺度分割目标的多尺度上下文信息;在通道分块自注意力模块中提出局部增强自注意力模块,进一步提取局部上下文信息。本文在多器官分割数据集和自动心脏诊断挑战数据集两个公开数据集上进行实验,与现有算法相比,本文算法研究在数据集上表现出了较优的性能。基于上述算法,本文设计并实现相应的基于Transformer上下文信息融合的医学图像分割系统,完成数据集选择、参数配置、算法训练、模型预测与性能评估等任务。系统架构自顶向下分为交互层、功能层和数据层。交互层提供系统中各个图形化窗口的控件交互操作和可视化信息展示。功能层承担系统的核心业务逻辑,包括进行算法训练与监听、生成多种分割预测结果和读取历史测试数据进行评估等。数据层整合系统的应用数据,包括医学图像数据集以及训练、预测与评估产生的可持久化数据等。同时,本文通过测试与分析验证了该系统满足对医学图像分割的研究过程与结果进行分析与展示的需求。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.002594
{DOI}: 10.26969/d.cnki.gbydu.2023.002594
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度可分离卷积神经网络的肺炎医学图像分类研究
{Author}: 胡君杰
{Tertiary Author}: 王演
{Publisher}: 大连海事大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;卷积神经网络;医学图像分割;注意力机制;医学图像分类
{Abstract}: 肺炎疾病是常见的呼吸系统疾病,具有高发病率和高致死率的特点。近年来,新冠病毒不断变异,导致肺炎疾病更加难以区分,且仅依靠医生的个人理论和经验使用传统方法进行图像排查,容易造成误诊。当然,传统方法的准确度满足临床需要,但对医务人员的理论和经验具有较高的要求,可胜任的医生数量相对不足,若患者因不能及时治疗出现白肺,会直接威胁生命健康安全。然而,无论是新冠肺炎患者的胸部X光图像还是CT图像都具有一定的特点,若能对其进行正确判读,既可缓解医生巨大阅片压力,又可提高诊断的准确率。基于深度学习的医学图像分类技术不仅是科学研究的重要方向,也是临床医疗中一种关键的辅助诊断方法。基于上述情况,本文对基于卷积神经网络胸部X光和CT图像的肺炎分类方法进行了比较深入的研究。主要研究工作如下:
(1)构建胸部X光和CT图像混合数据集,该数据集共包括健康肺部、普通肺炎和新冠肺炎三种类别,每个类别3000张图像,由胸部X光和CT图像接近1:1比例构成。总数据集为9000张图像,并按照8:2比例随机划分训练集和测试集。
(2)给出一种同时适合胸部X光和CT图像增强方法。由于图像来自不同数据集,且X光和CT图像成像方式不同,为使图像更适合基于卷积神经网络的肺炎图像分类网络,采取图像增强方式,对图像的亮度和对比度进行统一。在峰值信噪比、结构相似性和直方图三个指标下,对比直方图均衡化、Gamma变换、限制对比度自适应直方图均衡化三种图像增强方法,选取限制对比度自适应直方图均衡化为本文图像增强方法。在此基础上,采用几何变换方法进行数据增强。
(3)给出一种基于深度可分离金字塔网络肺部图像分割方法。在U-Net模型上进行改进,使用深度可分离卷积模块降低参数量,通过特征融合模块进行上采样,并借助跳跃结构的注意力模块提取关键特征。给出的方法在Montgomery数据集、JSRT数据集和混合测试集上进行测试,MDice分别可达97.23%、97.61%和99.80%,MMIoU分别可达94.68%、95.35%和99.60%。同时,本章模型的时间复杂度和空间复杂度与其他方法相比均有所下降,验证了本章方法的有效性。
(4)给出一种基于深度可分离卷积神经网络的肺炎图像分类方法。本文分类模型在ConvNeXt网络的基础上进行改进,使用Res-Dense-Inception深度可分离卷积模块进行提取特征和降参,并在网络中融合轴向注意力从宽度轴和高度轴两个方向进行自注意力,提升重要位置权重。最后,本文给出的方法在混合数据集上的准确率可达95.61%,同时在COVID-19 radiography database数据集上进行测试,准确率可达89.69%,验证了其可行性和有效性。
{URL}: https://link.cnki.net/doi/10.26989/d.cnki.gdlhu.2023.000428
{DOI}: 10.26989/d.cnki.gdlhu.2023.000428
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的图像修复研究
{Author}: 罗海银
{Tertiary Author}: 郑钰辉
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像修复;生成对抗网络;多层残差金字塔生成器;多尺度鉴别器;门控特征融合模块
{Abstract}: 进入21世纪后,由于计算机的迅速发展和图像处理工具的不断普及,使得图像修复技术越来越引起人们重视。在计算机视觉和图形环境中,图像修复指恢复破损图像中缺失区域像素,它在计算机视觉任务中发挥着不可替代的作用。图像修复技术不仅是计算机视觉领域中的基础技术之一,也是目前应用较为广泛的技术之一。图像修复任务又可视为一种特殊的图像生成任务,即生成图像的缺失像素,使图像完整真实。生成对抗网络模型具有强大的内容生成能力,研究人员将其应用于图像修复任务中,并取得了令人兴奋的效果。然而,生成对抗网络模型还存在模型不稳定、训练时间长等问题,导致生成图像出现语义不一致的样本内容。且该模型无法获取充分的深层语义信息。此外,现有图像修复方法往往未同时考虑图像的空间信息和语义信息。针对上述不足,本论文主要研究了基于生成对抗网络的图像修复任务,具体工作如下:(1)针对模型不稳定和图像深层语义信息获取不充分问题,提出了一种联合生成对抗网络与残差金字塔的图像修复方法。首先,在生成对抗网络中引入多层残差金字塔生成器,解决因神经网络深度增加而导致的精度降低问题,同时使用了实例归一化用于加速模型训练速度。其次,利用双鉴别器解决图像全局和局部区域语义不一致的不足,消除图像缺失区域边界处的不连续、模糊等问题。最后,运用金字塔L1损失和平均对抗损失,优化模型。在人脸、纹理、建筑、场景四类数据集上的实验表明:该方法不仅在实验数据上优于对比方法,而且可以生成与原图语义较为一致的修复图像。(2)针对模型未同时考虑图像空间信息和语义信息之不足,提出了一种基于门控特征融合的对抗式图像修复方法。首先,提出了两种不同的门控特征融合模块,即通道特征融合模块和空间特征融合模块。其中,通道特征融合模块用于获取不同通道特征图的语义信息;空间特征融合模块用于获取更多的空间、位置信息。其次,提出了一个新的多尺度鉴别器用于鉴别生成图像的全局一致性,主要由四个相同的鉴别器组成,用于判断不同分辨率的生成图像与其对应真实图像的一致性。最后,运用金字塔L1损失、感知损失和平均对抗损失,优化方法模型。在人脸、纹理、建筑、场景四类数据集上的实验表明:该方法在实验数据和可视化结果均优于流行的修复方法,且具有较强的泛化性。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2023.001153
{DOI}: 10.27248/d.cnki.gnjqc.2023.001153
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像去雾技术研究及应用
{Author}: 姚海
{Tertiary Author}: 秦华旺
{Publisher}: 南京信息工程大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像去雾;计算机视觉;多重欠曝光;车牌定位识别
{Abstract}: 雾霾是造成图像视觉模糊的重要原因之一,雾天导致图像的深度信息往往难以获取,因此图像去雾成为计算机视觉中一项极具挑战性的任务,研究识别率高、普适性强的图像去雾技术具有重要的理论意义和实用价值。本文研究了基于多聚焦融合和多重欠曝光的图像去雾技术,取得的主要研究成果如下:(1)针对雾霾图像相较无雾图像亮度更高而导致采集过程易失焦的问题,提出了一种改进的多聚焦融合技术。首先,利用非下采样轮廓波变换(NSCT)将采集的雾霾图像分解为近似子带和详细子带;然后,采用焦点度量优化策略(FMO)和修正拉普拉斯变换(ISML)分别融合近似子带系数和详细子带系数;最后,进行逆NSCT重构得到聚焦雾霾图像。与传统多聚焦图像融合算法相比,本文提出的算法在融合后图像的聚焦效果和客观评价指标上效果更好。(2)针对传统基于先验的去雾算法容易出现局部光晕,以及基于融合的去雾算法缺乏深度信息易导致去除浓雾效果不佳等问题,本文提出了一种结合先验的多重欠曝光图像去雾算法。首先,计算雾霾图像不同区域的透射率,获得更准确的先验信息;然后,对先验图进行伽马校正得到一组多重欠曝光图像集;接着,再利用引导滤波将多重欠曝光图像集分解为全局图和细节图,分别构造全局图图像块的融合权值图和细节图拉普拉斯融合权值图;最后,重构恢复出无霾图像。与常用的去雾算法相比,本文所提算法的去雾效果在视觉呈现上更好,在雾感密度评估器(FADE)等定量指标上也更具优势。(3)针对传统车牌定位识别系统在雾天中容易出现车牌定位不准、识别率低的问题,通过加入雾霾浓度检测模块、图像聚焦模块和图像去雾模块,搭建了雾天车牌定位识别系统。测试结果表明,针对雾天不反光车牌和雾天反光车牌,本文设计的系统较传统系统识别成功率分别提高了17%和32%。
{URL}: https://link.cnki.net/doi/10.27248/d.cnki.gnjqc.2023.001123
{DOI}: 10.27248/d.cnki.gnjqc.2023.001123
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的水下图像增强研究
{Author}: 胡海峰
{Tertiary Author}: 李凤英
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 卷积神经网络;特征金字塔;生成对抗网络;双注意力机制;水下图像增强
{Abstract}: 随着人类的探索领域逐渐触及海洋,各大领域对水下图像的需求也日益增加,然而受到水体中各种因素例如杂质、光的散射等影响,人们往往很难获得干净的图像从而满足实际需求。随着深度学习的快速发展,得益于其优秀的性能和精妙的结构,它在水下图像领域的应用取得了重大突破,充分解决了水下图像退化的问题。对此,基于深度学习方法对水下图像增强任务进行相关研究工作,主要如下:(1)针对传统卷积神经网络对于输入信息一般只关注局部,而不能进行全面关注,从而无法提取充足语义信息的问题,提出一种特征金字塔和卷积注意融合网络。模型以编码-解码器结构作为整体架构,在编码器中,分成4个阶段采用逐步提升层次的方式提取语义信息。在解码器中,参考了FPN,结合跳跃连接,构建类特征金字塔结构,在编码器每个阶段后自顶向下将语义信息进行特征融合,结合低语义信息和高语义信息从而提升模型的综合能力。此外,每个阶段的特征提取中还引入了SE模块,进一步提升了模型的语义提取性能。在数据集UIEB上的实验表明,模型在3个水下图像客观评估指标PSNR、SSIM和UIQM上分别达到了24.33、0.92和3.39,超过作为对比的6个模型如Deep-SESR、FUn IE-GAN、Shallow-UWnet等,很好地解决了水下图像存在的各种问题,同时,在数据集UIEB、EUVP和UFO-120上的消融实验证明了加入注意力机制SE模块的有效性。(2)针对传统Non-local模块在全局信息提取过程中不能充分利用信息,导致模型性能提升不足的问题,提出了一种改进型Non-local模块。与传统的Non-local模块不同,对该模块进行了扩展,模型层数由1变为3,且将卷积核大小分别设计为2、4、8,从而提取并融合多层语义信息。在UIEB数据集上的实验表明,改进型Non-local模块比传统Non-local模块能更充分地利用全局信息,从而提升模型整体性能。(3)针对生成对抗网络普遍存在的语义信息丢失现象,提出一种双注意力融合生成对抗网络。模型整体采用Pix2Pix结构,在生成器中,根据DANet设计了双注意力机制UNet网络,在首部引入了改进型Non-local模块,而在尾部引入了Transformer Encoder模块,从而减少模型训练中产生的语义损失;在鉴别器中,将其建模为Patch GAN结构,通过增强生成器合成图像的能力,从而在两者的对抗训练中提升鉴别器对真假图像的识别能力,最终提升模型的综合能力。在数据集EUVP上的实验中,提出的模型的3个水下图像客观评估指标PSNR、SSIM和UIQM分别达到了25.07、0.86和3.45,而在数据集UFO-120上的相应指标则达到了27.04、0.88和3.39。实验表明,双注意力融合生成对抗网络的性能超过作为对比的最新深度学习模型,从而更好解决了水下图像存在的退化问题。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2023.000093
{DOI}: 10.27049/d.cnki.ggldc.2023.000093
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉与深度学习的高通量种子识别与分割方法研究
{Author}: 梁宁
{Tertiary Author}: 裘正军
{Publisher}: 浙江大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 种子分割;种子计数;表型分析;实例分割;机器视觉;深度学习
{Abstract}: 种子被誉为农业的“芯片”,其品质优劣直接关系到作物产量与品质,因此种子品质检验对选育作物优质品种、保障国家粮食安全具有重要的意义。种子的形态表型参数测量是其品质检验的必要环节,人工测量方法易受测量环境、人员经验、种子差异等因素影响,而机械测量方法适用范围有限、易损伤种子。随着计算机与图像处理技术的快速发展,基于机器视觉的数据测量方法因其易于实现、成本低廉、可靠性较高,逐步取代了人工测量、机械测量等传统方法,特别适用于大规模、强连续、高强度的种子品质检验工作。在高通量的种子品质检验过程中,种子间易形成粘连与重叠问题,导致图像处理方法无法精确测量每粒种子的形态表型参数,准确、快速的粘连与重叠种子识别与分割是测量其形态表型参数的关键难点问题。此外,目前国内外研究多聚焦于实验室、静态环境下的种子识别与分割方法,已无法满足现代农业中作物穗部种子、动态种子品质检验的要求,快速、稳定的穗部种子、动态种子识别与分割是实现多环境下种子品质检验的难点问题。基于机器视觉与深度学习技术,本文针对粘连种子、重叠种子、穗部种子、动态种子识别与分割中存在的关键问题展开了研究,具体研究内容与进展如下:
(1)粘连种子识别与分割方法研究。种子间相互粘连是其高通量品质检验过程中最常见的问题,图像中单粒种子的形态表型参数受粘连现象影响严重,基于机器视觉技术解决粘连问题是准确测量种子形态表型参数的关键。本研究采集了十类常见的谷物、豆类、油料等作物种子的图像,创新性地提出了一种面向多类别、高密度粘连种子的多层次分割算法,由K-means聚类算法、小阈值双层嵌套分水岭算法、凹向分割线检测算法构成,分别对图像中非粘连、简单粘连、复杂粘连的种子进行识别与分割。通过误分割校正处理进一步解决多层次分割算法产生的欠分割与过分割问题,提升粘连种子识别与分割效果。此外,基于多层次分割算法开发了一套种子千粒重测量系统。测试结果显示,十类种子的分割精度均在99%以上,平均分割精度达到99.65%。经过该系统手动校正后,种子分割精度可以提升至100%,十类种子的千粒重测量平均用时1.54s。本研究提出的多层次分割算法与开发的千粒重测量系统准确、高效地实现了粘连种子的识别与分割及其千粒重测量。
(2)重叠种子识别与分割方法研究。扁平状的种子易出现重叠现象,导致种子间产生相互遮挡的问题而无法准确测量种子的形态表型参数,准确、快速的重叠种子识别与分割处理方法对测量扁平状种子形态表型参数具有重要意义。本研究以茄子、番茄和辣椒等扁平状茄科蔬菜种子为研究对象,针对小尺寸、高密度重叠种子标注量巨大的问题,采用“仿真到现实”思想创新性地设计了一种基于多特征随机化的种子图像仿真方法,快速合成了高质量蔬菜种子仿真图像并自动生成标签。此外,本研究基于蔬菜种子特性优化了Mask R-CNN模型结构参数,提高小尺寸、不规则形状蔬菜种子的分割性能。测试结果显示,由蔬菜种子仿真图像训练的Mask R-CNN模型在真实图像上取得优异的实例分割性能,AP@[0.50:0.95]达到0.85以上。并且,Mask R-CNN模型在复原被遮挡茄子、番茄和辣椒种子形状时的AP@[0.50:0.95]也分别达到了0.81、0.79和0.80。本研究设计的基于多特征随机化的种子图像仿真方法结合优化的Mask R-CNN模型解决了高密度重叠种子巨大的标注时间成本问题,并高效、精准地实现了重叠蔬菜种子识别与分割以及被遮挡种子形状复原。
(3)穗部种子原位识别与分割方法研究。作物采前穗部种子的形态表型参数可以直接反映作物与种子的生长状况,而穗部种子多紧密排布生长,存在复杂的粘连与重叠现象,基于机器视觉与深度学习方法实现穗部种子原位识别与分割可以为优化作物生长管理方式提供决策依据。本研究采集了田间环境下灌浆前期、灌浆后期与成熟期的三个品种小麦图像,并通过透视变换与图像尺寸优化等预处理提升数据集图像尺度统一性,保持图像尺寸最优化。本研究利用Mask R-CNN模型对小麦穗部图像进行了实例分割以获得小麦品种与小穗图像信息。此外,基于实例分割结果提取了小麦小穗形状、颜色、纹理等图像特征,通过机器学习模型建立了小穗图像特征与小穗种子数量之间的预测模型。测试结果显示,Mask R-CNN模型对小麦穗部图像进行实例分割时,AP@[0.5:0.95]达到了0.73。以提取的小穗形状、颜色、纹理等52种图像特征作为输入,SVM模型预测小穗种子数量结果最优,测试集准确率为85.5%。基于随机森林的特征选择方法剔除了小穗非重要图像特征,以筛选获得的27个图像特征为输入,SVM模型对小穗种子数量预测的性能接近全特征建模性能。最后,通过小穗种子数量相加测量穗部正面小麦种子总数,测量平均绝对误差低至1.04个,平均绝对百分比误差低至5%。本研究基于Mask R-CNN与SVM模型准确地实现了小麦穗部种子原位识别与分割,并测量了小麦穗部正面种子总数。
(4)动态种子识别与分割方法研究。高通量的生产线上动态种子表型参数测量是现代化种子品质检验发展的必然趋势,生产线上的种子处于运动状态,导致种子间的粘连与重叠现象不断变化,基于深度学习方法动态识别与分割生产线上种子对于实现现代化种子品质检验具有重要意义。本研究采集了5 cm/s、10 cm/s、20 cm/s速度下的大豆、花生、玉米种子视频并分解成种子图像数据集,提出了一种基于标记分水岭算法的种子图像稀疏预标注策略,以自动、快速标注种子轮廓。此外,基于提出的图像预标注策略,开发了种子轮廓标注软件,快速获取准确的测试图像种子轮廓标签,并基于YOLO V8深度学习模型识别与分割大豆、花生、玉米种子图像。测试结果显示,YOLO V8模型对5 cm/s速度下采集的种子图像实例分割效果最佳,边界框预测的AP@[0.50:0.95]高达0.87,而掩膜预测的AP@[0.50:0.95]也达到了0.72以上,单张种子图像实例分割处理平均速度低于20 ms。本研究提出的基于分水岭算法的种子图像稀疏预标注策略结合YOLO V8深度学习模型解决了种子视频帧图像标注任务繁重的问题,并实现了30帧/秒的动态种子识别与分割。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.002673
{DOI}: 10.27461/d.cnki.gzjdx.2023.002673
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向光学影像的显著性目标检测算法研究
{Author}: 宋达微
{Tertiary Author}: 李学龙
{Publisher}: 中国科学院大学(中国科学院西安光学精密机械研究所)
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 显著性感知机理;分层边缘细化;区域注意引导融合;相邻特征互补;差异增强
{Abstract}: 随着智能采集设备的日益成熟,光学影像数据呈现爆炸式增长。面向光学影像的显著性目标检测算法研究旨在利用计算机模拟人类的视觉注意力机制,从而提取出光学影像中人类感兴趣的区域。本文围绕光学影像的显著性感知机理这一科学问题展开研究,从自然场景和更为复杂的遥感场景出发,准确地从光学影像中获取关键信息,同时有效地去除冗余信息,最终提高了影像中单位数据量的显著信息表示能力。因此,本研究可以高效地利用有限的计算资源处理海量的光学影像数据,为计算机视觉高级任务如认知计算、前景提取、语义分割、变化检测等提供有力的帮助。面向光学影像的显著性目标检测算法研究主要包括:自然场景影像的RGB显著性目标检测,自然场景影像的RGB-D显著性目标检测,光学遥感影像的显著性目标检测和显著性区域引导的变化检测。其中存在的关键问题如下:(1)RGB显著性目标检测中的低层特征提取问题;(2)RGB-D显著性目标检测中的跨模态特征利用问题;(3)光学遥感显著性目标检测中的特征表达和约束问题;(4)变化检测中的差异特征增强问题。针对上述关键问题,本文进行了深入研究,主要研究内容总结如下:(1)基于分层边缘细化的RGB显著性目标检测算法。针对低层特征提取不到位,导致边缘细节不准确的问题。本文提出了由粗到细的检测方法,其中,显著性预测网络用于粗略检测显著区域,边缘保持网络用于精确检测显著目标的边缘。此外,与之前的无差别监督策略不同,本文采用了新的一对一分层监督策略来监督网络的不同输出。方法在5个公开的RGB显著性目标检测数据集上进行了评估,实验结果表明本算法有效地提取了低层特征,实现了准确的语义分类和清晰的边缘检测。(2)基于区域注意引导融合的RGB-D显著性目标检测算法。针对RGB特征和深度特征利用不充分,导致不能有效地挖掘跨模态特征互补性的问题。本文提出了区域注意引导的融合方法来融合跨模态特征,从而能够保持准确的显著区域和丰富的细节。引入了一个特征融合注意模块来突出双流高层融合特征的响应通道,并过滤干扰特征。方法在5个公开的RGB-D显著性目标检测数据集上进行了评估,实验结果表明本算法充分地利用了跨模态特征的互补性,实现了准确的显著性目标预测。(3)基于相邻特征互补的光学遥感显著性目标检测算法。针对忽视了光学遥感相邻特征表达和全局约束,导致特征表达和监督约束不充分的问题。本文提出了邻域特征互补的方法来利用相邻层和当前层之间的特征,从而有效地聚集显著性特征。引入了全局约束,从整体上来监督不同尺度的目标生成。方法在2个公开的光学遥感显著性目标检测数据集上进行了评估,实验结果表明本算法有效地利用了相邻层的特征并增加了合适的全局约束,从而可以准确地在复杂背景、多尺度目标等场景下检测出显著目标。(4)基于上下文和内容差异增强的变化检测算法。针对双时图像差异特征的空间关注度不够,导致变化区域检测不完整的问题。本文提出了显著性区域引导内容差异增强的方法来增强双时图像的变化特征,使变化区域更加完整。此外,引入了Transformer模块,可以深入地挖掘双时态特征的上下文关系。方法在2个公开的变化检测数据集上进行了评估,实验结果表明本算法不仅能增强变化区域的内容差异同时充分地利用了全局上下文关系,从而提升了变化检测的性能。
{URL}: https://link.cnki.net/doi/10.27605/d.cnki.gkxgs.2023.000009
{DOI}: 10.27605/d.cnki.gkxgs.2023.000009
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的室外场景深度估计方法研究
{Author}: 陆正阳
{Tertiary Author}: 陈莹
{Publisher}: 江南大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 室外场景深度估计;自监督学习;鲁棒深度估计;帧间监督深度估计
{Abstract}: 单目深度估计(Monocular Depth Estimation,MDE)是机器视觉和三维感知领域的基础问题,是将二维图像转换成三维场景的过程,其目的在于感知和理解真实的三维场景。室外场景中的单目深度估计应用最为广泛,该技术引领了机器人导航、自动驾驶、虚拟现实和增强现实等领域的巨大进步和发展。基于深度学习在视觉领域的飞速发展,低成本视觉设备逐渐替代或是辅助传统测距设备进行场景深度估计,一定程度上解决了高成本和标定复杂的缺陷。宏观世界是由三维欧几里德空间和一维时间轴组成的四维流形。机器视觉通过相机捕捉可见光频段内的二维图像或连续图像序列来感知世界。然而,图像仅能表征某一时刻三维世界投影在二维平面上的有限信息,无法表达时间信息和场景物体与相机的远近关系。因此,对三维场景进行准确的深度估计至关重要。深度估计可以帮助重建精准的立体结构,明确物体之间的位置关系,并辅助机器认知真实世界,进行语义理解,进而作出正确的决策。从监督学习和自监督学习方面,本文分析了现存深度估计方法存在的五个关键问题,对深度估计方法进行了进一步研究:(1)网络模型的信息传递问题;(2)对于复杂室外场景的特征提取同质化问题;(3)室外场景视频中帧间监督机制的低可靠性几何约束问题;(4)室外场景中动态物体运动特性的不确定性问题;(5)特定室外场景中帧内先验信息的自监督问题。本文的主要研究工作和取得的创新成果如下所示:(1)提出基于卷积空间传播机制的监督生成对抗深度估计方法,将卷积空间传播机制引入到生成对抗框架中。尽管深度估计算法提出了多种高效的网络结构,但是依然存在许多问题。针对网络传递中的信息损失和数据集的非均衡数据分布,论文提出基于相关性鉴别器损失函数的生成对抗网络。对于网络中的信息传递损失,通过建立密集连接的网络结构以增加信息传递通路,能够有效地避免网络中产生的信息损失。对于非均衡的数据分布,生成对抗机制建立了一个相对独立的深度图判别器,用以判别深度值的正确性,能够减轻数据不均衡对网络优化的影响。对于深度图边缘模糊问题,改进了卷积空间传播机制,用深度图的关联矩阵进行自迭代,以重建边缘梯度。在KITTI深度数据集上,本方法在Abs Rel达到了0.0720,SqRel达到了0.3250,RMS达到了2.7020,Log RMS达到了0.1160。(2)提出基于频域金字塔网络的鲁棒监督深度估计方法,利用频域信息提升深度估计网络的鲁棒性。由于真实室外场景中图像受大量噪声影响,如高斯噪声、雾气、运动模糊和过度曝光,在大规模标注的室外深度数据集中,深度估计模型难以达到生物视觉系统同样的鲁棒性。针对噪声导致的模型退化问题,通过融合来自多个频带的频域信息,论文构建了一种基于频域分割的监督深度估计金字塔网络。为了提高网络适应多频段输入的能力,本方法采用了一种金字塔网络结构来促进模型融合。其次,为了融合高频域和低频域信息,提出的空间注意力残差细化模块,不仅被用于从色彩域提取特征,而且从多级频段恢复细节信息。最后,为了测试模型在高噪声环境下的鲁棒性,通过模拟不同的噪声性质,构建了一个通用的加噪深度估计数据集。在KITTI深度数据集上,本方法在Abs Rel达到了0.0690,SqRel达到了0.3020,RMS达到了2.6520,Log RMS达到了0.1120。(3)提出基于双向约束的自监督深度估计方法,为帧监督机制下的深度估计网络提供了更加合理的几何约束。帧间监督深度估计方法存在的两个主要问题。一是在相邻帧匹配时,成功匹配的像素区域占比较小。二是在重投影匹配中,建立的几何关系不可靠。针对以上问题,本章对帧间监督方法建立了多重双边一致性约束。首先,对于相邻帧匹配中未被利用的像素问题,论文通过的重渲染网络将深度图重新渲染为真彩色图像,从而与深度估计网络共同建立循环一致性框架。其次,针对建立可靠的帧间约束,本章提出了姿态一致性和深度一致性。姿态一致性约束的目的在于保证相邻帧之间相机运动变换的可逆性,同样深度一致性约束的目的在于保证相邻帧深度的连续性。在KITTI深度数据集上,基于Cityscapes城市场景数据集预训练的本方法在Abs Rel达到了0.0990,SqRel达到了0.7180,RMS达到了4.4080,Log RMS达到了0.1790。(4)提出面向动态物体的联合自监督深度和光流估计方法,将光流图引入帧间监督深度估计方法,以解决动态物体的深度估计问题。在室外场景中,原始的帧间监督深度估计方法存在多种关键问题。一是原始的单向帧间约束可解释性和鲁棒性较低。二是原始的帧间约束没有解决动态物体的问题。针对这些问题,论文将光流信息引入帧间监督深度估计方法,通过联合估计深度图和光流图,以预测场景中物体的相对运动和各个物体的准确深度。因此,通过光流网络进行估计和描述动态物体的运动特性,论文构建了一个面向室外场景的联合自监督深度和光流估计框架,通过约束光度重投影误差和光流重建误差,同时优化光流估计、深度估计和姿态估计网络。在基于光流的不同运动区域分割中,通过非连通区域的判断,对初步估计的光流图进行自适应分割。对于帧间监督的深度估计,独立估计不同的运动区域的深度信息,再合成完整的深度图。此外,相机姿态矩阵和深度图重新合成了光流图,再与初步估计的光流图计算重建误差。在KITTI深度数据集上,基于Cityscapes城市场景数据集预训练的本方法在Abs Rel达到了0.0940,SqRel达到了0.6030,RMS达到了3.8920,Log RMS达到了0.1640。(5)提出水面反射场景的自监督深度估计方法,通过匹配水面反射镜像和真实场景,进行多视角的深度估计。在室外水面场景中,除了帧间的先验信息,帧内水面反射也有大量可靠深度信息。针对水面场景,深度估计任务可以被重新定义为真实场景和反射虚拟镜像的视图匹配任务。论文提出了在水面场景中,通过帧内镜像监督的深度估计方法。首先,为了匹配水面图像和真实图像,引入了由结构相似性(Structural Similarity Index,SSIM)发展而来的光度自适应结构相似性(Photometric Adaptive SSIM)特征匹配度量,以关注局部图像对比度和结构。其次,为了构建易于移植和扩展的通用框架,姿态网络和深度估计网络采用了通用的轻量级基础网络。在水面场景测试帧内监督方法中,本工作创建了虚幻引擎4渲染的大规模水面反射场景数据集。在该水面深度数据集上,本方法在Abs Rel达到了0.1360,SqRel达到了0.9990,RMS达到了5.0100。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2023.000104
{DOI}: 10.27169/d.cnki.gwqgu.2023.000104
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YOLOv5和DeepSort的行人检测与跟踪算法研究
{Author}: 任维民
{Tertiary Author}: 钟国韵
{Publisher}: 东华理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;行人检测;行人跟踪;YOLOv5;DeepSort
{Abstract}: 随着深度学习的不断发展,行人检测和跟踪算法逐渐成为计算机视觉领域中的热门研究方向,广泛应用于自动驾驶、智能监控和智慧交通等重要领域。但是由于图像或视频中的行人尺寸、外观和姿态各不相同,以及行人之间的遮挡情况,使其现有的算法往往无法准确地对小目标行人和遮挡行人进行检测与跟踪,容易产生误检、漏检等问题。因此,本文针对上述问题,提出了基于改进YOLOv5与Deep Sort的行人跟踪与检测算法,主要研究内容如下:
(1)针对小目标行人的检测局限性问题,提出一种基于改进YOLOv5的小目标行人检测算法。首先在YOLOv5中引入CA注意力机制,通过在通道注意力中嵌入位置信息,使模型更加准确地定位与识别行人目标区域;然后在YOLOv5中增加一个小尺度检测层,以便更好地利用浅层网络的语义特征,提高模型对小目标行人的检测能力。实验结果表明,本文提出的YOLOv5＿CA＿MH模型相比于原始YOLOv5模型,在PASCAL VOC 2007数据集上的精确率提升了1.2%,平均精度均值提升0.7%。
(2)针对遮挡行人的检测局限性问题,提出一种基于改进YOLOv5的遮挡行人检测算法。首先在YOLOv5中使用EIOU作为边界框回归损失函数,通过宽高损失减少了预测框与真实框之间的宽高值误差,提高了模型的边界框回归精度和收敛速度;然后在YOLOv5中使用Soft-NMS算法作为后处理算法,通过对大于重叠度阈值的预测框设置一个惩罚函数,提高模型对重叠行人目标区域的识别能力。实验结果表明,本文提出的YOLOv5＿EIOU＿Soft NMS模型相比于原始YOLOv5模型,在PASCAL VOC 2007数据集上的精确率提升了8%,平均精度均值提升了5.2%。
(3)针对实际场景中小目标行人和遮挡行人的跟踪局限性问题,提出一种基于改进YOLOv5与Deep Sort的多目标行人跟踪算法。首先在YOLOv5中同时结合小目标行人和遮挡行人的改进措施,作为Deep Sort算法的行人目标检测器;然后使用Mobile Net V3＿Small替换Deep Sort原有的重识别网络,更好地提取行人目标的外观特征。实验结果表明,本文提出的YOLOv5＿Ours+Deep Sort＿Ours模型相比于YOLOv5+Deep Sort模型,在MOT16数据集上的多目标跟踪准确率提升了1.9%,多目标跟踪精确度提升了0.4%,目标ID切换次数降低了214。并且本文方法相对于现有的目标跟踪算法,仍然具有比较明显的优势,可以很好的应用于行人跟踪任务。
{URL}: https://link.cnki.net/doi/10.27145/d.cnki.ghddc.2023.000008
{DOI}: 10.27145/d.cnki.ghddc.2023.000008
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体姿态估计的运动动作识别与分析
{Author}: 黄凯
{Tertiary Author}: 陈志刚
{Publisher}: 中南大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;动作识别;人体姿态估计;上下文语义;细粒化动作;体育运动训练
{Abstract}: 开放式运动场景下人体动作识别技术普遍存在背景干扰、人物动作密集、运动速度快和肢体遮挡等问题,导致传统识别方法准确率较低、复杂度较高。同时,针对特定运动项目的细粒度动作识别,识别难度更大,要求更高。因此在该场景下如何精准高效地在进行粗、细粒度动作识别,以此对动作进行分析指导是目前亟需解决的难题。本文基于体育运动相关的视频数据集进行人体姿态估计,以人体姿态估计获得的人体骨骼姿态点为基础,使用动作分类方法进行粗、细粒度动作识别,并设计了网球运动动作识别分析系统,该系统能有效地对运动员网球动作进行分析和指导。本文主要的研究内容如下:
(1)在人体姿态估计方面,针对在快速移动、复杂动作、存在大量视觉遮挡的运动动作中,人体姿态点提取失去可靠性、识别准确率大大降低等问题。提出了一种二维人体姿态估计方法PoseCResNet-R,该方法融合多尺度特征进行特征提取,并充分利用动作上下文时空信息,对骨骼姿态点进行修正以提升其准确度。结合开源数据集开发了复杂运动动作数据集,对此数据集视频帧中目标人物进行逐帧姿态标注。PoseCResNet-R在二维人体姿态估计数据集中AP值为0.671,AR值为0.725,对比同类方法,本文提出的方法精度极具竞争力。为了满足人物运动时与场景互动并获得更多人体姿态信息的需求,提出了一种基于Transformer的三维人体姿态估计方法STSPose将二维人体估计中得到的人体姿态点升至三维,并使用了骨长约束最终的三维人体姿态。对比同类方法,该方法在Human3.6M中MPJPE最低为47.3,更适合使用于运动场景下的三维人体姿态估计任务中。
(2)在运动动作识别方面,针对当前动作识别研究主流模型在追求分类准确度时,忽略了模型效率的问题。本文提出了一种动态时空图卷积网络(DLSTM-GCN)的方法,该方法使用识别终止策略网络替换ST-GCN中的TCN网络,根据识别终止策略网络得到的分类结果动态终止模型推理。该方法在复杂运动动作数据集中动作分类平均准确率m AP值为92.3,GFLOPs/V值为25.7,对比同类方法,DLSTM-GCN在得到更好的识别精度的同时大幅度提升了识别效率。
(3)根据对人体姿态估计以及粗细粒度动作分类方法的研究,为了评估所提出的方法在实际应用场景中的效果,开发了一个网球运动动作识别分析系统。该系统能对输入画面中人物的网球动作规范性进行打分评价,提出动作改进意见。系统在得到用户优秀的动作后将其归为标准动作视频纳入模型训练中,并且通过分析所有用户表现优秀的网球动作视频动作共性来精细化动作规则,以此实现基于网球动作规则为运动员日常训练等提供个性化的指导方案。
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2023.001557
{DOI}: 10.27661/d.cnki.gzhnu.2023.001557
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的视网膜血管分割算法研究与应用
{Author}: 吴诗雨
{Tertiary Author}: 卓广平
{Publisher}: 太原师范学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像分割;U-Net神经网络;视网膜血管分割;动静脉分类
{Abstract}: 研究表明,一些常见疾病,如高血压、糖尿病、心血管疾病和甲状腺病变等都将可能引起眼底视网膜血管病变。目前的临床诊断方法是医生对于视网膜血管的结构进行人工检测,并手工对视网膜血管进行分割,以此来获得视网膜血管信息。这种方法效率低下且花费成本较高,对眼科医生进行眼底血管的结构检测带来不便并在效果和时效性方面提出了挑战。因此,本文考虑利用深度学习的相关理论、方法和技术,对眼底视网膜图像分割与动静脉分类展开较为深入的分析和研究,并使其具有较为理想的实用价值。针对上述视网膜血管分割所存在的问题,本文基于改进U-Net神经网络模型对视网膜血管实现分割和动静脉血管分类。U-Net神经网络在医学图像分析领域表现出色,能够对视网膜血管实现有效的分割,本文通过实验分析对比了U-Net神经网络及其衍生网络的分割性能。在血管分割网络中采用了自注意力机制,可以保证神经网络对血管的语义信息更加关注,减少血管外部的信息干扰。网络通过迭代训练能够不断地对分割血管图像进行修正,得到更加准确的分割结果。将这两者结合起来,以此来实现视网膜血管的高度分割。视网膜动静脉血管的分类也是在分割的基础上进行实现,同样是基于U-Net神经网络进行分类。动静脉血管的分类采用了数据增强技术和半监督学习方法来解决动静脉血管标注数据不足的问题。将U-Net神经网络对视网膜血管动脉和静脉进行串联训练,在血管像素级分割的基础上实现了动静脉的分类,同时也保证了动静脉血管分类的准确性。最后,在公开数据集DRIVE和HRF进行了血管分割和动静脉分类实验。结果表明,本文所提出的改进网络在视网膜血管分割和动静脉分类上在准确度和时效性方面都取得了很好的分割性能。此外,在上述研究基础上我们搭建了视网膜血管分割和动静脉分类智能系统,能够更好地帮助医生进行临床分析和诊断。
{URL}: https://link.cnki.net/doi/10.27844/d.cnki.gtysf.2023.000024
{DOI}: 10.27844/d.cnki.gtysf.2023.000024
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于神经网络的伪装目标检测算法研究
{Author}: 李明岩
{Tertiary Author}: 吴川
{Publisher}: 中国科学院大学(中国科学院长春光学精密机械与物理研究所)
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 伪装目标检测;深度学习;边缘特征;特征融合
{Abstract}: 随着深度学习和计算机硬件技术的不断发展,当今图像领域研究的热点由基于传统方法的研究转向了基于深度神经网络的计算机视觉技术。目标检测是计算机视觉领域最基本的问题,其核心任务是对任意一幅给定的图像,采用某种目标识别算法和搜索策略,确定特定目标在图像中的位置和大小。伪装目标检测作为一种特殊的目标检测任务,近些年来逐渐受到国内外学者的重视。伪装目标通常具有模糊边界、混淆着色和低对比度的特点,这使得常规的目标检测算法难以应用于该类检测任务。本文就基于深度神经网络的伪装目标检测算法进行研究,旨在保证模型准确率的同时进一步探究模型的轻量化方法。基于深度神经网络的伪装目标检测技术通过多层卷积堆叠、池化及结合的方式,通过存储海量的权值参数实现特征学习能力,如何设计网络来有效融合不同层级大小的特征、如何有效去除背景噪声又不丢失细节信息、如何实现不同复杂场景下的泛化能力,是该领域所面临的主要挑战。本文在前人所提出的特征提取网络的基础上,设计边缘提取方法,并使用特殊的特征融合策略,充分运用边缘信息来提升特征融合的有效性,实现精细的像素级伪装目标检测算法。本文的主要工作如下:(1)针对现有伪装目标检测方法在边缘表征能力方面不足的问题,本文提出了一个基于图引导边缘感知学习的伪装目标检测网络。与现有的使用基于卷积的骨干网络的方法不同,该方法采用Swin Transformer骨干网络处理输入图像,提取更健壮的特征表示。之后,设计了一组边缘感知模块(EAM),利用浅层特征丰富的细节信息,实现伪装目标边缘先验预测。为了更有效地融合不同尺度的特征,提出了一种边缘聚合模块(FAM),利用图卷积网络动态地学习边缘像素点之间的内在联系,不断调整目标边界处权重,并通过自顶向下的方式逐步精细目标边缘。该方法在4个主流的伪装目标检测数据集上进行广泛的实验,超越了现有的优秀伪装目标检测算法,达到了最优的表现。最后,通过消融实验验证了不同模块的有效性。(2)为了改进上述模型中参数量过大及复杂度过高的问题,实现计算效率和预测精度的平衡,本文提出了一种基于边缘增强和特征融合的伪装目标检测网络。首先,替换了更轻量级的主干网络,以实现最大限度的减少模型参数量;使用不同的层间和层内特征增强策略,弥补主干网络多尺度表征能力不足的问题,并重新设计了边缘提取模块,实现更准确的边缘预测;最后,通过层间注意力机制来实现和图卷积网络相同的提纯功能,避免了冗余的反复采样边缘点的过程,从而大大减少了计算复杂度。大量的实验证明,该方法在大幅降低网络参数量和计算复杂度的同时,达到了优于其他先进算法的精度。最后,本文还在四种伪装目标检测下游应用上进行实验,证明了该方法强大的泛化能力,具备一定的应用前景。
{URL}: https://link.cnki.net/doi/10.27522/d.cnki.gkcgs.2023.000221
{DOI}: 10.27522/d.cnki.gkcgs.2023.000221
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的工厂人员行为识别研究
{Author}: 李昊朋
{Tertiary Author}: 王景成
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 度量学习;身份识别;SlowFast;CBAM;运动仿真流;双流网络;知识蒸馏
{Abstract}: 随着工业时代的快速发展,人们对工厂内的生产效率和生产安全有着越来越高的需求。为了对各生产环节的效率进行评估,同时为了避免意外伤害事故的发生,视频监控和智能分析技术发挥着非常重要的作用。但现有的传统监控系统仍有一些不足,首先传统的视频监控大多是通过人工的方法对各生产环节的人员行为进行判断,不够准确;而且传统的视频监控技术大多是离线运行,无法对人员行为进行精准实时的判断与危险预警。本文针对这两个主要问题,从三个方面入手,对工厂生产过程中的人员行为进行研究与分析。首先提出基于度量学习的身份识别算法。该算法使用残差网络构建数据预测模型,利用该模型从图像中提取人员的特征信息,再通过计算欧式距离,对特征进行比对,以识别人员身份。该算法的好处在于,能够从特征提取和欧式距离判定两个部分来提高识别精度并增强系统的客制化能力。相较于使用多目标追踪算法识别人员身份的一般思路,此算法还能够跨摄像头追踪,在一定程度上避免了身份丢失和身份跳变的问题。最终还分别在Market1501数据集和GENER-Market数据集下,验证了所提身份识别算法的实际可行性。其次,针对工厂内人员行为,提出融合卷积块注意力机制模块(Convolutional Block Attention Module,CBAM)的SlowFast行为识别算法。该算法使用两个平行的卷积神经网络对同一视频段进行处理,分别提取空间特征信息与行为特征信息,再通过侧向连接的方式融合特征,以此识别人员行为。相较于传统行为识别算法,该机制有效地减少了网络的训练时间和推理时间。为了能进一步提高准确性,还使用知识蒸馏的方法,用运动仿真流替代SlowFast慢通道来对网络进行改进,经过在自定义数据集和UCF-101数据集上的对比实验发现,改进后的SlowFast网络与其他方法相比,整体复杂度更低,预测准确率更高。除此之外,工厂内的人员行为往往会渗透着多人因素,因此仅针对单人的行为进行分析是不够的。针对此问题,本文还设计了一种融合了身份检测与行为识别的交互软件。该软件在考虑场景因素变化的情况下,设定了多人行为准则规范、建立了多人行为识别系统,并将深度学习任务转变为层次分析任务。该系统设计了“分散识别,集中分析”结构,与传统的完全基于深度学习的行为识别算法相比,该系统具有一定的灵活性,有更好的检测效果。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000826
{DOI}: 10.27391/d.cnki.gxagu.2023.000826
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 三目视觉测量系统标定技术研究
{Author}: 翟凯玥
{Tertiary Author}: 李静
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视觉检测;三目立体视觉;相机标定;角点检测;畸变参数估计
{Abstract}: 计算机视觉和人工智能的快速发展推动了视觉检测技术的不断升级,使得视觉检测系统能够处理更加复杂和多样化的图像数据,为航天航空遥测、军事侦察、医学成像等众多领域提供强有力的技术支持。在进行靶场试验时,通常需要两台高速摄像机搭建的参数测试系统通过记录弹丸、破片等的飞行过程获得其速度、角度、姿态等信息,对毁伤效能做出评估。传统双目测量系统由于受到基线长度和相机分辨率等限制导致其无法满足对较大场景的测量需求,且对于破片之间重合或遮挡的情况无法得到准确的测量结果。因此对于拥有更大视野和更高测量精度的三目测量系统的研究就显得尤为重要。本文主要对三目视觉测量系统标定技术进行研究,旨在通过优化标定方法,提高测量系统的精度和稳定性。具体研究内容包括:(1)对三目视觉测量系统的三目标定原理和方法进行了深入分析。在单个相机标定完成后,结合双目立体成像模型,运用多视角几何理论计算出相机之间的系统变换矩阵,得到三目系统的系统标定参数。同时引入与三目视觉测量系统相适的畸变模型,通过基于单应性矩阵的畸变参数估计方法近似估算出初始畸变系数,随后利用非线性迭代优化得到更精准的畸变系数。(2)对标定物特征点的检测方法进行了改进。针对棋盘格的特殊对角特性,本文研究了一种基于图像灰度特征的棋盘格内角点检测算法。首先进行了角点预筛选,剔除非角点区域,依据棋盘格角点的灰度特征并结合BW算子得到细化后的内角点集。通过算法在不同光照强度以及噪声环境下的实验证明了算法良好的性能,能满足相机标定的高精度需求。(3)研究了三目系统求解三维坐标的方法。该方法充分利用三台相机之间的内外参数转换关系,联合三组相机对之间的结构参数等信息求解初值,通过转换将三组坐标统一到基准相机坐标系下,通过重心法获得最优估计的被测点坐标。(4)在Matlab实验平台对本文提出的三目视觉测量标定方案进行了测试实验。首先进行了三目测量系统测量精度实验。在3.0m的测试深度下系统的重投影误差平均值为0.12pixel;进行实物测量时,重建长度与真实长度之间的长度相对误差低于2.3%,能达到较高的精度;为验证不同测量深度对系统精度及稳定性的影响进行了被测物分别距基准摄像机1.5m、3m、7m的测试实验;通过与双目测量系统的对比实验证明,本文的三目视觉测量系统相对于传统双目系统具有更高的精度和稳定性,能够准确地提取摄像机的内外参数并校正畸变,同时也验证了本文标定方法的可靠性和有效性,为实际应用中的高精度测量提供基础保障。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000890
{DOI}: 10.27391/d.cnki.gxagu.2023.000890
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的隔震结构动态位移监测方法研究
{Author}: 侯文鹏
{Tertiary Author}: 刘彦辉
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;隔震支座;非接触式位移测量;特征点匹配;目标识别
{Abstract}: 近年来,随着隔震技术的不断发展,隔震支座作为隔震结构的主要的耗能构件已经广泛应用到高层建筑、大型桥梁、核电站等重要工程领域。现如今,结构健康监测已成为延长隔震支座使用寿命较有效的方法,多采用的是传统的接触式位移传感器和加速度传感器进行监测。随着计算机视觉技术的突破性发展,相较于传统的监测方法,其具有非接触、高精度、操作方便等优势,在土木工程领域得到了广泛的应用。但已有的基于计算机视觉的结构位移监测方法,并不完全适用于隔震支座在地震时的位移监测,本文提出了一种基于计算机视觉技术的隔震支座动态位移监测方法,利用消费级摄像头,采用基于SURF特征点的特征光流和基于改进的亚像素角点目标追踪两种特征点匹配算法原理,实现对隔震支座动态位移的实时监测,并通过试验对算法的可行性进行验证。本文主要研究内容和结论有以下几个方面:(1)针对隔震支座的视觉监测特点,即监测设备安装在隔震支座下部连接层,考虑到地震会引起相机识别测量误差,提出了专门的隔震支座位移计算方法。通过在隔震支座结构平面法线垂直方向放置相机,在隔震支座上部和下部结构连接处表面安装人工标志物,利用视觉识别算法可以准确识别到结构表面安装的人工标志物内的目标特征点,进而追踪输出标靶内特征点的像素位移信息,采用比例因子系数转换分别得到隔震支座上部和下部结构的真实位移数据,最终计算两者的相对位移,可以消除误差影响,获得隔震支座的实际位移。(2)提出了一种基于SURF特征点匹配的特征光流算法。通过识别隔震支座上下结构所安装的人工标志物上的SURF特征点,以特征点为跟踪对象,实现对隔震支座的动态位移监测。通过监测隔震支座的振动试验,对该方法进行了验证,得到结论如下:该方法测得的位移时程曲线与激光位移传感计测得的位移时程曲线吻合度较好;两种测量方法在各工况下的水平位移峰值误差均在3%以下;水平位移测量峰值绝对误差不大于0.3mm,满足隔震支座水平位移测量的精度要求,证明该方法监测隔震结构位移具有可行性。(3)针对SURF的特征光流算法的不足,进一步提出了一种基于改进亚像素角点的目标追踪算法,该算法以特征角点为目标识别跟踪对象,可提高特征点识别的准确性以及目标追踪的稳定性,实现对隔震支座位移的监测。通过监测振动台模型结构隔震支座的振动台试验和隔震支座的基本力学性能试验,对该方法进行验证。试验结果表明:该方法在两个试验中测量的水平位移结果与位移计所测得结果吻合度较好;水平位移峰值误差均小于1%;位移峰值绝对误差均不大于1mm;相较于基于SURF的特征光流算法,该方法测得的隔震支座的位移峰值误差均有所降低,精准度和稳定性更高。证明了该方法的可行性和准确性。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.000186
{DOI}: 10.27040/d.cnki.ggzdu.2023.000186
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的苹果分级及表面损伤技术研究
{Author}: 赵树昌
{Tertiary Author}: 庞茂
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像处理;苹果分级;损伤检测
{Abstract}: 我国是苹果的生产大国,但是我国苹果的出口价格偏低,造成这种结果的原因是我国在苹果分级技术方面落后于国际标准。目前我国的苹果分级方式主要是人工式和机械式,两种方法存在很多不足如分级效率低、分级标准不稳定、易对苹果造成损伤。为提高苹果分级技术水平,结合机器视觉技术设计了一种苹果快速分级系统。该系统根据苹果分级实际需求,以苹果大小、形状、体积、重量、有无损伤为标准设计系统的总体方案。与传统苹果分级方式相比,很大程度上提高了分级的准确性、分级速度。主要研究工作如下:首先对光源、相机及镜头进行选型,然后建立基于机器视觉的苹果图像采集系统。对由于光学成像系统在制作工艺上存在损伤、装配时产生误差导致的成像畸变进行描述,采用张正友标定法对畸变进行矫正同时得到相机内外参矩阵使之用于将苹果图像像素尺寸转换为物理尺寸。通过对苹果不同颜色背景下R、G、B各分量的直方图进行研究得到最适合作为图像采集背景的白色。将苹果RGB彩色图像灰度化,使用高斯滤波进行平滑降噪,根据梯度信息,利用Canny边缘算子对苹果边缘进行检测和提取,实现苹果尺寸测量和边缘提取。采用积分法测算苹果体积:将苹果细分为若干薄片,计算出每一个薄片的体积再相加即可得到所求苹果体积,同时研究了所提积分法测算体积的使用范围与准确性。对苹果损伤识别进行研究,采用梯度方向信息熵与SVM支持向量机与深度学习YOLOv5目标检测对苹果损伤进行识别并对比两种方法的准确率,最后选用识别效果更好的YOLOv5模型作为最终的损伤检测方法。根据GB/T10651-2008《鲜苹果》规定,综合苹果大小、形状、体积、重量以及是否存在损伤创建苹果分级模型完成苹果分级。结果表明,积分法测算苹果体积苹果重量误差低于2%,机器视觉苹果分级准确率达96.35%,机器视觉分级系统满足苹果分级需求。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2023.000106
{DOI}: 10.27840/d.cnki.gzjkj.2023.000106
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的堆叠工件识别与定位方法研究
{Author}: 胡刘东
{Tertiary Author}: 于微波
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;堆叠工件;图像处理;深度学习;点云数据处理
{Abstract}: 目前我国已成为世界第二大经济体,但制造业自主创新能力稍显不足,关键核心技术受制于人,因此国家明确提出“中国制造2025”发展战略,打造具有国际竞争力的制造业。工件分拣作为生产制造业的重要环节,面对复杂工况下的自动化水平仍然较低。本文针对非结构环境下堆叠工件的分拣问题,提出了一种基于机器视觉的堆叠工件识别与定位方法,并通过单目结构光视觉系统引导工业机器人抓取视场工件,验证了所提方法的有效性。主要研究工作如下:首先,给出相机模型的建立及相关坐标系的转换,介绍课题工件数据集的制作流程。给出课题工件图像的特殊性,针对图像对比度出现的问题,采用直方图均衡化、限制对比度自适应直方图均衡化方法进行对比实验验证,介绍数据集制作软件的相关信息,完成了堆叠工件数据集的制作。其次,针对传统物体检测算法识别堆叠工件存在的问题,提出基于改进YOLO v3算法的堆叠工件检测方法。引入Inception结构增强特征检测网络的特征提取能力,引用增强型特征金字塔结构提高模型多尺度特征融合能力,利用K-means聚类融合交并比距离重新确定工件锚框,通过实验验证了方法对于堆叠工件识别的有效性。再次,针对纹理特征较少物体的点云数据配准存在的问题,提出一种基于点邻域条件约束的点云配准方法。综合运用内部形态描述子和点云法向量变化来提取特征点,利用点邻域信息加权和邻近点查找双重条件约束方法,提高内部形态描述子的特征提取效率,使用邻域点的加权距离条件约束增强直方图特征描述能力,然后完成物体点云数据的初始配准和精确配准,实验验证了所提方法提升纹理特征较少的工件点云配准精度和效率的有效性。最后,搭建了堆叠工件识别与定位人机交互系统,完成系统的软硬件设计和调试,通过实验验证了本文方法对于非结构环境下堆叠工件识别与定位问题的有效性。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000390
{DOI}: 10.27805/d.cnki.gccgy.2023.000390
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的道路行人检测与跟踪方法研究
{Author}: 陈新悦
{Tertiary Author}: 赵彬;黄志春
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;行人检测;YOLO V4;行人跟踪;DeepSORT
{Abstract}: 随着汽车数量不断增加,道路过度饱和与交通拥堵问题日益突出,交通流量超过道路负荷,道路交通事故屡屡发生。智能辅助驾驶可以根据实时路况辅助驾驶员驾驶,因此成为现在研究热点之一。目前,以深度学习为主的图像处理成为智能辅助驾驶视觉感知研究的主流方向,然而现有的感知算法在复杂的场景下的检测效果仍有较大的提升空间。因此,提升目标的检测精度,成为当前行人检测与跟踪技术亟需解决的问题。为提高驾驶员及道路使用者的安全性,本文针对在交通道路上的行人检测与跟踪算法进行研究。以交通道路上的行人为研究对象,使用摄像头采集行人图像信息,利用上下文信息,通过自适应分配权重的方法,完成行人的检测与跟踪,为辅助驾驶员进行避障提供可靠信息。具体研究内容如下:本文基于YOLO V4的检测框架,提出了一种利用上下文信息,通过扩大感受野和自适应分配权重完成行人检测的方法。首先,通过增强卷积神经网络远程依赖关系建模能力,弥补目标过小不易提取特征的缺点。其次,针对上述步骤造成的计算量增多,检测速度下降的问题,采用了一种能够平衡精度和速度的量化方式,在不降低检测速度的基础上,提高了模型的可靠性。最后,检测网络在COCO数据集上进行实验。实验证明,改进后的检测网络可以很好的识别行人,检测框也更加贴合行人外形。针对相邻帧之间目标运动速度不同,导致同一目标的检测框在不同帧上出现较大变化的缺点,本文使用DeepSORT算法并对其使用的Re ID模型进行优化。针对Re ID的参数量和计算量随神经网络规模的不断扩大而成倍增长的问题,用轻量化网络Shuffle Net V2替代原有的Re ID网络,并对其进行讨论。通过实验结果得出,优化后的算法能够在保持精度的同时,将权重大小缩小至原来的1/18。最后,在智能汽车动态仿真系统中搭建单目视觉行人检测系统,以验证本文算法。利用视景仿真系统采集视频数据,通过相关硬件模块和软件系统的协同工作实现优化后的YOLO V4模型与DeepSORT的融合,最终在显示器中展示实时的行人检测与跟踪结果。实验结果表明,所提出行人检测与跟踪算法在实验中达到了较为理想的效果。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000671
{DOI}: 10.27805/d.cnki.gccgy.2023.000671
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的复杂路况下车道线识别与跟踪方法研究
{Author}: 于国强
{Tertiary Author}: 邱东;杨伽利
{Publisher}: 长春工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;改进概率霍夫变换;无迹卡尔曼滤波;非结构化道路;改进区域生长
{Abstract}: 伴随着科技的不断发展,人们的生活水平也在不断地提升,汽车在我们的生活中已经变得越来越重要,给我们带来了方便的同时,也导致了大量的交通事故的发生。而汽车辅助驾驶系统能有效地避免交通事故的发生,汽车辅助驾驶的前提是车道线的正确识别与跟踪。现实生活中具有复杂多样的行车道路环境,如路面遮挡、车道线缺失、恶劣天气等问题,想要准确地完成车道线检测与跟踪并不容易,车道线的提取主要完成从图像中检测并识别出车道线,并且确定车辆在道路上的安全可行驶区域。而车道线的跟踪正确与否关系到了车辆下一时刻的去向。为此,本文提出了一种基于机器视觉的复杂路况车道线检测与跟踪的方法。主要的研究内容如下:1.针对结构化道路复杂路况下直线车道线检测效果不佳的问题,给出了一种基于累积概率Hough变换算法的车道线检测方法,在Canny算子的45°和135°方向上类比Sobel算子的思想增加了梯度计算模板,并从车道线长度和车道线与横轴的角度两个方面进行约束,结合直线模型检测车道线。通过与传统的Hough变换算法在不同环境下的比较,验证了该算法的鲁棒性和实时性。2.针对改进Hough变换对弯道检测效果不佳的情况,给出了逆透视变换结合滑动窗口弯道检测的算法。首先对道路图像进行弯道判定,对大于设定阈值的车道线判定为曲线,其次将小曲率弯道图像通过逆透视变换转换成俯视图,可以将俯视图中弯道近似成直线,最后结合滑动窗口法以及抛物线模型检测出车道线。3.针对非结构化道路车道线检测图像的环境变量较为复杂且干扰因素过多的问题,根据道路区域具有最大面积的性质,给出了基于最大面积的区域生长算法对道路目标区域进行提取,对面积进行约束从而剔除掉非目标道路区域,保证了道路边界检测的准确性,最后采用SIFT特征提取算法对非结构化道路边界进行特征点提取,用最小二乘法对提取后的特征点拟合。4.针对结构化道路车道线跟踪,由于传统卡尔曼滤波算法对车道线跟踪效果不理想,而无迹变换则能通过很少的采样点数据,计算出转换后数据的分布均值和方差,从而计算协方差矩阵,进而预测下一帧车道线的位置。故在约束累计概率Hough变换的基础上,结合无迹变换提出了基于无迹卡尔曼滤波的车道线跟踪算法。在多种视频序列下运行,并与现有的算法进行对比分析,验证了本文算法的有效性。
{URL}: https://link.cnki.net/doi/10.27805/d.cnki.gccgy.2023.000679
{DOI}: 10.27805/d.cnki.gccgy.2023.000679
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的苗期玉米作物行与行间杂草检测方法研究
{Author}: 刘斯琦
{Tertiary Author}: 苏中滨
{Publisher}: 东北农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 玉米幼苗;作物行;最小二乘法;杂草检测;注意力机制
{Abstract}: 杂草是玉米生长的最大威胁之一,在作物生长的初期若不及时处理会造成很大的损失。传统大面积喷洒除草剂不能针对杂草进行精准喷药,不但造成除草剂的浪费而且容易造成环境污染。随着计算机技术的发展,农业生产技术正朝着精准化方向前进,农业精准化植保设备成为了治理杂草技术中新的发展趋势。玉米作物行与杂草的准确、快速检测是精准农业决策与执行的前提,但在光照变化,杂草外观变化,叶片遮挡与作物行缺株等复杂田间环境下检测作物行与行间杂草仍然是一个很大的挑战。本研究以自然环境下苗期玉米作物行与行间杂草为研究对象,提出了一种基于机器视觉的作物行与行间杂草检测算法,为农业精准化植保设备提供理论依据与技术支持,促进精准农业的发展。本研究主要研究内容如下:(1)开展基于机器视觉技术的作物行与杂草检测方法研究需要前期数据集的制作与预处理,本研究针对苗期玉米作物行与行间杂草图像数据缺乏的问题,制作了作物行与杂草数据集,并根据复杂的田间环境选取合适的图像预处理方法。首先,为了使机器视觉系统适应复杂田间环境,由无人车搭载摄像头从30°斜视方向采集不同光照条件下的苗期玉米作物行RGB图像数据。选取2G-R-B超绿特征因子对RGB图像进行灰度转换,利用最大类间方差法将灰度图像转换为二值图像以降低光照因素对作物行分割效果的影响。对二值图像中的噪声与干扰像素进行分析与去噪测试,选取中值滤波法对二值图像进行去噪,并基于图像形态学处理方法去除二值图中像素面积小于10000像素的连通区域。为了研究杂草检测模型对田间杂草的特征提取能力,本文以自然环境下的玉米田中常见的4种杂草制作了玉米作物行间杂草数据集。数据的采集分为10个阶段,每阶段间隔3-5天,并采集了不同时间段、不同天气的数据以验证杂草检测算法对自然环境的适应性。对采集的杂草数据进行数据增强和数据标记等工作,将该杂草数据集作为目标检测算法的网络输入,为后续的研究提供数据支持。(2)提出了一种基于多感兴趣区域的苗期玉米作物行与导航线检测方法。根据作物的种植特点与二值图像的像素垂直投影曲线规律,将作物行的二值图像均分成10条水平条带,提取每条水平条带中的局部特征并将图像进行拼接来反映全局特征。设定阈值排除残余噪声的干扰,通过对最后一条水平条带的像素垂直投影曲线进行扫描确定作物行特征点与导航线特征点,并根据作物投影曲线波谷确定初始感兴趣区域的位置。根据作物行在图像底部到顶部呈现一种由宽变窄的趋势,将初始感兴趣区域应用到后续的水平条带中,重复作物行特征点与导航线特征点的确定方法,并根据作物投影曲线波谷确定新感兴趣区域的位置。基于改进的最小二乘法对特征点进行直线拟合,拟合直线的参数由样本点与实际点之间的误差的加权平方和来判断。根据作物行图像数据集进行作物行检测性能研究,使用不同方法分别对不同光照条件下的作物行图像进行检测,实验结果显示,本文提出的算法的平均误差为1.52°,准确率达到93.1%,平均运行时间为302.3ms,且效果优于Hough变换方法与最小二乘法。(3)提出了基于YOLOv4-weeds轻量模型的苗期玉米作物行间杂草检测方法。通过将残差结构与注意力机制相结合构建轻量特征提取单元,并设计了一种结合密集连接结构的金字塔池化结构,搭建结合空间注意力机制的多尺度特征融合模块,将提取的多尺度局部特征信息与后续的全局特征进行融合以得到更加完整的图像特征。使用Faster-RCNN、SSD 300和YOLO v3、YOLO v3-tiny和YOLO v4-tiny目标检测模型与本文提出的模型进行对比,并分别选取Res Net-50、VGG16和Dark Net53、Dark Net19和CSPDarknet53-tiny作为模型的主干网络。基于作物行间杂草数据集对不同的目标检测模型与本文提出的模型进行训练、验证与测试,验证本文算法在复杂环境下的杂草检测能力。结果表明,本文提出方法对玉米幼苗及其相关杂草检测的m AP为86.69%,优于其他杂草检测模型,检测速度为57.33f/s,模型大小为34.08MB。此外,将YOLO v4-weeds与YOLO v3、YOLO v3-tiny和YOLO v4-tiny模型在不同天气条件下的杂草的检测性能进行对比,结果表明,本文提出的模型在晴天和雨天的检测m AP分别比检测效果较好的YOLOv3模型高1.3%和0.4%。
{URL}: https://link.cnki.net/doi/10.27010/d.cnki.gdbnu.2023.000460
{DOI}: 10.27010/d.cnki.gdbnu.2023.000460
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的迷彩伪装人体目标检测研究
{Author}: 张伟
{Tertiary Author}: 牛福
{Publisher}: 军事科学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;迷彩伪装;人体目标;多光谱频率;注意力机制;人员搜救
{Abstract}: 随着计算机视觉的快速发展,目标检测技术已经深入到社会生活的方方面面。复杂环境人体目标检测作为计算机视觉领域的核心问题之一,愈发受到人们的广泛关注,并且在军事侦察、人员搜救、智能驾驶以及视频监控等方面有着广阔的应用前景。目前,迷彩伪装人体目标检测已成为复杂环境人体目标检测领域的难点之一,由于迷彩伪装作为军事伪装的主要手段之一,军事伪装目标通常所处环境错综复杂,重叠遮挡情况较为普遍,目标常与周围环境背景融为一体,具备隐蔽性非常高、辨识度非常低的特点,导致搜寻定位人体目标过程中容易出现误检漏检问题。因此,运用人工智能技术快速精确地检测识别军事伪装人员具有重要意义,本文将深度学习技术运用于复杂环境迷彩伪装人体目标检测任务中,主要开展了以下四个方面的工作:1.构建并制作了军事迷彩伪装人员数据集。以互联网上收集到的野外复杂环境下军事迷彩伪装视频为原始素材,通过视频取帧方式截取并筛选含有迷彩伪装人体目标的高清图像,并对图像中的人体目标进行人工标注,以此成功构建了多场景、多方位且高质量的军事迷彩伪装人员数据集,该数据集为本文检测方法的训练与验证奠定了数据基础。2.提出了基于注意力机制的迷彩伪装人体目标检测方法。迷彩伪装人体目标通常所处环境较为复杂,重叠遮挡情况较为普遍,导致算法难以提取到军事伪装目标的丰富特征信息,且随着网络层数加深,特征信息丢失更加严重,进而影响了检测精度。针对以上问题提出了一种基于注意力机制的迷彩伪装人体目标检测算法TC-YOLOv5s,首先在YOLOv5s框架基础上分别在特征提取和特征融合网络末端嵌入了自注意力模块,强化算法对图像全局信息的提取,建模所有像素之间的依赖关系,增强了算法对迷彩伪装人员与环境背景的辨识能力。然后在特征融合网络中添加了卷积注意力模块,进一步加强了算法网络对伪装人员特征的提取能力,削弱对周围环境的关注度,有效提高了算法的抗背景干扰能力。3.提出了基于多光谱频率的迷彩伪装人体目标检测方法。在多战场环境下的迷彩伪装人体目标检测任务中,存在目标与环境背景高度相似、区分度低而导致误检漏检的现象,以及传统注意力模块由于只关注单个频率而容易造成特征信息缺失的问题。针对上述问题提出了一种基于多光谱频率的迷彩伪装人体目标检测算法MBM-YOLOv5s。首先继续选择以YOLOv5s为基础框架,在主干特征提取网络中嵌入了多光谱通道注意力模块,以增强伪装人体目标特征之间的信息传播,提高网络对目标与复杂背景的辨识度。其次,将特征融合网络中原有特征金字塔网络替换为加权双向特征金字塔网络,实现高效的双向跨尺度连接和加权特征融合。最后,采用Mixup数据增强策略模拟重叠遮挡场景,加强网络模型对复杂样本的学习能力,改进算法有效提高了对迷彩伪装人体目标的检测精度。4.设计并搭建了基于深度学习的军事伪装人员检测系统。根据智能化作战、军事侦察制导以及自然灾害人员搜救等现实场景需求,通过Pycharm和Py Qt5等工具进行可视化界面设计和模块功能实现,然后搭载之前实验训练较好的MBMYOLOv5s网络模型成功设计了基于深度学习的军事伪装人员检测系统,并详细介绍了系统开发全过程,最后测试了该系统对多战场环境下军事伪装人员检测识别的准确性和可靠性。综上,本文将深度学习技术应用于复杂环境迷彩伪装人体目标检测任务,并通过算法优化改进和系统检测设计,有效实现了多战场环境下军事迷彩伪装人员的精确检测与识别。
{URL}: https://link.cnki.net/doi/10.27193/d.cnki.gjsky.2023.000133
{DOI}: 10.27193/d.cnki.gjsky.2023.000133
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 除草机器人田间玉米幼苗识别方法研究
{Author}: 梁晋欣
{Tertiary Author}: 李绍稳
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 田间除草机器人;深度学习;目标检测;轮廓提取;计算机视觉
{Abstract}: 田间杂草是玉米苗期生长的主要危害之一,杂草往往生命力顽强,生长繁殖速度快,与玉米幼苗争夺土壤养分、水分和阳光,影响玉米幼苗的生长和发育,导致玉米产量减少和质量下降。随着人工智能技术的不断发展,机器视觉技术在农业智能装备中的应用也越来越广泛。利用机器视觉技术识别玉米幼苗,可以提高除草机器人设备在玉米田间的作业能力。但由于田间环境复杂,目前除草机器人田间工作普遍存在玉米幼苗检测速度慢、识别不精准等问题,工作时容易造成玉米幼苗的误伤和误除。为此,本文提出了一种除草机器人田间玉米幼苗识别方法,主要工作及结论如下:(1)提出了田间玉米幼苗与杂草检测方法。采集自然环境下的玉米幼苗与杂草图像作为样本,对主流目标检测模型以及YOLOv5的各版本模型进行对比,选择并训练了基于YOLOv5s的目标检测模型对田间的玉米植株幼苗与杂草进行检测。模型训练时的精准率、召回率和m AP@0.5分别达到了87.6%、89.4%和90.5%,从实验检测结果图中可以发现,训练后的YOLOv5s模型可以有效检测田间的玉米植株幼苗和杂草。(2)提出了田间玉米植株轮廓提取方法。为了精准定位玉米植株立体轮廓,分别采用HSV颜色空间模型和RGB通道分离提取玉米植株的绿叶和根部特征,在得到绿叶和根部图像后使用F-B算法选取特征点并对特征点进行描述和匹配,利用随机抽样一致性算法剔除错误的匹配点,拼接获得完整玉米植株图像,然后使用Sobel算子提取植株图像轮廓。实验结果表明,F-B算法相比于scale-invariant feature transform(SIFT)、speeded up robust features(SURF)、oriented FAST and rotated BRIEF(ORB)算法在匹配速度、精确度上均有所提升且匹配准确度高于80%,使用Sobel算子提取植株图像轮廓,获得的轮廓清晰度和完整度较好,能够在较快速度和较高的精准度下实现对玉米植株轮廓的提取。(3)设计了田间玉米幼苗识别系统。系统部署在除草机器人上,使用深度相机实时获取视频中的关键帧图像作为输入,导入已经训练完成的玉米杂草检测网络模型进行检测。然后对目标玉米植株幼苗图像进行分割处理,得到目标玉米植株幼苗图像。进一步,对目标玉米植株幼苗图像进行轮廓提取。实际测试验证表明该系统实现了田间玉米幼苗的快速、有效识别。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2023.000118
{DOI}: 10.26919/d.cnki.gannu.2023.000118
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的淡水鱼类图像分类研究
{Author}: 朱宏进
{Tertiary Author}: 赵正伟
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 淡水鱼类识别;注意力机制;卷积神经网络;多尺度特征
{Abstract}: 淡水鱼种类识别是渔业资源开发规划,渔业向自动化、智能化发展的关键步骤,广泛应用于渔业资源管理、淡水鱼养殖、淡水鱼分拣深加工等方面。结合深度学习技术进行淡水鱼类种类识别的研究具有很高的经济价值。因此,本文针对传统淡水鱼类分类方法速度慢、精度低、特征提取困难等问题,开展了基于卷积神经网络的淡水鱼类图像分类研究,主要研究内容如下:(1)构建了模型训练所需的淡水鱼类图像数据集。首先通过手持设备实地拍摄和互联网图片搜集两种方式进行图像的采集,对淡水鱼类图像进行整理分类,共采集整理包含草鱼、鳙鱼、鲫鱼等10类淡水鱼图像。其次针对淡水鱼类图像样本数量不足的情况,对训练数据集进行了垂直翻转、水平旋转一定角度、随机裁剪等一系列数据增强操作,在一定程度上改善了模型训练过拟合的情况。(2)针对淡水鱼类图像复杂、特征提取困难的问题,本文设计了一种改进Xception模型。首先在Xception模型的深度可分离卷积模块中构建层次类连接,将特征图按通道进行分组滤波叠加,以更加细粒度的方式提取多尺度特征,增加每个网络层所提取特征信息的丰富度。同时在深度可分离卷积模块前添加1×1标准卷积层进行通道分组,进一步加强特征图不同通道间的信息交互。通过实验研究了不同分组数对模型分类性能的影响,确定最佳的分组数,并且探讨了不同超参数对分类性能的影响。实验结果表明,该方法能够高精度地对淡水鱼种类进行识别。(3)针对淡水鱼类图像类间相似度高,难以识别的问题,本文提出一种基于Res2Net50的淡水鱼类分类方法。首先将SANet中的SA模块嵌入Res2Net的残差模块中,融合不同组的空间和通道注意力特征信息,实现特征信息的重标定。其次在下采样的残差连接中添加平均池化层,同时使用3个3×3卷积核替代Res2Net模型中第一个卷积层的7×7卷积核,既加强了模型的非线性能力又减少了下采样过程中的特征信息损失。最后选择CELU激活函数提升模型的表达能力。实验结果表明,该方法能够有效地对淡水鱼类进行分类识别。(4)为了解决淡水鱼种类识别过程中速度慢、计算量大的问题,本文提出一种改进GhostNet模型。对GhostNet模型中的SE模块进行改进,探索了模块中通道压缩率和特征融合位置对模型分类性能的影响,使模型可以更好地学习到特征图不同通道的重要性。通过与其他轻量化模型对比,验证了所提方法在保持计算复杂度基本不变的同时,具有更佳的分类性能。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000717
{DOI}: 10.27035/d.cnki.ggxmc.2023.000717
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和图像处理的小麦穗部表型参数获取方法研究
{Author}: 张立夫
{Tertiary Author}: 马慧敏;王琦
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 表型参数;计数;在穗籽粒;深度学习;PyQt
{Abstract}: 小麦是三大粮食作物之一,在保障国家粮食安全方面发挥着极为重要的作用,其穗部表型参数也为小麦精准育种、智能化栽培提供了决策支持。穗粒数能够反映小麦品种的优劣并且能够估产,但传统的小麦穗粒计数主要是以脱粒进行的,破坏了小麦穗部的完整性,不利于小麦穗部表型性状研究;小麦的穗长与穗宽是小麦穗部表型中的重要特征参数,传统的测量方法大多为人工测量,费时费力。因此,本文针对以上问题,基于小麦穗部的图像特征,利用深度学习和图像处理的方法分别对小麦穗部的籽粒数以及小麦的穗长与穗宽进行了获取方法研究,具体工作和研究结果如下:（1）构建小麦穗部数据集并提出一种小麦在穗籽粒计数方法。采集了5个品种的小麦并进行去秆留穗处理,用手机拍摄1500张小麦穗部图像,经过对小麦样本剥离与分析,结合小麦穗部图像,发现小麦穗部中的小穗的透明处的个数能在一定程度上反映小麦穗粒数,依据此规律和小麦品种实际情况提出一种小麦在穗籽粒计数方法:将小麦的小穗分为四类,即1籽粒～4籽粒,对于单株小麦麦穗,分别拍摄正面与背面的图片,找到这两面中四个类别的个数,并与对应类别所代表的籽粒数进行相乘并相加,便得到了单株小麦麦穗的籽粒数,依据此方法完成约11700个小穗的标注。（2）搭建与改进小麦在穗籽粒识别计数模型。构建了YOLO系列四种目标检测网络模型并分别进行训练与对比,然后将综合性能表现相对优秀的YOLOv7模型进行了融合注意力机制的改进,试验结果表明,优化后的YOLOv7-CBAM模型性能表现最好,平均精度m AP达到66.51%,较原YOLOv7模型提升2.92%,将此模型应用于小麦在穗籽粒识别计数,与人工测量的5种麦穗实际籽粒数做对比分析,平均绝对误差为4.82个,平均相对误差为14.42%,为小麦籽粒计数提供了参考。（3）测量小麦穗长与穗宽。引入一种通过参照物的比例系数的方法进行了小麦穗部几何参数测量,采用Open CV对小麦穗部图像进行去噪处理,再用图像形态学操作去除麦穗的麦芒和茎秆,最后通过寻找最小外接矩形来测量麦穗的穗长与穗宽。通过对比人工统计结果,小麦穗长与穗宽的测量平均相对误差分别为1.62%和3.58%,指数回归模型的决定系数R2分别为0.982与0.831,验证了此方法的准确性。（4）设计并实现小麦穗部表型参数获取图形操作界面。利用Py Qt5图形界面工具的Qt Designer与Python语言对小麦穗部表型参数的获取设计了图形操作界面,能够实现单株小麦在穗籽粒计数以及批量计数并保存文件;测量小麦的穗长与穗宽功能也集成在了此图形操作界面之中。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2023.000514
{DOI}: 10.26919/d.cnki.gannu.2023.000514
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的名优茶嫩芽识别与采摘定位方法研究
{Author}: 梁静
{Tertiary Author}: 陈黎卿;秦军卫
{Publisher}: 安徽农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 茶叶采摘;目标检测;改进YOLOv7;图像分割;双目相机
{Abstract}: 作为安徽省地方特产之一,名优茶以其嫩芽肥壮、滋味鲜爽、香气高雅等特点深受消费者喜爱。但目前主流的“一刀切”式机械采茶方式不具有选择性采摘能力,茶叶被采后完整度较差,无法满足制作高品质名优茶的要求,导致茶农经济收入锐减。针对上述问题,本课题基于计算机视觉技术对自然环境下的名优茶嫩芽进行识别和定位研究,进而为后续自动化和智能化采摘设备的研发提供技术支撑。主要研究内容如下:(1)基于拍摄自然环境下不同种类的茶树图片,构建了模型训练和测试数据集。根据不同时间和天气情况,利用双目相机、手机等设备获取名优茶图片,并通过Labelimg软件对图中嫩芽进行标注。通过旋转、平移、添加噪声等方法对数据集进行扩增,以增加模型的训练数据量和多样性,提高模型的泛化能力和鲁棒性。(2)提出一种改进YOLOv7算法,提高了复杂环境下名优茶嫩芽的识别准确率。首先,将原始YOLOv7主干网络替换为Mobile Netv3,然后,引入GAM全局注意力机制和余弦退火学习策略,用以提高模型的准确率和鲁棒性。最后,利用构建的数据集进行对比验证,结果表明:改进YOLOv7的m AP和FPS指标分别为98.07%、83,比原始YOLOv7的m AP值高出1.34%,FPS提高了9.21%,模型大小减少37.5%,同时远优于Fast R-CNN和SSD模型。所提出的改进YOLOv7算法可准确识别名优茶嫩芽,具有实时检测能力,在一定程度上满足智能化采摘要求。(3)在准确识别出嫩芽主体的基础上,本研究分析对比嫩芽主体在RGB、HSV和Ycrcb色彩模型下的特点,发现在RGB颜色空间下名优茶嫩芽图像的彩色图像和背景图像差别显著。为此,提取嫩芽主体G-B通道分量并生成特征图。随后,利用大津法分割特征图中的嫩芽主体,并通过形态学处理求取采摘点的二维坐标。(4)基于双目立体视觉以及改进的立体匹配算法,实现了名优茶嫩芽的采摘点空间定位。基于双目相机成像原理,通过采用张正友标定法获取ZED双目相机的内外参数;在此基础上,利用SGBM算法对名优茶嫩芽图像进行像素点立体匹配,进而计算出视差并获取深度图;然后,运用三角形测距原理将采摘点的二维坐标结合深度图像转化为所需的空间三维坐标。最后通过名优茶嫩芽采摘系统试验得出:ZED双目相机测距与实际距离的相对误差在2%以内,为后续机械臂定位采摘平台的研发提供了较为准确的数据基础。
{URL}: https://link.cnki.net/doi/10.26919/d.cnki.gannu.2023.000674
{DOI}: 10.26919/d.cnki.gannu.2023.000674
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的无人机航拍图像目标检测
{Author}: 周建亭
{Tertiary Author}: 宣士斌
{Publisher}: 广西民族大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;注意力机制;可变形卷积;特征对齐金字塔
{Abstract}: 近年来,无人驾驶航空器(UAV)在遥感和监视应用中的使用大幅增加,对视觉导航、目标检测和路径规划的研究渐成热点。无人机具有多种优势,并在很多领域具有巨大的经济效益。快速发展的深度学习技术在计算机视觉任务上取得了显著的进展,有效减少了经典特征提取算法对人工设计特征的过度依赖,因此,研究基于深度学习技术的无人机航拍图像目标检测方法有着重要的研究意义和经济价值。然而,由于无人机航拍图像存在目标遮挡严重、小目标较多和图像背景复杂等特点,因此设计出高准确率的无人机航拍图像目标检测算法具有较大挑战性。本文利用深度学习来融合遮挡信息、增加低层特征占比并对特征对齐,来应对无人机航拍图像中的这些问题,主要的研究内容和成果如下:(1)提出融合遮挡信息的改进DDETR目标检测算法,以应对目标检测中的遮挡情况下的目标难检出和小目标漏检问题。提出遮挡程度估计模块来辅助模型解决遮挡问题,并设计与遮挡预测任务匹配的遮挡损失函数,通过评估物体的遮挡程度使模型能更好地检测出遮挡严重的目标。设计含更多低层次特征的特征映射模块来提高对中小目标的检测效果。多组实验结果表明,所提方法具有更好的检测效果。(2)提出特征增强与对齐的改进DDETR目标检测算法,以解决复杂背景下小目标检测难的问题。在DDETR算法框架下,利用特征对齐金字塔来学习特征融合时的语义信息偏移量,从而对齐多层次特征,提高模型对小目标的检测能力。针对复杂背景图像中的目标难检测问题,用Swin Transformer代替DDETR模型中的残差网络,以对复杂场景建模,提取具有更丰富语义信息的多层次特征,从而更好利用图像中的语义信息来检测目标。实验表明,特征语义信息增强与对齐的改进DDETR算法具有更高的物体检测准确率,与其他主流方法相比达到了先进水平。
{URL}: https://link.cnki.net/doi/10.27035/d.cnki.ggxmc.2023.000289
{DOI}: 10.27035/d.cnki.ggxmc.2023.000289
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人脸表情识别
{Author}: 马韦暠
{Tertiary Author}: 李泽滔
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人机交互;人脸表情识别;深度学习;轻量化网络;嵌入式平台
{Abstract}: 随着计算机技术和人工智能技术的不断发展,人机交互技术已经成为了信息产业发展的重要研究方向之一。与过去相比,如今的人们对于人机交互技术的要求更高,需要机器人更贴近人的需求,给予合适的反馈。为了达到这个目标,机器人需要具备情感分析的能力,通过与人交流中的情感分析,给出更加贴切的答复。而人脸表情识别技术是情感识别技术中的重点研究领域,目前也是比较热门的话题之一,具有着广泛的应用前景。由于在车辆快速行驶过程中目前缺少的人脸表情识别的移动式设备,本文在对国内外相关文献进行研究的基础上,从以下几个方面进行了研究:首先,对人脸表情识别技术的研究背景和意义、国内外的研究现状、深度学习的基本原理、主要学习框架、算法和代表性模型以及深度学习的评价指标做了比较全面的阐述。其次,本文将RAF-DB数据集导入yolov5系列模型中进行训练,并对结果进行对比分析。通过分析,发现yolov5s虽然训练结果不如其他模型,但是由于其模型量最小,因此可以在轻量化、快速推理和精度之间寻求平衡,适用于对实时性和资源限制有较高要求的应用场景。接着,通过使用ghostnet、mobilenetv3、shufflenet方法分别对yolov5s进行轻量化,通过实验结果采用ghost方法对yolov5s模型进行轻量化处理,通过替换原卷积层,将轻量化后的模型精简至原模型大小的54.6%。最后,本文将轻量化后的yolov5s＿ghost模型进行量化和部署到Linux平台进行验证,证明了人脸表情识别技术的轻量化、量化以及部署的可行性,为今后人脸表情识别技术在移动设备上的应用做出了一定的贡献。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2023.001190
{DOI}: 10.27047/d.cnki.ggudu.2023.001190
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像处理的钢轨表面缺陷检测系统设计
{Author}: 尚宇威
{Tertiary Author}: 白雪飞;董孝卿
{Publisher}: 石家庄铁道大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;钢轨缺陷;图像预处理;注意力机制;YOLOv5网络
{Abstract}: 铁路作为交通运输的大动脉,在经济社会发展中起着至关重要的作用。随着我国铁路运营里程、运行速度、运行密度的不断提高,钢轨表面产生的缺陷会对行车安全造成威胁,甚至危害人民财产和生命安全。目前,已有缺陷检测方法,如人工检测法、电磁涡流检测法和超声波检测都存在检测速度慢的局限性。针对上述问题,本文设计了一种基于图像处理的钢轨表面缺陷检测系统,针对如何提高检测速度并兼顾检测精度这一关键问题,进行了深入研究,具体研究工作如下:(1)设计并搭建了一套硬件系统,通过运动平台带动钢轨水平移动,处于钢轨正上方的工业相机实时拍摄钢轨表面获取钢轨图像,并对硬件系统中涉及的硬件进行分析与选型。(2)针对外界因素干扰会导致图像质量变差的问题,采用图像预处理方法减少外界因素的干扰。首先,通过非线性灰度变换对钢轨图像进行图像增强处理,增强钢轨区域和背景区域对比度。其次,通过维纳滤波对钢轨图像进行图像去模糊处理,较少运动模糊对钢轨缺陷检测的影响。之后,通过双边滤波对钢轨图像进行图像去噪处理,减少噪点对钢轨缺陷检测的影响。最后,采用直线段检测法(Line Segment Detector,LSD)和垂直投影积分对钢轨区域进行提取,自适应提取钢轨边缘坐标信息并进行裁剪,减少了钢轨背景环境的干扰,提高后续图像检测的准确率。(3)针对实际场景中钢轨缺陷在图像中占比较小和轨检车车速较快的问题,本文提出一种缺陷检测方法。首先,对输入图像采用T2T模块处理,用于减少特征图的特征丢失。之后,在主干网络中采用轻量化的Shuffle Net模块,提高网络的检测速度,并在其卷积模块后加入卷积注意模块(Convolutional Block Attention Module,CBAM),CBAM将卷积模块输出的特征图进行权重赋值,在不降低网络检测速度的同时可以提高网络对判别性特征的提取。最后,在用于检测小目标的76×76特征层中加入TPH模块,提高网络对小目标缺陷检测的准确率。通过实验对比分析,本文钢轨缺陷检测方法较YOLOv5和YOLOv4算法的m AP约提高1.1%和5.9%,推理速度约提高20%和27%。(4)根据检测系统总体方案进行软件系统设计,显示可人机交互的软件界面。通过软件系统调用本文预处理算法和检测算法并对运动的钢轨进行实时检测,经过实际测试,本文设计的钢轨缺陷检测系统在准确率、实时性和鲁棒性等方面符合缺陷实时检测的要求。
{URL}: https://link.cnki.net/doi/10.27334/d.cnki.gstdy.2023.001075
{DOI}: 10.27334/d.cnki.gstdy.2023.001075
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的羽毛球收集整理机器人设计与实现
{Author}: 孙佳东
{Tertiary Author}: 朱建军;樊龙龙
{Publisher}: 吉林化工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 羽毛球收集机器人;羽毛球识别;目标定位;羽毛球分拣;注意力机制
{Abstract}: 随着社会经济的迅速发展和人们生活水平的不断提高,越来越多的人投身羽毛球运动来增强身体素质。人们参与羽毛球运动时,利用休息间隙收集散落在场地中的羽毛球会影响训练效率和运动体验,当前羽毛球收集装置均为人工辅助装置;羽毛球的破损程度较大时,会影响球的飞行轨迹,对运动员判断产生影响,因此需要根据球的破损程度进行分拣,挑出破损程度大的球,目前没有相关装置可实现对不同破损程度羽毛球的分拣;羽毛球发球机需要球头朝向一致的球备用,运动员同样青睐于球头朝向一致的球备用,目前同样没有装置可以完成球的整理。针对羽毛球收集、整理、分拣难的问题,本文对羽毛球收集整理机器人的关键技术进行了多方面、系统的研究,主要完成了机器人的识别、定位、分类系统和运动控制系统的设计及硬件平台的搭建,实现了羽毛球的识别定位以及分类整理等功能。本文主要研究内容如下:首先,对羽毛球收集整理机器人要实现的功能进行分析,确定了系统总体设计方案。机器人具备收集场地内散落球、分拣不同破损程度球、整理球的功能;对机器人控制系统包括的模块和执行机构包括的装置进行介绍。对机器人硬件架构的机构及机械结构的功能块进行分析与介绍。其次,针对场地内羽毛球目标较小、羽毛球破损程度不明显,造成目标检测算法的检测精度较差、存在漏检等问题,将计算机视觉技术应用于羽毛球识别、定位与分类上,提出一种基于改进YOLOv5的羽毛球目标检测算法。分析YOLOv5网络结构及整体框架,并根据羽毛球检测识别、分类的实际需求,在YOLOv5主干网络的三个有效特征层后引入CBAM注意力机制,从空间和通道两个方面增强网络对羽毛球关键特征信息的获取,并在自制的羽毛球检测数据集上进行训练,羽毛球检测准确率到达了86.1%,对场地内散落球、导轨上球破损程度具有较高的检测精度,能够满足羽毛球的识别、分类需求。对场地内球的识别结果进行世界坐标系到像素坐标系的转换实现羽毛球定位。最后,为验证羽毛球收集整理机器人的性能,本文设计了基于Arduino的机器人控制系统,采用Arduino IDE作为开发工具,根据机器人预期功能制作了可收集、整理、分拣羽毛球的机器人样机,并对机器人自动找球、区域内地毯式扫描、无损捡球、整理球、根据破损程度分拣球等功能进行测试,测试结果表明机器人各部分功能均可实现;对机器人性能进行测试,其中无损捡球成功率为85%、整理球成功率为87%、根据破损程度分拣球成功率为63%,实验结果表明本文设计的基于视觉的羽毛球收集整理机器人基本达到了预期目标,具有一定的实际应用价值。
{URL}: https://link.cnki.net/doi/10.27911/d.cnki.ghjgx.2023.000078
{DOI}: 10.27911/d.cnki.ghjgx.2023.000078
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的番茄叶片病害识别与分类研究
{Author}: 王哲豪
{Tertiary Author}: 范丽丽
{Publisher}: 武汉轻工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 卷积神经网络;病害识别;目标检测;图像分类;深度学习
{Abstract}: 番茄检疫是保护番茄生长的一个重要过程,保障了务农人员能够快速高效的对番茄病害进行处理,从而保障番茄的产量和品质。番茄病害种类繁多,发病时间不确定,传统的计算机视觉方法对病害识别非常依赖于人工经验,耗费大量的人力物力,提高了生产成本。目前利用深度卷积神经网络对番茄病害识别一般都基于一些背景干净,目标单一的简单数据集,当投入到实际运用中往往达不到好的效果。同时由于深度卷积神经网络的计算量比较大,对设备的要求比较高,不利于务农人员对番茄病害进行实时识别。因此本文提出了一种基于轻量级的目标检测和目标分类相结合的方法,达到在复杂背景,多目标的情况下对番茄病害进行实时识别,具体的研究内容如下:(1)数据集的获取和制作:通过爬虫将互联网上番茄病害的图片批量下载,根据网络上已有的番茄病害数据集进行整合,经过图像增强方式进一步扩充数据集,利用Label Img软件对番茄叶片区域进行一一标注,构建完成番茄叶片识别数据集。(2)构建番茄叶片病害识别网络:本文以YOLO v3为基础构建番茄叶片病害识别模型,利用轻量级网络Mobile Net v2代替Darknet53作为YOLO v3的主干网络,加入了SPP模块,并修改了Anchor box的尺寸。使用番茄叶片识别数据集进行模型训练。实验结果表明本模型改进的有效性,通过与Faster R-CNN,SSD,和YOLO其他系列算法对比,证明了本文改进的YOLO v3＿mobv2＿spp模型具有高精确度和实时性。(3)构建番茄叶片病害分类网络:本文基于轻量级网络Shuffle Net v2,将Shuffle Net v2基本模块中所有3×3的卷积核替换成5×5的卷积核,并在主干分支加入SE模块,在增大感受野和提高模型的表达能力的同时控制了计算量。为了减少训练的时间,本文利用迁移学习冻结部分卷积层,利用目标识别得到的番茄叶片进行训练,在验证了改进模型的有效性之后与同样拥有残差模块的Res Net50,Mobile Net v2,Shuffle Net v2进行对比实验,证明了模型的可靠性和优越性。本文利用深度卷积神经网络完成了对番茄叶片识别和番茄病害分类网络,数据集的制作更加贴近于实际应用,针对于复杂背景,多目标,优化后的网络不仅在准确率上有很大的提升,模型训练时间大大减少。因此本模型可以更好的应用于移动端或嵌入式设备,为务农人员及时识别番茄病害提供了帮助。
{URL}: https://link.cnki.net/doi/10.27776/d.cnki.gwhgy.2023.000242
{DOI}: 10.27776/d.cnki.gwhgy.2023.000242
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的橙幼果识别与病虫害检测方法
{Author}: 李浩
{Tertiary Author}: 刘洁
{Publisher}: 华中农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;橙幼果;数字图像处理;果实损伤检测界面;智慧果园
{Abstract}: 橙是重要的水果品类和经济作物。橙幼果果情信息检测是制定果园管理策略的依据,对现代化、智能化果园生产具有重要意义。针对橙幼果果情自动化、规模化检测需求,本文提出基于深度学习的橙幼果识别和病虫害检测方法,主要研究内容及成果如下:（1）橙幼果背景去除方法研究。针对橙幼果颜色与背景相似导致传统方法识别困难的问题,提出了利用语义分割模型Seg Net去除图像背景以提高识别精度。首先建立橙幼果数据集,然后利用PSPNet、HRNet和Seg Net三种语义分割模型对数据进行处理,结果表明,Seg Net模型分割精度高于PSPNet与HRNet模型,其精确率、召回率、F1分数、MPA值和MIo U值分别为81.72%、82.06%、81.89%、81.17%和81.74%。基于学习率优化策略对Seg Net模型进行改进,改进后的模型的各指标分别为83.35%、84.79%、84.06%、82.34%和82.09%。对比原模型各指标分别提升了1.63%、1.73%、2.17%、1.17%和0.35%。所建模型实现了较高精度的橙幼果背景去除。（2）橙幼果目标识别模型建立。首先制作橙幼果识别数据集,数据集包含1500张经语义分割去除背景的图像,按3:1的比例划分训练集和测试集。对图像进行人工标注,使用数据增强的方法对数据集进行扩充后完成橙幼果数据集的构建。使用Faster-RCNN网络、SSD网络、单阶段检测模型YOLOv5s对橙幼果数据集进行训练,结果表明YOLOv5s模型的综合性能较优,其评价指标精确度、召回率、m AP值和平均识别时间分别为94.24%、96.98%、98.21%和0.067s。基于空洞空间卷积池化金字塔结构对YOLOv5s模型进行改进优化,结果显示改进后的模型即ASPPYOLOv5s的各指标分别为96.82%、96.20%、98.93%和0.071s。经语义分割后的图像的识别率满足目标需求。（3）基于深度学习的橙幼果损伤检测。依据橙幼果的常见损伤,本文构建了1200张由橙炭疽病、橙溃疡病、黑斑病和正常果实按照1:1:1:1的比例组成的数据集,使用未改进的YOLOv5s模型和基于注意力机制改进的YOLOv5s模型对数据集进行训练,结果表明改进过后的模型的平均精确率、平均召回率和平均m AP值均对比YOLOv5s模型分别提升2.5%、1.6%和1.1%。（4）基于Py Qt5平台的橙幼果病虫害检测界面设计。为了能直观显示病虫害橙幼果的信息,本文设计了基于Py Qt5平台的橙幼果病虫害检测界面,该界面能显示图像尺寸大小、果实病虫害类别和灰度值信息。研究结果表明,本文所提橙幼果识别方法和检测界面能够为果园管理提供橙幼果数量和质量信息。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2023.001118
{DOI}: 10.27158/d.cnki.ghznu.2023.001118
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的垃圾图像分类算法研究
{Author}: 玄雪玲
{Tertiary Author}: 郑忠龙
{Publisher}: 浙江师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;神经网络;垃圾图像分类;注意力机制;长尾分布
{Abstract}: 随着城市化进程的不断推进,生态环境正在面临严峻的挑战,具体表现为城市生活垃圾产量剧增,垃圾厂饱和等现象。如何有效治理垃圾成为社会性话题。随着深度学习和人工智能应用到各行各业,采用智能化方法解决垃圾分类问题已经成为一种可能,采用深度学习方法识别垃圾图像并应用于实际生活也成为一个研究热点。
深度学习中众多神经网络层出不穷,不同模型各有各的特点,部分模型存在参数量大,推理速度慢等缺点,所以,本文重点关注参数量较少的轻量化神经网络,扩充了开源的垃圾数据集,提出了两种轻量化模型解决不同的垃圾分类问题,并结合最终的研究成果,设计了垃圾图像分类小程序,给用户提供更方便的服务。
本文的主要研究工作包括:
(1)提出了基于卷积与自注意力机制相融合的轻量化神经网络模型。在MobileViT网络的基础上做出进一步的改进。为了降低模型的参数量,采用分层级联自注意力方法改进了全局表示模块,为了降低模型的计算量,采用深度卷积替换MobileViT Block中的标准卷积。最终得到MobileViT-A神经网络模型。该网络模型比基线模型的参数量降低了2M,计算量降低了200M,但是在自建垃圾数据集上的准确度与基线模型的准确度几乎一致,并且与其他轻量化模型相比,MobileViT-A的准确度更高,参数量更少。
(2)提出了基于改进EfficientNet的长尾分布垃圾图像分类模型。构建了基于EfficientNet的特征提取网络,采用迁移学习的方法训练主干网络用来提取图像特征。为了进一步锁定关键特征信息,在主干网络之后引入一种新的注意力机制,该注意力机制能够关注不同通道,不同空间位置,不同尺度大小的特征。为了解决数据集中存在的长尾分布问题,本文采用Focal Loss损失函数进行分类训练,并通过各项评估指标证明了使用Focal Loss损失函数能够缓解长尾分布现象带来的问题。最终,在自建数据集上达到93.5%的准确度。
(3)开发了基于深度学习的垃圾图像分类小程序。本文使用Flask框架和DCloud云数据库设计了垃圾图像分类小程序。该小程序允许用户拍照或上传垃圾图像,使用神经网络模型对图像进行分类预测,并将预测结果展示给用户。这将有助于人们更方便快速地了解垃圾种类,提高公共意识。
{URL}: https://link.cnki.net/doi/10.27464/d.cnki.gzsfu.2023.000455
{DOI}: 10.27464/d.cnki.gzsfu.2023.000455
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于小型无人机的目标检测与定位
{Author}: 邢麟杰
{Tertiary Author}: 杨扬
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;遥感目标检测;遥感目标定位;小型无人机;单目深度估计;复杂场景
{Abstract}: 近年来,随着无人机技术的进步,应用领域愈发广泛。将无人机遥感与目标检测和定位结合,可在安防、搜救、测量等方面作出更大贡献。因小型无人机本身性能限制,难满足实时性高、检测效果好的算法需求。同时,目标检测与定位需合适观察角度。因此,工程方面应设计无人机智能飞行平台以满足这些要求;算法方面应研究针对无人机遥感图像的目标检测与定位算法。两者相辅相成,具有理论价值和实际意义。过往研究显示,无人机在复杂场景中定位精度难保证。提高目标定位方法精度需在确保计算速度前提下实现。引入性能优异的深度估计方法可有效减少复杂地形带来的定位误差。本文基于深度学习方法,分别研究遥感图像的目标检测与深度估计。为提高目标定位准确度,开展理论分析、方法研究、实验验证等工作。主要研究内容如下:1)无人机智能飞行平台目标检测与定位任务依赖无人机飞行控制。本研究构建了多无人机协同作业平台,实时分析视频图像,并有效反馈飞行状态,从而提高检测与定位精度。多无人机平台靠近真实应用场景,解决实际问题,具有实用价值。2)深度估计方法复杂环境下,传统单目深度估计难找准确稳定参考基准。将预测相对深度转为绝对深度的方法需预定参考平面或尺度,通常以地面为基准。然而,复杂环境中常出现多平面、无平面问题,难找准确参考面。本文研究单目深度估计,设计渐进式深度估计方法,以无人机飞行信息为基准,设计相对深度至绝对深度映射关系。实验显示,本方法有效完成复杂场景下的深度估计任务。3)目标定位方法单目摄像头丢失图像深度信息,需设计适用于装载单目摄像头无人机的定位方法。通过建立摄像头与无人机间几何模型,提出基于单目视觉的目标定位方法。该方法可通过摄像头内外参数标定,获取图像内目标位置信息,进一步转换为无人机坐标系下位置。实验验证发现该方法可有效提高无人机目标定位精度及准确性,尤其在复杂环境中表现更优。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2023.001846
{DOI}: 10.27459/d.cnki.gynfc.2023.001846
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的表格识别系统的研究与实现
{Author}: 黄玮
{Tertiary Author}: 李学庆
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 表格检测;表格结构提取;语义分割;OCR
{Abstract}: 随着信息技术和计算机技术的普及和发展,越来越多的企业选择信息化系统来改善企业管理和业务流程,提高企业效率和竞争力,如何帮助企业实现信息化是一个值得研究的课题。本文以企业信息化系统开发过程中实现文档信息自动化处理为研究素材,研究并实现了基于深度学习的表格识别系统。表格识别系统对于企业信息化有重要的作用,首先它可以帮助企业自动化处理大量的表格数据,例如销售报表、采购订单、财务报表等。传统的手工处理表格数据需要大量的人力和时间成本,还容易出现错误和遗漏。而表格识别系统可以将这些工作自动化,提高企业信息处理的效率和准确性,其次它还能提供更好的数据可视化和分析能力,帮助企业更好地理解和利用数据。通过将表格数据转换成可处理的数字格式,企业可以利用数据分析工具对数据进行更深入的分析和挖掘,发现更多的商业机会和价值。为了实现一个表格识别系统,本文基于采购订单表格数据提出了一种基于深度学习的表格识别方法,可以对表单文档中的表格结构和文本信息进行较为准确的提取和识别。该方法利用深度学习中的目标检测和实例分割模型对文档中的表格区域进行检测和提取,利用语义分割模型对表格区域内的表格线进行提取并重构出表格结构,利用光学字符识别技术对文档中的文本进行检测和识别。本文的主要工作内容如下:首先,本文提出了一个三阶段的表格识别算法,将表格识别分为表格区域检测、表格结构提取、表格文本检测和识别三个阶段。在表格识别的每一个阶段,针对项目实际的需求对功能模块进行了工程化的改进和优化,基于实际的表单文档数据集进行多次实验,分析算法的缺陷,验证算法的准确性和运行效率,为表格识别系统的设计和实现提供了重要的算法支撑。其次,本文基于文本图像超分辨率处理算法对系统中的文本检测和识别模块进行改造,对文本检测提取出的文本框进行超分辨率处理生成高分辨率文本图像再进行文本识别,并使用财务表单数据对现有的文本检测和识别模型进行微调,提升表格识别系统文本检测和识别的准确性。为了增强这部分功能的复用性,本文将文本检测、文本图像超分辨率处理和文本识别组成新的端到端的OCR[1]模块。最后,本文设计并实现了一个表格识别系统,实现了表格图像的上传和表格识别结果的展示和校正修改,并对系统的各个模块进行测试。本文实现的表格识别系统已经应用于某企业的企业信息化系统中,并且取得了良好的应用效果。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.004201
{DOI}: 10.27272/d.cnki.gshdu.2023.004201
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的异常检测方法的研究
{Author}: 汤嘉枫
{Tertiary Author}: 董远
{Publisher}: 北京邮电大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 异常检测;注意力机制;深度学习;无监督学习
{Abstract}: 工业异常检测是工业生产中至关重要的一环,对保障产品质量至关重要。目前大多数工厂仍然采用人工或传统的计算机视觉的方法进行异常检测,在一些复杂场景下难免会存在效率低下、误检漏检等问题。近年来,随着深度学习技术的快速发展,许多研究人员将深度学习引入工业异常检测领域。和传统的计算机视觉方法相比,深度神经网络有着更强的特征提取能力和泛化能力,能适应更复杂的异常检测场景且具有更高的检测精度。因此,本文针对工业异常检测场景中存在的问题开展了基于深度学习技术的异常检测方法研究。具体的研究内容如下:(1)总结归纳了目前主流的工业异常检测算法,对实验中用到的数据集进行了介绍,并结合数据集对主流算法在工业异常检测场景中落地时遇到的困难和挑战进行了讨论。(2)针对工业异常检测场景中异常种类多样,且不同种类异常间差异大的问题,本文尝试在模型中引入注意力机制,并提出了基于注意力机制的特征融合模块。在该特征融合模块中,我们尝试将卷积和注意力机制进行结合,使模型能同时获得两者的优点。我们共提出了四种不同的卷积和注意力机制的结合方式,并通过实验证明,在这四种方式中,同时添加了多头自注意力机制和短路连接的特征融合模块的性能最优。得益于注意力机制更强的拟合能力和泛化能力,我们的模型能更精确的检测出异常区域的位置,在异常区域分割任务中的性能有了 一定的提升。(3)虽然注意力机制的引入提升了模型的性能,但也使得模型训练难度增大,在训练样本较少的情况下难以达到最优性能。针对上述问题,我们受图像分割任务中部分模型的启发,在模型中添加了跨层连接。跨层连接的引入能为模型的解码器提供更丰富的细节信息,并纠正了解码器在重建编码器特征图时产生的偏差。最终,我们提出的基于注意力机制的反向重建模型在MVTec AD数据集上进行测试后,在异常图像分类任务中的AUC-ROC为98.9%,在异常区域分割任务中的AUC-ROC为98.1%,AUC-PRO为94.7%,验证了该方法的有效性。
{URL}: https://link.cnki.net/doi/10.26969/d.cnki.gbydu.2023.000175
{DOI}: 10.26969/d.cnki.gbydu.2023.000175
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的老人异常行为智能检测系统
{Author}: 陈言
{Tertiary Author}: 杨明强
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 异常行为检测;机器视觉;检测与跟踪;YOLOv5;智慧养老
{Abstract}: 随着我国人口结构老龄化程度逐渐加深,养老问题越来越得到人们的广泛关注,尤其是老年人的安全监护问题显得至关重要。目前养老机构中大多采用传统的人工监护手段,耗费大量人力财力,还容易出现监护不及时等问题。随着智慧养老的兴起,基于机器视觉和人工智能的自动异常行为检测系统正逐步发展。本文在调研国内外异常行为检测方法的基础上,构建了一种改进的目标检测与跟踪算法,设计并实现针对养老院老人的三种异常行为检测方法并搭建系统,对于构建安全、智能的养老环境具有一定的现实意义。本文具体的研究工作主要包括以下部分:1.基于YOLOv5目标检测算法,本文提出几点改进。考虑到网络多次下采样所导致的小目标细节特征丢失问题,引入P2小目标检测层解决该问题,由三尺度检测改变为四尺度检测,加强高、低层之间的特征融合,并在不影响大目标检测的情况下有效提高小目标检测的准确率;为了进一步提升目标检测精度,在网络中引入注意力机制模块,分别加入三种注意力机制并对网络性能对比,确定CBAM为最优注意力机制模块;同时模拟场景制作数据集,再利用自制数据集对各模型进行训练和实验对比分析,得出融合小目标检测层和注意力机制的YOLOv5-P2-CBAM模型为最佳模型,准确率及召回率都得到了很好的提升。2.为了获得更准确和更稳定的多目标跟踪结果,基于DeepSORT设计目标跟踪算法,将原算法的目标检测器更换为改进的YOLOv5-P2-CBAM模型,构建YOLOv5-DeepSORT目标跟踪算法。并针对本研究场景利用自制跟踪数据集对深度外观模型进行训练,最后通过实验对比分析,得出本文跟踪算法的准确度和精度都得到了提升。在此基础上,针对举手主动求救、跌倒和久驻不动三种异常行为设计对应的识别算法,实现对三种异常行为的自动检测与报警。3.结合实际需求,利用YOLOv5-DeepSORT算法对目标进行检测和跟踪,在此基础上搭建养老院老人异常行为智能检测及报警系统,实现了实时监控、异常行为检测及报警、报警记录查询等功能。通过实际异常行为视频的测试,对系统的实时性、准确性进行评估,得到系统的检测准确率较高且延时较低,满足日常使用要求,可为老人的安全监护提供有效的技术支持,具有良好的应用前景。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.005574
{DOI}: 10.27272/d.cnki.gshdu.2023.005574
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的飞机维护检查系统算法设计与开发
{Author}: 程野
{Tertiary Author}: 王洪君
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 飞机维护检查;目标检测;深度学习;YOLOv7-tiny;模型轻量化
{Abstract}: 现代社会生活中,飞机作为一种便捷高速的交通工具已经普遍被大众所接受,飞机的飞行安全一直是各方关注的焦点。飞机起飞前的安全检查作为飞行前的最后一道安全保障措施,目前一般是由航空机务维修人员按照规定流程对飞机的重要部位进行目视检查,该项工作不仅需要消耗大量的人力、物力,也会由于维修人员的疏忽而导致误判以及漏判。随着计算机视觉技术的快速发展,该问题可以通过更加智能化的方式解决。本文提出部署在飞机巡检机器人上的飞机安全维护检查系统,该系统能够通过巡检机器人在检查过程中拍摄图片对飞机的各飞行部件进行安全检查,并对故障隐患进行定位以及记录。本文聚焦于目标检测任务,通过对基于YOLOv7-tiny的目标检测算法进行改进和优化进而减小系统对计算资源的占用以及提升系统的识别精度,主要研究内容有如下几个部分。第一部分主要介绍了计算机视觉的研究背景,综述了计算机视觉发展历程、目标检测算法研究现状以及神经网络模型轻量化研究现状,介绍了目前主流单阶段目标检测算法和模型轻量化基本工作原理,并对其中经典的目标检测模型进行了对比分析,最终选择更加适合部署在巡检机器人上的轻量化模型YOLOv7-tiny作为算法模型。第二部分主要是针对飞机维护检测系统需要部署在计算资源受限的巡检机器人上且存在检测目标尺寸多变、检测困难的问题,本文提出将GhostNet网络和深度可分离卷积与YOLOv7-tiny算法相结合,得到一种轻量化的YOLOGDW改进模型,该模型在整体框架基本不变的情况下,减少模型参数量,实现算法轻量化的目标,从而更适合部署在巡检机器人上执行目标检测任务;与此同时,为了提高改进模型的准确率,本文提出了使用Coordinate Attention结构和SPD结构对YOLOGDW模型进行优化改进,提高YOLOGDW模型骨干网络的特征提取能力,从而提高模型的检测精度。通过实验结果得知,改进后的SCAYOLOGDW模型在飞机起飞前安全检查数据集上的准确率达到98.0%,相比于YOLOv7-tiny模型提高了 1.5%,在参数量上,YOLOv7-tiny模型是SCAYOLOGDW模型的1.45倍,满足了模型轻量化的需求。第三部分本文根据改进的SCAYOLOGDW算法设计了飞机起飞前安全维护检查系统,并对系统内各模块的功能以及系统的性能进行了测试。实验结果表明,系统的各模块都能够正确地运行,在经过对目标检测算法的改进和优化后,系统的运行效率有比较明显的提升。系统的单帧耗时约为21.42ms,每秒可测试46到47帧,能够满足实时性的要求。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006443
{DOI}: 10.27272/d.cnki.gshdu.2023.006443
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于3D结构光视觉的机器人焊接导引系统研究
{Author}: 余明岭
{Tertiary Author}: 刘霞
{Publisher}: 东北石油大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;点云处理;焊缝特征提取;图像处理
{Abstract}: 目前,大部分的焊接机器人仍采用示教再现和离线编程的工作模式,生产效率较低且适应性较差,难以满足复杂的焊接作业要求。因此,利用视觉传感器获取焊接工件三维点云数据,实现焊缝的准确识别与定位、焊接轨迹规划,对焊接机器人自动化、智能化具有重要意义。以此为背景,本文对基于3D结构光视觉的机器人焊接导引系统进行了研究,主要研究内容如下:首先,完成了硬件选型及实验平台搭建,设计系统总体方案。选择视觉传感器与机器人以眼在手上(Eye-in-Hand)的方式安装,视觉传感器主要任务式获取工件三维点云信息,工业机器人作为拍摄动作和焊接动作的执行主体,结合由工业计算机和机器人控制柜组成的控制系统,作为数据处理与机器人控制的核心。其次,由于在焊接实际现场中背景复杂、且存在许多不可控干扰,视觉传感器获得的数据往往存在许多干扰数据,需要进行预处理以便于后续的焊缝特征提取。利用统计滤波器消除离群噪声后,使用随机一致性(RANSAC)的方法拟合得到焊接工件主平面法向量,随后对原始点云进行方向校正,最后根据Z轴向上分布情况将工件背景去除。然后,提出了一种基于点云切片投影的特征提取方法,提取出焊缝的特征点。根据点云最小有向包围盒确定一组等间距切片序列后,将切片中的点云数据由三维空间投影到二维图像中。通过最大距离法粗提取与直线求法精提取相结合提取得到焊缝特征点,最后拟合特征点序列求得焊缝谷线特征并与工件点云边缘求交点得到焊缝端点。最后,针对对接V型坡口焊缝,以相邻两组切片数据中提取得到的焊缝坡口特征点为基础,进行了焊接姿态的规划,并且对焊缝点序列实现了插补优化,获取具有良好平滑性的焊接轨迹。
{URL}: https://link.cnki.net/doi/10.26995/d.cnki.gdqsc.2023.000191
{DOI}: 10.26995/d.cnki.gdqsc.2023.000191
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向不完美数据的图像分割方法研究
{Author}: 丁健
{Tertiary Author}: 夏桂松
{Publisher}: 武汉大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 图像分割;无监督学习;零样本学习;鲁棒性;计算机视觉
{Abstract}: 在视觉感知中,为了从原始像素得到有意义的概念,需要将遵循一定规律的视觉单元组合在一起,从而以整体形式进行感知。将图像中像素进行分组得到不相交区域的过程被称为图像分割。从计算机视觉研究角度来看,图像分割是非常具有挑战性的一个核心问题,是多个视觉任务的基础。从应用角度来看,图像分割在机器人抓取、照片编辑、自动驾驶、医学诊断、指纹识别、遥感测绘等众多领域具有重要的应用价值。早期的图像分割算法主要依据格式塔中的相似性和相近性等规则,在无标注或少量标注的情况下进行类别无关的图像分割。随着数据集的发展和深度学习的到来,当前基于深度有监督学习的模型极大地提高了图像分割模型的性能,并可以预测语义类别。在多个公开数据集上,这些模型的性能与人类的能力相当,但它们严重依赖大规模像素级的语义类别标注,同时无法泛化到未知类别和未知的数据分布上。因此,在训练数据缺少标注样本、测试类别样本和测试数据分布样本的情况下,当前模型预测表现较差。针对以上训练数据不完美的问题,本文相应的研究了面向分割的无监督预训练、零样本语义分割和域泛化语义分割。本文的主要工作与贡献如下:(1)设计了一种面向图像分割任务的无监督对比学习预训练算法(Deeply Unsupervised Patch Re-ID,DUPR)。为解决全局级无监督对比学习预训练任务与图像分割下游任务之间的差异问题,本论文将无监督对比学习从全局级扩展至局部级。具体地,DUPR将两个视图中对应的局部区域(即切片)视为正样本对,其他图像的切片作为负样本,以对比学习的方式学习两个视图中的对应关系。通过这种方式预训练的模型,能产生具有局部区分性的特征,用于图像分割相关的下游任务。同时,因为图像分割任务通常需要多尺度图进行预测,本论文将无监督损失加到多尺度特征图上,以更好地与图像分割模型结构对齐。大量实验表明,在与图像分割相关的下游任务中,DUPR优于最先进的无监督预训练模型,甚至优于Image Net分类的有监督预训练模型。(2)提出了一种基于聚类和分类解耦的零样本语义分割框架,将零样本语义分割解耦为两个子任务:1)一个与类别无关的聚类任务,对像素进行分组;2)一个整体区域的零样本分类任务。前一个任务不涉及类别信息,可以直接对未见过的类别像素进行分组得到类别无关的掩膜区域。后一个任务进行区域级别的分类,由于符合格式塔整体感知过程,可以更好地利用大规模视觉-语言预训练模型(例如CLIP)。基于解耦框架,本论文用Transformer结构实现了一个简单而有效的零样本语义分割模型(Zero-Shot Semantic Segmentation Model with Transformer,ZegFormer),在零样本语义分割测试基准上大幅度超过了以前的方法。由于之前的零样本语义分割测试基准类别数量过少(最多171类),本论文基于语义分割数据集ADE20K-Full额外提出了一个包含847个类别的新测试基准,在这个新测试基准上,ZegFormer的表现接近有监督分割模型。(3)提出了一种基于层次化聚类的语义分割模型(Hierarchical Grouping Transformer for Domain Generalized Semantic Segmentation,HGFormer),通过显式地对像素进行分组,先形成部分级的掩膜,然后再形成整体级的掩膜。与逐像素分类模型相比,HGFormer采用掩膜分类,借助整体感知形式获得更具鲁棒性的分类预测;而与非层次化聚类的掩膜分类模型相比,HGFormer能够得到更鲁棒的高质量掩膜预测。此外,不同尺度的掩膜都可以进行分类,从而得到语义分割结果。接着,将两种尺度的掩膜分类结果相结合,以获得更具鲁棒性的语义分割结果。本论文通过使用七个公共语义分割数据集,构建了多个跨数据分布的图像语义分割实验设置。实验结果表明,层次化聚类模型HGFormer产生的语义分割结果比逐像素分类模型和非层次化聚类的掩膜分类模型更具鲁棒性。本文致力于解决深度学习图像分割模型的缺陷,研究涵盖了无监督预训练、零样本语义分割和域泛化语义分割,并在这些领域上实现了重要的突破。这些成果显著减少了训练过程中所需的人工标注数据量,并提高了图像分割模型在未知类别和数据分布上的泛化性能,对图像分割模型在实际应用中的推广具有积极作用。此外,图像分割作为计算机视觉的基础任务之一,本论文提出的模型和算法对其他计算机视觉任务的算法研究亦具有借鉴意义。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2023.000244
{DOI}: 10.27379/d.cnki.gwhdu.2023.000244
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的机械臂自动卸货系统设计与实现
{Author}: 褚石磊
{Tertiary Author}: 张伟
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 自动卸货;机械臂运动规划;目标检测;系统设计
{Abstract}: 随着计算机技术和机器人技术的发展,自动化操作在工厂中越来越常见。尽管存在简单的机械自动化设备和工业机器人,已经可以替代人工进行一些流水线工作,但机器人的灵活性和适应性依然不足,尤其在复杂的场景下,机器人很难取代人类操作,自动卸货就是物流仓储中最具挑战性的任务之一。自动卸货系统的实现可以降低人工的工作负荷,提高效率,避免卸货中伤人事故的发生。自动卸货任务中的困难在于:首先,集装箱和拖车中的货物呈“弱结构化”摆放,使目标的识别、抓取和搬运都很困难;其次,不当的卸货顺序可能导致效率低下,甚至货物的倒塌;另外,在高复杂度的空间中,机械臂的运动规划问题也是实现自动卸货的难点之一。考虑到自动卸货任务的需求和难点,本文进行了一系列相关研究。首先,提出了一种基于安全移动走廊的机械臂运动规划算法。该算法使用路径规划和空间扩充算法建立安全移动走廊,并使用安全移动走廊的约束条件和凸优化算法,实现了无碰撞的平滑轨迹。其次,还提出了一种基于强化学习和teacher-student模型的机械臂运动规划算法。该算法在训练时引入了特权信息和对比学习损失,不仅实现了更快的训练速度,还得到了更好的运动规划效果。最后,设计了一种数据集生成方法,用于堆叠货物检测器的训练。卸货序列生成算法使用基于启发信息的序列生成算法,最终得到的机械臂每次需要处理的货物位置。基于上述算法,实现了一个基于机器视觉的自动卸货系统。该系统包括三个模块:基于YOLOv5的货物分割处理模块、基于启发式算法的卸货序列生成模块和运动规划模块。该系统中包含了鲁棒性更强的目标检测算法、更加高效的卸货算法和安全性更高的运动规划算法。该系统是一套完整的自动卸货系统,可以端到端地进行部署和使用。为了验证系统的可行性并测试其效率,本文在CoppeliaSim虚拟环境和真实机器人平台上分别进行了部署和测试。真实机器人平台使用的是UR5六自由度机械臂,采用ROS进行控制。实验表明,本系统具有稳定且高效的自动卸货能力,整个系统的卸货成功率达到了 98.76%,每小时卸货速度可达196.7件。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.005583
{DOI}: 10.27272/d.cnki.gshdu.2023.005583
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的机器人智能抓取系统的设计与实现
{Author}: 李世杰
{Tertiary Author}: 左治江
{Publisher}: 江汉大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;深度学习;机器人抓取系统;云平台
{Abstract}: 新零售的普及促进智能超市的发展,为减轻智能超市补货人员的负担,针对当前协助补货类机器人无法直接代替工作人员进行超市补货,本文构建基于计算机视觉的机器人抓取系统:对目标检测,目标定位,机器人通信与控制等关键技术进行系统性研究;同时考虑到超市从业者普遍缺乏视觉相关知识,为降低计算机视觉的应用门槛,本文研发“深度学习云平台”供工作人员在线训练定制深度学习模型。本文主要工作如下:首先,进行机器人智能抓取系统的构建。基于超市工作场景,设计本文机器人抓取系统的逻辑架构。系统逻辑上分为云端,控制端与表现端,云端供用户在线定制训练深度学习模型,训练完成后部署模型到控制端;控制端驱动机器人抓取和放置货物,这些行为体现在表现端。同时构建软硬件系统,依据场景需求,针对性开展相关硬件的选型研究,并研究机器人通信模块与控制模块的设计与实现,构建软件系统。其次,进行目标检测与定位研究。目标检测方面:引入基于深度学习的目标检测算法,针对深度学习训练需要大量数据集的问题,进制数据增强研究以提高少量数据标注量下模型的表现;针对实际应用中嵌入式机器人系统算力不足难以运行深度学习模型的问题,对深度学习目标检测算法在检测精度与检测速度两方面进行对比研究,选取YOLOv3算法进行两种不同配置下算法模型的训练,并部署到嵌入式机器人系统中。目标定位方面:研究相机标定理论,并对图像中像素点到真实世界中一点的映射关系进行研究,得到机器人视觉系统对目标物体的定位规律,并设计实验验证了其可行性。之后,研发一套深度学习在线训练云平台,使得超市从业者在无需掌握相关视觉知识的情况下一键式在线进行深度学习模型定制。分析云平台系统的功能性与非功能性需求,沿用Web系统设计原理进行云平台整体架构的设计,逐一研发云平台前端与服务端系统各个功能模块,构建一个易于上手、安全稳定的深度学习在线训练云平台。最后,进行综合实验设计与验证。模拟真实超市环境并在上货与补货不同的应用场景中进行目标检测与机器人抓取的性能实验。使用YOLOv3-tiny算法进行目标检测精度达到91.68%,FPS在嵌入式平台中为1.2左右;机器人上货与补货平均成功率分别达91.5%,89.1%,上货与补货时间分别达到4.23秒,5.77秒;模拟多用户在线对深度学习云平台性能进行测试,系统响应时间在1000毫秒之内,表明系统具备良好性能。
{URL}: https://link.cnki.net/doi/10.27800/d.cnki.gjhdx.2023.000154
{DOI}: 10.27800/d.cnki.gjhdx.2023.000154
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的激光打标定位及质量检测
{Author}: 单涛
{Tertiary Author}: 王东兴
{Publisher}: 烟台大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;激光打标定位;图像矫正;缺陷识别
{Abstract}: 激光打标技术是激光加工领域中除激光切割技术外使用最为广泛的一项技术,在激光打标机的使用过程中,需要人工使用夹具对工件进行定位及人工质量检测。人工定位、质检存在工人劳动强度大、成本高、产品质量受个人主观影响大等缺点。随着机器视觉技术在工业生产中应用增多,使用机器视觉技术代替人工视觉进行定位及检测能够有效的提高生产效率和产品质量。本论文简单介绍了机器视觉技术及激光打标技术,调研分析了目前国内外机器视觉定位技术和字符缺陷检测技术的现状。根据实际应用需求对系统软硬件进行设计选型。将相机倾斜式布置,考虑到相机倾斜视角下工件厚度对图像处理工作造成的影响,提出了通过选择光源形状以及光源布置位置的方式避免工件厚度在图像处理过程中的影响,扩大打标机的使用范围。研究分析了图像处理技术中的图像矫正算法,考虑到倾斜视角下成像近大远小存在畸变,对工件定位及质量检测造成阻碍,结合常用的图像处理算法,将灭点透视校正算法与图像透视变换矩阵结合提出一种改进的灭点透视矫正算法。将相机采集到的图片进行矫正后结合激光打标加工的特点进行相机标定,选择基于多项式的畸变矫正模型对镜头畸变进行矫正。通过基于轮廓的模板匹配获取待加工工件相对于模板工件的位置及旋转角度,结合模板匹配算法的特点计算待加工工件打标点在打标机振镜系统坐标系中的坐标。选择合理的方案提取质量检测区域并使用区域生长法处理背景色区域。对错位歪斜缺陷使用模板匹配进行检测;在模板匹配的基础上使用图像差减法对打标内容笔画缺陷及脏污进行检测,通过连通域分析对缺陷进行标记;提出对打标功率类缺陷通过灰度直方图进行检测。在系统软硬件搭建完成后进行实验。实验表明本文提出的工件厚度隐藏方法和图像矫正方法能够有效避免工件厚度对图像处理造成的影响及将倾斜视角图像矫正为垂直视角图像,编写的程序能够达到较高的标定精度,以较快的速度实现打标定位及质量检测功能,准确地识别出缺陷工件。
{URL}: https://link.cnki.net/doi/10.27437/d.cnki.gytdu.2023.000349
{DOI}: 10.27437/d.cnki.gytdu.2023.000349
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 芯片表面缺陷图像检测方法研究
{Author}: 周亮
{Tertiary Author}: 潘开林
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 缺陷检测;机器视觉;图像处理;差分图像;缺陷分类
{Abstract}: 在裸芯片完成粘接之后,其表面往往存在着沾污、划痕、崩边等缺陷,这些缺陷会严重影响芯片的可靠性。通常采用人工目检的方式对裸芯片上存在的缺陷进行检测,目视检测有实时性差、成本高、精度低、标准不统一等缺点,逐渐被自动检测技术所取代。机器视觉检测技术有着耗时短、成本低、可用于实时检测等优点,越来越多的芯片生产厂家将基于机器视觉技术应用到芯片制造各环节的缺陷检测中。尽管目前基于机器视觉的芯片缺陷检测技术在印刷缺陷检测、引脚缺陷检测等方面取得了较大进展,但是对于裸芯片缺陷的检测及缺陷的分类还处于起步阶段。因此本研究基于机器视觉在裸芯片缺陷检测中的图像处理关键技术,构建起了一套基于图像预处理、图像配准、图像分割、特征提取、分类识别的裸芯片表面缺陷识别技术体系。针对某型号芯片缺陷样品数量少且采集得到的图像分辨率高的特点,本文提出了适用于小数据集、高分辨率图片的芯片缺陷识别算法,其原理为采用模板匹配生成差分图像的方法完成裸芯片的缺陷识别。本文主要的研究目的是对裸芯片完成粘接后出现的缺陷进行检测,并对常见缺陷进行分类。以某型号裸芯片为例,对该型号出现频率较高的沾污、划痕、崩边三种缺陷进行检测并进行分类,主要研究内容如下:(1)将待测芯片图像和模板图像进行配准。首先使用无缺陷的芯片样品作为模板芯片,采集模板芯片图像并进行相应的裁切、降噪等处理完成模板图像制作;采用SURF算法将待测样品图像和模板图像进行粗配准,针对基于特征点的图像配准方法精度不高的缺点,本文提出了使用麻雀搜索算法对单应性矩阵进行优化的图像精匹配方法;完成图像配准后将待测芯片图像经过变换、裁剪并与模板图像相减取模得到灰度差分图像。(2)对芯片灰度差分图像进行图像分割。通过对灰度差分图像进行阈值分割、去噪等操作来完成缺陷区域的提取。首先利用基于遗传算法优化的Otsu算法将灰度差分图像进行阈值分割得到二值差分图像;将二值差分图像进行数学形态学处理从而去除噪声;通过在差分图像上施加掩膜的方法来剔除裸芯片电学性能测试点上的压痕。(3)提取单个缺陷区域的特征。采用DBSCAN算法将二值差分图像中的缺陷区域进行聚类完成缺陷的实例分割,得到缺陷的数量和范围;分别提取单个缺陷区域的纹理特征、几何特征、灰度特征等22个特征向量并构成特征矩阵。(4)采用遗传算法优化的支持向量机对缺陷进行分类。为了减少数据冗余、降低特征矩阵维度、加快缺陷分类识别速度,使用NCA算法计算各特征权重,选择识别率最高的特征组合从而实现数据降维;采用遗传算法优化的支持向量机对芯片表面缺陷进行三分类,完成缺陷的分类识别。本文采用基于模板匹配生成差分图像的方法对芯片缺陷进行识别,采用人工提取缺陷特征生成特征矩阵,并采用基于遗传算法优化的支持向量机来完成缺陷分类任务,运用MATLAB GUI开发平台开发芯片表面缺陷检测系统,实现裸芯片表面缺陷检测,为芯片智能制造的缺陷检测环节提供了一定的理论支持和方法指导。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2023.000187
{DOI}: 10.27049/d.cnki.ggldc.2023.000187
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的果蔬自动识别系统设计
{Author}: 张璐璐
{Tertiary Author}: 何文雪
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 果蔬识别;YOLOv5;MobileNetv3;轻量级网络
{Abstract}: 信息化智能化高度发展的今天,人们的生活也期望着往更加简单便利的方向前进。目前最常见的超市称重称为称重打码一体秤,人工成本高,且耗时长,不适合人流量大的场景。有些比较先进的顾客半自助的智能电子称,对顾客操作要求较高。于是,设计一款简单方便,且自动化程度高的果蔬称重一体秤,符合目前智能化信息化社会发展的要求,具有较高的实用价值。近几年,机器视觉快速发展,由于其精度高,速度快等优点,应用也日益广泛,但由于计算成本和资源等不适合应用于小型的自助称重结算系统,研究轻量快速高精度的神经网络结构,有助于改进此种现象,本文基于YOLOv5网络进行轻量化设计,构建适用于果蔬实时监测的轻量分类算法模型,并进行硬件搭建进行验证测试。首先,针对果蔬识别分类场景,自制数据集,利用网络收集以及自行拍摄两种方法采集28种,3546张果蔬图像,包含多种光照,多类型包装以及多物品堆叠图像类型,为改善某些果蔬数据图像不足,通过几何变换和图像增强等方式进行扩充,得到24822张不同的数据图像,利用自制数据集,采用轻量化网络ShuffleNetv2和MobileNetv3对YOLOv5骨干网络部分进行替换,以构建轻量级网络,加速对特征提取处理,最高精度可达98.27%,图片识别速度仅为0.08s。其次,对基于MobileNetv3替换YOLOv5骨干的网络模型进行改进,主要包含以下改进方案:首先,对于果蔬品种较多,且大小不一的情况,如西瓜和山楂,增加预检测头以检测不同大小的目标,在网络骨干后端加入SPPF抑制信息的丢失,并在网络中加入SENet注意力机制,强化关键特征,采用ReLU6与h＿swish联合使用代替原来的swish激活函数,可有效避免过拟合与梯度消失现象,且在保持精度不变的情况下减少参数量,将IoU Loss替换为Focal-EIoU Loss对模型进行监督。最后为提高收敛速度,加快分类性能,利用改进后的解耦头代替耦合头,实验结果显示,改进的网络模型参数量下降了85%,精度只降了0.03%,单张图片识别速度提升了28.7%。这样的结果可满足当前对于果蔬识别分类的要求,且本文所研究的轻量级网络模型的要求也基本实现。最后对果蔬自助识别系统设计硬件架构以及软件系统,设计顾客和管理员系统,采用Python和Qt界面进行可视化,利用STC89C52单片机采集传感器信息与上位机进行通信,实现预设功能。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2023.002000
{DOI}: 10.27262/d.cnki.gqdau.2023.002000
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于线结构光的机器人视觉系统开发与应用
{Author}: 陈汉
{Tertiary Author}: 李志勇
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 线结构光;机器视觉;三维重建;工业机器人;点云
{Abstract}: 三维重建是一种高精度、高效率、非接触的测量技术,在工业检测、逆向工程、增材制造、工业自动化等领域发挥着重要作用。其中基于线结构光的三维机器视觉系统具有测量效率高、结构简单、灵活性强且应用场景多等显著优点。本文围绕基于线结构光的机器人视觉系统开发,开展三维表面重建关键技术研究。针对前该技术存在的问题:算法复杂、设备昂贵、工业适用性差等问题,本文的主要研究内容如下:1)搭建了CMOS工业相机、线激光器组成的结构光视觉传感装置,QT、Visual Studio平台及相关依赖库和辅助软件构成的计算机软件系统,开展三维重建算法和视觉系统研究;搭建六轴工业机器人、激光熔覆头、冷水装置、送粉装置、保护气瓶组成的机器人激光熔覆系统;通过ABB机器人的Robot Studio离线编程软件实现机器人修复系统与视觉系统的通讯。构成本文研究的实验平台。2)进行了三维重建系统的标定:包括视觉传感装置的标定和ABB机器人与视觉传感装置的手眼标定。视觉传感装置的标定包含相机标定和光平面标定;基于张氏标定法完成相机的内外参数标定;基于交比不变性实现光平面的标定;通过变换靶标位姿采集相机标定和光平面标定的图像信息,进行手眼标定;利用旋转矩阵向量性质为约束优化手眼标定线性模型,最小二乘算法对模型进行求解,实现物体二维图像信息到机器人末端基坐标的转换,用平均绝对误差评价系统标定精度,标定误差在0.3mm左右。3)提取激光条纹中心构建点云数据,实现三维重建。提出了一种基于“两步法”的条纹中心提取算法:首先使用骨架细化法粗提取条纹中心,利用双线性插值灰度重心法进行条纹中心的精提取。基于PCL点云库对点云数据进行预处理和点云表面重建算法进行研究。采用直通滤波、统计滤波去、体素栅格滤波对点云数据精简,完成点云预处理。采用滚球法实现点云数据的三维重建。4)针对非标零件测量和缺损零件修复效率低、自动化程度差的问题,采用本文搭建的实验平台对不锈钢表面凹坑进行测量和修复。对凹坑直径和深度进行测量实验;然后对点云数据处理,由系统软件生成STL模型并进行模型分层切片,根据分层切片结果设置机器人修复系统工艺参数,得到机器人具体加工路径,对凹坑缺陷表面进行激光熔覆实验,验证了本文三维视觉系统的可靠性。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.000091
{DOI}: 10.27470/d.cnki.ghbgc.2023.000091
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的一维连续性时序数据分析方法研究
{Author}: 王方年
{Tertiary Author}: 胡伟
{Publisher}: 北京化工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 一维数据分类;一维信号目标检测;Transformer;时间序列预测;磁异常检测
{Abstract}: 一维时序数据分为连续性时序数据和离散性时序数据,可看作是普通二维的特征矩阵向时间空间的一种拓展。连续性时序数据最主要的特点是构成的波形平滑。在一维连续性数据研究方向上,常见的任务包括分类、检测（检测信号出现的位置）和预测趋势走向等,最主要的两个要求是分析准确率高和推理速度快。本文以Transformer为基础模型,以一维连续性时序数据为研究对象,围绕三个基本任务（分类、检测、预测）展开研究,并对四类具有代表性和实际价值的一维连续性数据探究了细节性问题。这四类数据分别是:磁异常检测、遥感图像分类、医学领域的心律失常诊断、材料学领域的涂层寿命预测。本文的研究内容如下:（1）提出了Shifted-Grad Transformer（SGT）,其中的Shifted-Grad Block模块扩展了一维数据的梯度特征构造空间,构造了从最近邻到偏移最近邻的梯度特征,简化了繁重的数据预处理步骤,通过直接将一维连续数据送入SGT网络中,显著提高了分类的精度和速度。同时SGT对于Transformer进行改进,在Vision Transformer模型基础上,改进了patch split的构造结构,使得Transformer与Shifted-Grad Block相结合,增强了一维数据长距离依赖关系。SGT首先应用于磁异常信号分类,在磁数据上表现出了良好效果,分类准确率达到了99.01%,每秒可以处理2.8×10～3个输入,超过最好的方法1.57个百分点,快近28倍。针对磁异常信号检测,通过滑动窗口将检测任务转化为分类任务,并使用后处理动态规划算法,在（）时间复杂度下有效消除了滑动窗口检测结果出现的虚警,实现了磁异常信号目标检测。这一框架代码已开源1。本文继续研究了其他一维连续数据的一些经典问题和公共数据集。通过高光谱图像分类公开数据集Pavia University（spatially disjoint samples）数据、极化合成孔径雷达图像分类公开数据集（Flevoland dataset）、心律异常诊断公共数据集（MIT-BIH）的大量的实验对比,证明了SGT是处理一维连续性数据的一个通用性框架。（2）本文还研究了一维连续性时序数据预测问题,在Vision Transformer的基础上引入一个Time embedding模块,同时使用双分支Bidirectional LSTM网络,实现了对一维连续性时序数据的预测,并加强了时间特征对预测结果的影响。以材料领域的涂层性能劣化预测问题为实际应用场景,新模型和Informer以及MLP-Mixer等进行了对比实验,表现出更好的预测能力。总之,本文工作表明了基于Transformer的一维连续性时序数据的分析模型在多个相关领域都具有重要的研究意义和实用价值。
{URL}: https://link.cnki.net/doi/10.26939/d.cnki.gbhgu.2023.000661
{DOI}: 10.26939/d.cnki.gbhgu.2023.000661
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于MediaPipe框架的人体动作识别模型在Y Balance Test中的应用研究
{Author}: 孔德智
{Tertiary Author}: 李宁
{Publisher}: 成都体育学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器学习;MediaPipe;人体姿态检测;Y Balance Test
{Abstract}: 在计算机视觉技术快速发展的背景下,本论文旨在研究人体姿态识别技术算法在运动康复测试领域中的应用可行性,目的通过人体姿态关键点的识别与处理来实现Y Balance Test的全流程自动化检测与评分,以此来降低传统人工形式YBT学习与使用的门槛,扩展其使用场景,为康复治疗技术的推广应用提供新的思路。本论文首先采用了 MediaPipe框架下的BlazePose人体姿态关键点检测算法,预测出了普通三维人体坐标值作为原始输入数据,通过特征工程和分类算法的设计,实现了对YBT测试动作的识别分类与计数功能。在该动作识别模型的基础上,本研究通过对BlazePose算法识别得到的另一组基于真实世界的三维人体关键点坐标数据进行优化处理,实现对YBT测试过程中各个动作方向受试者最大伸出距离和受试者下肢长度的直接获取,从而计算得到前侧左右差值、后外侧左右差值、后内侧左右差值和YBT综合分数共4个YBT测试评价指标。在YBT自动评分算法的实现过程中,通过对训练集数据剔除率的分析,发现BlazePose算法在缺乏上下文信息的情况下对静态图片中人体关键点进行预测的能力具有一定波动,在某些人体关键肢体部位遮挡严重的情况下,BlazePose识别的准确率较低。但训练后的YBT动作识别模型在本研究中测试集数据上表现较好,总体识别准确率为96.7%。对于最终实现的YBT自动评分算法,本论文对传统人工YBT测试结果与YBT自动评分算法结果使用组内相关系数的方法进行了一致性分析,前侧差值、后侧外侧差值、后内侧差值和YBT综合分数这四个结果指标所对应的ICC值分别为-0.009、-0.279、0.124和0.040。一致性分析表明现阶段BlazePose所预测出的基于真实世界的三维人体关键点数据精度不能满足YBT测试的直接需要,基于该识别模型的YBT自动评分算法暂时不能代替传统人工的YBT测试。综上所述,本研究通过对MediaPipe框架下BlazePose算法的应用,实现了对YBT测试动作的分类计数以及测试过程中各个动作方向受试者最大伸出距离和受试者下肢长度的直接获取。最后经一致性分析验证表明,目前实现的YBT自动评分算法结果欠佳,需要进一步优化和改进。但YBT动作识别模型对于YBT测试动作识别准确率较高,可以由此进一步开发相关训练指导产品。
{URL}: https://link.cnki.net/doi/10.26987/d.cnki.gcdtc.2023.000330
{DOI}: 10.26987/d.cnki.gcdtc.2023.000330
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的名优茶单芽检测与精准采摘技术研究
{Author}: 李鑫德
{Tertiary Author}: 姜兆亮
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 茶芽采摘;深度学习;目标检测;采摘点定位;采摘序列规划
{Abstract}: 中国茶叶流通协会数据表明,2022年末全国茶园总面积约为320万公顷。随着茶园作业劳动力的日益短缺以及未来土地集中经营导致茶园规模化,应用先进的名优茶采摘机器人取代落后的人工采摘或者无差别机械收割作业已成为茶园名优茶收获的必然趋势。现有的名优茶采摘机器人受制于茶芽在线检测效率低、采摘点定位精准度差等问题,且在茶芽采摘策略与能耗优化问题上研究较少。因此,如何开发一种精准高效的视觉系统来检测茶田中的茶芽并定位采摘点,同时以一种更优的序列高效节能地采摘茶芽是亟待解决的问题。本文主要研究内容如下:针对茶芽检测效率低、精度差的问题,改进了 YOLOv3网络模型,提出了一种名优茶单芽快速检测方法。在茶园中采集茶芽图片,建立茶芽检测数据集。通过加入金字塔池化模块、改进多尺度融合检测模块、优化锚框与损失函数对经典YOLOv3网络模型进行了改进。改进后的网络检测精度和速度分别达到了 81.42%和15.87帧/秒,拥有更强的小目标检测能力和更快的检测速度,为茶芽采摘区域识别奠定了良好的基础。针对茶芽采摘点定位精准性较差的问题,提出一种基于PSPNet网络与深度相机的茶芽采摘点三维定位模型。建立茶芽采摘区域识别数据集,搭建基于PSPNet网络的茶芽采摘区域识别模型并对其进行训练。实验得到一芽一叶采摘区域识别的平均精度为80.76%,平均交并比为72.60%。利用深度相机结合质心法求得相机空间中的采摘点坐标,设置茶芽采摘点定位试验证明了采摘点识别与定位的精准性与可靠性。针对茶芽如何高效采摘的问题,提出了一种平行四边形采摘策略与茶芽采摘序列规划方法。基于最大效率与最小能耗目标,设计了路径-能耗综合最优目标函数。改进了经典蚁群算法,在适量茶芽和大量茶芽的情况下,改进蚁群算法的寻优能力均强于经典蚁群算法。在适量茶芽模拟实验中,本文茶芽采摘序列规划方法与最短路径规划方法相比,在总路径长度增加3.01%的情况下,能耗减少了 19.65%,实现采摘机器人在高效工作的同时最大程度地提高了续航能力。为了验证研究方法的可行性,对采茶机器人样机进行了试制,同时开发了采茶机器人智能采摘控制系统。在采摘序列规划试验中,适量茶芽的情况下本文采摘序列规划方法相较于最短路径规划化方法采摘时间增加了 0.28%,能耗减少了 12.5%。在茶田采摘试验中,茶芽检测成功率为90.02%,每张茶芽图片检测的平均耗时为0.0627s;茶芽采摘点定位成功率为84.21%,每个茶芽采摘点定位的平均耗时为0.0158s;茶芽采摘成功率为77.30%,每个茶芽采摘的平均耗时为2.01s,可以满足采茶机器人在茶田中的作业需求。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.002156
{DOI}: 10.27272/d.cnki.gshdu.2023.002156
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于亚像素边缘检测的圆心定位技术研究与应用
{Author}: 郭哲宏
{Tertiary Author}: 林振荣
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;亚像素边缘检测;圆心定位;最小二乘法
{Abstract}: 在工业制造中,常常需要对工业产品的位置,尺寸进行测量,而工业发展使被检测目标逐渐精密化,这就要求检测零件的精度变得更高。在高精度检测中,最准确的检测方式是通过工业显微镜进行观察,但这种方式会极大增加人力成本,同时检测结果也会因人而异,即便是同一个人观察也可能出现两种不同的结果,缺乏稳定性。更为重要的是,一方面要确保检测精度更高,另一方面还要有更快的检测速度,人眼一次只能单独观察零件的一个部位,很难有效率的完成检测工作。因此,本文基于图像处理技术的机器视觉系统,对工业零件的具体位置进行测量。本文主要对亚像素边缘检测技术和圆心定位技术展开研究,以标准圆和工厂实际生产零件喷丝板上的微孔为实验对象,论文的研究工作包括以下几个方面:(1)本文提出了一种基于曲波变换和局部效应的亚像素边缘检测方法。该算法针对曲线边缘进行检测,首先通过Wrapping曲波变换进行边缘分析,原图像经过曲波变换后,得到曲波系数集合,设置阈值将较小的系数置为零,再将系数曲波反变换得到新图像;然后将局部效应边缘检测作用于新图像,依据边缘邻域内的像素点计算边缘点的亚像素坐标;最后通过标准圆和微孔的边缘检测结果,证明了该算法在边缘检测方面的优越性。(2)针对噪声点干扰导致圆心定位不准确的问题,本文提出了一种边缘点筛选方法,并将亚像素边缘检测和圆心定位结合起来。首先通过本文的亚像素边缘检测算法定位图像中边缘点的位置;然后从同一个圆上两点之间的距离小于直径,以及邻近点之间的梯度夹角为锐角两个方面进行判定,筛选出同一个圆上的边缘点;最后使用最小二乘法求出圆心的位置。通过实验比较了目前较为准确的圆心定位方法,实验结果表明,该算法具有较高的检测精度以及抗噪能力。(3)本文搭建了视觉测量平台和视觉检测系统,在实际的微孔测量中,本文基于亚像素边缘检测的圆心定位方法可以达到0.02毫米左右的精度。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2023.003714
{DOI}: 10.27232/d.cnki.gnchu.2023.003714
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的面部表情识别方法研究
{Author}: 魏鑫光
{Tertiary Author}: 宋勇
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 面部表情识别;深度学习;卷积神经网络;对比学习;注意力机制
{Abstract}: 面部表情识别在医疗、教育、交通运输等多个领域具有极大应用价值,随着硬件设备条件的不断升级以及国家对人工智能领域的大力扶持,深度学习已经成为各个领域不可或缺的技术,卷积神经网络是深度学习最具代表性的网络模型之一,由于其在计算机视觉领域表现出的优异性能,基于卷积神经网络的面部表情识别已成为研究热点。然而,目前基于卷积神经网络的面部表情识别的研究仍然存在着一些难点:首先,现有面部表情图像数据集大都规模较小,且额外样本数据难以搜集;其次,由于面部图像中冗余信息的干扰,不同类表情识别时易发生混淆;最后,现有模型对于硬件和算力要求较高,存在难以实际应用等问题,因此,本文以卷积神经网络为基础,对面部表情识别算法目前存在的难点展开研究,主要研究内容如下:(1)提出基于对比学习的面部表情识别方法。此方法旨在解决真实环境中面部表情数据样本较少,难以获得有效的预训练模型的问题,其中,基于对比学习的预训练模型使用数据增强作为代理任务,通过对比现有数据样本之间的区别与联系,充分发掘面部表情潜在特征,在不使用额外数据的前提下,增强预训练模型的泛化性与稳定性,此外,本文在模型训练过程中使用分段迁移训练策略,该策略对网络权值进行分段调整,减少了网络迁移过程中特征提取能力的损失,进一步增加了网络训练过程的稳定性。(2)提出基于融合注意力机制的面部表情识别方法。为了减少输入面部图像中冗余信息带来的消极影响,获取更多有价值特征,本文提出FA-Net网络结构,该网络通过融合注意力机制从通道、空间两维度实现对输入图像的自适应加权,实现网络对脸部重点区域的聚焦,从而提取富有表情分辨力的特征;由于表情分类任务具有类内差异大的特点,因此本文在训练过程中引入亲和损失,通过增加类内样本在特征空间聚集程度从而增加表情可分性。提出的方法有效增强了网络对重要特征的提取能力,提升了表情识别精度。(3)提出一种轻量化面部表情识别网络,并基于此设计完成机器人实时面部表情识别系统。由于卷积网络模型大多对硬件与计算资源有一定的要求,难以进行实际应用,本文将上述提出的FA-Net网络结构使用对比学习思想进行预训练,正式训练后将其作为教师网络,使用轻量型网络MobileNetV3-Small作为学生网络,通过知识蒸馏将教师网络知识传递给学生网络,得到压缩后的模型MFA-Net,其兼顾面部表情任务的准确性与实时性,并以此为算法基础,以启智ROS机器人为硬件平台,设计了一个实时面部表情识别系统。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006762
{DOI}: 10.27272/d.cnki.gshdu.2023.006762
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 改进YOLOv5的瓷砖表面缺陷检测
{Author}: 余松森;张明威;杨欢
{Author Address}: 华南师范大学软件学院;
{Journal}: 计算机系统应用
{Year}: 2023
{Volume}: 32
{Issue}: 08
{Pages}: 151-161
{Keywords}: 机器视觉;深度学习;目标检测;YOLOv5算法;注意力机制;瓷砖表面缺陷
{Abstract}: 现有瓷砖表面缺陷检测存在识别微小目标缺陷能力不足、检测速度有待提升的问题,为此本文提出了基于改进YOLOv5的瓷砖表面缺陷检测方法.首先,由于瓷砖表面缺陷尺寸偏小的特性,对比分析YOLOv5s的3个目标检测头分支的检测能力,发现删除大目标检测头,只保留中目标检测头和小目标检测头的模型检测效果最佳.其次,为了进一步实现模型轻量化,使用ghost convolution和C3Ghost模块替换YOLOv5s在Backbone网络中的普通卷积和C3模块,减少模型参数量和计算量.最后,在YOLOv5s的Backbone和Neck网络末端添加coordinate attention注意力机制模块,解决原模型无注意力偏好的问题.该方法在天池瓷砖瑕疵检测数据集上进行实验,实验结果表明:改进后的检测模型的平均精度均值达66%,相比于原YOLOv5s模型提升了1.8%;且模型大小只有10.14 MB,参数量相比于原模型减少了48.7%,计算量减少了38.7%.
{ISBN/ISSN}: 1003-3254
{Notes}: 11-2854/TP
{URL}: https://link.cnki.net/doi/10.15888/j.cnki.csa.009185
{DOI}: 10.15888/j.cnki.csa.009185
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的小目标检测方法研究
{Author}: 赵春萌
{Tertiary Author}: 康戈文
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小目标检测;双阶段目标检测器;单阶段目标检测器;Faster R-CNN;YOLOv5
{Abstract}: 小目标检测是计算机视觉目标检测领域的一个重要问题,具有广泛的应用前景。然而,小目标通常具有低对比度、低分辨率和复杂背景等特征,这使得现有的目标检测方法在处理小目标时效果不佳,所以研究如何高效准确地检测小目标具有重要意义。通过使用深度学习技术进行改进,可以有效地提高小目标检测的准确性,这将推动小目标检测技术的进一步发展,并为实际应用提供更好的效果和体验。本文针对基于深度学习的小目标检测问题展开研究。首先,介绍了目标检测的基本概念和常用模型,着重分析了双阶段目标检测器Faster R-CNN和单阶段目标检测器YOLOv5。其次,分别对这两个模型进行了改进。最后,通过实验结果对比分析,验证了所提出方法的有效性和优越性。本文的主要工作如下:针对双阶段目标检测器Faster R-CNN,为解决小目标特征提取困难的问题,研究过程中对Faster R-CNN采用了ResNet50和VGG16作为骨架网络。在原有的模型基础上使用一种改进的IoU算法来解决正负样本不平衡的问题,同时引入FPN特征融合网络来提高检测器的多尺度检测能力。在实验过程中,使用了迁移学习的方法来对改进后的Faster R-CNN模型进行训练,并对模型在小目标检测方面的性能进行了评估。实验结果表明,相对于原始模型,在基于ResNet50和VGG16的架构下,改进后的Faster R-CNN模型mAP分别提升了9%和7.4%,这表明改进方法能够有效地提升模型的小目标检测性能。针对单阶段目标检测器YOLOv5,该模型在目标较大的情况下识别效果较好,但是对于小目标检测,容易出现漏检、误检的现象。因此在模型中添加了SPD模块,用于提高小目标的检测率。SPD扩大了卷积核的感受野,使得网络能够更好地捕捉图像中的细节信息。除此之外,又添加了CBAM机制,CBAM能自适应地计算通道和空间的注意力权重,从而提取图像中重要的特征信息,更好地区分目标和背景。在Vis Drone数据集上对改进后的模型进行了训练和测试。实验结果表明,相对于原有的YOLOv5模型,采用SPD和CBAM方法能够更好地关注有用的特征,从而提高小目标的检测准确率,相较于原有YOLOv5模型mAP指标提升了4.6%。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001478
{DOI}: 10.27005/d.cnki.gdzku.2023.001478
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的机器人物品递送与运输系统研究
{Author}: 刘志超
{Tertiary Author}: 许庆阳
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;机器人抓取;多机交互;多机通信
{Abstract}: 随着人口老龄化的日益严重以及全球疫病的频发,服务机器人产业的需求旺盛,以智能医护、智能配送为代表的服务机器人具有重要研究价值。在医疗环境中,机器人代替医护人员完成一些简单的医护任务,可以节省人力成本并且提高工作效率。因此,面向医疗场景中对患者药物进行拿取和配送的任务场景,本文构建了基于视觉的机器人物品递送与运输系统。本文通过研究目标检测与文字匹配方法实现药物的精准识别抓取,通过模糊定位策略实现抓取机器人和配送机器人的物品交互,最后通过机器人导航方法实现物品的运送。本文的主要研究内容如下:(1)对机器人抓取检测技术进行研究,分析传统机器人基于目标检测算法的物体抓取检测技术在药瓶检测中出现的问题,考虑到药瓶上普遍存在的文本信息,本文提出了将目标检测与文字检测识别相结合的机器人抓取目标检测方法,实现对待抓取目标的精准检测。(2)针对机器人抓取检测算法在机器人实际抓取过程中模型运行缓慢的问题,本文引入了目标跟踪算法对抓取检测进行优化,实现“一次检测,实时跟踪”,一旦对待抓取物体完成文字匹配,机器人可在移动过程中对其进行实时定位。通过设计实验验证,本文提出的基于场景文字识别的机器人抓取定位系统具有较高的可靠性、准确性和适用性。(3)对两台机器人之间的物品交互方法进行研究,在机器人SLAM建图与导航功能的基础上,设计一种机器人模糊定位方法,实现两台机器人在一定范围内的自主定位。基于HSV颜色特征对配送机器人配送盒进行检测,通过视觉方式计算抓取机器人夹爪的最佳释放点,实现物品在两台机器人之间的交互。(4)设计多机器人物品递送与运输系统,基于ROS中的话题模型与Socket网络通信建立多机器人之间的消息通信机制,面向医院中患者药瓶的抓取与配送任务,将机器人抓取与物品交互进行结合,搭建实验环境,设计实验流程,通过实验验证本文研究的机器人物品递送与运输系统的可行性与实用性。综上所述,本文提出一种基于场景文字识别的机器人抓取检测与定位方法,对于待抓取对象包含文字信息的场景,此方法可以有效地实现精准检测;提出的基于视觉的机器人物品交互与运输系统在医疗场景任务中具有一定的实际应用价值。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.006630
{DOI}: 10.27272/d.cnki.gshdu.2023.006630
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的精细化停车管理系统研究与设计
{Author}: 郭晓宇
{Tertiary Author}: 陈晔;李大威;许平建
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;车位检测;车型识别;YOLOv5s;Vision Transformer
{Abstract}: 我国国民经济水平不断上升,人民生活日益富足,私家车保有量飞速增长,停车难的问题逐渐显现。提高停车效率和提高停车场的车位利用率是解决当前问题见效周期最快、成本最低的方式。基于此,本文设计了一套精细化停车管理系统。通过机器视觉技术,实时检测空闲车位,并识别车辆型号,通过型号判断车辆尺寸,为车辆分配更适合其尺寸大小的空闲车位。从而使得停车场可以更加合理规划车位布局,高效利用停车场空间。因此,对停车场车位停车状态检测算法和车辆车型识别算法的准确率和运行速率提出了较高的要求。基于此,本文主要工作如下:(1)针对嵌入式设备运算能力不足的问题,提出了一种基于YOLOv5s的轻量化车位停车状态检测模型。首先,为了提高YOLOv5s模型识别的准确性,使用在提取重要特征方面具有强大能力的卷积块注意力模块(CBAM)。通过多种对比实验证明了优化模型的优越性。然后,利用Network Slimming算法对优化后模型的批归一化(BN)层进行剪枝操作,通过对比分析使用不同剪枝率得到模型的检测效果,选取最优模型。(2)在车辆型号识别的研究中,提出了一种基于视觉自注意力(Vi T)模型的优化算法。为了更好的提取图像特征,同时引入归纳偏置。首先,将原始图像进行3次CBS卷积操作后再输入至Vi T模型中。其次,使用Conv MLP替换Vi T模型中的MLP head模块。最后,通过消融实验以及与传统卷积网络模型进行对比实验,得出改进模型的识别准确率更高,证明了优化方案的有效性。(3)为了降低系统的数据传输量并提高传输速度,设计了边缘端、云端和终端协同的系统整体结构。边缘端采用嵌入式设备的分布式结构,摄像头传入的视频由嵌入式设备进行初步检测和识别,仅将识别结果传入至云端。云端负责边缘端传入数据的对接、处理和存储,以及将数据传输至终端。为了便于停车场管理和车主停车,终端采用PC端、移动端以及显示模块多种形式与用户进行交互。(4)设计并实现精细化停车管理系统。设计了系统终端的总体功能结构模块,并详细设计了每一个功能模块的流程以及系统使用的数据库。最终使用Win Form和Android开发软件系统,实现了用户注册登录、停车场查询、停车位推荐、在线缴费、历史订单查询等功能。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2023.001221
{DOI}: 10.27470/d.cnki.ghbgc.2023.001221
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的大豆种子品质检测与分选
{Author}: 李梁璨
{Tertiary Author}: 贺红;李素梅
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 计算机视觉;图像处理;Mask R-CNN;大豆籽粒分选装置;大豆考种
{Abstract}: 大豆富含各种重要的营养物质,是居民生活中最好的蛋白质来源之一。近年来随着大豆需求量的增加,国内大豆的自产量却没有明显提升,导致大豆缺口量有逐年扩大的趋势,已经严重威胁了我国的粮油安全,提升国内大豆的亩产量、培育新品种大豆迫在眉睫。考种是育种工作中至关重要的环节,获取大豆种子的表型信息并以此筛选出更优异的品种是育种工作顺利进行的保障。对大豆种子的考种是在收获后从大豆植株中剥离出种子,观察每颗植株所结种子的表型状态,并记录大豆种子的数量和各种表型信息。目前大豆的考种工作还是以人工观察为主,无法对大豆的表型特征进行量化,效率低下的同时也不能保证准确性。为了提高考种工作的效率和准确率,本文提出了一种基于机器视觉的自动化大豆种子品质检测与分选系统。本文的主要工作为:1.为了准确筛选出大豆种子中的残次品,基于Mask R-CNN模型,使用新的特征提取网络和注意力机制,提出了一种适合检测大豆种子的改进的Mask R-CNN模型。经过实验对比发现,相较于Mask R-CNN,改进的模型对残次品大豆种子的总体检测准确率提升了 19.92%,对于各种残次品大豆种子的检测精度都有提升。2.使用基于分水岭的大豆特征参数提取算法获取大豆种子的各种表型参数,包括周长、面积、圆度,在筛出残次品大豆的基础上可以进一步地根据量化的大豆表型参数进行分选,进一步提高考种的准确率。将该算法嵌入至硬件平台中,使用FPGA的处理器系统和可编程逻辑运行,提高算法运行速度。3.设计了一种大豆籽粒分选装置,控制端搭载上述两种大豆分选算法,通过自动化与机械设备结合,实现了使用机器视觉分选大豆种子的工作。系统使用传送带批量输送大豆,在运输过程中使用摄像头进行图像采集,使用计算机处理采集的图像,由算法分选出目标大豆,通过FPGA控制电磁阀开启相应的气动喷孔来剔除目标大豆,能够按照筛选标准自动化分选大豆种子。本文设计了一种大豆籽粒的人工智能选种装置,把基于机器视觉的大豆种子表型特征获取算法内置到选种装置的控制系统,可以大幅度地减少人工考种带来的误差,加快育种进程,提高现代种业的选种效率。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.005931
{DOI}: 10.27272/d.cnki.gshdu.2023.005931
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的混凝土表面裂缝识别研究
{Author}: 单佐林
{Tertiary Author}: 杜清府
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 混凝土裂缝;滤波算法;图像增强;图像分割
{Abstract}: 混凝土作为一种常见且十分重要的建材,它具有很多优点,比如耐久性好、易加工、成本低等,被广泛的应用在水坝、公路和桥梁等各项基础设施建设中,然而随着混凝土构件使用年限的不断增加,受到环境和荷载等因素的影响,桥梁、道路和大坝等混凝土构件的劣化速率不断加速。裂缝作为影响混凝土构件结构质量的一种常见安全隐患,裂缝本身对混凝土构件带来的威胁并不大,但若不经过及时且有效的处理,混凝土裂缝就很有可能会引起其他更为严重的灾害,而一旦桥梁、大坝等混凝土构件发生倒塌,将会造成严重的安全事故。因此,及时地对裂缝进行监测对于保证混凝土构件的安全稳定具有十分重要的意义。传统的采用人工对裂缝进行检测的方法十分费时费力,而且结果还具有很强的主观性,而无损检测设备造价昂贵,检测过程受到外界条件的影响比较大。利用图像处理技术进行检测成本低、灵活性高以及检测精度高,因此使得基于图像处理技术的检测方法的广泛应用已经成为了可能,但是通常来说,一种图像检测算法一般仅能够针对特定情况对裂缝识别,通用性不高,因此本文对混凝土裂缝识别的算法进行了深入的研究,主要研究内容包括:(1)对混凝土裂缝图像的预处理的各种算法进行了研究,通过对比中值滤波、高斯滤波、双边滤波以及均值滤波算法对混凝土裂缝图像的滤波效果,最终选用高斯滤波算法来对混凝土裂缝灰度图像进行平滑,减少图像的噪声,通过对比研究不同图像增强算法对于混凝土裂缝图像的增强效果,发现当γ<1时,伽马变换算法可以更好得提高裂缝图像的对比度,方便后续裂缝分割与识别。(2)对混凝土裂缝分割与提取算法的研究,实现了两种改进的模糊聚类算法对混凝土裂缝图像进行分割,并对比研究了边缘检测算法、阈值分割算法和模糊聚类算法对于混凝土裂缝图像的分割性能。结果表明,模糊聚类算法进行分割所得的二值图中噪声更少,且具有更好的分割效果,然后结合连通域的面积大小和圆形度这两个特征对二值图进行滤波去噪,从而准确提取混凝土裂缝,实验结果表明,HMRF-FCM算法的Dice系数平均可以达到0.9017。最后计算了混凝土裂缝的密度、重心等参数。(3)最后本文在Python开发环境下,采用Python与Matlab联合编程,并结合OpenCV库、PyQt以及MySQL数据库完成了混凝土裂缝识别软件的开发。软件封装了OTSU算法、FCM算法、FLICM算法和HMRF-FCM算法,可以根据不同条件使用不同的分割算法对混凝土裂缝进行提取。经实验验证,可以精确地识别并提取混凝土裂缝,软件自动将所得的混凝土裂缝密度、重心等参数储存在MySQL数据库中,最终计算结果显示在界面的表格中。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2023.003420
{DOI}: 10.27272/d.cnki.gshdu.2023.003420
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于OpenCV的数字仪表字符提取及快速识别研究
{Author}: 张银;吕彦明;钱云杰
{Author Address}: 江南大学机械工程学院;
{Journal}: 自动化仪表
{Year}: 2023
{Volume}: 44
{Issue}: 05
{Pages}: 46-50+55
{Keywords}: 图像处理;机器视觉;数字仪表;穿线法;自动识别;OpenCV;透视变换;轮廓提取
{Abstract}: 为了实现工业仪表的自动化识别检验、降低人力消耗，应用机器视觉和图像处理技术对数字仪表自动读数识别进行研究。对采集的字符图像进行一系列预处理，包括灰度化以及采用双边滤波算法对含有背景的图像进行图像降噪预处理。提出了1种针对数字仪表字符区提取及快速识别的算法。基于透视变换以及轮廓提取函数实现仪表字符区的倾斜校正及快速提取，并对提取的字符进行形态学处理。提出了1种改进的穿线法对未进行字符分割处理的图片进行识别，并针对字符1的特征提出了快速识别方法。该算法省去了字符分割的时间，提高了字符识别效率。试验证明，算法对数码管的识别正确率达到99.3%、单幅图片识别时间为6.95 ms,可有效应用于计量、检验等数显仪表识别场合，提高检验效率。
{ISBN/ISSN}: 1000-0380
{Notes}: 31-1501/TH
{URL}: https://link.cnki.net/doi/10.16086/j.cnki.issn1000-0380.2022090015
{DOI}: 10.16086/j.cnki.issn1000-0380.2022090015
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的海上垃圾识别研究
{Author}: 蔡成涛
{Tertiary Author}: 顾沈明
{Publisher}: 浙江海洋大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 垃圾监测;YoloV5s;轻量化;DeepSort;目标检测
{Abstract}: 塑料垃圾是海洋垃圾的主要组成部分,严重危害生态环境。国际上在海洋塑料垃圾治理上已经纷纷采取行动。由于塑料垃圾多具有可漂浮特性,在海水潮汐运动的作用下,容易聚集在海岸附近。随着目标检测技术的逐渐成熟,使用具备机器视觉的设备自动化监测垃圾或回收垃圾存在可行性。本研究设计研发出了一种基于改进YoloV5算法的轻量化视觉模型的数据平台,实现了让机器实时监测沿岸垃圾信息的功能。主要的工作内容和成果如下:1.依照多背景、多视角、标签分布平衡的原则自主创建了3156张以合成图像为主的海洋垃圾数据集,解决了海洋垃圾图片获取难的问题。深度分析海面环境,为增强模型适应力增强了数据。根据数据集标签位置信息统计了标签尺度,适配了对应的模型检测头。测算出最适合模型训练的划分比例。2.选择YoloV5s为基准模型,使用RepVGG Block替换原骨干网络3×3卷积来增强特征提取能力和运行效率。将改进的模型与DeepSort跟踪算法结合使DeepSort跟踪能力极大增强。为了使YoloV5更具轻量化且避免精度损失,研究中先在模型中引入SA注意力模块和先进的SIoU损失函数来提升精度,最后再对模型剪枝实现大幅增加检测速度和减轻模型体积。3.为了测试改进的后模型的性能,将其部署在Jetson Nano小型终端,得出快于YoloV5s约10帧的检测帧率和96.3%的高精度。为了使模型产生实用价值,本研究开发了数据平台与Jetson Nano对接,利用获得的检测位置、种类、垃圾数量生成直观的垃圾分布热力图来极大简化了垃圾监测工作。
{URL}: https://link.cnki.net/doi/10.27747/d.cnki.gzjhy.2023.000362
{DOI}: 10.27747/d.cnki.gzjhy.2023.000362
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自动驾驶场景下摄像头和毫米波雷达融合的3D目标检测
{Author}: 赵园
{Tertiary Author}: 张燕咏
{Publisher}: 中国科学技术大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 3D目标检测;毫米波雷达;传感器融合;自动驾驶
{Abstract}: 近几年自动驾驶成为了热门的研究方向,其中,作为决策与预测的先决条件,3D目标检测成为了感知模块必不可少的组成部分,直到现在仍然是计算机视觉领域颇有挑战性的研究领域之一。为了兼顾准确性与鲁棒性的检测结果,自动驾驶车辆通常配备多种类型的传感器,这些传感器各有优缺点,例如,摄像头可以提供高分辨率的图像,但在低光和恶劣天气条件下表现较差,毫米波雷达提供稳定的毫米级电磁波信号,但目前使用的型号精度低且不提供纵向分辨率。因此,本文探究如何通过传感器融合将摄像头与毫米波雷达的数据整合,从而实现更可靠、更准确的3D目标检测算法。毫米波雷达与视觉传感器的融合存在着许多困难挑战,不仅要处理输入数据规模的差异、视角变化、数据类型差异和雷达噪点等难题,还需要算法兼备稳定性与实时性。针对以上难点与挑战,本文提出了针对毫米波雷达-摄像头的融合框架BEV-Radar,做出了如下贡献:(1)针对视角差异及数据规模带来的空间对齐问题,由于毫米波雷达点的稀疏以及纵向分辨率的缺失,投影雷达点使其与相机图像对齐会让数据分布变得难以学习。本文通过分析前视角雷达点投影FV-Align与鸟瞰图特征对齐BEV-Align的特点,证明了观点:在稠密强模态和稀疏弱模态做特征前融合时,应尽可能避免地改变稀疏弱模态的数据分布。两个实验以差不多精度的视觉框架做基础,在不对框架做较大修改地情况下,通过不同视角改变毫米波雷达特征提取地数据分布,以性能表现证明了毫米波雷达与相机融合时BEV相比于前视图是更合适的视角。(2)针对不同模态传感器数据相异的表现特点带来的特征对齐问题,本文在BEV的基础上进一步提出了一种基于双向注意力机制多尺度的融合策略(Bidi-rectional Spatial Fusion)。该融合模块包含针对各自 模块分别的注意力提取和双向的注意力融合,并加入了卷积模块来提取局部的空间相关特征,从而进一步提升毫米波雷达与相机在空间形状上的对齐。在实时推理达到10FPS的情况下,BEV-Radar在公开数据集nuScenes的测试集上取得了 48.2mAP和57.6NDS的准确率。无论是与作为基础框架的纯视觉网络相比,还是与其他毫米波雷达和相机的融合方法相比,BEV-Radar都在各项任务中获得巨大提升,尤其对于速度项的回归精度更高。此外,本文还在不同天气、目标距离等的场景做了进一步实验分析,以证明了本融合算法应对自动驾驶多变场景的稳定能力。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001956
{DOI}: 10.27517/d.cnki.gzkju.2023.001956
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉的手指语识别系统设计
{Author}: 韩团军;马晨;王战备;尹继武
{Author Address}: 陕西理工大学物理与电信工程学院;
{Journal}: 实验技术与管理
{Year}: 2023
{Volume}: 40
{Issue}: 04
{Pages}: 119-124
{Keywords}: MediaPipe;支持向量机;手指语识别;机器视觉
{Abstract}: 针对传统手指语识别系统识别速度慢、准确率低、运算量大等问题，提出一种基于MediaPipe框架与支持向量机（SVM）的轻量级手指语识别系统。该系统通过MediaPipe提取手指语图像关节特征点，使用支持向量机（SVM）中的径向基核函数（RBF）对提取的特征进行分类，以一对一的方法将基本的二分类SVM转变为多类SVM，从而实现手语识别目的。该文还用准确度、精度、召回率和F分数等指标对该系统的性能进行了评价。
{ISBN/ISSN}: 1002-4956
{Notes}: 11-2034/T
{URL}: https://link.cnki.net/doi/10.16791/j.cnki.sjg.2023.04.017
{DOI}: 10.16791/j.cnki.sjg.2023.04.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 图像—文本多模态指代表达理解研究综述
{Author}: 王丽安;缪佩翰;苏伟;李玺;吉娜烨;姜燕冰
{Author Address}: 浙江大学软件学院;浙江大学计算机科学与技术学院;浙江传媒学院媒体工程学院;
{Journal}: 中国图象图形学报
{Year}: 2023
{Volume}: 28
{Issue}: 05
{Pages}: 1308-1325
{Keywords}: 视觉定位(VG);指代表达理解(REC);视觉与语言;视觉表征粒度;多模态特征融合
{Abstract}: 指代表达理解（referring expression comprehension,REC）作为视觉—语言相结合的多模态任务，旨在理解输入指代表达式的内容并在图像中定位其所描述的目标对象，受到计算机视觉和自然语言处理两个领域的关注。REC任务建立了人类语言与物理世界的视觉内容之间的桥梁，可以广泛应用于视觉理解系统和对话系统等人工智能设备中。解决该任务的关键在于对复杂的指代表达式进行充分的语义理解；然后利用语义信息对包含多个对象的图像进行关系推理以及对象筛选，最终在图像中唯一地定位目标对象。本文从计算机视觉的视角出发对REC任务进行了综述，首先介绍该任务的通用处理流程。然后，重点对REC领域现有方法进行分类总结，根据视觉数据表征粒度的不同，划分为基于区域卷积粒度视觉表征、基于网格卷积粒度视觉表征以及基于图像块粒度视觉表征的方法；并进一步按照视觉—文本特征融合模块的建模方式进行了更细粒度的归类。此外，本文还介绍了该任务的主流数据集和评估指标。最后，从模型的推理速度、模型的可解释性以及模型对表达式的推理能力3个方面揭示了现有方法面临的挑战，并对REC的发展进行了全面展望。本文希望通过对REC任务现有研究以及未来趋势的总结为相关领域研究人员提供一个全面的参考以及探索的方向。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwXEwzHsBiay1ZzFhcog_ji80ZwJA5rwarU_2EsUIPAGHzh5gLJs-z31-PeYj_PUh2zi97lt44-iTXSH4Aujow0ADyhw8XrGBusx6j0doi7PCMFBuX1IH2Fhp1aGu972MxL3bTv0t5M7THdYcaKH-kEo3lWWuWE_DCwnkxPCTCcrFlX1i3FE5MwoNe1Jqnl58I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的金枪鱼生物信息智能化识别研究
{Author}: 欧利国
{Tertiary Author}: 刘必林;陈新军
{Publisher}: 上海海洋大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 金枪鱼;生物信息;机器学习;深度学习;卷积神经网络;智能化识别
{Abstract}: 金枪鱼资源是我国远洋渔业生产的重要组成部分。目前,我国金枪鱼渔业其海上捕捞的金枪鱼物种仍然是人工分类,这是一个耗时且低效的过程,因此我国金枪鱼渔业管理需要向智能化发展。金枪鱼物种智能化识别在渔业生产和渔业资源评估中具有极其重要的意义,它有助于金枪鱼渔船的智能监控和建立电子观察员系统。由于生物信息是金枪鱼识别最重要的特征,因此,本文以远洋渔业极为重要的经济鱼种金枪鱼为研究对象,进行生物信息的自动化获取和智能化识别,构建基于计算机视觉的金枪鱼生物信息识别的智能化体系,以期为金枪鱼渔业管理智能化发展奠定基础。主要研究结果如下:(1)金枪鱼属鱼类形态指标自动测量分析。本文通过计算机视觉库Open CV对3种金枪鱼类图像进行预处理,利用双边滤波、灰度变换、二值处理和提取轮廓等图像处理技术得到金枪鱼类形态轮廓图像。根据预先选定的特征点,利用计算机视觉技术遍历轮廓图像上所有的像素点,并自动定位出每张轮廓图像的预选特征点共17个。利用计算机视觉技术遍历得到的特征点位置,自动测量出3种金枪鱼的形态指标像素长度,并计算出形态指标实际长度。并对比分析自动测量与人工测量形态指标的绝对误差和相对误差。研究结果表明,通过计算机视觉技术对3种金枪鱼的形态指标的自动测量效果较好,大眼金枪鱼、黄鳍金枪鱼和长鳍金枪鱼的12个形态指标的绝对误差范围分别为0.00～1.46、0.00～1.73、0.00～1.32,其相对误差范围分别为0.01%～5.84%、0.00%～6.17%、0.00%～6.89%。利用金枪鱼形态指标的KNN算法识别。本文通过自动测量得到形态指标,并分析3种金枪鱼的识别效果。在这项研究中,提出了一种基于KNN算法的金枪鱼属鱼类的形态指标的识别方法。将数据集分3种数据集,分别为全部形态指标,鱼体形态指标和鱼鳍形态指标。实验结果表明,在KNN算法的性能分析中鱼鳍形态指标均为最佳。在评估指标分析中,其鱼鳍形态指标的平均性能最好为0.90。AUC值的平均性能也是鱼鳍形态指标最高为0.951。在混淆矩阵的识别精度,鱼鳍形态指标的平均性能为90%,其大眼金枪鱼为95%、黄鳍金枪鱼为95%和长鳍金枪鱼为80%。通过对形态指标进行不同类型的划分能更好的研究金枪鱼的生物多样。(2)计算机视觉的椭圆傅里叶变换对金枪鱼形态轮廓信息进行分析。形态轮廓特征的提取效果直接影响到自动识别金枪鱼的精度,因此,为了研究计算机视觉对金枪鱼形态轮廓特征的自动提取效果,根据大眼金枪鱼的二维图像进行计算机视觉分析。通过对金枪鱼图像进行灰度转换,双边滤波,二值化图像处理和轮廓提取等图像处理。利用8个方位的链码技术对金枪鱼轮廓进行链码信息的自动提取。通过椭圆傅里叶变换计算出形态信息系数,并对金枪鱼形态进行轮廓重建。研究结果表明,自动提取金枪鱼形态轮廓特征效果较好。金枪鱼形态系数在低谐次变化波动较大,在高谐次变化波动较小。轮廓重建在低谐次变换对金枪鱼整体轮廓信息影响较大,在高谐次变换对金枪鱼局部轮廓信息影响较大。利用卷积神经网络VGG16对金枪鱼形态轮廓信息进行分析。鱼类形态变化多样,其形态轮廓特征具有种的特异性,并作为鱼类识别的重要科学依据。因此,为了分析卷积神经网络对金枪鱼的形态轮廓信息提取效果,利用大眼金枪鱼图像进行分析。通过计算机视觉的图像处理技术得到金枪鱼形态轮廓图像。可视化第一层卷积层的特征图,并进一步平均可视化所有卷积层和池化层的金枪鱼形态轮廓图像。提取深度特征数据,对深度特征数据进行主成分分析和绘制箱线图。研究结果表明,第一层卷积层的不同特征图能很好的获取金枪鱼形态轮廓信息。平均可视化所有卷积层和池化层的金枪鱼形态轮廓图像发现卷积神经网络能对金枪鱼形态轮廓信息进行有效提取。主成分分析表明金枪鱼形态轮廓信息提取效果较好,PC1到PC10的累计贡献率为82%。利用不同机器学习算法对金枪鱼的形态轮廓特征进行识别。形态特征是识别金枪鱼的最重要的特征之一,因此,本研究旨在通过形态特征验证3种金枪鱼的自动化识别效果。在这项研究中,提出了一种基于不同机器学习算法的金枪鱼属鱼类的形态特征的自动化识别方法。首先,通过椭圆傅里叶变换和卷积神经网络对形态轮廓进行可视化分析。然后,提取金枪鱼轮廓图像的椭圆傅里叶变换特征数据和深度特征数据,将两种不同形态特征进行主成分析。最后,利用不同机器学习算法分析同属不同种金枪鱼的识别性能。实验结果表明,椭圆傅里叶变换特征在KNN识别精度最高,大眼金枪鱼为90%,黄鳍金枪鱼为90%和长鳍金枪鱼为85%。深度特征在SVM识别性能最好,大眼金枪鱼为80%,黄鳍金枪鱼为90%和长鳍为100%。在形态识别上深度特征优于椭圆傅里叶变换特征。通过两种不同形态特征能很好的分析金枪鱼属鱼类的生物多样性和属间差异。(3)计算机视觉的灰度共生矩阵对金枪鱼的表型纹理信息进行量化分析。本文通过计算机视觉对3种金枪鱼图像进行预先定位基准点,通过移动基准点确定纹理特征区域并自动截取。对纹理图像进行灰度转换和灰度量化处理,量化的灰度图像进行灰度共生矩阵计算,并对灰度共生矩阵进行归一化处理。通过归一化的灰度共生矩阵计算出6个纹理指标,并分析纹理指标的距离和方向的变化趋势,通过因子分析研究金枪鱼纹理指标。研究结果表明,通过计算机视觉的纹理分析,3种金枪鱼纹理指标提取效果较好,其纹理指标在距离值为4时,变化趋势趋于稳定,而3种金枪鱼的纹理指标方向变化,其均值方向具有代表性。3种金枪鱼的因子分析,第1主成分贡献率为81.10%,表明提取的6个纹理指标意义较大且效果较好。通过卷积神经网络VGG16对金枪鱼的表型纹理进行可视化和信息提取。本文通过卷积神经网络对于3种金枪鱼的表型纹理进行量化分析。通过可视化第一层卷积层的表型纹理信息,再可视化每个卷积块的第一个和最后一个卷积层,最后可视化所有池化层。提取表型纹理的深度特征数据,并进行主成分分析和绘制箱线图。实验结果表明,初次卷积能很好的获取表型纹理信息。不同卷积块的卷积层和池化层获取的表型纹理效果较好,其变化过程从具体到抽象。主成分分析表明3种金枪鱼的表型纹理信息提取效果较好,大眼金枪鱼PC1为52%,黄鳍金枪鱼PC1为48%,长鳍金枪鱼PC1为40%。利用不同核函数的SVM算法对金枪鱼表型纹理进行分类。本研究利用灰度共生矩阵和VGG16对3种金枪鱼的局部表型纹理图像进行了可视化。通过表型纹理图像获取纹理特征指标数据、深度特征数据及其组合特征数据。利用不同核函数的SVM对金枪鱼的表型纹理进行自动分类。研究表明,灰度共生矩阵和VGG16可视化不同金枪鱼的表型纹理图像具有生物特异性,而对不同数据集可视化分析表明,数据分布具有明显的属间差异和生物特异性。在无交叉验证的分类结果中,纹理特征指标数据集在多项式核函数中的平均分类精度为83%,深度特征数据集在RBF核函数中的平均分类精度为93%,组合特征数据集在RBF核函数中的平均分类精度为95%。在交叉验证的分类结果中,不同数据集在不同核函数上与无交叉验证的结果类似,但精度略低,纹理特征指标数据集在多项式核函数的精度为83%,深度特征数据集在RBF核函数的精度为88%,组合特征数据集在RBF核函数的精度为89%。结果表明,利用不同核函数的SVM可以有效地对金枪鱼表型纹理进行分类。(4)本研究采用深度卷积神经网络作为一种智能、实时、无损的方法,将其应用于四种经济重要的金枪鱼种大眼金枪鱼、黄鳍金枪鱼,长鳍金枪鱼和鲣鱼的智能识别。实验结果表明:不同CNN对金枪鱼(整体和部分)的识别分析存在差异。VGGNet,ResNet和MobileNet进行对比分析,VGGNet性能最佳。VGGNet的可视化解释能很好分析金枪鱼种间的生物信息的特异性差异。VGGNet的评估指标和混淆矩阵性能平均都为97%。因此,该方法对金枪鱼物种具有很好的识别性能,将为金枪鱼渔业的电子监控系统的建立奠定基础。
{URL}: https://link.cnki.net/doi/10.27314/d.cnki.gsscu.2023.000004
{DOI}: 10.27314/d.cnki.gsscu.2023.000004
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 农作物害虫图像智能检测算法研究
{Author}: 董士风
{Tertiary Author}: 王儒敬
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 深度学习;计算机视觉;农作物害虫检测;小目标检测;多尺度目标检测;相似目标检测
{Abstract}: 害虫综合防治是保持农作物高量生产的一项重要措施,也是智能植保的重要组成部分。目前,为了提高植保人员的工作效率和减少人为带来的客观判断,基于视觉的农作物害虫自动识别和检测技术被广泛应用。随着人工智能的发展,通用目标检测任务取得了巨大的成功。研究人员将其应用于农作物害虫检测,近年来也成为计算机视觉领域的热门课题。然而在实际应用中农作物害虫图像识别与检测仍存在严峻的挑战,农作物害虫图像存在小尺度,多尺度,外观相似度高等难点导致检测精度不理想。针对害虫图像检测面临的主要难点,本文主要从农作物害虫尺度小、多尺度农作物害虫、农作物害虫类间外观差异小、提高检测速度四个方面展开检测算法研究。本文主要工作总结如下:1.提出一种基于通道重校准特征金字塔网络的害虫检测方法。由于小尺度目标所占像素少,导致表征信息不足,因此在训练过程中较难学习到有效的特征。针对小尺度害虫检测精度低的问题,提出了通道重校准的特征金字塔网络和自适应锚框模块两个关键组件。通道重校准的特征金字塔网络可以捕获判别特征,学习更精细的对象特征,显著提高了对小目标害虫的识别精度,而自适应锚框模块用于纠正小尺寸害虫容易存在锚框和真实标注框匹配效率不高的问题。这有效地减少了小尺度害虫的搜索范围,提高了网络在回归边界框时的准确性。通过在LMPD2020数据集上充分的对比实验证明了本文的方法取得了同期最佳的检测结果。2.提出了基于尺度感知网络的害虫检测方法。针对多尺度农作物害虫精准检测的问题,所提出方法由三个关键组件组成,即高层语义特征提取模块、低层特征增强模块和动态尺度感知头网络。高层语义特征提取模块可以保留高层特征的丰富信息并帮助构建特征金字塔网络。低层特征增强模块可以优化低级别的综合特征图,提供更精细的特征信息。此外,动态尺度感知检测头网络可以根据不同的物体尺度,自适应地选择合适的检测感受野,从而提高对于多尺度目标的检测性能。通过在APHID-4K和LMPD2020数据集上的对比实验结果表明,本文的方法取得同期最佳的检测结果。3.提出了基于辨识性特征融合的害虫检测网络。在农作物害虫图像检测的任务中,需要区分这些目标害虫的具体类别。同时,属于同一科的害虫在外形上高度相似,通常需要有专业知识的植保工作者才能精准辨识。针对害虫类间外观差异小的问题,本文提出的辨识性特征融合的害虫检测网络首先利用多尺度辨识性特征融合金字塔,通过自适应通道融合模块和全局上下文模块融合多尺度特征中的害虫信息。同时,设计了一种自适应特征区域建议网络,通过解决了区域推荐网络迭代时锚框和特征不对齐的问题,更加精准地提取害虫的显著性区域特征。在LMPD2020数据集上大量的实验表明,本文的方法取得了优异的检测性能。4.提出了基于注意力的单阶段害虫检测网络。针对农作物害虫检测在实际应用中对检测模型效率要求较高,在保证精度的条件下,降低模型时间复杂度。所提模型在训练阶段使用动态训练样本选择算法,选择高质量的正样本以提高模型训练的质量,动态捕捉包含多尺度背景信息的高质量训练样本,同时减少小尺度目标容易导致的假阳性样本问题。其次,从增强网络特征表达角度考虑,提出了一个融合注意力的动态检测头网络,提取用于定位和区分害虫对象的高代表性语义特征。通过在CropPest24和MPD2018数据集上大量的对比实验表明,本文的方法在保证精度的同时还具有较低的模型复杂度,并取得同期最好的检测结果。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001051
{DOI}: 10.27517/d.cnki.gzkju.2023.001051
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于时空深度学习的视觉目标跟踪算法研究
{Author}: 吴瑞旭
{Tertiary Author}: 温显斌
{Publisher}: 天津理工大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 深度学习;视觉跟踪;时空方法;孪生神经网络;注意力机制;Transformer结构
{Abstract}: 目标跟踪是指给定目标的一个初始状态,然后在视频序列中估计每一时刻的状态。在视频监控,自动驾驶,军事、人机交互等方面有着广泛的应用价值。但由于它面临遮挡、形变、旋转、尺度变化等诸多挑战性问题,所以引起众多学者的高度关注,是计算机视觉领域前沿研究热点。近年来,基于深度学习的视觉跟踪理论研究取得一定进展,这些成果尽管在准确性、实时性以及鲁棒性上都取得了不错的成绩,但是还存在着诸如时间信息特征被忽视、注意力机制以及Transformer结构不够完善、模型网络的局部和全局特征缺乏结合、在线跟踪鲁棒性不佳等问题。为此,本文基于孪生网络的框架,在时空维度下利用卷积神经网络和注意力机制对目标跟踪理论与算法进行深入研究,取得以下创新性成果:一、提出了基于时空和注意力的孪生网络视觉跟踪方法。该算法以孪生区域建议网络为基准结构,将主干网络原有的二维卷积神经网络改进为三维结构,这样可以增加时间维度,能够提取连续视频的运动信息,解决了时间特征容易被忽视的问题。为了使重要的时空信息得到突出,该算法采用了联合注意力模块,分别对空间、通道以及时间的显著特征进行增强,达到背景抑制和前景突出的作用。该方法通过注意力机制使算法模型更完善。二、提出了基于双注意力的Transformer时空融合视觉跟踪方法。首先,区别于以往只使用卷积神经网络的跟踪器,该算法除主干网络使用三维卷积提取时空信息外,在孪生网络框架内引入了Transformer,构造了双注意力时空融合Transformer模块,建立了全局长距离的非线性联系,捕获更多的目标背景相关信息。然后,为了使Transformer能够适应这种时空性质的跟踪,该算法改进了Transformer结构,通过时间注意力模块建立多帧间的特征图联系,获取时间运动信息;同时,通过空间注意力模块计算模板与搜索特征之间的相关性,区分前景与背景。最后,通过堆叠3个尺度的双注意力时空融合Transformer模块,并通过融合层将时空信息进行叠加,有效地融合了局部到全局的特征信息。该算法动态更新了部分模板,在以首帧模版为主体的前提下,增加更新变化,解决了只使用模版初始帧或动态帧导致的鲁棒性欠佳的问题。三、提出了基于Transformer的时空关键区域视觉跟踪方法。针对Transformer输入序列全局计算效率低下,既不能有效关注重要序列,也不能有效聚焦关键目标区域问题,首先,该算法构造了基于Transformer的关键区域提取模块,以此精炼模板和搜索特征序列,选择具有高响应值的少量序列,并通过互相关计算区分目标与背景。然后,为了减少参数量,算法直接使用Transformer作为主干网络去提取多帧视频特征,并将特征图叠加融合时空信息。最后,为了提升边界框估计的准确度,设计了中心角点预测方法,减轻了边缘无关信息的干扰。四、提出了可变形Transformer和时空的视觉跟踪方法。针对初始Transformer存在结构特征冗余、易受感兴趣区域外无关信息的影响、忽视局部和全局特征的融合、以及缺乏时空信息提取等问题。首先,该算法引入可变形注意力模块,该模块以数据依赖的方式选择序列的对应位置,可以获取更多有效特征并减少冗余。然后,构造包含模板和搜索两个分支的孪生网络跟踪器,模版分支通过二维卷积神经网络提取特征,并通过自注意力模块建立非线性全局联系;搜索分支则通过三维卷积神经网络提取时空特征,并通过时空融合模块,使重要的时空信息得以突出。最后,将模版和搜索分支特征再通过交叉注意力模块进行互相关计算,建立目标与背景的相关联系。由于该算法将卷积神经网络与Transformer同时使用,不仅使网络模型具有局部性,也具有全局性、时空性,而且更新了Transformer结构。另外,本文将所提出的方法在公认的公开数据集上进行实验评估分析,并与当前优秀的算法进行定量、定性比较分析,通过分析实验结果,可以发现本文提出的方法是有效的,它们有效地缓解上述关键性问题,并提升视觉目标跟踪算法的整体性能,做到实时跟踪。
{URL}: https://link.cnki.net/doi/10.27360/d.cnki.gtlgy.2023.000698
{DOI}: 10.27360/d.cnki.gtlgy.2023.000698
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于伪标签的弱监督语义分割研究
{Author}: 汝理想
{Tertiary Author}: 杜博;武辰
{Publisher}: 武汉大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 弱监督语义分割;伪标签;类别激活图;语义分割;计算机视觉
{Abstract}: 图像语义分割是计算机视觉领域中的重要研究话题之一,在例如自动驾驶、遥感图像分析、医学图像分析等多个实际场景中也都有广泛的应用。随着深度学习技术的发展,基于深度模型的方法在语义分割领域中逐渐占据了主导地位。然而,深度语义分割模型的训练往往需要大量的像素级标注样本,其中的标注过程需要昂贵的时间和人力投入。为了降低语义分割任务的标注成本,近年来,有研究提出基于更容易获得的图像级标注进行弱监督语义分割,并取得了显著的进展。然而,该领域中仍存在着一系列难点问题,包括初始伪标签精度较低、多阶段训练框架的模型复杂度高、基础网络结构的局限性等。为解决以上问题,提升弱监督语义分割结果的精度,论文基于类别激活图生成像素级伪标签监督信息,从视觉词汇学习、语义关系学习和表征对比学习等方面出发,对基于图像级标签的弱监督语义分割展开了研究。论文的主要研究内容包括:(1)针对初始伪标签精度较低的问题,论文提出一种基于视觉词汇学习和混合池化方法的弱监督语义分割方法。该方法设计了视觉词汇学习模块对网络提取的特征图进行编码,得到细粒度的局部视觉词汇标签,用于对网络的训练过程进行辅助监督,以促使网络发现更完整的物体区域,从而提升初始伪标签的精度。同时,该方法提出了基于学习和基于记忆的两种策略,分别通过梯度回传和在线重建的方法对视觉词汇学习模块进行更新。在混合池化模块中,提出的方法基于多尺度局部最大池化进行特征图聚合,在保证了图像中物体特征信息完整性的同时,尽可能地减少了背景信息的干扰。最后,使用所提出的方法生成初始伪标签,再经过多阶段弱监督语义分割框架的处理后,可以明显提升最终的语义分割结果。(2)多阶段框架仍存在模型复杂度高、训练效率较低的问题。为解决该问题,论文提出一种基于语义关系学习的端到端弱监督语义分割方法。首先,该方法基于Vision Transformer(ViT)结构对全局特征关联进行建模,以生成更准确的初始伪标签。然后,受ViT中自注意力矩阵和像素级语义关系的一致性启发,该方法进一步提出从ViT的自注意力矩阵中学习高置信度的语义关系,并用于对初始伪标签进行修正。为补全伪标签的局部细节信息,该方法设计了一个像素自适应修正模块,基于邻域像素的底层信息对伪标签进行自适应高效修正。最终的伪标签被用于监督分割解码器,从而实现了端到端的训练。该方法能明显地提高训练效率,并取得良好的语义分割结果。(3)ViT网络在深层时会出现表征过平滑的问题。为解决该问题,论文提出了基于表征对比的弱监督语义分割方法。首先,由于ViT的中间层表征能保持较好的语义多样性,该方法提出基于中间层表征得到高置信度的表征关系伪标签,用于对深层表征之间的相似度进行监督,以解决过平滑问题,并帮助生成高质量的伪标签。同时,为进一步利用ViT结构的特性,该方法提出了一个表征对比模块,通过将局部区域与全局图像的类别表征进行对比,促进物体区域表征的局部-整体一致性,并增大前景-背景区域之间的可分性,从而提升初始伪标签的精度。最终,所提出的方法能够有效地解决ViT的过平滑问题,并明显地提升端到端弱监督语义分割的精度。综上,论文提出了一系列的弱监督语义分割方法,有效地缓解了伪标签、训练框架和基础网络的问题,显著提高了弱监督语义分割的精度和训练效率。
{URL}: https://link.cnki.net/doi/10.27379/d.cnki.gwhdu.2023.000151
{DOI}: 10.27379/d.cnki.gwhdu.2023.000151
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于低光照图像增强的车牌识别系统研究
{Author}: 胡聪
{Tertiary Author}: 陈绪君
{Publisher}: 华中师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 图像增强;半波注意力机制;MS-SSIM损失函数;目标检测;车牌识别系统
{Abstract}: 近年来智慧交通领域获得了高速发展,基于车牌识别的交通控制系统已广泛应用于停车收费管理、车辆定位、车流监控和超速自动检测等诸多领域。基于车牌识别的应用研究一直是智慧城市管理领域的研究热点问题。然而,目前智慧交通控制系统仍存有不足:1)基于计算机视觉的车牌检测与识别算法在拍摄良好的图像或者视频上容易取得好的检测和识别效果,由于环境和技术等因素的限制,车牌图像在背光、不均匀光照和昏暗等条件下,车牌检测与识别精度较低、容易出现漏检、误检等现象。2)传统车牌检测与识别算法存在推理速度慢,通用性差等情况。
为解决上述问题,论文围绕低光照图像增强算法,车牌检测与车牌识别算法展开研究。针对当前基于深度学习的低光照图像增强算法存在模型参数大、复原质量不高的情况,在轻量级算法的基础上提出了融合半波注意力模块的低光照图像增强算法。针对现有目标检测算法存在小目标检测精度低,收敛速度慢等问题,对目标检测算法损失函数进行优化,提升模型收敛速度与检测精度。此外,论文设计了一种基于低光照图像增强的夜间车牌识别系统,可以满足夜间车牌检测的实时性与精确度要求。论文从低光照图像复原、车牌区域定位与车牌字符识别等方面展开研究,主要研究内容如下:
(1)针对当前基于卷积神经网络的低光照图像增强算法普遍存在模型参数过大、内存消耗高、图像复原质量不佳等问题,在轻量级算法IAT基础上,提出了融合半波注意力模块的低光照图像增强算法HBTNet。该改进措施改善了网络频繁卷积造成的空间信息损失,通过在网络中引入半波注意力模块,可有效获得小波域特性,丰富了上下文信息,提高了特征提取能力。最后通过引入MS-SSIM损失函数来获取图像的边缘和细节信息,提升了图像恢复的质量。实验结果表明,在LOL数据集上HBTNet相较于IAT算法PSNR提升了2.69%,SSIM提升了5.56%。HBTNet算法的模型参数量仅为0.11M,可满足终端用户实时性要求。
(2)针对传统车牌识别算法模型存在精度低、复杂度高等问题,论文采用YOLOv5目标检测算法进行车牌检测,为了改进YOLOv5目标检测算法存在损失函数收敛过慢、小目标检测精度低等问题,论文选择EIOU损失函数作为YOLOv5的定位损失。实验结果表明,相较于原始GIOU定位损失函数,使用EIOU损失函数使得模型收敛速度更快,对车牌的检测精度提升了0.7%。
(3)针对低光照条件下存在车牌检测精度低、车牌漏检、误检等问题,论文首先对低光照图像进行增强,再将增强后的高质量图像送入优化后的模型进行车牌区域定位与车牌字符识别。实验结果表明,相较于原始低光照图像,增强后的图像车牌检测精度提升了4.8%,车牌识别准确率提升了47%。
(4)论文最后设计一个夜间车牌识别系统。系统功能包括用户管理、图像增强、车牌定位、车牌识别等功能。该系统可有效提升交通管理部门信息化管理水平。
{URL}: https://link.cnki.net/doi/10.27159/d.cnki.ghzsu.2023.001878
{DOI}: 10.27159/d.cnki.ghzsu.2023.001878
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的管道全位置焊接熔池检测技术研究
{Author}: 马晓锋
{Tertiary Author}: 王中任
{Publisher}: 湖北文理学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 管道全位置焊接;熔池形态;偏差测定;缺陷预测;PSPNet
{Abstract}: 焊接在石油化工领域发挥着重要作用,电弧焊接过程存在复杂的物理信息,其中熔池的动态行为直接影响焊缝成形,也决定了焊接过程的稳定性和焊接质量的优劣,但昂贵专业的熔池相机不利于施工现场推广。因此,本课题以全位置管道为研究对象进行焊接熔池动态行为检测,研究焊接偏差与熔池特征的关系,实时检测熔池表面形态,建立神经网络预测焊缝质量,以及熔池的动态跟踪,旨在优化焊接工艺、提高焊接质量以及降低人工作业负荷。首先,对增强去噪、语义分割方法以及深度学习模型评价指标的基础理论和技术进行分析,进行本文的实验方案的设计,对熔池动态行为检测系统进行硬件选型,根据光的不同波段,选取合理的光学镜片构建滤光系统,对熔池形态进行动态捕捉,对熔池图像进行标定和预处理,为后面图像处理提供基础,对熔池特征进行定义,进行全位置管道焊接熔池的力学现象分析,研究其各位置熔池成型特点,以及基于熔池拖尾角度,建立焊接偏差量测定模型。其次,对测定原理进行实验,处理流程为:引导滤波图像增强,大津算法提取电弧,图像相减,熔池边缘提取,拖尾采样点提取,梯度下降拟合,对焊接偏差进行测定与偏差预警。通过搭建的系统实时采集熔池图像,采用卷积神经网络提取形态特征,实现在焊接过程中,对气孔缺陷的预测,构建深度训练模型,实时熔池图像作为输入,由网络进行充分的学习分类并进一步建立熔池图像和气孔缺陷的关系模型,对焊接缺陷进行预测,及时调节工艺参数。最后,利用改进生成对抗网络(GAN),对焊接过程中熔池图像去噪和增强,解决因保护气、弧光导致的图像模糊等现象,为熔池跟踪提供图像基础。利用改进PSPNet模型的熔池动态分割方法,通过构造多层信息提取网络结构、空洞卷积大视野的获取全局信息,修改激活函数等方面予以改进,实现对熔池的动态跟踪与精准检测。开发了一套集成图像采集控制、系统标定、图像处理、缺陷预测以及熔池动态跟踪等功能为一体的上位机熔池可视化检测软件,并为了验证焊接熔池视觉检测系统的功能及稳定性,搭建了检测系统平台,进行焊接实验与结果分析。本课题提出的方法能够实时检测熔池,重点在于实现了基于熔池动态行为的实时跟踪、焊接偏差预警、熔池行为监测、预测焊接气孔缺陷等,使得能及时调节工艺参数,本系统控制了自动焊接设备成本,在石油化工领域具有良好的应用前景。
{URL}: https://link.cnki.net/doi/10.44305/d.cnki.ghbwl.2023.000079
{DOI}: 10.44305/d.cnki.ghbwl.2023.000079
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Vision Transformer的目标检测研究
{Author}: 姚顺禹
{Tertiary Author}: 綦科
{Publisher}: 广州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;ViTs;局部增强;通道注意力;特征金字塔网络
{Abstract}: 目标检测是计算机视觉中的基本任务之一,旨在对图像中的目标进行定位和识别。卷积神经网络(CNN)一直长期以来主导着计算机视觉任务,例如分类、目标检测和实例分割,但近年来,Vision Transformer(ViT)在计算机视觉领域不同任务中都表现出了令人鼓舞的性能。ViT中的Transformer模块依靠自注意力机制可以捕获patch间的远程依赖关系(即全局上下文),并且得益于形状偏置,它们能够专注于图像的重要部分。但是,自注意力机制可能会忽略每个Patch中的结构信息和局部关系,这也会产生图像尺寸输入大小平方的计算复杂度。这是ViT的不足,但是相反,虽然CNN有限的感受野使其自身难以捕获到全局依赖性,但是可以通过在小邻域内通过卷积来有效地减少局部冗余,利用平移不变性的局部连通性,对图像中的每个Patch都由相同的权重处理,这种归纳偏置促使CNN在对视觉目标进行分类时对纹理而非形状具有更强的依赖性。因此,本文对目标检测模型结构中基于ViT的主干网络以及基于FPN的颈部结构提出了改进,以提升基于ViT的目标检测模型的性能。本文的贡献总结如下:(1)提出了一个由多组卷积和激活函数组成的局部增强模块,以弥补ViTs在提取特征时出现的缺乏全面信息的问题,从而使卷积和Transformer模块可以实现优势互补。其次,引入通道注意力模块来捕捉在自注意力计算过程中对通道进行频繁操作而产生的通道信息。然后,使用池化层来替换某些使用自注意力模块的Transformer块,减少了部分自注意力机制所带来的高昂算力需求。再者,单一的Transformer模块缺乏跨窗口的相关性,为了在保持非重叠窗口高效计算的同时,引入跨窗口连接。接着设计了一种交替策略,该策略在连续的Transformer块中交替使用三种配置。最后通过使用卷积位置编码,避免了传统位置编码中绝对位置编码缺乏移动性和可重用性、相对位置编码由于自注意力的修改而效果不佳的问题。实验证明,在没有进行预训练的情况下,本文提出的主干网络在COCO目标检测数据集上实现40.3 box AP和37.1 mask AP,在类似的FLOPs与参数设置下,分别超过了Res Net-50 10.0的box mAP以及7.0,CSwin-T 1.8的box mAP以及1.2的mask mAP。(2)设计了一种基于FPN的颈部结构:AFPN,来配合上文新设计的主干网络,利用来自多级特征图的语义信息来丰富高分辨率和局部注意力特征,进一步增加不同场景下模型的适用率。实验使用了与主干网络相同的测试评价指标和训练设置,通过不同的主干网络与AFPN以及FPN的结合分析出,AFPN较FPN有着一定程度的提升。
{URL}: https://link.cnki.net/doi/10.27040/d.cnki.ggzdu.2023.001484
{DOI}: 10.27040/d.cnki.ggzdu.2023.001484
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的工业零件缺陷检测
{Author}: 陈齐航
{Tertiary Author}: 蒋学芹;朱亚东
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;缺陷检测;监督学习;无监督学习;语义分割
{Abstract}: 在工业产品的生产过程中,由于生产设备老化、原材料不合格以及生产工艺落后等原因,部分产品出现缺陷难以避免,这些缺陷品可能无法满足产品所要求的功能特性。为了保证产品的合格率以及质量,对产品进行缺陷检测是至关重要的一个步骤,人工检测以及传统的机器学习方法有诸多弊端,例如成本高、效率低以及稳定性差等。随着计算机技术的不断发展,深度学习、计算机视觉等技术在工业领域的应用也越来越多,但目前大多数的方法仅采用卷积神经网络(Convolutional Neural Network,CNN)结构,无法很好地利用到全局信息。此外,目前大多数的方法都基于监督学习实现,而工业产品缺陷的数据集往往存在严重的不均衡情况,极端情况下更是仅有无缺陷数据,在这种情况下难以通过基于监督学习的方式进行缺陷检测。基于此现状,本文提出了两种基于深度学习的缺陷检测算法,用于工业场景下的缺陷检测,研究内容主要有以下两点:(1)本文提出一种基于监督学习的缺陷检测算法。该算法通过融合模块将CNN与Transformer提取到的特征进行融合,结合了二者的优点,使模型在关注局部信息的同时也可以很好地捕获远程的依赖关系,解决了当前大部分算法无法很好利用全局信息的问题,并在实验中表现出良好的性能。(2)本文提出一种基于无监督学习的缺陷检测算法。该算法基于图像重建的思想,利用Masked Autoencoder(MAE)对缺陷处的图像块进行重建,将图像块修复成无缺陷形态,并通过对比重建前后的图像的结构相似性来进行缺陷定位。该算法基于无监督学习来实现,无需使用带标注的缺陷数据,实现了在数据集严重不均衡的场景下的缺陷检测,并在实验中表现出了良好的性能。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2023.001045
{DOI}: 10.27012/d.cnki.gdhuu.2023.001045
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 结合YOLOv5神经网络轻量化改进的视觉SLAM算法研究
{Author}: 王钰祺
{Tertiary Author}: 李丽娜
{Publisher}: 辽宁大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: SLAM;目标检测;语义信息;YOLOv5
{Abstract}: 随着机器人应用领域的不断拓宽,在许多应用场景中,机器人需要在未知环境中移动并感知其周围的环境,这里需要的信息主要包括两个方面:机器人的位置和周围环境的观测点,这种同步定位与建图技术被称为SLAM技术。其中视觉SLAM技术成为了重要的发展方向,视觉SLAM技术成本更低、精度更高,且不依赖于特定的传感器,这使其在无人驾驶、机器人巡逻、机器人救援等领域得到了广泛的应用。目前比较成熟的开源SLAM系统都是以静态环境为前提建立的,所以在存在动态物体的环境中,特别是运动物体的纹理明显且占有较大图像区域的情况下,定位与建图的结果往往不具备实际应用的条件,并且虽然视觉SLAM技术目前有着广泛的研究与应用,但是无法为更高级人机交互提供必要信息。基于以上两点急需解决的问题,与深度学习相结合的视觉SLAM走入了人们的视野中。因此,进一步探究面向动态环境的具有更强的鲁棒性、适应性及实用性的视觉SLAM框架和算法具有重要的现实意义。鉴于以上,本文以存在动态物体的室内环境为研究背景,以RGBD摄像头为输入设备,开展了相关的视觉SLAM算法研究。首先,针对存在动态物体的实际环境,设计可以应用于SLAM系统的轻量型神经网络用于目标检测,在保证一定运行速度的前提下尽可能提高检测精准度;其次,设计筛选流程对检测物体进行动静判断;最后,利用目标检测与语义分割技术为SLAM地图添加语义信息。根据上述分析,本文从以下几个方面开展研究:1.针对SLAM技术的实时性需求,使用YOLOv5神经网络结构与Rep VGG神经网络相结合的轻量型神经网络模型,以实现快速地目标检测流程。2.对于动静点判断问题中的不准确情况,提出了将光流法与GMS算法相结合的动态物体或动态特征点的去除算法,有效提高了特征匹配的准确性,为准确位姿估计奠定了基础。3.针对SLAM无法为更高级人机交互提供有利信息的问题,将目标检测范围内特征点的语义信息提取加入建图线程,完成SLAM地图的框注,并且在实时关键帧选择完成后加入语义分割模块,展示实时语义信息。4.针对上述设计进行实验验证,首先对本文设计的目标检测网络和语义分割网络的应用精度进行检测,对训练精度以及相应数据集的检测结果进行分析,证实其准确性可以达到实时应用精度;其次,以TUM动态数据集为数据源对动态特征点的识别进行实验测试,证明光流法与GMS算法相结合可以有效的识别动态特征点;最后,应用TUM动态数据集进行动态环境下的运动主体位姿估计以及实时语义线程验证,证明实际应用可以达到预期效果。
{URL}: https://link.cnki.net/doi/10.27209/d.cnki.glniu.2023.000613
{DOI}: 10.27209/d.cnki.glniu.2023.000613
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进高分辨率网络的人体姿态估计算法研究
{Author}: 毋宁
{Tertiary Author}: 王鹏
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;人体姿态估计;高分辨率网络;注意力机制;轻量化
{Abstract}: 科技创新推动着社会生活不断的发展前进,人工智能使得人类的生产生活方便快捷。计算机视觉技术的出现更是加速了人工智能领域的发展,作为其重要分支之一的人体姿态估计技术,目前已在医疗、交通、军事等各个领域有着广泛的应用。在军事装备的智能化发展中,人体姿态估计算法为战场态势感知、实时精准打击提供了一定的技术支持。展开人体姿态估计算法的研究,对于军事行动指挥、国防安全保障有着重要的意义。但由于军事环境复杂,存在背景干扰、多尺度干扰以及关键点遮挡等众多影响,导致军事环境下的人体姿态估计算法仍存在检测效率低等问题。因此,本文以高分辨率网络HRNet为基础,展开了基于改进高分辨率网络的人体姿态估计算法研究,旨在提升人体姿态估计算法的精度与速率,实现军事装备的高效智能化。本文主要研究内容如下。(1)针对复杂背景及多尺度场景下人体关键点特征提取不够充分的问题,本文提出了一种融入双注意力机制的人体关键点特征提取网络。首先,为提升多尺度场景下人体姿态估计算法的特征获取能力,在此引入金字塔切分注意力模块(EPSA),用来改善网络对多尺度信息的获取能力,并在下采样时引入EPSA模块,避免网络在下采样过程中易造成信息丢失的问题;其次,为增强复杂场景下人体姿态估计网络对关键点位置信息的获取能力,结合位置注意力机制(CA)增强网络对位置特征的提取能力,保证对人体关键点位置信息的充分提取。实验表明本章构建的网络可充分获取图像中的多尺度特征信息,并能从复杂背景中有效提取人体关键点的位置信息,有效增强了姿态估计网络的人体关节点特征提取能力。(2)针对遮挡人体关键点检测效果差的问题,本文提出了一种基于热图的人体关键点回归优化算法。首先,针对上采样时特征损失较多会导致遮挡关键点特征缺少的问题,采用轻量级上采样模块(CARAFE)改进原有的最邻近插值上采样方式,减少上采样过程中的信息损失;其次,针对关键点热图回归时存在的特征信息融合不够充分,会导致遮挡关键点预测信息不足的问题,设计了一种改进的特征融合模块,以实现不同分辨率下特征信息的充分融合,为关键点位置回归提供更多参考信息;最后,针对关键点热图输出存在多个峰值导致的遮挡关键点回归位置不够准确的问题,结合高斯滤波优化热图输出,使得最终能输出精确的关键点位置。结果表明本章网络有效改善了遮挡关键点的检测效果,提高了模型的检测精度,实现了复杂多尺度场景下遮挡关键点的精确定位,具有较优的检测精度和较强的模型泛化能力。(3)针对网络结构复杂,模型参数量多、体积庞大影响人体姿态估计网络高效检测的问题,本文提出了一种轻量化的人体姿态估计算法。首先,构建了基于Ghost卷积模块轻量化的人体姿态估计网络,结合Ghost卷积模块改进常规卷积,大幅减少网络的参数量与运算量;其次,提出了基于改进HRNet网络模型的自适应剪枝算法,主要对卷积网络各个神经元之间存在的冗余链接进行模型剪枝,根据权重对冗余链接及不重要的神经元进行剪枝,在保证模型检测精度的基础上,压缩模型体积,提升模型的检测效率。最终通过实验验证了本文提出的基于改进高分辨率网络的人体姿态估计算法的有效性。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2023.000418
{DOI}: 10.27391/d.cnki.gxagu.2023.000418
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉路面识别的自动紧急制动策略研究
{Author}: 禚凇瑀
{Tertiary Author}: 赵健
{Publisher}: 吉林大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 智能汽车;自动紧急制动策略;路面状态识别;分级制动;语义分割
{Abstract}: 自动紧急制动系统是一种典型的智能驾驶辅助系统,能够提前警示驾驶员制动,并在必要时自动制动,防止碰撞发生或最大限度降低碰撞伤害。然而目前的自动紧急制动系统设计模式单一,忽略了路面状态的影响,无法适应不同路面的差异,降低了驾驶人对自动紧急制动系统的接受度和满意度。路面状态作为行驶过程的必要信息,对制定制动策略具有重要指导作用。因此,深入研究路面识别算法,有针对性地设计带有路面状态识别的自动紧急制动策略,是自动紧急制动系统的研究方向,也是自动紧急制动系统大规模应用和扩展的必要环节。本文依托吉林省自然科学基金(编号:20210101057JC),开展基于机器视觉路面识别的自动紧急制动策略研究。搭建实车驾驶数据采集平台,采集包含路面状态的驾驶场景图片,构建驾驶场景数据集,采用语义分割算法识别包含路面状态的驾驶场景;建立路面类型与附着系数的对应关系模型,设计基于语义分割结果的路面状态决策算法;面向安全性和舒适性要求,设计自动紧急制动策略;利用采集的真实图片数据对驾驶场景语义分割算法和路面状态决策算法进行测试;最后搭建Python-Matlab/SimulinkCar Sim联合仿真平台对基于路面状态识别的自动紧急制动策略进行试验验证。本文主要研究内容包括以下四部分:(1)驾驶场景数据采集与驾驶场景语义分割算法首先基于摄像头、上位机等软硬件,搭建实车驾驶数据采集平台,采集包含结构化和非结构化路面的驾驶场景数据。按照通用图像筛选原则对数据进行初步筛选处理。根据目标要求和收集数据类型,定义语义分割模型类别。最后设计了驾驶场景语义分割算法。(2)基于语义分割结果的路面状态决策算法构建路面类型和附着系数映射关系表格,得到路面类型与附着系数映射关系。利用语义分割结果,建立感兴趣区域(Region of Interest,ROI),在该区域内对路面类型进行统计,得到当前区域内的路面状态集合。利用建立的路面类型与附着系数对应关系,得到当前路面状态对应的附着系数集合。最后设计路面状态筛选规则,得到该状态下的路面附着系数。设计典型工况对路面状态决策算法进行离线仿真验证,结果表明该算法的有效性。(3)基于路面状态识别的自动紧急制动策略利用路面状态决策算法,得到当前路面附着系数。通过该路面的附着系数,生成了分级制动的自动紧急制动策略。采用PID控制算法完成制动减速度到主缸压力的转化,完成制动。该算法提升了不同路面条件下自动紧急制动系统的安全性并且提升交通环境的利用率。(4)试验验证与分析搭建测试验证平台,采用真实采集数据分别对语义分割算法和路面状态决策算法进行验证。按照欧盟新车安全评鉴协会(The European New Car Assessment Program,Euro-NCAP)标准,分别在不同工况下对自动紧急制动策略进行验证。搭建传输控制协议(Transmission Control Protocol,TCP),实现Python平台与Simulink之间通信。同时构建完成Simulink与Carsim平台通信。最后基于Python-Matlab/Simulink-Car Sim平台,对基于路面状态识别的自动紧急制动策略进行验证。结果证明基于路面状态识别的自动紧急制动策略的安全性,可靠性和可实现性。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2023.004287
{DOI}: 10.27162/d.cnki.gjlin.2023.004287
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的花生田间杂草识别与定位研究
{Author}: 王智
{Tertiary Author}: 张慧
{Publisher}: 河南农业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 杂草检测;精准农业;YOLOv4-Tiny;Real Sense空间定位
{Abstract}: 花生是我国重要的经济作物和粮食作物,在我国的油料生产中有着极高的地位。杂草控制是花生种植过程中的重要环节,合理地对花生田间的杂草进行处理,可以促使花生的高产与稳产。现有的杂草处理方法多为农户覆盖性的喷洒化学除草剂,这种方式不仅劳动强度大,同时也会因为农药的浪费,对农田造成不可逆的污染。目前,花生田间的杂草管理存在效率低下和农药大量浪费等问题。因此,本研究以花生田间的多种杂草为研究对象,展开基于机器视觉的杂草识别与定位研究,以期实现对花生田间多种杂草快速与准确的检测。主要研究内容如下:(1)构建了适用于花生田间杂草检测的数据集。首先,在多个花生田间进行调查分析与数据采集,确立了六种主要的杂草作为研究对象。其次,使用图像亮度变换、翻转、添加随机噪声等数据增强方法对数据集进行扩充,避免因为数据集过小引发的模型过拟合问题。最后,在相关领域专家的指导下,对数据集进行划分与标注,得到花生田间杂草检测数据集。(2)提出基于优化YOLOv4-Tiny网络的花生田间杂草识别模型。首先,通过融合浅层特征的细节信息,增加了一个新的特征识别层,提高了网络对小目标的检测能力。其次,在特征加强网络层嵌入ECA注意力模块,对特征的背景权重进行抑制。在训练过程中,使用CIo U损失代替原有的Io U损失,使网络可以更快的达到收敛状态。最后,使用Soft-NMS算法进行预测框的筛选工作,避免因为锚框重叠过大造成杂草的漏检。实验结果表明,优化的YOLOv4-Tiny网络对多种杂草的平均识别精度为94.54%,相比基础网络提升了6.83%,平均检测时间为10.4ms/张,且模型体积较小,易于嵌入式设备的部署。(3)提出基于Real Sense D435i相机的花生田间杂草定位方法。首先,基于Real Sense D435i相机搭建花生田间杂草识别与定位平台,通过张正友标定法获取相机的内参与畸变系数。其次,将经过中值滤波算法平滑处理后的深度图与彩色图进行配准对齐,使两者之间的像素点一一对应。最后,利用优化的YOLOv4-Tiny识别杂草并获取其二维坐标,再通过坐标转换计算出杂草的三维空间位置信息。定位实验表明,杂草识别与定位的平均绝对误差为18.5mm,平均相对误差为1.4%,可以为后续智能除草设备的研发提供定位指导。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2023.000636
{DOI}: 10.27117/d.cnki.ghenu.2023.000636
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的蔬菜识别关键技术研究与实现
{Author}: 翁悦
{Tertiary Author}: 张平均
{Publisher}: 福建工程学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 蔬菜识别;卷积神经网络;Transformer;Flask
{Abstract}: 随着智慧农业的发展,蔬菜在生产和流通环节的信息化程度越来越高,例如蔬菜分级、食品溯源追溯和蔬菜自助购物等。目前蔬菜市场流通环节,主要是以人工进行蔬菜分级、销售等,易受经验的影响,且效率低下。因此,将计算机视觉技术引入蔬菜流通环节当中,能够促进农业智能化发展,具有较大的应用价值。目前针对蔬菜图像识别的技术研究主要有两种方法,一种是传统图像处理,需要人为去设置大量相关参数提取蔬菜特征;另一种是基于深度学习的卷积神经网络(Convolutional Neural Network,CNN),通过训练而非编程抽取特征,具有更好的灵活性和鲁棒性。蔬菜的多样性与相似性使其难以识别,因此,本文基于深度学习的方法对CNN模型提出改进,进一步提升模型对蔬菜识别的准确率,并将改进模型部署在高性能云端服务器,设计并实现一种C/S(客户端/服务端)架构的蔬菜识别终端系统,提高蔬菜市场流通效率。本文的主要工作如下:(1)提出一种融合CNN和Transformer结构的蔬菜识别模型。通过分析CNN网络与Vision Transformer网络在图像分类领域对于特征提取侧重点的不同,采用并行结构构建一种混合网络,使其兼具两种网络各自的优势,命名为Cc T(CNN coupling Transformer)。CNN网络分支由多个残差模块组成,着重提取蔬菜图像的局部特征,Transformer网络分支由Transformer模块组成,着重提取蔬菜图像的全局特征,分支网络之间以交互的方式进行特征耦合,增强网络整体的特征提取能力。以自建的34类蔬菜图像数据集为研究对象,通过与多种分类模型的实验对比和对各类蔬菜具体的识别精度测试,证明所提出蔬菜识别模型的有效性。(2)基于Flask的蔬菜识别模型云端部署。首先对深度学习模型的部署方式进行分析,选择云端部署的方案,然后将训练完成的Cc T蔬菜识别模型上传至阿里云ECS服务器,以Flask框架为基础,配合u WSGI的稳定通信和Nginx强大的反向代理和负载均衡功能,实现蔬菜识别服务的云端部署。其次设计了蔬菜在线识别浏览器网页对云端部署的蔬菜识别服务进行功能展示。最后对云端部署蔬菜识别服务的响应时间进行测试,测试结果表明该方案满足实时性需求。(3)设计并实现一种C/S架构的蔬菜识别终端系统。终端系统从可行性与实际需求两方面进行分析与设计。蔬菜识别终端以蔬菜销售电子秤为基础平台,研发图像采集、云端通信等功能,以云服务器作为系统后端,实现蔬菜识别功能。依据功能需求搭建相关硬件平台,完成系统数据库与可视化操作界面的设计。最后对蔬菜识别终端系统进行实际效果展示,并通过功能与性能测试验证系统的可行性。
{URL}: https://link.cnki.net/doi/10.27865/d.cnki.gfgxy.2023.000356
{DOI}: 10.27865/d.cnki.gfgxy.2023.000356
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的生活垃圾图像分类算法的研究
{Author}: 马兰萍
{Tertiary Author}: 杨得国
{Publisher}: 西北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 垃圾分类;深度学习;图像识别;目标检测;卷积神经网络
{Abstract}: 如何采用合理且有效的方式对生活垃圾进行无害化处理是一个亟待解决的问题,其对资源可再生,改善生态环境以及促进生产和经济的可持续性发展具有重大意义。目前,传统垃圾分类的解决方案还存在很多局限,如分类速度慢,图像识别精度低,算法智能化、自动化程度低,无法搭建在智能移动终端设备等问题。本文针对现有模型垃圾分类中存在的准确率低,多目标小物体垃圾识别困难等问题,以深度学习为基础,开展生活垃圾识别和分类模型的研究,为垃圾分类的智能化和自动化提供新的模式和思路。具体研究内容包括:(1)提出基于注意力机制的垃圾图像分类模型。首先,针对目前基于深度学习垃圾分类模型不完善的问题,本文在Res Net50模型基础上使用深度可分离卷积,降低模型的参数量和计算量;其次,通过添加CBAM注意力机制,增强对局部和全局特征的提取,获取更完整、有效的特征信息;然后,使用Focal Loss替代标准交叉熵损失函数,处理数据集中样本不平衡的问题,提升模型的分类精度。实验结果表明,改进后的模型在垃圾图像数据集上的分类准确率达到了92.27%。与其他经典的图像分类模型相比,该模型能够更好地实现对不同种类垃圾的识别,具有较好的分类准确率,适用于垃圾分类领域的研究。(2)提出基于YOLOv3改进的多目标垃圾图像检测模型。首先,针对现有垃圾图像中,在一张图像内含有多个小尺寸垃圾的识别困难的问题,提出了多尺度特征融合的多目标的垃圾检测模型。本文在YOLOv3模型基础上引入了Mobile Netv3网络来取代YOLOv3的主干网络Darknet53,减少模型的复杂度,并保证模型的准确率;其次,采用4个不同的尺度检测增强对小目标物体的检测能力,使回归框的定位更精确;然后,使用CIOU损失函数替换原有的损失函数,进一步提升模型的精确度。实验结果表明,改进后的模型可以对不同类型的垃圾进行有效地检测与分类,目标的定位更加精准,其m AP值为65.21%,提升了检测精度和速度。与YOLOv3相比较,该模型在检测各类垃圾时的m AP值提高了2.5%,有效地改善了模型的性能,可以满足移动以及边缘计算设备等的应用需求。
{URL}: https://link.cnki.net/doi/10.27410/d.cnki.gxbfu.2023.001366
{DOI}: 10.27410/d.cnki.gxbfu.2023.001366
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于CLIP预训练模型的动作识别方法研究
{Author}: 袁海博
{Tertiary Author}: 刘淑华
{Publisher}: 东北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 视频动作识别;CLIP模型;提示学习;对比学习;参数高效微调
{Abstract}: 视频动作识别作为视频理解的重要子问题之一,一直是计算机视觉领域的研究重点。由于收集带有高质量标注的大规模视频数据集十分困难,难以从零训练一个针对视频任务的大参数量预训练模型。目前主流的研究方法通常在视频数据上端到端地微调图像预训练模型,然而这种方法存在计算量大和灾难性遗忘问题。为了能更好地将预训练模型迁移到动作识别任务,本文探索了应用提示学习和训练适配器这两类方法将视觉-语言预训练模型CLIP更好地迁移到视频动作识别任务,主要研究内容包括:(1)针对更困难的长视频动作序列识别任务,本文提出一种基于提示学习与对比学习的动作识别方法。该方法包含五种手工设计的提示模板,这些文本提示可以准确灵活地描述视频。此外,该方法还设计了一个提示多样化损失函数,通过惩罚文本编码器中自注意力矩阵的冗余信息来丰富提示模板嵌入的多样性。并用对比学习策略共同训练视频和文本编码器。实验结果表明,该框架不仅学习到动作序列的顺序,还可以学习到更高级的活动语义。(2)针对手工设计提示模板存在鲁棒性差、试错成本高等不足,本文提出一种基于自动提示学习的动作识别框架。该框架包含三种形状的自动提示模板,前缀提示、中位提示和后缀提示,其中提示的上下文是可学习的向量,而CLIP预训练模型的全部参数均被冻结,提示槽位为动作类别标签。此外,该框架还包含一个两级时空编码器用于弥合图像与视频的差距。实验结果表明,在小样本设置下,该框架的动作识别准确率就可以达到甚至超越手工提示模板方法。(3)设计并训练适配器是另一类有效的迁移学习方法,本文探索了如何应用适配器来帮助CLIP模型更好地迁移到视频动作识别任务。本文设计了一种编码器-解码器架构的动作识别框架,其中编码器是冻结的CLIP模型的图像编码器,解码器是集成了三种时序建模模块的Transformer解码器,解码器相较于编码器具有更小的计算复杂度。实验结果表明,该框架无需引入额外模态的数据,并且以较低的计算量和较少的参数量达到具有竞争力的动作识别准确率。上述提出的三种方法均可以有效地将CLIP模型迁移到视频动作识别任务,有助于解决视频数据集规模难以微调预训练模型全部参数的问题,并提升模型的视频动作识别准确性。
{URL}: https://link.cnki.net/doi/10.27011/d.cnki.gdbsu.2023.000283
{DOI}: 10.27011/d.cnki.gdbsu.2023.000283
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的田间作物与杂草识别
{Author}: 丰欣欣
{Tertiary Author}: 单慧勇;丁润锁
{Publisher}: 天津农学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;YoloV5;DeepSort;注意力机制;机械除草
{Abstract}: 田间作物与杂草识别是自动化除草设备的关键技术。近年来,随着深度学习的快速发展,应用卷积神经网络的目标检测技术表现优异,逐渐成为作物和杂草检测的主要方法,基于深度学习的田间杂草识别已成为该领域的研究热点。利用深度学习可自主提取作物杂草特征和泛化性强的优点,开展基于深度学习的注意力机制融合Deep Sort＿Yolo V5网络识别模型的研究,取得的主要研究成果如下:(1)玉米作为常见的谷类粮食作物,以其生长周期短,杂草对苗期生长影响大,成为田间机械化除草试验的主要数据对象。通过查阅国内外苗期玉米除草资料,并结合作物在不同生长时期的除草特性,选取三到五叶期玉米作为研究对象,采集并制作苗期玉米数据集。在识别系统设计中,通过识别苗期玉米间接检测杂草的方式,提高实时检测精度,以减少常规目标检测过程中由于杂草种类繁多和环境复杂造成的检测复杂度高、检测精度和鲁棒性差等问题。(2)提出一种改进的注意力机制融合Deep Sort＿Yolo V5网络识别模型,将注意力机制,Deep Sort多目标跟踪,Yolo V5识别网络相结合,在每个卷积层后引入高效通道注意力机制,提高杂草分类识别准确率。在基于Yolo V5融合Deep Sort的多目标跟踪算法优化中,研究当前主流多目标跟踪策略,将传统目标跟踪算法和多目标跟踪算法的跟踪进行比较,最终选择基于目标检测的多目标跟踪策略方法框架。使用YOLO系列检测器,对比了Yolo V3、Yolo V4、Yolo V5,由于Yolo V5的轻量高效的特点,选择Deep Sort＿Yolo V5模型作为主要框架。(3)田间环境条件恶劣复杂,杂草分布种类繁多,传统的杂草检测方法需要人工设计特征,存在操作复杂、检测速度慢、识别精度不足和鲁棒性差等缺陷,不适应田间实时作业场景。应用项目组搭建的田间除草机器人试验平台,分析评价所提出的改进注意力机制融合Deep Sort＿Yolo V5网络识别模型在田间进行实时检测的可行性。选取合适的软件配置和硬件设备,完成试验室仿真除草试验和田间自然条件下实时检测试验,实时检测目标耗时60ms,改进模型大小为67.2MB,识别率达到96.13%,初步实验结果表明,改进的识别模型满足自动化除草的识别需求。
{URL}: https://link.cnki.net/doi/10.27717/d.cnki.gtjnx.2023.000101
{DOI}: 10.27717/d.cnki.gtjnx.2023.000101
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合卷积与Transformer的目标检测算法研究及在口罩检测中的应用
{Author}: 郝凯
{Tertiary Author}: 赵作鹏
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;卷积融合Transformer;轻量化模型;口罩检测
{Abstract}: 目标检测作为计算机视觉中的一个关键技术,在各个领域有着广泛的应用。与其他视觉任务不同,目标检测需要同时对目标进行识别和定位,具有较高的挑战性,且在实际应用中往往需要部署到资源受限的移动设备中。因此,高性能轻量级的目标检测算法具有重要的研究意义。近年来,基于自注意力的视觉Transformer模型在目标检测任务上取得了超越卷积神经网络(Convolutional Neural Network,CNN)的性能。然而,当对模型的参数量和计算消耗进行限制时,基于CNN的轻量化算法仍具有统治地位。为了将卷积和Transformer的优势进行结合,本文对卷积融合Transformer目标检测算法进行研究。此外,在新冠、甲流等呼吸道疾病频发的背景下,应用上述算法对口罩佩戴规范性检测进行研究,具有重要的现实意义。论文所做的主要工作如下:(1)针对现有目标检测模型在检测精度和速度之间的不平衡问题,基于Yolov4-Tiny,设计兼顾精度和速度的轻量级模型SAI-YOLO。首先,对Yolov4-Tiny主干使用的CSPBlock进行改进,通过借鉴Inception v3的思想,设计了RESSEBlock结构,在降低模型参数量和计算难度的同时,提高检测速度。其次,在特征金字塔FPN部分添加混合注意力机制,增强对关键特征的提取能力,进一步提高检测精度。最后,使用优化的M-Re LU损失函数替代原本的Leaky＿Re LU,提高模型非线性映射能力。(2)针对卷积融合Transformer目标检测模型存在的精度低,计算成本高等问题,设计分层多级卷积交叉融合Transformer模型MCANet。首先,构建卷积融合Transformer模块MCA-CSP,采用串行加并行结合的方式将全局特征和局部特征进行融合。其次,以多尺度卷积为核心,设计多头自注意力计算方法MultiConv Head Attention(MCA)。最后,使用MCA构建全局特征提取模块MCA-Former,从而大幅降低计算成本。(3)针对现有口罩检测模型存在的鲁棒性差、检测速度慢和检测类别少等问题,设计轻量级口罩佩戴规范性检测模型LMCANet。首先,将研究内容(1)和研究内容(2)中所提的两个模型进行结合,使用RES-SEBlock替换MCANet中的CSPBlock进行局部特征提取。其次,将使用的普通卷积更换为深度可分离卷积,减少模型的参数量。然后,构建口罩佩戴规范性数据集Masked＿Imgs,在口罩检测的基础上,实现口罩佩戴规范性检测。最后,将所提模型在NVIDIA Jetson TX2中进行部署,实现移动端实时检测。论文对所提模型进行了充分的分析和实验。研究内容(1)中所提SAI-YOLO模型在VOC和MAFA数据集上m AP分别达到了77.59%和68.53%,在1920×1280分辨率的视频中,FPS达到114.5。研究内容(2)中所提MCANet在COCO数据集上AP50达到了42.3%,在VOC数据集上m AP达到了70.62%,优于多种流行的轻量级目标检测模型。研究内容(3)中所提LMCANet在WIDER Face数据集中m AP达到了73.23%。在自建口罩佩戴规范性数据集Masked＿Img上,对佩戴不规范行为的检测AP值达到了91.55%,并且具有较高的鲁棒性。在NVIDIA Jetson TX2上的检测速度达到30ms,满足实时检测的要求。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2023.001172
{DOI}: 10.27623/d.cnki.gzkyu.2023.001172
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于U-Net网络的医学图像分割方法研究
{Author}: 卞阳阳
{Tertiary Author}: 邓翔宇
{Publisher}: 西北师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学图像分割;卷积神经网络;U型网络;注意力机制;跳跃连接
{Abstract}: 随着医学成像技术的日臻完善,医学图像的检查已经成为诊断流程中必不可少的步骤,以此来协助医生更好地诊断病症。传统的人工检查医学图像的方式是一项耗费时间的工作,还需要临床专家和技术人员参与,不能满足广大医生和病人的需求,迫切地需要一种高效率的方式。通过引入计算机视觉技术来辅助医生不仅可以减轻医生的工作量,同时也能减少误判情况的出现。在医学图像分割任务中,如何实现快速分割的同时兼顾高准确性一直都是研究的热点。本文对基于U-Net网络的医学图像分割提出了新的改进模型,并在实验中验证了有效性。主要工作内容如下:(1)针对医学图像分割方法中存在的特征信息提取不充分,边界分割不清晰以及分割精度不足等问题,本文提出了融合空间通道注意力门的U-Net分割模型。通过融合残差机制和压缩-激励模块代替网络中原本的卷积模块对边界信息进行优化,同时在解码阶段应用空间通道注意力门来增强特征,优化了直接采用跳跃连接带来的语义信息差异的问题,从而提高算法分割的准确率。在LITS-28公共肝脏数据集上验证了本文算法,其中平均交并比(MIOU)和Dice相似系数分别达到93.68%和96.45%,相比于其它类似算法,本文所提算法的对肝脏边界分割更准确,分割的肝脏精度也更高。(2)由于卷积神经网络(Convolutional NeuralNetwork,CNN)模型本身的感受野有限,导致了在建立长距离依赖这方面CNN模型存在不足。针对这一问题,本文提出了基于Transformer的医学图像分割模型,在编码部分采用CNNTransformer混合的结构,既保留CNN在提取语义特征和细节信息的优势,又可以充分利用Transformer建立长距离依赖关系。同时改进了编码器中ResNet50网络的卷积层,改进后的卷积层比标准卷积层拥有了更好的特征提取能力。在解码部分加入基于归一化的注意力模块(NAM),重新设计了通道和空间注意子模块,利用权重贡献因子提高注意力机制的性能。在Synapse多器官分割数据集验证了本文算法的性能,其中平均骰子相似系数(DSC)和平均Hausdorff距离分别达到77.72%和31.53毫米,与其他算法相比,本文基于Transformer的医学图像分割模型得到的医学图像分割结果更准确。
{URL}: https://link.cnki.net/doi/10.27410/d.cnki.gxbfu.2023.001640
{DOI}: 10.27410/d.cnki.gxbfu.2023.001640
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5s的生活垃圾检测及系统设计
{Author}: 贺仲璐
{Tertiary Author}: 瞿少成
{Publisher}: 华中师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;垃圾分类系统;注意力机制;轻量化;网络剪枝;知识蒸馏
{Abstract}: 近年来,我国开始积极推广垃圾分类政策,但存在人们普遍缺乏相关知识,以及人工引导分类人力成本高等问题。随着目标检测技术的发展,借助该技术辅助市民进行垃圾分类,为垃圾分类政策的推广提供了一种新思路。目前垃圾分类的智能研究存在可检测类别较少、模型特征提取能力不足、检测实时性较差等问题。为了解决上述问题,本文从网络模型结构、模型复杂度等方面展开研究,设计并实现了一种基于CGPD-YOLOv5s的垃圾分类系统,该系统能够有效地进行多类别垃圾检测。本文的主要工作内容如下:(1)构建了包含多个类别的H2生活垃圾数据集。首先合并“华为云杯”数据集和HGI30数据集,接着剔除部分模糊、高度重复的数据,然后以PASCAL VOC格式标注数据,最后通过数据增强扩充部分数据集。构建的H2生活垃圾数据集共有23518张图片,包含57种垃圾,它们被分为4个类别:可回收垃圾、厨余垃圾、有害垃圾和其他垃圾。(2)提出了一种基于CGPD-YOLOv5s的生活垃圾检测方法。针对垃圾尺寸变化大、重叠遮挡以及YOLOv5s模型复杂、计算量大等问题,提出了一种基于CA注意力和Ghost Net的CG-YOLOv5s模型。其中,在YOLOv5s的颈部融合CA注意力机制可以更好地获取全局感受野,提升模型的特征提取能力;然后通过Ghost Net进行网络轻量化设计,采用Ghost Conv进行特征提取,基于G-Bottle Neck构建G-C3模块,以实现减少模型参数量、提高推理速度的目的。由于改进后的CG-YOLOv5s模型仍存在参数冗余,以及检测精度下降的问题,本文通过网络剪枝和知识蒸馏的策略进一步优化模型,得到CGPD-YOLOv5s。在H2生活垃圾数据集上的实验结果表明,CGPD-YOLOv5s相较于YOLOv5s在网络体积上压缩了75.5%,在实时推理速度上提升了46.8%,在模型精度上接近于YOLOv5s。可见CGPD-YOLOv5s在检测精度损失较小的情况下降低了模型的复杂度,适合部署在移动终端。(3)设计并实现了一种基于CGPD-YOLOv5s的垃圾分类系统。首先,对系统进行功能性需求分析和非功能性需求分析;然后,设计了系统总体架构、系统功能模块和数据库;最后,使用HTML、CSS、React框架、Antd组件库、My SQL数据库等技术实现了垃圾分类系统的用户子系统和管理员子系统。其中,用户子系统包括注册登录、生活垃圾检测、文本信息检索等功能;管理员子系统包括用户信息管理、检测记录管理、反馈数据审核等功能。(4)测试垃圾分类系统。从功能性和非功能性两个方面进行系统性能测试,测试结果表明,系统各功能模块基本达到设计要求,生活垃圾检测功能在系统中表现出较好的实时性和精度,系统页面较为简洁美观,兼容性良好。
{URL}: https://link.cnki.net/doi/10.27159/d.cnki.ghzsu.2023.001182
{DOI}: 10.27159/d.cnki.ghzsu.2023.001182
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 机器视觉和毫米波雷达融合感知算法研究
{Author}: 佘宇航
{Tertiary Author}: 张新晨
{Publisher}: 华中师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 多传感器融合;目标检测;毫米波雷达;机器视觉;鸟瞰图视角
{Abstract}: 随着中国经济的迅猛发展,家用汽车越来越普及,但交通事故数量也随之增加。为了减少交通事故的发生,现代技术如自动驾驶技术可以用来消除人为驾驶错误,从而提高行车安全性。该技术的核心在于通过在汽车上安装传感器来感知周围行车环境,从而实现对道路环境的有效感知和对行驶状态的快速响应。在智能汽车环境感知中,常用的传感器包括毫米波雷达和摄像头。毫米波雷达可以准确地感知目标的速度、方位、距离等信息,视觉传感器具有强大的目标分类能力。然而,视觉感知难以区分图像中物体的大小和远近,这对于道路驾驶检测是致命的。解决此问题的一种方案是采用鸟瞰图(BEV)技术,即从高处俯视的图像,帮助车辆无遮挡地获取道路上的实时信息。本文选择将毫米波雷达信息与视觉信息进行融合,并将融合感知结果以利于车辆决策规划的鸟瞰图形式输出,充分利用两者的优势进一步提高车辆决策的准确性。本研究的主要内容如下:(1)针对毫米波雷达信号存在的环境噪声和多径干扰的问题,需要对数据预处理包括去噪、卡曼尔滤波等滤波方式去除干扰。同时针对前沿4D毫米波雷达点云数据及算法展开讨论。(2)针对视觉算法存在的难以区分图像中物体大小和远近的问题,采用一种鸟瞰图的目标检测方法,将输出结果以一种高俯视图像表现出来。选择一种高效的改进BEV投影方式,将图片信息从相机的透视空间特征编码到BEV上。(3)针对单一传感器存在的难以全面准确地感知周围环境的问题,设计了毫米波雷达和视觉融合网络。同时设计输出视角,将检测的目标转换视图到BEV视角,完成融合网络的设计。(4)针对所设计的融合网络,搭建了一种机器视觉和毫米波雷达融合网络的检测平台。选择适当的雷达和相机等设备完成硬件平台的设计,然后在软件系统上实现融合模型方法,并在真实驾驶环境下进行了实车数据采集。经过实验验证和数据统计,本文提出的融合网络比较视觉算法在检测准确率上提升了5.5%,在每秒检出速度上提高了4.9帧,表明本文提出的融合网络比较视觉算法提高了检测速度并且保证了目标检测的准确率,且将输出结果以利于车辆规划的BEV形式输出,提高了车辆的决策规划性。
{URL}: https://link.cnki.net/doi/10.27159/d.cnki.ghzsu.2023.001165
{DOI}: 10.27159/d.cnki.ghzsu.2023.001165
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 高精度相机标定算法研究
{Author}: 李一硕
{Tertiary Author}: 盛遵冰
{Publisher}: 黑龙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 相机标定;标定板姿态;垂直直线;平面变换;角度测量
{Abstract}: 相机标定是机器视觉技术中的一个重要步骤,其准确性直接影响到后续图像处理、识别和控制等任务的精度和可靠性。本文以此为背景,对现有的标定方法进行了详细研究,对张正友标定方法进行了分析和改进,提高了标定精度,并在实验中验证了其有效性。具体研究内容包括以下方面:第一,在总结前人工作基础上,提出了一种基于平面变换的两垂直线标定方法,提升了标定精度,在算法实现中,通过提升检测标志点的精度等方法,(如圆心提取)提升现有算法精度。该方法通过平面变换减小透视偏差带来的影响,同时避免了引入单应性矩阵等问题,并对该方法进行了理论推导和实验验证,结果表明该方法在精度上优于传统的张正友标定法。第二,根据误差理论,详细分析了外部因素,如姿态、数量等对精度的影响,并在此基础上得到了相机标定过程中,标定靶标的姿态变化范围、数量等信息,以此,提出四姿态均匀标定方法以提升标定精度。第三,将相机标定用于具有实际工程背景的飞机襟翼和垂尾摆动角度的测量,解决了目前使用姿态传感器测量垂直方向摆动角度较低的问题。实验表明,此方法在水平方向的精度与姿态传感器相当,在垂直方向上的精度,优于姿态传感器,为相机标定技术在航空领域的推广和应用提供了依据。本文对单目相机标定方法进行了探讨,从算法和标定靶标姿态两个方面讨论了实现高精度标定的策略,并以此为基础,完成了对模拟飞机襟翼和垂尾转动状态的角度测量,这为空间大尺度物体的空间转角测量提供了一种解决方案。
{URL}: https://link.cnki.net/doi/10.27123/d.cnki.ghlju.2023.001911
{DOI}: 10.27123/d.cnki.ghlju.2023.001911
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像风格迁移算法的研究与实现
{Author}: 姜风超
{Tertiary Author}: 张明
{Publisher}: 江苏科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 风格迁移;语义分割;真实化风格;动漫化风格;风格迁移系统
{Abstract}: 图像风格迁移是计算机视觉领域的研究热点之一。其主要目的是将一张图像的风格应用到另一张图像中,从而生成一张具有新风格的图像。这项技术在图像处理、计算机视觉、计算机艺术等领域具有广泛的应用前景。传统的风格迁移技术在艺术化图像风格迁移方面效果较好,但在真实化图像风格和动漫化图像风格方面表现不佳。在真实化图像风格方面,传统算法生成的图像常常存在图像纹理扭曲、失真以及风格溢出等问题。在动漫化图像风格方面,传统算法往往难以保留原有图像的特征,生成图像存在过拟合和伪影等问题。故此,本文针对上述两种风格迁移存在的问题作出了以下工作:(1)针对基于真实化风格图像进行迁移后生成图像存在纹理扭曲、失真以及风格溢出等问题,本文提出了一种基于正则损失约束和语义分割的风格迁移算法。首先,通过引入正则损失约束来解决生成图像存在的纹理扭曲及失真问题,只改变原始图像的颜色信息,通过这种方式,生成的风格化图像不会受到纹理扭曲的影响,保留了原始图像的内容特征和颜色特征;然后,通过引入语义分割算法,将图像分成不同的区域,并对每个区域分别进行风格化处理,从而实现对图像局部风格的控制;最后,在COCO和Wiki Art数据集上的实验表明,基于改进模型迁移后的效果图像PSNR值总体提高了2.7%,SSIM值总体提高了3.4%,该方法可以实现对图像局部风格的精细控制,从而生成更加逼真和自然的风格化图像。(2)针对基于动漫化风格图像进行迁移后生成图像存在语义信息丢失、过拟合和伪影等问题,本文提出了一种基于残差块和自适应点层实例归一化的风格迁移算法。首先,本文在Cartoon GAN模型的基础上引入了残差模块,解决训练中容易出现的退化现象,从而提取到更细节的特征;其次,引入Ada Po LIN自适应点层实例归一化替换原有的BN归一化,解决BN归一化不能同时将局部区域的颜色、纹理信息及形状信息从真实图像传输到生成图像上的问题,从而更利于处理颜色、纹理样式和局部形状的变换;然后,通过引入感知损失,提高生成图像的真实感,避免了传统的像素级别损失函数所存在的问题;最后,在train2014数据集上的实验表明,基于改进模型迁移后的效果图像PSNR值总体提高了2.5%,SSIM值总体提高了3.3%,因此通过数据表明上述改进方法可以很好地提高图像的迁移效果。(3)最后,结合本文所提出的方法设计并实现了图像风格迁移系统,用户可根据自身的需求,选择不同的图像风格迁移类型,极大方便了用户的操作。
{URL}: https://link.cnki.net/doi/10.27171/d.cnki.ghdcc.2023.000308
{DOI}: 10.27171/d.cnki.ghdcc.2023.000308
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于生成对抗网络的图像自增强去雾算法
{Author}: 刘万军;程裕茜;曲海成
{Author Address}: 辽宁工程技术大学软件学院;
{Journal}: 系统仿真学报
{Year}: 2024
{Volume}: 36
{Issue}: 05
{Pages}: 1093-1106
{Keywords}: 图像处理;机器视觉;生成对抗网络;光学模型;图像去雾
{Abstract}: 针对现有去雾模型使用合成有雾图像数据集训练后容易出现过拟合的问题，提出了一种融合生成对抗网络的图像自增强去雾算法。在结合两个生成对抗网络的同时估计图像的深度信息。第一个GAN利用清晰图像学习图像加雾过程，将其生成的有雾图像作为第二个GAN的输入，指导第二个GAN如何正确去雾。为了减少图像处理前后的差异，利用一致性损失函数来优化两个网络。在图像加雾部分添加场景深度估计模块，并对散射因子进行随机采样，实现图像自增强功能，更加真实地模拟现实世界中不同浓度的雾气。该算法无需使用合成有雾图像数据集的成对信息，进一步避免过拟合问题。实验结果表明：所提算法能够取得较好的去雾效果，在主观视觉质量和客观评价指标上均有良好表现，优于同类算法。
{ISBN/ISSN}: 1004-731X
{Notes}: 11-3092/V
{URL}: https://link.cnki.net/doi/10.16182/j.issn1004731x.joss.22-1551
{DOI}: 10.16182/j.issn1004731x.joss.22-1551
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 一种基于机器视觉和深度残差收缩网络的智能制造缺陷检测方法
{Author}: 刘汉举
{Author Address}: 湖北工业大学工程技术学院;
{Journal}: 中国科技论文
{Year}: 2023
{Volume}: 18
{Issue}: 04
{Pages}: 462-468
{Keywords}: 机器视觉;深度残差收缩网络;深度长短期记忆神经网络;智能制造;缺陷检测
{Abstract}: 针对基于显性知识的智能制造缺陷检测机制在工程实践中日益凸显的若干缺陷，提出了一种基于机器视觉和深度残差收缩网络(deep residual shrinkage networks, D-RSN)的智能制造缺陷检测方法，并进行了先验环境下的仿真验证。首先利用互补金属氧化物半导体(complementary metal oxide semiconductor, CMOS)相机集群搭建快速机器视觉图像获取装置，形成融合前置训练集和后置测试集的图像特征数据池；然后利用D-RSN对数据池前置训练集进行图像缺陷特征隐性知识学习辨识，构建时间正序下的图像缺陷特征全息感知机制；最后利用深度长短期记忆(deep long short-term memory, D-LSTM)神经网络对数据池后置测试集进行图像缺陷自主检测，借助图像缺陷定位及分类函数输出检测结果。选取某医用外科口罩智能制造生产线为工程实践验证载体，对模型进行了工程应用实践验证，结果表明：所提方法较好地改善了基于显性知识的智能制造缺陷检测机制在工程实践中日益凸显的若干缺陷，可以自主学习辨识图像缺陷特征隐性知识，大幅度提高了智能制造缺陷检测有效率，图像缺陷检测均值有效率达98.37%,符合医用外科口罩智能制造生产线国检要求。
{ISBN/ISSN}: 2095-2783
{Notes}: 10-1033/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwI4HfWHHODBp06W40x58vtiqqMSYGjPVFUMBJDdVuQmgYL4VMvIT_dT2XDcRZMK3pZo9Npmv-jWs9ukIogzirvTXaLeuo34SiBMJEoDZ3hWK9sU9xHJ2Ea-NbZNhgf9RGcuMKlqA4T29T4Vp2V0JyqNld0PeQwea-sPqZerLBzmmypBdnGSaL3gklpQsDWHK4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智慧交通灯控制系统
{Author}: 郭之栋;刘筠;杨凡;周昕;陈亮亮
{Author Address}: 江西科技师范大学通信与电子学院;
{Journal}: 计算机与现代化
{Year}: 2023
{Volume}: 
{Issue}: 04
{Pages}: 101-105
{Keywords}: 机器视觉;目标检测;配时算法;智慧交通灯
{Abstract}: 为了准确、灵活、高效地完成实时交通灯指挥任务，引入机器视觉，设计一套基于机器视觉的智慧交通灯控制系统，来满足现阶段城市道路交通灯智能化所需。本系统采用OV2640摄像头对道路情况进行拍摄，采集图像信息，接着对采集到的数据进行存储，再基于视觉处理中的YOLO (You Only Look Once)系列算法对数据中道路情况进行实时识别，然后把识别的结果传送到配时模块，最后获得最为及时的数据及时处理作用在交通灯上，并在仿真中取得了较好的效果，进一步推动智慧交通系统的应用。
{ISBN/ISSN}: 1006-2475
{Notes}: 36-1137/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvytY9fz3CVZ-D6mk6llhG1dA5raTOyVkwjKf72rI2bTer_2XsbXIPTpMkIyvjy8O_uZPD8P6AxiXCVg7yGHQjIE3jsA4PV5g2h5NPvhDiQ8m-moAbBzxGOOAT9bB_LC0VTqffslJuVKbzB6wfALnT91HD8I1GAxEDrrDdeNewfI4A0kdoOVEOffuw0l-zGBGAw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的挖掘机自主作业运动规划研究
{Author}: 赵江营
{Tertiary Author}: 胡永彪;夏晓华
{Publisher}: 长安大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 挖掘机;铲入点;卸料点;挖掘运动建模;轨迹优化
{Abstract}: 目前土方挖掘作业的自主化程度较低,挖掘作业环境的铲入点和卸料点识别、挖掘轨迹规划、动作执行等还完全依赖于熟练驾驶员的经验决策分析和操作技能。为了实现自主化挖掘作业,本文基于机器视觉技术,采用理论分析、数值模拟和试验研究相结合的方法,对挖掘机自主作业的挖掘区域三维重建点云处理、铲入点与卸料点的检测与定位、作业过程运动建模、挖掘运动轨迹优化方法与关键技术进行了系统深入的研究。本文主要工作如下:针对沟槽挖掘工况与功能需求构建了自主挖掘作业系统,完成了硬件设备的选型和安装。设计了上位机软件架构,开发了下位机控制程序。基于挖掘机自主作业系统机器工作装置与回转装置的运动控制要求,确定了控制策略。提出了一种基于无监督点云处理的自主挖掘作业铲入点检测方法。首先通过立体视觉技术与相机坐标系到挖掘机全局基坐标系的坐标变换,得到了挖掘机全局基坐标系下挖掘区域的三维点云。然后基于无监督的全局图聚类方法对沟槽挖掘区域点云进行提取。最后基于工作装置平面沟槽挖掘区域轮廓铲入点的几何特征,构造了全局梯度一致度函数用于描述铲入点的几何特征,实现铲入点的检测。现场试验表明,该方法能够有效地实现沟槽挖掘区域的提取,其精确率、召回率、F1分数分别可达到97.69%、93.82%、95.72%。在5×5.5 m的挖掘作业范围之内,铲入点的最大绝对定位误差为69.0 mm,平均相对定位误差为1.36%,验证了此方法能够用于挖掘机自主作业铲入点检测。提出了一种通过已标定的单目相机跟踪靶标测量自主挖掘作业卸料点位姿的方法,能够精确测量挖掘作业卸料点的动态位姿参数,实现了动态挖掘作业过程中卸料点位置的精确测量。试验结果和误差分析表明,测量系统的最大测量距离为11 m,最大姿态角误差为8°,最大位置测量误差为22 mm。在多次试验中卸料点的最大绝对定位误差为48.0 mm,平均相对定位误差为0.66%,证明了卸料点定位方法的可行性和有效性。提出了一个基于熟练驾驶人员挖掘路径生成挖掘机作业运动轨迹的方法。首先将熟练驾驶员操作挖掘作业时的轨迹转换为拓扑等效轨迹。然后利用样条函数对挖掘轨迹进行参数化,使轨迹依次通过与人工挖掘轨迹拓扑等效的路径点,迭代优化求解轨迹生成问题,得到动力学可行性约束下的时间-冲击最优轨迹。现场试验结果表明,在满斗挖掘时,7铲挖掘过程中的自主挖掘作业所用的时间是80.4 s,少于而人工挖掘所用的时间83.2 s,证明了此方法的可行性。建立了一个完整的基于视觉的自主沟槽分层挖掘轨迹优化模型。首先建立起沟槽挖掘作业的分层挖掘模型用于规划铲斗齿尖路径。然后通过视觉感知技术获取铲入点与卸料点的定位信息,利用人工挖掘作业的拓扑信息获取中间路径点。利用Bézier曲线依次连接这些路径点,并对轨迹进行重时间参数化,在满斗挖掘与动力学可行性约束条件下,通过时空优化生成一条快速、光滑和稳定的挖掘轨迹。最后通过自主挖掘与熟练人工挖掘作业现场试验对比,自主挖掘所用的时间为80.8 s,熟练人工挖掘的时间为84.1 s,该轨迹优化方法能够提升3.9%的挖掘作业效率,并且自主挖掘的冲击小于人工挖掘,该方法所生成的轨迹在运动的平稳、高效方面能够达到预期效果。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.000050
{DOI}: 10.26976/d.cnki.gchau.2023.000050
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的驾驶员异常行为检测研究
{Author}: 冯志雯
{Tertiary Author}: 赵军
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 疲劳检测;异常行为检测;机器视觉;YOLOv5s
{Abstract}: 在我国的机动车驾驶事故中,由于驾驶员异常行为引发的事故占很大比重。在注意力高度集中的驾驶行车过程中,驾驶员的生理和心理上都承受着较大的负荷。驾驶员在疲劳状态下,动作变得迟缓,若在驾驶过程中进行抽烟、喝水或是使用手机时,都会导致其注意力不集中,这些驾驶异常行为很容易引发道路交通事故。因此,研发能实时监测驾驶员疲劳状态和异常行为的系统,及时发现和警示制止疲劳驾驶和驾驶时的分心行为,对减少道路事故,保障驾驶员人身安全和道路交通安全运行都具有重要意义。目前已有的检测方案中较多的关注点在于根据机动车整体运行状态来理性评估车辆状态,这样存在延时性,以及忽略了人的心理属性等弊端,为解决以上问题,本文提出了一个基于人脸及行为识别的驾驶员疲劳及分心行为检测系统。本文主要研究了驾驶员处于疲劳驾驶和分心驾驶这两种异常驾驶状态时,利用机器视觉图像检测技术对驾驶员当前驾驶状态进行准确识别和检测,以及搭建该检测系统。在驾驶员疲劳状态检测中,人脸识别使用了级联Adaboost人脸检测器对驾驶员的面部进行整体检测,在检测疲劳状态过程中利用了Dlib库与面部68关键点抓取技术对驾驶员的眼部区域和嘴部区域进行准确定位和识别,通过关键点之间的几何坐标关系计算眼部的实时横纵比例以及嘴部的实时张度,通过PERCLOS算法进一步计算驾驶员眼部闭合状态和打哈欠的状态。以这两个特征为基础判定驾驶员是否存在疲劳并给予实时预警。同时本文以手机,水杯,香烟三种物体特征作为驾驶员使用手机,喝水和抽烟等三种分心的异常驾驶状态的目标特征。将抽象的检测驾驶员分心状态下的异常驾驶行为状态的任务具象为针对具体目标进行目标检测的任务,从而进一步实现对分心状态下的异常驾驶行为进行准确识别的任务。在算法层面上本文提出将一阶段目标检测网络YOLOv5s模型引入了CA注意力机制,在很大程度上提高了对于微小目标的检测能力,减少了检测背景冗余信息的干扰,改进后的m AP值达到98.2%。整体的可视化界面采用了python的pyside2插件进行综合设计,将驾驶员疲劳状态检测和驾驶员的分心驾驶状态检测集成在同一窗口下,最终研究成果能够实时的捕捉驾驶员的面部状态,并对驾驶员的疲劳驾驶状态和分心行为进行实时检测和实时预警。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2023.001215
{DOI}: 10.27205/d.cnki.gltec.2023.001215
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉问答技术研究综述
{Author}: 王虞;孙海春
{Author Address}: 中国人民公安大学信息网络安全学院;安全防范技术与风险评估公安部重点实验室;
{Journal}: 计算机科学与探索
{Year}: 2023
{Volume}: 17
{Issue}: 07
{Pages}: 1487-1505
{Keywords}: 视觉问答(VQA);模态融合;视觉对话;智能问答;跨模态技术
{Abstract}: 视觉问答（visual question answering,VQA）是融合自然语言处理与计算机视觉技术的图-文跨模态热门任务。该任务以计算机智能识别与检索图像内容并给出准确答案为主要目标，融合应用了目标识别与检测、智能问答、图像属性分类、场景分析等多项技术，能够支撑许多前沿交互式人工智能高层任务，如视觉对话、视觉导航等，具有广泛的应用前景和极高的应用价值。近几年，计算机视觉、自然语言处理及图-文跨模态领域人工智能模型的发展为视觉问答任务的实现提供了许多新的技术和方法。主要对2019—2022年视觉问答领域的主流模型及专业数据集进行总结。首先，依据视觉问答任务实现的模块框架，对关键步骤中的主流技术方法进行综述讨论。其次，按照主流模型采用的技术方法，将该领域内各类模型进行细分，并简要介绍改进重点和局限性。随后，综述视觉问答常用数据集与评价指标，对几类典型模型性能进行对比阐述。最后，对现阶段视觉问答领域内亟待解决的问题进行重点阐述，并对视觉问答领域未来应用及技术发展进行预测和展望。
{ISBN/ISSN}: 1673-9418
{Notes}: 11-5602/TP
{URL}: https://link.cnki.net/urlid/11.5602.TP.20230412.1514.005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 图像语义内容分割理论与方法研究
{Author}: 张效良
{Tertiary Author}: 李宏亮
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 图像语义内容分割;计算机视觉;语义分割;实例分割;全景分割
{Abstract}: 作为计算视觉领域的基础任务以及研究热点,图像语义内容分割具有重要的理论意义和研究价值,且被广泛地应用于自动驾驶、视频监控以及生物医疗等诸多领域。近年来,随着人工智能技术以及深度学习在计算机视觉领域的快速发展与应用,图像语义内容分割从仅需要区分图像中的前景对象与背景内容的简单任务,发展为了需要对图像中的不同的语义内容进行分割的复杂任务。然而,由于现实中图像通常包含了大量种类繁多、尺度不一且相互间关系复杂的语义内容,如何准确且快速地识别并分割出图像中的语义内容仍然面临着巨大的挑战。因此,为了应对计算机视觉应用对提升图像语义内容分割精度的迫切需求,本文展开了对图像语义内容分割理论与方法的研究。本文将以提升图像语义内容分割算法的性能以及降低图像语义分割算法的运算消耗为总体目标,分别对图像语义内容分割中的语义分割、实例分割以及全景分割三个主要任务进行研究。具体研究内容以及创新点包括以下几个方面:(1)针对实例分割中目标检测器精度对实例分割性能影响的问题,即由于目标检测器可能没有完全地检测到前景对象,从而导致实例分割算法不能对前景对象进行完整地分割,本文进行了基于前景对象优化的实例分割研究。本文构建了前景像素与其所属的前景对象的关系的数学模型,并提出了基于前景对象优化的实例分割算法,用以辅助基于目标检测框架的实例分割算法分割前景对象中没有被目标检测器检测到的区域,从而进一步地提升实例分割算法的性能。(2)针对实例分割中前景对象之间相互混淆导致的问题,即基于目标检测框架的实例分割算法会对目标检测框内与目标前景对象属于同一语义类别的非目标前景像素的特征过度响应的问题,本文进行了基于前景对象混淆处理的实例分割研究。本文将实例分割中前景对象之间相互混淆的问题视为非目标前景像素特征过度响应的问题,并提出了基于前景对象混淆处理的实例分割算法,用以辅助实例分割算法在目标检测框中区分目标前景对象与非目标前景区域,从而进一步地提升实例分割算法的性能。(3)针对实例分割中如何在同一图像中同时分割多个前景对象的问题,本文进行了基于协同注意力的实例分割研究。本文研究发现当同一图片当中存在多个需要被分割的前景对象时,这些前景对象共享着相同的背景信息,且彼此之间存在复杂的语义以及空间关系,特别是当这些前景对象属于同一个语义类别的时候。因此,本文提出了基于协同注意力的实例分割算法,通过共享同一图片中具有相同语义类别的前景对象的外观特征以及语义特征,加强对应语义类别的前景对象的实例分割特征,从而进一步地提升实例分割算法的性能。(4)针对语义分割中如何在不同图片中分割相同的语义内容的问题,本文进行了基于特征记忆的语义分割研究。本文研究发现在语义分割中,相同的语义内容在不同的图片中也存在着语义与空间关系。因此,本文提出了基于特征记忆的语义分割算法,通过记忆不同图片中同一语义内容的语义以及空间信息,加强语义分割特征,从而进一步提升语义分割算法性能。(5)针对全景分割中由于网络结构过于复杂从而导致计算时间以及计算资源消耗的问题,本文进行了基于像素关系预测的全景分割研究。本文首先构建了像素间关系的数学模型,用以判断两个像素是否是属于同一个前景对象;然后提出了基于像素关系预测的全景分割算法,在确保全景分割性能的同时实现了快速的全景分割。(6)针对全景分割中前景像素聚类方法过于复杂从而导致的计算时间以及计算资源消耗的问题,本文进行了基于前景像素聚类的全景分割研究。本文首先构建了三维空间矢量的数学模型,将前景像素与背景像素的判断、前景对象几何中心的预测以及前景像素与其所属的前景对象的关系预测统一到了一个数学模型之中;然后利用构建的三维空间矢量数学模型提出了基于前景像素聚类的全景分割算法,在确保全景分割性能的同时实现了快速的全景分割。本文所开展的图像语义内容分割理论与方法研究探讨了如何利用图像中不同语义内容间复杂的语义以及空间关系信息,实现了高质量的图像语义内容分割,为其它的计算机视觉任务提供了技术支持。本文的理论成果能够被广泛地应用于自动驾驶、医学诊断以及图像检索等现实领域中,具有重要的理论价值以及应用价值。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.000061
{DOI}: 10.27005/d.cnki.gdzku.2023.000061
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的高分辨率遥感影像道路提取方法研究
{Author}: 王琪
{Tertiary Author}: 程建
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;高分辨率遥感影像;道路提取;多尺度特征;注意力机制
{Abstract}: 道路是遥感影像中的典型地物目标,准确的道路信息在自动驾驶、城市规划、地图绘制等应用领域中极具重要性。随着遥感观测技术的持续发展,海量的高分辨率遥感影像为道路提取任务提供了充裕的数据资源。与实地采集和专家手工标注相比,自动从高分辨率遥感影像中提取道路更有效率,已成为遥感图像分析领域的研究热点。基于深度学习的方法凭借其出色的特征提取能力已成为高分辨率遥感影像道路提取研究的主流。但由于高分辨率遥感影像中道路本身与背景环境的复杂性,大部分道路提取方法的精度并不理想。鉴于此,本文基于深度学习开展了如下高分辨率遥感影像道路提取方法的研究工作:(1)研究基于编码-解码网络结构的道路提取方法。为了有效提取并保留道路特征信息,本文首先分别基于卷积神经网络和Transformer开展了编码-解码网络结构的道路提取分析,挑选出了性能出色的Link Net。本文还针对网络的编码器结构中存在的道路信息损耗问题,设计了密集特征强化模块,通过对比实验验证了其可以有效增强网络对道路特征信息的表示。最终,构建了用于后续章节道路提取实验的基础骨架网络。(2)研究结合多尺度信息融合机制的道路提取方法。为了提升基础骨架网络的道路特征提取能力,本文设计了一种密集多尺度信息融合模块,利用密集级联的多尺度空洞卷积操作与并行的全局池化操作来提取多尺度道路特征信息。根据对比实验结果,密集多尺度信息融合模块可以更有效地提升基础骨架网络的道路提取能力,并通过与密集特征强化模块的组合,在道路提取结果的准确性和完整性上均优于对比方法。(3)研究结合注意力机制的道路提取方法。针对以局部计算为主的多尺度信息融合机制无法有效感知到远距离道路像素间关系的问题,本文设计了一种双十字条状注意力模块,在全局视野下同时关注水平、垂直、左对角线和右对角线等方向上的道路像素间依赖关系,进而强化道路特征信息。根据对比实验结果,双十字条状注意力模块可帮助网络模型关注到更有效的道路特征,最终获得在评估指标和可视化结果上均最优秀的道路提取结果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003666
{DOI}: 10.27005/d.cnki.gdzku.2023.003666
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的汽车零部件外观缺陷检测
{Author}: 滕叶莹
{Tertiary Author}: 刘文
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 外观缺陷检测;三维视觉;二维视觉;YOLOv7;缺陷分类
{Abstract}: 随着中国制造2025、工业4.0的快速推进,汽车制造智能化程度不断提升,对汽车零部件的质量检测方法提出了更高的要求,传统的零部件检测都是通过人工检测的方式,此方法检测效率低下且不稳定。而现有的基于机器视觉的缺陷检测方式难以对多种类不同结构的零部件进行检测,或对工业应用环境过于苛刻,普适性较低。因此,本文根据企业研发需求,结合二维与三维视觉各自的优势之处开发出能够较好地适应不同生产环境、稳定地检测各类缺陷的系统,主要研究内容如下:
首先,围绕需要检测的缺陷类型、检测精度及检测速度进行了需求分析,设计了整体的检测流程,通过计算分析确定了激光扫描仪、相机等的选型,设计了支撑机构、传送载物平台、调姿机构等用于相应的模块中。另外,针对缺陷样本数量较少的问题,研究了数据集的扩充方法。
其次,为充分利用深度信息进行检测,在三维检测模块中,针对点云匹配对缺陷的提取效果较差及耗时过长的问题,提出了一种基于深度图像的模板匹配方法提取缺陷信息。首先对点云数据进行预处理以滤除离群噪点,然后按高度分割点云,去除背景区域并将物体点云转为深度图像。通过实验对比选择经RANSAC优化后的SIFT特征点图像配准方法对待测零部件与模板零部件进行配准,并在配准后通过差分图像提取出灰度不等的区域,比较后判定是否为外观缺陷。本模块整体流程的平均耗时为6.65s,在精度0.3mm范围内准确率达到98.32%。
最后,为了尽可能解决环境影响检测效果的问题,利用二维视觉检测各种微弱的表面缺陷,本文提出了包括快速寻源、调姿聚焦、多方验证三个阶段的SFC三阶段检测方法。第一阶段在快速的基础上针对原始YOLOv7算法目标方向性特征丢失、对特征图未充分利用、小尺寸缺陷难以检测等不足,结合Rep VGG网络结构对E-ELAN进行改进;引入CA高效注意力机制模块对特征图做进一步细化;针对小目标检测的问题引入Swin Transformer V2。第二阶段是对检测到的有疑似缺陷区域进行调姿聚焦,利于第三阶段的缺陷分类工作。在多方验证阶段,针对小目标及提高检测准确率问题,进一步对网络模型进行改进,在牺牲少量时间的基础上取得了更高的检测准确率,实验表明最终的检测准确率为98.54%。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.001412
{DOI}: 10.27461/d.cnki.gzjdx.2023.001412
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的汽车目标追踪方法
{Author}: 王文龙
{Tertiary Author}: 王晓原
{Publisher}: 青岛科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;深度学习;目标检测;目标追踪;驾驶安全
{Abstract}: 随着经济和社会的发展,我国汽车保有量不断增大。相比之下,我国公路总里程的增速十分缓慢,导致交通供需发展日渐失衡、安全等交通矛盾日益突出。近年来,智能化技术相继出现并蓬勃发展,智能汽车逐渐成为缓解乃至解决交通矛盾的有效手段,并被《中国制造2025》和《“十四五”现代综合交通运输体系发展规划》等国家政策列为重点支持对象。智能汽车是一个集合环境感知、规划决策、多等级辅助驾驶等多功能的综合系统。其中,环境感知是规划决策和辅助驾驶等的基础功能,直接攸关驾驶安全和效率。汽车行驶前向的车辆目标追踪是智能汽车环境感知的重要一环。汽车目标追踪方法的准确性和实时性对于保障智能汽车的行驶安全和效率至关重要。基于此,本文围绕“汽车目标追踪方法”展开,以机器视觉为主要技术手段,重点研究:(1)汽车目标追踪硬件选型及系统搭建。首先,考虑汽车所处交通场景的复杂性,系统地分析了用于车辆目标追踪的前端传感器和后端处理器的规格和性能要求;其次,基于分析结果,搭建由传感器和处理器共同构成的系统硬件部分;再次,针对现有公开数据集中部分类型车辆样本不足的问题,运用收集车辆图像并进行自标注的方法,扩充类型及其样本量,构建自建数据集;最后,在处理器上部署深度学习环境,完成系统搭建。(2)基于改进YOLOv5s算法的汽车目标检测方法。检测是追踪的前提。目标检测方法的性能直接影响目标追踪方法。在车辆检测方面,基于YOLOv5s的方法日渐兴起并广受认可。然而,既有基于YOLOv5s的汽车目标检测方法在检测精度、误检率以及复杂场景中的鲁棒性等方面仍有可提升的空间。针对此,本文提出了两种改进策略:其一是运用Co T3模块替换主干结构中的C3模块、其二是将损失函数替换为EIo U或SIo U,并运用消融实验分析改进效果。结果表明:运用Co T3模块和SIo U损失函数得到的改进YOLOv5s算法的综合性能更佳。同时,与YOLOv4-tiny和YOLOv7-tiny算法的对比实验结果证明了本文所建改进YOLOv5s算法检测性能的优越性;与未改进方法的对比结果显示,本文所建方法的精确度提高了5.7%、平均精度提高了7.4%。(3)基于StrongSORT算法的汽车目标追踪方法。在目标追踪方面,Deep SORT算法应用较多。但既有基于Deep SORT算法的汽车目标追踪普遍存在连续追踪时不够稳定、目标被遮挡后重追踪实现率较低等缺陷。针对此,本文提出一种基于Strong SORT算法的汽车目标追踪方法:首先,运用增强相关系数算法对连续两帧图像进行对比配准;其次,分别基于NSA卡尔曼滤波法和Bo T特征提取器实现对目标车辆运动特征和外观特征的重适应;最后,运用全局线性匹配代替Deep SORT算法中的级联匹配机制。对比和评价实验结果证明了本文所建基于Strong SORT算法的目标追踪方法算法性能,具体为:相较于基于Deep SORT的目标追踪方法,本文所建基于Strong SORT的方法在MOTA、IDF1和HOTA三个指标上分别实现了4.9%、7.4%和3.6%的性能提升。(4)考虑多种车辆类型的汽车目标追踪方法的验证与评价。为综合检验、评价所建基于改进YOLOv5s和Strong SORT的汽车目标追踪方法的整体实际应用性能,一方面本文运用行车记录仪采集的视频数据集,以平均漏检率、平均误检率、平均重追踪率、ID切换总数以及平均推理速度作为性能指标检验、评价所建方法性能。结果表明,在对车辆正常行驶有影响的前方区域内,所建方法在多种类型车辆的检测与追踪任务中实现了平均处理时间70.05毫秒、平均漏检率14.1%、平均误检率4.0%和平均重追踪率29.2%的性能。另一方面,组织了正常车流、拥挤车流、变道行为、转弯行为、照度变化、遮挡后重追踪六个典型交通场景中的自然驾驶实验,检验、评价所建方法实际部署到车辆平台的性能。结果表明,本文所建方法能够实现典型交通场景中前方多种车辆类型的目标检测与连续、稳定追踪,具有较高的鲁棒性。上述结果表明,本文中所提基于机器视觉的汽车目标追踪方法能够实现典型城市道路交通场景中包括小型乘用车、卡车、公共汽车等在内的多种车辆类型的目标检测和追踪。研究结果的鲁棒性和实时性较强,能够为智能汽车、先进驾驶辅助系统、自动驾驶等技术的发展和应用提供理论和方法参考。
{URL}: https://link.cnki.net/doi/10.27264/d.cnki.gqdhc.2023.001202
{DOI}: 10.27264/d.cnki.gqdhc.2023.001202
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的无人机航拍图像目标识别技术研究
{Author}: 吴丹丹
{Tertiary Author}: 胡焱
{Publisher}: 中国民用航空飞行学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 无人机航拍图像;嵌入式;并行计算;YOLOv3-tiny;TensorRT
{Abstract}: 将相机与深度学习算法相结合构成可以实现目标检测的智能处理系统,并将其部署在嵌入式计算设备中搭载于无人机上,可完成对无人机航拍图像的实时分析工作,在智慧交通和安防系统中有极高的市场应用价值。但是,在实际应用中,航拍图像分析往往要求高识别准确度、高实时性,除此之外为保证无人机续航,其对体积重量功耗要求极高,诸多技术难点亟待克服。首先,机载计算平台需使用嵌入式计算设备,但其算力低下往往不能满足;其次,受限于嵌入式Soc所使用的arm芯片和npu有限的计算效率,模型在全精度推理耗时较长,无法满足实时性要求;无人机获取的航拍图像中的目标物体尺寸小,又极易受到外界环境因素影响,进一步增加了航拍图像的目标检测难度。为了在计算资源有限的嵌入式计算设备上提高航拍图像目标检测的速度和准确度,本文基于NVIDIA Xavier搭建了一套基于深度学习的无人机航拍图像目标识别系统。利用SIMD技术实现图像前处理算法的并行化加速运算,使得程序执行效率提高了5倍以上,解决了前处理算法在实现过程中存在的大量时间开销问题。结合嵌入式计算设备的应用场景对比分析各种算法的优劣势,选择YOLOv3-tiny算法作为部署在嵌入式计算设备的目标检测算法,并利用TensorRT加速模型推理,最终该系统准确度可达90%以上,单张图像的推理时间为11.9ms,符合实时性要求。实验证明该系统可以按照预期完成搭载在无人机上的嵌入式计算设备的目标检测任务,准确率高且资源占用率低,而且还能最大限度地延长无人机的飞行时间。同时,该算法还具有极强的可移植性,可以根据实际任务需要应用于其他航拍目标的识别检测。
{URL}: https://link.cnki.net/doi/10.27722/d.cnki.gzgmh.2023.000055
{DOI}: 10.27722/d.cnki.gzgmh.2023.000055
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 番茄采摘车的目标识别定位与导航技术研究
{Author}: 钱振
{Tertiary Author}: 杨坚;易书新
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 番茄成熟度识别;番茄空间定位;多传感器融合;番茄采摘车;机器视觉
{Abstract}: 作为番茄第一大国,我国番茄年产量占全球的三分之一。目前,国内的番茄种植普遍选择传统模式,其中番茄采摘耗时耗力。随着机器视觉等技术的快速发展,番茄采摘车的研发已成为热点方向。但是,番茄温室内光照条件多变,番茄、枝叶之间存在遮挡,这导致现有的目标识别算法难以快速准确的识别番茄成熟度。由于番茄体积小、果实密集,导致了番茄空间定位困难。此外,番茄作物之间间距狭长、温室环境复杂,使得番茄采摘车难以实现自主移动。因此,本文旨在设计一种视觉系统,使得番茄采摘车能够实现番茄成熟度识别、果实空间定位和自主移动等功能,并在真实的番茄温室环境下进行验证试验。本文的主要研究内容和结论如下:(1)以红风铃番茄为研究对象,制作了适用于成熟期为红果的小番茄数据集,该数据集可识别番茄的成熟度。提出基于改进YOLOv4-tiny的神经网络模型,通过在头部网络部分增加第三个检测头来提高小目标识别准确率;将CBAM模块融入到骨干部分,以提高被遮挡番茄的识别准确率;采用密集连接结构来加强全局特征信息的融合;在主干网络部分使用Mish激活函数来确保深层卷积中提取特征的准确性。试验结果表明,与 YOLOv3、YOLOv4、YOLOv4-tiny、YOLOv5m 和 YOLOv51 模型相比,YOLOv4-tiny-X模型在保证极高检测速度的前提下,具有最高的平均精度均值,平均精度均值分别提高了 30.9、0.2、0.7、5.4和4.9个百分点,改进模型的平均精度均值为97.9%,识别速度为111帧/s。实时识别的可视化结果表明,面对复杂的环境,改进的神经网络模型具有稳定性。(2)在室内实验室搭建番茄模型,用于番茄空间定位试验。首先使用标定板对双目相机标定以获取Intel RealSense D435i相机的内、外参数;然后利用相机内、外参数进行立体矫正和RGB-D图像配准;接着使用YOLOv4-tiny-X模型实时识别出番茄ROI,用于获取番茄的中心点;最后通过番茄ROI中心点坐标和相机坐标系转换,求出番茄的空间位置。番茄空间定位试验结果表明,提出的方法可以获取全部番茄的三维坐标。测量误差对比试验表明,当双目相机与番茄的距离在0.2-0.5米之内时,使用双目相机结合YOLOv4-tiny-X模型对番茄进行三维定位的距离误差小于3毫米。(3)在Gazebo仿真环境下进行番茄采摘车建图与导航试验。首先搭建番茄采摘车模型与番茄温室模型。接着使用拓展卡尔曼滤波融合多传感器的方法对番茄温室进行周围环境感知,用于采摘车定位和建图。试验结果表明,多传感器融合后构建的温室地图更加精准;最后在番茄温室栅格地图上指定目标点,番茄采摘车通过A*算法可以在地图上规划出一条合理的路径,且在自主移动过程中不断优化路径,实现了番茄采摘车自主导航的功能。(4)开展系统验证试验,将提出的算法模型搭建在番茄采摘车上,番茄采摘车对温室内的番茄进行成熟度识别、定位,以及在温室内构建高精地图与自主导航。试验结果表明,在真实的番茄温室下提出的方法与仿真环境下表现类似,可准确的识别出番茄的成熟度;通过Intel RealSense D435i红外双目相机在复杂的环境下能对番茄果实进行空间定位;番茄采摘车在真实的番茄温室可以构建高精度的室内地图并实现自主导航功能。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2023.002664
{DOI}: 10.27441/d.cnki.gyzdu.2023.002664
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的光伏板故障检测算法研究
{Author}: 沈灵鑫
{Tertiary Author}: 王银
{Publisher}: 太原科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 光伏板故障检测;深度学习;语义分割;目标检测;Transformer
{Abstract}: 近年来,随着光伏产业的发展壮大,光伏系统安全稳定地运行关系到光伏电站的发电效能和经济效益,如何高效经济地完成光伏电站的日常运维成为了关键问题。传统的光伏电站运行维护主要基于光伏逆变器的电气特性或经典的图像处理方法,无人机巡检的兴起与发展极大地改变了这一现状,无人机携带的红外相机可以发现光伏板的内部故障,结合基于计算机视觉的深度学习检测方法可高效精确地检测出光伏板的多种常见故障,节省大量人力物力。本文使用基于深度学习的语义分割和目标检测算法,对红外光伏板故障检测任务进行了研究,具体的研究内容包括:首先,对无人机采集的光伏板红外图像进行数据增广后使用Labelimg数据标注软件进行人工标注,整理为PV＿larege和PV＿roof两个数据集,然后介绍了常用的数据预处理和增强方式。然后,为了消除后续检测中无关背景带来的负面干扰,设计了两种基于深度学习的语义分割网络对光伏板区域进行提取。以改进后的Deep Labv3+网络为基础,针对PV＿large数据集边缘断续腐蚀问题,设计了融合边缘特征的Deep Labv3+语义分割网络,进一步优化了边缘细节,分割准确率达到99.96%;针对PV＿roof数据集因受屋顶彩钢瓦干扰而导致的背景误分割问题,设计了融合视觉特征的语义分割模型,提取红外光下光伏组件和彩钢瓦的纹理特征并在聚类后进行选择性抑制,减少了屋顶背景的误分割现象和光伏组件的内部空洞,分割准确率达到96.15%,为后续检测工作提供了良好的输入。最后,将基于Transformer的PVT-v2结构与改进后的YOLOX结合,设计了针对集中式分布的红外光伏板的故障检测模型PV-YOLO,在PV＿large数据集上进行的实验证明在相同参数量级下本文算法具有明显的精度优势,最高m AP达到92.56%。针对屋顶光伏板故障检测任务特点,进一步精简网络,设计了轻量级光伏板故障检测算法PV-YOLO-Tiny,在PV＿roof数据集上与YOLO系列的轻量模型进行了对比试验,证明了该网络的优越性。
{URL}: https://link.cnki.net/doi/10.27721/d.cnki.gyzjc.2023.000394
{DOI}: 10.27721/d.cnki.gyzjc.2023.000394
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的手势识别算法研究
{Author}: 孙欢
{Tertiary Author}: 杨铁梅
{Publisher}: 太原科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 手势识别;VIT;迁移学习;ResNet
{Abstract}: 随着人工智能产业的发展,人与计算机的交互也越来越智能化。传统的手势识别依赖于特定设备或者数据手套,其准确率低且价格相对昂贵。计算机技术的发展和网络摄像头的普及,使得基于计算机视觉的手势识别方法具有成本低、准确率高、实时性强等特点,研究起来十分有必要,不仅可以提高用户体验,也会促进手势识别的应用。手语识别的基础是手势的识别,通常情况下,手势可以分为静态手势和动态手势,静态手势用一张图片来表示,与动态手势相比特征更加固定,更容易处理。本文利用卷积神经网络和深度学习相关理论对静态手势识别进行研究,主要研究内容概括如下:1、数据集制作及预处理。针对开源的手语数据集,将数据集中符合要求的图片挑选出来。采用超分辨率重建算法SRGAN对获取到的图像进行重构,解决手势图像分辨率低的问题,最后使用数据增强操作将图像汇总制作样本充足的数据集。2、针对自制数据集规模小的问题,使用Transformer在视觉领域初次使用的Vision Transformer(VIT)网络训练手势图像,将VIT分类网络进行迁移学习,在ImageNet数据集上训练好权重参数,将其迁移至本文数据集进行再训练,以提升检测速度。3、针对传统CNN分类网络感受野小,不捕获全局特征,Transformer缺乏归纳偏置不能获得先验信息的问题,提出一种结合ResNet和Transformer的静态手势识别方法,将ResNet的卷积操作引入Transformer结构,设计轻量级多头注意力以及局部感知单元提取局部和全局特征,在网络参数量变化不大的情况下使网络能更好的提取特征,提高模型的准确率。最后运用迁移学习将改进后的网络在ImageNet中训练得到预训练模型,将此模型用到自制数据集中。通过分析实验结果,验证本文算法的鲁棒性和泛化性。
{URL}: https://link.cnki.net/doi/10.27721/d.cnki.gyzjc.2023.000507
{DOI}: 10.27721/d.cnki.gyzjc.2023.000507
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的低光照图像增强
{Author}: 胥鹏
{Tertiary Author}: 王正宁
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 低光照图像增强;图像去噪;注意力机制;生成对抗网络;深度学习
{Abstract}: 低光照图像增强旨在解决光线较暗的条件下捕获的低质量图片的一系列退化问题。在拍摄环境较差,拍摄人员和设备不够专业等因素的影响下,拍摄的图片往往有光照不均匀、噪声严重、细节丢失严重、极端低光照等问题。增强低光照图像,解决退化问题,不仅可以优化图像识别等高水平视觉任务的性能,还能提高如自动驾驶等实际应用的性能。然而,在真实低光照图像的增强方面仍存在一些问题。典型的,在光照不足的条件下捕获的真实低光照图像受到严重的噪声影响,现有方法大多采用附加的去噪方法作为预处理或者后处理,但是前者会导致模糊,后者会导致噪声放大。此外,低光照图像增强过程中还会有严重的细节损失问题。针对这些问题,本论文围绕去噪和细节恢复两个方面,开展了大量面向低光照图像增强的方法研究。具体研究内容如下:1.基于Retinex的低光照图像增强方法研究。为了有效抑制噪声、恢复细节,提出了一种新的基于Retinex理论的有监督卷积网络模型。该模型有三个子网络,具体来说,提出了由多尺度U型编解码网络构成的分解网络,其以正常光图像的反射图作为约束将输入图像分解为光照图和反射图。另外,设计了新的反射重建网络,其可以根据光照图的信息重建反射图,使用由空间注意力机制、通道注意力机制、残差单元和空洞卷积组成的多块联合注意力残差单元来实现去噪的同时增强对比度。还构建了光照调整网络调整低光照图像的光照图,结合反射重建网络得到的反射图,以得到更高质量的正常光照图像。实验证明,本方法可有效减少噪声和颜色失真的影响,并提高图像增强的效果。2.基于多注意力生成对抗网络(Generative Adversarial Network,GAN)的低光照图像增强方法研究。提出了一种基于双鉴别器GAN的无监督增强方法,融合全局和局部特征实现低光照图像增强,克服了有监督方法对成对数据的依赖。提出一种多注意力机制引导的多尺度U型编解码网络生成器,并使用全局鉴别器和局部鉴别器共同引导图像的鉴别,全局鉴别器关注图片结构和光照增强,局部鉴别器关注区域细节和光照增强。引入光照通道作为输入,并使用联合注意力模块进一步增强网络的注意力引导能力,有针对性地捕获图像中的重要信息。同时,在编解码网络中引入Nonlocal模块以保留更多的细节信息。联合使用感知损失和对抗性损失进行训练。实验证明,本方法达到了较好的低光照图像增强效果。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003242
{DOI}: 10.27005/d.cnki.gdzku.2023.003242
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多传感器融合与深度学习的目标检测模型与算法的研究
{Author}: 邬驰宇
{Tertiary Author}: 张小川
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;侵限检测;多传感器融合
{Abstract}: 目标检测在深度学习技术融入后取得了极大的发展,在工程侵限检测领域中开展了许多应用。小范围现场的工程侵限检测如车辆侵限检测、轨道侵限检测等复杂场景依靠单一视觉传感器难以获得精确结果,需要融合激光雷达这样的点云传感器提升算法检测能力。大范围超视距的火灾侵限检测需要融合多源的遥感图像传感器数据用于检测。本文针对以上问题和需要,以计算机视觉的深度学习目标检测模型与算法为研究核心,辅以多传感器融合技术,应用于具体的工程侵限检测中。具体的研究内容如下:(1)在深入研究 FasterRCNN(Faster Region based Convolutional Neural Ne-twork)、SSD(Single Shot multi-box Detector)、RetinaNet、YOLOv3(You Only Look Once v3)这4种目标检测算法的基础上进行充分实验和讨论,选择YOLO v3为基准模型进行改进,在消融实验的基础下选择以ASPP(Atrous Spatial Pyra-mid Pooling)和 PAN(Path Aggregation Network)改进模型结构,以 Mosaic 数据增强、Mixup数据增强、仿射变换数据增强三种数据增强方法提升数据质量,以GIoU(Generalized Intersection over Union)损失函数改进原损失函数的设计偏向,改进的YOLOv3算法较原方法整体地提升了算法检测精度,对算法推理速度几乎没有影响,特别是提升了算法对不同尺寸图像的特征提取能力,提升了对低置信度分数的检测框的重视程度。(2)提出一种改进YOLOv3结合点云的车辆侵限检测算法,应用于小范围的高压线缆的工程侵限检测,经图像目标检测获取图像检测框,基于激光雷达和相机下多传感器的外参矩阵获得相关点云,经点云算法获得检测框内车辆距线缆的距离,具有较高的检测精度和实时性。(3)提出一种Deeplabv3+结合点云的轨道侵限检测算法,应用于小范围的轨道侵限检测,需多传感器数据融合,经图像检测获得轨道范围,基于点云数据检测轨道范围内障碍物的距离,具有较高的检测精度和足够的实时推理速度。(4)提出一种基于映射表的遥感多源图像数据融合算法,选定研究区域及遥感传感器情况下,算法时间复杂度低于一般方法,将此方法用于大范围超视距的火灾侵限检测,实验证明了遥感图像传感器融合算法的可行性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.000014
{DOI}: 10.27005/d.cnki.gdzku.2023.000014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视频图像的车辆检测跟踪及车速检测算法研究
{Author}: 姚琼辛
{Tertiary Author}: 李钢
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;视频图像;目标检测;多目标跟踪;车速检测
{Abstract}: 智能化的车辆检测跟踪及车速检测对提高城市交通治理水平、解决交通安全问题具有重要的意义。现阶段,受天气、目标遮挡、形变等因素的影响,基于视频图像的车辆检测及跟踪技术存在检测鲁棒性差、错误率高以及跟踪ID变化频繁等诸多问题。针对上述问题,本文聚焦于城市与高速公路交通场景中车辆的检测跟踪以及车速检测算法研究,旨在提高跟踪与检测的精度,在此基础上获取车辆行驶速度,实现车辆超速行为的检测。本文主要贡献如下:1.本文基于精度与速度均高的YOLOX-s目标检测算法,针对车辆的类内遮挡现象提出改进策略。首先,使用Ghost卷积替换YOLOX-s主干网络中的普通卷积,减少模型参数量,从而提高模型的检测效率;然后,引入CBAM注意力机制,增强重要的特征,削弱不重要的特征,从而达到优化模型的目的;最后,考虑了预测框和检测框的长宽比以及两框中心点距离,改进损失函数及非极大值抑制,使检测框定位时更加精准。同时制作数据集,在自制数据集上对原始的YOLOX-s与改进的YOLOX-s算法进行训练以及测试,得到车辆检测器。实验结果表明,改进后的YOLOX-s算法的检测性能优于原始的YOLOX-s,其检测速度达到了77f/s,检测精度达到了92.8%,比原始模型提升了1.7%。2.本文以目标检测的结果为基础,采用多目标跟踪算法DeepSort对检测到的车辆进行跟踪,针对ID转换频繁的问题对DeepSort算法提出改进策略。一是使用改进的宽残差网络代替原始的残差网络,将宽残差网络的图像输入大小修改为128×128,使模型更适合本文的交通场景;二是将中心损失函数与softmax损失函数结合,提高卷积神经网络特征提取能力。最后在改进的YOLOX-s基础上对改进的DeepSort进行训练以及测试,得到最终的车辆跟踪结果。实验结果表明,改进DeepSort算法的跟踪精度有了一定程度的提高,并且ID变化次数也有所减少。3.本文在改进的YOLOX-s目标检测与DeepSort多目标跟踪算法的基础上,检测车辆行驶速度,从而判断车辆超速行为。首先,使用相机标定技术将像素坐标系转化为世界坐标系,通过车辆移动位置的像素距离来计算车辆实际位移,从而计算实时车速。其次,将本文基于视频的测速方法所得速度与人工标定的测速方法所得速度进行对比分析,证明了本文测速方法的可行性及有效性。最后,建立超速检测模型实现车辆超速行为的检测。实验结果表明,本文所提出的测速与超速行为检测方法稳定有效,且具有一定的实际应用价值。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2023.002137
{DOI}: 10.26976/d.cnki.gchau.2023.002137
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉和深度学习的隔震支座动态位移测量方法
{Author}: 党育;贺一哲
{Author Address}: 兰州理工大学土木学院;
{Journal}: 振动与冲击
{Year}: 2023
{Volume}: 42
{Issue}: 06
{Pages}: 90-97+165
{Keywords}: 深度学习;计算机视觉;隔震支座;动态位移;YOLOv5
{Abstract}: 针对地震时隔震支座的视觉测量特点，即地震时相机与隔震支座均会发生运动，且不便追踪相机位姿，提出一种无需额外跟踪相机运动的隔震支座动态位移测量方法。首先，沿结构水平两个正交方向，分别设置相机和标靶，且相机光轴与标靶平面相互垂直，用比例因子法对各方向各时刻的相机进行标定；其次，采用深度学习方法，训练一个YOLOv5模型以自动识别和定位标靶，再对YOLOv5的目标框放大并对目标框内的图像进行特征识别和提取，二次精确定位标靶；最后，使用支座上、下连接板处标靶的相对位移，确定隔震支座的动态位移。通过拍摄一个LRB500隔震支座力学性能试验过程，对提出的方法进行验证。结果表明：该方法得到的支座水平位移时程曲线与位移计结果在各时刻的误差均小于1.0%,水平向位移峰值的绝对误差最大为1.042 mm,竖向位移峰值的绝对误差最大为0.219 mm,说明提出的方法具有较高的检测精度，可以在无需追踪相机位姿的情况下，完成隔震支座在地震作用下的变形检测。
{ISBN/ISSN}: 1000-3835
{Notes}: 31-1316/TU
{URL}: https://link.cnki.net/doi/10.13465/j.cnki.jvs.2023.06.011
{DOI}: 10.13465/j.cnki.jvs.2023.06.011
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的图像匹配方法研究
{Author}: 鹿志旭
{Tertiary Author}: 周天池
{Publisher}: 盐城工学院
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像匹配;SURF算法;ORB;双向近邻FLANN匹配
{Abstract}: 图像匹配是通过分析图像的纹理、灰度等特征信息,从而达到匹配相似或相同图像的方法,是机器视觉和图像处理技术研究中最关键的一步,已经被广泛应用于工业瑕疵检测、物体识别与定位、医疗图像分析、无人驾驶等领域。图像匹配方法一般分为基于灰度信息和特征信息两类,前者计算复杂耗时长,后者计算简单耗时短且对复杂变化有较强的鲁棒特性。目前,国内外学者针对图像匹配方法做了大量改进研究,但面对实际应用场景下图像采集环境的复杂多变,如光照、视角等,图像匹配仍会出现准确率下降等问题,因此对复杂多变的场景下的图像匹配技术进行研究就显得尤为重要。本文将围绕基于特征的图像匹配方法进行深入研究,并提出能够在复杂多变的场景下保持较好性能的改进算法。论文的主要工作包括:(1)重点介绍了SURF(Speeded Up Robust Features)算法和ORB(Oriented FAST and Rotated BRIEF)算法两种基于点特征的特征提取方法,系统分析了算法的基本原理和实现过程,对算法的优缺点进行了分析。并分析了图像匹配方法的几种关键技术,预处理的方法、基本组成要素、匹配方法的分类和性能的评估标准,为后续章节做理论支撑。(2)由于传统SURF算法在面对旋转变换大的场景下旋转性不佳,特征描述符构建后易出现误匹配。对于这个问题,通过对DAISY描述符深入研究,将DAISY描述符引入到SURF算法加以改进,构建了一种改进SURF特征点的匹配图像算法。该算法首先由SURF算法进行特征检测,然后使用DAISY描述符完成特征描述,最后在欧氏距离初始匹配的基础上采用随机抽样一致性算法进行误匹配剔除完成匹配。本文采用三组发生不同变化的图像同传统SURF算法进行对比分析研究。实验结果表明:本文改进的SURF算法,保证SURF算法特征检测能力的同时,在旋转、灰度、图像模糊、JPEG压缩、光照等变换或实拍图像的场景中,相较于传统SURF算法在维持较高正确匹配点对数的前提下,降低了运算时间,提高了数据处理效率,也保证了算法的实时性。(3)针对ORB算法不具备尺度不变性和传统图像识别方法识别效率低等问题。结合SURF算法性能的优势,构建了一种改进ORB-FLANN的工件图像识别方法,并应用于工件图像识别场景进行验证。对ORB算法检测出来的特征点采用SURF完成特征描述符的构建。在特征匹配阶段,对于原始FLANN匹配会存在一对多等误匹配问题,提出一种双向近邻FLANN匹配方法,通过此方法实现改进算法的粗匹配,保留可靠性更高的特征点。最后采用PROSAC完成对其他误匹配点对的剔除,提高图像匹配的精确度。实验结果表明,该算法同其它现有文献算法相比,改进算法在处理不同变换图像时,匹配正确率分别提高2.6%～18.8%和29.5%～43.9%,相对算法耗时控制在4s以内,同时提高了对工件图像的识别效率,且改进算法具有尺度不变性。
{URL}: https://link.cnki.net/doi/10.44381/d.cnki.gycit.2023.000120
{DOI}: 10.44381/d.cnki.gycit.2023.000120
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的一种改进铁轨表面缺陷检测方法
{Author}: 李国旺;李英;马韵琪;夏晨旭
{Author Address}: 长春理工大学光电工程学院;
{Journal}: 湖北师范大学学报(自然科学版)
{Year}: 2023
{Volume}: 43
{Issue}: 01
{Pages}: 33-39
{Keywords}: 机器视觉;缺陷检测;阈值分割;特征提取
{Abstract}: 由于机器视觉对铁轨表面进行缺陷检测时，其检测的缺陷大小远超过实际缺陷大小，为提高检测缺陷大小的精准性，提出基于机器视觉的一种改进铁轨表面缺陷检测方法。首先，提出一种基于边缘灰度值水平投影最大值的轨道边缘提取算法，在经过边缘检测后的图像中定位出轨道的真正边缘；然后，利用自适应降噪双边滤波保留缺陷边缘，针对性去除轨道表面噪声，避免了图像分割后需要进行形态学处理而造成的缺陷损失；最后，基于Otsu阈值分割引入背景加权，使分割的缺陷更接近实际缺陷。实验结果表明，低于50个像素的缺陷部分准确率和召回率分别达到：99.64%和100.00%,高于50个像素的缺陷部分准确率和召回率分别达到：97.89%和99.58%.
{ISBN/ISSN}: 2096-3149
{Notes}: 42-1891/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzVoHCDP144Gg227Hj7Mbu10LuEVls_dECqOMfMY4vKBLIwYGsyroYOSgI7Tuv2bANADyo_FLt0qDlaQaMczqQlSPwLjyUVZHicVnVzK_GMNmr2ht_QzzEb5XHx1u2J8pr9UAT9G_8wKoZcVwD-SEACKaeOisdBklcOLViGhiDx2VXJd9IHRWHMEfqizeRbIOI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv4的轻量化菠萝苗心检测算法
{Author}: 张日红;区建爽;李小敏;凌轩;朱政;侯炳法
{Author Address}: 仲恺农业工程学院机电工程学院;
{Journal}: 农业工程学报
{Year}: 2023
{Volume}: 39
{Issue}: 04
{Pages}: 135-143
{Keywords}: 机器视觉;图像处理;菠萝催花;目标检测;深度可分离卷积;GhostNet;YOLOv4
{Abstract}: 当前菠萝催花作业以人工喷洒为主，生产效率低、劳动强度大。菠萝苗心位置的精准识别和定位是实现机械化、智能化菠萝催花的核心问题。该研究在YOLOv4目标识别算法的基础上，选择GhostNet作为主干特征提取网络，构建了一种混合网络模型，并在颈部网络中融合深度可分离卷积与轻量级的注意力模块。改进后的模型相较于YOLOv4模型的总参数量减少70%。与YOLOv4、Faster R-CNN和CenterNet 3个模型进行检测对比试验，结果可得：改进模型在菠萝植株种植密集与稀疏的条件下识别精度分别为94.7%和95.5%，实时识别速度可达27帧/s，每张图像平均检测时间为72 ms，相比常规YOLOv4模型用时缩短23%。总体性能表现均优于对比组的目标检测模型。总的来说，改进模型YOLOv4-GHDW在一定程度上实现了检测速度、识别精度和模型体量三者之间平衡，能够在实际种植环境下对菠萝苗心有较好的识别效果。研究结果可为智能化菠萝精准催花设备研发提供视觉技术支持。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://link.cnki.net/urlid/11.2047.s.20230320.1757.038
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 工业图像无监督异常检测与定位研究
{Author}: 黄超
{Tertiary Author}: 吴洪
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 工业缺陷检测;异常检测与定位;聚类学习;特征原型;图像修复
{Abstract}: 随着工业4.0的发展,智能制造越来越受重视。作为智能制造中关键的一环,工业图像缺陷检测有助于提升生产效率与降低工业成本。与传统图像异常检测不同,工业缺陷检测不仅需要进行图像级的异常判断,还需要定位到具体的异常区域,涉及异常检测和异常定位两个任务。由于实际工业场景中存在异常数据难获取、标注成本大等问题,当前的研究工作均采用无监督学习算法,即只根据正常图像构建检测模型。本论文针对工业图像的无监督异常检测与定位算法进行研究,利用深度学习与无监督学习的相关理论与技术,设计了三种不同的算法模型,并通过在MVTec AD与BTAD两个真实工业缺陷检测数据集上的实验证明了算法的有效性。本论文的具体研究工作与主要贡献如下:(1)受到语义分割的启发,将问题建模为像素类别分配任务,并提出了一个基于特征聚类学习的检测模型Pixel AD。训练阶段进行正常像素特征聚类,以簇集作为伪类别,从而为训练样本赋予像素级伪类别标签,进行像素级分类学习。由于异常区域像素与正常模式的差异性,模型无法以高置信度对其进行类别分配,因此基于置信度计算像素级异常得分以进行异常检测与定位。实验表明,该算法能够准确检测到不同类型与尺寸的异常区域,且适用于不同工业应用场景。(2)针对基于分布外检测(out-of-distribution,OOD)方法推理效率低的问题,提出了一个基于特征原型学习的异常检测网络Proto AD。该算法无需训练,直接利用预训练特征提取器得到正常像素特征并进行L2范数归一化,进行非参数聚类自动找到特征原型。通过在特征提取器后附加一个L2范数归一化、一个1×1卷积层、一个通道最大池化操作和一个减法操作来构造端到端的异常检测与定位网络,并将原型作为其中1×1卷积层的核参数。实验表明,该算法达到了与SOTA方法相当的检测性能,并且显著提升了基于OOD方法的推理效率。(3)针对基于图像修复策略检测方法存在的不足,提出了一种全新的图像修复模型Mae AD,其由非对称的Transformer编解码模块和轻量级卷积U-Net细化模块组成。其中Transformer善于捕获长距离信息与建模高级语义结构,CNN模块善于修复图像局部区域细节。同时还采用了层次特征对齐损失,在训练时增加了特征空间的一致性约束,并在测试时参与异常得分计算。实验表明,该算法达到了这类方法中的最佳性能,且缩小了基于重构方法与基于OOD方法间的性能差距。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.003277
{DOI}: 10.27005/d.cnki.gdzku.2023.003277
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的独居老人摔倒行为监测研究
{Author}: 何中力
{Tertiary Author}: 郑忠龙
{Publisher}: 浙江师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 目标检测;行为识别;双流卷积网络;摔倒检测
{Abstract}: 随着我国经济的快速发展,人们生活水平不断提高,对自身健康问题也越来越关注,尤其是独居老人,由于其特殊的生理特征,在疾病和意外事故发生时无法得到及时且有效的治疗。因此如何对老年人摔倒行为进行监测成为当前研究热点之一。随着计算机技术、图像处理等相关软件不断发展,出现了各种基于深度学习的新型智能辅助设备,这些设备通过对老年人异常状态的实时监测,能有效地提高医疗效率,同时减轻医务人员的压力。由于老年人身体机能下降、反应迟钝等特点,常常会因为缺乏有效的监护措施而产生危险,如在家跌倒、高血压等。本文实现了一种基于视频信号的摔倒监测系统,旨在快速有效地对老人的摔倒行为进行监测、及时发现危险并预警,为老人的救治争取宝贵时间,还通过对监测数据的可视化显示解决了老人的监护问题。
现有的基于计算机视觉的摔倒检测算法对于多人复杂环境下的摔倒检测,存在实时性差的问题。现有算法多针对单人场景,在多人场景中,如果不将信息筛选直接传入摔倒识别网络,就会导致网络负载。其次现有行为识别网络对于多人场景下小目标摔倒行为识别并不如意,因为在现实的监测环境中,监控中的远景目标在整个图像中占比小,这一类小目标的细节信息会在不断加深的网络中丢失,从而造成漏检。
本文针对以上问题进行了如下研究:
1.针对多人复杂环境下实时性差的问题,采用Openpose的骨骼识别算法,结合目标检测模型对人体骨骼关键点进行检测。首先使用目标检测模型对人体进行检测,将检测模型得到的人体区域送入骨骼识别模型中提取骨骼关键点,从而降低复杂环境带来的干扰。分析摔倒特征与蹲下等日常行为特征的区别,选用颈部关键点垂直方向的高度差和颈胯连接线与垂直方向的角度作为判断特征,当特征变化超过一定阈值时,将判定可能发生摔倒行为,对可能发生摔倒的人体区域进行截取保留,从而减少信息的传输量,提高实时性,以此设计了一种基于骨骼点特征的摔倒预判断方法;
2.为了提升对小目标行为识别的准确度,在双流卷积网络的空间流网络中加入多特征融合模块,使得浅层与深层网络得到的不同尺度的特征信息进行融合,改善小目标的细节信息在不断加深的网络层数中造成丢失的问题。本文的双流神经网络采用时空异构的方法对信息进行提取,空间流网络选用Res Net作为基础网络对空间信息进行学习,时间流网络选用BN-Inception作为基础网络对时序信息进行学习。通过在多种数据集上的仿真实验,本文提出的算法与传统方法相比,具有一定的优越性;
3.在系统应用方面,设计并实现了人体检测、摔倒检测和危险警报模块,通过这些模块将视频流发送到视频监控中心,并完成对目标对象的检测和摔倒动作的判断,实现老人摔倒的实时监测和报警。
{URL}: https://link.cnki.net/doi/10.27464/d.cnki.gzsfu.2023.000882
{DOI}: 10.27464/d.cnki.gzsfu.2023.000882
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的金属工件智能分拣系统设计
{Author}: 张炳星;高军伟
{Author Address}: 青岛大学自动化学院;山东省工业控制技术重点实验室;
{Journal}: 工具技术
{Year}: 2023
{Volume}: 57
{Issue}: 03
{Pages}: 140-144
{Keywords}: 机器视觉;SOA-OTSU;Blob连通域;Arduino控制
{Abstract}: 针对传统工业中人工分拣效率低和成本高等问题，设计了基于机器视觉的机械臂智能分拣系统。通过摄像头采集图像并对图像进行灰度滤波操作后，使用SOA-OTSU算法对图像进行阈值分割，对目标区域进行Blob连通域分析，实现对工件的识别与定位。运用标准D-H参数法建立三自由度机械臂模型，将工件位置坐标代入逆运动学方程，解得每个连杆的关节转角，将其转化为机械臂步进值，并通过串口通信方式发送给Arduino,由Arduino控制机械臂完成工件的抓取与放置。实验结果表明，该方法提高了分拣系统抓取的准确性。
{ISBN/ISSN}: 1000-7008
{Notes}: 51-1271/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyl4IAa7Re7nFjyIi2qdVKd_5XNEFE-JwE45mkNDrAeQveGoA0tPWe6HBwGdOg7XPiQT0cGDu_ce-kxM8vNw8dRDd9k-gFblAHX-QPzjvoUCu_w0DQUhPxkGRfMEZsIISjUSRgsc_tawqoqWZIQmF8bEk0B7cmMBeMT8Qwl6wUrYpzbyMi9C8YO9ud1RvyTfV8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的自监督医学图像分割算法研究
{Author}: 陈坤
{Tertiary Author}: 顾实
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学影像分析;自监督学习;Transformer;知识蒸馏;语义分割
{Abstract}: 医学图像分割作为辅助医疗诊断的重要手段,在临床上有着广泛的应用。随着深度学习的快速发展,卷积神经网络在计算机视觉领域的地位受到了挑战。Transformer在自然场景图像分割方面表现出卓越的性能,这得益于其捕获远距离特征的能力。为了研究基于Transformer的分割模型在医学图像上的效果,本文提出了一种新的自监督医学图像分割架构。通过设计代理任务进行预训练,使模型更好的提取和处理医学图像的视觉信息,然后在分割任务上进行微调,以此解决医学图像缺乏大规模标注数据的困难。通过在两个主流数据集上进行的大量实验,验证了所提出的TF-UNet模型在医学图像分割任务中的有效性。并且与其他主流模型的比较表明,该模型在大多数场景下表现优异。此外,为了平衡分割的精度和效率问题,本文进一步提出了一种基于知识蒸馏的改进模型TF-KDNet。它将TF-UNet模型作为教师模型,同时训练一个较小的学生模型,通过最小化教师模型输出和学生模型输出之间的距离,来传递教师模型的知识。通过实验证明,这种方式可以在保持准确性的同时,大大降低计算成本和内存占用,为医学图像分割提供了可替代方案。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.004524
{DOI}: 10.27005/d.cnki.gdzku.2023.004524
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的小目标检测跟踪算法研究与应用
{Author}: 钟行
{Tertiary Author}: 李凡
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小目标;上下文信息;全局注意力机制;多角度信息
{Abstract}: 随着各类陆基、空基和天基等监控设备的不断普及,军事防御、公安追查以及城市服务等领域对图像中的小型目标检测跟踪提出了迫切需求。由于小目标具有覆盖面积小、边界模糊、运动时容易出现大幅位移以及遮挡等问题,导致通用的检测跟踪算法难以获取到准确的小目标深层特征以及目标匹配度。针对上述挑战,本文基于先检测后跟踪的算法框架展开研究,分别从以下三个方面进行改进:（1）提出一种基于上下文信息的特征提取主干网络。随着算法中的不断下采样,小目标会在分辨率小的深层特征图上出现信息模糊、丢失甚至完全消失的现象。本文针对该问题提出一种上下文信息特征提取主干网络,采用了基于swin transformer的多头注意力机制模块获取较大感受野的上下文信息,然后将其与主干网络得到的特征信息相融合,作为小目标特征丢失时的信息补充。为了进一步提高小目标的定位精度,提出一种浅化特征头策略,增加检测头特征图的分辨率以提升算法对于小目标的针对性和适用性。（2）提出一种基于全局注意力机制的多路径特征融合网络。为了增加网络对目标上下文和特征信息的传递和融合能力,采用全局注意力机制放大全局维度特征,并使用来自融合网络浅层、深层以及主干网络的多条路径,对特征信息以及上下文信息进行补充。实验表明,在Vis Drone2019数据集上,本文提出的基于上下文信息和注意力机制的目标检测算法CGA-YOLO相比YOLOv5l模型在m AP指标上有5.4%的提升,并且在小目标存在遮挡、密集排列的场景中有更突出的表现。（3）提出一种基于多角度信息的多目标跟踪算法。为了解决因小目标信息模糊造成检测框浮动,导致的跟踪匹配失败问题,本文分别从扩大特征信息、增加定位差异度以及预测运动轨迹三个方面对算法进行改进,在增加同一目标在相邻帧间匹配相似度的同时,提高遮挡、漏检等异常情况下小目标的跟踪匹配率。实验表明,在PESMOD数据集上,本文提出的多角度信息目标跟踪算法MD-Deep SORT对比Deep SORT算法能减少42.6%的IDS问题,并在IDF1值上有9.7%的提升。最后,本文在上述研究基础上设计并实现了一个智能交通密度监测和目标跟踪系统,在平台中对本文提出的算法进行应用。系统测试结果表明,本文提出的小目标检测跟踪算法能高效完成目标监控任务,具有较高的准确性和应用价值。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001569
{DOI}: 10.27005/d.cnki.gdzku.2023.001569
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进YoloV5和Openpose的分心驾驶行为识别研究
{Author}: 杨楠
{Tertiary Author}: 赵骥
{Publisher}: 辽宁科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 分心驾驶;计算机视觉;YoloV5;Openpose;欧几里得距离
{Abstract}: 随着现代汽车工业的发展,驾驶机动车时吸烟或接打电话的行为是一个很普遍的现象,这类普遍的行为会导致司机在驾驶过程中注意力分散,从而造成灾难性的后果。因此,分心驾驶的检测与道路交通安全息息相关,利用计算机视觉技术监测驾驶员是否分心并报警,有利于帮助驾驶员集中注意力,避免交通安全事故的发生。目前国内外分心驾驶行为识别解决方案分为两种:一种是围绕车辆行驶轨迹的变化进行判断,另一种是围绕驾驶员外在的生理表现进行判断。通过间接监测车辆行驶轨迹变化的方式,虽然不会对驾驶员造成干扰,但是车辆差异和驾驶员驾驶习惯等因素都对分心驾驶的识别带来了挑战。另外,直接监测驾驶员心率、血压、脑电信号等生理指标数据的方式,往往需要佩戴繁琐的检测仪器,长时间佩戴会引起驾驶员的不适。随着机器学习领域算法精准度和鲁棒性的不断提高,为识别分心驾驶行为带来了新方向。本文针对吸烟分心驾驶行为和接打电话分心驾驶行为,提出了一种基于计算机视觉的二阶段分心驾驶行为识别方法。本文的主要工作及成果如下:(1)构建分心驾驶行为数据集。由于目前没有分心驾驶公共数据集,并且跟驾驶相关的数据集有样本空间小、标注不准确、数据集划分和采集方式不合理等问题,所以本文构建了分心驾驶行为数据集。数据集包含两个种类:吸烟驾驶和接打电话驾驶。通过两种形式获取样本数据,第一种形式主要来源于真实场景下的自行拍摄,第二种形式主要来源于网络。我们分别从不同角度、不同光照、不同天气和不同复杂背景等条件下进行样本数据的收集,使用Label Img对样本数据进行种类的划分和位置的标注。在本数据集中,人工标注了8835张数据图片。(2)目标检测网络的改进。目标检测阶段以Yolo V5模型为基础,为适用我们课题范围提出两点改进措施:首先,对香烟和手机的检测符合相对尺寸小目标的定义,为此我们对预测头做了改进,在浅层网络上添加一个P2预测头,使模型在浅层网络上能够获取到更多的细节信息;其次,我们对Sigmoid函数概率和不为1的问题进行了优化,使其对损失的收敛结果更满足我们互斥类别数据集的要求。改进后模型的m AP达到了77.22%,较改进前高出了约9个百分点,并且检测速度相差无几。(3)姿态估计网络的改进。姿态估计阶段以轻量级Openpose模型为基础。在此基础上,我们提出了两点改进策略:首先,对网络的结构进行改进,既提高了网络的传播能力,又使网络更有效地训练;其次,引入CA注意力机制提高信息处理的效率和准确性。在COCO数据集下,优化后的网络平均精度达到了64.8%。(4)二阶段行为识别网络的设计。对改进后的Yolo V5和Openpose网络模型进行融合,提出一种新的二阶段分心驾驶行为识别算法。使用欧几里得距离特征作为主要判断条件,使用手肘角度特征作为辅助判断条件。在测试数据集下,吸烟分心驾驶行为的正确率达到92.16%,接打电话分心驾驶行为的正确率达到94.60%,对正常驾驶识别的正确率达到100%,模型的平均正确率达到了93.76%。最后,本文提出的二阶段分心驾驶行为识别模型,在不干扰驾驶员的情况下,识别效果和识别速度均能达到最优效果。
{URL}: https://link.cnki.net/doi/10.26923/d.cnki.gasgc.2023.000215
{DOI}: 10.26923/d.cnki.gasgc.2023.000215
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的物流包裹自主分拣系统研究
{Author}: 李顺
{Tertiary Author}: 程万胜
{Publisher}: 辽宁科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 工业机器人;ROS;手眼标定;自主分拣;机器视觉
{Abstract}: 互联网时代,人工智能日益兴起,同时伴随着物流行业的快速发展以及中国的老龄化日益严重,采用人工进行分拣作业的任务越来越繁重,导致了人力成本的增加,传统工业机器人只能采用单一的示教功能进行重复性工作,很难得到大范围应用,泛化性较低,存在着很大的智能化需求,本系统基于视觉结合工业机器人,对面向物流包裹的机器人自主分拣系统进行研究,主要工作及研究内容如下:(1)使用ABB IRB4600型号工业机器人、Intel Realsense D455型号深度相机、拥有Ubuntu18.04的计算机等硬件构建了机器人分拣系统。其方案的主要运行流程为:首先,通过相机采集图像,利用YOLOv5s对待抓取平台上的快递盒进行识别与定位,同时将目标位置转换为机器人基座坐标系下的坐标,随后经过算法规划通过控制器控制机器人完成目标物体抓取。(2)相机与机器人构成的自主分拣系统的标定问题,对涉及到的坐标系之间的关系进行了解析,对于相机内部参数的标定,在ROS系统下,采用张正友标定法完成对相机的内参标定,采用眼在手外的方式,通过Tsai两步法进行计算,求得相机与机器人基座之间的转换关系。(3)针对目标识别与3D坐标获取,采用YOLOV5s算法,首先进行数据集采集与标注并将数据集转换为VOC格式,完成数据集的制作后进行网络模型训练,获得最佳权重文件,对目标完成识别后,通过计算识别到的目标物体的边界框中心坐标以及深度相机获取物体与相机之间的距离,二者结合获得目标物体在相机下的位置信息,在经转换关系最终获得机器人基座下目标位置信息。(4)上位机与实体机器人的实时通信与控制,为实现PC通过ROS实现对ABB机器人的控制,通过对仿真平台的构建,首先从ABB官方网站获得机器人的URDF文件,然后在ROS平台中进行Move It!的配置,同时对于路径规划算法的选择进行了讨论,确认最终选择RRT-Connect算法进行机器人的路径规划。同时在Windows系统下利用Robot Studio软件搭建机器人仿真系统,在机器人控制器中完成相关ROS通信任务的配置,完成机器人仿真实时控制。(5)先后进行了自主分拣系统平台的搭建、视觉单元的调试并对视觉定位进行测试与分析、机器人单元的调试,完成了自主分系统对快递盒的识别,最后通过机器人自主分拣实验进行整体自主抓取验证,共进行48次自主抓取实验,抓取成功率为93.75%,验证了系统的可行性与稳定性,基本达到了预期要求。
{URL}: https://link.cnki.net/doi/10.26923/d.cnki.gasgc.2023.000644
{DOI}: 10.26923/d.cnki.gasgc.2023.000644
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工件识别应用研究
{Author}: 郑如新;孙青云;马素慧;程冬
{Author Address}: 南京林业大学机械电子工程学院;河北科技师范学院机电工程学院;
{Journal}: 机械设计与制造
{Year}: 2023
{Volume}: 
{Issue}: 08
{Pages}: 299-303
{Keywords}: 机器视觉;图像处理;HALCON;识别;检测;分类
{Abstract}: 在现代化的工厂流水线生产中，大部分都是使用人工的方式去识别工件。如果长时间使用人工去识别分类工件的话，不仅劳动强度大，而且还会造成人眼的视觉疲劳，容易出现错误。为了避免此类情况的发生，采用机器视觉图像处理软件的计算机识别检测的方式最为有利。这里在此提出HALCON图像处理软件对工件进行识别处理，判断最终是否能够正确的识别该工件。试验结果表明：经过一系列的图像处理手段，最终可以不受其他工件的影响，正确的识别出该工件。
{ISBN/ISSN}: 1001-3997
{Notes}: 21-1140/TH
{URL}: https://link.cnki.net/doi/10.19356/j.cnki.1001-3997.20230310.032
{DOI}: 10.19356/j.cnki.1001-3997.20230310.032
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于3种不同颜色空间的作物行提取方法比较研究
{Author}: 张秀丽;周湘铭;赵任重;陈永;周培林
{Author Address}: 河南农业大学机电工程学院;
{Journal}: 江苏农业科学
{Year}: 2023
{Volume}: 51
{Issue}: 10
{Pages}: 211-219
{Keywords}: RGB;HSV;CIE-Lab;OTSU算法;作物行识别;机器视觉
{Abstract}: 作物行检测是精准农业和自动导航的关键。为研究不同颜色空间作物行提取方法克服光照条件变化影响的性能，综合比较不同方法的优劣情况，选取归一化RGB颜色空间提取ExG分量方法(ExG分量法)、HSV颜色空间提取H分量方法(H分量法)、CIE-Lab颜色空间提取a分量方法(a分量法)3种方法，分别在阴天和晴天2种光照条件下进行了详细分析和比较。结果表明，ExG分量法和a分量法在阴天和晴天环境都具有可行性且基本能够满足实际需求；H分量法仅在阴天环境下具有可行性且基本能够满足实际需求，在晴天环境下无法完全准确分离作物和土壤。分析得出，阴天环境下综合比较优劣结果为a分量法>H分量法>ExG分量法，晴天环境下综合比较优劣结果为a分量法>ExG分量法。
{ISBN/ISSN}: 1002-1302
{Notes}: 32-1214/S
{URL}: https://link.cnki.net/doi/10.15889/j.issn.1002-1302.2023.10.029
{DOI}: 10.15889/j.issn.1002-1302.2023.10.029
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的板材缺陷检测算法研究
{Author}: 张子磊
{Tertiary Author}: 李东洁
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;目标检测;木材缺陷检测;YOLOX;特征融合
{Abstract}: 原木制作的实木板材,坚固耐用、纹理自然、美观舒适、健康环保,具有天然的木材芳香,是装修房屋、制作高档家具、工艺品的优质材料,广泛应用于建筑和家具装饰领域。由于板材中存在活节、死结、裂纹等缺陷,严重影响其外观品质和物理性能。木材加工企业需要剔除板材表面缺陷,将深度学习与板材缺陷检测相结合,分析识别不同类型的板材缺陷,对提高木材的出材率,保证木材的生产质量,具有重要意义。针对木材缺陷样本不足、网络鲁棒性差的问题采取在线数据增强和离线数据生成,扩展样本的数量,增加模型泛化能力和鲁棒性。采用Mosaic数据增强和Mixup数据增强,DCGAN网络,生成新的图像,解决木材缺陷类别不平衡的问题。针对板材表面缺陷检测结果准确率低,检测速度慢,模型参数量大等问题,利用计算机视觉优势,改进YOLOX目标检测算法的特征融合模块,添加ECA(Efficient Channel Attention)注意力机制,ASSF(Adaptively Spatial Feature Fusion)自适应空间特征融合机制,改进置信度损失函数为Focal Loss,定位损失函数为EIoU,提升算法的特征提取能力和检测的准确率,实验表明改进后的模型检测橡木四类缺陷具有较大提升,改进后的EAE-YOLOX,mAP达到96.68%,速度达到46.7fps,相比于其他经典目标检测算法具有明显优势。考虑模型的深度和宽度,使用深度可分离卷积和可选的多版本算法,减少模型参数量和计算量,寻求最优的模型EAE-YOLOX-tiny,mAP达到94.92%,速度达到52.09fps。测试了网络输入不同大小图片对精度的影响,并交叉验证橡木和松木两种数据集的检测结果。设计了板材缺陷检测系统的软件界面,首先分析了相关需求,设计软件的总体框架和检测流程,然后使用Qt编写软件界面,最后演示整个板材缺陷检测软件的操作流程,展现出满意的效果。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2023.000709
{DOI}: 10.27063/d.cnki.ghlgu.2023.000709
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的钢板表面缺陷检测系统
{Author}: 戴建
{Author Address}: 南京钢铁联合有限公司炼铁事业部;
{Journal}: 冶金与材料
{Year}: 2023
{Volume}: 43
{Issue}: 01
{Pages}: 157-159
{Keywords}: 机器视觉;钢板;表面缺陷;检测系统
{Abstract}: 钢板的制造能力是钢铁企业发达程度的一项主要指标，因其优异的表面质量特征和机械力学性能，在车辆工业、国防、航空航天、化工设备以及轻工业生产加工等行业中获得了广泛的使用。同时由于加工技术和生产工艺的完善和企业自动化管理能力的日益增强，钢板的形状精度、板形、动力学性能和表面质量特征均受到了较好的保证，而随着车辆、航空、机械电子、家电和建筑装潢材料等钢板的主要客户对钢板表面质量的需求也愈来愈大，使钢板表面质量问题也日益凸显。
{ISBN/ISSN}: 2096-4854
{Notes}: 23-1602/TF
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyEpZEhqAdtFa8I2QDLgnmH5M5x1FLRLrM1vRIfTqUJ2X95zUPeVZS_XqVHyEnQYQDFxMdYj0A2fn_Os_Ne84h0mbg1UKzND3kaAdrC7ifTSxQgdA_FZSQ9m2DXJpDtfuBDyM8_iRCtkN8zulbCst_bmNq6UYetbvbo9djeOLRybWwkkX5X2yUwU1OXaTok9LI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度迁移学习的脉冲涡流热成像裂纹缺陷检测
{Author}: 郝柏桥;范玉刚;宋执环
{Author Address}: 昆明理工大学信息工程与自动化学院;昆明理工大学云南省人工智能重点实验室;浙江大学控制科学与工程学院;
{Journal}: 光学学报
{Year}: 2023
{Volume}: 43
{Issue}: 04
{Pages}: 146-154
{Keywords}: 机器视觉;无损检测;脉冲涡流热成像;迁移学习;非负矩阵分解;YOLO v5
{Abstract}: 提出一种迁移学习与深度学习相结合的钢板裂纹缺陷检测方法。首先，通过非负矩阵分解（NMF）建立红外缺陷数据集的目标域特征空间，以余弦相似度为衡量指标选取可见光缺陷数据集的源域样本，对深度学习模型进行预训练，并将模型权重参数迁移至目标域，实现相似领域的知识迁移；然后，在YOLO v5算法基础上引入自适应空间特征融合（ASFF）模块，提高缺陷检测精度。实验结果表明：所提方法对钢板脉冲涡流热成像裂纹缺陷的检测精度达到98.6%，可实现不同长度裂纹的准确识别与定位。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzD8Dl85gPZ-r1Q3y4y-tu9Op-T-KgLM7tVDb9WeI2Nfl12hq88PK3-HY8xRd11MYOJNCZOmU8O28r3yPzZAQk0MOAr3CBr-Ed4YBryMkYfsnpWvWTNsnQODivZ77PyuzRedHvJFyYCfUj9pstVOQjnJqsPwW3SjlKjp2QhvRLJtDmBGulT1GNEpo-GCbiP5kM=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Harris与SURF特征点检测的手术器械机器视觉识别方法
{Author}: 陈贤儿;梁丹;傅云龙;梁冬泰;刘涛
{Author Address}: 宁波大学机械工程与力学学院;
{Journal}: 传感器与微系统
{Year}: 2023
{Volume}: 42
{Issue}: 02
{Pages}: 118-121
{Keywords}: 机器视觉;手术器械;Harris角点检测;目标识别
{Abstract}: 针对手术器械快速识别与定位需求，提出一种基于改进Harris与SURF特征点检测的手术器械机器视觉检测方法。通过MASK匀光算法消除金属表面不均匀光泽反射，并设计改进的Harris角点检测算法实现无堆叠手术器械的快速检测。利用SURF算法提取图像特征信息，采用KD-Tree搜索相似特征矢量，以实现堆叠手术器械的准确识别与定位。实验结果表明：本文方法的识别准确率和识别时间分别为92.4%和3.15 s,可有效实现典型手术器械的视觉识别与定位。
{ISBN/ISSN}: 2096-2436
{Notes}: 23-1537/TN
{URL}: https://link.cnki.net/doi/10.13873/J.1000-9787(2023)02-0118-04
{DOI}: 10.13873/J.1000-9787(2023)02-0118-04
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于数字孪生的异构多源多模态数据融合方法研究
{Author}: 孟畅
{Tertiary Author}: 张景异
{Publisher}: 沈阳理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 深度学习;数据融合;异构多源多模态数据;图像合成
{Abstract}: 随着工业4.0的到来,数字孪生技术成为工业4.0的关键使能技术,并且随着传感器、信息采集、信息传输和数据库等技术的高速发展,数字孪生体尤其对于异构多源多模态数据的处理要求不断增加,随之带来的数据信息提取质量较差,数据融合效果较差,共同学习结果较差等问题。这些问题成为制约数字孪生技术在决策层发展的主要障碍之一。目前,基于深度学习的异构多源多模态数据融合方法为此领域中一种重要的方法,已经在工业4.0的推动下得到了学者们的高度关注,具有重要的研究意义。本文在总结以往的研究成果上,对于基于数字孪生的异构多源多模态数据融合方法展开研究。本文首先提出了针对文本和图像数据的特征提取模块,能够实现针对文本和图像数据的关键信息提取工作;然后为了实现异构多源多模态数据融合,提出了一种张量分解的融合模块HSM-Net。本文主要研究内容如下:1)在基于深度学习方法的异构多源多模态数据融合方法中,数据的特征提取是很重要的一部分。特征提取的质量对后续融合结果具有至关重要的影响。本文从数据特征提取角度出发,针对文本数据的提取方法展开研究。本文将Bert预训练模型、MLP和残差网络相结合,使其能够分辨整个文本表达的含义,并利用残差网络的优点有效的避免了梯度消失或梯度爆炸等问题。2)为了后续的数据融合工作,提供高质量的数据特征,针对图像数据,提出了一种基于Vision Transformer的特征提取模块,该模块能够有效地结合CNN局部上下文信息和Vision Transformer的全局上下文信息的优点。模块共包含三个阶段,每个阶段均由CNN与Vision Transformer构成,逐级降低参数量,提高计算速度的同时,实现CNN处理底层特征,Vision Transformer处理高阶信息,为后续融合工作提供更优的数据特征。3)由于文本、轮廓、分割与风格数据之间存在数据类型异构的问题,若采用传统的数据融合方法很难对其进行有效的融合。为了充分利用多种不同模态数据的有效信息,提出了一种基于张量分解的融合模块,该模块针对不同模态的信息进行特征提取,再基于特征向量进行编码操作,然后进行映射到高维空间,利用张量分解理论,将高秩张量分解为低秩张量,在进行融合操作,有效的融合了更高维度的潜在信息,进一步蕴含了更多丰富的有效信息。
{URL}: https://link.cnki.net/doi/10.27323/d.cnki.gsgyc.2023.000083
{DOI}: 10.27323/d.cnki.gsgyc.2023.000083
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的物料分拣装置设计与制作
{Author}: 郭鹤;常修源
{Author Address}: 郑州科技学院;
{Journal}: 科技与创新
{Year}: 2023
{Volume}: 
{Issue}: 02
{Pages}: 33-36
{Keywords}: 物料分拣;CoreXY结构;HSV模型;颜色与形状识别
{Abstract}: 根据物料分拣要求设计并制作了基于机器视觉的物料分拣装置。装置具有3个自由度，采用CoreXY结构控制抓取机构进行X、Y方向移动，并采用连杆-滑块机构控制其进行Z方向移动。装置可通过手势识别算法实现非接触启动，采用Canny算子检测物料边缘，进而判断物料形状，采用HSV图像模型判断物料中心点颜色，并将颜色和形状信息发送到上位机，在上位机人机交互界面进行实时显示，同时，上位机通过串口协议将控制信号发送至ARM单片机，最终控制执行机构进行物料抓取与放置。对不同规格的物料进行多次分拣实验并记录分拣结果，分拣装置的平均分拣准确率为100%，平均分拣时间为78 s，达到了预期效果。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2023.02.009
{DOI}: 10.15913/j.cnki.kjycx.2023.02.009
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv3的浮游藻类检测算法
{Author}: 储震;张小玲;殷高方;贾仁庆;漆艳菊;徐敏;胡翔;黄朋;马明俊;杨瑞芳;方丽;赵南京
{Author Address}: 安徽大学物质科学与信息技术研究院安徽省信息材料与智能感知实验室;中国科学院安徽光学精密机械研究所中国科学院环境光学与技术重点实验室;中国科学技术大学环境科学与光电技术学院;合肥学院生物食品与环境学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 02
{Pages}: 257-264
{Keywords}: 机器视觉;SPP-GIoU-YOLOv3;目标检测;深度学习;浮游藻类
{Abstract}: 浮游藻类的种类多样性和群落结构是水生态环境建设评价的重要指标，利用细胞图像对其进行识别是实现浮游藻类检测的重要手段。相较于传统的显微镜检法，基于深度学习的目标检测算法因更高效的检测能力而越来越多地被运用到浮游藻类检测领域。针对YOLOv3目标检测算法对部分形态小、边界模糊和粘连浮游藻类的检测精度低等问题，采用空间金字塔池化（SPP）结构改进了YOLOv3目标检测算法的特征提取方式，采用广义交并比（GIoU）边界损失函数改进了YOLOv3目标检测算法的边界损失函数，最终构建了一种基于SPP和GIoU改进的YOLOv3浮游藻类检测算法（SPP-GIoU-YOLOv3）。实验结果表明：在检测速度无明显差异的情况下，所提SPP-GIoU-YOLOv3分类检测算法对实验藻类的平均精度均值达95.21%，比YOLOv3目标检测算法提高了4.24个百分点。本研究为发展准确快速的浮游藻类检测方法技术提供了一定的基础。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvya2ZD6KM5c3r6Y9sqMnaZgABNzbrdA_ChwSf0_pU2WpFPvH3BtKApjOlhe7EEO-JdosThiVP6TpI6C8XGSyPCZ1W98qcsErDXL6D_SHXOM8gClLhn6PcM9cFlR3H8W5bjJtYKBOLAZGWfxyYFfsWLif6C7xNBZ9EYygB9oiUgIYAsjehSg9MZGfOicVRT1S5o=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉在线检测瓶装白酒杂质的研究
{Author}: 冯铃;温培和;赵平
{Author Address}: 四川化工职业技术学院智能制造学院;
{Journal}: 工业控制计算机
{Year}: 2023
{Volume}: 36
{Issue}: 01
{Pages}: 14-16
{Keywords}: 瓶装白酒;机器视觉;图像处理;算法
{Abstract}: 以泸州某白酒厂为例，提出应用机器视觉在线检测的方法来对瓶装白酒杂质进行检测。对所建立的机器视觉在线检测系统进行了介绍，并对系统中的各组成部分进行了选型，根据白酒厂酒质监测系统设备实际工况，采用了合适的图像处理算法，并对算法的合理性进行了实验研究。实验结果表明，通过采取这种方法，能够实现瓶装白酒的准确检测，提高白酒厂家的生产效率，减少人员支出，增加企业利润。
{ISBN/ISSN}: 1001-182X
{Notes}: 32-1764/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxmhaXNKTsJUWSfMd8TCuOKy6Ejrw-F18OHNkZagq473xJd2-Qv83XUgdDS2ytKk4i_ULTEgL_XufNrsMBXEJ6H_UQ0uOBdJeEFaxam-2s1qVqv_lZ1KCXOg12E0ffJ0yw5bsiygLiExK_oTbZS4mf9T3foqrTJGwnTqhBv8QDV_tirn1FVU9us8mBrZERzKzo=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 在Linux环境下基于OpenCV图像处理的研究与实现
{Author}: 黄俊明;陈平平;王彩申
{Author Address}: 东莞理工学院电子工程与智能化学院;
{Journal}: 电脑编程技巧与维护
{Year}: 2023
{Volume}: 
{Issue}: 01
{Pages}: 143-146
{Keywords}: 计算机视觉;OpenCV技术;Python语言;数字图像处理
{Abstract}: 近些年来，数字图像处理技术在不断提高，高效地应用数字图像处理技术成为一大热门技术话题。通过OpenCV-Python编译技术来加强数字图像处理的效果，以此达到其效率的提高，通过使用Python能更好地与人工智能技术接轨，也提高了程序编写的便利性。讲述了在Linux下OpenCV计算机视觉库的的的环境搭建，以平滑处理、边缘检测为例，介绍了OpenCV-Python在图像处理中的典型应用。
{ISBN/ISSN}: 1006-4052
{Notes}: 11-3411/TP
{URL}: https://link.cnki.net/doi/10.16184/j.cnki.comprg.2023.01.006
{DOI}: 10.16184/j.cnki.comprg.2023.01.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习模型中间层特征压缩技术综述
{Author}: 汪维;徐龙;陈卓
{Author Address}: 中国科学院国家空间科学中心空间天气国家重点实验室;中国科学院大学;中国科学院国家天文台;新加坡科技局通信研究院;
{Journal}: 计算机应用研究
{Year}: 2023
{Volume}: 40
{Issue}: 05
{Pages}: 1281-1291
{Keywords}: 深度学习;边云端智能协作;特征压缩;编码框架;比特分配
{Abstract}: 深度学习模型中间层特征压缩作为深度学习领域中一个新兴的研究热点被广泛关注并应用于边端—云端智能协同任务中。针对深度学习模型中间层特征压缩的研究现状，对当前压缩方式中存在的问题进行分析总结。首先，系统地分类阐述了基于图像/视频编解码框架、基于特征通道比特分配和基于深度学习网络结构的三种深度学习模型中间层特征压缩方式；随后，对比了三种深度学习模型中间层特征压缩方式在数据集上的表现；最后，探讨了当前深度学习模型中间层特征压缩研究面临的挑战，展望了中间层特征压缩技术未来的发展趋势。
{ISBN/ISSN}: 1001-3695
{Notes}: 51-1196/TP
{URL}: https://link.cnki.net/doi/10.19734/j.issn.1001-3695.2022.09.0493
{DOI}: 10.19734/j.issn.1001-3695.2022.09.0493
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于YOLOv5的目标识别相机
{Author}: 黄静;张晋
{Author Address}: 浙江理工大学信息学院;
{Journal}: 计算机时代
{Year}: 2023
{Volume}: 
{Issue}: 01
{Pages}: 91-94
{Keywords}: 树莓派;移动设备;计算机视觉;深度学习
{Abstract}: 计算机视觉技术可以为猪的养殖户提供一种非接触式以及自动化和普遍式的监管模式，对养殖中的生猪/种猪等无任何不良影响。提出利用一种基于树莓派和计算机视觉技术相结合的便携式相机，可让养殖场工作人员携带设备到现场进行猪体识别与猪图像数据采集。简化了工作流程。设备操作简单，能提高实际工作效率。
{ISBN/ISSN}: 1006-8228
{Notes}: 33-1094/TP
{URL}: https://link.cnki.net/doi/10.16644/j.cnki.cn33-1094/tp.2023.01.023
{DOI}: 10.16644/j.cnki.cn33-1094/tp.2023.01.023
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的织物疵点检测研究进展
{Author}: 王斌;李敏;雷承霖;何儒汉
{Author Address}: 武汉纺织大学湖北省服装信息化工程技术研究中心;武汉纺织大学计算机与人工智能学院;武汉纺织大学纺织服装智能化湖北省工程研究中心;
{Journal}: 纺织学报
{Year}: 2023
{Volume}: 44
{Issue}: 01
{Pages}: 219-227
{Keywords}: 深度学习;疵点检测;纺织品;神经网络;图像分割;机器视觉
{Abstract}: 为提高疵点检测的准确性和通用性，实现使用简洁而有效的形式对织物图像的特点和疵点的本质特征进行综合表达，首先，介绍了深度学习技术，对引入了深度学习的疵点检测方法进行综述，同时对深度学习与疵点检测的内在关系进行阐述；然后，分析总结了深度学习的概念及代表性的计算模型，并对引入深度学习的疵点检测方法进行归纳、总结和分类；最后，对典型的方法进行了分析，讨论了各种方法的优缺点，并对未来的研究趋势进行了展望。指出：随着深度学习的发展，探索更加通用的检测方法是推进深度学习在织物疵点检测领域应用的努力方向。
{ISBN/ISSN}: 0253-9721
{Notes}: 11-5167/TS
{URL}: https://link.cnki.net/doi/10.13475/j.fzxb.20211105509
{DOI}: 10.13475/j.fzxb.20211105509
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv5的航空发动机表面缺陷检测模型
{Author}: 李鑫;李香蓉;汪诚;李秋良;李卓越
{Author Address}: 空军工程大学基础部;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 16
{Pages}: 304-313
{Keywords}: 机器视觉;航空发动机;表面缺陷检测;YOLOv5;注意力机制
{Abstract}: 针对目前航空发动机表面人工缺陷检测效率低的问题，提出一种基于改进YOLOv5的缺陷检测模型YOLOv5-CE。首先，在网络中融合数据增强策略搜索算法，自动为当前数据集搜索最佳的数据增强策略，实现训练效果的提升；其次，在backbone网络中引入坐标注意力机制，在通道注意力的基础上嵌入坐标信息，提高对小缺陷目标的检测能力；最后，将YOLOv5的定位损失函数改进为efficient intersection over union损失，在加快模型收敛的同时提高预测框回归精度。实验结果表明，所提YOLOv5-CE模型，相比原YOLOv5s网络，在检测速度几乎没有下降的情况下平均精度均值提高了1.2个百分点，达到了98.5%，能够高效智能检测航空发动机4种常见类型缺陷。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20230104.1228.006
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的大豆损伤无损检测算法研究
{Author}: 黄子良
{Tertiary Author}: 王儒敬
{Publisher}: 中国科学技术大学
{Type of Work}: 博士
{Year}: 2023
{Keywords}: 大豆损伤;无损检测;近红外光谱;可见光成像;机器学习;计算机视觉;深度学习;目标检测
{Abstract}: 大豆作为我国最主要的高蛋白食物原料和油料作物之一,其优产稳产意义重大。种子是大豆培育及生产的基础,其质量直接影响作物最终产量与输出品质。现存的种子筛选方法存在准确率低、速度慢、容易对种子造成二次损伤等问题。本文结合计算机视觉技术具有快速、无损、高通量等特点,综合利用近红外光谱成像及可见光成像技术,研究了大豆损伤无损检测算法,建立了准确、快速、无损的大豆检测模型。从单粒检测、低通量检测以及高通量检测三个方面,深入研究了大豆无损检测的主要问题及挑战。本文内容及创新点如下:1.基于机器学习的大豆近红外光谱数据识别算法研究。近红外光谱技术多用于玉米、水稻和小麦等农作物种子,对于透光性较差的大豆种子鲜有研究。本文利用FT-NIR光谱仪进行非接触式数据采集,针对近红外光谱数据信息量大、无效信息和冗余信息多等问题,提出使用一阶导数结合SG平滑的方式对原始光谱数据进行预处理,达到选取有效波段的目的。针对光谱数据中物理层交叠信息的解释性弱且模型高度依赖数学模型的问题,提出使用机器学习方法进行特征提取和分类,利用随机森林及变量选择优化算法实现了对大豆种皮裂纹的准确检测。实验结果表明,本文提出的随机森林模型准确率为80%,原始模型结合变量选择优化算法的检测准确率为84%。该研究证明了使用机器学习结合近红外光谱技术对大豆种皮裂纹进行无损检测的有效性。2.基于多模型融合的低通量大豆检测算法研究。使用机器学习结合近红外光谱技术存在以下几点不足:设备只能对单粒的大豆种子进行检测,无法对多粒种子同步检测;近红外光谱数据在不同的预处理方法下会产生差异较大的结果,在一定程度上影响分类器的准确性;机器学习方法鲁棒性差、模型超参数较多。针对上述问题,本文设计了一种多模型融合的两阶段检测策略,即分割-分类策略对大豆进行检测。第一阶段使用Mask R-CNN模型对低通量的大豆进行精确检测与分割。由于大豆损伤形式高度相似,因此该阶段分类准确度差。针对分类精度差的问题,第二阶段采用轻量化模型SNet进行分类。SNet利用混合特征重校准模块以提升模型分类性能,该模型参数量仅为1.29M。实验结果表明,SNet以96.2%的准确率实现了对大豆籽粒的精确分类,其性能均优于其他对比方法。3.基于可逆卷积网络的高通量大豆检测算法研究。高通量检测存在以下几个问题:密集目标数据的精细标注时间和人力成本高昂;大豆籽粒数量多,籽粒间存在着较大概率的粘连和遮挡;检测模型中经典特征金字塔存在信息丢失。针对上述问题,首先设计了一种基于自监督的方式来构建大量的合成数据并且能够自动生成逐像素的标注信息,该方法在解决精细标注复杂问题的同时,一定程度上缓解了农业数据及标注信息稀缺的问题。其次,提出基于可逆卷积的Inv-Mask模型,利用可逆卷积双向映射、空间域和通道域复杂度低的特点,实现对高通量种子的准确、快速检测。最后,设计了基于可逆卷积的特征选择金字塔(FS-FPN),增强了模型提取多尺度特征的能力,解决了信息丢失导致的模型精度下降问题。实验结果表明,本文提出的合成数据方法有效解决了数据短缺的问题,设计的Inv-Mask模型结合FS-FPN性能良好,其检测准确率及检测速度提升明显,具有较大的实用价值。
{URL}: https://link.cnki.net/doi/10.27517/d.cnki.gzkju.2023.001205
{DOI}: 10.27517/d.cnki.gzkju.2023.001205
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 公共场所行人目标跟踪与重识别方法研究
{Author}: 周育竹
{Tertiary Author}: 谢英红
{Publisher}: 沈阳大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 行人检测;行人跟踪;行人重识别;注意力机制;多尺度学习
{Abstract}: 随着科技进步与社会发展,城市的视频监控网络基本成型,智能监控已被广泛使用在车站、道路交通、校园、社区等公共场所。行人作为公共场所的主体,行人目标检测、行人目标跟踪及行人目标重识别成为计算机视觉领域热点研究课题。为了实现在公共场所下行人目标的自动跟踪及重识别任务,本章分别就监控场景下的行人检测、行人跟踪与行人重识别展开研究,主要工作如下:
(1)为了能够更准确、高效地实现行人检测,本章提出一个基于YOLOv5的行人检测模型,结合Ghost Net将CSP模块改进为CSPghost模块,相比原始目标检测模型,检测速度更快;为了使模型具有较高的检测精度,在每个CSPghost模块后面插入通道注意力模块;最后,优化了边框回归损失函数,采用了考虑长度损失和宽度损失的EIOU损失函数,EIOU的回归结果比GIOU的回归速度更快,结果更好。
(2)通过设计更稳健的CSP网络,获取更深层的语义信息来大幅度提升跟踪性能。通过设计注意力机制,提高有利于跟踪任务的特征在通道维度和空间维度的权重,提升网络的判别能力,提高了目标在旋转变化、快速运动时的跟踪准确性。通过设计特征金字塔与路径聚合网络,融合不同层次的特征,加强位置信息在网络中的响应,实现了多尺度目标跟踪的位置准确性。此外,为提高网络对相似目标之间的鉴别能力,本章设计了干扰感知模块,提高算法的抗干扰性能。
(3)提出的多尺度特征学习算法,通过空洞卷积扩大感受野,将得到的多个尺度上的特征水平分割后全局平均池化,在保持参数量的同时,增强模型的分类能力。在行人特征提取网络中加入特征对齐模块,通过适当地空间变换,将目标行人的特征与原图像的特征位置一一对应,增强模型对图像中人体尺度变化和遮挡的适应能力,进一步提升识别精度。增加特征擦除分支,加强局部区域的特征学习。将整体网络融入孪生网络强化训练,提高网络的表达性和鲁棒性。
{URL}: https://link.cnki.net/doi/10.27692/d.cnki.gsydx.2022.000270
{DOI}: 10.27692/d.cnki.gsydx.2022.000270
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的杨梅成熟度检测仪的研发
{Author}: 周焜
{Tertiary Author}: 费正顺;项新建
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 成熟度检测;YOLOX-NANO算法;注意力机制;Jetson nano
{Abstract}: 杨梅是一种具有高附加值的水果,随着杨梅市场的扩大以及杨梅精品化发展,杨梅采摘的智能化需求日益增加。近些年深度学习的发展在农业智能化领域取得了瞩目的成就,许多学者将深度学习应用于水果分类分级上。但是在复杂光照、枝叶遮挡、果实堆叠的自然环境下,仍然存在漏检、误检和定位不准等问题。为提高杨梅采摘智能化水平,开发杨梅无损检测设备,本文提出了一种基于改进YOLOX-NANO算法的杨梅成熟度检测方法,并开发了一款杨梅成熟度无损检测仪。本文的主要工作如下:
(1)针对杨梅数据集缺失的问题,构建了用于杨梅成熟度判别的单一背景的杨梅成熟度数据集以及用于训练深度学习模型的自然环境下杨梅图像数据集。基于大津法(Otsu)和形态学操作对用于成熟度划分的杨梅图像进行分割,分割后的图像转换至Lab颜色空间,通过分析数据确定色泽比a/b值为成熟度划分标准。根据阈值对自然环境下杨梅数据集进行成熟度信息标注,并使用6种不同的图像扩增策略对数据集进行扩增,最终制作成10070张杨梅成熟度数据集。
(2)针对YOLOX-NANO算法对果实堆叠、枝叶遮挡等问题出现漏检导致检测效果不佳等问题,提出了改进YOLOX-NANO目标检测算法,在特征加强网络(FPN)中引入通道注意力(ECA)模块,提高了网络的特征提取能力;引入了高效交并比(EIo U)损失函数替换了原本的交并比(Io U)损失函数,使得模型收敛更快且精度得到了提高。引入了ECA注意力机制的改进算法相对于原算法m AP得到了2.9%的提升,最终的改进算法m AP提升了4.54%。
(3)使用Jetson nano A02嵌入式深度学习开发平台搭建了杨梅成熟度检测仪。使用Py QT设计用于交互的杨梅成熟度检测软件平台,包括GUI界面和检测模型调用。用户可以通过软件选择图片检测或实时/本地视频检测,检测结果显示在软件页面中。
实验结果证明,本文改进的YOLOX-NANO算法能部署到Jetson nano A02嵌入式AI平台当中,使用该算法对杨梅成熟度进行检测,检测准确率为92.67%,推理速度为15帧/秒,通过验证本文系统能够正常运行,并且能够对杨梅进行有效识别。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000179
{DOI}: 10.27840/d.cnki.gzjkj.2022.000179
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的水面垃圾目标检测算法设计
{Author}: 张芙蓉
{Author Address}: 长沙航空职业技术学院;
{Journal}: 湖南工业职业技术学院学报
{Year}: 2022
{Volume}: 22
{Issue}: 06
{Pages}: 13-16
{Keywords}: 水面垃圾清理;机器人;目标检测;机器视觉
{Abstract}: 针对水面垃圾清理机器人作业中的垃圾识别及方位检测的技术要求，采用改进型YOLO算法，部署在嵌入式AI-K210硬件上，实现实时检测水面垃圾的类别、位置和面积，为水面垃圾清理提供机器视觉，方便水面垃圾清理机器人更精确地规划自动清理路线，以提高水面垃圾清理机器人的工作效率。
{ISBN/ISSN}: 1671-5004
{Notes}: 43-1374/Z
{URL}: https://link.cnki.net/doi/10.13787/j.cnki.43-1374/z.2022.06.003
{DOI}: 10.13787/j.cnki.43-1374/z.2022.06.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习方法的目标检测技术在自动驾驶汽车的应用研究
{Author}: 石启飞
{Author Address}: 宿州职业技术学院;
{Journal}: 景德镇学院学报
{Year}: 2022
{Volume}: 37
{Issue}: 06
{Pages}: 58-61
{Keywords}: CNN;Faster R-CNN;Fast R-CNN;R-CNN;SSD;YOLO;自动驾驶汽车
{Abstract}: 在自动驾驶汽车设计中可能会使用不同的目标检测技术，无线电探测与测距技术(RADAR)、光图像探测与测距技术(LiDAR)和计算机视觉是公认的检测技术。计算机视觉是一种从数字图像中提取重要特征的方法，使计算机能够感知物体的特征并解释图像。在近几年的研究中，已经发现计算机视觉警示基于深度学习方法可以实时检测目标并应用在自动化领域。
{ISBN/ISSN}: 2095-9699
{Notes}: 36-1340/G4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvykX6cAX_sui1PZpBO9yeAPYzLppXvvrR_1WMyJ_sNMQ8RqxbAM1jyuR1vx8p4Z_8Il372awG5QT3iobjzPquTwqYaJUR480zZaEPgR5bCOIrH2EE_qNnqBM7L5WlSIOqbMsSZBCdKGj7qiEHxik1Fsk_6YCBu_nVsc6ly-yNwS4GgxYnxgAHYm1Q3BE3cRi4w=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 苹果外部缺陷全表面在线检测分选装置研发
{Author}: 彭彦昆;孙晨;刘乐;李阳
{Author Address}: 中国农业大学工学院;国家农产品加工技术装备研发分中心;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 23
{Pages}: 266-275
{Keywords}: 机器视觉;农产品;无损检测;苹果外部品质;在线式装置
{Abstract}: 中国是水果消费大国，但在水果产后检测装备方面相对滞后。针对目前在线检测装置无法采集苹果全表面图像信息且无法精确计算缺陷面积的问题，该研究以表面缺陷面积的快速检测为主要目标，提出苹果全表面图像合成算法，设计了一套苹果外部品质在线检测及分级装置。该研究以苹果为例，基于球模型提出苹果全表面图像合成算法、缺陷面积校正算法精确计算苹果的表面缺陷面积。通过试验验证，对苹果表面图像进行分割合成后，整体的图像的漏检率为0。提出缺陷面积校正算法，可以计算图像中位于任意位置的苹果缺陷真实面积，选取了120个样本进行验证，其中擦伤样本、碰伤样本、痘斑病样本、表面腐败样本各30个。4种表面损伤面积的预测值和真实值的决定系数R2均在0.97以上，均方根误差（Root Mean Squared Error, RMSE）在4 mm2以下。在偏角试验中，4种表面损伤面积的预测值和真实值的决定系数R2均在0.974 2以上，RMSE在6.304 4 mm2以下。装置检测苹果的速度为2个/s，评级准确率为95%。研究结果表明，检测与苹果评级精度较高，工作较为稳定，实现了苹果外部缺陷的检测与分级评价，可为苹果的外部品质检测提供技术支撑。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyZ1w5euQed1B79atdBRiDdQ4PNlqTK5kMUSh36Ifq9YwEPI0YOBOmTK1bK_BhbwfLFQE8bVzBFFvbOc_EZQvVVrZl7jmIP-7BQ7l8BWEz35hchibqHPBGCXgfj2_wXV3c84_kf_aioX4IWNcvo5peXAAibwUYoFe0JV9X3Wo18hR6absvAUJ_g3GRGmY6d16A=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 宽度学习在目标跟踪中的应用研究
{Author}: 张丹
{Tertiary Author}: 陈俊龙
{Publisher}: 大连海事大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 宽度学习系统;目标跟踪;多策略;尺度和漂移矫正;再学习和重检测
{Abstract}: 目标跟踪是计算机视觉领域的重要研究内容,其在智能交通、导航、视频监控、人机交互等领域都有着广泛的应用。目标跟踪过程中存在着背景混杂、尺度变化、旋转、形变、快速运动、遮挡、丢失等多种挑战。因此,研究实时有效的目标跟踪方法,对于计算机视觉技术的发展和应用有着重要的理论意义和应用价值。智能船舶是航海领域的研究热点,且对海洋科技的发展至关重要,计算机视觉技术是其研究的重要辅助手段,目标跟踪是其中的重要研究内容。因此,本文针对目标跟踪过程中存在的问题及其在交通运输方面应用的挑战,重点研究基于宽度学习的目标跟踪方法。近年来,深度学习、相关滤波等方法在目标跟踪领域的应用,大大促进了目标跟踪技术的发展。但也有着跟踪数据量有限,更新影响运行速度,训练时间长,跟踪精度仍需进一步提高等问题。本文针对目标跟踪及其在交通运输方面应用的挑战,主要基于宽度学习系统,开展了基于宽度学习的多策略目标跟踪方法、尺度和漂移矫正目标跟踪方法、孪生网络目标跟踪方法研究,用于解决目标跟踪过程中的遮挡、丢失、尺度变化、快速运动等问题,解决船舶跟踪过程中的小目标、远距离等问题,具体的研究分为以下三个部分:(1)针对一些基于深度学习的目标跟踪方法,离线训练时间长、计算量大等问题,结合宽度学习在网络计算量方面的优势,提出了基于宽度学习的目标跟踪方法。并结合多策略开展目标跟踪,一定程度上解决了遮挡等目标跟踪问题。该方法首先对宽度学习系统进行离线训练,获得宽度学习评价器;其次,为了提高跟踪算法的抗遮挡性和准确性,引入了多个跟踪策略,即在可准确找到目标的情况下采用搜索算法获取目标候选区域,节省跟踪时间;在多帧无法准确找到目标时采用加速鲁棒特征算法进行全局搜索,提高跟踪准确性。通过在标准数据集和船舶数据集上测试,结果表明,该方法训练时间短,跟踪适应性好。(2)针对目标跟踪过程中的尺度变化和漂移问题,提出了基于宽度学习的提升基线跟踪器跟踪精度的目标跟踪方法。根据宽度学习系统训练快速的特点,基于宽度学习的机制训练Io U网络,用于适应尺度变化。合理设计跟踪策略用于估计目标的跟踪情况,当跟踪定位不准确导致漂移时采用已经训练的宽度学习Io U网络进行粗略位置矫正,提高跟踪器的性能。通过在标准数据集和船舶数据集上测试,结果表明,该方法不仅有效的完成了尺度估计,且一定程度矫正了目标丢失、快速运动等情况下导致的跟踪漂移,提高了跟踪准确性。(3)针对目标快速运动、被遮挡,跟踪器在线更新影响运算速度等问题,提出了基于宽度学习的孪生网络目标跟踪方法。该方法可在跟踪过程中基于宽度学习系统进行在线训练,充分利用了跟踪数据集中目标的特征信息,使得特征提取更有效和更准确,实现了跟踪过程中的再学习。通过再学习的宽度学习系统进行跟踪过程中的重检测,有效解决了跟踪过程中短时遮挡、快速运动以及孪生全卷积方法无法实时更新外观特征等问题。通过在标准数据集和船舶数据集上测试,结果表明,基线跟踪器的性能得到了提高,且可在船舶数据集中解决小目标、远距离、短时遮挡等问题。综上所述,本文针对目标跟踪及其在交通运输应用过程中存在的挑战,将宽度学习应用于目标跟踪并开展了深入研究。针对部分基于深度学习的目标跟踪方法训练时间长、计算量大以及跟踪过程中的短时遮挡等问题,提出了基于宽度学习的多策略目标跟踪方法。针对跟踪过程中尺度变化和目标外观变化等导致跟踪漂移的问题,提出了基于宽度学习的目标跟踪尺度和漂移矫正方法。另外,基于宽度学习的优势,针对目标跟踪中的快速运动等问题,提出了基于宽度学习的孪生网络目标跟踪方法。充分的理论分析和在大量的标准数据集、船舶数据集上的实验结果表明,本文方法可以一定程度上解决目标跟踪跟踪过程中存在的一些问题,提升了目标跟踪方法的性能。
{URL}: https://link.cnki.net/doi/10.26989/d.cnki.gdlhu.2022.000057
{DOI}: 10.26989/d.cnki.gdlhu.2022.000057
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于OpenPose和人机交互的人体姿态识别技术研究
{Author}: 王非
{Tertiary Author}: 刘军
{Publisher}: 沈阳理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 人体姿态识别;特征融合;深度图像数据;反卷积
{Abstract}: 深度学习与计算机视觉发展迅速,已经从理论逐渐进入大众生活之中。随着深度学习以及计算机视觉的迅猛发展,人体姿态识别技术也逐渐在人机交互、医疗康复、监控安防和智能家居等领域占据重要地位。人体姿态识别技术具体流程为输入图像或视频等数据,对二维图像数据上的人体进行关键点检测识别的技术,以及通过关键点获取人体姿态信息去理解人体行为。虽然人体姿态识别技术发展迅速,网络模型逐渐增大,网络层数逐渐加深,对于复杂环境下人体关键点识别准确率逐渐提高,但在实际应用中,单一的网络模型不能充分利用图像的不同特征,容易由复杂环境产生的遮挡等因素产生误检、漏检等问题。以及网络层数的加深使得模型对硬件要求也会提高,并且会降低识别速率,同时巨大的参数量使得训练时容易产生梯度消失或梯度爆炸等问题,加大训练的难度。使得具有时效性的人机交互等项目变得困难。在之前的研究工作中,通常关注于改进网络的单个的模块而忽视了网络整体方案的改进和创新。在充分研究了RGB彩色图像,RGB-D深度图像以及Open Pose、Goog Le Net等网络后,由于彩色图像和深度图像数据类型不同,所以使用一种对于RGB图像数据和深度图像数据作为输入表现优异的双通道卷积神经网络,即Goog Le Net和NIN结构为基础组成的双分支卷积神经网络进行人体姿态识别,同时针对Inception结构和NIN结构进改进,使得两个分支网络可以充分提取RGB数据和深度数据的语义特征,并对输入的阶段进行特征融合实验,确定使用反卷积进行输入域的中间级特征融合,达到利用最优网络提取不同数据进行互补的效果,并完成人体姿态识别。同时利用NAdam优化器优化神经网络。实验证明了改进Inception结构和NIN结构后的双通道卷积神经网络不仅提高了识别准确率,并且大大优化了参数数量,性能明显优于原始网络和其他主流神经网络。
{URL}: https://link.cnki.net/doi/10.27323/d.cnki.gsgyc.2023.000151
{DOI}: 10.27323/d.cnki.gsgyc.2023.000151
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的复杂零件表面质量检测系统设计与实现
{Author}: 陈思宇
{Tertiary Author}: 慕丽
{Publisher}: 沈阳理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 机器视觉;图像处理;深度学习
{Abstract}: 制造业是国民经济的命脉,如今我国已经迈入制造大国的行列,但还不是制造强国,主要原因是产品质量问题较为突出、劳动生产率较低,因此要想提高我国的核心竞争力,应当将智能制造做为主攻方向。而在智能制造中,机器视觉技术被视为重要的一环,是提高生产环节自动化最高效的工具。本文围绕复杂零件表面质量检测问题,应用机器视觉技术,从图像采集、图像预处理、特征提取、检测分析、合格性分拣五个方面对机械零件质量检测展开研究,旨在提出一种通用性强、功能丰富、精度高、速度快的表面质量检测系统。本文的主要工作内容如下:(1)设计机器视觉检测硬件系统。对机器视觉检测所要用到的工业相机、镜头、光源、机械臂、控制器结合被检测要求进行选型,并且设计定位元件,使其保证被检测件在视场中的位置相对固定,同时设计相机、光源支架实现检测系统能够根据被测零件的特点进行多方向调节。最后合理布置产线系统,确保在线检测中机械臂与传送带相对位置固定。(2)设计模块化框架视觉算法。将一些常用的图像处理算法,如图像采集、图像预处理、图像分割、特征提取、写入报表、登录界面等制作为子程序的形式,可以实现快速集成和测试新算法,只需要通过简单的修改配置参数将各个模块进行组合,就可以完成各种复杂的视觉检测任务,压缩现场调试的时间,降低技术验证难度。(3)构建缺陷类型数据库。对于常见的划痕、斑点类缺陷自制数据库,对待检测零件的内外表面每类缺陷采集200张图像,使用常见的数据扩充方法,将每类缺陷类型各增加到800张,以提高模型的鲁棒性。(4)对质量检测方法进行改进。对于尺寸测量,舍弃传统的单一模板运算的方法,将检测的路径扩展到二维空间且仅对某一特定区域进行检测,减小了计算量,提高了实时性;对于缺陷检测,将传统的基于阈值分割与模式匹配的缺陷检测算法与基于深度学习的SSD＿Mobilenet V2缺陷检测算法进行对比实验,分析各自的应用场景。同时设计了深度学习一键训练模块,简化了训练的流程。(5)对深度学习推理过程进行优化。分析了传统的使用GPU进行推理的劣势,提出了一种基于CPU+Open VINO的推理模型,将推理的时间缩短为原来的六分之一,大大提升了检测的效率。(6)开发机械零件质量检测系统。通过离线测试与在线检测两种工作方式,完成对模块的搭建工作。在离线测试中,主要应用图像采集模块、图像预处理模块、特征提取模块、尺寸测量模块、缺陷检测模块、写入报表模块完成对零件的多参数多表面的高精度检测;在在线检测中,主要应用图像采集模块、尺寸测量模块、缺陷检测模块、通信模块,通过将采集、检测程序部署到CRIO中,实现高速、并行检测。
{URL}: https://link.cnki.net/doi/10.27323/d.cnki.gsgyc.2023.000254
{DOI}: 10.27323/d.cnki.gsgyc.2023.000254
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目立体视觉的测量技术研究
{Author}: 李淼
{Tertiary Author}: 华宇宁
{Publisher}: 沈阳理工大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 双目立体视觉;三维测量;立体匹配算法;OpenCV
{Abstract}: 双目立体视觉是机器视觉研究的重要分支之一,随着计算机硬件处理能力的增强与图像采集设备精度的提高,在工业、航天、医疗、汽车等领域都有着广泛的应用。双目视觉测量技术能够非接触获得拍摄目标的三维空间信息,有着结构简易、操作方便、测量精度高的优点。文章从立体视觉技术出发,研究双目立体视觉的测量方法,为了提高测量的准确度,对立体匹配算法进行改进,搭建了双目视觉测量系统。现阶段利用CT设备采集医学影像时,需要医师根据临床扫描参数确定患者检查部位以及扫描范围,对患者手动摆位后放线得到医学影片。本文从实际需求出发,研究在非接触的情况下获取人体检查部位的长度与厚度,为扫描床的远程移动提供数据。针对双目视觉测量系统测量过程中涉及的双目相机标定、图像预处理、立体校正、立体匹配等重要技术进行了理论与实验分析。本文主要研究内容如下:首先介绍了双目相机成像几何模型、双目视觉测量原理以及双目相机标定原理。进行了基于张正友标定法的相机标定实验,最终选择了重投影误差较小的基于OpenCV库编程的自动标定法获取相机内外参数。其次针对相机自身结构、光照不均以及镜头畸变等因素导致的图像明暗差异和左右图像相对应的像素点不能行对准的问题,最终选择限制对比度的自适应直方图均衡化图像增强算法以及Bouguet校正法处理双目相机采集的图像。然后研究了立体匹配算法的关键技术,经过实验对比分析BM、SGBM、ADCensus这三种常用立体匹配算法的匹配效果后,选择SGBM算法作为本研究的立体匹配算法。针对算法在图像光线明暗不均匀、左右成像盲区处立体匹配质量较差以及获取的视差图存在孤立空洞的问题,对SGBM算法进行改进,将梯度代价与Census代价相结合作为计算最终代价值的方法,并在视差后处理步骤中添加自适应中值滤波算法对视差图进行精细化处理,提升了算法抗光线干扰的能力和匹配的准确度。最后搭建双目视觉测量实验平台,基于Visual Studio 2019和OpenCV视觉库设计MFC图形界面,在CT机调试间完成尺寸测量实验。实验结果表明本研究搭建的测量系统能够准确测量,测量的相对误差不超过0.62%,能够为扫描床的移动提供准确的数据。
{URL}: https://link.cnki.net/doi/10.27323/d.cnki.gsgyc.2023.000043
{DOI}: 10.27323/d.cnki.gsgyc.2023.000043
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于生成对抗网络的图像超分辨率算法研究
{Author}: 薛涵博
{Tertiary Author}: 雷景生
{Publisher}: 浙江科技学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 超分辨率重建;生成对抗网络;计算机视觉;感知效果
{Abstract}: 近年来,随着经济与科技的快速发展,影像技术以前所未有的力度影响着我们的日常生活,图像的成像技术逐渐成为研究热点。超分辨率重建算法就是在软件层面上来提高图像的质量,是一个经典的计算机视觉任务。生成对抗网络的研究促进了超分辨率技术的发展,基于生成对抗网络的超分辨率算法解决了传统算法重建图像纹理平滑、感知效果差的问题,但是由于生成对抗网络训练不稳定、生成网络学习能力差的问题,导致重建图像还存在着纹理缺失、伪影、噪点等问题。本文主要围绕着基于生成对抗网络的超分辨率重建技术展开研究与分析,主要内容如下:
(1)针对超分辨率对抗网络训练不稳定、重建图像缺失纹理的问题,提出了基于高频信息特征融合的超分辨率对抗网络,将高频信息和RGB图像在预提取特征后进行特征融合,并将融合结果作为判别模块的输入,通过输出像素域得分矩阵来反馈学习结果,它增加了网络的学习能力,增强了对抗训练的稳定性,同时让判别器更专注于图像的高频信息部分,从而约束生成器重建出纹理细节更加丰富的图像。
(2)针对特定复杂图像的特点提出了基于逆向特征融合模块和残差特征膨胀模块的超分辨率重建算法。逆向特征融合模块来实现图像高级语义与低级语义的结合,使得重建后的图像整体表现更好,并有效的减少重建图像的棋盘效应。残差特征膨胀模块增加图像纹理细节的提取能力,使重建图像的局部细节更加丰富。
(3)针对现实场景中超分辨率对抗算法存在的问题,在第三章和第四章研究的基础上提出了残差特征增强的超分辨率对抗网络。通过引入基于高频信息融合的判别网络来提升对抗训练的反馈能力,使高频信息直接去约束生成器的重建结果,并使用非固定标签计算损失来降低判别器的学习效率,增强网络训练的稳定性。同时在第四章研究的基础上设计了深度残差特征增强网络作为对抗网络的生成器,进一步提升细节的特征提取能力。
{URL}: https://link.cnki.net/doi/10.27840/d.cnki.gzjkj.2022.000360
{DOI}: 10.27840/d.cnki.gzjkj.2022.000360
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的鬼成像算法研究
{Author}: 胡峥
{Tertiary Author}: 朱虎
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 鬼成像技术;图像处理;深度神经网络;计算机视觉
{Abstract}: 鬼成像技术是一种通过测量参考光场与探测光场之间的关联函数从而获取目标图像信息的新型成像技术。它是一种不同于传统光学成像的成像方式,由于其通过测量光束之间的空间相关性进行成像的特点,所以在遥感成像、超分辨率成像等多个领域都扮演重要的角色。但鬼成像技术也由于其自身的特点,需要大量的采样来重建高质量的图像。近年来,深度学习鬼成像成为图像处理领域的热点研究课题。但是现有的方法在面对低采样率下的鬼成像图像重建任务时,重建效果和重建速度依旧不尽人意,尤其是光学设备较差、数据量较少的场景。因此,本文立足于深度学习鬼成像,针对提高低采样率下的鬼成像图像的成像质量进行深入研究,具体如下:(1)从捕获局部到全局之间的关联信息和利用上下文更好地进行信息建模角度出发,本文提出一种基于闭环子空间映射的多层级网络鬼成像重建方法。本方法提出并引入基于子空间映射的闭环模块,利用监督学习使整体网络快速稳定,并不断利用图像的深层特征进而学习全局相关性。此外,本方法使用多层级聚合进行特征融合,结合浅层特征和深层特征,借助层级连接,充分利用上下文信息,逐步优化重建图像。大量的实验结果证明,与目前较为领先的深度学习鬼成像重建方法相比,该方法在低采样率下,能较好完成鬼成像重建任务,重建结果可辨识,结构完整,背景噪声较少。(2)在极低采样率下,上述方法的重建效果并不完美,因此提出一种基于多层级聚合网络的鬼成像重建扩散概率模型。该方法首次将扩散概率模型应用在鬼成像领域,并在正向过程以及反向扩散过程的联合学习过程中充分利用监督学习:在正向过程中,利用层级感知损失,增强模型对感知特征的学习能力;在反向过程中借助分类器更好地恢复背景,提高重建图像的质量。大量的实验结果证明,在极低采样率下,面对简单目标或者复杂物体,本模型都有着更为突出的鬼成像图像重建效果。重建图像内外纹理结构清晰且与原始图像较为接近,并且该模型具有一定泛化性,适用于更多的实时应用场景。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.000872
{DOI}: 10.27251/d.cnki.gnjdc.2022.000872
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向绿色环境的垃圾检测算法研究
{Author}: 蔡勇
{Tertiary Author}: 成孝刚
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 生物质;目标检测;角度检测;CA注意力机制;特征融合
{Abstract}: 城市垃圾焚烧发电是生物质能源再利用的重要方法之一。但是,其中可回收垃圾的焚烧会带来资源浪费和环境破坏。当前,垃圾处理工厂主要依赖人工分拣的方式从城市垃圾中筛选出可回收垃圾。这种方式工作效率低,成本代价大,不利于人员身心健康。本文针对生物质焚烧发电面临的可回收垃圾分拣难题展开研究。利用目标检测技术,为焚烧发电前的垃圾分拣赋能,以提升工作效率。本文主要工作概述如下:(1)构建了多维度可回收垃圾检测数据集(Mi Re G:Multi-dimensional dataset of Recyclable Garbage Detection)。该数据集包含可回收垃圾图片、垃圾类别、坐标和角度等多维信息。本文在实测环境下进行数据采集,并展开大量数据预处理工作,构建图片共计6694张。通过人工标注方法,得到对应的多维信息。(2)融合Yolov5与CA注意力机制的垃圾检测算法。为提升检测精度,本文将CA注意力机制引入Yolov5网络,以提升网络搜索能力。在此基础上,根据实测环境进行超参调节,以提升检测精度。数据验证表明,改进网络的整体性检测精确度由90.5%提高到91.6%,对于纸盒的检测精确度由85.9%提高到90.2%。(3)基于Center Net的垃圾检测算法及其改进:实际应用中,对于可回收垃圾的抓取,为了减少漏检现象,需要对网络做改进。为了提升夹爪抓取效率,需检测目标物体在背景中的角度信息。本文在Center Net的基础上,开展了两方面研究:(a)基于CenterNet与特征融合的垃圾检测算法。针对漏检现象,本文分别以Res Net-50和Res Net-101作为主干网,以优化Center Net网络结构,并引入特征融合模块对网络进行改进,以增强特征提取能力。结果表明,检测准确度分别提升了1%。(b)为实现角度检测,本文对CenterNet末端进行改进,增加了角度检测算子,以完成对于目标物体角度的检测。结果表明,角度误差小于0.5度。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001106
{DOI}: 10.27251/d.cnki.gnjdc.2022.001106
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于上下文关联特征学习的实时语义分割研究
{Author}: 徐国安
{Tertiary Author}: 高广谓
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 实时语义分割;卷积神经网络;Transformer;空洞卷积;深度可分离卷积
{Abstract}: 近年来,作为计算机视觉领域一个具有挑战性的研究课题——图像语义分割,在自动驾驶、医疗影像分析、无人机落点判定以及航天卫星遥感等现实场景中发挥了至关重要的作用。受益于深度学习中卷积神经网络在图像处理领域的巨大成功,目前的语义分割任务在性能方面取得了显著提升。然而,大多数语义分割方法只是通过不断增加模型复杂度来提高分割效果,却忽略了硬件资源内存、显存消耗和推理延迟等问题。针对以上问题,本文基于深度卷积神经网络,提出了轻量级实时语义分割模型兼顾算法精度、推理速度和内存占比,具体研究内容如下:(1)本文设计了一种基于多尺度上下文融合方案的新型轻量级网络(MSCFNet),探索了一种非对称的编码器-解码器架构。在编码器部分采用了由分解卷积、深度可分离卷积和空洞卷积组成的有效的非对称残差卷积模块,并且在三次降采样之后,利用原图信息进行相应尺度细节信息补充;同时,利用网络不同阶段的注意力分支来捕获多尺度的上下文信息,并在解码部分融合它们以提高图像特征的表达。MSCFNet在Cityscapes数据集上实现了71.9%m Io U的精度,并且可以在一个Titan XP GPU配置上以超过50FPS的前向推理速度运行;在Cam Vid数据集上实现69.3%m Io U的精度,很好地实现了分割效率和分割精度之间的平衡。(2)针对图像语义分割在编码部分下采样会丢失信息这一问题,本文提出了一种快速双边对称网络FBSNet。具体来说,FBSNet采用了具有两个分支的对称编码器-解码器结构,分别是语义信息分支和空间细节分支。语义信息分支是具有深度网络结构的主要分支,用来获取输入图像丰富的上下文信息以及获得足够的感受野;空间细节分支是浅而简单的网络,用于建立每个像素之间的局部依赖关系以保存细节。同时,设计了一个特征聚合模块,以有效地结合这两个分支的输出特征。在一张RTX2080Ti GPU配置上进行测试,在Cityscapes数据集上以每秒90帧的推理速度达到70.9%m Io U的分割精度,在Cam Vid数据集上以每秒120帧的推理速度达到68.9%的分割精度,且整体模型大小只有0.62M,计算复杂度只有9.7G,是这一种硬件资源受限条件下的高效分割方法。(3)利用Transformer不拘束于局部信息之间的权值配比关系,而是着眼全局的相互依赖这一特性,将卷积神经网络CNN与Transformer相结合,提出了一种基于卷积神经网络编码解码结构的网络(LETNet)。首先利用编码器对输入的图像进行特征提取,然后将特征图进行重塑切割变为一维序列输入到高效的Transformer进行全局特征建模。解码部分负责恢复到初始的分辨率进行逐像素点的分类预测最终形成分割图。LETNet仅在一张RTX3090 GPU的硬件基础、整体只有0.91M参数量以及12.6G计算复杂度的条件下,在Cityscapes数据集上取得了71.6%的分割结果,在Cam Vid数据集上更是取得了70.5%的显著表现。该方法充分证明了卷积神经网络CNN与Transformer结合之后在实时语义分割领域的有效性。综上,本文针对实时语义分割问题提出了三种有效的网络,结合了卷积神经网络与Transformer,以解决实际问题为出发点,结合空洞卷积、深度可分离卷积、注意力机制等在分割精度、模型大小和推理速度取得了更好的平衡,并且通过实验证明,本文提出的方法取得了预期的效果,具备了部署到实际场景应用的能力。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001435
{DOI}: 10.27251/d.cnki.gnjdc.2022.001435
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的驾驶行为分析及边缘系统设计
{Author}: 杨明
{Tertiary Author}: 沈澍
{Publisher}: 南京邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 驾驶行为识别;机器视觉;卷积神经网络;迁移学习;边缘系统
{Abstract}: 当今,汽车出行给人们带来便利的同时也给交通安全增加了很大的压力。其中,长时间的驾驶导致的疲劳行为以及不规范的分心驾驶行为是导致交通事故频发的主要原因。为此,本文主要研究了基于机器视觉的驾驶行为分析识别方法以及设计了一套实时边缘系统,其主要工作如下:首先,本文研究了基于迁移学习的驾驶行为识别方法。该部分主要分为对驾驶行为识别方法的研究以及图像增强技术的技术研究,以及公开数据集上的实验设计与分析。驾驶行为的识别方法研究主要包括卷积神经网络的理论研究以及主流模型的研究,包括Alex Net、VGGNet、Google Net、Res Net等模型进行研究,探究了机器视觉方法在驾驶行为分析的可行性。其次,本文针对疲劳行为进行识别分析研究。该部分主要包括对于驾驶疲劳检测方法的研究以及疲劳行为识别系统的设计与实现。其中驾驶疲劳检测方法的研究主要包括基于HOG的人脸检测以及人脸关键点检测,最后使用PERCLOS原理对疲劳行为进行识别。基于疲劳检测的方法基础,本文设计了一套疲劳行为的实时识别系统,在复杂场景中,实现了对于闭眼与哈欠行为的识别,综合判断驾驶员的疲劳状态。然后,本文针对驾驶分心行为进行识别分析研究。该部分包括对于NJUPT数据集的采集、数据集的选取研究、模型的训练与评估以及多权重驾驶行为的分析。在数据集采集与数据集选取研究部分,使用同一个模型VGG16在不同的数据集上进行训练最终选取泛化能力最强的数据集组合。在对图像数据集进行预处理之后,对该数据集进行多个模型的测试评估,综合平衡准确率与推理速度的结果,选取Shuffle Net V2作为边缘系统所使用的模型并进行模型的改进,使分心行为总体识别率由82%提高到86.3%。最后,本文实现了一种基于机器视觉的驾驶行为边缘系统。主要包括系统设计以及系统功能测试两个部分。系统设计部分主要介绍了硬件与软件的设计与实现。系统功能测试部分实现了在实际环境中功能测试,对驾驶员的行为进行了实时检测,达到了80%以上的正确率,基本满足实时识别的要求。
{URL}: https://link.cnki.net/doi/10.27251/d.cnki.gnjdc.2022.001681
{DOI}: 10.27251/d.cnki.gnjdc.2022.001681
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 利用可解释性方法的对抗攻击和防御研究
{Author}: 李小剑
{Tertiary Author}: 谢晓尧
{Publisher}: 贵州师范大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 对抗样本;可解释方法;对抗训练;恶意TLS流量;恶意软件
{Abstract}: 以机器学习、深度学习为代表的人工智能技术在不断发展且广泛服务和赋能人类生产生活方式的同时,其自身存在的技术漏洞所带来安全隐患却不容忽视。由于先天性的算法黑箱和训练过程不可解释性等自身存在的安全问题,衍生出了针对数据、模型和算法的攻击,这吸引了越来越多安全研究人员的关注,其中针对模型算法安全的对抗样本攻击成为当下人工智能安全领域最为关注的研究热点。研究表明,在各领域表现良好的机器学习模型在面对对抗样本攻击时表现得十分脆弱,攻击者通过在原始输入数据中添加精心设计的细微扰动所形成的对抗样本,能够诱导机器学习模型以高置信度做出错误的决策。对抗样本的存在给恶意攻击者提供了强有力的攻击,使网络空间安全面临更为严峻的挑战,阻碍了机器学习、深度学习在该领域的各应用场景的深入拓展。因此,开展机器学习和深度学习算法安全性的研究,特别是对抗样本攻击和防御技术的研究具有重要的理论价值和现实意义。
本文先从攻击的角度,分析了网络空间安全领域中恶意流量、恶意软件检测两个具有高对抗性攻防场景中生成对抗样本所特有的场景约束和挑战,同时利用可解释性方法“透明化”深度学习复杂推理背后的决策逻辑,为生成适合这两个场景的对抗样本提供指导依据;接着从防御的视角,在图像分类领域提出一种新的提高模型对抗鲁棒性的对抗训练方法,有效地改善了标准对抗训练方法训练耗时过长等问题。本文的主要研究内容和创新工作如下:
1、基于LIME规避检测的恶意TLS对抗流量生成研究
针对主流基于机器学习算法的恶意流量检测系统,在未知模型结构和参数细节的前提下,提出一种基于LIME（Local Interpretable Model-Agnostic Explanations,LIME）的对抗样本生成方法。该方法首先针对每一恶意TLS样本实例及其一组近邻训练一个简单易解释的线性模型,用于拟合黑盒分类器关于该实例决策边界局部性质,并以线性模型的权重系数表示输入向量各分量对分类结果的影响权重,从而通过简单模型解释目标模型局部特征权重。同时为降低生成实际有效对抗攻击流量的难度,将输入样本沿替代线性模型决策边界法向量方向进行扰动,并将扰动添加到样本中有利于使目标检测模型判断为良性流量的负特征上来生成对抗样本,确保生成的对抗样本保留了原始恶意样本的攻击特性。与Bot GAN相比,本文方法扰动恶意流量特征维度更少,减少了生成实际恶意对抗流量的难度。最后根据修改的对抗特征逆向构建攻击流量,生成可在真实网络环境中传输的对抗流量,实验结果表明,该方法可对主流基于机器学习算法的目标检测系统构成实际威胁。
2、基于良性显著特征恶意软件对抗样本生成研究
针对基于灰度图像恶意软件检测系统,提出一种保留恶意软件可用性和功能性的对抗样本生成方法。首先重点分析PE文件格式和加载对齐机制,发现PE文件各区块之间因加载机制文件对齐而存在的间隙空间和PE文件尾部空间添加或修改数据均不会破坏PE文件功能性和可用性,并将这两部分空间区域作为对抗攻击区域。在此基础上提出两种基于良性显著特征的对抗样本生成方法:BSFA和EnhancedBSFA。其中BSFA方法利用Grad-CAM可解释方法从良性样本提取具有类别区分性的良性显著特征,将其作为扰动值填充或修改恶意样本攻击区域内容,以增加恶意样本的良性判别属性,从而诱导目标检测模型将恶意PE文件误判为良性样本。EnhancedBSFA方法为在BSFA方法的基础上融合了M-FGSM方法,其攻击效果更佳。
3、基于自适应噪声添加与最大化模型预测熵对抗训练算法与研究
为抵御对抗样本的攻击,提出一种新的提高模型鲁棒性对抗训练方法。从分析神经网络在推理时背后的决策依据着手,探究深度神经网络在分类对抗样本时做出错误决策的原因,以透明化深度学习的“黑盒性”。在此基础上引入可解释性工作Grad-CAM,首先提出利用类激活映射指导噪声自适应添加（ANA）的对抗训练方法,该方法通过在输入图像对类别导向起关键作用的区域添加更多的噪声,以抑制神经网络对该区域像素变化的敏感程度,而在其他非关键区域添加较小的噪声,以提高模型的分类精度。相对于标准的对抗训练TRADES、Madry,ANA方法只需迭代计算一次反向梯度,有效节省了对抗训练的时间。其次,为进一步提高模型的对抗鲁棒性和泛化能力,在原有网络代价函数添加最大化模型预测熵（MME）正则项,在保证模型分类边界面不产生偏移的前提下,降低了模型受到对抗攻击的可能性,并从理论上证明了组合自适应噪声与最大化模型预测熵（ANAMPE）的对抗训练方法有严格的下确界。最后在MNIST,CIFAR-10和CIFAR-100数据集上验证了ANAMPE方法在5种主流白盒攻击下FGSM,MIM,BIM,JSMA,C&W模型防御对抗攻击的能力,实验结果表明,ANAMPE方法相比于ANA可以进一步提高模型的对抗鲁棒性。
{URL}: https://link.cnki.net/doi/10.27048/d.cnki.ggzsu.2022.001020
{DOI}: 10.27048/d.cnki.ggzsu.2022.001020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于注意力机制的视觉描述研究
{Author}: 万博洋
{Tertiary Author}: 方玉明;温文媖
{Publisher}: 江西财经大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉描述;模型评价;深度学习;特征编码;注意力监督
{Abstract}: 面向图像和视频数据的视觉描述(Visual Captioning,VC)任务是计算机跨媒体领域的一个基础且重要的研究领域,其能为图像或视频自动生成描述其内容的自然语言文本。近年来,随着深度学习技术的不断进步,计算机视觉和自然语言处理领域获得了重大进展,而视觉描述作为同时牵涉计算机视觉和人类自然语言的研究领域也获得了长足的进步。具体来说,在大规模视觉描述数据集的支持下,研究人员设计基于深度学习的编码-解码网络的视觉描述模型。被提出的视觉描述模型也不断地推高基准视觉描述数据集的成绩指标。尽管视觉描述领域已经获得了令人瞩目的成果,当前视觉描述领域依然在模型评价、模型架构和模型监督三个方面有不足之处:第一,现有基于通用视觉描述数据集的模型评价方法无法有效地评价视觉描述模型的泛化能力,这导致影响视觉描述模型的泛化能力的关键因素还有待研究,从而进一步阻碍了视觉描述模型的设计;第二现有视觉描述模型在视觉信息编码阶段往往忽视了视觉特征通道之间的联系,这伤害了视觉描述模型中视觉编码特征的表征能力,进而降低视觉描述模型生成描述文本的质量;第三,基于显式监督建立视觉目标和文本名词之间关系是提升视觉描述模型输出文本质量的有效方法,但是现有的注意力监督方法都忽视了视觉目标的富信息量局部特征,这降低了视觉描述模型对视觉目标生成描述的细粒度和准确度。为了解决上述问题,本文开展了一系列面向视觉描述任务的研究,旨在探索构建鲁棒视觉描述模型的关键因素、提高视觉描述模型的视觉信息建模能力和提升视觉描述模型对视觉目标的描述质量。本文的主要创新点如下:
(1)提出一种基于最大差异竞争的视觉描述模型评价方法。本文基于图像描述模型进行评估实验。近年来,在通用大规模数据集和深度学习技术的支持下,图像描述领域获得了长足的发展。但是,图像描述模型的在通用数据集的成绩进入到了一个瓶颈期,最近被提出的图像描述模型仅获得了微小的成绩提升,且彼此成绩差别极小。观察到这一现象后,一个重要的问题浮现出来:“这些最新图像描述模型在真实场景图像的效果如何?”为了厘清这个问题,本文提出模型评价方法评价现有图像描述模型的泛化能力。具体来说,本文设计了一种基于最大差异竞争的模型评价来验证现有的图像描述模型。首先,本文基于参评图像描述模型的输出之间的差异,从一个可以任意大小的原始图像数据集中提取富信息图像获得新测试集样本。其次,通过一个小规模且低成本的主观标注实验获得包含测试样本和人工标注的富信息测试集。再次,基于参评模型在富信息测试集的成绩进行它们的泛化能力评价。最后,通过对泛化能力评价实验结果进行分析,得到影响图像描述模型性能的关键因素,并总结视觉描述模型的潜在研究方向。
(2)提出一种面向图像描述的双流自注意力深度学习模型。最近,基于自注意力机制的编码-解码模型在图像描述领域占据了统治地位。但是,已经被发表的图像描述模型中绝大多数在进行视觉特征编码时只关注建立空间tokens之间的关系,而视觉特征通道之间的关系被忽视。考虑到视觉特征中不同的特征通道被认为代表不同视觉目标,现有图像描述模型对通道级特征编码的忽视会损害它们生成的语句在描述视觉目标名词和形容词方面的性能。为了缓解上述问题,本文提出了一种双流自注意力网络。具体来说,作者设计了一种并行结构的双流自注意力模块,该模块同时基于空间tokens和通道tokens进行视觉信息编码。同时,为了高效且有效地获取通道级视觉特征,作者提出了一种线性计算复杂度的群自注意力编码模块作为双流自注意力模块的通道级视觉编码模块。经过多个基准数据集验证,双流自注意力模块通过增强模型的视觉编码能力有效地提升图像描述模型的成绩。
(3)提出一种面向视频描述的富信息量注意力监督方法。现有注意力监督方法显式地引导视觉描述模型在生成文本时关注视觉输入中的相关内容,从而提升视觉描述模型的准确度和可解释性。但是,现有注意力监督方法常常忽视小却富信息量的视觉区域,这是因为根据现有注意力监督方法采用的基于交并比的关注区域采样法,这些视觉区域被认为是不需要被关注的。在另一方面,现有注意力监督方法通用的注意力损失函数要求模型生成文本时平等地关注所有相关视觉区域。这使得模型难以聚焦到与文本更相关的富信息量区域,降低了模型生成文本的质量。为了缓解上述问题,本文提出了一种富信息量注意力监督法,该监督法包含一种基于候选区域的注意力标签采集法和一种基于群的注意力损失函数。其中,被提出的注意力标签采集法将与人工标注区域交叠的小尺寸候选区域作为注意力正区域,而基于群的注意力损失函数允许模型动态地给注意力正区域分配注意力。本文提出的注意力监督方法可以直接应用在现有的视频描述模型,其能在不增加推理成本的基础上提升视频描述模型的文本生成质量,引导多个视频描述模型在基准数据集上获得了一致的性能提升。
总体而言,本文首先提出了一种新的模型评价方法,该评价方法作为现有基于基准数据集的模型评价方法的补充,发现了视觉编码、模型结构和注意力机制等因素对图像描述模型泛化能力的重要影响。本文还根据模型评价结果指出提升视觉描述模型性能的潜在研究方向。在此基础上,本文提出了一种视觉特征编码模块,其高效且有效地获得了更具表征能力的视觉编码特征,并以此视觉编码特征提升图像描述模型的成绩。并且,本文从注意力监督的角度出发,发现了小却富信息量的视觉区域对视觉描述模型在描述准确度和细粒度方面的提升作用。
{URL}: https://link.cnki.net/doi/10.27175/d.cnki.gjxcu.2022.002025
{DOI}: 10.27175/d.cnki.gjxcu.2022.002025
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于黎曼流形学习的图像集分类算法研究
{Author}: 王锐
{Tertiary Author}: 吴小俊;孙俊
{Publisher}: 江南大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 图像集分类;黎曼流形学习;深度学习;度量学习;神经网络
{Abstract}: 图像集是指由一组同属于相同类别的图片构成的集合(如视频片段),是多媒体数据的重要载体之一。图像集分类是计算机视觉和模式识别中的基础研究方向,是图像和视频理解领域的重要信息处理技术,在智慧城市等人工智能场景中有着广泛的应用。以图像集为对象的分类算法旨在对图像集的数据结构和语义信息进行表示学习,从而实现对其所属类别的正确判定。经过二十几年的研究和发展,研究者们相继在理论、方法以及数据集等三个维度丰富了图像集分类的研究范畴,激发了对该方向深入探索的研究活力。尽管图像集相较于单幅静态图像涵盖了由姿态、视角、光照、运动速度以及背景等变化而导致的物体表观差异,如何对上述复杂的数据分布信息进行合理地编码,以及如何有效地度量图像集间的相似性,已成为该领域当前所面临的主要难题。近年来,随着以黎曼几何为基础的流形学习方法在视觉数据的非线性表征中展现出的优异性能,图像集分类领域的主要研究手段也侧重于这一方面。具体来说,基于浅层黎曼流形学习的图像集分类模型在传统机器学习算法的基础上通过引入黎曼度量学习等判别分析理论,提升了分类的精度;而深度神经网络范式在黎曼流形范畴的推广提供了较之传统手工特征更加有效的几何语义信息,进一步改善了分类的准确性和鲁棒性。本文在黎曼流形学习的基础上,深入分析了浅层方法和深度模型在表示学习过程中存在的不足,从数据建模、网络架构以及目标函数三个方面提出解决思路,并设计有效的实施方案。本文主要的研究工作概括如下:(1)提出了基于多流形联合表征和多核度量学习的图像集分类算法。考虑到不同的黎曼流形所蕴含的统计信息具有互补性,从多流形联合表征的视角对图像集数据进行建模,克服了单一的黎曼流形特征信息量有限的问题。对于抽取到的多种结构化特征,利用设计的多核度量学习框架,并结合注意力机制,不仅缓解了数据在跨域融合过程中出现的结构信息扭曲问题,同时也增强了所学特征的判别能力,提升了分类准确性。(2)提出了基于轻量级对称正定(Symmetric Positive Definite,SPD)流形神经网络的图像集分类算法。针对浅层学习模型表征能力有限、迭代优化耗时的问题,通过在SPD流形上构造一个轻量级的黎曼神经网络,并结合设计的黎曼特征修正模块、池化模块以及核判别分析算法,实现了对SPD矩阵的多级非线性学习和判别性分类。此外,基于双向二维主成分分析技术的无监督权值优化机制简化了模型搭建,提升了计算效率。(3)提出了基于SPD流形深度度量学习的图像集分类算法。在原有SPD流形神经网络(SPDNet)的基础上,针对由数据的多级压缩映射而诱发的结构信息退化问题,通过在SPD流形上构造一个新颖的黎曼自编码网络,并结合设计的度量学习正则化项以及重构误差项进行端到端联合训练,增强了隐含层特征的信息量。此外,上述目标函数为交叉熵损失项提供了用于描述特征分布的互补性监督信息,提升了分类准确性。(4)提出了基于深度SPD流形神经网络的图像集分类算法。分析已有黎曼网络的构建范式,利用Stiefel权值矩阵的半正交性特点,在SPDNet(主干网络)的输出端构建了一个堆叠式的黎曼自编码模型。在多个重构误差项的连续监督下,每一个黎曼自编码器的映射机制都将逼近于恒等映射,从而能够有效地克服深度黎曼网络的信息退化问题。此外,为设计的黎曼网络引入了两阶段度量学习,进一步强化了分类准确性。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.002244
{DOI}: 10.27169/d.cnki.gwqgu.2022.002244
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂场景中基于胶囊网络的牛只个体脸部识别研究
{Author}: 徐峰
{Tertiary Author}: 高静
{Publisher}: 内蒙古农业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 牛脸识别;生物识别技术;计算机视觉;胶囊网络;小样本学习
{Abstract}: 随着大众生活品质的不断提升,肉类、奶类、乳制品类的需求量也在不断加大。同时我国养殖政策从追求产量和产值转向追求质量和卫生,政府、社会和消费者对食品安全也越来越关注和重视。牛只个体识别在食品溯源、身份鉴别、生产管理、疫苗接种、疾病防控和牲畜的所有权分配等方面发挥了重要作用。耳标等侵入式牛只个体识别方法,存在设备容易丢失、损坏、可被复制和篡改等弊端。而牛脸作为暴露在外的生物特征,生物信息显著,在非侵扰的情况下即可完成个体识别。牛只个体脸部识别属于实例级识别任务范畴,牛群中个体脸部之间的差别不大,而同一个个体的多个数据样本由于场景、视角、光线、形变等方面的差异,造成个体脸部不同样本之间特征迥异。这些都是全世界牛只个体脸部识别面临的关键问题和挑战。基于以上,本研究从生物特征识别分析技术、计算机视觉和深度学习等技术方面,围绕着深度学习模型和个体样本量之间的依存性,研究复杂场景中牛只个体脸部的识别问题。本文主要研究对象、内容及结论如下:1)针对鲜有批量获取高质量、规范化牛脸图像数据的标准流程,本研究制定了在复杂场景中牛只个体脸部数据标准化采集方案。通过牧场实地调研,根据大规模养殖实际情况和数据采集关键技术要点,提出了牛只个体脸部样本采集准则和数据拍摄要求。依据准则和要求,采集牛只个体数据并创建原始牛只视频、图像数据集。提出Res SSD算法,利用残差学习模块提取并融合多尺度特征图,完成从原始牛只数据集中提取牛脸图像。总结上述工作,制定了牛只个体脸部数据采集、制作方案。2)针对目前少有大规模公开牛只个体的脸部数据集,本研究构建了264个牛只个体的脸部图像数据集。数据集包含可用于图像识别和目标检测的牛只个体图像、牛只个体脸部标注文件、牛只个体脸部图像各143751个文件。为弥补数据集中牛只个体类别样本量间的不均衡,提出了M-CVAE算法,通过提取正则化的高斯潜在变量,生成指定牛只个体的脸部图像代替数据增强技术。3)针对个体多样本情况下的图像识别,本研究提出了C-LBP Caps Net算法进行牛只个体脸部图像识别。首先,将卷积特征和局部二值模式纹理特征相结合,提出了C-LBP融合特征提取器。接着,分别利用自注意力机制和增加胶囊层数,改进经典胶囊网络结构,在增强特征提取能力的同时提高了胶囊利用率。把C-LBP融合特征提取器和改进的胶囊网络配合使用,提出了C-LBP Caps Net算法。C-LBP Caps Net在牛只个体脸部数据集上与其他网络模型做实验比较。实验结果表明,C-LBP Caps Net在牛只个体脸部识别时准确率达到99.12%,F1值达到98.84%。当训练过程中添加新的位姿数据时,C-LBP Caps Net也较其他网络表现出良好的性能和鲁棒性。4)针对个体小样本情况下的图像识别,本研究提出了Siamese DB Caps Net算法。首先,通过融合密集模块来改进经典胶囊网络结构,在提高CNN提取特征能力的同时保留特征的空间信息,提取图像的位姿向量。接着,利用孪生网络结构提取图像对特征,得到双变量特征。根据位姿向量的不变性特点,使用双变量特征的相关性分析取代经典孪生网络的距离度量,实现图像的分类识别。在小样本牛只个体脸部数据集上和其他网络模型进行实验比较。实验结果证明,Siamese DB Caps Net准确率达到93.00%,F1值达到93.54%。5)针对个体没有训练样本情况下的图像识别,本研究提出了牛只个体脸部识别的零样本学习方法。根据Siamese DB Caps Net网络使用位姿向量可以提取牛只脸部特征,类推从未参加训练的牛只脸部数据中也可以映射到相似的位姿向量特征。使用Siamese DB Caps Net训练得到的最优模型,在30头未参与训练的陌生牛只脸部数据集上进行测试。牛只个体脸部识别率达到了86.92%,证明Siamese DB Caps Net模型可以进行陌生牛只个体的零样本脸部识别。
{URL}: https://link.cnki.net/doi/10.27229/d.cnki.gnmnu.2022.001242
{DOI}: 10.27229/d.cnki.gnmnu.2022.001242
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像和光谱技术的马铃薯早疫病智能诊断方法研究
{Author}: 于涵
{Tertiary Author}: 杨克军;黄忠文
{Publisher}: 黑龙江八一农垦大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 马铃薯早疫病;图像处理;近红外光谱;傅立叶变换红外光谱;诊断
{Abstract}: 马铃薯的产销量在全球主要粮食作物中排在小麦、玉米、水稻之后,居第四位。马铃薯早疫病作为田间常见的马铃薯病害,不仅影响马铃薯品质,而且会大幅度降低马铃薯产量。针对目前马铃薯早疫病传统诊断方式效能低下的情况,本文以马铃薯早疫病检测和诊断技术为研究对象,分别研究了基于视觉技术、基于红外光谱技术和基于傅里叶变换红外光谱技术的马铃薯早疫病检测诊断关键技术,形成了能精准、迅速地诊断马铃薯早疫病的监测方法,研究结果为运用光谱图像技术监测马铃薯早疫病提供了技术和理论依据,为智慧农业发展提供了植物病害智能监测预警内容,具有重要的理论意义和应用价值。1.基于计算机视觉的马铃薯早疫病诊断系统的研发以马铃薯早疫病的病斑为主要研究对象,利用自制的图像采集校正背板对马铃薯早疫病病斑进行采集,利用R通路灰度化图像对病斑边缘进行增强完成病斑的提取,利用邻域平均法对早疫病病斑图像的进行增强,选用EM分割对早疫病病斑图像进行分离处理。提取多变量特征参数,选定了适合表示马铃薯早疫病病斑特征的9个颜色参数、3个纹理参数、1个图形参数,共13种有效特征参数描述马铃薯早疫病病斑特征。尝试两种模式识别方式对马铃薯早疫病图像进行识别分类,其中Bayes线性判别模型对验证集叶片病害样本的平均识别率可达到99.17%,BP神经网络模型对马铃薯早疫病判别准确率均达到100%。完成了对马铃薯早疫病智能识别系统的搭建并部署到服务器,实现了基于计算机图像处理技术的马铃薯早疫病的网络诊断系统。2.建立基于近红外光谱技术的马铃薯早疫病光谱诊断模型通过对比多种预处理方式,发现SG卷积平滑滤波法对马铃薯早疫病近红外光谱的降噪效果较好,不仅速度快而且保证有效信息的保留。运用逐步判别分析,在红外光谱的50个波段中提取了8个特征频段进行早疫病的识别建模。利用典型判别的模式算法得到的马铃薯早疫病识别模型,识别的准确率达到96%。考虑到光谱的反射率的结果不符合直接运用于神经网络算法的条件,因此,另外通过主成分分析和BP神经网络的算法构建出了马铃薯早疫病病害分析的新模式,大大提高了模拟运算的效率与准确性,通过该模型对马铃薯早疫病进行识别,可以获得100%识别度和89%的准确性,为利用手持设备或无人机实现对马铃薯早疫病检测提供高效算法。3.确定了基于傅立叶光谱的马铃薯早疫病早期检测技术通过对早疫病傅立叶光谱的研究,发现染病叶片和健康马铃薯叶片的谱图在1250cm-1、1500cm-1和1760cm-1之间的峰面值有明显差异。利用这些敏感波段进行聚类分析,实现了利用傅立叶变换的红外技术对马铃薯早疫病的早期检测诊断。
{URL}: https://link.cnki.net/doi/10.27122/d.cnki.ghlnu.2022.000293
{DOI}: 10.27122/d.cnki.ghlnu.2022.000293
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的垃圾检测与分类系统研究与实现
{Author}: 姚林涛
{Tertiary Author}: 耿志卿;李贵柯
{Publisher}: 河北工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 垃圾分类系统;幽灵网络;轻量化;坐标注意力机制;焦点损失函数
{Abstract}: 日益繁荣的工农商业创造出大量的物质资源,极大地丰富了人们的物质生活。然而产出的垃圾问题也变得愈加严峻,更使得垃圾分类的普及迫在眉睫。随着科技的进步,利用人工智能技术帮助人们处理各种工作已经成为大势所趋。其中,计算机视觉技术可以帮助人们完成垃圾分类。对于移植和使用深度学习算法而言,模型体积是一个极其重要的指标。为此本文基于YOLOv4目标检测算法提出一种轻量化的垃圾检测与分类网络(Garbage Net,GBGNet),降低了对于设备平台存储量、功耗及计算能力的要求,并设计出一个部署在计算机端的垃圾检测与分类系统和一个部署在资源有限的移动端的垃圾分类系统。具体工作如下:(1)研究各种轻量化主干特征提取网络,通过实验对比最终确定采用轻量级的幽灵网络(Ghost Net)作为特征提取网络,设计出Ghost Net-YOLOv4目标检测网络,采用迁移学习的训练方式以确保网络的特征提取能力。(2)建立了Garbage Photo(GBGPhoto)垃圾检测与分类数据集。通过网络爬虫等方式获得垃圾数据集并进行筛选,按国家现行垃圾分类标准分成四类,利用数据增广对扩充数据集进一步扩充,使用Label Img对其进行标注,建立了GBGPhoto垃圾检测与分类数据集。(3)构建出一种用于垃圾检测与分类的GBGNet深度神经网络模型。通过设计的GM-CBL(Ghost Module-CBL)轻量化卷积块,同时借鉴Ghost Net结构与深度可分离卷积思想,将特征融合网络模型体积压缩到原有的1/3。利用坐标注意力机制提升网络检测精度,采用焦点损失函数缓解参数不平衡问题,最终得到用于垃圾检测与分类的GBGNet网络模型。(4)设计并完成垃圾检测与分类系统,该系统可以调用摄像头拍摄垃圾,并实时显示其位置信息、垃圾名称、垃圾分类,可将信息传递给后续分拣装置完成垃圾分拣。(5)设计并完成一个移动端的智能垃圾分类系统,并将系统成功部署在移动端。系统通过拍照、录像、读取相册的方式对图片中的垃圾进行检测与分类,为用户提供了一种快速识别垃圾种类的工具。
{URL}: https://link.cnki.net/doi/10.27104/d.cnki.ghbjy.2022.000589
{DOI}: 10.27104/d.cnki.ghbjy.2022.000589
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的目标检测网络剪枝及FPGA部署
{Author}: 程强
{Tertiary Author}: 白勇
{Publisher}: 海南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;网络剪枝;YOLOX;FPGA
{Abstract}: 人工智能的发展正促进计算机视觉的智能化广泛应用。本文针对计算机视觉中目标检测技术的落地部署需求,开展了基于深度学习的目标检测网络的剪枝优化和FPGA部署研究。本文使用三种剪枝方法对目标检测网络进行剪枝,在保持较高精度的同时减少目标检测网络的参数量和计算量,达到目标检测网络在部署平台加速的目的。本文的主要研究内容概述如下:
1.针对部署平台Ultra96-V2 FPGA开发板,将待部署的目标检测网络YOLOX-S中开发板不支持的算子进行替换,设计多种备选方案,重新训练网络并测试精度。替换stem层、SPP层后网络的精度分别增加0.35、1.63个百分点,替换激活函数后精度下降3.31个百分点。相比原模型,模型精度最终只下降1.33个百分点,适合用于部署。
2.分别使用L1范数剪枝方法、几何中位数剪枝方法、网络瘦身剪枝方法对修改后的YOLOX-S模型进行剪枝。对比相同剪枝比例下模型的精度、模型参数量、模型浮点运算次数等指标,结果表明网络瘦身剪枝方法在同剪枝比例下精度最高,参数压缩量最大,以0.5比例剪枝的模型精度比原模型还高0.44个百分点。另外,结合L1范数剪枝方法、几何中位数剪枝方法对网络瘦身剪枝后的模型再剪枝。结果表明压缩的参数量基本一致的情况下,结合使用两种剪枝方法比使用单一的剪枝方法剪枝的精度更高。
3.将各个剪枝后的模型部署到Ultra96-V2 FPGA开发板上,并对比各个剪枝模型在Ultra96-V2开发板中的实际检测效果。结果表明使用网络瘦身剪枝方法以0.5比例剪枝检测效果最好。通过比较各个剪枝模型检测图片所需的时间,结果表明剪枝对加速模型的推理有明显作用,模型推理时间减少18.4%到26.6%不等。
综上所述,本论文针对部署FPGA的平台对YOLOX进行了网络改造,并采用不同的剪枝方法对部署模型进行推理加速,并且提出和验证两种混合剪枝方法,相比使用单一的剪枝方法的达到了更高的检测精度。
{URL}: https://link.cnki.net/doi/10.27073/d.cnki.ghadu.2022.001026
{DOI}: 10.27073/d.cnki.ghadu.2022.001026
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的织物疵点实时检测研究
{Author}: 闫本超
{Tertiary Author}: 潘如如;王宗伟
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 织物疵点检测;机器视觉;图像显著性;实时系统;多线程处理
{Abstract}: 纺织品检测是纺织企业在质量控制的核心环节,其直接影响产品质量好坏与企业的经济效益。长期以来依靠人工的检验方式存在检测存在精度差、效率低、易疲劳等问题,为克服人工检测存在诸多弊端,实时化、自动化与智能化的检测系统是未来发展的必然趋势。现如今的实时检测设备主要从国外引进,采购与维修成本较高,同时对我国纺织品的适用性较差,因此国内非常有必要自行开发研究织物疵点实时检测系统。本文针对上述问题,从企业实际运用出发,利用机器视觉与图像处理技术,设计一款织物疵点实时检测系统。完成硬件平台搭建与软件操作、疵点检测算法、检测实时集成等功能一体的织物自动实时检测系统,实现织物疵点的实时化、自动化与智能化检测。本文具体研究工作如下:(1)从织物疵点实时检测生产的实际需求出发,首先搭建一种适合织物疵点实时检测的硬件平台系统。依据实时检测系统需求,挑选合适的硬件组件,并对硬件进行构架搭建,主要包括相机、光源、镜头、平面镜与光电传感器等组件。为采集良好的织物图像,根据所选组件设计织物图像采集区域,采集区域提供不同打光方式,满足不同厚度织物的拍摄需求,多台相机并排设计满足大部分织物检测幅宽要求。为方便人机交互操作,设计了静态检测与实时检测软件界面。(2)对织物图像实时检测算法进行研究,提出一种改进ITTI显著模型的织物疵点快速检测出算法。首先对采集的织物图像进行预处理,利用高斯平滑方法消除图像噪声。然后通过降采样方法提取织物图像金字塔,对得到的每层金字塔图像通过中央周边差操作来提取亮度特征、Gabor滤波操作来提取图像方向特征。最后通过特征融合得出疵点显著图,利用自适应阈值分割疵点图像,结果表明该方法能有效检出坯布油污、断经、破洞等疵点,检出效果较好。(3)对机器视觉实时检测系统进行集成与调试。依据系统功能来设计不同功能模块,以确保检测系统运行的合理性。对系统采集的图像进行分割分块处理,利用本文所述疵点检测算法对小块进行检测,通过比较不同数量图像块同时检测的时间优化效果,验证了多线程图像分块并行检测方法能够提升织物检测的实时检测速度;集成操作软件与系统硬件,调试并实现了机器视觉下织物疵点实时检测;针对织物疵点实时检测研究,本文提出的机器视觉下的织物疵点实时检测系统,在完成硬件搭建与软件操作任务下,通过嵌入快速织物疵点识别算法,完成织物疵点实时性检测,具有较高的检测效果以及实时检测程度,满足企业生产检测的实际需求。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.002154
{DOI}: 10.27169/d.cnki.gwqgu.2022.002154
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的盘铣刀磨损状态检测方法研究
{Author}: 柳国栋
{Tertiary Author}: 吴松林;刘建鑫
{Publisher}: 西京学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 盘铣刀片;机器视觉;特征提取;失效检测;图像处理
{Abstract}: 机械加工中,刀具有着非常重要的地位,直接影响到产品的加工质量、企业生产效率及成本。在数控铣加工过程中,组合刀片式的盘铣刀使用广泛,较传统的一体式刀具,其成本低且便捷,是目前应用的主流刀具。实际生产中,刀片定时更换,使用量较大,很多更换后的刀片仍然可以继续使用。目前,主要依据技术人员的经验对刀片磨损情况进行判断,无法形成定量的结果。导致很多刀具没有达到应有的使用寿命就已经被淘汰,造成大量的浪费。将机器视觉技术应用于刀片磨损状态检测可以有效解决刀具检测效率低、精度差、检测标准不统一和检测成本高等问题。本文以盘铣刀片为研究对象,采用机器视觉的方法实现了刀片磨损程度的自动化检测,具体内容如下:首先,详细分析了刀具的磨损失效原因及其主要表现形式,结合企业生产实际并根据刀具的磨损特点制定了相应的检测标准。其次,对刀具检测的硬件系统进行了选型设计,包括摄像头、组合光源及实验台架。摄像头采用张正友标定法进行了标定实验。通过光源的对比分析以及各种光源的组合实验确定了合适的组合光源系统,并设计了实验台架。对采集到的刀片图像进行了一系列的图像预处理实验,包括伽马变换的灰度处理、高斯滤波降噪、OTSU阈值法的图像分割,并利用了图形形态学处理以及用最小外接矩形法对检测部位框定等,最终实现了刀片磨损区域的界定。通过图像像素尺寸的标定,对铣刀片磨损面积进行了统计分析,对铣刀片磨损部位进行连通域的标定和去除,并利用Canny算子对磨损边缘进行提取,再进行内部填充,计算出了磨损面积和最大磨损宽度。利用MATLAB GUI进行了检测软件的设计,实现了检测结果的输出。最后,采用19JPC万能工具显微镜对铣刀片的检测结果和机器视觉检测结果进行了对比实验分析,验证了基于机器视觉的铣刀磨损状态检测方法的有效性和准确性。
{URL}: https://link.cnki.net/doi/10.27831/d.cnki.gxjxy.2022.000061
{DOI}: 10.27831/d.cnki.gxjxy.2022.000061
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于多角度面部特征的文献阅读专注度研究
{Author}: 刘洋;朱学芳
{Author Address}: 南京大学信息管理学院;
{Journal}: 数据分析与知识发现
{Year}: 2023
{Volume}: 7
{Issue}: 09
{Pages}: 100-113
{Keywords}: 文献阅读;专注度评价;多角度面部特征;计算机视觉;模糊综合评价
{Abstract}: 【目的】文献阅读专注度目前大多采用人工方式或眼动跟踪方法进行评价，为实现专注度评价过程的自动化检测和实时反馈，本文将计算机视觉技术和专注度评价研究相结合，对智能技术在智慧知识服务中的应用研究也有意义。【方法】通过阅读者头部垂直方向和水平方向转动角度检测头部姿态；通过眼部以及嘴部的闭合度检测阅读者闭眼或打哈欠状态进而对疲劳度进行评分；并且依据阅读者的表情识别结果对情绪进行评分，之后应用模糊综合评价算法对相关因素进行权重确定和评分整合，获得阅读者在文献阅读过程中不同时刻的专注度状态。【结果】将该文献阅读专注度模型应用于实际阅读场景以评价头部倾斜、疲劳和消极情绪状态文献阅读专注度，获得的效果分别比正常状态低26.3%、25.2%和6.8%。【局限】当文献阅读视频出现面部特征模糊时，视觉识别技术检测精度不足，同时存在部分极端阅读实例有待优化。【结论】本文模型可以应用于多领域的下游任务中，既可以辅助阅读者及时调整文献阅读策略以提高阅读效率，也可以辅助图书馆等部门制定图书采购策略，进而减少图书资源浪费。
{ISBN/ISSN}: 2096-3467
{Notes}: 10-1478/G2
{URL}: https://link.cnki.net/urlid/10.1478.G2.20221125.1905.016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器视觉下的雾天车行环境感知研究综述
{Author}: 吕栋腾;杨育良
{Author Address}: 陕西国防工业职业技术学院;四川大学;
{Journal}: 自动化与仪器仪表
{Year}: 2022
{Volume}: 
{Issue}: 11
{Pages}: 1-6
{Keywords}: 车行环境感知;图像去雾;语义分割;深度估计
{Abstract}: 近年来自动驾驶及其相关技术的发展已经引起全社会的广泛关注。自动驾驶系统的核心技术包含环境感知、智能决策以及智能控制，其中环境感知又是整个系统的前端和基础。系统地梳理了基于机器视觉的雾天车行环境感知的研究进展和现状，对雾天车行环境感知算法中图像去雾、语义分割、深度估计三个方面的研究进行了总结，并对基于机器视觉的雾天车行环境感知系统的研究方向进行了展望，期望对相关研究者有所借鉴。
{ISBN/ISSN}: 1001-9227
{Notes}: 50-1066/TP
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.1001-9227.2022.11.001
{DOI}: 10.14016/j.cnki.1001-9227.2022.11.001
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的汽车精密零件表面缺陷自动检测方法
{Author}: 徐立青
{Author Address}: 陕西铁路工程职业技术学院;
{Journal}: 自动化与仪器仪表
{Year}: 2022
{Volume}: 
{Issue}: 11
{Pages}: 36-39+45
{Keywords}: 机器视觉;汽车精密零件;缺陷;自动检测;纹理;有限元
{Abstract}: 汽车精密零件表面缺陷会导致零件故障，为了提高缺陷检测能力，提出基于机器视觉的汽车精密零件表面缺陷自动检测方法。构建汽车精密零件表面缺陷的机器视觉图像采集模型，采用单背景约束下的表面光泽点提取的方法，分析汽车精密零件表面的结构纹理特征值，在视觉传感下通过对汽车精密零件的形变、相变参数分析，分析汽车精密零件的机械性能和服役性能，在切削载荷作用下，通过疲劳裂纹的视觉特征重构，在机器视觉下采用表面残余应力及变质层的动态特征分析，通过缺陷特征检测和有限元仿真分析，实现对汽车精密零件表面缺陷自动检测。测试结果表明，采用该方法进行汽车精密零件表面缺陷检测的纹理匹配度较高，检测性能较好，对零件表面的断屑、化学磨损等各类缺陷检测的可靠性较高。
{ISBN/ISSN}: 1001-9227
{Notes}: 50-1066/TP
{URL}: https://link.cnki.net/doi/10.14016/j.cnki.1001-9227.2022.11.036
{DOI}: 10.14016/j.cnki.1001-9227.2022.11.036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 自动驾驶汽车障碍物检测技术综述
{Author}: 杨晨曦;李军
{Author Address}: 重庆交通大学机电与车辆工程学院;
{Journal}: 传感器世界
{Year}: 2022
{Volume}: 28
{Issue}: 11
{Pages}: 1-6
{Keywords}: 障碍物检测;机器视觉;自动驾驶汽车;多信息融合
{Abstract}: 如何可靠地感知环境和辨别障碍物是自动驾驶汽车最重要的能力之一。其中，障碍物检测是文献中讨论最广泛的课题之一。在任何车辆运动中，都需要非常仔细地对障碍物进行检测，如果检测是可靠的，那么就能确定它的优化方案，以确保行车安全。文章介绍了自动驾驶汽车障碍物检测方法所需各类不同类型传感器的特点，重点阐述了基于电磁波信息、图像信息、多信息融合的障碍检测技术，其中许多方法已经提出了不同的应用领域和场景，为智能车研发提供一定的参考和借鉴。
{ISBN/ISSN}: 1006-883X
{Notes}: 11-3736/TP
{URL}: https://link.cnki.net/doi/10.16204/j.cnki.sw.2022.11.005
{DOI}: 10.16204/j.cnki.sw.2022.11.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 机器学习中成员推理攻击和防御研究综述
{Author}: 牛俊;马骁骥;陈颖;张歌;何志鹏;侯哲贤;朱笑岩;伍高飞;陈恺;张玉清
{Author Address}: 西安电子科技大学计算机科学与技术学院;国家计算机网络入侵防范中心中国科学院大学;海南大学网络空间安全学院;西安电子科技大学广州研究院;西安邮电大学网络空间安全学院;西安电子科技大学网络与信息安全学院;西安电子科技大学通信工程学院;中国科学院信息工程研究所信息安全国家重点实验室;中国科学院大学网络空间安全学院;
{Journal}: 信息安全学报
{Year}: 2022
{Volume}: 7
{Issue}: 06
{Pages}: 1-30
{Keywords}: 机器学习;成员推理攻击;隐私安全;防御措施
{Abstract}: 机器学习被广泛应用于各个领域,已成为推动各行业革命的强大动力,极大促进了人工智能的繁荣与发展。同时,机器学习模型的训练和预测均需要大量数据,而这些数据可能包含隐私信息,导致其隐私安全面临严峻挑战。成员推理攻击主要通过推测一个数据样本是否被用于训练目标模型来破坏数据隐私,其不仅可以破坏多种机器学习模型(如,分类模型和生成模型)的数据隐私,而且其隐私泄露也渗透到图像分类、语音识别、自然语言处理、计算机视觉等领域,这对机器学习的长远发展产生了极大的安全威胁。因此,为了提高机器学习模型对成员推理攻击的安全性,本文从机器学习隐私安全攻防角度,全面系统性分析和总结了成员推理攻击和防御的基本原理和特点。首先,介绍了成员推理攻击的定义、威胁模型,并从攻击原理、攻击场景、背景知识、攻击的目标模型、攻击领域、攻击数据集大小六个方面对成员推理攻击进行分类,比较不同攻击的优缺点;然后,从目标模型的训练数据、模型类型以及模型的过拟合程度三个角度分析成员推理攻击存在原因,并从差分隐私、正则化、数据增强、模型堆叠、早停、信任分数掩蔽和知识蒸馏七个层面对比分析不同防御措施;接着,归纳总结了成员推理攻击和防御常用的评估指标和数据集,以及其在其他方面的应用。最后,通过对比分析已有成员推理攻击和防御的优缺点,对其面临的挑战和未来研究方向进行了展望。
{ISBN/ISSN}: 2096-1146
{Notes}: 10-1380/TN
{URL}: https://link.cnki.net/doi/10.19363/J.cnki.cn10-1380/tn.2022.11.01
{DOI}: 10.19363/J.cnki.cn10-1380/tn.2022.11.01
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 判别式视觉跟踪算法中深度特征表示与模型更新策略研究
{Author}: 马素刚
{Tertiary Author}: 段里仁
{Publisher}: 长安大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉目标跟踪;相关滤波;博弈特征融合;全卷积孪生网络;轻量级空间注意力;模型更新策略
{Abstract}: 视觉目标跟踪作为计算机视觉领域的重点研究方向,在视频监控、人机交互、智能交通、智能诊断、海洋探索、战场侦察等实际场景下得到了广泛应用。视觉跟踪的基本任务是,在给定视频的第一帧图像中,通过手工方式或者检测算法标注出目标的位置和大小,然后利用视觉跟踪算法预测目标在该视频后续每一帧中的位置和大小。视觉跟踪算法虽然经过了多年的发展,但仍然存在一些需要深入研究的问题:(1)目标表征能力弱。面对复杂多样的目标,需要选择合适的特征表示方法,才能对目标外观进行准确建模。一方面,针对不同的目标,往往具有不同的特点,应该选择不同的特征表示;另一方面,针对同一目标,如果在运动过程中外观不停地发生变化,也需要对其特征表示方法进行自适应调整。现有多数跟踪算法采用单一特征或者多个特征的简单融合,导致生成的目标特征对目标的表征能力较弱。(2)模型更新策略简单。视频中的目标外观一直处于变化中,甚至出现有些目标在相邻帧之间差异非常大的情形。为了适应这种变化,需要对跟踪算法观测模型进行更新。如果对模型每帧进行更新,不仅增加计算负担,当出现目标遮挡等情形时还会对模型造成污染,导致模型退化;如果长时间对模型不予更新,跟踪算法将无法适应目标外观的快速变化。现有的多数跟踪算法采用“不更新”或者“每帧更新”策略,不能满足鲁棒跟踪的需要。本文从目标深度特征表示和模型更新策略两方面对判别式视觉跟踪进行深入研究,主要工作总结如下:(1)提出了一种深度特征通道选择的方法,解决相关滤波框架下目标特征表示能力弱的问题。依据目标显著性区域与搜索区域的平均特征能量比对多通道特征进行裁剪,去除无效通道和干扰通道,同时提高了算法的跟踪准确度和跟踪速度。引入深层网络Res Net提取目标特征并进行特征融合,能够解决目标手工特征表达能力弱问题。利用深层网络Dense Net的特定层提取目标特征,发挥了更深层神经网络优点。利用通道选择对深度特征中存在的无效通道进行裁剪,提高了目标特征通道有效性,进一步增强了目标特征的表达能力。(2)提出了一种多特征博弈融合和高置信度模型更新的方法,解决相关滤波框架下目标多特征融合效果差和模型无法适时更新问题。利用多专家系统构造多个特征组合,并从中筛选出两个最重要的特征组合,再利用博弈论思想,对这两个特征组合进行博弈融合,能够提高多特征融合效果,得到鲁棒的融合特征;依据新提出的跟踪质量评估指标,设计了一种有效的模型适时更新策略。多互补特征博弈融合解决了手工特征或深度特征造成的特征单一问题,而利用专家系统构造多个特征组合并进行筛选,能够充分发挥HOG特征、CN特征和深度特征的优势,进一步提升了多特征融合效果,增强了融合特征的表达能力。(3)提出了一种轻量级空间注意力机制和连通域模板更新的方法,解决孪生网络(Siam FC)框架下主干网络目标表征能力弱和目标模板无法更新问题。在Siam FC基础上,将特征提取主干网络Alex Net替换为更深层次的VGG-19网络,并在模板分支主干网络后串接新设计的轻量级空间注意力模块LSAM,同时利用连通域模板更新策略,增强了主干网络特征提取能力的同时,实现了目标模板的选择性更新。将非局部注意力和通道注意力,以及全局上下文注意力和坐标注意力分别串联到主干网络尾部,能够实现模型对目标区域的重点关注,并提高模型对目标外观显著变化的适应性。使用双模板策略,解决了目标模板无法更新的问题。使用轻量级空间注意力模块LSAM和连通域模板更新策略,更好地解决了主干网络目标表征能力弱和目标模板无法更新问题。本文针对特征表示和模型更新两方面存在的问题,对判别式视觉跟踪算法展开研究,提高了跟踪算法性能。多个基准数据集上的实验结果表明,所提方法较好地解决了视频序列中存在的尺度变化、光照变化、目标遮挡、目标形变、背景干扰、低分辨率等具有挑战性的问题,实现了跟踪算法在复杂环境下的持续稳定跟踪,进一步促进了视觉跟踪算法在实际场景中的应用。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2022.000036
{DOI}: 10.26976/d.cnki.gchau.2022.000036
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的铝合金轮毂尺寸测量
{Author}: 杜丽峰;周正;王天琪
{Author Address}: 天津市天锻压力机有限公司;天津工业大学机械工程学院;
{Journal}: 机械设计
{Year}: 2022
{Volume}: 39
{Issue}: S2
{Pages}: 193-198
{Keywords}: 机器视觉;二维标定;图像处理;轮廓提取;曲线拟合
{Abstract}: 针对铝合金轮毂工件的尺寸测量问题开展研究，在MATLAB环境下编制了测量软件程序。首先，采用基于Harris算子的标定方法来对相机进行标定；然后，采用直方图均衡化法处理轮毂正面图像，进一步的轮毂图像经过自动阈值分割，Canny边缘检测，开运算形态处理等步骤得到轮毂轮廓图像；最后，采用Hough算法完成对轮廓的拟合，并进行了外轮廓直径的测量。
{ISBN/ISSN}: 1001-2354
{Notes}: 12-1120/TH
{URL}: https://link.cnki.net/doi/10.13841/j.cnki.jxsj.2022.s2.033
{DOI}: 10.13841/j.cnki.jxsj.2022.s2.033
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于Transformer的医学图像分类研究
{Author}: 刘金伟
{Tertiary Author}: 曹桂涛
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 医学图像分类;Transformer;小样本学习;特征金字塔;原型网络
{Abstract}: 随着医疗水平的日益提高,医学图像在越来越多的疾病诊治中承担着重要的辅助作用。虽然医学图像能够辅助医务人员进行更准确地诊治,但是,医学图像在应用中需要大量标注,大大增加了医务人员的负担。因此,利用计算机视觉的方法进行医学图像分析的相关研究越来越得到关注。目前主流的基于卷积神经网络的医学图像分类模型存在着分类准确度不高和泛化性不足的问题,难以找到一个适合不同的医学图像分类任务的模型。同时,由于医学图像采集困难以及人工标注成本高昂等问题,有标签的医学图像数据样本是非常少的,普通的深度学习模型不能够实现准确的分类。为了应对医学图像分类任务中的挑战,本文提出了两个基于Transformer的医学图像分类模型。通过设计合适的医学图像分类网络结构,提出的两个模型结合了Transformer强大的建模能力和注意力机制的优势,在特征学习和分类预测上都表现出了优异的效果,适应了不同场景下的医学图像分类任务。针对基于卷积神经网络的模型在医学图像分类任务上表现不佳的问题,提出了一个特征金字塔Transformer模型。利用多尺度特征丰富图像的特征信息,并结合Transformer的长程建模能力是特征金字塔Transformer模型的主体思想。Transformer结构的应用弥补了卷积神经网络由于卷积运算局部性造成的特征学习的不足。通过对比实验和消融实验证明了特征金字塔Transformer模型在医学图像分类十项全能任务上具有更高的分类准确性和泛化性。针对有标签医学图像数据获取困难的问题,提出了一个基于Transformer的小样本医学图像分类模型。利用原型网络和Transformer的思想,模型生成了与任务相关的切片原型,接着通过混合度量的方式度量查询样本切片原型和支撑集切片原型的距离,并基于距离对查询样本类别进行预测。Transformer的注意力思想以及混合度量的应用增强了模型的特征学习和原型匹配的能力。为了验证模型的分类效果,在医学图像分类十项全能任务和一个身体部位X光图像数据集上构建了两个小样本学习的数据集并进行了实验。将提出的模型和一些常用的小样本图像分类模型进行了对比,基于Transformer的小样本医学图像分类模型的分类准确度能够达到最高。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000141
{DOI}: 10.27149/d.cnki.ghdsu.2023.000141
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: Android平台下基于OpenCV的人脸检测系统的实现
{Author}: 杜丹
{Author Address}: 马鞍山师范高等专科学校软件工程系;
{Journal}: 电脑知识与技术
{Year}: 2022
{Volume}: 18
{Issue}: 30
{Pages}: 11-13+22
{Keywords}: 人脸检测;Android;OpenCV
{Abstract}: 人脸检测是指把人脸从一幅静止的图像或者动态视频中检测出来，并且指出人脸在图像或视频中的大小和位置。基于移动端的人脸检测技术操作方便、安全有效，受到了越来越多用户的青睐，人脸检测的方法成为各个计算机视觉技术人员的研究热点。基于此背景，在Android平台下，提出一种基于OpenCV的人脸检测系统，采用训练好的LBP(Local Binary Pattern)与HAAR（特征级联分类）生成人脸分类器，对预处理好的人脸图像，利用OpenCV中的detectMultiScale方法来实现人脸检测，可以对手机端的人脸正面图片进行识别，从测试结果表明，该方法对人脸正面状态下的识别率高，可适用于各个应用场景。
{ISBN/ISSN}: 1009-3044
{Notes}: 34-1205/TP
{URL}: https://link.cnki.net/doi/10.14004/j.cnki.ckt.2022.1953
{DOI}: 10.14004/j.cnki.ckt.2022.1953
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的畜禽体质量评估研究进展
{Author}: 谢秋菊;周红;包军;李庆达
{Author Address}: 东北农业大学电气与信息学院;农业农村部生猪养殖设施工程重点实验室;黑龙江八一农垦大学工程学院;东北农业大学动物科学技术学院;教育部北方寒区猪智能化繁育与养殖工程研究中心;
{Journal}: 农业机械学报
{Year}: 2022
{Volume}: 53
{Issue}: 10
{Pages}: 1-15
{Keywords}: 畜禽;机器视觉;体尺;体质量评估;机器学习;深度学习
{Abstract}: 体质量(体重)是反映畜禽身体健康与生长状况、繁殖与生产性能的重要指标。对畜禽体质量精准快速地评估和监测是提升养殖生产管理水平、实现精准畜牧生产的重要手段。传统的直接称量方式耗时费力，易造成动物的应激反应。基于机器视觉技术的体质量评估，能够利用视觉检测技术获取体型特征建立其与体质量之间的智能评估模型，是目前畜禽养殖智能化技术研究的热点。首先对体质量的评估方法进行分类阐述；然后，详细分析了机器视觉体尺图像获取的传感器类型、畜禽体尺提取与处理方法及应用现状；重点开展基于机器学习方法的体尺、体征与体质量评估模型相关研究的分析，对比了各类机器学习算法在体质量评估方面的应用效果和最新研究成果，特别探讨和分析了深度学习算法在全自动畜禽体质量评估领域的发展潜力；最后，指出畜禽体质量评估研究面临的问题和未来研究的发展趋势。
{ISBN/ISSN}: 1000-1298
{Notes}: 11-1964/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw-BJPiFeLM0l9NvfVCdlquzO2q-dWK8AWIF_FsFGfls_hMv1MaQ-uLdhLJxyjJnhlCiz9LPId6f5nWShVrgv9zFbRGdxllelR9Y4p9ZpTTZmZnxJPjQsaeBJrFwyaWKW1FS0JJEwE9EPR1oN7MbVZni8IexzWB1YcekUnbDnjJpNXLvecSqx3tvn09guKdVk8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的带钢表面缺陷检测系统中图像处理方法设计研究
{Author}: 许春和
{Author Address}: 绥化学院;
{Journal}: 大众标准化
{Year}: 2022
{Volume}: 
{Issue}: 20
{Pages}: 179-181
{Keywords}: 机器视觉;带钢表面缺陷检测系统;图像处理方法;设计
{Abstract}: 为进一步完善带钢生产流程，增强带钢生产效果，有必要针对带钢生产过程中因各种因素而形成的表面缺陷展开检测，以此来对其进行提前干预与调整，作为表面缺陷检测的关键内容，图像处理得到更多的重视，需以机器视觉为基础设计对应的图像处理方法，实现对各项图像的科学分类，得到其正确的缺陷检测结果。文章就基于机器视觉的带钢表面缺陷检测系统中图像处理方法设计进行了论述与分析。
{ISBN/ISSN}: 1007-1350
{Notes}: 14-1101/T
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzYs6yVjCC9FqgQxTdBwXWkLfBPKsvn_4HaYFX42HKykO-IXrYUllHYDpKYvOPEewOVw61jiphrqotnLsTXIbc3OlnYAt8jL8AFIfFyt_0QHgDHpqAYEwMYyZCH8C3_9dICVsFRQfdnFG5_8gDmHrnu17BYevaBOjAEBrqAbpUBxKrB6o_lrrxJ8HgQT3PKGYA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的车铣刀具磨损检测方法
{Author}: 邓晓鹏;胡小锋
{Author Address}: 上海交通大学机械与动力工程学院;
{Journal}: 组合机床与自动化加工技术
{Year}: 2022
{Volume}: 
{Issue}: 10
{Pages}: 105-108+114
{Keywords}: 车铣刀具;机器视觉;傅里叶变换;区域生长算法;一致性分析
{Abstract}: 针对加工过程中人工检测刀具磨损效率较低、难以获取刀具磨损全局信息等问题，提出一种基于机器视觉的车铣刀具磨损检测方法。首先通过傅里叶变换将刀具图像映射到频域空间，去除刀体条纹对应的频率分量，消除刀具图像中的条纹干扰。通过自适应区域生长算法分割图像背景区域，并以分割结果为模板，实现图像对比度自适应增强与刀体非磨损区域分割。合并两次分割结果，得到磨损区域二值图像，实现刀具磨损量的自动测量。最后，通过磨损数据的一致性分析验证算法的有效性。结果表明：所提方法测量结果与人工测量结果具有较强的一致性；相较于已有的视觉检测算法，该方法抗干扰能力强，可从低质量图像中准确提取刀具磨损信息，从而实现刀具磨损状态的有效检测。
{ISBN/ISSN}: 1001-2265
{Notes}: 21-1132/TG
{URL}: https://link.cnki.net/doi/10.13462/j.cnki.mmtamt.2022.10.023
{DOI}: 10.13462/j.cnki.mmtamt.2022.10.023
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习在苹果产业链中的应用与研究进展
{Author}: 黄昊;谢圣桥;陈度;王恒
{Author Address}: 中国农业大学工学院;中国农业大学现代农业装备优化设计北京市重点实验室;洛阳智能农业装备研究院有限公司;
{Journal}: 中国农业科技导报
{Year}: 2022
{Volume}: 24
{Issue}: 10
{Pages}: 79-89
{Keywords}: 深度学习;苹果;机器视觉;卷积神经网络
{Abstract}: 我国是苹果生产大国，苹果种植面积广、品种多。将深度学习与机器视觉技术相结合并运用于苹果种植和生产的全产业链中是苹果产业技术升级的重要手段和方向。聚焦苹果产业链中的果树种植、收获采摘和产后检测3个关键阶段，系统性梳理深度学习技术的相关应用与研究进展，其中主要涉及叶部病虫害识别、种植监测、采摘机器人的目标识别和苹果无损分级检测等研究领域，在分析对比不同技术之间的差异与共性的基础上，探讨深度学习在苹果产业链中所面临的困难与挑战。
{ISBN/ISSN}: 1008-0864
{Notes}: 11-3900/S
{URL}: https://link.cnki.net/doi/10.13304/j.nykjdb.2021.0688
{DOI}: 10.13304/j.nykjdb.2021.0688
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能抓取系统的设计
{Author}: 万松峰;吴靖明
{Author Address}: 东莞职业技术学院智能制造学院;
{Journal}: 机械管理开发
{Year}: 2022
{Volume}: 37
{Issue}: 10
{Pages}: 228-229
{Keywords}: 机器视觉;工业机器人;识别;抓取
{Abstract}: 3C产品组装是3C产品生产制造中的最后一环,将流水线上的3C外壳件进行高速、准确抓取对提升3C产品组装的生产效率具有十分重要的意义。基于此,以流水线生产时3C产品外壳件的组装为研究对象,搭建“机器视觉+工业机器人”的智能抓取系统并进行实际应用。结果表明,该系统实现了对手机外壳的精准识别和抓取。
{ISBN/ISSN}: 1003-773X
{Notes}: 14-1134/TH
{URL}: https://link.cnki.net/doi/10.16525/j.cnki.cn14-1134/th.2022.10.097
{DOI}: 10.16525/j.cnki.cn14-1134/th.2022.10.097
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的医学图像分割算法研究
{Author}: 金群超
{Tertiary Author}: 李智
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 息肉分割;视网膜血管分割;注意力机制;多尺度设计;反馈机制
{Abstract}: 在临床诊疗的过程中,精准地分割出医学图像中的器官或是病灶可以大幅提升医生的工作效率。随着人工智能技术的发展,基于深度学习的图像分割技术已被广泛应用在各行各业,包括医学影像领域。然而,在医学图像分割中仍然存在着一些挑战性问题,如待分割目标的尺度变化大、待分割区域与其周边区域的对比度低、存在着大量困难样本和形状复杂样本等。本文以结肠镜息肉分割和视网膜血管分割为例,针对上述问题展开研究,并给出如下基本思路。首先,充分挖掘不同分割任务中医学图像的自有特性并设计相应的方法,以提高模型的分割能力。再者,使用先进的特征提取器,用以提取更加鲁棒和强大的表征信息。此外,利用注意力机制和多尺度设计的特性,帮助深度网络关注复杂且尺度多变的待分割区域。本文的工作主要分为以下几点:(1)提出了一种基于边缘监督和反馈注意力机制的息肉图像分割网络(FEG-Net)。该网络结合反馈机制和注意力机制,提升了模型在复杂样本上的识别能力。此外,设计了低代价的边缘提取器,通过网络的浅层监督,以获取更为清晰的息肉边缘。(2)提出了一种基于RGB自适应选择和Swin Transformer的视网膜血管分割网络(Swin-ASNet)。根据眼底图特性,提出了基于多尺度思想和注意力机制的自适应选择融合模块,有效利用了不同通道的信息。同时,设计了高低交互模块,将高层次语义信息注入到低层次细节信息中,进一步获取精准的分割结果。(3)设计并实现了一个基于Flask框架的医学图像分割系统,该系统可以对医生所上传的医学图像进行分割并进行可视化展示,以辅助医生的诊断,实现了深度学习算法的工程化落地。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2023.000311
{DOI}: 10.27149/d.cnki.ghdsu.2023.000311
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于U型Swin Transformer自编码器的色织物缺陷检测
{Author}: 黄媛媛;熊文博;张宏伟;张伟伟
{Author Address}: 西安工程大学电子信息学院;浙江大学工业控制技术国家重点实验室;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 12
{Pages}: 303-310
{Keywords}: 机器视觉;图像处理;色织物;缺陷检测;无监督学习;Swin Transformer
{Abstract}: 针对传统卷积神经网络对色织物花型缺陷检测效果不佳的问题，提出一种基于U型Swin Transformer重构模型和残差分析的缺陷检测方法。该方法使用Transformer模型，可更好地实现对图像全局特征的提取以及更准确的重构，同时解决了实际生产过程中缺陷样本数量少且种类不平衡的问题。首先，针对某种花型，采用叠加噪声后的无缺陷样本完成重构模型的训练过程；然后，将待测图像输入模型中获得重构图像；接着，计算待测图像和重构图像的残差图像；最后，通过阈值分割和数学形态学处理，即可实现对缺陷区域的检测和定位。实验结果表明，该方法在不需要对缺陷样本标记的情况下，能够有效地检测和定位多个色织物花型上的缺陷区域。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.tn.20220927.1957.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的目标识别分类方法
{Author}: 罗华;郭静;杨娜;李瑞峰;郭超
{Author Address}: 西北工业大学;西安航天时代精密机电有限公司;
{Journal}: 航空计算技术
{Year}: 2022
{Volume}: 52
{Issue}: 05
{Pages}: 28-32
{Keywords}: 机器视觉;目标识别;自动分类;视觉引导;OCR
{Abstract}: 工业现场生产的产品批量小、更新快、品种多，存在工作效率低、检测或识别质量得不到保证等问题。为了解决此问题，提出了一种基于机器视觉的目标识别分类方法。采用线阵相机，通过控制产品运动，获取产品表面完整的信息图像，利用多层感知器对图像拼接和处理后的字符进行识别，确定产品型号及批次，引导机器人完成产品的准确分类。实验结果表明，方法识别时间18 ms,识别准确率98%,可有效解决人工作业的各种问题。
{ISBN/ISSN}: 1671-654X
{Notes}: 61-1276/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzx6rLl--43l8_1MReAoN2i5m19GdigsnIne41qmqwLw3t09VGYGqp1u85QBTv-T11QaQfQ8Stpj5Jcw0Ct2g4_VFIoWktO-_bn2zX_wstFEtsLyBtXOr2dyAyAVMLbOiMbIJWem5e8qzcVAV_kQjea_PoKTInftFsLSeYRd1aavgUfZS5qxqIapRSkXL8RLx8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的机器人目标识别实验教学设计与改革
{Author}: 赵地;杜玉红;丁振宇;谢广明
{Author Address}: 天津工业大学工程教学实习训练中心工程训练国家级实验教学示范中心;北京大学工学院湍流与复杂系统国家重点实验室智能仿生设计实验室;天津工业大学教学质量监控与评估中心;天津工业大学电子与信息工程学院;
{Journal}: 实验技术与管理
{Year}: 2022
{Volume}: 39
{Issue}: 09
{Pages}: 191-196
{Keywords}: 实验教学改革;机器视觉;目标识别与追踪
{Abstract}: 设计了一个自追踪摄像头云台控制机器人实验。文章从人体的检测定位及云台控制方面阐述了系统的设计思路，利用机器视觉技术得到了人体目标在视角中的坐标，又对舵机进行了目标控制。追踪目标的过程最终以Mobile Net-SSD网络模型为基础，通过深度可分离的整合设计，改善了现有整合网络的复杂参数问题，从而优化了网络结构。后期将引导学生从改进本实验模型结构和图像预处理等方面提高最终算法的检测速度、检测准确率、识别准确率等。该实验设计涉及学科较为综合，功能扩展性好，实用性强，是机器人教学、机器学习实践与嵌入式系统相融合的创新实验项目。
{ISBN/ISSN}: 1002-4956
{Notes}: 11-2034/T
{URL}: https://link.cnki.net/doi/10.16791/j.cnki.sjg.2022.09.031
{DOI}: 10.16791/j.cnki.sjg.2022.09.031
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 快速精准识别棚内草莓的改进YOLOv4-Tiny模型
{Author}: 孙俊;陈义德;周鑫;沈继锋;武小红
{Author Address}: 江苏大学电气信息工程学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 18
{Pages}: 195-203
{Keywords}: 机器视觉;图像处理;果实识别;YOLOv4-Tiny;注意力机制;小目标
{Abstract}: 为了实现棚内草莓果实的快速精准识别，该研究提出一种基于改进YOLOv4-Tiny的草莓检测模型。首先，为了大幅度减少模型计算量，采用轻量型网络GhostNet作为特征提取网络，并在GhostBottleneck结构中嵌入卷积注意力模块以加强网络的特征提取能力；其次，在颈部网络中添加空间金字塔池化模块和特征金字塔网络结构，融合多尺度特征提升小目标草莓的检测效果；最后，采用高效交并比损失作为边界框回归损失函数，加速网络收敛并提高模型的检测准确率。结果表明，改进YOLOv4-Tiny模型权重大小仅为4.68 MB，平均每幅图片的检测时间为5.63 ms，在测试集上的平均精度均值达到92.62%，相较于原YOLOv4-Tiny模型提升了5.77个百分点。与主流的目标检测模型SSD、CenterNet、YOLOv3、YOLOv4和YOLOv5s相比，改进YOLOv4-Tiny模型平均精度均值分别高出9.11、4.80、2.26、1.22、1.91个百分点，并且模型权重大小和检测速度方面均具有绝对优势，该研究可为后续果实智能化采摘提供技术支撑。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxeagYkU0OpHZuvG7ySB-gTnK6LLOAMVG15l05qATo-QMi2Zv1O_OdxxU89CfGs6SZeHWGM9e1JthpohXOkhzGuxvhCRs_uVvHjUI30Hbes6HVy-bEQ0_xRLTSXq1tksAmKbxlfA0J_slbG-so558R-M65d2eaRIInQvoZoh2N9BcgZBMkovMLsLjZ6fJ1aptI=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉在观测量化鱼类行为中的研究
{Author}: 曹誉尹
{Author Address}: 重庆交通大学河海学院;
{Journal}: 农业与技术
{Year}: 2022
{Volume}: 42
{Issue}: 17
{Pages}: 121-124
{Keywords}: 计算机视觉;鱼类行为
{Abstract}: 基于物联网、大数据和摄像设备等现代信息技术的可用性和普遍性计算机视觉取得了长足的进步。近年来，其已经成为实现自动鱼类行为监测的强大工具。快速发展的机器学习和人工智能促进了鱼类的种类鉴定、数量估计和行为分析的研究。本文总结了典型鱼类行为、计算机视觉量化鱼类行为的方法及鱼类行为特征参数与应用现状。本综述旨在帮助研究人员了解计算机视觉在鱼类行为分析方法中的发展，促进鱼类生境恢复及水环境生物监测的发展。
{ISBN/ISSN}: 1671-962X
{Notes}: 22-1159/S
{URL}: https://link.cnki.net/doi/10.19754/j.nyyjs.20220915030
{DOI}: 10.19754/j.nyyjs.20220915030
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉系统在工业机器人上的应用
{Author}: 高俊英;高玉光
{Author Address}: 山东华宇工学院;
{Journal}: 软件
{Year}: 2022
{Volume}: 43
{Issue}: 09
{Pages}: 107-109
{Keywords}: 计算机;视觉系统;工业机器人
{Abstract}: 随着我国科学技术的不断发展,我国的工业技术水平得到了快速的提升。近年来,在科学技术的带动下,工业机器人在工业领域开始有广泛的应用,在操作人员的引导下可以更好地完成相应的工作内容。但机器人对外界的感知能力不足,不能根据外界环境变化做出调整,需要导航技术对其进行引导,而计算机视觉系统是应用比较广泛的导航系统。计算机视觉系统在工业机器人上的应用,可以通过相应的系统进行图像采集、分析、计算处理,根据图像处理结果来实现对机器人的导航,让机器人更好的随外界环境变化及时做出调整,让机器人更加灵活,提高机器人的外界适应性,更好地满足工业生产要求。
{ISBN/ISSN}: 1003-6970
{Notes}: 12-1151/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzlOA6pBL4QRhXGmWToWzN7pq7yydJx_0YicaCNcanNprd03J01Wt4masOxYnnyY-dDS2ImEvnlr9IIah68VqAjdoy3s3fHZYcRPuauOj4vv7toCTUjCc5AUP_abryTFcxvIPDokSq_JlKH_KtvZ-Gd63W3-ILqxI0cmChg1PYDXfm_omFZD3W7LP8qY6oOM2Q=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的疲劳驾驶监测算法研究
{Author}: 申海洋;笪诚
{Author Address}: 巢湖学院电子工程学院;
{Journal}: 蚌埠学院学报
{Year}: 2022
{Volume}: 11
{Issue}: 05
{Pages}: 61-66
{Keywords}: 疲劳驾驶;机器视觉;面部识别;图像标准差
{Abstract}: 疲劳驾驶严重威胁驾驶安全，目前，车辆制造商常采用对驾驶时间计时或对车辆行驶姿态分析的方式来进行防疲劳驾驶提醒，存在适应性差、准确率不足的问题。为了解决这个问题，提出了一种基于机器视觉的疲劳驾驶监测算法：通过边缘直方图相关性匹配算法消除图像背景并提取出驾驶员图像，再利用肤色聚类实现对驾驶员面部提取，基于面部灰度分布特征完成眼睛部位定位分割，再计算眼睛区域图像的灰度直方图和标准差，最后，设定阈值来判断眼睛闭合、睁开的状态。如连续多帧视频里眼睛都处于闭合状态，则属于疲劳驾驶。实验表明，算法准确度高、计算量较小，能有效地监测到驾驶员的疲劳驾驶状态。
{ISBN/ISSN}: 2095-297X
{Notes}: 34-1321/Z
{URL}: https://link.cnki.net/doi/10.13900/j.cnki.jbc.2022.05.021
{DOI}: 10.13900/j.cnki.jbc.2022.05.021
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉自动化装配系统研究
{Author}: 黄波;赵飞;王佳;何庆中;王宇峰
{Author Address}: 四川轻化工大学机械工程学院;
{Journal}: 制造技术与机床
{Year}: 2022
{Volume}: 
{Issue}: 09
{Pages}: 117-122
{Keywords}: 机器视觉;自动化装配;平台搭建;实验分析
{Abstract}: 在装配环节，针对目前多数企业（尤其是中小型企业）采用人工装配、劳动量大、装配效率低的问题，提出一种基于机器视觉的自动化装配系统研究。以YB100型转子式机油泵为研究对象，通过SolidWorks软件进行虚拟样机三维结构设计，Halcon做相机内参标定，分层式系统控制以及人机交互平台搭建，完成实物搭建与装配流程实物说明。最后，经过重复性测试计算与装配时间的实验分析测试，可得出，自动化装配的重复定位精度0.02 mm，且根据测试零件定位时间可得出各个零件装配在500 ms以内，满足机油泵装配在精度与效率上的要求。
{ISBN/ISSN}: 1005-2402
{Notes}: 11-3398/TH
{URL}: https://link.cnki.net/doi/10.19287/j.mtmt.1005-2402.2022.09.018
{DOI}: 10.19287/j.mtmt.1005-2402.2022.09.018
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 光场相机建模与畸变校正改进方法
{Author}: 杨守瑞;段婉莹;艾文宇;陈胜勇
{Author Address}: 天津理工大学计算机科学与工程学院教育部视觉与系统重点实验室;
{Journal}: 红外与激光工程
{Year}: 2023
{Volume}: 52
{Issue}: 01
{Pages}: 239-247
{Keywords}: 机器视觉;光场相机;重投影误差;相机标定;镜头畸变
{Abstract}: 光场相机作为一种新型的成像系统，可以直接从一次曝光的图像中得到三维信息。为了能够更充分有效地利用光场数据包含的角度和位置信息，完成更加精准的场景深度计算，从而提升光场相机的三维重建的精度，需要实现精确的几何建模，并精确标定其模型参数。该方法从薄透镜模型和小孔成像模型出发，将主透镜建模为薄透镜模型，将微透镜建模为小孔成像模型，结合光场相机双平面模型，将每个提取到的特征点与其在三维空间中的射线建立联系，详细解释了内参矩阵中每个参数的物理意义，以及标定过程中初值确定的过程，并在镜头径向畸变模型的基础上进一步应用了相机镜头的切向畸变模型以及基于射线重投影误差的非线性优化方法，改进了光场相机的标定方法。实验显示，该方法的RMS射线重投影误差为0.332 mm，与经典的Dansereau标定方法相比，进行非线性优化后得到的射线重投影误差精度提升了8%。该方法详细分析的场景点与特定像素索引的推导过程对光场相机的标定具有重要的研究意义，为光场相机光学模型的建立与初始化标定奠定了基础。
{ISBN/ISSN}: 1007-2276
{Notes}: 12-1261/TN
{URL}: https://link.cnki.net/urlid/12.1261.TN.20220829.1430.005
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的混凝土裂缝检测中预处理综述
{Author}: 吴涵;王睿;周春宁
{Author Address}: 四川师范大学工学院;
{Journal}: 四川建筑
{Year}: 2022
{Volume}: 42
{Issue}: 04
{Pages}: 259-262
{Keywords}: 混凝土裂缝;图像灰度化;图像增强;图像去噪
{Abstract}: 混凝土裂缝的检测对于混凝土构件的养护与维修具有重大意义，而采用机器视觉系统检测替代人工检测不仅节约成本，而且大大提高检测效率。混凝土裂缝在经机器采集成图像后需进行预处理，预处理为后面的裂缝识别与检测提供保证。文章针对较为常见的预处理方法：图像灰度化、图像增强、图像去噪3个部分进行了总结归纳，为预处理的选择应用提供一定的帮助。
{ISBN/ISSN}: 1007-8983
{Notes}: 51-1133/TU
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyk5R24Q9fYsvtScVZSPyYnCZ1V2URJC727Ez7VnSaFT3dAFc2F3zd4vyZRniJ2b1rG8k6cFZnUhWBvGY4tujdUsTuRM-pWjTWQ1VVI8sydZNIr3_9bLrzWyjzelbaVkSEGEeheleP338BdSrXQece7xn-T-YtQh--MUQsrLuc2e4YopgpHa8DFid3qz5PF__c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 面向新工科的机器视觉课程建设及实践研究
{Author}: 丁毓峰;蔡兰兰;赵俊超
{Author Address}: 武汉理工大学机电工程学院;
{Journal}: 中国现代教育装备
{Year}: 2022
{Volume}: 
{Issue}: 15
{Pages}: 86-88+92
{Keywords}: 新工科;机器视觉;无人机;课程体系;实践教学
{Abstract}: 通过分析机械工程专业特色，提出了面向新工科的机器视觉应用需求、课程规划及实践教学体系。实践教学体系中开设了机器视觉基础算法、森林火灾监控无人机、PCB故障检测等多个机器视觉实验项目。以森林火灾监控无人机实验为例，简述了开设机器视觉实验的实验原理、方法及过程。实践证明，实验效果较好，达到机器视觉理论和技术的学习目标。
{ISBN/ISSN}: 1672-1438
{Notes}: 11-4994/T
{URL}: https://link.cnki.net/doi/10.13492/j.cnki.cmee.2022.15.014
{DOI}: 10.13492/j.cnki.cmee.2022.15.014
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 深度学习背景下计算机视觉课程教学改革
{Author}: 陈章宝;邓运生;李壮
{Author Address}: 蚌埠学院电子与电气工程学院;
{Journal}: 安顺学院学报
{Year}: 2022
{Volume}: 24
{Issue}: 04
{Pages}: 122-128
{Keywords}: 计算机视觉;深度学习;教学改革;案例教学
{Abstract}: 在分析深度学习理论及其应用技术的基础上，提出对现有计算机视觉教学的适应性改革，将深度学习融入现有的教学内容中，通过教学内容的优化、教学平台和资源建设，以及教学模式的创新，学生能够在传统计算机视觉技术的基础上，顺利开展基于深度学习理论的计算机视觉技术的学习和应用工程开发。
{ISBN/ISSN}: 1673-9507
{Notes}: 52-1145/G4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxUIMrllJshEIrDa6Md2QCc6AyZyDYMMuqlEaWzm69l4lfp8_TxEFiAMlBuPRyxr0LrbbQEWZBpdQab5yGiwORd0r5Qo7GehpzqxalWQTsqjaswi6JD_mVwLUEF1_J3ntiBEzp1D8Aty81eXJM5o_kIM5FMAgsPKUywjWhUcgLLC84JBToPzHEfReBxl_0Wgv8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的奶牛跛行识别技术研究进展
{Author}: 李前;初梦苑;康熙;刘刚
{Author Address}: 中国农业大学智慧农业系统集成研究教育部重点实验室;中国农业大学农业农村部农业信息获取技术重点实验室;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 15
{Pages}: 159-169
{Keywords}: 计算机视觉;图像处理;深度学习;奶牛跛行识别;可见光相机;深度相机;热红外相机
{Abstract}: 奶牛跛行严重降低奶牛福利及潜在产奶量，影响养殖场经济效益。准确高效识别奶牛跛行，有助于奶牛肢蹄病的及早发现与治疗，促进奶业的健康和可持续发展。人工观察法识别奶牛跛行存在识别效率低、成本高、主观性强等问题。计算机视觉技术可以通过无应激、无接触地采集奶牛行走视频数据，准确高效识别奶牛跛行。该研究从可见光相机、深度相机以及热红外相机3种视频采集手段出发，概述了当前奶牛跛行自动识别的主要研究方法、关键技术以及未来发展方向等，对比分析了各研究方法的优势和不足，指出个体差异性、跛行特征的优选以及早期跛行识别等需要重点关注的技术问题。同时，该研究从数据获取、技术研发和试验验证等方面，分析了奶牛跛行识别技术研究领域存在的主要问题及挑战，展望了未来奶牛跛行识别技术的研究重点和发展方向，为奶牛跛行的精准高效识别提供相关理论依据和技术参考。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzJX554gJAjNhoFIr4dMW1xIHqcYLjucRCp_uI_oJoZgH9o7z6DG1cAA9Sk93CqGIdvVe-58BXP26F0IBUCRuYCE8aMRjYShKZ6plKPnyh2f3pXMMxKASQpWZW3A3bZq7vhHwr-rx4VsWhDgmHtdBfF4hwqMec6UBq8Mmf02f4tIySauivgyktJSi1pwB_rn2U=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于视觉的嵌入式摘酒系统研究
{Author}: 班暾
{Tertiary Author}: 杨江
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;嵌入式系统;Webassembly;人工智能;自动化系统
{Abstract}: 白酒生产时的摘酒环节可以将不同品质酒液进行区分并分别存储,是生产关键环节。代代相传的传统摘酒工艺采用“看花摘酒”方法,酒液冲击接酒碗产生的气泡被称为酒花,通过人工观察酒花视觉特征(看花),来将白酒分段(摘酒)。“看花摘酒”存在分段标准不一、严重依赖人工经验、后继乏人等缺点,不利于产品质量的稳定。以自动化摘酒来替代人工是酒厂发展的趋势,同时摘酒这样的视觉分类任务也非常适合计算机自动完成。由于嵌入式设备功耗小、性价比高且维护简便,使用嵌入式设备实现自动化摘酒系统能够进一步降低成本;但其计算性能一般、内存带宽及片上缓存较小,无法像高性能计算机那样轻松运行相关程序。为了突出嵌入式设备性价比高的优势,同时弥补其劣势,实现适合于嵌入式设备的视觉摘酒系统,本文进行了深入研究。本文在设计中采用更轻量的模型,更高效的计算策略,充分利用嵌入式平台资源,同时保持酒花分类较高准确度,最终达到扬长避短的效果,能够准确可靠、高效率、高性价比地在嵌入式设备上完成摘酒任务。本文工作具体包括:1)设计了“一套系统,两种模式”的嵌入式自动化摘酒系统,两种模式分别为常态运行模式、维护测试模式。常态运行模式下系统自动稳定地实现摘酒,一旦程序故障切换为维护测试模式,由人工看花摘酒而不影响生产,同时更新后的程序能迅速在实际硬件上部署、验证、测试。2)提出一种部署程序的特殊方法,该方法基于Webassembly实现。该方法将整个酒花分类程序编译为高效的Webassembly模块并由网页加载调用,将网页保存在上位机上,任意下位机通过浏览器访问网页即可获取该程序;系统维护测试模式使用了该特殊部署方法,能够通过修改上位机保存的程序,实现对任意下位机的迅速改动,使得更新后程序能够被快速测试和验证,减少维护阶段时间。3)实现基于视觉的酒花分类程序。程序中对相关文献所提出的前处理方法进行改进;设计了轻量级的酒花分类神经网络模型Wine Res6,Caffe模型大小仅655.4KB;同时设计了一种以状态机为基础的酒花分类后处理算法,避免只依靠网络模型结果产生的分类波动,同时有效提高分类正确率。最终在测试集上达到97.2%的分类正确率。4)实现了适合嵌入式设备推理神经网络模型的推理引擎ESNN。ESNN能够高效推理常见神经网络;以纯C++实现,跨平台能力强;功能精简、完整;无任何第三方库依赖。本文酒花分类程序使用ESNN加载并推理神经网络。ESNN的实现借鉴了其他推理引擎NCNN、框架Caffe等的设计思路,并作出独有的创新优化。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001816
{DOI}: 10.27461/d.cnki.gzjdx.2022.001816
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像超分辨率重构技术
{Author}: 苟东强
{Author Address}: 重庆邮电大学软件工程学院;
{Journal}: 信息记录材料
{Year}: 2022
{Volume}: 23
{Issue}: 08
{Pages}: 100-103
{Keywords}: 图像超分辨率;深度学习;生成对抗网络;卷积神经网络
{Abstract}: 图像是信息的重要载体，高分辨率的图像更有利于信息传播，使用基于深度学习的方法来提升图像分辨率是有必要的。首先介绍了传统的图像超分辨率方法，并阐述了传统方法的弊端，提出要将深度学习引入图像超分辨率处理中，将从基于生成对抗网络、基于上采样和基于卷积神经网络三个方面重点研究了深度学习的图像超分辨率重构方法，最后总结了图像超分辨率方法的应用现状，体现研究价值。
{ISBN/ISSN}: 1009-5624
{Notes}: 13-1295/TQ
{URL}: https://link.cnki.net/doi/10.16009/j.cnki.cn13-1295/tq.2022.08.042
{DOI}: 10.16009/j.cnki.cn13-1295/tq.2022.08.042
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于线结构光视觉的平面度误差测量方法
{Author}: 刘思远;侯跃谦;寇莹;任真;胡正乙;赵雪微;葛云鹏
{Author Address}: 吉林大学机械与航空航天工程学院;长春大学机械工程学院;华南理工大学机械与汽车工程学院;长春汽车工业高等专科学校产教融合发展中心;
{Journal}: 吉林大学学报(工学版)
{Year}: 2023
{Volume}: 53
{Issue}: 12
{Pages}: 3358-3366
{Keywords}: 机器视觉;平面度;线结构光视觉;公差测量
{Abstract}: 针对机械零部件制造及加工领域的平面度测量问题，提出了一种基于线结构光视觉技术的平面度误差测量方法。首先，采集被测平面上不同位置的光条图像，并根据每个位置所对应的光平面方程获得扫描点的空间坐标。其次，对国家标准中平面度误差评定方法进行分析，建立了基于几何约束的平面度误差视觉测量算法。最后，通过本文算法，利用扫描点空间坐标计算出评定基面及平面度误差。在实验中，选择镶块模具的定位面作为被测平面，并将视觉测量结果与采用接触式测量方法获得的结果进行对比，测量误差小于20μm。实验结果表明本文提出的平面度误差测量方法具有一定的可行性，提高了平面度误差的测量效率。
{ISBN/ISSN}: 1671-5497
{Notes}: 22-1341/T
{URL}: https://link.cnki.net/doi/10.13229/j.cnki.jdxbgxb.20220050
{DOI}: 10.13229/j.cnki.jdxbgxb.20220050
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉导引的固定翼无人机自主着陆算法研究
{Author}: 胡运强;曹云峰;庄丽葵;宋晓峰
{Author Address}: 南京航空航天大学自动化学院;南京航空航天大学航天学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 14
{Pages}: 252-265
{Keywords}: 机器视觉;固定翼无人机;自主着陆;跑道检测识别;位姿估计
{Abstract}: 研究了使用视觉导引系统进行固定翼无人机自主着陆时的相关问题，主要针对提高视觉导航系统获取导航参数的速度及精度展开研究。视觉导航系统获取参数分为两步：跑道检测识别、固定翼无人机相对位姿估计。提高导航系统参数获取速度，主要通过提高耗时较高的跑道检测识别算法的检测识别效率来完成。利用跑道在序列图像中的时空一致性进行候选区域提取，在不影响召回率的情形下减少无效候选区域，从而提高跑道检测效率，最终提高视觉导引系统获取导引参数的速度。为提高估计的导引参数精度，结合跑道上的点线特征进行位姿估计，通过增加可利用的特征数量来提高位姿估计精度。实验仿真结果表明，所提方法有效提高了视觉导航系统获取导航参数的速度及精度。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220714.1250.281
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进CenterNet的水下目标检测算法
{Author}: 王蓉蓉;蒋中云
{Author Address}: 上海海洋大学信息学院;上海建桥学院信息技术学院;
{Journal}: 激光与光电子学进展
{Year}: 2023
{Volume}: 60
{Issue}: 02
{Pages}: 239-248
{Keywords}: 机器视觉;水下目标检测;CenterNet;高分辨率网络;注意力机制;特征融合
{Abstract}: 针对常规目标检测器检测水下目标时存在特征提取困难、目标漏检等问题，提出一种改进CenterNet的水下目标检测算法。首先，使用高分辨率人体姿态估计网络HRNet代替CenterNet模型中的Hourglass-104骨干网络，降低模型参数量，提升网络推理速度；其次，引入瓶颈注意力模块，在空间维度及通道维度进行特征增强，使网络关注重要目标特征信息，提高检测精度；最后，构建特征融合模块，融合网络内部丰富的语义信息和空间位置信息，并利用感受野模块增强融合后的特征，提高网络多尺度目标检测能力。在URPU水下目标检测数据集上进行实验，与CenterNet相比，所提算法的检测精度可达77.4%，提升1.5个百分点，检测速度为7 frame/s，提升35.6%，参数量为30.4 MB，压缩84.1%，同时与其他主流目标检测算法相比具有更高的检测精度，在水下目标检测任务上更具优势。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220713.1233.102
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于半监督学习和生成对抗网络的医学图像融合算法
{Author}: 尹海涛;岳勇赢
{Author Address}: 南京邮电大学自动化学院人工智能学院;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 22
{Pages}: 245-254
{Keywords}: 机器视觉;生成对抗网络;半监督学习;医学图像融合;注意力机制
{Abstract}: 为了有效利用少量的医学图像标签数据和大量的无标签数据，提出了一种基于半监督学习和生成对抗网络的医学图像融合算法。所提生成对抗网络融合架构包含1个生成器网络和2个判别器网络。采用半监督学习策略对所提网络进行训练，主要包括监督训练、无监督训练、参数微调等3个阶段。此外，生成器由面向融合任务的U-Net和squeeze and excitation通道注意力模块组成，而判别器含有3层卷积层、1层全连接层及sigmoid激活输出层。在各种不同模态医学图像上的实验结果表明，与现有的6种基于深度学习的算法相比，所提算法的主观视觉效果和客观性能指标都有一定竞争力。相关消融实验也验证了半监督学习策略能强化生成网络的性能，提高融合图像的质量。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://link.cnki.net/urlid/31.1690.TN.20220713.1218.006
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的图像拼接技术研究
{Author}: 管娜
{Author Address}: 江苏省扬州技师学院;
{Journal}: 长江信息通信
{Year}: 2022
{Volume}: 35
{Issue}: 07
{Pages}: 58-60
{Keywords}: 图像拼接;计算机视觉;图像融合
{Abstract}: 数字图像拼接技术可通过对部分重叠区域的图像进行处理，通过配准来获取到准确的对应关系，把不同视角条件下的图像投影至相同平面，对重叠区进行对齐处理合并、优化，可得到更好视觉效果的全景图像。文章先对图像拼接流程进行论述，并对图像配准、图像融合进行研究，最后对评价方式和最佳缝合线图像拼接方法进行探讨，可供相关人员参考。
{ISBN/ISSN}: 2096-9759
{Notes}: 42-1914/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvywyx_6TxOsS6T150Bh-a-NG8Z1OpPfuMS0UnTHI1jpVoTMgV6_4qS8BWb9WGdlePYaX71QDKoUpx66AZ9In942ICKB4yT80ygMz5rL89cHTvwMJ1Ev8ivHS3OZPFIgzlWsdjMON72yBz1n0w4W8VJE0Q3bz9cICKCmwvYxne1AcWRQUvpfYEJCpWsflMf5xj4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的结构应变无靶标鲁棒监测
{Author}: 朱前坤;王军营;杜永峰;张琼
{Author Address}: 兰州理工大学防震减灾研究所;兰州理工大学西部土木工程防灾减灾教育部工程研究中心;
{Journal}: 建筑结构学报
{Year}: 2023
{Volume}: 44
{Issue}: 10
{Pages}: 211-221
{Keywords}: 结构表面应变;计算机视觉;相位;支持向量回归;准静态分析;应变云图
{Abstract}: 传统视觉监测方法对结构的现场监测精度往往受控于人造靶标和光照条件等因素，为克服现场光照条件对视觉测量精度的影响，结合基于相位的稠密光流算法和支持向量回归(support vector regression, SVR)算法对现场结构应变的无靶标鲁棒监测。建立基于应变传感器原理的应变转换方法实现结构表面连续应变场的计算，并通过模拟测试试验和现场测试试验验证所提方法可行性。模拟测试试验结果表明：在测量精度相当的情况下，所提方法相较于传统DIC算法的运算速度提升50%,且能够得到更为清晰完整展现细节的应变云图；现场测试试验中，所提方法表现出较好的环境抗干扰能力，与传统测试方法对比的应变测量误差可控制在2.0%以内。相较于传统视觉监测方法，所提方法在保证精度要求的前提下提高了运算速度及鲁棒性，且无需人造靶标，可适用于特定大型工程结构表面应变的现场监测。
{ISBN/ISSN}: 1000-6869
{Notes}: 11-1931/TU
{URL}: https://link.cnki.net/doi/10.14006/j.jzjgxb.2022.0062
{DOI}: 10.14006/j.jzjgxb.2022.0062
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 用于计算机视觉任务的光场成像技术综述（英文）
{Author}: 贾晨;石凡;赵萌;陈胜勇
{Author Address}: 天津理工大学学习型智能系统教育部工程研究中心;天津理工大学计算机视觉与系统教育部重点实验室;
{Journal}: Frontiers of Information Technology & Electronic Engineering
{Year}: 2022
{Volume}: 23
{Issue}: 07
{Pages}: 1077-1098
{Keywords}: 光场成像;相机阵列;微透镜阵列;极平面图像;计算机视觉
{Abstract}: 光场成像因其解决计算机视觉问题的能力而备受关注。本文首先简要回顾了近年来计算机视觉的研究进展。对于影响计算机视觉发展的大多数因素来说，视觉信息获取的丰富性和准确性起着决定性作用。光场成像技术利用照相机或微透镜阵列记录光线位置和方向信息，获取完整三维场景信息，为计算机视觉研究做出巨大贡献。光场成像提高了深度估计以及图像分割、融合和三维重建的精度。光场成像还被创新地应用于虹膜和人脸识别、材料和虚假行人识别、极平面图像采集和形状恢复以及光场显微镜。我们进一步总结了光场成像技术在计算机视觉研究中存在的问题和发展趋势，如光场数据集的建立和评估、在高动态范围条件下的应用、光场增强和虚拟现实。光场成像在各种研究中取得巨大成功。在过去25年，超过180篇文献报道了光场成像在解决计算机视觉问题上的能力。我们梳理了这些文献，使研究人员更容易搜索有关解决方案的详细方法。
{ISBN/ISSN}: 2095-9184
{Notes}: 33-1389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzvlAv--S8abQAR8Eg_uPlJLIKbX8nlfb6wOjSlzmz6_AWlijyGPNR_9JZF-9TF0O3OCw2bTlclAVzdOItooUirk0V4_YnxOPxpe556-A9EuyiH9pqgw5VoS0o-9530WIeMSK67nbH9VnfmiNiUxTKYB62WPkJ7pBiJ4qhN9CzoU1cILScPVUH2c7vxtcnx_PA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的机器人焊缝识别与定位方法研究
{Author}: 张洪瑞
{Tertiary Author}: 伍洲
{Publisher}: 重庆大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目视觉;立体匹配;智能焊接;焊缝识别
{Abstract}: 随着我国工业焊接生产领域自动化、智能化变革潮流的到来,当前机器人智能焊接技术拥有非常广阔的应用场景以及研究价值。但目前实际生产应用中的焊接机器人仍然存在许多问题亟需解决,例如图像处理易受环境背景干扰、焊缝识别精度不高以及系统鲁棒性较低等问题。本文针对以上问题对智能焊接技术进行深入研究,设计了一种以深度学习和计算机视觉技术为基础,结合双目视觉以及线激光传感器的机器人智能焊接系统。论文的主要工作内容如下:(1)首先对智能焊接技术在国内外的相关研究进展进行综述,总结了现存的难点及热点问题,并分析设计了系统整体流程和框架。(2)系统模型的搭建和标定。介绍了相机成像模型、畸变模型以及双目模型,并根据模型原理对系统坐标系间的转换关系进行数学推导,使用Halcon软件完成了相机的单目和双目标定实验,并对标定结果进行误差分析,最后完成了工具坐标系标定实验。(3)图像感兴趣区域(ROI)获取。针对智能焊接系统存在的图像背景复杂、需要人为提取图像ROI等问题,使用深度学习中旋转框目标识别算法实现图像ROI的智能提取。根据焊接系统特点选取了适合的卷积神经网络模型,采集图像并完成数据集的标注,在Halcon中完成深度学习环境的搭建以及网络模型的训练和检测,实验结果表明旋转包围框提取的图像ROI所包含背景信息相较于平行框目标检测算法更少。(4)焊缝识别。对已提取图像ROI进行灰度化、双边滤波以及图像增强等预处理操作,提高焊缝图像特征,使用阈值分割算法对图像进行二值化处理,将焊缝特征与无关背景分离,最后通过canny边缘检测以及霍夫直线检测算法实现焊缝的识别和检测。(5)焊缝三维重构。首先对双目系统进行极线校正,使用立体匹配算法NCC进行特征匹配得到图像视差图以及视差置信度图,并根据双目视差测距原理获取焊缝目标像素的深度信息,完成系统手眼标定并得到焊点真实坐标值,为确保系统精度及安全性,使用线激光传感器以预扫描的形式对目标焊缝进行激光寻位,并根据扫描结果对焊点坐标进行检验和修正,保障了系统精度及可靠性。(6)搭建系统实验平台,完成系统硬件选型和程序的编写及通信,并控制焊接机器人完成模拟焊接实验,实验结果验证了本文所设计系统的可行性。
{URL}: https://link.cnki.net/doi/10.27670/d.cnki.gcqdu.2022.001199
{DOI}: 10.27670/d.cnki.gcqdu.2022.001199
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像超分辨率轻量级算法研究
{Author}: 江明
{Tertiary Author}: 肖庆生
{Publisher}: 江西理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像超分辨率;轻量级;注意力机制;残差学习;生成对抗网络
{Abstract}: 随着多元化信息时代的飞速发展以及计算机硬件水平的显著提高,人们越来越注重接收到的图像质量,而高分辨率图像由于其高质量的画面受到青睐。图像超分辨率重建作为提高图像分辨率的一种重要手段受到广泛关注。深度学习技术广泛应用于计算机视觉领域,并在超分辨率重建任务中通过提取低分辨率图像的特征进行图像重建,从而得到一张对应的高分辨率图像。针对现有基于深度学习的图像超分辨率算法在重建任务上存在模型参数过多,计算更为复杂,不利于现实场景下的应用,本文提出了两种轻量级的超分辨率算法。(1)针对现有图像超分辨率重建算法大多通过扩展卷积神经网络深度和宽度来提取更多特征细节,这将导致算法计算复杂度的提高和模型参数量的增大,本文提出了一种自适应残差注意力的轻量级图像超分辨率重建算法。该算法整体采用全局和局部残差连接相结合的方法,通过改进坐标注意力网络,生成了关注高频位置信息的注意力特征图;接着将改进的自适应残差注意力信息提取模块和坐标注意力模块双支路并行连接,使输出的特征信息包含更多图像细节,在保证模型性能的情况下,大大减少了参数数量。实验证明,该算法在公共测试集上的重建图像质量更好,对比其他算法的客观评价指标更高,同时模型参数量更少。(2)针对现有图像超分辨率重建算法存在特征细节上处理不足的问题,本文提出了一种基于改进生成对抗网络的轻量级图像超分辨率重建算法。该算法整体采用生成对抗网络的思想,主要在生成网络部分进行改进。首先,在生成网络的深层特征提取模块中使用面向边缘的卷积模块,更好的提取图像的边缘信息;其次在上采样重建模块中,使用像素注意力机制和上采样相结合的方法更好的恢复图像细节;最后在推理阶段,使用重参数思想将面向边缘的卷积模块进一步整合为常规卷积,达到减少模型参数的目的。实验证明,该算法使用生成对抗网络重建的图像在特征细节方面表现更好,使用了重参数化技术,使模型参数量大大减少。
{URL}: https://link.cnki.net/doi/10.27176/d.cnki.gnfyc.2022.000740
{DOI}: 10.27176/d.cnki.gnfyc.2022.000740
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于无人机影像的大豆苗情快速检测方法研究
{Author}: 赵弋秋
{Tertiary Author}: 李赫
{Publisher}: 河南农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 无人机;大豆;机器视觉;YOLOv5;苗情检测
{Abstract}: 大豆幼苗的长势不均匀、出苗不良以及田间杂草胁迫等情况都将阻碍作物生长,降低作物产量,快速检测大豆田间苗情及杂草分布,实现大豆苗期田间精准管理,对保证大豆高质高产有着重要的意义。本文基于低空无人机平台,以大豆苗(VC期至V2期)为对象,结合机器视觉、深度学习技术,对田间的作物及作物行分布信息进行检测,实现了田间大豆苗情及杂草分布信息的获取。同时基于本文提出的关键检测算法,开发了大豆苗情检测系统,实现了基于无人机影像的大豆苗情快速检测与分析。主要研究内容如下:(1)基于深度学习目标检测技术的大豆叶片识别。本文通过对比选择不同深度学习模型间的精度与速度,选择使用YOLOv5s模型进行大豆叶片目标的识别。结合无人机大田影像的特点及模型本身的结构,本文对模型进行了精简优化,在原有YOLOv5s模型的基础上减去了20*20尺度的相关特征层以提升模型性能。使用优化前后的模型对大豆叶片的识别进行了训练和对比测试,模型测试结果表明,优化后的YOLOv5s模型精度达到91.8%,mAP@0.5达到了0.938,相较于原始YOLOv5s模型,仅下降0.029。而优化后的模型平均单张识别速度仅有6.42 ms,识别帧率达到了155.76帧每秒,相较于原始模型提升了40%,本文优化后的YOLOv5s模型在保有原模型精度的前提下实现了性能的提升。(2)提出了一种针对大田无人机影像的作物行检测方法,通过分析作物行在图像中的几何排列特性,将作物行检测拆分为几何变换、滤波、分割、拟合四个过程。几何变换把作物行视作线性纹理,通过Radon变换检测图像中的作物行纹理方向,并将图像作物行纹理方向约束至作物行沿图像X轴分布,在此基础上使用长边与作物行方向平行的长网格滤除作物行外的噪声。同时为了实现自动化作物行分割,在传统K均值聚类的基础上,根据作物行排列规律设计了自动确定K值的方法,最后使用最小二乘直线拟合法对分割后的作物行分别进行拟合,实现了对无人机图像中作物行分布的快速检测。在随机抽取的验证数据中,作物行中心线识别率达93.9%,在不同种植模式和拍摄高度下识别率均达到了92%以上,与人工目视检测对比的平均角度偏差为0.126°,平均检测时间0.31秒,在精度与速度上都具有良好表现。(3)设计了大豆苗情关键指标的提取方法。通过多个指数对比后,使用过红绿指数对地面植被分布进行二值化分割,并结合大豆叶片识别结果进一步分割大豆叶片,获得地面植被分布和大豆叶片分布。在地面植被、大豆叶片和作物行的分布基础上,设计了苗情检测关键指标的计算方法:a)基于大豆叶片分布和作物行分布图像,对作物行上的作物分布进行小区域运算并绘制作物分布图,得到了不同区域间地面作物冠层覆盖面积的变异系数,实现了对大豆苗分布的量化评估。b)基于二值化单条作物行图像,使用投影分割法定位作物行内的缺苗位置,绘制了对图像的作物缺苗断行分布,定位了缺苗位置并计算了断行长度、缺苗率、出苗率等量化指标,同时结合种植农艺及图像拍摄参数,进一步估算了图像中正常苗与缺失苗的数量。c)通过从地面植被冠层分布中减去大豆叶片分布的方法,结合开运算滤波和小区域运算,从无人机影像中检测绘制了田间杂草分布处方图,并计算杂草覆盖率。(4)设计与开发了大豆苗情检测系统。基于Qt和Python,设计开发了集田间数据的展示、处理、分析等功能于一体的田间苗情检测系统。系统围绕主要检测算法需求,设计了数据管理模块、核心检测模块、数据后处理模块等多个模块,实现了从原始数据载入到最终结果输出的快速全程操作。
{URL}: https://link.cnki.net/doi/10.27117/d.cnki.ghenu.2022.000361
{DOI}: 10.27117/d.cnki.ghenu.2022.000361
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于人体关键点检测的起跑动作矫正系统的研究与实现
{Author}: 巢斌
{Tertiary Author}: 张亚萍
{Publisher}: 云南师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人体姿态估计;起跑姿势预测;起跑姿势数据集;注意力机制;姿势矫正
{Abstract}: 我国作为一个现代化体育强国,随着经济的快速发展,人民物质文化生活质量迅速提高,全民健身的理念深入人心。全民健身活动展开的同时,我们注意到,一些技巧性运动因为难度较高,导致人们在运动时容易出现错误动作,甚至存在很大的安全隐患。传统的体育训练多数情况下都是采取基于体育教练员肉眼观测的训练方式,体育教练员通过观察运动员在训练时的动作,结合自己的经验与看法对运动员进行指导,没有定量的数据进行分析,训练过程受人为主观意识影响严重,使得运动员训练结果差异性较大。要想对人们运动姿势进行科学的分析指导,就必须获取到人们运动时的运动数据或者肢体姿态数据。近年来,随着深度学习和人体姿态估计等相关技术的深入研究,将这些技术应用在运动检测、运动数据分析等方面,使我们能够获得运动者的肢体和相关关键点数据,这不仅可以科学地指导运动员的整个训练过程,同时还提高了教练员教授和运动员训练效率以及运动中的安全系数。本文提出了基于注意力机制的高分辨率人体关键点检测网络,并设计实现了基于关键点检测网络的运动员起跑动作矫正系统,建立了运动员起跑运动数据集,包含各就位阶段、预备阶段、途中跑阶段三部分姿势图像,并以预备阶段姿势为主要研究对象,进一步的研究计算机视觉技术在运动员起跑姿势图像关键点检测中的应用,本文研究的主要内容如下:(1)建立了运动员起跑运动数据集,通过现场拍摄、网络视频截取等多种方式采集了运动员在起跑各就位阶段、预备阶段、途中跑阶段这三个类别的起跑图像,并将采集好的起跑图像通过多种数据增强方式和数据标准化处理来扩充数据集,最后对图像进行分类整理制作成供实验使用的运动员起跑运动数据集。(2)本文通过对传统的人体姿态估计算法进行学习研究发现,传统姿态估计算法多数在网络模型中进行了上下采样,这导致在训练中丧失了很多空间信息,加之网络模型结构复杂,参数量和计算量大,导致传统的网络模型在人体姿态估计任务上准确率低。本文针对传统人体姿态估计算法存在的缺点和问题进行研究,提出了基于注意力机制的高分辨率人体关键点检测网络,网络模型保持了高分辨率表征,可以更准确地对图像中人体进行关键点定位。引入注意力模块,是为了让网络更关注目标实例,同时尽最大限度控制参数量和计算量。本文引入三种不同的注意力模块与模型融合进行消融实验,证明了CBAM注意力机制与模型融合进行起跑姿势预测的有效性。实验结果表明,基于注意力机制的高分辨率人体关键点检测网络获得了更高的起跑姿势预测准确率,且有效地控制了网络训练过程中的参数量和计算量。(3)设计实现了基于人体关键点检测的运动员起跑动作矫正系统。系统主要包含有用户的注册登录功能、姿势图像上传功能、图像预测功能、展示预测结果和改正建议的功能。
{URL}: https://link.cnki.net/doi/10.27459/d.cnki.gynfc.2022.000959
{DOI}: 10.27459/d.cnki.gynfc.2022.000959
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向数据不规则分布的深度特征学习研究
{Author}: 刘家伦
{Tertiary Author}: 李文辉
{Publisher}: 吉林大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 长尾分布;多模态分布;无监督域适应;深度特征学习
{Abstract}: 图像是人类获取信息的直接来源。随着互联网、移动智能设备和社交媒体等技术的迅猛发展,人们可以轻松地获取到大量的图像资源,与单一的小规模学术集不同,人们实际获取的大规模数据往往呈现出多模态,不均衡的分布,甚至是无标签的。本文将这类分布统一称为数据的不规则分布。数据的不规则分布问题广泛存在于学术研究以及实际生活中,尤其是随着近些年深度学习的迅速发展,为图像特征学习提供了强有力的研究途径,获得了计算机视觉等相关研究领域的高度关注,被广泛应用于学术界以及工业界。结合以上两点,针对数据不规则分布的深度特征学习具有显著的理论研究价值和强烈的实际应用需求,本文展开研究了数据不规则分布常见的三个问题,即数据呈现长尾分布问题,数据呈现多模态分布问题,以及训练域和测试域分布不对齐的问题。1)针对长尾分布问题,本文提出了两种方法:可学习的尾部数据扩充方法,Feature Cloud;基于模型抖动信息的的尾部数据扩充方法,MBJ。本文提出将头部类丰富的类内多样性迁移至尾部类来缓解尾部类类内多样性不足的问题。具体地,在特征空间中扩充尾部类的分布,使其具有与头部类相似范围的分布。将一个尾部特征向量替换为一簇特征向量,称之为Feature Cloud。实验结果显示,Feature Cloud在长尾表征学习以及分类学习任务上获得了国际领先水平的性能表现。本文提出利用历史模型之间的抖动信息来丰富尾部数据的多样性。模型在每次迭代后,参数会不断发生变化,产生权重向量的抖动(weight jitter),对应地,给定一张图像,两个历史模型产生的特征向量也是不同的,即会产生特征向量的抖动(feature jitter)。本文认为这些抖动信息为尾部数据的扩充提供了可靠的信息,为此,本文利用存储器将这些抖动信息进行收集,来为尾部数据提供额外的样本多样性。实验结果显示MBJ在长尾表征学习以及分类学习任务上获得了国际领先水平的性能表现。2)针对多模态分布问题,本文提出了一种利用存储器做增强的单方向度量学习方法,称为MAUM。方法包含两部分:单方向度量学习和基于存储器的增强方法。MAUM首先学习多个模态下的专属类代理,接下来利用模态专属类代理去拉近它对立模态的特征向量。进而,本文将由于模型漂移现象产生的多个模态专属类代理进行存储来增加它们的多样性,这为单方向度量学习提供了额外的困难正样本。实验结果表明,MAUM不仅在模态衡均衡情况下获得了国际领先水平的性能表现,在模态不均衡问题上也获得了额外的鲁棒性。3)针对训练域和测试域分布不对齐的问题,本文提出了一种多域图像风格迁移的无监督域适应方法,称为IPGAN。IPGAN首先将源域的图像风格转换为多个目标子域的图像风格以此来减少它们之间的分布差异,并且保证转换后的图像具有与原始图像一致的身份信息。接下来利用风格转换后,具有标注信息的源域数据训练模型并将其应用到目标域中进行测试。实验结果表明IPGAN获得了非常具有竞争力的性能表现。
{URL}: https://link.cnki.net/doi/10.27162/d.cnki.gjlin.2022.000265
{DOI}: 10.27162/d.cnki.gjlin.2022.000265
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人脸跟踪云台的红外热成像系统
{Author}: 张紫东;马春燕;陈燕;姚坤;李根;郭然
{Author Address}: 太原理工大学电气与动力工程学院;
{Journal}: 电子器件
{Year}: 2022
{Volume}: 45
{Issue}: 03
{Pages}: 665-671
{Keywords}: 温度监测;MLX90640红外阵列传感器;OpenMV;目标追踪;人脸识别
{Abstract}: 针对疫情防控与疫情常态期间的公共场所人员温度异常检测模式固定、响应迟钝、直接接触测温等缺点，设计了一种追踪动态人脸的红外热成像测温系统。系统基于红外阵列传感器MLX90640和CMOS摄像头模块OV7725,以STM32H743为核心控制器，加持了二自由度云台，并借助OpenMV IDE软件结合HaarCascade级联分类器、目标追踪PID算法、LBP特征提取，实现了从人脸检测、人脸跟踪到温度检测和人脸识别的功能。最后通过整机调试，可以完成对动态人脸的追踪、人体温度异常的检测、被测者身份认证。实验表明，该非接触测温系统操作简单、红外热成像图像质量较高、测温灵敏，且硬件便于与门禁系统搭配使用，应用场景较广。
{ISBN/ISSN}: 1005-9490
{Notes}: 32-1416/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzm61pa9oxy4uulABwPMUDaFDCv1MQRjzY-V5C1zgxiGgOrdD8oqDuQRJJ4J-VNcg4dLvFwXJugOW8xcc4cs1dkI6NSeXAslTMyOXzlI3y-S66NEeutTxVDnlFqrmBhwnT0bB2IPFFf_Q4dQM1l-cBuE7vNHv6vIWW1k-tDUyCWFYj51aRq3OZyJf0gzmqEqT0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与深度学习的飞机防护栅裂纹检测系统
{Author}: 张良安;陈洋;谢胜龙;刘同鑫
{Author Address}: 安徽工业大学机械工程学院;安徽省工业互联网智能应用与安全工程实验室;中国计量大学机电工程学院;
{Journal}: 兵工学报
{Year}: 2023
{Volume}: 44
{Issue}: 02
{Pages}: 507-516
{Keywords}: 飞机防护栅;裂纹检测;机器视觉;深度学习;卷积神经网络
{Abstract}: 针对传统飞机防护栅裂纹检测中存在的效率低、可靠性差等问题，基于机器视觉技术设计一种飞机防护栅裂纹检测装置，并结合图像处理技术与深度学习原理提出一种飞机防护栅裂纹检测算法。设计飞机防护栅裂纹检测系统，研究防护栅裂纹图像识别算法。采集并整理飞机防护栅裂缝图像，研究并制作飞机防护栅裂纹检测数据集；分别以ZF-Net、VGG-16和ResNet-101卷积神经网络作为Faster-RCNN特征提取网络，开展飞机防护栅表面裂纹和缺陷裂纹检测研究。实验结果表明：3种模型均达到了良好的检测精度，其检测精度分别为92.79%、95.12%和97.54%,其中ResNet-101网络检测效果最好，相比于现有的防护栅裂纹机器视觉检测方法，漏检率和虚警率分别下降了22.54%和89.28%,检出率提高了22.54%;ResNet-101网络在不同光照条件下仍有较高的检测精度，检测装置和检测算法有效，可为飞机防护栅的检测提供了新方法。
{ISBN/ISSN}: 1000-1093
{Notes}: 11-2176/TJ
{URL}: https://link.cnki.net/urlid/11.2176.TJ.20220614.1659.003
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机器人视觉系统与标定研究
{Author}: 孙东;巩雪
{Author Address}: 哈尔滨商业大学轻工学院;
{Journal}: 哈尔滨商业大学学报(自然科学版)
{Year}: 2022
{Volume}: 38
{Issue}: 03
{Pages}: 312-317
{Keywords}: 机器视觉;视觉系统;标定;相机;机器人;视觉传感
{Abstract}: 随着机械生产智能化、自动化程度的提高，对机器视觉的依赖程度越来越高，机器视觉的应用范围也随之扩大.摄像机标定对于立体成像系统的实现非常重要，其精度直接影响到立体成像系统的精度.为了研究视觉机器人以及视觉系统，利用Matlab中Camera Calibrator方法进行了标定试验，得到了更方便更简单的标定方法，结果表明，此方法所运用的设备更简单且缩短了标定时间.
{ISBN/ISSN}: 1672-0946
{Notes}: 23-1497/N
{URL}: https://link.cnki.net/doi/10.19492/j.cnki.1672-0946.2022.03.017
{DOI}: 10.19492/j.cnki.1672-0946.2022.03.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 文档智能：数据集、模型和应用
{Author}: 崔磊;徐毅恒;吕腾超;韦福如
{Author Address}: 微软亚洲研究院自然语言计算组;
{Journal}: 中文信息学报
{Year}: 2022
{Volume}: 36
{Issue}: 06
{Pages}: 1-19
{Keywords}: 文档智能;深度学习;多模态自然语言处理
{Abstract}: 文档智能是指通过计算机进行自动阅读、理解以及分析商业文档的过程，是自然语言处理和计算机视觉交叉领域的一个重要研究方向。近年来，深度学习技术的普及极大地推动了文档智能领域的发展，以文档版面分析、文档信息抽取、文档视觉问答以及文档图像分类等为代表的文档智能任务均有显著的性能提升。该文对于早期基于启发式规则的文档分析技术、基于统计机器学习的算法以及近年来基于深度学习和预训练的方法进行简要介绍，并展望了文档智能技术的未来发展方向。
{ISBN/ISSN}: 1003-0077
{Notes}: 11-2325/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyG4v__hzC8WH-xBl0bc0iEJLzzggwvFnDosWwLVlf66rMa-mV7kfpUPBPL1TkmzE69DtQY3MZyGmmL6jHe4nLnYboq3SwtqR7N-4ZNPNGv29wO718AHVjvDuh4beYZF-1X8iH22XRXFGrAGlW0O0WQibzVuHznn21KPBOuRiQoPARw0ijKKTqqZNaE6Gcc304=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向红外图像中弱小目标检测的深度卷积神经网络研究
{Author}: 孙召进
{Tertiary Author}: 王国刚
{Publisher}: 沈阳化工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 红外弱小目标;JAnet;YOLO;高斯;Transfomer;膨胀卷积
{Abstract}: 红外探测技术因其具有较好的隐蔽性和较强的抗干扰能力等特点,在红外制导、预警等军事领域得到较为广泛的应用,其中面向红外图像中的(弱)小目标检测能力直接决定现代化武器装备的水准,成为当前重点研究和发展的方向之一。如何解决红外弱小目标在红外图像中占有的像素非常少,特征不明显,目标特征易于噪声混淆等问题,有效提高红外(弱)小目标的检测能力是当前的研究热点。本文针对基于深度学习的对空红外弱小目标和对地红外小目标检测算法展开研究。本文的主要贡献如下:第一,针对经典的基于深度学习的对空红外弱小目标检测算法存在目标信息在高层感受野消失导致无法检出的问题,提出一种新的基于多通道多尺度特征融合的对空红外弱小目标检测算法(J-MSF)。首先,该算法提出了一种新的多通道JAnet结构,基于此结构搭建了主干特征提取网络;其次,设计了下降门限式特征金字塔池化结构(DSPP),并提出了多尺度融合检测策略;最后,设计了高斯损失优化函数。实验结果表明,所提出的算法在“地/空背景下红外图像弱小飞机目标检测跟踪数据集”上的检测效果与YOLOv3、YOLOv4算法对比,检出率、整体AP值分别提升9.07%、9.89%和1.67%、3.16%。第二,针对基于深度学习的对地红外小目标的目标检测算法对热辐射不均匀的目标进行检测时,目标易与背景噪声混淆导致检测精度低的问题,提出一种自编码学习的多层细粒度感知网络检测算法(MFG-TF)。首先,该算法采用CNN与Transformer结合的自编码和解码结构进行搭建主干提取网络;其次,设计了内置膨胀卷积的尺度自适应融合模块;最后,采用Transformer检测头对小目标进行检测。实验结果表明,所提出的算法MFG-TF在“面向空地应用的红外时敏目标检测跟踪数据集”上的检测效果与YOLOv3、YOLOv4、Vi T算法对比,准确率、整体AP值分别提升3.85、1.18、1.32和2.26、0.66、0.94。实验结果表明,本文提出算法在红外(弱)小目标检测功能上优于目前主流检测算法,体现出了良好的实时性和适应性,可以有效的应用于对空红外弱小目标和对地红外小目标。同时,J-MSF和MFG-TF也展现出较好的鲁棒性和较高的检测性能。
{URL}: https://link.cnki.net/doi/10.27905/d.cnki.gsghy.2022.000052
{DOI}: 10.27905/d.cnki.gsghy.2022.000052
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的轨道侵限异物检测方法研究
{Author}: 刘力
{Tertiary Author}: 苟军年
{Publisher}: 兰州交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 异物检测;轨道检测;YOLO v4;计算机视觉;卷积神经网络
{Abstract}: 随着轨道交通行业的快速发展,新的列控系统对设备自动化程度的要求不断提高。铁道侵限异物检测作为保证列车运行安全的重要课题之一,一直是铁路从业人员和相关科研工作者所关注的领域。随机的车、人、物等异物入侵行车限界的行为,对列车的行车安全产生了严重的威胁,现有的安装防护网及重点区域视频监控等常规防护措施已无法满足要求。因此,研究可以实现对列车行驶前方不间断检测的技术,是保障列车出行安全的现实需求。目前,基于深度学习计算机视觉技术的侵限检测逐渐成为了主流研究方向。基于列车运行的安全防护需求,本文主要研究了深度学习在铁道侵限异物检测任务中的应用技术,并根据本课题所研究对象的特点进行了针对性的改进以满足具体要求。主要研究内容如下:(1)侵限图像的预处理。数字图像在成像和传输过程中由于电子元器件发热而产生的噪声具有随机、不可预测的特点,使得图像的质量大幅降低。对噪声的去除一直是数字图像处理过程中的重要环节,为了降低噪声对轨道检测和侵限异物检测效果的影响,本文对均值滤波、高斯滤波和双边滤波三种广泛使用的去噪算法进行了对比研究,并选择高斯滤波算法作为本文样本图像进行预处理的方法。(2)轨道检测。针对传统边缘检测方法对钢轨检测效果不理想,在建立钢轨线性模型时需要使用滑动窗口的方法来进一步对轨道的特征点进行筛选,处理过程过于复杂。故提出了采用基于深度学习的语义分割网络UNet对钢轨进行检测的方法,该方法通过对像素的语义类别进行预测,可以直接将钢轨作为待检测语义类别从图片中分割出来。最后通过对钢轨像素的直接遍历提取轨道特征点,并用最小二乘法实现了钢轨线性模型的建立。(3)YOLO v4实现铁道侵限异物的检测。YOLO v4强化的特征提取网络实现了对图片特征的精细化提取,形成多尺度特征;PANet则对不同尺度的特征进行了充分的融合;不同尺度的检测头对不同大小的物体实现了准确的分类及回归。通过实验验证,YOLO v4对本文研究的绝大多数异物均实现了较好的检测效果,但是对于与环境对比度小、特征不太明显物体的检测效果则不太理想。因此,本文对YOLO v4网络进行了如下改进:(1)在特征提取网络和特征融合网络之间加入注意力机制网络SENet,进一步加强对有效特征的利用;(2)改进了K-means算法中聚类中心初始化的方法,并用改进后的方法在自制数据集上进行聚类,修改anchor尺寸;(3)使用迁移学习的方法进行网络模型的训练,提高泛化性能;(4)在特征提取网络结构中加入了drop block层,抑制检测模型的过拟合现象。实验结果表明:改进YOLO v4算法不仅实现了对侵限异物的准确检测,而且在实时性方面表现较好,具有一定的应用价值。
{URL}: https://link.cnki.net/doi/10.27205/d.cnki.gltec.2022.000733
{DOI}: 10.27205/d.cnki.gltec.2022.000733
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于双向特征融合的露天矿区道路障碍检测
{Author}: 阮顺领;李少博;顾清华;江松;毛晶
{Author Address}: 西安建筑科技大学资源工程学院;西安建筑科技大学西安市智慧工业感知计算与决策重点实验室;西安优迈智慧矿山研究院有限公司;
{Journal}: 煤炭学报
{Year}: 2023
{Volume}: 48
{Issue}: 03
{Pages}: 1425-1438
{Keywords}: 露天矿;无人驾驶卡车;机器视觉;障碍检测;特征融合
{Abstract}: 近年来矿用卡车自动驾驶的兴起，使得障碍检测变得至关重要，露天矿区非结构化道路复杂多变，时常出现碎石、坑洼等小目标或多尺度行车障碍，严重危害行车安全。因此，笔者提出一种基于双向特征融合的露天矿区道路障碍检测方法。通过实地采集并使用数据扩增方法对露天矿障碍图像数据集进一步细分及扩充，并在特征提取阶段提出了更适用于障碍检测的RepVGG+骨干网络结构。在特征融合阶段，提出基于SimAM空间与通道注意力和跨阶段连接的双向特征融合金字塔模型。通过扩大预测小目标障碍的特征图和特征感受野，提升小目标障碍检测性能，通过双向特征融合机制提升多尺度检测性能。同时对网络分类预测模块的卷积层和先验框尺寸进一步调整，提升障碍检测性能，降低特征冗余，加快模型推理速度。在模型的损失函数方面，针对训练中样本不均衡和障碍物边界框定位不精准问题，使用融合标签平滑正则化的Focal Loss作为分类损失函数，GIoU Loss作为边界框损失函数进一步优化露天矿区障碍模型。实验表明本文方法能有效识别复杂背景下露天矿区非结构化道路障碍物，在实际应用中，检测精度达到了91.76%,检测速度达到56.76 fps,相较于主流检测方法有着更好的小目标和多尺度目标检测性能，可以满足露天矿区无人矿卡行进中的障碍安全检测要求。
{ISBN/ISSN}: 0253-9993
{Notes}: 11-2190/TD
{URL}: https://link.cnki.net/doi/10.13225/j.cnki.jccs.2022.0198
{DOI}: 10.13225/j.cnki.jccs.2022.0198
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图像识别的风力机叶片表面损伤分析研究
{Author}: 任其科
{Tertiary Author}: 蒙建国
{Publisher}: 内蒙古科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 风机叶片;缺陷检测;图像处理;ResNet50;RAdam
{Abstract}: 风力机一般安装在海拔较高的山岭地带,工作环境恶劣,叶片长期暴露在外很容易产生裂纹、涂层破坏、油污、点蚀等表面缺陷,如果不能得到及时的修复,随着时间的推移,叶片可能产生断裂而造成大的事故,所以需要对风力机叶片表面进行缺陷检测以防止事故的发生。目前,风力机叶片的缺陷检测工作基本依靠人力进行观测,不仅效率低下、成本高昂而且这种方法经常容易导致误判。本文采用无人机采集风力机叶片表面损伤图片和视频,借助机器视觉领域结合深度学习领域的算法对风力机叶片表面损伤图片进行处理,达到图片自动精确分类的目的。首先对风力机叶片的图像采集装置以及图像处理装置的软件和硬件进行了设计与选型。选用大疆旗下的M210RTK无人机搭载禅思Z30云台相机对风力机叶片损伤位置的图片进行收集,将图片经过筛选构建出一个四损伤类型的数据集,并对图片进行旋转、缩放等增强处理来扩充数据集以保证训练完成后网络模型的鲁棒性。其次借助机器视觉领域传统的图像处理方法,对图像进行灰度处理、滤波处理、二值化分割处理、形态学处理以及连通域标记处理这一流程,该算法流程将图片的损伤区域与图片背景分离,为后面利用神经网络对叶片损伤图片进行准确分类提供保障。最后利用深度学习目标检测算法,对处理完成的图像进行准确分类,本文选择分类准确率较高三种卷积神经网络VGG16、Google Net、Res Net50分别对上述处理完成的图片进行分类。通过将各网络模型多次迭代后的准确率以及损失值曲线进行对比,VGG16、Google Net、Res Net50验证集的准确率分别为85.98%、89.02%、92.07%,初步选用准确率最高、损失值最小的卷积神经网络Res Net50作为图片分类的网络模型。为了提高该网络模型的性能,进一步对Adam、RAdam优化器优化完成的Res Net50网络进行对比,通过对两优化模型分类结果比较,确定RAdam优化网络模型准确率更高,收敛速度更快。本文从网站和风场继续收集了部分叶片损伤图片,用混淆矩阵对每一类的准确率进行验证,得到最终分类结果的准确率为95.83%,达到图片分类的要求。文章最终选用RAdam优化后的Res Net50网络对风力机叶片表面损伤图片进行分类测试,该流程可以实现图片的快速、准确分类。
{URL}: https://link.cnki.net/doi/10.27724/d.cnki.gnmgk.2022.000579
{DOI}: 10.27724/d.cnki.gnmgk.2022.000579
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的工件识别技术研究
{Author}: 位冲冲
{Tertiary Author}: 宫妍;任迪
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;工件识别;卷积神经网络;图像预处理;数据增强
{Abstract}: 针对传统的工件识别流程是由人工根据工件的特点设计需要提取的特征,并利用简单的算法来完成,整个过程具有耗时高、成本大、通用性较差和识别准确率不高等问题,本文将机器视觉技术和卷积神经网络算法结合起来,用于工件的识别与分类,系统能够完成自动化地图像特征获取,与分类识别过程融为一体,提高了工件识别准确率和识别速度,主要工作内容如下:(1)针对卷积神经网络模型需要大量数据进行训练,按照实际工业生产中的场景,对采集到的八类工件原始数据进行了数据增强操作,并划分为三种数据集;为提高数据集图像质量,对数据集进行滤波、图像增强、归一化等一系列预处理操作,使用三种滤波处理方式进行对比,结果表明中值滤波处理效果更好。(2)针对卷积神经网络用于工件识别的流程以及常用的训练方法,总结了几种防止模型发生过拟合的技巧;研究了 AlexNet和LeNet-5网络模型结构特点,以及用于工件识别中的优缺点,针对其缺点做出了适合本文工件识别的改进;为了理解卷积核的作用以及CNN各层的功能,通过可视化操作,分析了图像经过卷积之后输出的特征图。(3)针对AlexNet在训练过程中出现的训练速度缓慢,loss值和acc值曲线波动大,在验证集上准确率不高,并有一定程度的过拟合等问题,分析原因之后对网络做出几点改进,通过减少图像的输入尺寸、网络层数来减少网络参数,用目前主流的批归一化层来取代局部响应归一化层,改进后识别效果显著提高;针对LeNet-5结构简单、识别率低等问题,增加了输入图像尺寸和网络深度,使用ReLU代替原激活函数,用多个小卷积核代替大卷积核,结果表明能更好地防止过拟合现象的发生。(4)通过实验对比证明,改进后的网络模型能更好地识别本文工件,准确率和识别速度得到大幅提升并符合期待值,而且所占的存储空间更小,泛化性能良好,模型的性能、识别速度和准确率不仅优于原始网络,更优于传统机器学习算法。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2022.000344
{DOI}: 10.27787/d.cnki.ghrbs.2022.000344
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的牛日常行为识别研究
{Author}: 杜妍茹
{Tertiary Author}: 王月明
{Publisher}: 内蒙古科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 牛日常行为;行为识别;智慧养殖;Yolov5-deepsort;统计
{Abstract}: 随着我国养殖业大规模和集约化的发展,对牲畜的行为监管变得尤为重要,能够为疾病预防、合理喂养和繁殖育种提供数据资源,有助于更好的关注牲畜福利和繁殖效率。但目前我国畜牧养殖业仍以人工养殖为主,这种传统的养殖方式普遍存在基础设施落后、管理粗放、规模小、效率低和效益差等问题。随着智慧养殖理念的提出,基于传感器的牲畜行为识别蓬勃发展,但该方法需为牲畜佩戴传感器,容易引起应激反应,给牲畜的正常活动带来不便。本文提出基于计算机视觉的牛日常行为识别方法,实现了对牛日常行为无接触、自动化的实时监测。本文研究工作主要包含以下内容:首先,构建养殖场中单目标牛日常行为数据集,利用Yolov5s目标检测算法识别单目标牛的日常行为,设计了单目标牛日常行为时间统计算法,实现单目标牛日常行为时间的统计,为后续多目标牛日常行为识别提供参考价值。然后,构建养殖场中多目标牛日常行为数据集,利用Yolov5x目标检测算法识别多目标牛日常行为,并设计多目标牛日常行为时间统计算法,实现对多目标牛日常行为时间的统计。接着,构建牛身份ID追踪数据集,利用Yolov5-deepsort目标追踪算法对养殖场中多目标牛身份ID进行追踪并识别牛的日常行为。最后,结合Yolov5-deepsort目标追踪算法设计了对每个牛身份ID下的牛各日常行为时间统计的算法,实现了养殖场中牛只身份ID追踪,牛日常行为识别以及各ID下牛日常行为发生时间的统计,为养殖场牛日常养殖管理、牛健康状况分析评估提供数据依据和一种技术解决方案,为智慧养殖和精准养殖提供技术支持。
{URL}: https://link.cnki.net/doi/10.27724/d.cnki.gnmgk.2022.000779
{DOI}: 10.27724/d.cnki.gnmgk.2022.000779
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的四旋翼无人机跟踪系统设计
{Author}: 谢松
{Tertiary Author}: 王家成
{Publisher}: 阜阳师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 四旋翼无人机;机器视觉;自抗扰;识别追踪
{Abstract}: 小型四旋翼无人机拥有众多优点,例如,重量轻、体积较小、易于操控和良好的稳定性等优点。近年来,随着硬件设备性能的提升,基于无人机平台实现的功能也越来越丰富。尤其是将无人机与机器视觉模块相结合,使得无人机能够自主完成对预定目标的识别以及追踪处理,这就需要无人机飞行时拥有良好的稳定性,以便进行拍照和识别。通过机器视觉模块与无人机平台相结合,大大拓展了无人机的应用场景,具有一定的工程应用价值和实际意义。本文主要便是围绕着无人机的飞行稳定性和搭载机器视觉对预定目标进行识别追踪的相关工作进行研究,内容如下:1.四旋翼无人机建模:通过对无人机各个模块硬件的选取介绍,对动力模块建立数学模型,计算分析得到了所搭建无人机的飞行性能,该模型可以滞空飞行约14min。对无人机飞行原理进行说明并建立了相应的坐标系。并针对无人机的具体结构运用牛顿-欧拉方程推导得出无人机的动力学、力学模型。通过分析系统整体模型并进行线性化处理得到了四旋翼无人机的整体数学模型,建立了对应的仿真模型用于控制器的仿真验证。2.自抗扰控制算法:通过对无人机的控制器进行研究,针对传统PID控制在无人机控制器当中应用的缺点,提出了自抗扰控制(ADRC-Active Disturbances Rejection Controller)算法。由于无人机飞行当中易受环境因素等干扰,ADRC有着良好的抗干扰能力,十分适合应用于无人机平台。并通过MATLAB/Simulink对ADRC和PID算法进行仿真模拟性能分析,在相同环境下得出ADRC相较于PID控制的响应曲线波动幅度更小,调节速度更快,稳定效果更好。3.基于机器视觉的飞行控制:利用改进过的无人机平台进行与机器视觉模块相结合,构建了基于机器视觉的飞行控制器完成了对预定目标的准确识别以及对移动目标的追踪。同时改进后的飞行平台有着更好的飞行稳定性,能够长时间稳定的识别跟踪目标,验证了实验的可靠性以及稳定性。
{URL}: https://link.cnki.net/doi/10.27846/d.cnki.gfysf.2022.000070
{DOI}: 10.27846/d.cnki.gfysf.2022.000070
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人体姿态估计
{Author}: 许帅
{Tertiary Author}: 王国栋
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;计算机视觉;特征融合;人体姿态估计
{Abstract}: 人体姿态估计任务旨在从图像或视频中定位出人体关键点位置,该任务可作为其他计算机视觉任务的基础。近年来,人体姿态估计受到了越来越多的关注,并被广泛应用到人机交互、计算机仿真系统等现实场景。现有的基于深度学习的算法克服了手工提取特征主观性较强的弊端,具有强大的特征学习能力。然而如遮挡、训练数据不足等问题仍制约着算法检测精度的提升,且复杂的网络结构会导致检测速度过慢。针对上述问题,本文提出了以下三种解决方案:(1)提出了一种基于动态人体感知卷积的人体姿态估计算法。针对人体特征复杂的特点,引入可变形卷积使网络能够自适应的调整感受野,增强主干网络聚合多尺度空间信息的能力。采用条件卷积设计关键点检测模块,避免了算法检测速度依赖于人体实例数量的问题。通过基于回归的关键点对齐模块获得精准的关键点坐标。在公开数据集上的实验结果表明,该算法能够在检测精度与速度之间取得良好的平衡。(2)设计了一个基于双向融合特征金字塔的端到端人体姿态估计算法。建立了一个双向融合特征金字塔网络,通过双向跨尺度连接和加权特征融合,实现了高效的特征提取。以人体关键点的最小外接矩形为边界框进行训练,将目标检测的思路应用到人体姿态估计中。在公开数据集上的实验结果表明,该算法能够实现高效的人体关键点检测。(3)探索了一种基于Swin Transformer主干和位置编码器的人体姿态估计算法。引入Swin Transformer作为主干网络,并针对人体姿态估计任务的特性优化网络结构。通过将原始图像信息压缩成关键点紧凑的位置序列,把人体姿态估计任务转化为编码任务。通过计算注意力分数得到关键点依赖项,预测最终的关键点位置。在公开数据集上的实验结果表明,该算法能有效预测被遮挡的人体关键点位置。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2022.002565
{DOI}: 10.27262/d.cnki.gqdau.2022.002565
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的细粒度图像识别问题研究
{Author}: 张大玮
{Tertiary Author}: 谭园园
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;细粒度图像识别;迁移学习;注意力特征提取网络
{Abstract}: 细粒度图像识别是计算机视觉领域最重要的分支之一。近年来,随着计算机视觉领域的快速发展,细粒度图像识别技术已经在餐饮、网购、教育、城市交通等领域表现出强大的价值。细粒度图像识别技术可以分为强监督细粒度图像识别和弱监督细粒度图像识别。强监督细粒度图像识别需要在训练之前对图片中要识别的区域进行适当的人工标注,其准备工作耗时耗力,需要人工标注的专业性程度较高。因此,本文研究的是不依靠额外的人工标注信息进行的细粒度图像识别。为了获得较高精度的细粒度图像识别技术,则要对该目标对象进行更加精细的位置检测和更加精细的特征提取。本文采用深度学习卷积神经网络算法框架,采用定位判别性区域网络、特征增强网络、遮掩判别性区域网络、双线性注意网络模块强化网络的特征信息提取能力。主要研究内容如下:(1)综述了细粒度图像识别问题的研究背景及意义,综述了国内外研究细粒度图像识别方法,引出了弱监督细粒度图像识别方法是目前研究的主流方向。介绍了在深度学习的过程当中有关于细粒度图像识别的相关技术,计算机视觉中常见的两种注意力机制和细粒度图像识别领域常用的数据集。(2)为了解决卷积神经网络在训练数据时识别精度不高的问题,本文采用了迁移学习的思想,以Efficient Net V2为主干网络,对三种细粒度图像数据集分别进行图像识别。迁移学习训练的过程中,最初的十次训练需要冻结网络中除全连接层以外的权重参数,在之后的训练则需解冻网络全部权重参数。通过与其他网络算法的对比实验和自己数据集的可视化分析实验得出,基于Efficient Net V2网络的迁移学习具有很强的图像识别性能。(3)为了解决弱监督细粒度图像识别算法很难捕获到图片当中最具有判别性特征区域的问题,本文提出了一种注意力特征提取网络(Attention Feature Extraction Network,AFEN)来强化网络对最优判别性特征区域进行特征提取。采用特征增强的方式强化网络对相关特征图通道的权重,柔性池化的方式减少网络的信息丢失,设计定位判别性区域网络和遮掩判别性区域网络与主干网络互相作用的方式修正网络内部的参数信息。设计并应用类中心损失、互补性损失函数Ls1、互补性损失Ls2与分类损失矫正了网络的修正效果。应用CUB-200-2011、FGVC-Aircraft和Stanford Cars数据集进行实验,根据实验结果可得出AFEN算法的细粒度图像识别准确率均高于其他的网络结构,对判别性区域的定位和对特征信息的加强提取表现出较好的细粒度图像识别能力。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000601
{DOI}: 10.27322/d.cnki.gsgyu.2022.000601
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于U-Net和GAN的视网膜眼底图像分割方法研究
{Author}: 许广
{Tertiary Author}: 汪华登
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 视网膜血管分割;U-Net;注意力机制;多尺度特征;生成对抗网络
{Abstract}: 视网膜眼底图像血管分割具有重要的临床应用价值,然而,当前基于深度学习的分割方法还存在着许多不足,如微细血管的分割质量不够好,血管容易出现断裂和缺失的现象,分割的准确率和灵敏度等指标有待于进一步提升等。针对上述不足,本文提出了一种新型分割网络模型AMSFU-Net,与其它方法相比,微细血管的分割质量得到了很大的提升。另一方面,我们将所提AMSFU-Net模型作为生成器,同时设计了新的生成对抗学习策略和损失函数,提出了眼底血管分割生成对抗模型RetinalGAN,在眼底血管分割问题上超越了许多基于GAN方法的性能,且我们通过对抗学习进一步提升了AMSFU-Net模型的鲁棒性。本文的主要研究工作和贡献点包括:(1)在AMSFU-Net中,我们提出了面向编码和解码阶段的两种注意力模型,依据特征的重要性对其权重进行了调整,实现了特征的重标定,使得模型重点关注血管特征图的重要区域和位置,提升模型血管分割的精确度。(2)我们设计了多尺度的特征提取与聚合模块,借助不同扩张率、不同核大小的空洞卷积的组合获得了多种不同感受野大小的多尺度特征,该结构有利于模型识别出不同形态、粗细的血管结构。(3)在AMSFU-Net的编码路径中,我们对多个不同编码阶段的特征图进行了块嵌入(patch embedding),获得了多个尺度的tokens特征序列,并通过Transformer模型来建立多个尺度特征序列的全局上下文信息的依赖关系,提升模型对微细、结构复杂血管的分割能力。(4)我们将基于创新点(1)(2)和(3)所提出的AMSFU-Net作为生成器,同时设计了一种二分类的判别器模型,通过基于图像对的生成对抗策略,为生成器和判别器各自设计了新的损失函数和训练策略,提出了Retinal-GAN模型,提升了传统GAN方法的血管分割质量和指标,分割出的微细血管显得更加的清晰和连续。从实验结果上看,我们的AMSFU-Net模型在DRIVE数据集上的准确率和灵敏度分别达到了96.26%和83.92%,在STARE数据集上则分别达到了97.30%和81.24%。在以AMSFU-Net模型作为生成器的基础上,我们提出的Retinal-GAN模型在DRIVE数据集上准确率和灵敏度分别达到了96.60%和84.11%,在STARE数据集上则达到了97.43%和83.22%。总的来说,我们提出的基于U-Net和GAN的模型在一些分割性能指标上要高于多个现有的方法,分割出的血管缺失和断裂的情形相对更少,血管结构更加的清晰,对一些相对复杂的血管如微细血管等的分割效果也更佳。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000991
{DOI}: 10.27049/d.cnki.ggldc.2022.000991
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于伪标签训练的半监督语义分割方法研究
{Author}: 黄惠文
{Tertiary Author}: 罗笑南
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;语义分割;半监督学习;自训练;伪标签训练
{Abstract}: 近年来,为了缓解像素级标注样本数量严重不足的问题,基于自训练的半监督语义分割方法得到了广泛的关注。这些方法首先用少量的有标注样本去训练分割网络,然后把大量无标注样本的预测结果作为伪标签,从而扩大数据集中训练样本的数量。但由于伪标签中存在许多噪声,因此模型性能的提升有限。此外,当有标注样本和伪标签样本的数量极不均衡时,伪标签训练反而可能会导致模型性能下降。为了有效地降低伪标签中的噪声对语义分割模型的消极影响,本文深入研究了基于伪标签训练的半监督图像语义分割方法,主要工作内容及贡献如下:首先,分析了伪标签训练策略中存在的三方面问题,研究并提出了基于协同伪标签的半监督图像语义分割模型,该模型包括高级语义错误校正模块、低级语义错误校正模块和基于双学生的分割网络,以及提出了自适应加权交叉熵损失函数。提出的高级语义错误校正模块和低级语义错误校正模块,旨在分别缓解伪标签中存在的假阳性分类错误和假阴性分类错误;提出的基于双学生的分割网络架构,旨在解决单个分割网络无法识别自身生成伪标签的错误的问题;提出的自适应加权交叉熵损失函数,旨在解决基于置信度的阈值过滤法造成的伪标签浪费问题。然后,分析了基于单分支结构的语义分割模型在伪标签训练过程中潜在的负优化问题,研究并提出了基于双分支伪标签训练的半监督图像语义分割模型,该模型包括双分支分割网络和改进的单分支解码器。提出的双分支网络由共享编码器模块和两个独立的解码器模块组成;提出的有监督分支和半监督分支,旨在降低伪标签中的噪声对有监督分支模型参数更新过程的干扰;提出的改进的DeepLabv3+解码器模块,旨在提高特征融合的效果。最后,结合本文提出的两种基于伪标签训练的半监督图像语义分割方法,进行了大量的消融实验与对比实验。结果验证了本文所提出的两个半监督模型的有效性,并通过与其他半监督语义分割方法的结果进行对比,证明了本文所提出方法的先进性。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000173
{DOI}: 10.27049/d.cnki.ggldc.2022.000173
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 快递包裹信息码视觉定位与识别技术研究
{Author}: 孙东
{Tertiary Author}: 巩雪;顾三鸿
{Publisher}: 哈尔滨商业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 物流包装;机器视觉;形态识别;信息定位;信息提取
{Abstract}: 中国快递行业的飞速发展,带来了快递时长的激烈竞争。物流包装信息的提取作为快递运营过程中的关键环节,其效率和精准度将影响快递企业的分拣成本、运营效率、服务水平以及企业的市场竞争力和未来几年发展。为了有效解在中转中心地提取物流快递包裹的信息,采用系统思维和新颖的算法对物流包装信息进行处理,同时运用视觉技术中的深度学习来定位和识别物流包装信息,以利于物流分拣工作中降低重复工作的疲劳,增加快递分拣的效率。为了更好的实现智能物流中的全自动化,首先对快递包裹的不同包装类型对分拣时的影响进行分析后,通过相关软件的调整实验,完成对倾斜的信息码进行矫后完成识读,其实用可靠性达到97.5%。获得物流快递单号信息,达到在分拣后使同一目的地的同一种类快递可以进行堆叠,减少快递占用空间,使同种类包装快递的商品得到更好的保护的目的。其次针对分拣中视觉技术中的深度学习概念进行概述,运用传统的深度学习方法对快递包裹相关数据集的进行采集并处理,通过学习后运用其进行分类定位的实验,平均精度值达到71.06%,发现无法对小目标进行很好的处理。达到可以实现快递包裹相关信息的分类及定位,为后续分拣中快递包裹的定位提供包装的目的。较于传统的视觉技术中的深度学习不能很好的识别定位小目标,在传统算法的基础上,针对对象特点,引入新的深度学习算法并进行了优化。通过引入形成新的4尺度检测整体结构,实现对小目标快递包裹的检测。通过引入多尺度特征融合结构来进行特征增强。通过引入GIOU损失函数代来进行边框回归,实现定位精度的提高。最后,进行数据集的收集与处理,得到优化后算法的平均精度值为94.12%。通过实验结果表明,与传统检测算法相比有较大优势,同时检测速率上满足实时性要求,有一定的实用性与有效性。最后,设计了物流快递包裹信息提取系统,该系统涵括了物流外包装定位识别与分类功能、快递外包装中条形码和二维码的定位、识别和解码功能、快递单号输出功能和物流外包装分类输出功能并且能从输入的快递图像中精确地提取价值信息内容。系统实验表明,该系统能有效对物流快递包裹信息进行定位及提取,且该系统可广泛地应用于物品类别分类等领域。
{URL}: https://link.cnki.net/doi/10.27787/d.cnki.ghrbs.2022.000345
{DOI}: 10.27787/d.cnki.ghrbs.2022.000345
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的交通施工场地风险目标辨识与跟踪方法
{Author}: 郭亚朋
{Tertiary Author}: 李顺龙
{Publisher}: 哈尔滨工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 施工场地;风险目标辨识;风险目标跟踪;深度学习;计算机视觉
{Abstract}: 交通基础设施是一个国家和地区经济和社会发展的生命线。在交通基础设施施工建设过程中,有限空间内会短时间聚集大量复杂的人、机、物、料等资源,复杂的施工资源交互作用在时空约束下令施工场地的安全管理极具挑战性。施工场地风险目标的状态识别可为施工管理者获取场地的动态信息提供有效数据支持,从而保障施工场地的正常运营和施工人员的生命安全。当前基于传统接触式传感手段的方法无法有效反演出有效真实的风险目标的时空状态,同时还存在成本高效率低的不足。针对以上难题,本文考虑交通施工场地风险目标空间分布“大分散、小聚集”的特点,结合考虑时间域的风险目标分布特征演化,分别以施工人员、施工车辆、施工机械和施工船舶为研究对象,由稀疏分布到密集分布、由刚体到可变形体、由空间域到时空域、由二维到三维,逐步深入地研究基于计算机视觉的交通施工场地风险目标辨识与跟踪方法。主要研究内容包括:(1)针对空间大尺度施工场地稀疏分布的施工人员位置和状态快速辨识问题,提出了基于图像拼接技术的施工人员两层次信息辨识方法。首先利用无人机拍摄图像时的GPS和姿态信息对施工场地图像进行预配准,建立了基于特征区域过滤的特征提取与匹配技术,采用最佳缝合线方法以消除鬼影效应从而得到施工场地的全场图像;然后根据施工人员的稀疏分布特性,使用分类网络对人员区域进行筛选后利用检测网络对施工人员的位置和状态进行辨识。(2)针对施工场地密集分布的施工车辆的精准辨识问题,提出了基于旋转检测框和特征融合的密集施工车辆信息辨识方法。采用旋转检测框对施工车辆位置、尺度及朝向信息进行建模,建立集成旋转检测框候选生成和回归的单阶段检测网络,使用特征融合模块对特征进行多层级融合以进一步提高辨识精度。使用具有代表性的真实施工场地的各类施工车辆数据对本章方法进行了验证。(3)针对施工场地中工作风险更高的铰接式施工机械的高效状态辨识问题,提出了基于轻量化网络的铰接式施工机械姿态估计方法。首先对施工机械姿态进行参数化,使用二维高斯分布对关键节点坐标处理形成热力图,在网络层面、模块层面以及通道层面对姿态估计网络进行了轻量化,构造基于L2函数的网络损失函数。最后利用包含多种复杂施工场地背景的挖掘机图像标注数据集对本章方法进行了验证。(4)针对施工场地中施工车辆的时空信息的完整获取问题,提出了基于旋转检测框的施工车辆二维运动跟踪方法。利用旋转检测框的特征对二维平移和旋转运动进行描述以表示施工车辆的外包轮廓,建立轮廓检测模块以获取复杂背景中的施工车辆外包轮廓,采用卡尔曼滤波技术对轮廓信息的时间演化进行关联,构造了交占比指标控制的跟踪ID管理模块。最后对真实施工车辆视频获取了二维运动信息。(5)针对施工场地中施工船舶运行时空信息获取问题,提出了基于单目视觉的施工船舶三维参数跟踪方法。利用互联网搜集的船舶图像及标注训练深度船舶检测模型,定位施工船舶所在区域后变换色彩空间后使用形态学运算得到船舶的精准轮廓,构造场地已知条件,建立了基于射影变换模型的三维时空参数计算方法。对真实施工场地船舶的三维参数进行了跟踪以验证方法的可行性。本文的研究成果将为交通施工场地各类风险目标的状态识别提供理论支撑,为施工场地的安全管控提供数据基础。
{URL}: https://link.cnki.net/doi/10.27061/d.cnki.ghgdu.2022.000227
{DOI}: 10.27061/d.cnki.ghgdu.2022.000227
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于卷积神经网络的煤矸石识别模型研究
{Author}: 穆拉德
{Tertiary Author}: 牛强
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 卷积神经网络;煤矸石分类;热图像;体积感知与预测;支持向量机
{Abstract}: 煤炭作为最有影响力的化石燃料之一,在开采过程中,通常伴随着煤矸石。煤矸石的堆积导致土地资源的浪费和环境的破坏,因此煤与矸石的分离是煤炭工业的一个重要研究方向。现有煤矸石分选是通过人工分选和机械分选等多种技术完成的,存在着严重的问题。人工分选需要熟练工人的经验,但工作环境对工人的健康影响很大,而机械程序则严重影响工作环境和生产质量。计算机视觉和神经网络的引入不仅保障了工人的安全,在提高分离系统效率方面也发挥了巨大的作用,但它们仍然存在煤矸石视觉相似性等重大问题,无法直接利用原始图像信息对煤矸石进行有效地识别。因此,本文结合感知机理,研究煤矸石识别问题。针对每种物质根据其成分具有不同的热量排放这一事实,提出多种基于热图像的煤和煤矸石分类模型,此外基于物体的体积和重量之间的关系,提出多个基于煤矸石体积感知与预测的煤矸石识别模型。本文主要研究内容如下:(1)通过研究了煤矸石在一定情况下的热辐射效应,构建一种基于热图像的煤矸石分选SVM模型YCb Cr-SVM。首先利用红外辐射原理,通过比较黑体煤和煤矸石在不同温度下的发射率功率与波长构建煤矸石识别相关的物理原理模型,为基于热图像的煤矸石分类模型提供参考依据。在此基础上搭建热图像数据采集平台,基于YCb Cr颜色空间表示,提取热图像Cb颜色信息作为特征,利用高斯SVM的对煤与煤矸石进行分类,与基于普通数字图像的方法对比,证明基于热图像方法的优越性。(2)针对基于SVM模型的煤矸石识别需要大量分析和提取热图像特征,导致模型识别效率降低的问题,开展快速提取煤矸石热图像特征的研究。根据卷积神经网络(CNN)在图像处理中的优势,提出了一种基于CNN的煤矸石热图像特征提取方法,构建了一种煤矸石识别模型CGR-CNN,通过对煤矸石热图像特征的训练与测试实现煤矸石准确、高效的识别。(3)针对基于热图像特征的煤矸石识别模型受热环境影响,导致模型使用受限的问题,开展通用煤矸石识别方法的研究。根据煤和矸石的密度差异,提出基于样本体积与重量关系的识别方法,构建了基于样本体积的煤矸石分类模型VW-SVM,设计了Ex MW＿SVM、CGVP＿CNN和MCGVP＿CNN三种模型来预测样本体积,用于VW-SVM模型的测试,实现基于体积与重量关系的煤矸石识别。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000082
{DOI}: 10.27623/d.cnki.gzkyu.2022.000082
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多任务对抗学习的行人重识别方法研究
{Author}: 陈莹
{Tertiary Author}: 夏士雄
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 行人重识别;变分推理;图像生成;滤波器剪枝;进化算法
{Abstract}: 随着智慧城市建设的稳步推进,公共视频监控网络获得了长足发展,监控摄像头在医院、学校、商场等公共场所广泛部署,在提高公共安全和改善交通管理、应急指挥等方面的同时,带来了海量的视频和图像数据分析需求。基于人工处理和提取数据的传统监控方法具有出错率高、速度慢、效率低等缺点,因此基于深度学习的智能视频监控系统应运而生。行人重识别（Re-identification,Re ID）作为智能视频监控处理数据的一项重要技术,其目的是在行人检测的基础上利用计算机视觉技术判断不同摄像头获取的图像或者视频序列中是否存在特定行人的技术,它通常被作为行人检索的一个子问题,因此具有重大的研究意义和广泛的应用前景。在实际的场景应用中,行人重识别技术仍存在以下挑战:第一,由于多摄像设备全天时、全天候的工作采集了大量的视频和图像信息,但会存在一些行人训练样本数量有限的问题;第二,由于行人姿态的变化不仅丢失部分行人信息,而且还会引起大于身份差异的外观变化,导致现有工作难以学到鲁棒的行人特征;第三,现有Re ID技术为了提高识别精度往往采用复杂的网络模型,导致其难以部署到对实时需求度较高的业务场景中。针对上述问题,本文从多样性样本生成、相似行人判别性特征学习和轻量化网络设计这三个角度开展了下述创新性工作。（1）多样性行人图像生成方法。针对大数据环境下特定行人样本多样性差的问题,提出了一个基于变分推理的多姿态样本生成网络模型（CVGAN）。通过采用姿态估计器和设计基于变分推理的自动编码器,CVGAN模型能够在解耦同一个行人姿态和外观信息的同时,可以实现任意姿态的行人图像生成。在三个基准数据集上的实验证明,CVGAN方法比大多数主流的生成方法更具优越性。（2）高分辨行人图像生成方法。针对生成样本纹理信息缺失的问题,提出了一种高分辨图像生成的孪生对抗学习方法（PS2GAN）。为了生成具有目标姿态的行人图像,设计基于孪生生成对抗网络的图像生成模型,并基于孪生结构设计对比姿态损失。为了生成更加逼真的行人图像,采用最近邻损失缩小生成图像和真实图像之间的差异,使高层信息更接近。本方法在多个公开数据集上都取得了良好的生成效果。此外,将生成样本用于扩充Re ID训练集,识别性能有一定的提升。（3）多任务姿态无关的特征学习方法。针对行人Re ID方法易受相似行人干扰的问题,提出了一种面向相似样本学习的强化变分对抗网络方法（RL-VGAN）。提出行人重识别孪生变分对抗学习方法,实现样本生成和相似性样本对抗一体化学习的目标。将深度学习与强化学习决策的优势结合起来,一方面通过端到端的学习提升生成网络生成样本的能力,另一方面提升行人重识别方法对相似样本干扰的鲁棒性。训练时,采用三阶段训练策略实现图像生成和行人重识别两个任务,可以更好地应对姿态变化和相似行人干扰等因素造成的行人身份特征判别难的问题。该方法在多个行人重识别数据集上取得了良好的识别性能。（4）基于进化算法的滤波器剪枝方法。针对行人重识别网络模型训练参数多、计算量大的问题,提出了一种基于进化算法的滤波器剪枝方法（EAFPruner）。首先将网络剪枝过程建模为组合优化问题,并采用进化算法求解,使用L1范数作为冗余准则来评估滤波器的重要性。此外,采用一种基于自适应批归一化层更新的评价方式快速地评估修剪后网络性能与微调后精度之间强相互关系以减少微调时间消耗。然后选择精度最高的修剪网络进行微调并评估识别效果。在四个Re ID数据集上进行的实验结果验证了EAFPruner方法的有效性。（5）基于上述四个工作,设计了基于多任务对抗学习行人重识别验证系统。本系统由参数设置子模块和多任务对抗学习行人重识别子模块两大部分组成,可视化地显示模型的参数设置和网络的训练过程。该论文共有图64幅,表21个,参考文献189篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000074
{DOI}: 10.27623/d.cnki.gzkyu.2022.000074
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的行人重识别关键技术的研究
{Author}: 裴胜玉
{Tertiary Author}: 樊晓平
{Publisher}: 中南大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 计算机视觉;行人重识别;深度学习;注意力机制;聚类
{Abstract}: 给定一个感兴趣的行人查询,行人重识别的目标是确定该对象是否在不同的时间出现在同一摄像头,或者是否在不同的时间出现在另一个摄像头。行人可以使用图像、视频序列、甚至文本形式表示。近年来,深度学习在计算机视觉领域取得了极大的成功,基于深度学习的行人重识别在智能安防和智慧城市等领域也得到了广泛应用。行人重识别技术在图像和视频两个不同对象类型有不同的核心问题需要解决。基于图像的行人重识别任务的核心问题在于如何提取更加鲁棒的行人特征,基于视频的行人重识别任务的核心问题在于如何更好地提取视频序列时空信息的特征表达。另外,在完全监督和无监督两个不同学习方法下也有不同的核心问题亟待解决,无监督行人重识别的核心问题就在于完全没有标注标签的情形下如何更有效地生成优质伪标签。本文基于深度学习技术,针对图像和视频两个不同对象类型的行人重识别和无监督行人重识别任务分别提出相应的解决方法,主要创新点如下:(1)对于基于图像的行人重识别问题,受相机视角、行人姿态、遮挡、背景等影响,行人重识别框架有效特征选择困难。为了解决基于深度学习的行人重识别网络模型有效特征选择单一问题,提出基于自适应空间尺度(Adaptive Spatial Scale,ASS)的行人重识别网络框架。ASS策略提取Res Net网络中的局部特征和全局特征,并通过聚合操作自适应特征尺度,提高模型的特征学习能力。网络框架将ASS策略嵌入到卷积网络的最后两层,实现端到端训练和测试,有效特征提取效率更高。实验表明,该算法能提高特征表征能力,有效解决训练过程中身份损失和三元组损失收敛冲突的问题。(2)针对基于图像的行人重识别数据集规模不够,深度学习网络模型泛化能力不足,容易出现过拟合现象的问题,提出属性感知增强的行人重识别网络模型。该网络包含属性感知模块、局部模块和全局模块,通过引入非局部注意力模块,增强Res Net网络空间语义信息,并通过局部分支模块学习行人局部细粒度信息。此外,该网络还设计了针对各分支网络的规范化处理模块以避免过度属性学习。实验表明,该算法有效增强空间语义信息,取得很好的识别率和精度。(3)对于基于视频的行人重识别问题,富含更多时间、空间信息,有效特征提取困难。针对行人视频序列图像帧时空线索信息容易丢失的问题,提出多水平融合时空协同注意力(Multi-level Fusion Temporal-Spatial Co-attention,MLTS)的行人重识别方法。该网络包含全局模块、局部模块和注意力模块,通过设计局部分支模块以解决视频序列图像帧姿态不对齐问题,并通过引入知识进化提升Res Net的特征学习能力。此外,该网络还设计了多水平融合时空协同注意力学习视频时空线索。实验表明,该算法的三个模块可以很好的结合,相互补充,能解决图像帧信息不对齐,减少遮挡和杂乱背景的干扰。(4)针对大规模行人数据标签标定困难,聚类方法容易引入噪声标签的问题,提出相机感知增强的无监督行人重识别方法。该网络通过行人身份伪标签采样提高样本多样性,设计摄像机感知模块学习行人不变特征,结合多源特征提取策略取得了较高的识别率。此外,该网络结合对比学习、度量学习等多种混合的统一更新策略学习簇级水平内存字典,动态更新特征。实验表明,该算法能有效减少伪标签噪声的影响,快速提升现有方法的性能。综上所述,本文通过对基于深度学习的行人重识别任务面临的若干问题进行深入剖析,研究了优化卷积神经网络特征聚合、自适应关注局部细粒度属性、视频序列时空对齐学习、相机感知增强学习等方法,有助于行人重识别技术的发展,具有重要的理论意义和应用前景。图68幅,表44个,参考文献199篇
{URL}: https://link.cnki.net/doi/10.27661/d.cnki.gzhnu.2022.000485
{DOI}: 10.27661/d.cnki.gzhnu.2022.000485
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的小样本图像分类算法研究
{Author}: 施启睿
{Tertiary Author}: 刘园园
{Publisher}: 西安电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 小样本学习;自监督学习;Transformer;多模态;度量学习
{Abstract}: 目前基于深度学习的人工智能算法已经在许多领域超越了人类,然而这类技术对数据的依赖性较高。在许多应用场景中,获取数据的过程面临着各种挑战,从而限制了深度学习算法在这些场景下的应用。因此探究在小数据量条件下训练可靠的深度神经网络具有重要的现实意义。
小样本学习致力于解决数据稀少场景下训练模型的问题。在各类小样本学习算法中,基于度量的小样本算法性能较好。本文的研究问题为小样本图像分类,针对基于度量的小样本学习算法中数据匮乏、模型表征能力不足以及度量方式不准确等问题,从输入数据、特征编码模型、度量方式等角度出发对其进行改进。本文的主要研究内容如下:
1.提出了基于对比学习和自注意力的小样本图像分类模型。该方法设计了一个监督对比块损失用于模型的预训练过程,该损失函数能够有效提升模型的泛化性能。此外,基于度量的小样本算法大多将图像压缩成特征向量,这种做法不仅丢失了图像的空间结构信息,还无法准确表示图像的前景物体。本文针对该问题提出使用特征图来度量图像间相似性,采用了自注意力机制对图像块进行匹配,确保模型能够准确对比关系相近的图像区域,从而做出更精确的预测。实验证明这两项改进能够有效提升小样本分类模型的性能。
2.提出了基于视觉Transformer的小样本图像分类模型。该方法探究性的将视觉Transformer模型应用于小样本分类任务中。并通过分析自注意力机制和卷积操作之间的区别和联系,得出这两种操作方式的优缺点。据此设计了一种结合了卷积和自注意力机制的视觉网络模型。该模型能够同时编码全局特征和局部特征,模型的表征能力得以增强。实验结果验证了该视觉模型在小样本分类任务上的有效性,以及展示了各种视觉Transformer模型在小样本分类任务上分类结果。
3.提出了基于多模态的小样本图像分类模型。该方法在预训练阶段引入代理任务辅助训练网络模型,通过这种方式增强模型的泛化能力。另外,本文提出使用多模态学习来解决小样本分类场景下数据稀缺的问题。具体而言,本文以原型网络为基础,设计了两种不同的特征融合方式对图像特征和文本特征进行融合,来增强特征空间内的原型表示,使得原型更具有代表性。实验结果表明,该方法能够有效提升模型在小样本分类场景下的准确率。
{URL}: https://link.cnki.net/doi/10.27389/d.cnki.gxadu.2022.002687
{DOI}: 10.27389/d.cnki.gxadu.2022.002687
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的混凝土构件损伤检测与定位方法研究
{Author}: 江永清
{Tertiary Author}: 庞丹丹
{Publisher}: 山东建筑大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 计算机视觉;损伤检测;深度学习;损伤定位;自监督学习
{Abstract}: 混凝土构件垮塌的原因往往都是由于没有进行科学及时的病害检测,这些微小结构的开裂通常会引发整个工程的灾难性破坏。而实际工程中基于目视巡检的传统检测方法通常缺乏准确性和通用性,无法在复杂的基础设施条件下工作;因此必须选择科学合理的方法对建筑物结构进行检查,定期对其健康状况进行评估。其次,准确识别到缺陷之后的一项重要任务就是找到缺陷的位置并执行具体的维护工作。深度学习方法的发展引导了有关损伤检测和图像定位技术的新研究,这种基于视觉元素的结构损伤检测方法有助于建立适当的维护策略,从而节省维护预算并改善基础设施的性能。因此,为了充分利用深度学习方法解决混凝土构件损伤地检测与定位任务,本文研究了一种基于计算机视觉的自动检测和定位混凝土损伤的方法,主要研究内容如下:针对没有统一的混凝土损伤数据集所导致的各种方法缺乏检测标准问题,构建了一个包含各种复杂场景下的大规模混凝土损伤数据集。该数据集由10691张包含混凝土裂纹、斑点、钢筋裸露和剥落等各种典型缺陷类型的图像组成。针对现阶段混凝土缺陷检测算法的推理速度慢、准确率低等问题,采用深度可分离卷积,倒残差网络结构和线性瓶颈结构给出了一种快速检测和分类混凝土损伤的新颖深度学习方法。所出的方法与原始的混凝土损伤检测算法相比,网络参数只占原始网络的1/5,网络推理速度分别升了24.1%和53.5%,综合检测精度分别高了3.25%和4.04%。为了进一步高混凝土损伤检测算法的性能,分别对混凝土损伤检测和分割算法进行了优化,出了一种基于深度学习的两阶段混凝土损伤检测与分割的方法。所出的方法将混凝土损伤检测和分割相结合,以便在第二阶段中对检测到的混凝土裂缝进行分割,将检测精度具体到损伤像素点。实验结果表明,相比于原始网络的精度分别升了4.31%和7.47%,网络的推理速度分别升了35.3%和50.3%。为了降低混凝土缺陷检测方法在实际工程应用中的数据标注成本,高像素级的损伤检测精度并且实现混凝土损伤地理位置的定位,出了一种基于自监督实例分割和位置识别的混凝土损伤检测与定位方法。该模型不仅拥有在复杂场景中检测和分类各种典型混凝土缺陷的能力;同时可以对检测到的缺陷进行精确的地理定位而无需外部传感器。所出的模型仅通过边界框注释成本和自动索引的方式便可实现缺陷的像素级检测和地理定位任务。实验结果表明,所出模型的检测精度和定位精度分别达到了48.75%和83.69%,与其他方法相比具有显著优势。
{URL}: https://link.cnki.net/doi/10.27273/d.cnki.gsajc.2022.000207
{DOI}: 10.27273/d.cnki.gsajc.2022.000207
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂环境下基于深度学习和信息融合的实时多目标识别和6D姿态估计方法
{Author}: 梁雨
{Tertiary Author}: 梁国远;王灿
{Publisher}: 中国科学院大学(中国科学院深圳先进技术研究院)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 卷积神经网络;物体识别;语义分割;物体6D姿态估计;信息融合
{Abstract}: 近年来,随着人工智能的高速发展以及人口老龄化程度的加剧,越来越多的智能服务机器人逐渐出现在日常生活中,而在复杂的室内环境下准确、实时地进行多目标物体识别和姿态估计是智能服务机器人执行决策的重要前提。此外,物体识别和姿态估计在计算机视觉领域其他重要课题中,也发挥着不可替代的作用,如虚拟现实、增强现实、自动驾驶等。然而,基于传统方法的物体识别和姿态估计难以克服遮挡、光照变化等挑战。随着深度学习技术的蓬勃发展,卷积神经网络逐渐成为目标识别和姿态估计领域的主流方法。因此,本文以“复杂环境下基于深度学习和信息融合的实时多目标识别和6D姿态估计方法”为课题,对基于卷积神经网络的多目标物体识别和6D姿态估计方法进行了深入的研究。本文的工作内容主要包括两个部分:复杂背景下的多目标物体识别,基于二维、三维信息融合的物体6D姿态估计。1、复杂背景下的多目标物体识别。机器人与外界交互的首要任务是从复杂的环境中识别出目标物体。语义分割作为一种像素级别的物体分类方法,除了可以检测到目标物体外,还可以沿着轮廓准确地分割出物体,从而更好地处理遮挡问题。此外,在卷积神经网络中,不同尺寸大小的特征不仅具有不同的感受野,而且通常包含互补的信息。因此,本文提出的语义分割网络的主要创新点是提出了一个多尺度特征融合模块,以提高网络对图像的理解能力,从而提高网络的分割性能。2、基于二维、三维信息融合的物体6D姿态估计。物体的6D姿态估计方法的输入类型主要有三种,RGB图像、三维数据(点云或深度图)、RGB-D数据。通常来说,RGB图像可以提供丰富的纹理信息,但是不能提供物体的几何信息,所以在遮挡严重的情况下一般难以取得较好的效果;而基于点云或深度图的方法可以提供物体的几何信息,这对于规模较大的自动驾驶场景中的物体检测和姿态估计是有效的,但是对于室内这样的复杂场景,仅仅使用点云或者深度数据是不够的。因此,在这几类方法中,基于RGB-D数据的方法通常会有更好的效果,因为它既利用了纹理信息又利用了几何信息。而以往的基于信息融合的网络存在一些缺点:如在获取点云的几何特征时,没有充分利用点云局部领域信息以及特征融合方式过于简单等问题。为了充分利用RGB图像和点云这两种互补的多模态信息,本文提出的姿态估计网络进行了以下两点改进:(1)使用动态图卷积EdgeConv提取点云中蕴含的几何特征,充分挖掘点云的领域信息。(2)提出一种多模态特征混合融合的方式将这两种特征更有效的连接起来,使网络在复杂环境下仍然能实现准确的物体6D姿态估计。
{URL}: https://link.cnki.net/doi/10.27822/d.cnki.gszxj.2022.000116
{DOI}: 10.27822/d.cnki.gszxj.2022.000116
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于全卷积网络的混凝土表面裂缝识别研究
{Author}: 谢昭
{Tertiary Author}: 张宁
{Publisher}: 西北农林科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 表面裂缝;计算机视觉;卷积神经网络;语义分割;特征量化
{Abstract}: 由于环境和荷载的影响,桥梁、道路和大坝等基础设施的退化速度正在加快,裂缝作为影响建筑物结构质量的主要缺陷之一,对其监测使建筑物保持良好状态至关重要。传统人工裂缝检测结果容易受到影响,不仅检测结果不可靠,而且费时。基于传统数字图像的混凝土裂缝检测的方式,对图像预处理技术要求高,且检测结果易受周围光照、噪声等因素影响。而深度学习中卷积神经网络中通过对裂缝边界特征提取,进而精确地识别裂缝,其检测效果具有良好的精度与鲁棒性。本文采用Seg Net神经网络模型进行混凝土表面裂缝识别,并对识别后量化进行了系统研究,得到裂缝特征参数量化方法。本文主要研究内容和结论如下:（1）本文基于深度学习模型对混凝土表面裂缝进行识别,以Seg Net模型为基础。利用图像增强与迁移学习解决图像训练集少的问题,在此数据集上进行5×10-5,1×10-4,5×10-4,1×10-3这4种学习率值进行对比,通过评价指标对比发现学习率为1×10-4时的识别效果最佳。并将Seg Net裂缝识别结果与FCN模型与Otus算法进行了对比分析,得出Seg Net模型识别的鲁棒性更强,检测结果更准确。（2）提出一种精确的裂缝特征参数量化方法,以实现裂缝面积、长度、宽度等信息的分析计算。首先将Seg Net模型分割后的二值图进行处理,对分割后存在部分噪点图像进行形态学去噪,通过Zhang-suen方法将二值图骨架化。对于复杂裂缝细化后周围可能存在大量毛刺,通过Matlab设定阈值长度进行毛刺消除,并对具有连接段的裂缝骨架采用分离算法进行断开。（3）基于深度学习的测量方法,本文对单钢筋混凝土梁进行试验测试。整个试验包括图像采集、区域裁剪、裂缝识别和参数量化。通过对裂缝区域从加载到最终破坏进行全程拍摄,在此基础上分别对梁最终破坏的裂缝静态分布与加载过程中裂缝动态分布分别进行量化计算。将裂缝分割结果与人工测量结果进行对比,验证了基于深度学习裂缝测量方法的准确性与实用性。
{URL}: https://link.cnki.net/doi/10.27409/d.cnki.gxbnu.2022.001388
{DOI}: 10.27409/d.cnki.gxbnu.2022.001388
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 智能汽车乘员监测系统（OMS）关键技术的研究与实现
{Author}: 符树敏
{Tertiary Author}: 严芬;母焰
{Publisher}: 扬州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 智能座舱;人机交互;OpenPose;Mediapipe;人体姿态识别;手势识别
{Abstract}: 近几年,随着计算机视觉和智能汽车的不断发展,智能座舱成为汽车市场继智能驾驶后又一火爆的发展方向。智能座舱又称为智能汽车乘员监测系统(OMS),它不仅包含了 ADAS辅助驾驶的一些技术,也提出针对乘客的多项关键新技术,例如情绪识别、遗忘物监测、姿态识别和手势识别等智能技术。驾驶汽车除了需保证驾驶员安全和满足驾驶员的安全外,也要对车内乘客的安全和乘车体验等方面予以保证。因此,根据智能汽车乘员监测系统定义,切实从乘客的安全和坐车体验的角度考虑,提出基于人体姿态识别技术和目标检测技术研究实现满足乘客的需求,拓展智能汽车乘员监测系统的关键技术体系,论文主要工作如下:1.针对儿童的高度一般不符合副驾安全气囊弹出的高度,会在车祸时对儿童造成不必要的二次伤害问题,提出了一种基于OpenPose人体姿态识别技术的副驾儿童辨别算法,实现对副驾儿童的预警功能。通过OpenPose姿态识别算法获取车内所有乘客的骨架关键点信息,利用传统图像处理的方法将副驾的乘客骨架信息分离处理;然后,通过二维坐标系与三维空间坐标系转换原理得到副驾乘车实际的坐高从而判断乘客的类别。2.针对车内乘客多媒体的人机交互功能需求,提出了一种基于Mediapipe手部关键点检测的车内投影手势交互算法,实现了乘客在车内进行人机投影交互完成部分多媒体功能。通过投影仪和相机相结合,投影仪在后排车顶投屏,相机获取后排车顶地图像,乘客在后排车顶做点击或者拖动投屏上的虚拟按键,利用本文提出地基于Mediapipe手部关键点检测的车内投影手势交互算法将乘客的手势分析出来,并产生对应响应的信号传输给车机系统,触发对应的功能。3.基于本课题智能汽车乘员监测系统(OMS)关键技术研究成果,结合智能汽车乘员监测系统的其它功能和需求,设计并实现了智能汽车乘员监测系统。使用TCP通信方式和多进程编程模式,对课题研究成果进行可视化的展示,为智能座舱研究发展做出一定的贡献。综上,本文针对汽车舱内乘客的安全以及人机交互的现实问题,提出了结合人体关键点特征实现乘客坐高分析和手势投影交互两种算法,并集成到智能汽车乘员监测系统中,根据实际的驾驶场景做出严谨的评估分析。最终根据大量的实车场景数据验证了算法的有效性。
{URL}: https://link.cnki.net/doi/10.27441/d.cnki.gyzdu.2022.002051
{DOI}: 10.27441/d.cnki.gyzdu.2022.002051
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 复杂道路背景下的目标检测算法研究
{Author}: 王鹏飞
{Tertiary Author}: 黄汉明
{Publisher}: 广西师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;目标检测;复杂背景;自动驾驶;YOLOv5
{Abstract}: 汽车保有量的快速增加方便了人们的出行,但随之而来的道路拥堵、交通事故伤亡等问题也日益严重。近些年来随着人工智能的快速发展,汽车自动驾驶技术成为了解决传统汽车道路交通问题的重要技术,受到了越来越多企业及国家的重视与研究。目标检测算法作为自动驾驶系统的基础和重要组成部分,需要快速而准确地识别并定位目标,在一般的道路背景下,现有的目标检测算法已经可以胜任,但在复杂的道路背景下,由于目标多而杂,且距离和角度变化大,会存在着密集目标的遮挡问题以及小目标检测问题,容易造成误检和漏检,给现有的目标检测算法带来了极大的挑战,与此同时,自动驾驶系统的复杂度越来越高,给硬件也带来了很大的负担,因此,将目标检测算法设计地更加轻量化具有重大的现实意义。本文以基于深度学习的目标检测算法为基础,对复杂道路背景下的目标检测算法展开研究,具体研究内容如下:(1)针对复杂道路背景下的遮挡目标和小目标导致的误检、漏检问题,本文以YOLOv5s算法为基础,首先引入Quality Focal Loss,将分类得分与位置的质量预测结合,使得改进后的损失函数在保证原始Focal Loss能够平衡正负、难易样本特性的同时,还能够处理连续的标签值,无损提高了检测精度;其次增加一层浅层检测层作为更小目标的检测层,将原始算法的三尺度检测改为四尺度,特征融合部分也作相应改动,提高了算法对小目标特征的学习能力;然后借鉴Bi FPN的特征融合思想,提出了去权重的Bi FPN,充分利用深层、浅层以及原始的特征信息,加强了特征融合,进一步减少卷积过程中特征信息的丢失,提高了小目标的检测精度;最后为了进一步提升算法的特征提取能力,引入CBAM注意力机制,通过实验探究,将CBAM注意力模块嵌入算法的检测头前,让算法更关注有用的信息。(2)针对复杂道路背景下目标检测算法不够轻量化的问题,本文同样以YOLOv5s算法为基础,首先保留对Focal Loss以及对多尺度检测的改进,保证了算法有较高的检测精度;其次,借鉴Ghost Net,通过实验探究,将原算法Neck部分的Bottleneck替换为Ghost Bottleneck,在保持检测精度的前提下,减小了算法模型的体积,减少了参数量和计算量;然后将原网络的Backbone部分替换为Mobilenetv3,进一步轻量化算法,提升了算法在CPU环境下的检测速度;最后将算法进行一系列格式转换,成功嵌入树莓派视觉小车,实现算法落地。
{URL}: https://link.cnki.net/doi/10.27036/d.cnki.ggxsu.2022.001512
{DOI}: 10.27036/d.cnki.ggxsu.2022.001512
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 海洋浮游动物原位图像智能识别算法设计与嵌入式系统实现
{Author}: 杨振宇
{Tertiary Author}: 李剑平;陈世峰
{Publisher}: 中国科学院大学(中国科学院深圳先进技术研究院)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像识别;机器视觉;嵌入式部署;海洋浮游动物;原位观测
{Abstract}: 海洋浮游动物广泛分布于海洋之中,与人类生活密切相关。近年来,浮游生物原位成像技术的发展极大地提升了原位图像的获取效率。利用计算机和统计分析技术实现对海洋图像的自动化识别也引起了广泛关注,在一些已有的浮游生物闭集分类工作中也展现出了良好的效果。然而,自然海水下的浮游动物识别仍然面临诸多挑战:自然海水中物体构成极其复杂,难以穷尽,对浮游动物的识别不可避免地会遇到开集问题;浮游动物的数量分布天然不均衡,并时刻处于动态变化的过程中;自然海水中大量的非浮游颗粒物,也会对浮游生物的识别产生干扰等。这些因素往往会造成识别算法在实际应用中效果的显著下降。基于此,本文以实现自然海水下的浮游动物识别为目标,分别对原位图像预处理、浮游动物图像识别、基于嵌入式平台的识别算法的部署实现展开研究。在原位图像预处理中,本文设计了一套预处理流程来提取其中符合观测条件的目标。对于目标定位问题提出了一种基于滑动窗的目标定位算法,在定位高浊度海水下的低亮度目标时也取得了很好的效果。对于浮游动物图像的聚焦评价,本文分别提出一种基于边缘梯度特征和一种基于卷积神经网络的算法,在评价效果和计算速度上实现互补。为了缓解自然海水中浮游动物识别面临的数据不均衡、数据集漂移、开集等问题,本文提出采用图像检索的方式进行浮游动物识别。在对比学习有效的训练方式和暗场彩色图像很好的图像质量的共同作用下,该算法取得了优秀的表现。相比于常用的分类方法更加灵活便捷,能够满足多种原位观测的应用需求。最后,在算法设计的基础上,本文在嵌入式平台上实现了算法的部署,完成了原位图像处理程序的设计与神经网络的加速优化。有效地避免了传输图像对通信的压力,能够满足原位实时观测的需求。
{URL}: https://link.cnki.net/doi/10.27822/d.cnki.gszxj.2022.000117
{DOI}: 10.27822/d.cnki.gszxj.2022.000117
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的螺丝孔检测与锁付系统研究
{Author}: 邵坤
{Tertiary Author}: 沈满德
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;手机中框;模板匹配;螺孔识别定位;锁付系统
{Abstract}: 自动螺丝机在生产组装过程中最关键的步骤之一就是实现工件中螺丝孔的锁付,而准确识别出螺丝孔并精确定位其中心坐标是完成螺丝孔锁付功能的核心。对于产品背景复杂的螺丝孔进行锁付时,示教型螺丝机需要人工识别,提前给定螺孔坐标,其操作步骤繁琐复杂,且螺孔定位误差较大;传统视觉型螺丝机对相似的干扰螺孔难以正确区分,造成锁付准确率偏低,误检情况严重。所以针对上述问题,本文以某型号的手机中框作为研究对象,设计了一套基于机器视觉的螺丝孔检测与锁付系统,对手机中框上的螺丝孔进行准确识别和精确定位,最后完成对螺丝孔的锁付功能。主要研究内容如下:首先,介绍了国内外自动螺丝机的研究现状和螺丝机系统中机器视觉的应用,确定了基于机器视觉的螺丝孔检测与锁付系统的总体方案,对系统的硬件设备、环境搭建和软件界面平台进行了设计,并选择了适合本系统的设备型号。然后,研究了图像滤波、图像增强、图像分割等图像预处理算法,对比了不同增强、去噪滤波算法用于手机中框图像的处理效果。首先采用线性灰度变换算法增强手机中框上螺丝孔的对比度,再采用中值滤波与均值滤波组合的滤波算法去除图像噪声和平滑图像,最后采用基于均值的局部动态阈值分割算法分割出包含全部目标螺孔的疑似区域。其次,针对目标螺孔识别问题提出了基于区域组合特征和形状模板匹配的目标检测识别算法,对疑似区域进行组合特征选择,生成单一的矩形区域同模板进行比对,实现目标螺孔的识别。针对目标螺丝孔定位问题提出了基于亚像素级边缘检测的定位算法,提取目标螺孔的亚像素级轮廓,保留规则的轮廓再利用最小二乘法进行圆拟合,计算拟合圆心坐标的均值,即定位目标螺孔的中心坐标。最后,研究开发了视觉软件系统,设计了人机交互界面,并对系统进行实验测试。实验结果表明,本系统对手机中框中螺孔识别的平均准确率达到93%,定位的螺丝孔中心坐标误差在0.2mm,实现了对复杂背景下手机中框上螺丝孔的精确锁付,基本满足工业生产要求。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2022.000267
{DOI}: 10.27698/d.cnki.gwhxj.2022.000267
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 苹果树叶病害图像分割与识别研究
{Author}: 杨翠玲
{Tertiary Author}: 林和;韩立刚
{Publisher}: 兰州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像识别;深度学习;病害识别;卷积神经网络;Softmax
{Abstract}: 目的——近年来,许多植物病害给世界务农人群带来了痛苦,估计每年造成全球农作物产量减少14%。植物病理学旨在提高植物在不利的环境条件和能引起病害的寄生微生物下的生存机会,温度、p H值、湿度和水分是影响植物病害发生的环境因素。而植物病害种类的误诊会导致化学品滥用,一方面造成经济损失,环境失衡和污染,另一方面产生耐药性原体菌株,从而给农民增加更大的负担。目前对于人类检测的疾病诊断是耗时且昂贵的,基于植物叶片图像的病斑自动分割与诊断比现有的方法更加有效,为此,本文将采用深度学习的方法来完成苹果树叶病害图像分割与识别研究。方法——植物病害识别包括图像采集、预处理、分割、特征提取以及基于一些模型的识别。使用深度卷积神经网络模型,从苹果植株叶片的图像中检测出苹果植株病害,并将其准确分类为6类。识别类别包括“健康”、“炭疽叶枯病”、“灰斑病”、“锈病”、“斑点落叶病”、“多种病害”。本文利用图像增强技术,即图像旋转和翻转、直方图均衡化、色彩变换等技术,对苹果树叶病害数据集进行了改进。基于增强后的数据集,提出了一种新的CNN网络模型用于苹果树叶病害图像分割,以及改进VGG网络模型用于苹果树叶病害识别。研究结果——将苹果树叶病害图像数据集通过图像增强技术进行处理,通过图像分割技术以及改进所提出的卷积神经网络模型;利用卷积神经网络分割的图像数据集训练改进的CNN网络模型,最终得到准确率较高的CNN模型,并在此模型基础上设计并实现苹果树叶病害图像识别系统,使得模型具备现实使用价值。研究的局限性——苹果树叶病害图像数据集中的图像种类和数量是定量的,改进的模型只能对提供在研究范围内的苹果树叶病害种类进行有效识别,而这只能象征苹果树叶最常见的几种病害的情形,对于数据集以外的树叶病害种类不确定能够准确识别;在系统应用中若图像的背景更为复杂,是否还能分割并准确识别,有待验证。实际影响——相对于传统方法来说,将深度学习应用到苹果树叶病害图像分割和识别中,不仅可以提高分割和识别精度,还能简化对应的分割和识别流程,获得较优的模型,解决了果农在种植水果时预防工作强度大、耗费时间长、效率低下的问题。独创性——将苹果树叶病害图像数据集通过图像增强技术进行处理,经过特征提取实现有效分割来提升图像病斑的识别程度;用改进的CNN模型对分割后的图像进行识别,最终得到较高识别准确率的模型。
{URL}: https://link.cnki.net/doi/10.27204/d.cnki.glzhu.2022.003378
{DOI}: 10.27204/d.cnki.glzhu.2022.003378
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的铁轨异物检测方法研究及系统实现
{Author}: 冉祥良
{Tertiary Author}: 汤全武
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 轨道异物检测;深度学习;YOLO-v5;注意力机制;Bi-FPN
{Abstract}: 随着我国铁路运营里程不断增加,铁路覆盖范围变得非常广阔,使得行驶环境更加地复杂,铁轨作为行驶的路基,其异物入侵问题严重影响了行车安全。目前轨道异物检测主要是人工巡检与传统检测技术辅助排查,这些检测方式存在成本高和适应性低等不足,并不能很好的满足需求。本文提出了基于深度学习的铁轨异物检测方法,选取一阶段算法YOLO-v5进行铁轨异物的检测研究,旨在提高检测精度及检测速度。本文主要研究内容包括:第一,通过对图像去噪、均值化、翻转等常规处理,以及图像增强与扩充操作,完成轨道异物图像集的制作;第二,YOLO-v5网络s版本虽然检测速度快,但检测小目标性能较差,本文在网络的CSP模块中加入注意力机制增强特征提取能力和丰富特征信息,同时选用CIOU替换GIOU损失函数;第三,有些轨道异物与背景特征差异不明显,若是异物目标尺寸发生变化,不仅检测准确率降低,还可能出现漏检或误检问题,本文采用Bi-FPN特征融合方式对网络进行改进,提升特征信息融合的能力;第四,本文利用QT库设计了一套铁轨异物检测系统,通过加载权重模型和选取测试图片及视频,完成铁轨异物检测系统的测试。实验结果表明,通过对基础网络加入CA和CBAM机制的结果分析,加入CBAM机制的训练loss曲线收敛下降趋势更快,其模型精确率和mAP值均优于加入CA机制;基于Bi-FPN模式的检测网络相对于改进前,目标loss曲线下降幅度变得更陡,曲线收敛速度更佳,mAP值提升了1.1%,经测试集验证,其识别准确率提高了 0.92%。若目标尺寸发生变化,还可以识别出漏检的目标,本次所用服务器检测每张图片相比于改进前耗时减少约0.291ms。因此,本文通过一些改进方法可使得网络进一步提升检测性能。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2022.000351
{DOI}: 10.27257/d.cnki.gnxhc.2022.000351
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的图像去雾方法研究
{Author}: 朱东辉
{Tertiary Author}: 刘进锋;杨蓬勃
{Publisher}: 宁夏大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;图像去雾;编码器-解码器;对比学习;域偏移
{Abstract}: 随着信息化技术的飞速发展,多种多样的成像设备已经遍布到各个角落,好的成像质量成为信息化系统成功的重要前提。雾霾、烟雾的存在使得成像设备所获取的图像朦胧不清,直接影响着信息化系统对图像的进一步利用。因此,从有雾图像中恢复出高质量无雾清晰图像成为重要的实际需求,对去雾算法的研究有着现实使用价值。本文从去雾算法的发展历程和研究现状入手,研究图像去雾算法常用的理论知识和技术基础,对比了六种经典的去雾算法,发现经典去雾算法的一些优缺点,通过对比研究它们的去雾效果,总结出四条经验,为后续去雾方法的研究提供参考。针对经典去雾算法中总结出的经验,本文基于编码器-解码器结构,结合多尺度融合技术、特征注意力机制、可变形卷积和对比正则化,提出一个去雾网络C-DehazeNet。本文选用翻译网络CUT对数据集进行扩展,用于缓解域偏移问题。设计并实现了一个图像去雾系统,将本文研究的去雾方法集成到系统中。本文所做工作如下:1.梳理去雾算法发展过程中的主要算法演变过程,选择了其中较为经典的六种方法进行研究,通过各个网络自己对比及不同网络间的相互对比,分析它们的优缺点,总结出四条在设计去雾网络时可以参考的经验;2.提出C-DehazeNet去雾网络。使用室外训练集OTS训练网络,从主观角度对比优化网络和经典去雾算法的去雾效果,使用客观评价指标数值验证所提网络的有效性,通过消融实验证明C-DehazeNet各模块的有效性;3.大多数去雾算法使用合成数据集训练网络,所得模型对真实图像去雾效果不佳,这类在合成域上训练模型对真实域图像处理效果不好的现象称为域偏移问题。为缓解域偏移问题,本文使用图像翻译网络CUT,将有雾图像数据集相互翻译,用以弥合域偏移的鸿沟;4.设计并实现了一个电脑端图像去雾系统。系统集成了六种经典的去雾方法和本文提出的C-DehazeNet,用户可根据需要选择去雾方法及对应的模型进行去雾。本文使用RESIDE数据集中的室外训练集(OTS)和经过翻译的扩展数据集训练网络,使用真实有雾图像和综合目标测试集(SOTS)验证网络的去雾效果;选用峰值信噪比(PSNR)与结构相似性(SSIM)对去雾网络进行客观评价;对比去雾图像的色彩还原、对比度、亮度和局部细节恢复情况对去雾网络进行主观评价。
{URL}: https://link.cnki.net/doi/10.27257/d.cnki.gnxhc.2022.000317
{DOI}: 10.27257/d.cnki.gnxhc.2022.000317
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于轻量型神经网络的矿工不安全行为识别算法研究
{Author}: 程昱昊
{Tertiary Author}: 丁恩杰
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 行为识别;图像分类;轻量型卷积神经网络;动态卷积核;通道压缩
{Abstract}: 煤炭行业的发展对于国家能源的供应起着重要的作用。在以矿工为主体的煤炭行业中,由于职业操作不规范导致的煤矿事故严重影响着人员安全,因此对于矿工不安全行为识别的研究在降低煤矿事故率方面有着重大意义。如何在低光照等复杂的煤矿背景环境下精准识别矿工不安全行为成为解决该问题的关键,随着深度学习技术的不断发展,为矿工不安全行为识别算法的研究提供了新的机遇,但同时也带来了大量资源设备的消耗。由于深度卷积网络的复杂性以及矿井下的资源设备受限,基于深度学习的矿工不安全行为研究通常将井下边端设备采集的数据运输到云端进行分析与判别,从而导致判别过程存在延时,无法保证不安全行为识别的实时性。因此针对不安全行为的实时响应问题,对参数量较少的轻量型网络进行研究。本文具体工作如下:(1)针对矿工不安全行为的静态图像判别任务,提出了一种基于高效注意力机制的动态卷积核的方法,并将其应用于轻量化网络中进行不安全行为判别。通过动态卷积核来增加轻量化网络的特征表达能力;在动态卷积核的注意力机制中采用四种通道压缩的方法来解决卷积核内部存在的冗余问题,减少网络的参数量;采用自适应的下采样方法保留有用信息,提升网络判别图像的性能。(2)由于静态图像网络模型未考虑到时序信息,因此提出一种三维轻量化网络,并在视频集的行为识别任务上得以应用。将二维的轻量化网络改进成三维网络,不仅学习到时序的特征,也保证了模型的轻量化;并设计了一种基于注意力机制的三维动态卷积核,通过注意力机制能够提取网络中的重要信息,提升网络识别的性能。(3)为了进一步验证提出的网络模型在矿工不安全行为判别任务上的可行性,分别构建了矿工不安全行为静态图像集与视频集。通过将高效注意力机制的动态轻量型卷积网络在静态图像集上验证发现,其准确率相比静态网络提升了2.4%,参数量相比标准动态网络降低了20.17%,并将改进后的三维动态轻量型卷积网络在视频集上进行识别,由结果表明,其识别准确率达到88.58%,平均F1的值达到87.27%。该论文有图30幅,表24个,参考文献89篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000289
{DOI}: 10.27623/d.cnki.gzkyu.2022.000289
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的人脸检测算法研究
{Author}: 夏寒林
{Tertiary Author}: 刘争艳
{Publisher}: 阜阳师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 快速卷积神经网络;深度学习;人脸检测;异常行为检测
{Abstract}: 人脸检测技术研究是计算机视觉领域研究的热门之一。该技术是利用信息化手段对图片或视频等媒体中的人脸进行定位,并通过标签标记出其位置和大小。这项技术的发展是人脸识别算法研究的基础,直接决定着人脸识别算法的最终识别效果。但是,在实际的人脸检测过程中,常常受到检测场景复杂、面部遮挡、低分辨率、人脸偏转等人为和环境因素的影响,而导致传统的检测方法在现实环境中的应用不能达到精准、快速、实时的效果。近年来,随着人工智能技术的发展,特别是深度学习技术的应用给人脸检测技术在检测速度和精度等方面带来了革命性的变化,并且有了大幅度的提高。本文在深度学习理论基础上,对人脸检测算法进行进一步的研究,通过将深度学习算法理论应用到人脸检测算法中,分别对正常人脸和异常行为进行检测。主要内容如下:1、本文对传统的人脸检测算法、卷积神经网络以及基于深度学习的人脸检测算法进行详细综述。重点介绍MTCNN和S3FD两种代表算法。2、针对快速卷积神经网络算法在处理小人脸检测问题上存在检测准确度不高,速率低的缺点,本文对现有的基于快速卷积神经网络算法进行优化改进,提出了一种基于快速卷积神经网络改进的人脸检测算法。最终本文提出的算法在Wider FACE数据集和FDDB数据集上进行了验证,证明了算法在针对小脸检测问题时,取得了较好的检测效果。3、对快速卷积神经网络进行进一步深入研究并将其应用到视频异常行为检测中,提出了一种异常行为检测的算法。4、对本文的研究工作进行总结与展望。
{URL}: https://link.cnki.net/doi/10.27846/d.cnki.gfysf.2022.000258
{DOI}: 10.27846/d.cnki.gfysf.2022.000258
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 融合物体语义信息的移动机器人视觉SLAM算法研究
{Author}: 于源卓
{Tertiary Author}: 张洪;马歆
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 移动机器人;同时定位与建图;机器视觉;语义信息融合;深度语义地图
{Abstract}: 随着社会的进步以及科技的发展,移动机器人在人类丰富的生产生活中发挥着更加重要的作用。人工智能的出现对移动机器人的功能提出了更多样化的需求,自主定位与地图构建作为移动机器人必备的功能,引起众多学者的广泛关注。本文针对移动机器人同时定位与建图(Simultaneous Localization and Mapping,SLAM)精度差,构建地图信息单一的问题,将环境中物体对象语义信息提取并融入视觉SLAM,进行了融合物体语义信息的移动机器人视觉SLAM算法研究。首先,根据硬件条件以及所需满足工程要求,对比不同语义信息融合方法,选择最优方案,完成了本文研究内容介绍及整体方案设计。其次,设计了以RGB-D相机为传感器改进关键帧选择的视觉SLAM算法,实现移动机器人自身定位,完成位姿优化及地图构建。算法以ORB-SLAM2为基础,对RGB图像进行特征提取,对相邻两帧图像进行特征匹配,通过Pnp算法进行位姿估计,得到相机当前位姿。通过改进的关键帧选择算法选择合适关键帧,使用光束平差法以及牛顿高斯法进行后端优化并采用基于词袋模型的回环检测消除算法累计误差。使用TUM公开数据集进行实验,实验结果表明改进后的算法选择了更多的关键帧,具有更高的定位精度,能够完成位姿估计并准确构建稠密点云地图。然后,设计了基于深度可分离卷积及通道间注意力机制的改进YOLOv4目标检测与识别算法,进行二维图像语义信息检测。该算法采用CSPDarknet作为特征提取基础网络,通过空间金字塔池化(Spatial Pyramid Pooling,SPP)与路径增广网络(Path Augmentation,PANet)构建特征金字塔,将所得特征输入YOLO Head进行目标检测与识别。在此基础上添加通道间注意力机制,使用深度可分离卷积代替部分传统卷积,在提升目标检测与识别效果的同时,使得网络更加轻量化,适用于以CPU作为控制核心的移动机器人。使用Pascal VOC数据集进行实验,实验结果表明改进后的算法具有更高的检测精度、更小的模型参数以及更快的检测速度,满足语义信息提取要求。接着,设计了RGB图像分割算法以及语义信息融合算法,在二维图像中分割提取物体语义信息,并将其融入视觉SLAM,构建深度语义地图。图像分割采用Graphcuts与Grabcut两种算法相结合的方式,实现RGB图像的精准分割。通过信息一致性及视觉SLAM定位结果进行像素点逆运算构建深度八叉树地图,对目标物体进行语义标注并实时更新,将对象物体语义信息融入视觉SLAM,构建深度语义地图。使用TUM公开数据集进行实验,实验结果表明所设计算法能够将物体语义信息融入视觉SLAM,构建清晰明了的深度语义地图。最后,设计并搭建了移动机器人样机,通过所搭建移动机器人进行了视觉SLAM算法、目标检测与识别算法以及融合物体语义信息的视觉SLAM算法实验。实验结果表明,本文所改进的视觉SLAM算法在移动机器人运行过程中有着更高的定位精度并能够实现实验室稠密点云地图构建;改进的目标检测与识别算法具有更高的识别准确率、更轻量化的网络模型以及更快的检测速度;所设计的语义融合算法能够成功将实验室物体语义信息融入视觉SLAM,构建实验室深度语义地图。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000763
{DOI}: 10.27169/d.cnki.gwqgu.2022.000763
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于改进卷积神经网络的小目标检测方法研究
{Author}: 李文涛
{Tertiary Author}: 彭力;侯立功
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 小目标检测;卷积神经网络;边框回归;注意力机制;特征融合
{Abstract}: 目标检测任务作为计算机视觉基础任务之一,在无人机航拍、遥感图像、无人驾驶汽车等领域得到了广泛的应用。当前在目标检测中大目标的检测效果已经取得了较高水平,而小目标由于其分辨率低,包含的特征信息较少,且在卷积神经网络的传播过程中容易丢失信息,导致其检测效果较差。为了解决小目标检测过程中存在的上述问题,本文以SSD(Single Shot Multi Box Detector)目标检测网络模型作为基础展开研究,分别从以下三个方面来进行改进:(1)提出了一种新的边框回归损失函数算法NIo U(New-Io U Loss)。好的回归损失函数能优化网络模型参数,增强卷积神经网络的特征提取能力,对于特征缺乏的小目标检测非常重要。传统的边框回归损失函数容易丢失边框回归学习方向,本文加强对于多尺度目标的关注,基于预测边框和标签边框中心点距离和重叠面积比的回归算法进行改进,增加了宽高尺度损失共三种类型的惩罚项作为限制条件。通过实验发现,该损失函数使得模型能够正确回归,提高模型对小目标的检测精度,有效避免待检测物体漏检和误检等严重影响目标检测模型收敛精度的现象发生。(2)提出了一种基于多尺度通道的注意力机制算法。小目标特征信息少并且容易在卷积神经网络传播过程中丢失部分信息,本文采用注意力机制提高模型对于小目标特征的关注。针对一般通道注意力算法忽视空间信息获取的问题,本文首先对通道进行切分,将每个通道特征图上的空间信息进行多尺度特征提取,然后再从不同尺度特征图上获取通道注意力权重。该算法促进了各通道间信息交流,空间信息和通道信息的关联加强了目标整体特征对最终模型检测结果的贡献,解决了神经网络传播过程中小目标信息丢失的问题。(3)提出了一种改进的特征融合网络。由于小目标像素数量少,特征信息在下采样过程中容易丢失,本文设计了一种融合注意力机制的瓶颈模块,增加目标特征信息的交互,减少目标信息丢失。提出了一种融合高低层特征的特征融合网络,该融合网络有效的结合了卷积神经网络低层特征图的细节信息和高层特征图的语义信息,极大程度增强了小目标的定位能力,提高检测精度。为了验证本文所提出改进方法在实际应用场景中的性能表现,针对疫情防控情况下对于人们口罩佩戴检测的需求情况,设计并实现了口罩佩戴小目标检测系统,用于对输入图像中的相关人员口罩佩戴情况进行检测,可视化检测结果并进行记录。最后进行系统功能性测试验证了本文所设计检测系统的可行性与有效性。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000184
{DOI}: 10.27169/d.cnki.gwqgu.2022.000184
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的红外场景目标检测
{Author}: 秦鹏
{Tertiary Author}: 刘云峰
{Publisher}: 中国科学院大学(中国科学院光电技术研究所)
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 红外目标检测;特征提取;YOLO;嵌入式部署
{Abstract}: 红外成像系统以其全天时的特点而被广泛应用于智能驾驶、红外侦察、环境监测等诸多领域。随着GPU算力的提升和大型标注数据集的出现,使用深度学习的方法对红外目标检测进行研究具有重要意义。然而红外图像因其波长较长导致目标的轮廓边缘模糊,特征细节不明显,缺乏颜色信息,与可见光图像相比检测难度更大。事实上,尽管随着深度学习网络的飞速发展,红外目标检测已取得了很大进步,但仍存在以下问题:(1)现有的卷积激活结构在提取特征时缺乏灵活性,编码容量受限;(2)卷积神经网络主要对局部像素建模,未考虑全局像素之间的特征关系;(3)未充分利用红外目标相对背景存在的显著性,缺少位置信息注意力;(4)嵌入式平台部署时,网络推理速度较慢,不能达到实时检测。鉴此,本文开展了如下研究工作:(1)针对红外目标特征信息较少,普通的卷积网络结构特征提取能力欠佳等问题,本文在YOLOv3的基础上设计了Effi-YOLO网络。该网络以动态卷积激活结构灵活地根据输入特征调整卷积计算区域及权重系数,并根据计算结果采用与之适应的激活率。采用轻量高效的骨干网络进行基础特征提取,并使用具有显著性增强的感受野模块扩大模型感受野,建立新的目标位置损失函数,提升模型目标回归定位准确度。在FLIR数据集上进行测试,新模型相对基线算法YOLOv3模型大小缩减为33.3%,检测m AP提升了9.9%。(2)针对卷积神经网络只对局部像素建模,缺乏像素点之间的长程依赖信息,未充分利用显著性信息等问题,设计了DINet网络模型。DINet结合了Transformer的全局信息和卷积神经网络的局部信息,强化了特征提取和建模能力。图像输入阶段利用显著性预测网络生成了具有显著性目标信息的伪彩色图像。构建了新的感受野增强模块,在扩大模型感受野同时,增强目标区域内部显著性信息,并通过多层特征层融合结构进一步提升红外目标检测性能。在FLIR数据集上检测精度比YOLOv5-S提升5.5%;在KIAST数据集上漏检率比IATDNN+IASS低4.11%。(3)为了满足实际工程项目需要,构建了一个红外无人机数据集用于网络模型的训练与验证。选择轻量化的YOLOv5-S网络,在PC端训练好之后对TX2平台进行移植。为了进一步加快模型推理速度,在TX2上采用Tensor RT加速技术对移植的YOLOv5-S进行浮点计算优化和模型结构融合,成倍提升模型推理速度,最终推理速度达到58帧/秒,满足实时检测要求。综上,本文的研究通过高效的特征提取、自适应的动态卷积激活结构、双模态图像的特征增强有效提升了目标检测能力和红外系统的目标检测性能,在公开数据集及自建数据集上进行验证,结果表明算法相对基线算法有明显提升。
{URL}: https://link.cnki.net/doi/10.27543/d.cnki.gkgdk.2022.000064
{DOI}: 10.27543/d.cnki.gkgdk.2022.000064
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的医学图像分割算法与应用研究
{Author}: 普志方
{Tertiary Author}: 陈秀宏
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 医学图像分割;深度学习;卷积神经网络;Transformer;生成对抗
{Abstract}: 医学图像分析是当前研究计算机视觉的关键领域之一,其中医学图像分割的作用是确定感兴趣对象的二维区域或内部体素的集合,感兴趣对象一般包括器官及其子部分,这是计算机辅助检测的第一步。本文针对医学图像分割任务,基于深度学习的算法展开研究,在细胞核、肝脏和肺部图像分割数据集上进行实验,以提高医学图像分割的精度。主要研究内容包括:首先,改进一种基于卷积神经网络和编解码结构的细胞核图像分割算法(Att Inc Net)。以U-Net框架为基础,编码器部分整合了通道注意力SE(Squeeze-andExcitation)和空间条纹池化SP(Strip Pooling)。级联路径上设计了一种轻量级的多尺度模块,用以减少编解码之间的特征差异。解码器部分增加了一个能够提供多层次信息的侧边输出结构,并利用阶梯和损失监督训练。在细胞核图像分割数据集上的实验证明Att Inc Net相比于其它网络有更好的分割效果,但该方法没有考虑建模长距离依赖。然后,设计一种基于CNN-Transformer的混合双路肝脏图像分割算法(Hct Net)。卷积神经网络虽然能捕获局部特征,但无法在全局特征空间建立显式的长距离依赖关系。针对Att Inc Net存在的局限性,Hct Net兼顾了卷积和Transformer的优势,把原始的U-Net作为卷积链路用于提取局部信息,另外建立一条独立的transformer链路用于捕捉全局联系,于瓶颈位置将两者有效融合。在肝脏图像分割数据集上的实验证明Hct Net优于其它先进的网络,为后续的研究提供了一个简洁通用的基础框架。最后,改进一种基于生成对抗网络并结合了Transformer的肺部图像分割算法(Sct GAN)。大多数分割算法使用像素损失监督模型学习局部信息和远程联系,很难进一步提高医学图像分割的性能。Sct GAN以Pix2Pix框架为基础,生成器使用Hct Net,利用其强大的特征提取能力增强生成网络的性能。判别器部分设计了一个先卷积后transformer并输出多层次结果的网络,在不同程度的视野上进行评估,能有效提高判别网络的区分能力。在肺部图像分割数据集上进行实验,Sct GAN取得了较好的结果。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.001476
{DOI}: 10.27169/d.cnki.gwqgu.2022.001476
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的水炮消防机器人自动灭火行为研究
{Author}: 马辰昊
{Tertiary Author}: 赵永生
{Publisher}: 燕山大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 消防机器人;图像处理;机器视觉;射流轨迹;自动灭火
{Abstract}: 消防机器人可代替消防人员进入高危火场进行灭火救援任务,可大幅度减少人员伤亡,提高灭火效率。该论文针对现有消防机器人自主作战能力差、难以满足消防实际需求的问题,为消防机器人自动灭火行为提供新方法。在复杂多变的火场中实现机器人自主灭火作业困难重重,判断火源位置、准确打击目标、制定灭火策略等问题尤为重要。为此研究了多传感器融合的火灾感知系统,实现了火灾现场的火焰、温度等识别;研究了基于双目视觉的火源定位系统,实现了对火焰目标的空间定位;研究了基于机器视觉的消防水炮射流轨迹目标识别系统,实现了对水流落点的精准判断;最终完成了自动灭火作业。为研究火灾环境信息感知,所研究的消防机器人搭载热成像双光谱MINI云台。通过多阈值Otsu法、帧间差分法等方式进行背景分割、运动检测;根据火焰颜色的典型特征,使用基于RGB和HSV相结合的色彩模型判据,采用多特征判据相结合的方法识别火焰目标。基于数字图像处理技术建立火焰目标样本集,借助卷积神经网络进行训练。采用YOLO目标识别算法对图像内容进行预测,实现对火源位置的准确判断,大大提高了火灾感知系统的鲁棒性和并行性。为研究消防水炮射流轨迹及落点位置,分析射流轨迹变化的主要影响因素;建立了射流轨迹模型;通过提取射流曲线,推算出落点坐标和射流范围;通过第一人称视角的图像处理,借助角点检测和机器学习中k-means聚类算法进行水流落点的位置判断,为自动灭火行为提供信息支持。基于双目视觉原理,判断火源与水流落点的空间位置信息。依据所识别的火焰目标和水流落点图像,建立双目视觉相机坐标变换关系,利用所获得目标的二维坐标信息,判断火源目标与水流落点的相对位置关系,通过水炮摇摆与俯仰控制来实现在自动灭火行为。
{URL}: https://link.cnki.net/doi/10.27440/d.cnki.gysdu.2022.000097
{DOI}: 10.27440/d.cnki.gysdu.2022.000097
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的柑橘果形在线测控分选系统研究
{Author}: 王志宇
{Tertiary Author}: 文韬
{Publisher}: 中南林业科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;重心法;测控系统;嵌入式;圆形度;果径
{Abstract}: 柑橘作为湖南省主要的经济农作物之一,进入市场前需要对其外部果形品质进行检测与分选,根据柑橘果形品质的不同等级,将优质的柑橘售往鲜果市场,果形不合格的柑橘售往罐头或果汁加工工厂进行处理,从而增加柑橘在市场的经济效益。目前,针对柑橘的产后果形检测,普遍采用人工分选或者使用简单的机械操控,存在检测精度和自动化程度低等问题。因此,本研究基于机器视觉技术和PLC控制技术,搭建了柑橘果形在线检测与分选控制系统;设计了多工位的视觉检测模块、水果输送模块和自动化控制模块;分析了多工位图像检测的误差,采用图像预处理和重心法识别柑橘的姿态并计算果形特征,进而结合分选控制算法,对柑橘进行在线测控和分选;经过速度对果形特征的影响试验和果形动态分选试验,验证了测控系统的快速、稳定、和准确性,具体内容如下:(1)搭建了柑橘果形在线检测与分选控制系统,完成测控系统中输送模块、视觉检测模块、自动化控制模块和通信模块的设计。在视觉检测区域内开设5个检测工位,增加了单目相机捕获动态柑橘果梗的概率,并对运动状态下的柑橘进行了受力分析。工业相机选用外触发拍照的模式,提高了测控系统动态捕获柑橘图像的稳定性。(2)通过对单目相机获取的多工位图像进行半径误差和形状误差分析,结果显示半径误差在1.8%以内,形状误差范围在2.71%-3.69%。视觉检测模块对获取的原始色彩图像,经高斯滤波降噪、图像灰度化和二值化处理后,采用重心法求出轮廓的零阶矩和一阶矩,从而计算柑橘果梗轮廓及其形心,判别两者在二维坐标系中的位置关系,选取柑橘果梗朝上且满足平面位置关系的果姿,计算柑橘的圆形度和果径特征。(3)通过自动化控制技术研发了嵌入式果形测控软件,实现了柑橘果形自动化测控与人机交互的功能。其中,通过对果杯下端固定支架遮挡光电传感器产生脉冲信号的个数进行统计,结合柑橘果形在线处理系统,将同一柑橘在不同工位下的果形特征信息汇总到该柑橘上。并且,针对系统中单点检测和多点控制的情况,设计了链式分选控制系统。根据不同速度下的柑橘果形检测试验,结合SPSS软件中的单因素方差分析,结果显示速度对柑橘果形检测结果与人工分拣结果无显著性差异(P>0.05),说明不同速度下该系统检测果形的稳定性较好。(4)系统通过不同分拣速度检测柑橘果形特征试验表明,不同输送速度下系统检测柑橘圆形度的平均误差范围为0.0031-0.0070,最大偏差变化范围为0.07%-1.71%。系统检测果径的平均误差范围为0.42 mm-0.56 mm,最大偏差变化范围为0.067%-2.27%。根据速度对果形特征的试验和果形特征检测试验表明,分级设备在每秒8个柑橘的检测速度下,设备的生产效率最高,单个柑橘的检测与分选平均耗时约为127 ms,柑橘果形综合分选正确率为93.00%,实现了在线快速、稳定、准确检测与分选的要求。本研究针对柑橘果形特征所设计的在线检测与分选系统,不仅提高了柑橘产后果形分选的效率,而且为其它水果的分选提供技术参考。
{URL}: https://link.cnki.net/doi/10.27662/d.cnki.gznlc.2022.000193
{DOI}: 10.27662/d.cnki.gznlc.2022.000193
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的矿井环境三维重建研究
{Author}: 周楠
{Tertiary Author}: 唐守锋
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;深度图修复;点云配准;三维重建
{Abstract}: 随着我国各个领域的高速发展,煤炭作为主体能源,其需求量逐年攀升。煤炭行业深入贯彻国家能源安全战略,逐步推动煤矿开采向无人化、智能化方向发展。煤矿井下的作业环境十分特殊,是一种结构化与非结构化交织杂糅的复杂地形环境,灾后的矿井场景完全属于非结构化环境。为保证煤矿智能生产机器人的日常工作和灾后救援机器人救援任务的顺利进行,迫切需要对煤矿井下受限场景进行三维环境重建。针对上述问题,主要的研究内容如下:(1)研究三维刚体运动以及关键坐标系之间的转换关系。针对相机畸变对图像数据的影响,采用张正友标定法,应用MATLAB标定工具进行标定实验,计算相机内参和畸变系数,减小了相机畸变对图像数据的影响。(2)针对矿井环境照度低、尘雾弥漫等现象导致采集的彩色图像模糊不清问题,对比分析主流图像去雾算法,选用基于优化对比度增强算法对图像进行去雾处理。针对Kinect2相机采集的深度图像存在空洞、无法获取准确深度值的问题,提出一种改进FMM的深度图空洞修复算法。引入置信度因子并使用固定尺度邻域替换原修复邻域,当置信度较低时,根据图像特征连续性确定候选块搜索范围,利用相似性度量函数获取最佳匹配块,将最佳匹配块的中心像素值替换至待修复点完成修复。实验结果表明,相较于传统FMM算法,本文算法处理后的图像峰值信噪比提升了11.79%,能够完整修复空洞区域,避免物体边缘失真。(3)针对待处理的点云数据量较大以及随机采样点的几何特征不稳定的问题,提出一种基于改进采样一致性与迭代最近邻的两步式点云配准算法。首先,将采集的彩色图和深度图进行图像对齐,生成三维点云并进行点云预处理;然后,利用平均曲率精简点云数据,结合距离阈值与点云平均密度两个约束,生成几何特征更为丰富的特征点集与匹配点集,计算点集间对应点的变换关系进行点云粗配准;最后,将改进算法输出的点云变换关系作为迭代最近邻算法(ICP)的初值进行精配准,组成两步式点云配准算法。由实验结果可知,两步式配准算法具有较高的点云配准精度。(4)对基于机器视觉的矿井环境三维重建系统进行可行性研究,在实验室内搭建了矿井非结构化模拟环境以及矿井巷道模拟环境,分别对两种环境进行三维重建与精度分析。实验结果表明,针对矿井模拟环境所重建的三维模型符合真实场景,重建精度可达厘米级,验证了本系统在矿井特殊环境下的可行性。该论文有图64幅,表13个,参考文献88篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000258
{DOI}: 10.27623/d.cnki.gzkyu.2022.000258
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的产品包装缺陷检测系统研究
{Author}: 王双全
{Tertiary Author}: 雷萌
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;乳品包装;缺陷检测;YOLOv3
{Abstract}: 乳制品的生产程序主要包括收奶、杀菌、发酵、灌装、包装。由于设备故障、原料异常等因素,产品包装表面难免会出现不同程度的缺陷,产品外包装表面缺陷检测是生产过程中包装工段质量管控的重点。因此,开展产品包装表面缺陷检测研究具有重要的实际意义。目前,很多工厂对于包装缺陷的检测仍采用人工形式,导致了人工成本高、检测精度不稳定的问题,进而给乳制品的市场带来了质量投诉风险。伴随机器视觉技术的迅猛发展,为解决人工检测的缺陷,本文将机器视觉应用到乳制品生产过程中,研究了一种基于深度学习的乳品包装缺陷检测算法。围绕着该主题,本文主要工作内容如下:(1)针对缺陷检测的发展现状和本文研究对象所处环境及需求,分别构建了基于Faster R-CNN、YOLOv3和SSD目标检测算法的乳制品包装检测模型,进行了外观、吸管、封合缺陷问题的检测实验。经过结果对比分析,选择综合性能最高的YOLOv3算法进行改进优化。(2)针对YOLOv3网络对包装外观轻度变形检测精度偏低以及部分预测框定位不准确的问题,通过分析Darknet53结构和YOLOv3损失函数的计算原理,给出了以下改进方法:引入GIo U Loss代替原网络MSE Loss、增加104*104的预测层以及增加先验框数量。实验结果表明,改进YOLOv3算法模型的m AP提升了2.83%,缺陷AP平均值提升了5.8%,综合性能得到了优化。(3)针对本文改进后的YOLOv3缺陷检测算法及实际需求,设计了一款基于Py Qt5实现的操作系统软件,包含登陆、注册、图片检测、视频检测和实时检测,实现了乳制品包装缺陷的实时监测,拓展了其实际应用。通过对乳品包装缺陷检测的研究,缺陷识别效果得到了提升,m AP达到了93.7%,缺陷AP平均值达到了88.06%,基本满足了针对于外形、吸管、封合缺陷检测的需求,实现了对生产线乳品包装缺陷实时自动检测的初步探索。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000350
{DOI}: 10.27623/d.cnki.gzkyu.2022.000350
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 一种融合注意力机制的MobileNet-SSD目标检测算法研究
{Author}: 李奕霖
{Tertiary Author}: 林海峰;栾江霞
{Publisher}: 厦门理工学院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: SSD网络;Mobilenet网络;注意力机制;损失函数
{Abstract}: 目标检测算法是计算机视觉的核心基础,具有重要的研究与应用意义。随着深度学习的发展,计算机视觉领域也在各个领域发挥重要作用。但由于传统目标检测算法通常使用基于手工设计的特征进行分类,对于目标的多样性不能很好的兼容,并且深度学习目标检测算法大多采用的模型参数量大,计算速度慢,不能很好地集成在移动设备或嵌入式设备中。因此设计具有更高精度且速度更快的目标检测网络成为了学术与实际应用中亟待解决的问题。针对此问题,本文提出一种融合注意力机制的Mobile Net-SSD模型,采用轻量化网络模型Mobile Net,结合SSD检测网络进行目标检测。同时在模型中的6层特征层后融入注意力机制模块,提高检测模型精度。对比实验结果表明,改进后的Mobile Net-SSD网络相比VGG参数量下降了33倍,在融入CBAM注意力机制模块后,检测精度提高了1%。为了进一步提高精度,在回归损失函数上使用CIOU算法替代Smooth＿L1算法,将坐标关系与相对位置结合考虑,优化学习策略,提高训练效果。并且将预选框处理方式进行改进,采用框融合的Soft-NMS算法进行去重叠框算法,优化多目标重叠的检测性能。实验结果表明,改进后的算法模型检测精度提高了3%。同时对移动端或嵌入式设备不需要较大的计算量即可满足需求。在Pascal VOC2007和VOC2012数据集上的实验结果表明,该模型在识别精确度和检测速度上都获得了很好的性能,在GTX1080上检测速度可以达到60.9fps,m AP精度达到了73.6%。针对移动与嵌入式设备,对模型进行压缩,设计目标检测应用软件,进行实验。本文模型参数量小、计算速度快、识别精度高,可以更好地实现移动终端及嵌入式系统的进行检测。
{URL}: https://link.cnki.net/doi/10.27866/d.cnki.gxlxy.2022.000176
{DOI}: 10.27866/d.cnki.gxlxy.2022.000176
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的肉块分拣系统设计与研究
{Author}: 吴志
{Tertiary Author}: 宁萌;苏高峰
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 分拣系统;系统标定;图像增强;特征提取;控制策略
{Abstract}: 随着近年来肉制品行业迅猛发展,传统猪肉脯工艺中的手工摊筛已经成为猪肉脯行业快速发展的瓶颈,导致猪肉脯行业产能无法满足市场日益增长的需求。目前猪肉脯行业拟采用按纹理方向分拣肉块代替手工摊筛,分拣一般通过人工或示教机器人来实现。然而由于肉块温度低且纹理难以识别,员工长时间进行肉块分拣会造成手部冻伤与视力退化,而且该方式生产效率较低,同时传统的示教分拣机器人因无法识别肉块纹理而无法满足分拣需求。因此在充分调研国内外分拣系统和分析肉块分拣具体需求后,本文结合机器视觉与直角坐标型机器人设计了一款肉块分拣系统,并围绕其展开以下工作。(1)针对分拣系统的整体设计。首先根据肉块分拣的需求与问题,完成了肉块分拣系统整体方案设计;然后针对肉块特性搭建了图像采集单元与分拣单元;最后设计了分拣系统的软件模块,同时介绍了图像算法的处理流程。(2)针对视觉系统的标定。首先建立了视觉识别模型;然后使用Matlab与Halcon对相机进行标定,求解模型参数,结果表明Halcon求解的模型参数精度更高;最后研究了机器人与相机配置模型,采用Eye-to-hand模型对机器人与相机进行标定,得到机器人与相机标定参数。结合两次标定结果为后续肉块定位奠定基础。(3)针对肉块图像的增强与分割。首先由于单一的图像增强算法无法满足实际需求,提出了一种混合图像增强算法,实验表明该算法能够有效去除肉块图像中的噪声,同时让肉块纹理更加凸显;然后针对传统Otsu算法存在抵抗噪声能力差与效率低的问题,提出了一种基于改进遗传算法的Otsu图像分割算法(GA-OTSU),实验表明处理肉块图像GA-OTSU分割效果更好;最后采用形态学算法消除图像分割造成的孔洞与毛刺问题。(4)针对肉块的特征提取与控制策略的设计。在特征提取方面,首先使用常见的四种算子提取肉块轮廓,实验表明Canny算子提取的肉块轮廓最为完整清晰;然后针对肉块形状的特殊性,提出了基于最小外接矩形的定位原理,将肉块近似为最小外接矩形,通过求得矩形的特征信息来得到肉块的特征信息;此外针对肉块纹理分散问题,提出了一种基于Radon变换的纹理方向提取算法,提取肉块中纹理占比最大区域的纹理方向作为肉块的纹理方向。在分拣控制策略方面,首先提出了基于PID的动态追踪控制方法,实现机器人与传送带的同步跟踪;然后设计了传送带上肉块的实时定位方法,并且针对前后图像中出现重复肉块问题,提出了去重方法;最后针对分拣机器人追求高分拣效率而导致运行过程中产生震动和冲击的问题,提出了基于S型速度曲线的轨迹规划方法。(5)针对分拣系统的实验验证。首先搭建了整套分拣系统,然后使用不同大小模具进行分拣实验,验证了该系统分拣效果良好,但是最终成品由于肉块形状不规则导致仍存在细小孔洞问题。因此增加了喷浆装置进一步完善分拣系统,最后将完善后的成品与手工生产的成品进行品质对比实验。实验表明完善后成品率达到96%,各项指标评分均超过9.0达到行业标准,验证了分拣系统生产的成品质量与整套工艺均符合行业要求。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.001130
{DOI}: 10.27169/d.cnki.gwqgu.2022.001130
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于语义分割的芯片焊缝X-ray图像缺陷检测系统
{Author}: 吴忠卿
{Tertiary Author}: 李可;苏文胜
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 缺陷检测;机器视觉;语义分割;空间注意力;密集条件随机场
{Abstract}: 芯片产业是世界上技术最先进的行业之一。芯片封装是芯片制造过程的关键,通常使用金属焊料将保护壳焊接在基座上以保护内部芯片。由于芯片尺寸小、精度高,焊接时难以保证焊料填满焊接面,导致焊缝气泡的产生,造成保护壳失效。因此开展芯片焊缝气泡缺陷检测的研究意义重大。X-ray成像相较于可见光成像能够迅速获得芯片内部信息,更适用于芯片内部缺陷的检测。但其生成图像是多层芯片结构的叠加图像,具有对比度低、背景干扰大、缺陷特征不明显等特点,基于传统图像处理的缺陷检测方法难以实现对缺陷的精确提取,且泛化性较差。U-Net语义分割网络是近几年较受欢迎的图像语义分割模型,可以学习目标样本的形状、颜色、纹理和位置等信息,然后在待测图像中精确分割出目标区域。本文主要研究了基于U-Net网络的芯片X-ray图像焊缝气泡缺陷检测算法,并针对U-Net语义分割网络特征提取不足、分割边缘不清晰等问题进行了改进。在此基础上搭建了自动化的芯片X-ray图像缺陷检测系统,主要研究工作如下:(1)结合X-ray系统的成像原理,分析了利用X-ray检测获得的芯片图像的特征,根据图像特征具体分析了识别芯片焊缝气泡缺陷的难点。提出了利用直方图均衡化对原始数据进行特征增强,然后对增强后的数据进行人工标注,制作语义分割数据集,通过利用语义分割网络对图像中的气泡缺陷进行检测的方法,形成一套X-ray芯片缺陷检测系统。(2)提出了一种基于改进U-Net语义分割网络的芯片X-ray图像缺陷检测算法。将UNet语义分割网络模型引入芯片焊缝缺陷检测,利用Mobile-Net作为U-Net模型的特征提取网络,提高网络获取缺陷形状和位置信息的能力,减少模型需要训练的参数量,仅需较少的样本就能完成网络全部参数的训练。同时在Mobile-Net的低维特征提取部分引入空间注意力机制,有效提升网络对图像低维特征的提取能力;在Mobile-Net的高维特征提取部分引入空间金字塔池化模块,将网络的全局信息和局部信息融合。最后利用该模型处理芯片X-ray图像数据,取得了较好的效果。(3)为了处理芯片缺陷和背景像素样本不平衡问题以及缺陷边缘困难样本难以识别的问题,本文利用焦点损失对网络的损失函数进行优化,在网络的训练过程中将训练重点聚焦在缺陷样本和边缘困难样本上。针对U-Net模型解码器上采样层导致的特征信息丢失问题,在分类完成后引入密集条件随机场,结合像素点的像素值和所属类别信息对像素的分类结果重新评估,进一步提高了模型的分割精度。(4)为了将算法更好地应用于实际生产线,根据企业具体要求对芯片合格率进行判定,开发了一套集成了批量缺陷识别、焊接面识别、缺陷与焊接面宽度比测量、判断是否合格并生成检测报表功能的软件平台。针对后续可能需要对缺陷数据进行扩充的问题,开发了一套能够标注新增数据,再对网络进行训练从而更新检测模型的软件,从而可以对算法模型进行不断优化。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.001115
{DOI}: 10.27169/d.cnki.gwqgu.2022.001115
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的树上柑橘识别方法研究
{Author}: 张梓峻
{Tertiary Author}: 化春键;匡逸强
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 柑橘;机器视觉;图像增强;图像分割;目标识别
{Abstract}: 我国作为柑橘的重要原产地之一,已有4000多年的柑橘栽培历史。时至今日,柑橘已经成为我国种植面积最大、产量最高和消费量最大的水果。在柑橘产业当中,果实采摘是整个生产过程中劳动强度大、季节性强的一个重要环节,传统的人工采摘方式不仅效率低下,而且需要雇用大量的劳动力,产生大量的人力成本。研究基于机器视觉的树上柑橘果实识别方法能够为柑橘的自动采收工作提供关键技术,有利于提高柑橘的采摘效率,降低生产成本。主要的研究内容如下:(1)基于机器视觉的柑橘采摘机械手设计。基于对采摘机械手的工作需求与工作环境的分析,完成了基于机器视觉的柑橘采摘机械手整体结构的设计,对相机等重要硬件进行了选型与分析,完成了采摘机械手工作流程与控制系统的设计。(2)柑橘图像增强算法研究。为了解决自然环境中采集的柑橘图像受光照影响导致柑橘目标难以识别的问题,提出了两种有效的柑橘图像增强方法。针对光照分布不均匀的柑橘图像,在模糊集理论的基础上,结合图像的全局信息将像素划分为需要进行增强和抑制两类,再引入像素点周围的局部信息建立指数函数对图像进行增强。针对亮度过低的柑橘图像,在Retinex原理的基础上,将引导滤波处理后的V分量图像作为光照分量代入,通过计算分离出反射分量,使用改进的双边伽马自适应增强方法提高光照分量图像亮度,利用人眼对灰度的视觉特性对反射分量进行细节增强。两种图像增强算法均能有效改善对应柑橘图像的亮度信息。(3)绿色柑橘目标识别算法研究。为了解决自然环境中绿色柑橘目标难以准确识别的问题,提出了一种改进流形排序算法的柑橘目标识别方法。针对传统的基于图的流形排序显著性检测算法获得的显著图效果不够理想的问题,使用结合相对总变差和局部复杂度的方法提取更准确的前景种子,将提取到的前景种子与去除前景种子的边界背景先验显著图相结合进行流形排序得到最后的显著图。改进后的方法能够有效识别出绿色柑橘区域,识别准确率较改进前算法提升明显。(4)复杂场景下柑橘目标识别算法研究。为了解决复杂自然环境中柑橘目标难以准确识别的问题,使用基于回归的YOLOv3算法对柑橘目标进行识别研究。使用采集到的室外果园环境柑橘图像构建柑橘数据集,通过预训练方法提升网络的学习和识别能力,使用训练集对YOLOv3模型进行训练,并在测试集上进行实验与结果分析。实验结果表明,训练后的YOLOv3模型在测试集数据中的识别性能较好,能够有效识别出自然环境中的柑橘目标。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.000192
{DOI}: 10.27169/d.cnki.gwqgu.2022.000192
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的檀香紫檀木材识别方法研究
{Author}: 梁懿
{Tertiary Author}: 孙建平
{Publisher}: 广西大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 檀香紫檀;木材识别;计算机视觉;图像预处理;非约束图像识别
{Abstract}: 由于非法采伐和贸易剧增,木材资源尤其是珍稀木材物种面临重大威胁。准确高效的木材识别是实现合理有效地保护、管理和利用木材资源所要解决的重要问题。尽管计算机视觉广泛和深入的应用极大推动了木材图像智能识别的发展,但是目前基于计算机视觉的木材图像识别一般受成像环境的约束,只能在特定的图像采集条件下进行有效分类,难以满足高效识别木材的需求。并且,木材具有较大的变异性、较大的类内差异性和较小的类间差异性,因此难以提取有效的木材宏观图像特征。为了在非约束条件下正确识别木材宏观图像,即降低木材识别对采集环境的要求,本研究以宏观和微观构造特征相似的檀香紫檀、染料紫檀和胶漆树为研究对象,在图像增强和数据增强的预处理基础上结合传统机器学习和深度学习对木材进行识别。主要进行了以下研究工作:首先,针对木材图像非约束条件下难以识别的问题进行图像预处理。一方面采用图像超分辨率重建方法提高退化图像的质量,获取更多图像细节特征。另一方面采用数据增强方法扩大木材图像数据库,扩充识别模型训练时图像集的多样性。其次,利用传统机器学习方法构建木材纵切面的宏观图像识别模型。利用灰度共生矩阵、小波变换、方向梯度直方图、局部二值模式和视觉词袋算法提取的图像特征作为输入,然后采用线性判别分析、K近邻、支持向量机和人工神经网络算法进行木材图像识别,分析不同算法构建的识别模型的预测性能,并通过T分布随机邻域嵌入的可视化方法进一步验证图像特征参数的可区分性和图像预处理方法的有效性。研究发现基于加速鲁棒特征(SURF)的视觉词袋算法提取的木材图像特征最具区分度,将图像特征输入人工神经网络训练出的模型分类效果最好,三个不同条件下获取的图像集的识别精度分别为96.3%、88.9%和74.1%,经过图像预处理后达到96.3%、94.4%和82.4%。最后,利用深度学习方法构建木材纵切面的宏观图像识别模型。将Alex Net、VGGNet、Google Net、Res Net和Bilinear CNN用于木材识别,并分析了不同卷积神经网络(CNN)模型的识别性能。结果表明Res Net50为最佳识别模型,三个不同图像集的识别精度分别为97.2%、73.2%和56.5%。经过图像预处理后精度提高至98.2%、97.2%和81.5%,识别结果整体优于传统机器学习方法构建的木材识别模型。除此以外,还通过特征图可视化的方法展示了从CNN浅层提取具体特征到从深层提取抽象特征的过程,并采用梯度加权类激活映射图(Grad CAM)进行可视化分析发现图像预处理前后CNN在木材图像上的关注区域存在差异。综上,经过图像预处理后,利用计算机视觉构建的檀香紫檀木材识别模型具有较强的泛化能力和鲁棒性,能够在非约束条件下高效识别木材纵切面宏观图像。本研究为木材准确高效且无损的智能化识别提供新思路,具有较好的应用推广价值。
{URL}: https://link.cnki.net/doi/10.27034/d.cnki.ggxiu.2022.001120
{DOI}: 10.27034/d.cnki.ggxiu.2022.001120
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的对靶喷雾系统设计与试验
{Author}: 梁永安
{Tertiary Author}: 肖丽萍;王训杰
{Publisher}: 江西农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;精准施药;对靶喷雾;控制系统;节药率
{Abstract}: 我国是世界蔬菜生产和消费第一大国,目前蔬菜生产已经成为我国种植业中仅次于粮食的第二大农作物,然而蔬菜生产过程中病虫害不仅影响蔬菜外观,还影响其长势、产量及质量。目前,蔬菜病虫害防控仍大多采用化学农药,施药技术落后,在蔬菜行距、株距较大的情况下使用连续喷雾,喷头无法对靶施药,且施药次数较多,出现大量药液无效沉积且流失到空气土壤,农药利用率低且浪费严重,造成环境污染、叶面农药残留超标。针对以上问题,本文以大田白菜为作业对象,根据大田白菜显著颜色特征,设计基于机器视觉的对靶喷雾系统,将连续喷雾方式变为间歇性施药,喷头间距可根据实际作物种植行距自动调节对行,实现精准施药,有效减少农药浪费和避免污染环境。取得如下主要研究成果:(1)设计了对靶喷雾系统行走底盘。对靶喷雾系统行走底盘包括车架、行走轮、转向机构和喷雾工作部件,喷雾工作部件由喷头间距调节机构、喷头高度调节机构及喷雾管路三部分组成。行走底盘采用电动轮和自动转向梯形机构,结合控制系统可实现远程控制自动行走,达到人车分离、人药分离的作业目标;喷头间距调节机构利用桁架杆结构的平行四边形框架特性来实现喷头喷雾间距的连续调节,实现对行施药的目的;喷头高度调节机构通过千斤顶结构和伸缩喷杆实现喷头工作高度的调节,满足不同高度作物的施药作业要求;喷雾管路药液经隔膜泵加压再由电磁阀控制喷雾。(2)开发了对靶喷雾控制系统的硬件电路和软件程序。以STC89C52单片机为控制核心,采用蓝牙模块建立移动设备与喷雾系统之间的无线通信,且在智能手机上设计了喷雾底盘通信界面,可以发送指令控制喷雾底盘行走和调节喷雾参数,还可以显示喷雾底盘行走速度和药箱液量信息;采用PCF8591模块输出模拟信号实现行走轮速度的调节,通过AD模拟输入通道结合传感器实现行走速度和药箱液量信息的采集;驱动电路实现微处理器对电机、电推杆、隔膜泵、电磁阀、电动轮等执行元件的控制;应用Open MV视觉模块实现作物靶标的识别,根据靶标方位等信息控制喷雾装置自动对行对靶施药。(3)研究了绿色作物的图像识别与分割算法。对不同颜色因子和阈值分割方法的图像分割效果进行了分析,提出了一种基于高斯双边滤波和超绿算法的大田白菜图像分割方法,可实现不同光照条件下白菜图像的准确分割,且基于边缘检测提取了大白菜轮廓和中心点特征。(4)测试了对靶喷雾系统性能。为测试对靶喷雾系统的性能,对其控制系统响应时间、对行误差、雾滴分布均匀性及田间实际喷雾效果进行了测试。结果表明:控制系统响应时间为344ms;作物行距45、55、65cm对行偏差分别为7.6,8.2,7.2mm;喷雾系统行走速度、喷雾流量、喷雾距离对雾滴分布均匀性影响显著,通过二次旋转正交试验确定最佳工作参数为行走速度0.39m/s,喷雾流量340.76m L/min,喷雾距离42.22cm,沉积变异系数最小为13.11%;与连续喷雾方式相比大白菜株距40、50、60cm节药率分别为6.13%、25.80%、37.04%。
{URL}: https://link.cnki.net/doi/10.27177/d.cnki.gjxnu.2022.000569
{DOI}: 10.27177/d.cnki.gjxnu.2022.000569
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 自然环境下脐橙果实快速识别与定位研究
{Author}: 熊正午
{Tertiary Author}: 戴仕明;汪彩华
{Publisher}: 江西农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 脐橙采摘;YOLO v3;Kinect v2;目标识别;三维空间定位
{Abstract}: 赣南脐橙具有味道芳香浓甜、果肉营养丰富等特点,是江西省特产水果之一,深受消费者喜爱,在赣南广泛种植。但目前脐橙采摘以人工为主,采摘期内劳动强度大,据统计采摘成本占到全部生产成本的30%～40%。本文采用计算机视觉技术,研究自然环境下脐橙果实的识别与定位方法,为脐橙采摘机器人研发提供研究基础,从而实现赣南脐橙的自动化和智能化采摘。主要研究内容如下:(1)自然环境下脐橙果实图像采集及预处理方法研究。根据项目实际需求,选择基于Kinect v2深度相机采集脐橙果实彩色图和深度图,在保证相机精度和稳定性同时,采集不同程度光照、不同拍摄角度的脐橙果实图像,确保识别模型训练时具有代表性。针对自然环境下脐橙果实的颜色特点,对比RGB、HSV和Lab三个颜色空间下脐橙果实图像和各分量图像进行对比,结果表明在RGB颜色空间下,脐橙果实的彩色图像与背景图像存在较大差异,综合三种颜色空间的对比结果,最终选择使用RGB颜色空间作为自然环境下脐橙果实彩色图像样本的颜色空间模型。为了去除自然环境下光照等噪声因素的干扰,对比中值滤波、小波和快速导向滤波的去噪效果,试验结果显示,快速导向滤波算法对脐橙果实图像去噪效果更好,明显能提高脐橙图像的对比度,突出特征信息。(2)脐橙果实识别模型构建及改进。使用YOLO v3目标识别算法并在其基础上进行改进,用于建立脐橙果实的识别模型。采用带有残差模块的Darknet-53作为特征提取网络,将多尺度融合的3尺度检测网络减少为2尺度检测网络,引入GIo U边界损失函数代替原损失函数,并使用DBSCAN+Kmeans聚类算法,对训练数据集聚类分析,优化预测分支的先验框尺寸,通过迁移学习方法进行训练。设计单果、向光、背光、果实重叠、枝叶遮挡5组测试集的对比试验,并与原始YOLO v3模型、SSD模型和Faster R-CNN模型性能进行比较。结果表明,改进后模型在5种环境下综合性能都优于其他网络,尤其在真实种植环境下识别准确率达到了91.22%,召回率为97.30%,F1平均值为94.16%,识别速率约为26.48fps。(3)基于Kinect v2的脐橙果实定位方法研究。为了实现脐橙果实采摘点的空间定位,介绍了四个坐标系之间的相互转换过程及转换公式,通过相机标定实验,使用张正友标定法,获取Kinect v2相机的内外参数和相关矩阵,对相机标定结果进行重投影误差分析,结果表明其平均重投影误差值处于误差允许范围内,满足实际应用条件。利用前述建立的脐橙果实识别模型,由彩色图和深度图配准,得到脐橙果实采摘点在相机坐标系下的三维坐标,并设计三维坐标误差实验,实验结果表明,改进后的YOLO v3模型结合Kinect v2传感器的定位相对误差在2%以内,能满足脐橙果实采摘点的三维空间定位要求。(4)脐橙采摘机器人识别定位系统开发。基于自然环境下脐橙果实的识别模型及采摘点的三维空间定位方法,开发脐橙采摘机器人识别定位系统。该系统基于Windows操作系统,利用Open CV计算机视觉库结合Qt5.10集成开发环境,系统功能模块主要包括:系统登录模块、图像导入与保存模块、图像预处理模块、脐橙果实识别模块、果实空间定位模块等,实现脐橙果实的识别与定位。
{URL}: https://link.cnki.net/doi/10.27177/d.cnki.gjxnu.2022.000471
{DOI}: 10.27177/d.cnki.gjxnu.2022.000471
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的刀具磨损检测方法研究
{Author}: 王鹏
{Tertiary Author}: 谷艳玲;陈长征
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像处理;机器视觉;刀具磨损;卷积神经网络
{Abstract}: 制造业的不断发展,带来了深入的技术变革,各行各业对制造业的需求也不断增加,其中精度和效率是制造业生产过程中重要的衡量指标。而所制造产品的精度和效率最主要体现在制造工具上。刀具作为制造加工中最重要的加工因素之一,在学术上一直有着很高的研究意义和价值。本文以高速铣削过程中刀具的磨损状态为研究对象,提出了一种基于机器视觉的刀具磨损检测方法研究。具体内容如下:基于刀具磨损检测技术现状、分类及存在的问题,提出了重点研究基于机器视觉中刀具磨损表面图像的刀具磨损检测方法,分析了刀具磨损形态的磨损过程和磨钝标准。针对获取的刀具磨损图像,通过灰度化、中值滤波和Canny算子等图像处理方法可以有效检测刀具磨损边缘,实现对刀具磨损图像的预处理。在图像处理的基础上,利用深度卷积神经网络在图像识别及分类的广泛应用,可以实现更轻松便捷的识别方法,避免传统检测方法中复杂的特征提取及计算。尤其是在少量数据集的情况下,通过迁移学习,利用已有的优秀网络模型训练出较高处理效率、较高准确率的网络模型。本文重点研究分析了卷积神经网络中的Alex Net网络和Res Net残差网络,微调Alex Net及Res Net18网络参数,通过全连接层的重建,利用铣刀刀具磨损图像进行迁移学习优化训练,并对这两个模型的训练效果进行分析对比。实现了新训练方法包括使用少量样本与全样本、预处理图像及未处理图像等对比,在少量样本的训练中Alex Net反而略优于层数较深的Res Net18;在较多样本基础上,大部分训练结果显示Res Net18的准确率略优于Alex Net。基于上述迁移学习的Res Net18网络,根据需求功能完成基于机器视觉的刀具磨损检测功能模块软件程序框架的设计与开发,利用Matlab以及其App Designer进行混合编程,设计了迁移学习网络模块、磨损图像及显示模块、图像预处理模块以及磨损类型智能识别模块,最终通过识别状态结果、识别率及识别用时给刀具在生产加工期间提供是否需更换的建议。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000805
{DOI}: 10.27322/d.cnki.gsgyu.2022.000805
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轴类零件检测系统的研究与实现
{Author}: 高宁
{Tertiary Author}: 岳笑含
{Publisher}: 沈阳工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;尺寸测量;HED模型;机器视觉;轴类零件
{Abstract}: 随着中国制造业现代化的迅速发展,各种机械设备对其零部件的精度需求愈来愈高。零件在制造过程中必然会形成各种质量问题和缺陷,如尺寸偏差、裂纹等。然而常规的人工检验方法不但效率低下,检测准确度也欠佳,且接触式测量容易划伤零件,很难保证品质控制的一致性。故本课题针对轴类零件尺寸质量检测的实际项目需求,研究并实现了一种基于机器视觉的轴类零件检测系统,以改善目前实际生产作业中的检测精度和检测效率等问题。本文提出的检测方案总体架构包含主要两个步骤,一是边缘检测,二是特征测量。其中面向轴类零件的边缘检测方法,给出了一种基于改进的HED深度学习网络模型的零件图像边缘检测方案,首先利用亚像素卷积技术改进了HED网络模型中的上采样方式;然后在模型训练完成后,再应用非极大值抑制以及双阈值处理方式完成HED模型输出图像边缘的后续处理;此外,为提高尺寸测量的准确度,再采用了改良形态学梯度技术的样条插值亚像素边缘检测技术处理边缘轮廓,进一步获得更加精细的边缘图像,实现了亚像素分辨率级别的图像边缘。面向轴类零件的特征测量方法,采用了利用定弦定角原理改进的霍夫变换圆检测算法以及亚像素角点检测算法进行边缘图像中特征尺寸的测量,进一步提高了轴类零件特征参数的测量准确度。基于上述的轴类零件检测方案,给出了相应的软硬件设计,其中:硬件系统设计方面,根据轴类零件的特殊形状及检测需求,设计了硬件系统的总体结构,对相机、镜头、光源、照明方式和运动控制系统进行了研究与型号选择,并进行了相机标定,保证检测系统能够获取清晰的图像资源;在软件系统设计方面,视觉检测系统采用C/S结构,使用QT开发软件和SQLite数据库进行开发设计,主要功能包括有工位任务设定、目标零件识别、尺寸参数检测、历史数据查询等。基于上述检测实验平台的搭建,对一种小型轴类零件进行了检测系统的验证,实验数据表明本文的检测系统能够有效检测出边缘特征并进行测量工作,测量精度最高可达0.001mm,为解决相关轴类零件的尺寸质量检测问题提供了参考,具有一定应用意义。
{URL}: https://link.cnki.net/doi/10.27322/d.cnki.gsgyu.2022.000483
{DOI}: 10.27322/d.cnki.gsgyu.2022.000483
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的食品包装印刷缺陷检测关键技术研究及应用
{Author}: 何昊
{Tertiary Author}: 尹健
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;食品包装印刷品;图像配准;缺陷检测分类;GA-BP神经网络
{Abstract}: 针对现有食品包装印刷品缺陷检测算法存在漏检率高、识别分类准确度低、实时性差等问题,对食品包装印刷制品开展了图像配准、图像缺陷检测、缺陷分类等算法研究,采用一种基于机器视觉的食品包装印刷缺陷实时检测技术,满足了工业现场生产实际要求,论文主要研究内容及成果如下:(1)总体设计。根据检测需求,提出了基于机器视觉的食品包装缺陷检测系统的总体设计方案,搭建了机器视觉检测的硬件系统,确定了印刷缺陷检测的流程。(2)相机标定与预处理。对相机进行标定确定了图像采集参数,并完成图像的预处理,经过多组实验对比,选择加权平均值法、高斯滤波、线性灰度变换和最大类间方差法分别完成图像灰度化、图像去噪、对比度增强、图像分割工作。(3)图像配准。结合霍夫变换求取边缘直线抗噪声好、精确度高的特性,针对其计算量大的问题,提出一种基于外轮廓与限制动态参数的霍夫变换相结合的图像配准算法。该算法利用轮廓信息进行图像粗配准,根据粗配准的先验信息,在ROI中利用限制动态参数的霍夫变化搜索直线,采用特定区域法对相交点进行配对,完成精配准。经过实验验证,该算法在精度和速度方面综合表现良好。(4)缺陷检测。针对阈值法制作检测模板阈值难确定的问题,提出一种改进的阈值法的检测模板制作方法;结合人眼视觉特点设计动态阈值图像差影法对缺陷图像进行二值化,并利用Canny算子和形态学处理剔除缺陷二值图中的边缘伪缺陷,利用形态学处理融合离散缺陷和去除孤立点。利用本文算法、差影法、分区域检测法与分层搜索法分别对印刷图像进行实验验证,结果表明本文算法在误检率和准确率方面表现最好,在漏检率方面有待提高。(5)缺陷分类。对游程编码进行研究,提出改进游程编码的缺陷标记算法,完成对缺陷区域的标记,并完成缺陷特征提取和数据预处理,制作印刷品缺陷数据集。为解决传统BP神经网络算法收敛速度慢、容易陷入局部最优的问题,利用遗传算法(GA)对BP神经网络初始权重和阈值优化。最后利用训练集分对BP神经网络、GA-BP神经网络、支持向量机(SVM)进行训练,再利用测试集进行验证,结果表明GA-BP神经网络拥有更好的分类效果。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.002295
{DOI}: 10.27047/d.cnki.ggudu.2022.002295
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉与质构检测的冷鲜牛肉新鲜度判别
{Author}: 张茹
{Tertiary Author}: 俞经虎
{Publisher}: 江南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 冷鲜牛肉;机器视觉;质地特性;BP神经网络;GoogLeNet
{Abstract}: 冷鲜肉品的新鲜度检测对解决食品安全问题、保障消费者权益、规范冷鲜肉市场有着至关重要的作用,而目前市场上肉品新鲜度检测方法主要是针对肉品中挥发性盐基氮含量的检测,此方法存在着周期长、成本高、操作复杂等缺陷,难以对流通、售卖中的冷鲜肉新鲜度进行检测。因此,为适应不同市场检测场景需求,以4℃密封贮藏的冷鲜牛肉为研究对象,提出两种冷鲜牛肉新鲜度检测方法,一种适用于对准确度要求较高的离线检测场景,通过构建图像-质构信息融合模型对冷鲜牛肉新鲜度进行判别,另一种能够实现冷鲜牛肉新鲜度的快速在线检测,使用卷积网络通过图像特征对冷鲜牛肉新鲜度进行判别。首先,对冷鲜牛肉进行新鲜度等级划分以及质地特性采集。对贮藏0-10天、4℃密封贮藏条件下的冷鲜牛肉进行挥发性盐基氮含量检测,依据国家标准规定,将冷鲜牛肉按照挥发性盐基氮含量划分为新鲜、次新鲜、腐败三类。使用质构仪对不同新鲜度的冷鲜牛肉进行质地特性检测并构建质地特性数据集。在质地特性数据集基础上将冷鲜牛肉的每个质地特性与新鲜度进行相关性分析,为后续新鲜度识别提供质地数据集基础以及理论上的可行性。其次,对不同新鲜度的冷鲜牛肉进行图像采集工作。基于任务要求进行工业相机、镜头选型以及照明设置,完成图像采集平台的搭建。以图像采集平台为基础,通过试验采集了660组在4℃环境下贮藏的冷鲜牛肉图像,使用MATLAB-GUI工具箱设计集图像处理与图像特征提取为一体的人机互动操作界面,用于开展图像处理、特征提取等工作,获取冷鲜牛肉图像特征数据并构建图像特征数据集。在图像特征数据集基础上将冷鲜牛肉的每种图像特征属性与新鲜度进行相关性分析,为后续新鲜度识别提供图像数据集基础以及理论上的可行性。然后,构建BP神经网络信息融合模型,提出一种基于图像信息与质构信息融合的离线冷鲜牛肉新鲜度检测方法。主要包括两个步骤:一是确定融合数据集,对所采集15个质地、图像特性进行主成分分析,选取累计贡献率99.84%的属性构成融合数据集;二是使用融合数据集对BP神经网络进行训练,并使用遗传算法对神经网络初始参数进行优化,优化后的模型对冷鲜牛肉新鲜度识别率为97.00%,研究表明,识别准确率相较于单一图像特征或单一质地特性有了较为显著的提高,融合模型具有较高的可靠性。最后,为适应不同的市场应用场景,满足快捷、实时的检测需求,提出了另一种基于机器视觉技术的快速检测方法。该检测方法将所采集的图像通过旋转、翻转、裁剪等操作进行图像数据集的扩大,又将迁移学习的概念引入到神经网络的训练中,试验结果表明图像数据集的扩大以及迁移学习能有效缓解小数据集在复杂网络结构上的过拟合问题,最终网络模型对冷鲜牛肉新鲜度识别率为92.80%,在保障一定准确率的同时,其优点在于能够实现更为快速的在线检测。
{URL}: https://link.cnki.net/doi/10.27169/d.cnki.gwqgu.2022.001190
{DOI}: 10.27169/d.cnki.gwqgu.2022.001190
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的结构振动检测研究
{Author}: 张雅泽
{Tertiary Author}: 潘存治
{Publisher}: 石家庄铁道大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 振动检测;计算机视觉;运动放大;运动估计;图像处理
{Abstract}: 振动检测在架桥机、桥梁等结构的故障诊断与健康监测中是至关重要的。理论上,结构存在损伤时,结构的柔度和承载力都会发生改变,其固有频率和模态阵型等模态参数也会发生变化。近年来,以计算机视觉为代表的非接触式检测方法开始成为结构振动检测领域的研究热点。与传统方法相比,基于计算机视觉的振动检测方法具有设备简单、无破坏性、测量范围广且不会改变被测目标的振动特性等优点。论文着重研究了基于相位的运动估计和运动放大算法,开发了基于视觉的振动检测系统,并通过实验对该系统进行了测试分析。研究内容包括以下四个方面:(1)总结了机械故障诊断的研究现状以及计算机视觉在振动检测中的应用。(2)对图像预处理技术进行了研究,重点研究了图像增强技术,主要包括图像灰度值增强、直方图均衡化、图像滤波以及RGB视频的降噪预处理等。(3)研究了视觉振动检测成像原理和检测流程。针对实际工程中的结构微振动,研究了无特征运动追踪技术和以光流法为基础的运动放大算法;对运动放大算法中基于欧拉视角的三种方法进行对比和实验,证明了基于相位的运动估计与放大算法既能对微小振动进行检测,且在噪声抑制方面效果也较好。(4)以LabVIEW和MATLAB为平台,开发了以相位运动估计和放大算法为核心的振动检测系统,完成了图像采集与文件管理、图像增强、振动分析、结果显示等模块的设计。分别针对简支梁和模拟箱梁开展了振动实验,检测结果与传统传感器检测结果进行了对比,结果表明,所开发的振动检测系统达到了设计要求。论文研究成果对结构振动检测具有推广应用价值。
{URL}: https://link.cnki.net/doi/10.27334/d.cnki.gstdy.2022.000308
{DOI}: 10.27334/d.cnki.gstdy.2022.000308
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于三维重建的蜜柚外部几何特征估测研究
{Author}: 林洋洋
{Tertiary Author}: 饶秀勤
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 琯溪蜜柚;三维重建;点云补全;机器视觉;外部几何特征
{Abstract}: 我国是世界上柚种植面积最大的国家,柚产量位居世界第一,但柚的分等分级仍依赖人工,费时费力,亟需提升商品化处理装备的检测水平与生产效率。本文以琯溪蜜柚为研究对象,研究了琯溪蜜柚三维重建与孔洞补全等关键技术问题,建立了基于三维模型的蜜柚体积、密度、纵径及横径估测方法。主要研究内容如下:（1）构建了用于蜜柚多视图三维重建的机器视觉系统。该系统主要由光照系统、旋转平台、图像采集装置及采集软件组成。实测了横向圆周阵列条形光源、穹顶环形面板光源、纵向圆周阵列条形光源及圆筒式均布面光源等4种光照方案的蜜柚表面平均亮度,分别为143.1、184.6、191.6、196.1,标准差分别为16.4、25.7、23.3、5.8,由此确定了圆筒式均布面光源方案,克服了蜜柚表面反光强烈引起的图像亮斑问题。选取了MV-CA013-20GC型工业相机及8 mm工业镜头,图像采集装置与采集软件实现了图像同步触发采集。（2）提出了基于双视角点云实现琯溪蜜柚实时重建方法。基于开发的蜜柚三维图像处理软件,实测了0.55～0.95 m深度距离下Azure Kinect DK、Real Sense D455、Real Sense L515及HLT003S-001等4种深度相机的平均残差波动和平均绝对距离误差,平均绝对距离误差分别小于1 mm、7 mm、3 mm、2 mm,由此确定采用Azure Kinect DK深度相机以双视角方式进行重建,以减少点云表面缺失区域,实现琯溪蜜柚实时获取与重建。（3）建立了琯溪蜜柚三维点云高精度重建与孔洞点云补全模型。基于构建的均匀光环境机器视觉系统,提出了基于标定码解决蜜柚点云尺度不确定性和重建精度评价方法,建立了多视图三维点云模型重建方案,实现了琯溪蜜柚三维点云高精度重建,重建模型点云精度误差处于-0.66～0.72 mm。采用MSN点云补全网络模型实现了蜜柚数据集孔洞点云的快速补全,平均补全生成速度为10.46个/s。（4）建立了基于三维模型的蜜柚体积、密度、纵径及横径估测方法。提出了基于最小有向包围盒及三角化凸包三维点云方法,以分析重建模型对蜜柚体积、密度、纵径及横径估测的影响。结果表明:精滤波点云、下采样点云及补全点云三者的体积、密度及纵横径估测值均与蜜柚实测值呈现正相关,体积平均相对误差分别为5.04%、3.91%和3.17%,密度平均绝对误差分别为0.031 g/cm3、0.025 g/cm3和0.020 g/cm3,纵径平均绝对误差分别为2.80 mm、1.69 mm和3.82 mm,横径平均绝对误差分别为2.51 mm、1.84 mm和2.47 mm。由此确定了补全点云可用于体积与密度估测,下采样点云可用于纵径与横径估测的方案。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001791
{DOI}: 10.27461/d.cnki.gzjdx.2022.001791
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于课堂视频的学生行为与专注度识别研究
{Author}: 朱睿
{Tertiary Author}: 莫建文
{Publisher}: 桂林电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 学习专注度;学生行为识别;目标检测;姿态估计;多任务学习
{Abstract}: 人工智能技术的快速发展促进教育领域改革的不断深化,人们开始使用智能化和信息化的处理方式对课堂教学质量展开评估。课堂是学生学习知识、接受教育的重要场所。学生作为课堂教学活动中的主要个体,他们在课堂上的行为变化是教学活动的直接体现,因此学生的课堂行为反映了学生的学习状态。在传统的观测方法中,研究人员通过课堂观测、问卷调查等途径来获取学生课堂行为信息。这种以人为主导的检测方法难以避免主观性,并且存在效率低、观测不全等问题,难以扩展到智能信息化课堂教学中。而基于深度学习的课堂行为识别方法虽然克服了传统方法的缺点,但也存在一系列数据和技术上的问题。比如,目前并没有针对学生课堂目标检测、行为的数据集,真实教室环境中深度学习算法易受到光线、遮挡、摄像头视角等因素的影响。针对以上问题,本论文主要开展以下工作:(1)构建学生课堂数据集。本文采集不同课程不同教室的视频数据构建了学生课堂数据集。构造的数据集由检测部分、姿态部分和行为部分组成。检测部分包括5,000个样本,每个样本含8到66个学生。姿态估计部分包括2,832个样本,每个样本包含关键点和物体目标标签。行为部分有3,173个样本,具体行为包括:读写、看黑板、玩手机、左右看、起立、举手和趴着。(2)设计了一种基于课堂教学视频的行为识别与专注度评价算法,根据学生课堂行为来计算学生的专注度。首先,输入视频经过采样、检测获取学生的位置信息;其次,利用跟踪分配方法,将课堂中的多目标视频转换为学生单目标的编号(ID)序列;最后将学生ID序列输入到基于部件注意力的行为识别网络中得到单个学生专注度得分,并利用加权融合的方式得到全体学生和整体课堂的专注度得分。此外,采用迁移学习的方式来改善样本量不足的问题。经过多次实验表明,本方法能够检测出单个学生和课堂整体专注度,并且基于部件注意力的行为识别算法检测精度达到85%以上。(3)设计了一种结合姿态估计和目标检测的多任务课堂行为识别算法,用于课堂视频场景中的学生行为识别。首先目标检测器从课堂视频的关键帧中提取单个学生区域作为算法的输入。然后多任务热图网络(MTHN)模块提取多尺度特征联合的中间热图,通过不同的映射关系将中间热图编码为姿态估计和目标检测任务的私有热图,进而获取关键点和物体位置信息。最后,利用行为向量和度量向量对课堂行为进行建模,并通过行为识别算法检测出学生行为。经实验表明,本文提出的行为识别算法在测试阶段表现良好,检测准确率达到90%以上。在算法精确度提高的情况下,学生和整体课堂专注度得分随时间变化的曲线呈现平滑的趋势。
{URL}: https://link.cnki.net/doi/10.27049/d.cnki.ggldc.2022.000969
{DOI}: 10.27049/d.cnki.ggldc.2022.000969
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的圈养鲈鱼智能决策投饵系统的研究
{Author}: 张镇府
{Tertiary Author}: 朱明
{Publisher}: 华中农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 水产养殖;机器视觉;智能投饵;深度学习;投喂系统;大口黑鲈
{Abstract}: 随着人们对水产品需求的不断提高,水产养殖规模不断扩大;同时物联网、机器视觉和深度学习等技术的应用使得鱼类养殖模式逐渐向智能化方向发展。在鱼类养殖过程中,合理控制饲料投喂量是节约养殖成本,提高经济效益的关键。目前鱼类饲料投喂方式主要为人工投喂和机械投喂,均难以依据鱼类生长情况和实际摄食信息做出相应调整,因此容易出现投喂不足或投喂过剩现象,影响鱼类养殖经济效益。通过研究鱼类摄食行为能够指导饲料投喂,但鱼类养殖环境复杂多变且难以控制,不同的养殖模式、多变的气候条件和人类活动等因素会影响鱼类摄食行为的识别,基于鱼类摄食行为的智能投喂仍存在一些困难。针对上述情况,本文通过研究水面大口黑鲈(Micropterus salmoides)摄食行为,设计了一种基于机器视觉的智能决策投饵系统,以实现室外圈养鲈鱼的智能投喂。本文主要研究工作和结论如下:(1)大口黑鲈食欲等级划分。在“零排放”圈养模式下搭建水上视频采集系统,采集鱼群摄食过程中的视频。通过结合生长投喂规律,对鱼群摄食过程中的行为进行分析,选取每轮投喂后第20～40s的视频作为数据样本,并将鱼群食欲等级划分为“强”、“中”、“弱”和“无”4个等级。(2)基于传统机器学习的鱼群食欲等级识别。依据划分的食欲等级,制作鱼群食欲等级图像数据集,经数据增强后的数据集共16000张图像。通过特征工程提取了17个鱼群摄食图像纹理、颜色和形状特征,并采用Fisher得分方法选择特征,得到的5个特征分别为对比度、逆差距、熵、相关性和能量,作为传统机器学习模型的数据样本。构建了包括K近邻、支持向量机、随机森林和Stacking的传统机器学习模型,并基于鱼群摄食图像特征进行训练。结果显示,在4个模型中,随机森林模型识别效果最好,其平均准确率、精准率、召回率和F1分数分别为83.65%、83.67%、83.65%和83.66%,平均识别速率为18.58帧/s。(3)基于深度学习的鱼群食欲等级识别。通过构建Res Net18、Shuffle Net V2和Mobile Net V3-Small深度学习模型,对比了3个深度学习模型对鱼群食欲等级的识别结果。结果显示,Mobile Net V3-Small模型总体识别效果最好,其平均准确率、精准率、召回率和F1分数分别为97.10%、97.11%、91.77%和94.37%,理论计算量为582.40MB,参数量为1.53MB,平均识别速率为32.06帧/s。为提高模型准确率,通过添加膨胀卷积层的方式改进Mobile Net V3-Small模型,改进后模型的平均准确率、精准率、召回率和F1分数分别提高了0.15%、0.15%、0.41%和0.28%。此外,对比了4种固定学习率和Cosine-Warmup学习率对模型识别效果的影响。结果显示,经Cosine-Warmup学习率训练得到的改进Mobile Net V3-Small模型平均准确率、精准率、召回率和F1分数分别为98.31%、98.31%、94.82%和96.53%,较最优固定学习率0.001模型分别提高了0.36%、0.35%、0.72%和0.54%。通过对比传统机器学习模型和深度学习模型对鱼群食欲等级的识别结果,最终选取经Cosine-Warmup学习率调整策略训练得到的改进Mobile Net V3-Small模型作为决策投饵模型,用于识别鱼群食欲等级,并指导饲料投喂。(4)智能决策投饵系统设计与试验。首先,设计并构建系统总体框架。然后,改进了小型池塘投饵机,将其控制系统改为Node MCU-8266控制系统,并验证其投喂精度能够满足试验要求。基于MQTT协议和阿里云物联网平台搭建了Wi-Fi物联网系统,实现了投饵机与计算机决策系统间的信息交互。此外,设计了一款系统图形用户界面,用于实现鱼类信息、视频画面展示以及相关投喂方案的远程操作控制,并建立了SQLite数据库,以保存和读取投喂数据。最后,为验证智能决策投饵系统的实际效果,进行了智能决策投饵系统试验。试验结果显示,相较于人工经验投喂,基于该系统投喂的鱼群饵料系数降低了0.03,增重率提高了0.11%,特定生长率相同,基于该系统投喂的鱼群整体生长情况优于人工投喂方式。该系统能够准确识别鱼群食欲等级,合理调整饲料投喂量并指导投喂,能够在一定程度上代替养殖人员做投喂决策,从而节约养殖成本,为室外集约化养殖模式下的鱼类智能投喂提供了参考。
{URL}: https://link.cnki.net/doi/10.27158/d.cnki.ghznu.2022.000791
{DOI}: 10.27158/d.cnki.ghznu.2022.000791
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的钢结构工件识别及定位系统设计与研究
{Author}: 赵晓山
{Tertiary Author}: 赵延治
{Publisher}: 燕山大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 钢结构;数据处理;数据库;机器视觉;工件识别;工件定位
{Abstract}: 目前国内的装配式建筑中,装配式钢结构建筑所占比例高、需求量大。建筑钢结构作为装配式钢结构建筑的主要组成部分,其产量和质量要求也在逐年提高。智能数据处理技术和机器视觉技术是目前传统制造业升级改造的热点技术,其中智能数据处理技术可以保证整条生产线的数据需求,维持整体的完整性和生产的准确性。而机器视觉技术则可以提高工件识别的准确率和效率同时节约人力成本。本文以钢结构生产方式改造为技术背景,开发了基于机器视觉的钢结构工件识别及定位系统。主要研究内容为:首先,根据建筑钢结构生产方式和结构特点,确定系统的功能需求,对整个系统所需模块和功能进行了设计。融合数据处理及数据库技术和机器视觉技术设计出了一套基于机器视觉的钢结构工件识别及定位系统。其次,利用MySQL数据库工具完成钢结构工件数据库的创建,并利用Python编程语言编写了钢结构三维数据XML文件解析程序,成功得到钢结构工件的特征信息、定位信息和利用模拟相机所拍摄的工件轮廓信息,将工件的最终定位信息转换成姿态矩阵、欧拉角和四元数存储进数据库内。然后,结合数据库数据和实际工件开发出基于机器视觉的自动识别和定位系统。利用Python连接工业相机完成了图像采集,针对实际工件图像设计了图像处理流程,实现了实际工件轮廓提取和特征信息提取;使用Python编程语言编写工件识别及定位算法,完成了待焊接工件的识别和定位。最后搭建了基于机器视觉的钢结构工件识别及定位实验系统。所搭建系统可以正确识别实验工件得到工件信息,确定工件位姿并传输至工业机器人进行抓取,同时得到该工件所在钢结构中的最终位姿。本文研究内容可为机器视觉在钢结构工件识别及定位的应用提供参考。
{URL}: https://link.cnki.net/doi/10.27440/d.cnki.gysdu.2022.001326
{DOI}: 10.27440/d.cnki.gysdu.2022.001326
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的果园病虫害识别研究
{Author}: 王铁伟
{Tertiary Author}: 杨然兵;宋来庆
{Publisher}: 青岛农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 深度学习;卷积神经网络;病虫害识别;MPest-RCNN;EResNet-SVM;系统设计
{Abstract}: 农业病虫害对农作物及其产品的危害极大,很多病虫害的分布范围广、数量多、繁殖速度快,只有尽早监测病虫害的情况,才能及时做出防治。为此,针对果园病虫害目标检测和分类过程中最常见的几类问题,研究了常见典型病虫害进行智能识别的深度学习方法,并通过实验验证了所提出的模型和方法的有效性。本文的主要研究内容可概括如下:1.针对已有目标检测方法准确率有待提高的问题,本文在建立了果园病虫害数据集的基础之上,通过改进卷积神经网络的结构和特征提取器等方式,同时利用数据增强、数据重组的技术,提出了基于Faster R-CNN改进的MPest-RCNN果园害虫识别计数新方法,解决了多种害虫因同时识别时个体差异较大出现的识别率低的问题。实验结果表明所提出的方法的识别精度达到了99.11%,对比实验证明了基于MPest-RCNN深度学习模型的果园害虫识别和计数方法的有效性。2.针对卷积神经网络在分类过程中存在一定程度的过拟合现象和传统分类器对非线性处理能力不足的问题,本文提出了基于Res Net18改进的残差网络果园病虫害分类ERes Net-SVM新方法,解决了训练过程中出现的过拟合和卷积神经网络特征提取不深入的问题。通过改进激活函数、加入残差模块和dropout层的方法有效缓解了卷积神经网络分类模型在训练过程中的产生的过拟合问题。实验结果表明,ERes Net-SVM对8种病害的识别准确率为99.3%,比原始的Res Net18模型提高5.9%,对6种虫害的识别准确率为100%,比原始的Res Net18模型提高3.9%。3.针对传统病虫害识别系统检测效率较低的问题,本文在研究典型果园害虫识别计数模型建立的基础之上,通过Python语言和Django框架开发了一个基于深度学习的果园害虫识别和计数系统。该系统能在计算机上简便高效的操作和运行,为接下来智能农业和精准农业的推广与应用提供理论与技术支持。
{URL}: https://link.cnki.net/doi/10.27203/d.cnki.glync.2022.000040
{DOI}: 10.27203/d.cnki.glync.2022.000040
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉可供性研究综述
{Author}: 李云龙;卿粼波;韩龙玫;王昱晨
{Author Address}: 四川大学电子信息学院;成都市规划设计研究院;
{Journal}: 计算机工程与应用
{Year}: 2022
{Volume}: 58
{Issue}: 18
{Pages}: 1-15
{Keywords}: 可供性;深度学习;计算机视觉;机器学习
{Abstract}: 可供性是指在环境内物体所提供的一系列交互可能，描述环境属性与个体之间的连接过程。其中，视觉可供性研究即通过使用图像、视频等视觉数据，探究视觉主体与环境或物体交互的可能性，涉及到场景识别、动作识别、物体检测等相关领域。视觉可供性可广泛应用于机器人、场景理解等领域。根据目前已有的相关研究，按功能可供性、行为可供性、社交可供性三方面对视觉可供性进行分类，并针对每一类可供性检测方法按照传统机器学习方法和深度学习方法进行详细论述。对当前典型的视觉可供性数据集进行归纳与分析，对视觉可供性的应用方向及未来可能的研究方向进行讨论。
{ISBN/ISSN}: 1002-8331
{Notes}: 11-2127/TP
{URL}: https://link.cnki.net/urlid/11.2127.TP.20220527.1755.007
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的番茄检测方法研究
{Author}: 王冲
{Tertiary Author}: 杨公平
{Publisher}: 山东大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 番茄检测;形态学重构;阈值分割;Mask R-CNN;Swin Transformer
{Abstract}: 番茄营养丰富,是我国农业生产中种植最为普遍的蔬菜之一,但是人工采摘番茄是一项劳动密集而且耗时耗力的工作。随着科学技术的发展,农业生产中很多工作被采摘机器人取代。采摘机器人首先利用计算机视觉系统进行果实检测,然后根据检测结果引导机械臂进行采摘作业。其中,果实检测是采摘机器人的首要任务和技术难点,检测效果的优劣直接关系到机器人采摘的准确度和采摘效率。本文针对番茄采摘机器人视觉系统检测果实不准确的问题,开展了基于计算机视觉的番茄检测方法的相关研究,主要研究内容如下:(1)提出了一种基于形态学重构和阈值分割的番茄检测方法。首先分析了不同颜色空间的特征,通过R-G色差法得到番茄果实的色差灰度图,经过转换的色差图像能够显著地增强番茄果实和背景之间的对比度。其次对图像进行中值滤波和孔洞填充操作,去除图像中的噪点,消除细小的孔洞。然后基于形态学重构生成灰度特质均匀且易于分割的图像,再利用Otsu自适应阈值分割方法从图像中分割提取出目标果实区域。最后基于分割后的图像利用Canny算子提取果实边缘轮廓,通过霍夫变换拟合圆形轮廓,从而有效地检测出成熟番茄果实。(2)提出了一种基于Swin Transformer改进的Mask R-CNN模型,用于番茄目标检测。为了更好地提取特征,该模型采用Swin Transformer作为骨干网络提取特征,并采用多尺度训练技术进一步提升了模型的检测精度。该模型不仅可以识别图像中每个番茄的品种(正常番茄和樱桃番茄)以及番茄成熟阶段(完全成熟、半成熟和未熟),也可以准确地将番茄从背景环境中检测和分割出来。通过对比实验分析,该模型对番茄目标检测和实例分割的平均精度mAP分别为89.4%和89.2%。实验结果表明该模型分割的掩膜图像能够精准地拟合果实区域。
{URL}: https://link.cnki.net/doi/10.27272/d.cnki.gshdu.2022.005255
{DOI}: 10.27272/d.cnki.gshdu.2022.005255
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于双目视觉的焊缝识别与跟踪系统研究
{Author}: 张中正
{Tertiary Author}: 张华;孙小亮
{Publisher}: 南昌大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 双目视觉;Bouguet立体校正;图像处理;轨迹检测;焊缝跟踪
{Abstract}: 焊接作为制造领域中一种重要加工手段,以其可靠、稳定、低成本、适用于多种金属材料的连接等优点,被广泛应用在船舶、航天、汽车制造等工业领域。随着“工业4.0”的提出,制造业领域对焊接自动化、精准化和智能化提出了更高的要求。目前的焊接系统大多是非线性的,编程示教的控制方式缺乏对焊接过程中装配误差和焊件热变形的检测,焊缝轨迹容易出现偏差,焊接质量不佳。针对上述问题,设计了一套基于双目视觉的焊缝识别与跟踪系统,并对典型V型焊缝坡口进行焊缝跟踪实验。首先,介绍了系统的硬件组成,包括龙门架三轴移动平台、焊枪、双目视觉传感器和PC104+总线控制箱。设计了一种双目视觉传感器,并对传感器的硬件选型、结构参数和有效视场进行理论分析。其次,设计了双目视觉系统的标定算法,使用MATLAB工具箱标定了双目相机,使用Bouguet立体校正算法实现了特征点之间的匹配和三维重建,并且对双目相机的测量精度进行了分析。在相机内参已知的情况下,采用基于单特征点的位姿估计算法,简化了手眼标定模型,获得手眼标定结果。然后,设计了焊缝图像处理算法,主要包括ROI提取、图像形态学滤波、图像二值化、中心线提取。改进了焊缝拟合算法,在距离滤波的基础上,通过亚像素级角点检测和像素插补的方法,提高了焊缝拟合的精度。最后,将焊缝特征点的二维信息转换到基坐标系下的三维位置信息,对焊缝特征点进行拟合,完成了焊缝轨迹检测和焊缝跟踪实验。实验表明,焊缝轨迹检测误差在±0.6mm以内,焊缝过渡均匀,焊接质量良好,验证了双目视觉系统设计和图像处理算法的可靠性。
{URL}: https://link.cnki.net/doi/10.27232/d.cnki.gnchu.2022.002675
{DOI}: 10.27232/d.cnki.gnchu.2022.002675
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的自动喷涂系统设计
{Author}: 王先月
{Tertiary Author}: 潘松峰
{Publisher}: 青岛大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 喷涂机器人;机器视觉;轨迹优化;自动喷涂系统
{Abstract}: 在“工业4.0”和“中国制造2025”的推动下,工业喷涂领域的竞争也日益激烈,人们在追求自动化、数字化水平更高的产品的同时,也对外观提出了更高的要求。目前,喷涂行业仍面临喷涂效率低下、成本较高、喷涂质量不稳定的问题,并且在很大程度上仍依赖于熟练技术工人完成喷涂任务。当工件类型更换或工件在生产线上的位置发生变化时需重新示教喷涂轨迹,这种操作不仅降低了自动化水平,而且对工人的专业技能有较高要求。为了解决目前喷涂行业面临的问题,实现小型喷涂企业向设备自动化程度更高、喷涂质量更稳定、效率更高的方向平稳过渡,本文设计了一种基于机器视觉的自动喷涂系统。该系统能弥补喷涂行业的短板,在复杂环境中完成喷涂任务。本文主要工作如下:1.针对喷涂效率低、质量不稳定、工件位姿不固定等问题,将机器视觉引入到喷涂系统中,设计了一款基于机器视觉的自动喷涂系统。该喷涂系统主要由喷涂机器人模块、视觉模块、传送模块、RFID模块组成,并且完成了各个模块的选型和设计。在本文中,该系统虽然以一类车灯作为研究对象,但可适用于其它类型工件的喷涂,具有一定普适性。2.对车灯工件的识别定位和尺寸测量进行了研究。首先通过对比确定最合适的算法对图像进行预处理;然后利用Canny边缘检测算法提取工件边缘,以主轴和副轴与边缘的交点作为特征点,依据特征点求出变换参数进行模板匹配,从而实现工件的识别;最后利用相机标定对工件进行定位,利用测量系统获取工件尺寸,为喷涂轨迹规划提供保障。3.依据工件边缘的最小外接矩形,提出以最小外接矩形的顶点为起始喷涂点沿长边方形进行Z字型喷涂,明显提高喷涂效率。研究了三角分片方法,提出了基于交叉变异的粒子群算法的轨迹优化问题,由于复杂曲面分片方法计算量大、过程复杂,因此本文提出了针对平面车灯工件的分片方法,保证涂层全覆盖。本文通过建立喷枪和涂层增长速率模型,以涂层均匀性为优化目标,以实际涂层厚度与理想涂层厚度的方差为优化函数寻找最优解,确定了最佳喷涂效果时的涂层重叠距离和喷涂速度。4.喷涂系统在投入使用前,需要进行喷涂模拟实验。在Robot Studio软件中搭建了喷涂工作站并确定布局,将在Solidworks软件中建立的车灯模型导入喷涂工作站,把喷涂轨迹规划程序加载到控制器进行喷涂仿真实验。同时完成了喷涂机器人的工作空间和喷涂轨迹的仿真,验证了喷涂系统的可行性。
{URL}: https://link.cnki.net/doi/10.27262/d.cnki.gqdau.2022.001116
{DOI}: 10.27262/d.cnki.gqdau.2022.001116
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的水位检测算法
{Author}: 孙维亚;王达;许帅;汪京晔;马占宇
{Author Address}: 南水北调中线干线工程建设管理局;北京邮电大学人工智能学院;
{Journal}: 应用科学学报
{Year}: 2022
{Volume}: 40
{Issue}: 03
{Pages}: 434-447
{Keywords}: 水尺读数;计算机视觉;边缘特征;关键字处理
{Abstract}: 鉴于传统的水位读数方法误差大，成本高，需要一种精确、实时、鲁棒的智能水位检测算法来高效读取水位，为此提出了一种基于计算机视觉的水位检测算法以满足实际需求。首先对拍摄到的图像进行预处理和边缘检测以找出水尺位置，并通过仿射变换对水尺进行矫正。通过两种策略在水尺区域找到水尺关键字的位置，即关键字处理。然后对边缘特征进行投影并检测出水面位置。最后根据关键字处理结果和边缘特征计算得到水面高度。大量实验和实地测试的结果表明：所提算法在基于计算机视觉的水位检测、水尺读数等领域具有理论和应用的双重价值。
{ISBN/ISSN}: 0255-8297
{Notes}: 31-1404/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwvLvpChVaMSFt8NERvvBywtcUy4UcPT1oPGV1llrL3iSdY8TJFDBQMsfHWsDfA-mEtkZqLhSPHOih0o-FX_qgaRdYCVLZZH3SDkvSdlI-Wwqzfn6zFEtCyVugzA474KweElvPqOBlTFysk9Txr8PEsoVb3Ntedpx020UFhilK0jqQVD5eB150225z8m1b6Fyw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLOv3的纹理瓷砖缺陷检测
{Author}: 李泽辉;陈新度;黄佳生;吴磊;练洋奇
{Author Address}: 广东工业大学广东省计算机集成制造重点实验室;广东工业大学省部共建精密电子制造技术与装备国家重点实验室;科达制造股份有限公司切割技术事业部;
{Journal}: 激光与光电子学进展
{Year}: 2022
{Volume}: 59
{Issue}: 10
{Pages}: 294-302
{Keywords}: 机器视觉;图像处理;缺陷检测;YOLOv3;自编码器
{Abstract}: 针对目前瓷砖缺陷检测算法主要依赖人工设计特征和分类器，实际应用中存在调试困难、鲁棒性不足的问题，提出一种基于改进YOLOv3的纹理瓷砖缺陷检测算法。首先，在Darknet-53前加入卷积自编码器，将瓷砖的弱缺陷重构图像与原输入融合，得到更丰富的输入信息。然后，利用K-means聚类方法计算新的锚框，以获得更适合的锚框。最后，针对小样本问题，利用在公共数据集上预训练好的权重初始化网络，以提高模型收敛性能。实验结果表明，改进后的模型平均准确率提高了5个百分点，基本保持原模型的预测速度，可以有效检出纹理瓷砖的孔洞及划痕缺陷。
{ISBN/ISSN}: 1006-4125
{Notes}: 31-1690/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwYbhfM0KhGNsOYKFFUGI70ojlONIC3IqnuJV4r6Tn347LNpqiYEOACWUO_Ol_Yi23c7o230ePuP48Qd4e8nfehbgIWCQkiOyRFneDroyafoGltWKgPxxGmkuuEdujfnmV302FDHNJSWg5c_OWvCbM38A_IoE19wtSW_M08a_JOzMkLZ2bWd3W5ZlMHv7c_IXs=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于图卷积神经网络的人体动作识别
{Author}: 潘锐
{Tertiary Author}: 蔡林沁
{Publisher}: 重庆邮电大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 动作识别;图卷积神经网络;注意力机制;自学习的P矩阵;残差网络
{Abstract}: 随着计算机视觉和人工智能等热门学科的发展,人体动作识别在视频监控、人机交互以及医疗健康等领域扮演着越来越重要的角色。传统的RGB视频人体动作识别容易受到光流、背景、身体尺度和视角等因素的干扰,在卷积过程中骨骼数据特征不易获取。为了克服传统RGB视频动作识别的缺陷,本文选择基于骨骼序列的人体动作识别作为研究方向,结合图神经网络和深度学习方法,围绕人体骨骼序列数据的获取、自学习图卷积网络的构建、融合注意力的自学习图卷积网络的构建和最终的人体动作识别系统等四个问题展开深入研究。
首先,针对人体骨骼姿态数据的获取,本文构建了基于OpenPose姿态估计的算法环境,并分析了OpenPose算法的工作原理和人体骨骼序列数据的获取过程。
其次,提出了一种自学习P矩阵的时空图卷积网络(PST-GCN)人体动作识别方法,对输入不规则的骨骼数据进行高效图卷积运算的同时,能够自适应地改变图卷积网络结构,提高了模型的灵活性,使得相似动作能够更好地识别。在此基础上,本文融合了一种空间和通道注意力模块,构建了融合注意力的自学习图卷积网络,以此来加强关节点特征间的空间联系和时序通道特征。利用本文方法PA-GCN在公开数据集NTU-RGBD的Cross-Subject和Cross-View标准测试,分别取得了86.9%和94.5%的识别率。在Kinetics数据集Top1和Top5标准下分别取得34.9%、57.1%的识别率。超过了目前部分关注度较高的研究,体现了较高的准确性和良好的识别性能。
最后,基于本文提出的融合注意力的自学习图卷积人体动作识别模型(PAGCN),利用PyQt5和OpenPose设计了一款人体动作识别系统,通过多名测试者制作的数据样本对系统的动作估计和动作识别功能进行了测试,测试结果表明系统功能完善,具有良好的准确性和稳定性。
{URL}: https://link.cnki.net/doi/10.27675/d.cnki.gcydx.2022.000404
{DOI}: 10.27675/d.cnki.gcydx.2022.000404
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 多尺度卷积神经网络的图像边缘检测
{Author}: 石昌友;孙强;卢建平;夏榕泽;刘锦锋
{Author Address}: 陆军工程大学通信士官学校;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 08
{Pages}: 121-128
{Keywords}: 计算机视觉;卷积神经网络;自注意力集中;多尺度技术
{Abstract}: 在受图像拍摄条件、图像内容自身复杂性、图像内容与背景接近程度等多种因素的影响，图像的边缘线检测容易发生漏检、误检。因模型自身设计缺陷或训练样本中边缘像素点与非边缘像素点的不平衡原因，多数算法的图像边缘检测结果普遍存在线条粗、质量较低的问题。提出一种多尺度卷积神经网络模型，由三个分别接受一幅图像的不同尺度输入的子网络结构组成，分别在不同尺度视觉下学习图像的边缘知识。然后按尺度从粗到细对各尺度提取的知识特征进行融合，实现边缘轮廓检测。模型充分利用多尺度技术在图像处理领域的优势，同时引入了自注意力机制以提升卷积特征内部关联性的捕获能力。本文提出了一个新的损失函数，由交叉熵损失函数和L1范数组成，避免训练样本非均衡性对训练模型的影响。使用指标ODS、OIS、AP度量图像边缘检测的质量。在BIPED数据集上测试，三个指标的得分分别为0.845,0.856,0.886。在BSDS500数据集上测试，算法在F-measure指标上得分为0.826。实验结果表明，与其它学习型的算法相比，算法输出图像边缘结果漏检率更低、且质量更高。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108738
{DOI}: 10.19651/j.cnki.emt.2108738
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的自然场景人体姿态估计
{Author}: 熊新宇
{Tertiary Author}: 程建
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 多人姿态估计;自上而下方法;自下而上方法;人体目标检测;多尺度特征融合
{Abstract}: 人体姿态估计是计算机视觉领域的研究热点课题之一,本文研究自然场景中的2D人体姿态估计。人体姿态估计有两个主要应用方向:一是基于人体姿态估计算法提取图像信息中的人体姿势,再结合一定的后处理算法对目标人物的动作进行分析;二是使用人体姿态估计算法实时捕捉人体骨骼模型,并将其用于生成虚拟形象。前者的应用场景大多在大型公共场所的安防监控领域,而后者的一个典型场景是电影和游戏制作过程中的动作捕捉技术,本文重点研究第一类应用场景下的人体姿态估计。人体姿态估计算法一般包含人体目标检测、人体关键点检测和关键点关联这些组成模块中的部分或全部。本文分别从自上而下和自下而上的多人姿态估计算法进行相应的改进和实验分析。1.自上而下的多人姿态估计算法。首先设法消除因数据预处理而带来的系统误差。然后选取合适的人体检测器,构建人体姿态估计骨干网络。针对人体姿态估计任务容易受到不同尺度大小、有无遮挡等因素的影响,采用能够很好地进行多尺度特征融合的骨干网络。最后,设计合适的损失函数,进行相关实验并验证了以上数据处理算法和网络结构的有效性。2.自下而上的多人姿态估计算法。在自下而上方法中,人体关键点之间的关联是一个很重要的步骤。首先,在姿态估计骨干网络中通过加入Transformer编码器来提高网络对关键点之间相关性的提取能力,然后使用一种合适的关联算法实现关键点连接。其次,自下而上算法中存在不同大小的人体目标导致的同一种关键点有不同尺度大小的问题,本文对不同尺度关键点采取不同的关键点热图生成方法。本文通过实验验证了以上算法、网络结构、模块的有效性与先进性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000487
{DOI}: 10.27005/d.cnki.gdzku.2022.000487
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 改进U-Net芯片X线图像焊缝气泡缺陷检测方法
{Author}: 李可;吴忠卿;吉勇;宿磊
{Author Address}: 江南大学机械工程学院;江南大学江苏省食品先进制造装备技术重点实验室;中国电子科技集团第五十八研究所;
{Journal}: 华中科技大学学报(自然科学版)
{Year}: 2022
{Volume}: 50
{Issue}: 06
{Pages}: 104-110
{Keywords}: 缺陷检测;机器视觉;语义分割;空间注意力;密集条件随机场
{Abstract}: 针对传统图像处理算法的芯片缺陷检测方法难以实现缺陷的精确提取且泛化性较差的问题，提出了结合空间注意力机制(SAM)、空间金字塔池化(SPP)、移动端神经网络(Mobile-Net)和密集条件随机场(DCRF)改进经典UNet芯片X线图像焊缝气泡缺陷的检测方法(DSSMob-U-Net)．首先，针对经典U-Net网络特征提取能力不足、泛化性较差的问题，引入Mobile-Net作为U-Net的主干特征提取网络，提高网络获取缺陷形状和位置信息的能力，并减少网络的参数量，降低模型对训练样本量的要求；其次，在Mobile-Net的低维特征提取部分引入空间注意力机制，并在特征提取后引入空间金字塔池化，提升网络对图像高、低维特征的提取能力，解码后针对解码器上采样层导致的特征信息丢失问题，在分类完成后引入密集条件随机场，结合像素点的像素值和所属类别信息对像素的分类结果重新评估，进一步提高分割精度；最后，在芯片缺陷数据集上进行实验，验证了DSSMob-U-Net模型的有效性，并与其他常用的语义分割网络进行比较，结果表明该模型具有更好的检测性能．
{ISBN/ISSN}: 1671-4512
{Notes}: 42-1658/N
{URL}: https://link.cnki.net/doi/10.13245/j.hust.220613
{DOI}: 10.13245/j.hust.220613
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于无人飞机机器视觉的结构缺陷智能识别方法及系统
{Author}: 彭雄
{Tertiary Author}: 钟新谷;陈安华
{Publisher}: 湖南科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 机器视觉;无人飞机;深度学习;三点激光测距仪;结构缺陷;智能识别
{Abstract}: 我国基础设施结构规模庞大,近年来相当一部分基础设施结构如风机、光伏电站、输电线塔、桥梁、房屋建筑等尚未达到设计使用年限就出现了较多的缺陷和病害,引起公众广泛关注。但目前基础设施结构的表观缺陷检测设备和手段有限,缺乏缺陷检测专用装备系统及相应算法,如何快速、精确的对结构表面缺陷进行识别与测量成为迫切需要解决的问题。因此,本文以多旋翼无人飞机为平台集成可见光相机、红外热成像相机、三点激光测距仪形成结构缺陷检测无人飞机机器视觉系统,基于深度学习人工智能提出适于机载成像特点的缺陷识别和测量相应算法,以大跨径桥梁裂缝和建筑外墙饰面脱粘缺陷的识别与测量为例验证本文方法及系统的有效性,进而可扩展应用至其他基础设施结构的定期维护管养,为我国基础设施结构的检查评定提供装备基础,有效保障人民生命财产安全。本文主要研究内容如下:(1)集成无人飞机机器视觉结构缺陷识别与测量系统。以旋翼无人飞机为工作平台,通过对上置云台机载相机加装三点激光器与相机快门同步测量物距,形成无人飞机机载成像表面缺陷测量系统,获得附加物距的缺陷图像,进行相机标定与实际裂缝测量试验,验证本文系统精度;集成激光测距仪与红外热成像视频同步,形成无人飞机机载红外热成像结构表层内部缺陷测量系统,以建筑饰面砖脱粘缺陷为例,通过无人飞机饰面层脱粘缺陷热成像敏感性试验,得到饰面层脱粘缺陷温度场分布规律。为后续提出桥梁裂缝和建筑外墙饰面脱粘缺陷识别与测量智能算法提供基础。(2)提出基于特征点张量投票的无人飞机机载远距离成像桥梁裂缝发现算法。针对无人飞机远距离成像桥梁裂缝边缘模糊、长度方向上不连续、只有1-2像素宽度的特点,基于神经网络对局部区域微小裂缝的强大特征提取能力和张量投票的感知重组能力,将远距离成像桥梁裂缝发现视为裂缝网格特征点识别及其概率重组的过程,利用结合SE模块的分类神经网络SE-Res Net50对裂缝图像网格进行特征提取与判断生成裂缝特征点,基于特征点张量投票形成裂缝概率显著图,通过非极大值抑制将概率显著图细化形成近似裂缝骨架和裂缝发现检测锚框。对比典型目标识别神经网络,所提出算法对微小桥梁裂缝目标具有更高的精度和鲁棒性,适于无人飞机机载远距离成像桥梁裂缝发现。(3)提出基于混合特征学习的无人飞机成像裂缝形态提取算法。针对近距离成像裂缝图像具有区域特征和边缘灰度特征明显、但成像背景复杂且对精度有较高要求的特点,传统检测与分割方法阈值需人工手动调整,深度学习语义分割基于概率判断裂缝宽度预测精度较差的问题,提出基于混合特征学习的两阶段裂缝目标形态提取算法。基于区域全卷积(R-FCN)网络实时检测和定位图像内桥梁裂缝,利用HaarAda Boost学习裂缝边缘纹理特征对R-FCN网络定位区域进行精细定位,通过局部阈值分割实现桥梁裂缝的像素级高精度语义分割和形态提取,以实际桥梁裂缝宽度人工测试结果验证本文系统与方法。(4)提出基于深度强化学习的裂缝图像宽度快速计算方法。针对裂缝图像宽度测量过程中逐点计算宽度或取平均宽度均不符合相关规范要求,且与人工测量裂缝以先验知识估计测量点位置再测量代表性裂缝宽度的过程相差较大的问题。将裂缝图像法向宽度测量视为不同分类条件下裂缝测量位置和几何简化方式的决策过程。针对裂缝图像的多样性背景,根据裂缝边缘的曲率特点,设计裂缝分类指标,基于分类判断和曲率极值点计算结果对裂缝形状简化,在简化图形形心处计算法向宽度。对比常用裂缝宽度计算中心线法和极值点法,验证本文算法的精度和鲁棒性。(5)提出了基于CenterNet和模糊聚类的热成像脱粘缺陷识别方法。针对红外热成像缺陷区域图像边缘模糊、梯度变化不明显和缺陷区域尺度变化大的特点。基于无锚框Center Net目标检测点网络速度快、精度高、适应力强的特点对脱粘缺陷目标进行识别与定位,结合模糊聚类方法实现高精度的脱粘缺陷热成像图像像素级分割,以曾出现过饰面脱粘剥落的教学楼外墙检测为例,验证本文方法的有效性。
{URL}: https://link.cnki.net/doi/10.27738/d.cnki.ghnkd.2022.000005
{DOI}: 10.27738/d.cnki.ghnkd.2022.000005
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于临床影像的肺病智能诊断方法研究
{Author}: 黄志伟
{Tertiary Author}: 林金朝
{Publisher}: 重庆邮电大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 深度学习;临床影像;肺部疾病;信息处理;计算机辅助诊断
{Abstract}: 胸部X线片(Chest X-ray,CXR)和计算机断层扫描成像(Computed Tomography,CT)是临床上最常见的医学影像学检查手段,对诊断常见的肺部疾病至关重要。目前,阅读胸片和CT图像并作出准确的诊断依赖于放射科医师的专业知识和医学经验。随着肺部疾病临床影像数量的不断增加,对肺部纹理细微变化的深入诊断给医生带来了繁重的工作量,即使是最有经验的影像科医生也可能会出现诊断错误。因此,借助人工智能(Artificial Intelligence,AI)技术,通过读取患者临床影像信息实现自动诊断肺部疾病、勾画肺部区域、输出诊断报告,开发一套基于深度学习的肺病智能辅助诊断方法,具有较高的临床实际应用价值。
本文围绕肺部疾病临床影像的计算机辅助诊断(Computer Aided Diagnosis,CAD)方法开展研究,针对深度学习方法在医学图像处理领域的研究热点,以方法理论研究和临床实际需求为基础,在肺部疾病临床影像的预测分类、区域分割、图像超分辨和诊断报告生成四个方面展开具体研究工作。
(1)针对深度学习模型要求输入图像为低分辨率和肺部疾病区域在整张图像中占比较小的问题,本文设计一种高分辨率肺部疾病分类算法应用于分类14个胸部疾病和诊断胸部X线图像。高分辨率肺部疾病分类网络由四个并行的子网络组成,通过多尺度融合过程反复交换特征信息。通过局部和全局特征提取分支训练两个高分辨率网络,并将特征融合模块进行连接和微调,最终进行预测。所设计的算法在Chest X-ray14数据集的实验结果证明了模型的有效性和准确性。局部和全局特征提取分支融合后改善了分类性能,提高了分类效果。
(2)针对CT图像中肺部边缘模糊导致难以分割的问题,本文提出了一种改进的U-Net肺部区域分割算法。该算法在U-Net网络的下采样部分对输入图像做拉普拉斯金字塔分解,叠加图像特征提取提升网络对中间特征信息的处理能力。在UNet网络的上采样部分,引入轻量级注意模块,在提取深层特征信息的同时进行注意力监督,有效提取CT图像肺部区域的特征信息。实验结果表明,所设计的算法对磨玻璃影(Ground Glass Opacity,GGO)分割准确率为0.973,可有效完成CT图像肺部分割任务。CT图像的肺部分割能帮助医生对肺部炎症疾病进行快速准确分类。
(3)针对肺部CT图像金属伪影去除过程中存在着疾病信息丢失、二次伪影和主观评价少等问题,本文提出了一种基于多模态特征边缘增强生成对抗网络的算法,在消除金属伪影的同时增强校正后CT图像的纹理结构。首先,引入交互信息限制了冗余特征的生成,以确保校正后CT与靶CT的疾病信息一致性。交互信息和CT图像融合,产生多模态特征表示,克服单模态数据的代表性能力限制。然后,设计了一个边缘增强子网络来避免二次伪影和抑制噪声。此外,还邀请了三位影像医师对校正后的CT图像进行主观评价。客观和主观评价显示,该算法可以获得高质量去除金属伪影的效果。
(4)针对现阶段缺乏大规模可应用于深度学习的医学影像和报告数据集,自动阅读胸部X射线图像仍然是一项具有挑战性的工作,探索能够模拟人类放射科医生高级推理的技术,本文以临床影像和诊断文本数据集提供的先验知识,提出了一种新的图像-文本嵌入网络来提取独特的图像和文本表示,自动从回溯性图像和报告数据中提取深度学习的标注。该算法在端到端CNN-RNN架构中实现,用于学习独特的图像和文本表示的混合。然后,论证和讨论在自动标注和报告任务中包含放射报告的利弊。虽然在多标签疾病分类方面取得了重大改进,但在提高生成报告的质量方面仍有很大的空间。
{URL}: https://link.cnki.net/doi/10.27675/d.cnki.gcydx.2022.000104
{DOI}: 10.27675/d.cnki.gcydx.2022.000104
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向复杂场景的行人重识别关键技术研究
{Author}: 马丁
{Tertiary Author}: 周勇
{Publisher}: 中国矿业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 行人重识别;伪标签;半监督;强化学习
{Abstract}: 自国家“十三五”开始,人工智能可以赋予安防系统任务更鲜明的选择和更完善的结果,目前已逐渐进入新的快车道。并从传统安防系统事发时的被动防御逐渐过渡到事发前的自主进行阻止和事发时自主报警的方向。随着经济的发展,国家有了更丰富的财力铺设范围更广、清晰度更高的视频监控摄像头,这些高清摄像头对于社会安全治安建设、城市平安建设、各相关部门信息化、卫生健康区域防护与溯源等领域都做出卓越贡献。特别是在疫情期间,以安防系统为辅助的密接人员溯源追查工作取得优秀的成果。由于摄像头往往无法正确清晰地抓拍到人的正脸,在一些现实的应用场景中,仅仅依靠人脸信息并不能满足实际工作需要,现阶段为了促进人工智能在安防领域的落地,必须使其能够利用诸如人体的姿态、服装等不同角度的全面信息特征,使行人身份的鉴别从单纯依靠人脸识别突破到认识一个“人”个体的阶段。对于行人重识别技术本身而言,其主要任务是从已有的大型图像数据库中检索出特定图像,是一种只针对行人这一主体的图像检索任务。行人重识别技术在从理论算法到实际落地应用的过程中,也面临重重困难。受到摄像头位置及摄像头视野的限制,单一的摄像头不可能对某片监控区域进行全方位覆盖。即使多个摄像头针对同一区域拍摄,也依然因为不同摄像头之间存在光照、角度、遮挡等诸多因素之间的差异,甚至不同规格和型号的摄像头也会带来清晰度和其他不可预测的实际问题,导致现有行人重识别算法无法走出实验室,达到可接受的落地应用精确性。虽然在全国铺设范围巨大的摄像头采集下,积累了海量的视频数据,然而这些数据中的大部分包含的有效行人信息是很少的,并且如此数量级的视频数据在没有人为标注的情况下几乎对于行人重识别任务没有任何帮助。数据量大、有效样本却不足,这是典型的大数据小样本问题。立足于解决复杂场景下行人重识别中存在的问题,本文做出了许多探索。从数据扩充的角度,探索了行人样本追踪模型和行人样本扩充方法。从模型改进角度,提出了自适应迭代方法。从系统优化角度,提出了时-空信息联合的行人重识别系统优化方法。主要创新点包括:(1)为了解决在行人追踪的任务中行人样本受遮挡的问题,本文提出一种基于半监督学习的稳定孪生网络追踪方法STWS(Shape Robust Siamese Network Tracking Based on Semi-Supervised Learning),目的是为了改善图像中目标的定位。现有大多数半监督方法只定位对象中具有最显著特征的区域,而不是目标的所有相关区域,这导致模型性能欠佳。本文提出的STWS方法核心思想是在训练数据中随机隐藏目标样本部分区域,从而生成基于原始行人样本的受遮挡行人样本,目的是为了将网络的关注重点平均分散于不同的局部区域,当具有最显著特征的区域被隐藏时,迫使网络寻找其它相关部分。本文提出的STWS模型能够有效将网络训练时的关注重点从少数重点位置扩散到目标图像全局,从而更好地解决图像遮挡问题。并且在STWS随机隐藏目标样本部分区域的过程中,大大丰富了受遮挡样本的数量,从而达到了扩充数据集的目的。(2)针对现有行人重识别视频数据的帧间信息挖掘不充分的问题,本文提出一种基于强化学习的渐进式行人重识别网络更新方法RLPU(Reinforcement Learning Progressive Update Network for Person Re ID)。通过行人追踪算法对视频帧间信息高效利用的特性和强化学习从环境状态映射到动作的特性。由行人追踪算法得到行人的轨迹片段,依托轨迹片段信息给行人分配伪标签,并由强化学习在行人重识别网络迭代更新的过程中,根据每轮迭代后行人重识别模型运行结果是否有明显提升判断当前更新策略的优劣,得到最优的伪标签更新策略,从而动态筛选伪标签。RLPU算法提高了现有基准的性能,并且具有较高的运行效率。(3)针对大规模数据集标注成本高问题,本文基于STWS算法和RLPU算法提出基于视频的半监督自适应分步行人重识别方法SSAS(Semi-Supervised Adaptive Stepwise Learning),在得到行人轨迹片段和部分伪标签的基础上,SSAS算法提出了一种更全局化的伪标签更新思想。区别于RLPU利用强化学习由行人重识别模型的迭代结果筛选伪标签的方法,SSAS利用了Kullback-Leibler散度的核心思路,从特征分布的角度对伪标签的优劣进行度量。逐步增加伪标签的复杂性,由简单样本开始,逐渐增加困难样本,与此同时删除效果较弱的样本进行更新。本文提出的SSAS方法通过动态的伪标签筛选策略,稳步提高了行人重识别任务的识别准确率,并通过实验证明了本方法的优越性。(4)针对行人背景复杂多变问题,本文基于以上几种方法做了更进一步的探索,提出了时-空信息联合的行人重识别系统优化方法OTSI(Optimization Method of Person Re-identification System Based on Time-Space Information)。利用行人追踪算法挖掘视频中的时间信息得到行人的轨迹片段,扩充伪标签视频片段数据集。同时在行人追踪算法因外界干扰丢失目标行人的情况下,利用行人重识别算法挖掘视频中的空间信息得到行人的位置片段,使行人追踪算法的精准度提高。两者相辅相成,得到行人图像数据动态字典,并由强化学习管理更新过程,得到行人追踪算法和行人重识别算法最优的更新管理策略,依靠这种时-空信息联合的系统优化方法,可出色地满足在复杂场景下的应用需求。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000073
{DOI}: 10.27623/d.cnki.gzkyu.2022.000073
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度卷积神经网络通道剪枝方法研究
{Author}: 常璟飞
{Tertiary Author}: 陆阳
{Publisher}: 合肥工业大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 卷积神经网络;模型压缩;通道剪枝;图像分类;目标检测
{Abstract}: 深度卷积神经网络在计算机视觉、自然语言处理等领域取得了超越传统方法的优异性能,然而,随着网络规模的增加和各种复杂结构的出现,在诸如自动驾驶、可穿戴设备、智能机器人等内存和算力有限的场景,应用和部署深度卷积神经网络难度较大,限制了卷积网络和相关任务的应用发展。因此,在精度损失较小的情况下,对深度卷积神经网络的压缩进行理论分析并建立高效的压缩模型是十分必要和紧迫的。目前,已有研究揭示了深度卷积网络中存在明显的参数冗余现象,这为网络压缩建立了基本的理论依据。而且,现有的方法在参数重要性评价标准、压缩效率、网络精度损失等方面依然存在较大的改进空间。本文在对国内外网络压缩和加速方法进行分析总结的基础上,重点针对卷积神经网络的通道剪枝技术进行了深入研究。完成的主要研究工作总结如下:1)提出了一种基于中间特征注意力的通道剪枝方法。利用特征注意力模块的中间激活张量来评价通道的重要程度,进而设置阈值删除网络中不重要的特征图及其相对应的卷积核。解决了现有量级剪枝标准容易忽略参数在网络整体结构中的作用这一问题。此外,针对基础残差模块提出了一种新的剪枝策略,对同一阶段中包含的相同残差模块统一裁剪,使这些残差模块的输入和输出通道数保持一致。2)提出了一种基于粒子群优化的通道聚类剪枝方法。首先根据特征图之间的余弦相似度对网络通道进行基于密度的聚类剪枝,然后将剪枝后的子网络扩展为候选子网络种群,最后利用粒子群优化算法进行搜索寻优,在一定的压缩率范围内获得了性能更好的网络通道数配置。解决了现有网络剪枝方法较多依赖人工干预的问题,实现了自动剪枝。3)提出了一种联合知识迁移和对抗博弈的全局均衡迭代剪枝方法。通过分析不同层中输出特征图的量级分布,揭示了现有剪枝方法存在参数量和浮点运算量压缩率不均衡的问题,并建立了一种基于特征图1范数最大归一化的全局均衡迭代剪枝策略。进一步设计了剪枝间隙性能恢复策略,通过剪枝-优化迭代来保证在每次剪枝过程中网络都具有良好的精度,实现剪枝的准确性。减少了由于单阶段剪枝所造成的误裁剪情况。
{URL}: https://link.cnki.net/doi/10.27101/d.cnki.ghfgu.2022.000065
{DOI}: 10.27101/d.cnki.ghfgu.2022.000065
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的生活垃圾智能分拣车设计与实现
{Author}: 王慧
{Tertiary Author}: 蒋朝根
{Publisher}: 西南交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 垃圾分拣;计算机视觉;多轴机械臂;智能小车;Jetson Nano;手眼标定
{Abstract}: 随着社会经济水平的快速发展,人民精神文化水平不断提高,对于生态环境的保护意识不断增强。面对日益增涨的生活垃圾,从源头推行垃圾分类,降低垃圾数量,提高垃圾利用率刻不容缓。随着机械化以及智能化水平的快速发展,机器人科技产业不断蓬勃发展,利用机器人实现垃圾分拣具有广阔的市场前景。计算机视觉被广泛应用于物体识别、自动驾驶、目标检测等领域,将计算机视觉技术与机器人科技相结合的垃圾分拣技术成为了一种新的发展趋势。目前国内现有的垃圾分拣机器人主要位于垃圾场与垃圾工作站,位置固定,成本高,且是在垃圾分类末端进行垃圾分拣。针对垃圾分拣问题,本文设计了一款灵活轻便的智能垃圾分拣车,主要分拣小型区域内产生的生活垃圾,力求从垃圾源头实现垃圾分类,提高垃圾转换效率。本文研究的主要内容如下:明确总体方案设计目标,选择合适的硬件进行组装。对比多种目标检测算法,最终选取适用性强,模型体积小,便于移植于嵌入式设备的YOLO v5作为本文的基线网络。本文采用的数据集为华为垃圾分类数据集,通过数据分析,对类别数量不均衡的垃圾分类数据集通过旋转、更改亮度、噪声模糊以及加入自制垃圾分类数据集来平衡各类别垃圾数量。改进YOLO v5s网络模型,通过对比不同网络模型性能评价指标结果,最终确定以Shuffle Net V2作为主干网络,激活函数为h-swish与注意力机制为NAM的网络模型作为最终的垃圾分类识别模型,map@0.5可以达到92.1%,损失函数为0.0411,与原YOLO v5s网络模型相比,map@0.5提高了1.8%,Precision提高了0.4%,Recall提高了3.7%,损失降低了0.99%。将该模型移植于Jetson Nano中,并对其进Tensor RT加速处理,推理速度为21.82ms。为确保标定的准确性,利用三种相机标定方法来获取相机参数,四种手眼标定算法确定机械臂末端与相机之间的转换矩阵,利用Move It!实现多轴机械臂的运动规划。通过陀螺仪获取角速度,卡尔曼滤波算法计算角度,以此获取小车位姿状态。利用增量式闭环控制PID算法控制小车运动,实现ROS主控与STM32串口通信,使小车在指定区域搜寻垃圾,实现垃圾分拣功能。
{URL}: https://link.cnki.net/doi/10.27414/d.cnki.gxnju.2022.002370
{DOI}: 10.27414/d.cnki.gxnju.2022.002370
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的番茄成熟度识别及成熟期预测模型
{Author}: 李仁智
{Tertiary Author}: 李文峰
{Publisher}: 云南农业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 番茄;成熟度;机器视觉;深度学习;生理发育时间
{Abstract}: 番茄作为世界三大贸易蔬菜之一,不仅具有较高的营养价值,而且种植面积广泛。我国是亚洲番茄产量最大的国家,同时也是鲜食和加工生产大国,鲜食番茄产量稳居世界第一,加工番茄产量居世界前三位。近年来,随着番茄制品毛利率逐年降低,减少生产成本迫在眉睫。虽然通过机械采摘的方法可以提高番茄采摘的生产效率,但番茄在机械采摘过程中存在混有未成熟果实导致资源浪费的问题。此外,部分需要长期贮藏的番茄果实需要在绿熟期进行采摘。因此,有必要在采摘前对番茄果实的成熟度进行有效识别,从而筛选出成熟度适宜的番茄果实进行机械采摘,且温室或大田环境下机械采摘设备硬件条件有限。
本文为提高机械采摘番茄的准确率、实时性、适用性,结合计算机视觉技术、深度学习理论和生长模拟模型等,研究构建了基于YOLOv5的番茄果实成熟度识别模型及基于生理发育时间法的番茄生长发育模型。通过上述模型,在实现对温室环境中不同成熟度番茄果实高精度识别与预测的同时,有效减小模型大小、提高速度,从而实现温室或大田环境部署。本文主要研究内容和结果如下:
(1)提出了基于YOLOv5s的番茄果实成熟度目标识别方法。在基于YOLOv5目标检测网络的基础上引入Faster R-CNN目标检测网络进行对比。首先,将番茄果实成熟度人工划分为绿熟、变色、粉红和红熟四个成熟阶段,并制作番茄果实成熟度数据集对目标检测网络进行训练,经过参数优化和模型结构调整,选择出最适番茄果实成熟度识别模型。试验结果表明,YOLOv5s目标检测网络对番茄果实成熟度识别的准确率为95.47%,召回率为89.19%,平均精度均值为96.76%,平均检测时间为9.3ms/幅,模型大小仅为23.9MB。能够有效识别出处于不同复杂环境中的番茄果实,具有较高的识别速度,成熟度识别效果较好,且模型内存占用较小,有利于在农业机械采摘设备上进行部署。
(2)提出了基于生理发育时间法的番茄果实成熟期预测模型。依据同品种番茄生理发育时间恒定的原理,通过采集结果期番茄果实的发育日期及温度、光照情况,利用生理发育时间法建立了番茄果实生长发育的非线性模拟模型。分别模拟番茄果实在绿熟期-变色期、变色期-粉红期、粉红期-红熟期的生理发育日期。试验结果表明,模拟值与实测值的误差小于2日,RMSE分别为1.095,0.894,1.095,NRMSE分别为4.52%,24.83%,33.18%。模型模拟值与实测值之间存在着较高的一致性。通过对番茄进行高精度的果实成熟期预测可有效提高机械采摘识别效率。
{URL}: https://link.cnki.net/doi/10.27458/d.cnki.gynyu.2022.000168
{DOI}: 10.27458/d.cnki.gynyu.2022.000168
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向机械臂抓取的视觉感知方法研究
{Author}: 穆逢君
{Tertiary Author}: 邱静
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机械臂抓取;机器人感知;机器视觉;时空特征融合;弱监督学习
{Abstract}: 近年来,随着机器智能技术的发展,机械臂抓取在机器人操作、装配等场景得到了广泛的应用,现有的机械臂抓取方法需要精确感知空间中物体的6D位姿。然而,机械臂抓取场景中通常存在着传感器视野遮挡、物品堆叠等不利于感知的因素,使现有的感知方法难以满足机械臂抓取对精度与稳定性的需求。此外,对高成本物体位姿标注数据的依赖也使现有感知方法难以在不同物体与场景间进行快速迁移。针对上述问题,本文将针对机械臂抓取场景中的视觉感知方法开展研究,以提高物体位姿估计方法对遮挡的鲁棒性,并消除其对高成本标注数据的依赖。本文的研究内容和成果主要包括以下几个方面:(1)针对现有视觉感知方法不适用于严重遮挡场景的问题,设计并实现了一种对环境遮挡高鲁棒性的物体位姿估计方法Temporal Fusion。该方法基于RGB-D图像序列构建时空融合特征,并使用注意力增强的卷积神经网络回归物体的6D位姿,有效提高了物体位姿估计方法在严重遮挡下的性能。实验结果表明,本方法达到了99.3%的位姿估计精度,且可以对完全被遮挡物体进行位姿估计,优于现有的领先方法Dense Fusion。(2)针对现有物体位姿估计方法难以获取位姿标注数据以快速迁移的问题,提出并实现了一种无监督标注生成与弱监督学习方法Weak6D。该方法构建了适用于弱监督学习的物体位姿估计网络,提出了无监督生成优化目标的迭代优化解析器,并使用弱监督学习方法训练网络模型。实验结果表明,Weak6D无需任何物体6D位姿标注数据即可达到98.4%的位姿估计精度,与有监督学习的领先方法Dense Fusion接近,使视觉感知方法可以在机械臂抓取任务中快速迁移。(3)针对现有机械臂抓取的应用验证中缺乏感知方法验证平台的问题,搭建了具有完整机械臂与环境模型与开放接口的仿真平台。该环境具有机械臂抓取任务所需的机器人、待抓取物体、放置平台与环境光照等可控模块,并设计了所需的开放控制与状态读取接口,适用于对机械臂抓取中感知方法的验证。本论文提出的物体位姿估计方法Temporal Fusion与Weak6D实现了机械臂抓取场景中的高鲁棒视觉感知,并克服了现有方法对高成本位姿标注数据的依赖。因此,本论文提出的视觉感知方法在严重遮挡下同样可以满足机械臂抓取的视觉感知需求,并可在多种抓取场景与物体间进行快速迁移,具有较高的应用前景。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.002699
{DOI}: 10.27005/d.cnki.gdzku.2022.002699
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习和边缘计算的人数统计系统研究与设计
{Author}: 张志立
{Tertiary Author}: 谢胜利;谢振东
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人数统计;目标检测;目标跟踪;边缘计算;Jetson Nano
{Abstract}: 随着深度学习理论技术的不断完善与发展,计算机视觉在日常生活中的应用也越来越多。人数统计任务作为计算机视觉领域重要的研究方向之一,也逐渐影响着人们的生产生活。如对于疫情防控,通过统计公共场合的人数如会议厅、车站、教室等场合对疫情防控起到了重要作用。在人流量管控方面,通过对固定区域过往人流量的分析可以给出行人员提供更加可靠的出行策略。本文通过对国内外人数统计方法的研究和分析,分别基于目标检测算法和目标跟踪算法进行人数统计。(1)本文从实际应用场景出发,综合检测精度和检测速度,基于YOLO系列最新检测器YOLOv5(s号V3版本)通过检测人头的方式进行人数统计,并针对原始YOLOv5小目标人头检测效果欠佳的情况对YOLOv5进行了网络结构上的改进。实验证明在检测速度稍有下降的情况下,改进后YOLOv5的人头检测精度Recall及m AP@0.5较未改进之前分别提升0.9%和0.8%,小目标人头检测效果也有所改善。(2)为满足人数统计任务的实际应用需求,本文在改进后的YOLOv5检测器基础上引入Deep SORT跟踪器对人头进行检测跟踪,通过制定上下行撞线区域进行人流量的计数统计。经实验测试,采取人头跟踪的方式进行人流量统计,准确率可达95%以上,相比于以往多数通过跟踪行人进行人流量统计的方式,本文通过检测跟踪人头的方式更加适用于拥挤场合下的人流量统计。(3)为使人数统计算法落地用于实际场景,本文搭建了基于Jetson Nano的边缘智能系统平台,通过Tensor RT和C++加速推理将YOLOv5部署于Jetson Nano用于人数统计。经实验测试,以本地视频人数统计为例,部分小范围人数统计场景实时FPS可达24帧/秒左右。相比于以往大多数服务器端的人数统计,本文部署的端侧人数统计系统可直接用于实时性要求不高的小范围人数统计场景,大大降低了移动端人数统计任务所需的硬件成本,使得算法落地更加便捷高效。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000093
{DOI}: 10.27029/d.cnki.ggdgu.2022.000093
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 光学动作捕捉系统的多相机标定算法研究
{Author}: 张冬阳
{Tertiary Author}: 史坤峰
{Publisher}: 郑州轻工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 动作捕捉;相机标定;一维标定物;无穷远平面搜索
{Abstract}: 作为人工智能的一个分支,计算机视觉在近些年来得到了快速的发展,光学动作捕捉系统以计算机视觉为基础,利用多个相机在不同角度对特征点的追踪和定位来完成动作捕捉。动作捕捉的关键前提就是对所有的相机进行精确标定,所以相机标定也一直受到人们的重视。多相机标定的目的主要是从2维的图像视图还原场景的3维信息。相机的标定方法按照标定物可分为1维标定、2维标定、3维标定和自标定。其中自标定方法仅需要图像信息便可完成相机标定,但精度较低。2维标定和3维标定有着较高的精度但是标定物制作复杂,成本较高,并且在一些场景下容易发生自遮挡现象。而1维标定物制作简单且不易发生自遮挡现象,在实际应用中得到广泛的青睐。其中只有两标记点的1维标定物不会产生非共线的制作误差,另外即使两标记点的距离存在测量误差,也不影响内参数和外参数中的姿态角,只有外参数中的相对位置与真实值相差一个统一的尺度因子。两标记点标定物在本文简称为“线段”,由于几何信息较少,基于线段长度先验的欧氏升级参数计算尚缺少实际适用的算法。首先,本文提出了基于线段长度与解多项式方程的相机标定算法。通过对不同的参数进行约束,利用已知长度的线段构造方程,并采用消元法减少未知量的个数,最后构造通用求解模板,利用Gr?bner基法求解多项式方程。多相机标定的实质是计算相机的9个参数,所以理论上仅需要9个已知长度的线段来构造方程便可求解。但现有算法在线段个数较少的情况下对噪声极为敏感,成功率较低。本文提出的算法有更好的鲁棒性和更简单的求解过程。另外,本文提出了基于线段长度与无穷远搜索的相机标定算法。通过施加手性约束,将无穷远平面约束在一个3维的参数立方体内,然后采用不同的搜索方法对该参数立方体进行搜索。将搜索到的每一个无穷远平面当作是已知条件,则未知量仅为相机的内参数,可以结合线段的长度用简单的线性方法求解。最后对每个结果采用不同的代价函数进行非线性优化,选择出最优的解。该方法避开了复杂的代数计算,提高了标定速度。最后,本文提出了3个基于光学动作捕捉系统的实际应用。第一,利用动捕对空间点实现了精确定位,精度达到了0.1毫米左右,将空间点安装在机械臂上便可得到机械臂的精确位置,从而实现对机械臂的校准工作。第二,利用动作捕捉系统实现了对人体脊柱的重建,在人体后背对应的椎骨位置贴上marker小球,用小球间接定位椎骨的空间位置,建立人体脊柱模型,在人体的持续运动中得到动态的脊柱信息,从而帮助医疗人员更全面的了解病人的脊柱问题。第三,利用动捕实现了增强现实系统的标定,也就是计算拍摄真实场景的彩色相机与动捕系统之间的转换关系,从而得到彩色相机所拍摄到的真实场景与计算机中虚拟场景的转换关系,最终实现现实与虚拟结合。
{URL}: https://link.cnki.net/doi/10.27469/d.cnki.gzzqc.2022.000127
{DOI}: 10.27469/d.cnki.gzzqc.2022.000127
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的行人目标检测与跟踪算法研究
{Author}: 王双
{Tertiary Author}: 徐淑萍
{Publisher}: 西安工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 行人检测与跟踪;YOLOV3+Deepsort;X-tion摄像头;ROS
{Abstract}: 行人目标检测与跟踪算法作为计算机视觉的重要研发范畴,也作为自主跟踪机器人获知行人目标以及外部环境信息的基础,目前已广泛应用于对各类交通站、商业区、居民区等环境以满足社会中对行人目标检测与跟踪的各类需求。本文针对基于机器视觉的行人目标检测与跟踪算法进行了研究,利用实验测试证明了优化后的行人目标检测与跟踪算法的在性能方面的提升,依托移动机器人平台,在ROS机器人软件平台上构建了移动机器人对行人目标的视觉跟踪系统,最终完成了移动机器人对行人目标在室内环境下跟踪任务。本文的主要研究内容如下:1)研究了基于YOLOv3的行人目标检测算法,为进一步优化YOLOV3算法对行人目标检测的性能,对锚框参数的选取以及损失函数进行了优化,并增加了行人数据集对改进后的YOLOv3算法进行训练,输出训练结果,说明相较YOLOV3算法,改进后的算法在精度上提升了5.2%,在漏检率上降低了2.58%,在稳定性方面提高了3.31%。说明改进后的YOLOV3算法性能有了较大提升。2)研究了基于改进后的YOLOv3+Deep Sort行人跟踪算法,与YOLOv3+Deep Sort算法进行对比,通过实验发现改进后的算法相比于改进前在检测精度与跟踪精度上,分别增加了了3.1%,2.1%,在行人目标跟踪过程中的编号跳变情况降低了1.08%,跟踪帧率也从28帧/秒增加到34帧/秒。说明改进后的YOLOv3+Deep Sort算法在跟踪精度,跟踪帧率,行人编号跳变以及漏检程度上都优于改进前的算法。3)研究了基于X-tion摄像头的行人测距算法,为了使测距精度更加准确,利用张正友标定法对X-tion摄像头进行了标定,获得相关参数。然后基于结构光的测距算法完成了行人目标测距实验。通过测试结果可知,测量距离与真实距离的相对误差为2.9%,说明行人测距算法的精度能够满足移动机器人的测距要求,并为移动机器人的行人目标视觉跟踪系统的实现奠定了基础。4)研究了对移动机器人行人目标视觉跟踪系统的设计,完成基于ROS的机器人软件平台对视觉跟踪系统程序的设计方案,设计在室内简单环境下对行人目标的跟踪运动控制策略,并完成了对系统程序的编写,设计了相关测试实验,证明在移动机器人上可以完成对行人目标的跟踪功能。
{URL}: https://link.cnki.net/doi/10.27391/d.cnki.gxagu.2022.000577
{DOI}: 10.27391/d.cnki.gxagu.2022.000577
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的汽车零件涂装缺陷检测方法研究
{Author}: 周鼎贺
{Tertiary Author}: 宋志峰
{Publisher}: 武汉纺织大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 涂装零件;图像处理;机器视觉;缺陷检测
{Abstract}: 随着汽车行业的不断发展,车身整体与其零件的涂装工艺也得到了快速的发展,为了保证其零件良好的外观性与较长的使用寿命,需要对涂装汽车零件进行严格的质量检测,确保达到规定的质量水平线。涂装汽车零件表面的缺陷主要包括划痕、凸点、胶合、流挂等,缺陷的位置与大小均随机出现,并且检测精度要求较高,传统人工对汽车外覆涂装零件进行缺陷检测的过程中,存在着检测效率和检测准确率较低等问题。而随着机器视觉技术的不断发展,应用领域也越来越广泛,利用机器视觉检测代替人工检测,不仅能降低生产成本,还可以进一步提高检测效率与检测准确率。据此本论文设计了一种基于机器视觉的涂装缺陷检测系统,对涂装汽车零件表面的缺陷特征进行研究分析,并在Halcon与MATLAB中实现了相关检测算法的研究使用。主要研究内容如下所示:1)对检测系统的硬件平台进行搭建获取相应的图像信息。主要包括对机械传输结构的设计以及对图像采集系统中镜头、相机、光源等器件的对比选型。2)研究了针对图像背景噪声去除与图像光照不均匀两类问题的图像预处理方案。首先对图像背景噪声与图像光照不均匀问题出现的原因进行了硬件层面的分析与原理方面的介绍,针对背景噪声的去除以及平衡光照的不同特点提出了相应的解决方案。采用构建不同种类的频率域低通滤波器对背景噪声进行去除,针对图像光照不均匀提出基于同态滤波的图像预处理方法,实现了预先提出的图像预处理效果。3)对图像进行感兴趣区域的分割与缺陷提取算法进行研究。介绍了多种目标区域与非目标区域进行分割的算法,提出了一种亚像素边缘提取与自动阈值分割的算法对感兴趣区域分割。在表面缺陷提取算法进行研究时,根据其不同的缺陷特点相对应的提出相应缺陷检测算法。提出了基于灰度投影原理的一种灰度变化缺陷检测算法、基于形态学Blob的缺陷提取算法以及一种基于分水岭算法的优化方法,并对这些算法进行实际应用,验证了其算法的正确性与可靠性。4)对上位机人机交互界面进行设计。人机界面的交互软件由三部分组成,分别是由登陆界面、基于C#的.NET视觉系统框架及嵌套于框架内的基于Halcon缺陷检测算法的部分组合而成。在实现检测功能的基础之上,使得本系统具有良好的可操作性。本系统通过搭建实验平台并进行实际实验测试,试验结果表明此系统能快速、准确的识别提取涂装缺陷特征,平均单次识别时间为320ms,识别准确率为97%,相较于人工检测效率提高近40%,满足工业涂装缺陷检测的要求。
{URL}: https://link.cnki.net/doi/10.27698/d.cnki.gwhxj.2022.000242
{DOI}: 10.27698/d.cnki.gwhxj.2022.000242
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的PCBA缺陷检测系统研究与设计
{Author}: 孔树荫
{Tertiary Author}: 曹江中
{Publisher}: 广东工业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: PCBA;缺陷检测;彩色图像;机器学习;图像分割
{Abstract}: PCBA（Printed Circuit Board Assembly）是指在PCB（Printed Circuit Board）使用各种元器件进行插件和焊接的制程。随着电子产品的发展和智能制造技术的进步,PCBA朝着高精度、高密度的方向发展。由于生产工艺和人为因素,PCBA无可避免会出现各种缺陷问题,因此对PCBA进行缺陷检测是必不可少的环节。传统人工检测不仅效率低、而且人工成本昂贵,无法满足现代工业化生产的需求。近年来,随着计算机技术的发展,基于机器视觉的PCBA缺陷检测方法逐步得到应用,但由于PCBA的缺陷部位细微且种类繁多,在成像上缺陷的区分难度大,导致通用的PCBA缺陷检测系统鲁棒性欠佳,检出率并不理想,因此许多企业需要针对PCBA的特点和检测需求定制开发检测设备。本文针对某国际知名制造企业的实际需求,设计了一种检测效率高、硬件成本低、配置简单的PCBA缺陷检测系统、实现了电源风扇PCBA多种缺陷检测功能,具有较高的应用价值。本论文的主要工作如下:（1）设计并实现了一个基于机器视觉的PCBA缺陷检测系统。分析了PCBA常见的缺陷问题,设计了PCBA系统架构,根据PCBA的实际生产环境和检测需求对系统硬件进行选型,选用合适的工业相机、镜头和光源组成图像采集系统,设计了PCBA缺陷检测系统软件界面;研究了图像处理相关理论及方法,包括灰度化、图像滤波、灰度变换、图像配准和几何变换理论,完成对PCBA图像的采集和图像预处理,完成线序检测图像和THT焊点检测图像的提取,针对特定的检测功能,设计了对应的检测算法。（2）设计了基于LUV(CIE 1976（*,*,*）)颜色空间和多层感知机的线序检测算法。本文研究了颜色空间和机器学习方法,分析了PCBA图像在不同颜色空间的效果,并对比不同分类器对线序检测图像的颜色分类结果,设计了基于LUV颜色空间和多层感知机的线序检测算法,通过线序检测图像进行颜色分类,提取焊线区域,根据坐标关系对焊线区域进行排序,判断焊线焊接顺序是否出错,完成对线序检测图像的颜色分类和排序。（3）设计了基于彩色图像分割的THT（Through Hole Technology）焊点检测算法。针对THT通孔技术焊点出现少锡、包锡、桥接的缺陷,研究通孔技术THT焊点的缺陷检测问题,设计了基于彩色图像分割的THT焊点检测算法,利用RGB和HSV颜色空间以及边缘检测算法对THT焊点图像进行彩色图像分割,提取焊点图像的缺陷特征并进行分类。同时,我们也对比了基于深度学习的THT焊点检测方法,结果表明基于彩色图像分割的方法更适用于企业提出的检测需求,可以在工业生产中提供实时检测方案。本文设计的PCBA缺陷检测系统已应用于该企业的实际生产中,在流水线上进行的大规模检测结果证明该系统具有实时性强和检测效率高等优点。
{URL}: https://link.cnki.net/doi/10.27029/d.cnki.ggdgu.2022.000497
{DOI}: 10.27029/d.cnki.ggdgu.2022.000497
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 智能工程测量机器人研究
{Author}: 曹泽强
{Tertiary Author}: 周立;吴柏宣
{Publisher}: 江苏海洋大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 工程测量;局部地形图测绘;AprilTag图像识别;单目视觉测距;YOLOv5目标识别框架
{Abstract}: 为促进计算机视觉、人工智能以及智能机器人等技术在传统工程测量行业中的应用,针对于工程测量规划设计阶段绘制局部地形图的任务需求,在Robomaster EP机器人平台上集成多种传感器,经软硬件开发,提出一种非接触式的基于April Tag图像识别的机器人智能图根控制测量方法和一种非接触式的基于单目视觉测距和YOLOv5（You Only Look Once）目标识别框架的机器人智能碎部点测量方法。在机器人智能图根控制测量方法研究中,以Robomaster EP机器人作为测量平台,以机器人相机的旋转中心替代图根控制点。通过April Tag图像识别获取机器人相机的旋转中心的三维坐标,模拟实现在传统图根控制测量过程中分别使用全站仪和水准仪测定图根点平面坐标和高程的过程。在机器人智能碎部点测量方法研究中,以Robomaster EP机器人作为测量平台,以机器人相机的旋转中心替代图根控制点。然后通过YOLOv5目标识别框架自动识别机器人周围地物类型,并进行单目视觉测距,模拟实现在传统碎部点测量过程中,使用全站仪配合棱镜（杆）采集碎部点的过程。在室内环境下,通过多组实验分别研究机器人相机的俯仰角、航向角和观测距离的变化对图根控制测量精度和碎部点测量精度的影响。实验结果表明:当机器人相机的航向角∈（-7.4°,10.6°）时,或者俯仰角∈（-8.9°,9.9°）时,亦或者观测距离∈（2508）8),3008)8))时,April Tag图像识别综合误差<0.4,识别效果良好,且以机器人相机的旋转中心替代图根控制点的三维坐标测算误差均可达到毫米级;当机器人相机的航向角∈（-7.5°,9.8°）时,或者俯仰角∈（-5.9°,5.9°）时,亦或者观测距离∈（5508）8),9508)8))等3种情况时,YOLOv5目标识别框架对机器人周围地物的识别精度都大于78%,识别时间都小于0.003s,识别效果良好,且机器人相机与地物之间的单目视觉测距误差可达到毫米级。以上实验结果初步表明在工程测量规划设计阶段的局部地形图测绘任务中,使用计算机视觉、人工智能以及智能机器人等技术进行图根控制测量和碎部点测量具有一定理论可行性,为未来工程测量行业研究新型智能工程测量机器人提供一定理论依据和技术探索。本论文有44幅图,18个表,90篇参考文献。
{URL}: https://link.cnki.net/doi/10.44354/d.cnki.gjsuy.2022.000026
{DOI}: 10.44354/d.cnki.gjsuy.2022.000026
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器学习的光伏板表面缺陷图像诊断研究
{Author}: 钟泳松
{Tertiary Author}: 徐凌桦
{Publisher}: 贵州大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 光伏板;机器视觉;迁移学习;目标检测;图像分类;生成对抗网络
{Abstract}: 随着我国光伏产业快速发展,集中式光伏电站和分布式光伏系统大范围应用,可以预见的是光伏运维需求会日益增加。光伏板表面缺陷检测是光伏电站运维中一项重要工作,直接影响光伏电站发电效率和安全运行。电路结构法又不完全适用于确定不同类型的光伏板表面缺陷且传统的人工巡检方式效率低。因此,将目标检测技术、图像分类技术应用到光伏板表面缺陷巡检中,能有效解决上述问题。本文以自主搭建的光伏板阵列实验平台为参考,运用光伏板目标检测算法、缺陷分类算法、缺陷评估算法、缺陷图像增广算法,实现对光伏板阵列中每张光伏板单张提取并精细分析缺陷种类预测缺陷程度,提升光伏电站运维效率,降低运维成本。主要研究工作如下:(1)针对光伏板精准检测提取问题,提出一种改进的SSD(Single Shot Multi Box Detector,SSD)光伏板检测算法。首先,为了提升SSD算法检测精度,在其主干网络VGG16中融合了6个CBAM(Convolutional Block Attention Module,CBAM)注意力机制模块分别对应其输出的6个尺度的特征图,增强了算法的多尺度特征提取能力;其次,针对数据集不足的问题,采用数据增强技术和迁移学习的策略辅助模型训练;最后,针对光伏板的形状特征,重新设计了网络中默认框的长宽比。结果表明改进后SSD算法检测精度更高,模型训练速度更快。实现从复杂背景中检测并提取光伏板图像特征,将光伏板阵列图像转化为单张标准的光伏板图像,减少地面背景等因素干扰的需求,为后续缺陷识别和评估提供数据。(2)针对光伏板表面缺陷数据不足问题,采用了WGAN(Wasserstein GAN,WGAN)模型对现有的缺陷数据集进行数据增广。首先,分析三类可见光下光伏板表面缺陷成因和特征,确定研究的缺陷类型;其次,通过实验对比分析了WGAN、WGAN-GP(Improved Training of Wasserstein GANs,WGANGP)、DCGAN(Deep Convolutional GAN,DCGAN)的效果,结果表明,WGAN收敛过程更加稳定,损失收敛值较小,表明WGAN生成的图像更加接近真实图像;最后,将生成图像和真实图像共同用于训练光伏板缺陷分类模型,实验结果表明,在原有数据集基础上添加一定数量的生成图像可以有效提升模型的分类准确率。(3)针对光伏板表面缺陷分类和评估问题,提出一种改进的光伏板表面缺陷图像识别和分析算法。首先,为了提升Res Net(Residual Networks,Res Net)算法分类准确度,在算法每个残差结构中嵌入SENet(Squeeze and Excitation,SENet)通道注意力模块,提升模型特征提取能力,实验结果表明,改进后Res Net模型在光伏表面缺陷数据集上分类准利率较原算法有了很大提升;其次,将光伏板表面缺陷和对应的发电效率损失匹配构建数据集,借助迁移学习策略在改进的光伏板缺陷识别算法基础上微调参数,获得缺陷图像和内部发电效率损失的关系,借此定量评估缺陷的程度和等级,为差异化定制以缺陷种类和缺陷程度为不同优先级的光伏板运维方案提供依据。
{URL}: https://link.cnki.net/doi/10.27047/d.cnki.ggudu.2022.002827
{DOI}: 10.27047/d.cnki.ggudu.2022.002827
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的螃蟹分拣装置研究
{Author}: 沈健
{Tertiary Author}: 袁跃峰
{Publisher}: 浙江海洋大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 梭子蟹;深度学习;机器视觉;自动分拣
{Abstract}: 我国海洋渔业资源丰富,蟹类捕捞产量也在逐年增长,其中从舟山上岸的梭子蟹总量大约占全国的七成,捕获梭子蟹的收入是当地渔民一大来源之一。梭子蟹被捕捞上岸后,面临着被分拣的问题。传统的分拣基本上靠当地有经验的人力完成分拣工作,分拣工作包括把螃蟹中的公母各自挑选出来和把螃蟹按照大小划分等级,是一件十分繁琐和浪费人力的工作。但这也是螃蟹流入市场供应链必不可少的一个第一步加工步骤。极大的限制了梭子蟹加工产业的发展。按照现代流水线分类的快速化、低成本化的要求,本文设计了基于机器视觉的一种螃蟹自动分拣装置,通过采集螃蟹的腹部图像和装置上的称重传感器采集到的重量数据,能够快速的对被分类的螃蟹做出处理结果—按照螃蟹的公母与重量分类分级处理。本装置的研究设计主要由算法、软件、机械三个部分组成。为了实现螃蟹分类的研究,本文主要做了如下工作:(1)采集梭子蟹的图像,为后面工作的开展准备样本数据集。并对数据集进行二次加工和预处理。(2)各自选取最优的基于Alex Net网络和AGG16网络训练出来的螃蟹分类神经网络模型作对照实验,分别取得了93.2%和93.1%识别准确率,再选取其中最佳的分类神经网络模型,在此基础上对该网络模型的性能作分析研究。(3)利用传统机器视觉按照螃蟹大小进行分类。(4)为了更加直观的反应出在螃蟹分类模型的性能,利用Python中的Py Side2模块完成了对模型验证过程的图形界面程序的设计开发。(5)设计出一套可行性的方案,能配合算法模型并能在实际中应用的机械装置流水线设计。本文研究旨在借助深度学习技术训练出识别成功率较高的公母螃蟹分类神经网络模型和利用机器视觉技术对螃蟹按照大小进行分级,并结合机械装置的设计,提高螃蟹分拣的效率,解放宝贵的人力资源,在研究成果实用化方面有了很大进步。
{URL}: https://link.cnki.net/doi/10.27747/d.cnki.gzjhy.2022.000017
{DOI}: 10.27747/d.cnki.gzjhy.2022.000017
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的FDM 3D打印在线检测
{Author}: 施张杰
{Tertiary Author}: 鲁玉军
{Publisher}: 浙江理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: FDM;3D打印;视觉检测;特征提取;振动分析
{Abstract}: 随着工业生产方式的转变和3D打印技术的成熟,越来越多的工业产品已应用了3D打印技术,其中熔融沉积成型技术(Fused Deposition Modeling,FDM)原理简单且应用广,很多企业青睐这种打印技术。但由于受到机械结构、工艺参数等因素影响,打印过程中会出现影响产品外观、性能的缺陷,造成时间、材料等成本浪费。目前传统的故障分析不能满足打印产品的质量需求,本文针对这一问题开展了具体研究,主要工作如下:(1)提出了一种基于机器视觉的FDM 3D打印侧表面产品缺陷检测方法。根据FDM 3D打印原理,设计了FDM 3D打印产品缺陷在线检测系统并介绍流程。为了减少采集过程中喷头移动对检测的影响,本文选择侧表面进行在线检测。(2)搭建了FDM 3D打印产品在线检测的实验平台。首先针对各种光源不同特点,选取环形LED灯作为光源;然后通过对比,选取了海康CMOS面阵工业相机;最后确定了FDM 3D打印设备和计算机,完成了机器视觉检测的硬件平台的搭建。(3)设计了FDM 3D打印产品图像预处理流程。首先使用自适应直方图对原始图像进行对比增强;然后提出了一种基于掩膜的自适应阈值分割处理算法,有效分离了背景和被测目标,得到了良好的目标区域;最后通过LBP、Canny、双边滤波等图像处理常用算法,去除了图片中的噪声,为之后的缺陷提取奠定了基础。(4)实现了FDM 3D打印产品几何形状缺陷分割和特征提取。首先根据像素尺寸提出了一种双尺寸矩形内核的缺陷识别方法,有效提取了缺陷的轮廓;然后利用缺陷轮廓的最小外接矩形来定位与标记缺陷,确定了合适的缺陷特征。最后提出了由外接矩形的中心坐标、长宽比和面积比所组成的参数矩阵来描述缺陷。(5)对FDM 3D打印机进行振动分析和检测实验。首先进行了坐标变换和相机标定;其次为保证实验可信度,对打印机进行振动信号的提取,通过时域统计指标分析打印机工作状态。在打印机正常工作情况下,对采集到的缺陷进行了分类并分析其可能出现的原因。
{URL}: https://link.cnki.net/doi/10.27786/d.cnki.gzjlg.2022.000673
{DOI}: 10.27786/d.cnki.gzjlg.2022.000673
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的盲道识别与避障系统
{Author}: 谢浩
{Tertiary Author}: 张欣
{Publisher}: 河北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 盲道识别与避障系统;YOLOv5;负障碍;边缘计算设备;实时预警
{Abstract}: 我国作为世界人口第一大国,截至2021年年末,我国受到视力障碍影响的人数已多达1700余万,视力的受损甚至丧失使他们的正常出行受到了严重的影响。为了解决视力障碍者出行不便的问题,研究人员设计出了各种导盲设备。但是现有的一些导盲设备普遍以检测道路水平面以上的正障碍物为主,却往往忽略了视力障碍者出行时对他们威胁更大的坑洞等水平面以下的负障碍,同时这些导盲设备普遍存在功能不全,无法实时预警,携带不便等问题。为了解决上述的问题,帮助视障人士安全出行,本文设计并开发了一款便携式的基于计算机视觉的盲道识别与避障系统,具体研究如下:1.通过查阅相关资料和外出实地调研,分析视力障碍人士在出行中存在的困难,除了盲道上可能存在于水平面上/下的正/负障碍外,视力障碍者在行走过程中也要穿过十字路口等危险地段。针对这些问题,实地拍摄并制作了相关数据集,包括盲道、盲道上的坑洞、红绿灯、斑马线等5类。2.针对现有目标检测算法YOLOv5对远处微小的红绿灯识别率较低,斑马线检测识别准确率较差,坑洞由于目标形状大小不统一造成误检率较高等问题。本文在YOLOv5主干网络CSPDark Net53的卷积层之间添加了CA注意力机制模块,解决了全局池化方法难以保存位置信息的缺陷,能提取到更丰富的特征信息。同时在Neck网络中引入自适应图像金字塔(AAM-FPN),减少了特征通道和在高层特征图中上下文信息的丢失,使网络对小目标的检测效果进一步提升。最后在自己制作的数据集上,使用数据增强方法扩展数据集,并在此基础上完成相关实验,与现有YOLO算法相比本文改进的YOLOv5算法在检测精度上更优。3.为了使盲道识别与避障系统能实时辅助视障人士安全出行,将改进后的YOLOv5检测模型导出为ONNX格式并移植到边缘计算设备NVIDIA Jetson Nano B01中,使用GPU推理引擎Tensor RT对改进后的YOLOv5目标检测模型进行裁剪和重构:对网络层进行横、纵向合并,对模型参数进行量化,减少计算消耗;使用Deep Stream对视频流数据进行结构化处理,经过多方面的优化,实现了在尽可能不影响算法识别精度的前提下极大提高了算法在边缘计算设备上的运行速度。4.针对视力障碍者出行的特殊需求性,本文以超声波传感器HC-SR04模块为基础,引入并改进计算机视觉算法YOLOv5,同时将算法移植到边缘计算设备NVIDIA Jetson Nano B01上,开发了具备实用性的盲道识别与避障系统。通过外出在真实道路上进行模拟实验,得出结论,此系统可以通过超声波避障系统实时检测前进方向上水平面以上的正障碍,同时可以通过计算机视觉避障系统实时识别盲道、盲道上的坑洞等水平面以下的负障碍、斑马线、红绿灯等目标。实现了对导盲目标物的实时检测和语音预警,能够实时辅助视障人士安全出行。整个系统运行稳定,方便携带且具有较高的拓展能力。
{URL}: https://link.cnki.net/doi/10.27103/d.cnki.ghebu.2022.001360
{DOI}: 10.27103/d.cnki.ghebu.2022.001360
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的工业机器人分拣实验平台设计
{Author}: 魏鸿磊;商业彤;孙松;孔祥志;王晶;刘乘昊
{Author Address}: 大连工业大学机械工程与自动化学院;
{Journal}: 实验科学与技术
{Year}: 2022
{Volume}: 20
{Issue}: 02
{Pages}: 138-142
{Keywords}: 机器人控制;手眼标定;目标识别;教学实验平台
{Abstract}: 为提高机械电子等专业学生的实训质量，设计了基于机器视觉的工业机器人分拣实验平台。平台包括上位机、机器视觉、机器人和气动系统共4个子系统，涉及图像目标识别与定位、图像坐标系与机器人坐标系的转换、吸盘控制系统设计等关键技术，并设计了6组创新型实训项目。通过该实验平台，学生可以进行图像采集与处理、机器人控制以及上位机软件开发等多方面的学习。在近三届共30人的学生中进行的教学实验证明，该实训系统对培养学生的学习兴趣、创新能力和实践能力具有重要作用。
{ISBN/ISSN}: 1672-4550
{Notes}: 51-1653/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzo2pxfOr6niRPwo44zYgj8_yVq2FlufwDqD4dxLbF7jti5uY6nRQxYuWkD-1w7o5sOzIeYHmDTpdHAsP2e0HB8W1II4TeNrU_LC6sxNZO_W8XD-QAW3A_yIYsOtODBY_CcdKzuMKd_PAHcMRvbEcntXBjm0161IhGkkr_MemYLItOmwu06RDva2xUXwE-R3yg=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于方向性靶标和多约束优化的双目相机标定
{Author}: 杨霈;殷玉龙;卢荣胜;朱华炳
{Author Address}: 合肥工业大学机械工程学院;合肥工业大学仪器科学与光电工程学院;
{Journal}: 光学学报
{Year}: 2022
{Volume}: 42
{Issue}: 08
{Pages}: 195-206
{Keywords}: 机器视觉;双目相机标定;方向性平面靶标;平面靶标姿态;多约束优化
{Abstract}: 提出了一种基于方向性靶标和多约束优化的双目相机标定方法。新型方向性平面靶标能够判断靶标的旋转方向，并对每个标定角点进行编码，以保证双目相机在拍摄到局部靶标的情况下依然能够完成同名点匹配，进而完成双目相机标定。根据方向性靶标建立双目相机标定模型，引入用于描述平面靶标姿态的天顶角和方位角，通过天顶角和方位角筛选出在不同位置上的靶标姿态均具有明显差异的图像作为标定图像，这提高了双目标定结果的稳定性；结合靶标的三维几何信息，建立了多维度约束的双目参数优化模型，提高了双目标定结果的精度。实验结果表明，与传统的张氏标定方法相比，所提出的标定方法能够有效提高所获得的标定结果的稳定性和精度；通过对标准量块进行多次测量，进一步验证了所提方法的有效性。
{ISBN/ISSN}: 0253-2239
{Notes}: 31-1252/O4
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzAXj92dM0azRio4fqTAvluawt3QIH8ZhgcmtbKu6n6BP8B5cV7ntakl6jvQKVmwZoTWkQRWwVxDmpwuTR7cFDPGAbJR-AXXzZm1zbhiWwqZMApebKLdto9vZq23Ap6VS-LzzGVlk8ryoDjTzFIaL_Xr3bXJbDsKJoQWqw0iwjXWyU-FQp7qE6yKJ2NVbyG6Iw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 人工智能时代计算机视觉技术的发展趋势研究——评《计算机视觉基础》
{Author}: 王明
{Author Address}: 荆州学院;
{Journal}: 现代雷达
{Year}: 2022
{Volume}: 44
{Issue}: 04
{Pages}: 103
{Abstract}: <正>当下，人工智能技术获得快速发展，人们通过人工智能的数据收集、分析等优点，正在不断便利民众的生活以及提升民众的工作效率，现如今人工智能已经在多个领域中大放异彩。其中计算机视觉技术作为人工智能重点研究领域，对于人工智能技术的进一步发展与创新有着十分重要的作用。
{ISBN/ISSN}: 1004-7859
{Notes}: 32-1353/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy9bt-Sr6_D00O7u-tW3d7tyNK6qgdofrzTqT9OcVsbzceker_yP8AGinP2KuxSQxdBwc-9p3YVmJ_oBMXpMVso0aFrIVKqSCnZ3XHdDhBRyem-IXF2qsryRFtoEEx3amuLZx1DdaaVQyOnk-zYV86wPvfesYHWf9gjaMBy5xBTiy7fLpQ0_lbXgyuhH6Ci3-c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 煤矿掘进机器人视觉位姿感知与控制关键技术
{Author}: 徐伟锋;金向阳;张丽平
{Author Address}: 绍兴职业技术学院;中国矿业大学(北京);中煤科工集团国际工程有限公司;国能网信科技(北京)有限公司;
{Journal}: 煤矿机械
{Year}: 2022
{Volume}: 43
{Issue}: 05
{Pages}: 181-184
{Keywords}: 机器视觉;掘进机器人;位姿感知;智能化
{Abstract}: 针对煤矿井下掘进机器人位姿感知精度低、远程监控效果差及智能控制难度大等问题，通过分析机器视觉在煤矿掘进机器人中的应用情况，从掘进机器人位姿视觉检测、远程视频监控、数字孪生驱动控制和智能协同控制等方面进行深入探究，提出煤矿掘进机器人位姿视觉测量原理和方法，结合远程视频监控技术，实现对掘进机器人地面远程控制，并对其应用效果加以分析与总结。同时，为进一步提升掘进机器人智能化程度和远程控制可靠性，利用数字孪生驱动的虚实远程控制技术，构建煤矿掘进机器人三维可视化模型，通过煤矿掘、支、锚、运多种机器人的多位一体并行智能化协同控制，实现煤矿掘进绿色、安全、高效的智能化生产。
{ISBN/ISSN}: 1003-0794
{Notes}: 23-1280/TD
{URL}: https://link.cnki.net/doi/10.13436/j.mkjx.202205059
{DOI}: 10.13436/j.mkjx.202205059
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 采用双目视觉和自适应Kalman滤波的作物行识别与跟踪
{Author}: 翟志强;熊坤;王亮;杜岳峰;朱忠祥;毛恩荣
{Author Address}: 中国农业大学工学院;
{Journal}: 农业工程学报
{Year}: 2022
{Volume}: 38
{Issue}: 08
{Pages}: 143-151
{Keywords}: 导航;机器视觉;图像处理;大田作物;作物行识别;作物行跟踪;线性状态观测
{Abstract}: 针对传统作物行识别方法在相邻图像间的识别结果偏差较大，作物行的定位精度和稳定性低等问题，该研究提出一种基于双目视觉和自适应Kalman滤波技术的作物行识别与跟踪方法。对于作物行识别，首先建立图像预处理算法，基于改进的超绿-超红模型和最大类间方差法分割植被灰度特征；建立作物行特征提取算法，基于特征点检测技术和双目视差测距方法计算植被角点特征的三维坐标，根据三维阈值提取作物行特征点，进而建立作物行中心线检测算法，建立基于主成分分析的直线拟合模型，根据作物行特征点的频数统计规律检测作物行冠层中心线。对于作物行跟踪，建立跟踪目标规划模型，提取位于图像中央区域的作物行作为跟踪目标；建立目标状态方程，基于自适应Kalman滤波技术构建作物行中心线跟踪模型。以棉花图像开展试验研究，图像数据包括阴影、杂草、地头等田间场景。试验结果表明，该研究方法的作物行识别准确度、精度和速度均较高，识别正确率约为92.36%，平均航向偏差为0.31°、标准差为2.55°，平均识别速度约80.25 ms/帧；经目标跟踪后，航向角和横向位置估计的标准差分别为2.62°和0.043m、较无跟踪状态分别减小22.94%和10.42%，作物行中心线的方位估计精度进一步提高。研究成果可为导航系统提供连续、稳定的作物行导引参数。
{ISBN/ISSN}: 1002-6819
{Notes}: 11-2047/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy5VVdQcz0M6PQTKygMtPU84Edpbb8umJ3MViNcFdmzLyJatOuzG2BCZpk1F1k-aY5dJ1K8OQoXBz80gR8r9HMcMnnDbu9WnAAOUKBTXJaWsfNqyB08w3jeqmNcuPQYQaWPTTdiAunbqS7la5e54n8GUqK6GLgRtpWvcolYP4FsaFuBQE_2Fj2x0XJhAEE0wYA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 点线特征自适应融合室内SLAM算法
{Author}: 刘少哲;刘作军;胡超芳;陈海永
{Author Address}: 河北工业大学人工智能与数据科学学院;天津大学电气自动化与信息工程学院;
{Journal}: 小型微型计算机系统
{Year}: 2023
{Volume}: 44
{Issue}: 05
{Pages}: 1015-1022
{Keywords}: 机器视觉;同时定位与地图创建;点线特征;自适应模型;低纹理
{Abstract}: 传统的视觉同时定位与地图创建(SLAM)依赖于点特征来估计相机位姿.然而在室内环境中存在大量低纹理区域，使得提取足够多的点特征变得困难.此外，当相机抖动剧烈或转向过快时，基于点特征的SLAM系统也并不鲁棒.针对上述问题，本文提出了一种基于RGB-D的点线特征融合SLAM算法，利用点特征和线特征的优点，在困难环境下获得了鲁棒的结果.首先，提出了一种基于特征丰富度的特征提取策略.解决在模糊和低纹理区域内提取特征困难的问题.其次，设计了一种点线特征关联图，优化线特征匹配效果.该方法不仅参考了线特征之间的相似关系，还考虑了点线特征之间的几何关系.最后，在构建光束法平差的成本函数时建立自适应模型，实现点线双模态特征的"无缝融合".本文分别在两个公开数据集和室内真实场景中进行了算法评估，并与其他先进算法对比.结果表明本文提出的算法具有更好的整体性能.
{ISBN/ISSN}: 1000-1220
{Notes}: 21-1106/TP
{URL}: https://link.cnki.net/doi/10.20009/j.cnki.21-1106/TP.2021-0743
{DOI}: 10.20009/j.cnki.21-1106/TP.2021-0743
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的植物三维重建方法研究
{Author}: 安亚剑
{Tertiary Author}: 张志斌
{Publisher}: 内蒙古大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 植物三维重建;深度学习;图像分类;多视图;深度估计
{Abstract}: 随着计算机视觉的高速发展,植物三维重建技术应用于农业机器人导航、生态环境监测等多个科研领域。传统三维重建算法中,由于植物本身形态复杂,当处于自然环境条件下,例如不同光照等难以满足高质量植物三维重建的要求。随着深度学习的不断发展,将深度学习结合三维重建算法可实现高质量三维重建,但深度学习植物三维重建目前国内外鲜有相关研究。故本文基于深度学习三维重建网络对不同光照条件下多视图植物进行高质量三维重建,主要研究工作如下:第一、为去除背景对于植物三维重建的影响,首先采用传统的算法,对基于不同光照条件下的多视图植物图像提出基于灰度统计直方图参数的主成分分析(PCA)统一阈值图像分类方法。然后,对已分类植物图像分别采用不同的分割方法将植物与背景进行分割,以消除背景对三维重建的影响。即采用颜色因子结合阈值法,进行正常光照条件下植物图像分割;采用轮廓系数优化SLIC超像素块,并结合决策树算法,进行异常光照条件下的植物图像分割。实验结果表明本文方法的有效性,图像分类方法平均误差为0.004%,能够实现光照影响植物图像的准确分类;正常光照下的植物图像分割精度可达95%以上,异常光照下的植物图像分割精度为83.75%,且轮廓系数改进植物图像分割精度为84.37%。第二、在植物图像分割基础上,基于深度学习网络Patchmatch Net进行植物三维重建模型构建。针对原网络多尺度特征提取模块权值共享无法有效分离前景、背景的特征而影响最终三维重建的问题,首先将注意力机制模型SENet、CBAM分别引入多尺度特征提取网络模块,对通道特征及空间特征重新赋予权重,以提升网络对于目标重建的关注度。然后,为进一步优化深度图质量从而保证最终三维重建质量,针对原网络深度图模块,采用多尺度残差网络,并融合参考图生成残差多尺度优化的深度图,以实现高质量植物三维重建。最后,基于深度学习框架Py Torch实现整个算法模型,并进行不同注意力机制、多尺度残差网络的定性、定量分析,且与传统三维重建算法进行对比。实验结果表明,相较于传统三维重建算法Camp、Gipuma、COLMAP,本文方法误差分别降低44.3%、45.9%、30.8%;相较于深度学习网络MVSNet、Patchmatch Net,本文方法误差分别降低24.1%、4.6%;对比深度图质量及三维重建质量,本文改进网络可生成范围更广、平滑度更高的深度图,可最终将深度图进行融合构建出高质量的三维点云模型;且对于不同光照条件及弱纹理植物的三维重建,本文改进方法具有较好的鲁棒性与泛化性能力。
{URL}: https://link.cnki.net/doi/10.27224/d.cnki.gnmdu.2022.001164
{DOI}: 10.27224/d.cnki.gnmdu.2022.001164
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 消防救援机器人辅助探测系统设计
{Author}: 张亚婉;莫浩明;朱颖;唐艳凤;招奕钧
{Author Address}: 广东工业大学华立学院机电工程学院;
{Journal}: 电子设计工程
{Year}: 2022
{Volume}: 30
{Issue}: 08
{Pages}: 66-70
{Keywords}: OpenCV;视频识别;火灾探测;计算机视觉
{Abstract}: 针对消防救援行动中，消防人员不能立刻掌握火场内部信息而导致救援不及时，文中设计了一套基于OpenCV计算机视觉库和CUDA运算平台应用于消防机器人的辅助探测系统，提出使用RGB色彩空间与HSI色彩模型混合技术识别火焰颜色、面积等特征，识别实时输入的视频序列中是否有火焰信息。在正常、过强、昏暗3种光照条件下模拟实现了识别单个或多个火焰的情况，实验结果表明，该方法能够准确地识别火焰行为，可以对不同光照条件进行有效识别，以实际真火实验的100张图片为样本，识别准确率超过96%。
{ISBN/ISSN}: 1674-6236
{Notes}: 61-1477/TN
{URL}: https://link.cnki.net/doi/10.14022/j.issn1674-6236.2022.08.014
{DOI}: 10.14022/j.issn1674-6236.2022.08.014
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的答题卡智能识别算法研究
{Author}: 张风霞;段金成;朱晓庆;万雷鸣
{Author Address}: 黑龙江科技大学电子与信息工程学院;哈尔滨铁路局大功率机车检修段;
{Journal}: 科学技术创新
{Year}: 2022
{Issue}: 12
{Pages}: 24-28
{Keywords}: 机器视觉;图像处理;人工智能;答题卡
{Abstract}: 答题卡识别是机器视觉研究中的一项关键的内容，也是图像处理以及人工智能研究的一个关键的方向。本文针对具有大量客观题的答题卡识别任务场景，设计了一套利用填涂点特征信息进行填涂信息识别的算法。该算法首先对采集的图像信息进行二值化、滤波、倾斜校正等预处理，其次综合利用填涂面积和灰度等信息对目标图像进行识别，最后将识别结果与标准答案样本进行比对，得出最后结果。经过实验验证，该算法平均识别的速度可以保证控制在2s内，对于规范的填涂情况下的答题卡，准确性为99.23%，基本上能够满足实际的应用要求。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvwgoiEb9wkx46NwzCdpdFN11RJ_DexLvglVNxe3Q-pVTAduoQtM3HCpTv5pNvOKNVvg0n_F59Thg1nbA-DnK0FWNuO_-UjxOFZIpAaXAqf-MMleJDu3Ala7q6IlPIegHaAr1t6-9RYkyRzMk67a7sohPjSrxJFZoghRF_5wdHDhBGzZ0xYCvFZ1pwhp-pWPkxA=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 融合自注意力机制的生成对抗网络跨视角步态识别
{Author}: 张红颖;包雯静
{Author Address}: 中国民航大学天津市智能信号与图像处理重点实验室;中国民航大学电子信息与自动化学院;
{Journal}: 中国图象图形学报
{Year}: 2022
{Volume}: 27
{Issue}: 04
{Pages}: 1097-1109
{Keywords}: 机器视觉;步态识别;跨视角;自注意力;生成对抗网络(GANs)
{Abstract}: 目的 针对目前基于生成式的步态识别方法采用特定视角的步态模板转换、识别率随视角跨度增大而不断下降的问题,本文提出融合自注意力机制的生成对抗网络的跨视角步态识别方法。方法 该方法的网络结构由生成器、视角判别器和身份保持器构成,建立可实现任意视角间步态转换的网络模型。生成网络采用编码器—解码器结构将输入的步态特征和视角指示器连接,进而实现不同视角域的转换,并通过对抗训练和像素级损失使生成的目标视角步态模板与真实的步态模板相似。在判别网络中,利用视角判别器来约束生成视角与目标视角相一致,并使用联合困难三元组损失的身份保持器以最大化保留输入模板的身份信息。同时,在生成网络和判别网络中加入自注意力机制,以捕捉特征的全局依赖关系,从而提高生成图像的质量,并引入谱规范化使网络稳定训练。结果 在CASIA-B(Chinese Academy of Sciences’ Institute of Automation gait database——dataset B)和OU-MVLP(OU-ISIR gait database-multi-view large population dataset)数据集上进行实验,当引入自注意力模块和身份保留损失训练网络时,在CASIA-B数据集上的识别率有显著提升,平均rank-1准确率比Gait GAN(gait generative adversarial network)方法高15%。所提方法在OU-MVLP大规模的跨视角步态数据库中仍具有较好的适用性,可以达到65.9%的平均识别精度。结论 本文方法提升了生成步态模板的质量,提取的视角不变特征更具判别力,识别精度较现有方法有一定提升,能较好地解决跨视角步态识别问题。
{ISBN/ISSN}: 1006-8961
{Notes}: 11-3758/TB
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvy7ztVzDG6HmbBpBADAtEgJaqTgBUmm3Uoi3hcuJ2R8OARAwNUfYRJqSUQc7RcxW7C2SOQv_yX9_jj1s2cBJHzXpyPzOgy6X5tuJFBZFnJOIyQeYtp8odrU1jIhiwvbViic-6WyXMSGTz8o5lONc8gewBGRb-psCATkdnzC3-TP2adqQgzmRlOxGlXdaGBAB7I=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 行为识别中视频时空建模及其鲁棒性研究
{Author}: 张静然
{Tertiary Author}: 申恒涛
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 动作识别;图卷积网络;表征学习;自监督学习;对抗攻击
{Abstract}: 随着移动互联技术的发展和便携数据采集设备的普及,视频数据非常容易获取并成为生活中传播信息的重要载体,同时它也促进了人们获取信息途径和分享生活的方式,基于这些视频数据的信息挖掘和内容理解是引领城数字经济发展的重要选择。视频行为识别任务作为视频分析和理解的重要研究内容之一,不仅有着重要学术意义,而且存在广泛的应用前景。面对快速增长的视频数据,利用深度学习技术进行行为识别已成为主流的方式,如果只是简单的应用深度网络,很难挖掘有复杂结构的视频中的本质特征,为了高效分析视频以识别视频中的行为,需要考虑以下三点:(1)合理分析视频时空结构;(2)减少对标注数据依赖;(3)进行模型安全分析。这三个方面的研究核心在于探索鲁棒的视频时空分析理解技术,本文基于这种考虑,开展一系列包括有监督视频行为识别方法、无监督视频表征方法、基于视频行为识别的对抗攻击方法的研究,并着重探讨其中的难点和后续的研究开展方向;主要的工作如下:(1)提出了基于时域推理图的视频行为识别模型。虽然现在的基于深度学习的视频行为识别方法相较于传统方法有很大进步,但它们大多只考虑短程时序建模,对细粒度的动作关联和长程的行为依赖结构关注较少,而对视频中时序依赖的探索是复杂行为识别中必不可少的部分。本文方法构建多头时序邻接矩阵来表征行为间的动作粗细粒度依赖关系,避免了无法进行时序建模和只能进行长程尺度的粗粒度动作关系建模问题;同时以该多头邻接矩阵为基础进行图卷积,对视频中的长短动作时序关系进行推理,并应用新创建的多头语意融合器对各种类型的动作关系进行特征语意融合,从而提高了视频行为的类别识别准确度。在主流的基础数据集上,本文方法取得了最优的结果,后续的消融实验也证明了时域推理图可以提取有判别性的特征。(2)提出基于图对比增强的视频自监督表征学习方法。将图像邻域的对比学习方案扩展到视频领域需要考虑序列型数据间的时序结构特性。基于这种考虑,本文方法提供了一个新的视角来研究视频中的时序结构,具体地,提出一种构建时域图方法和设计一种在该时域图基础上进行图数据增强方法,以高效的利用视频中帧相关性特性来进行视频帧序列对对比学习。首先,利用关联视频特征间局部相似性进行时域图构建,然后在时域图的基础上提出新颖的图增强方法进行视频表征学习,该增强方法主要是通过对时域图进行加噪扰动,扰动后的时域图增加了多样性但仍旧保留了完整的视频结构特性;最终,本文应用两种新颖的对比学习方案来训练所提出的框架,并以隐藏在视频背后的本质结构特性作为自监督信号。实验部分,本文方法在一系列下游任务如视频行为识别、视频检索上,验证本文方法的有效性。(3)提出基于视频自监督课程学习的视觉和语音关联性增强方法。合理的利用语音和视觉的并发特性特性,不仅可以减小人工标注的成本,而且可以更高效的提取视觉和语音特征。但现在的大多工作只是关注两个模态间共享关联信息,很少单独考虑每个模态中特有信息。为了解决这些问题,本文方法可以考虑语音和视频帧序列对不同模态间的关联性,同时关注单模态本身的结构特性。具体地,在教师-学生迁移框架下提出一种两阶段的学习方法来进行语音和视频帧序列对对比学习,以克服直接进行教师-学生移学习的困难性;其次,利用语音和视觉信息的关联性作为潜在自监督信号进行对比迁移训练;最终,利用教师-学生结构下学习的语音和视觉表征进行下游视频动作和语音识别测试。后续的实验也验证这种方式进行视频中视觉和语音表征学习有利于下游任务如动作识别和语音识别。(4)提出基于视频动作识别模型的采样不敏感对抗攻击方法。尽管基于深度学习的动作识别模型在公开数据集上获得取得长远的进步,但它们对实际输入数据的扰动噪声鲁棒性问题上研究较少。本文在图像对抗攻击的基础上研究视频动作识别模型的鲁棒性问题,考虑了视频的时序冗余特性,所提出的方法可以生成一种对采样方法不敏感的对抗扰动,保证对视频中任意的采样帧进行攻击处理后仍然可以让视频识别模型错误分类。首先,提出一种时序连贯性正则化算子,它以扰动后序列帧的信息增益来挖掘攻击后的视频帧的时序信息;其次,提出一种高效的近似梯度优化算子来迭代生成对抗扰动,以保证对抗方法对采样不敏感;最终,提出一个攻击校验约束来调整上述的对采样不敏感的扰动,达到最终的视频动作识别对抗攻击目的。实验部分结果表明本文方法有更好的攻击性能。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000292
{DOI}: 10.27005/d.cnki.gdzku.2022.000292
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的交通违法行为检测
{Author}: 张涛
{Tertiary Author}: 袁伟
{Publisher}: 长安大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 交通安全;交通违法行为检测;NanoDet算法;YOLO＿F算法;PP＿Picodet算法
{Abstract}: 近年来,随着我国汽车保有量不断增长,各类因交通违法行为而造成的交通事故频繁发生,这对人民生命和财产安全造成了严重的威胁。如何快速检测交通违法行为,提升检测的准确率,一直是当前交通安全领域的研究重点。驾驶员正确地佩戴安全带,可以有效的避免交通事故中驾驶员的死亡率,能够快速且准确地检测出驾驶员是否佩戴安全带,是本文的研究重点之一。检测道路车辆是否遮挡车牌也是本文的研究重点之一,实时地检测车牌遮挡行为能够起到维持交通秩序的作用,进而可以降低交通事故的发生率。电动车和摩托车骑乘人员正确佩戴安全头盔,可以有效的提高骑乘人员在交通事故中的生还率。因此,准确的检测骑乘人员是否佩戴安全头盔也是本文研究的重点内容。论文以基于计算机视觉的交通违法行为检测为研究对象,首先对图像处理、卷积神经网络和目标检测的相关理论进行了概述。针对驾驶员安全带检测,分析了 NanoDet目标检测算法的模型结构,根据YOLOF算法的思想,对特征融合模块进行了优化和改进,使用Dilated Encoder结构代替PAN结构实现特征融合,提出了 NanoDet-saft安全带检测算法,并在驾驶员区域检测任务和安全带检测任务中分别达到了 99.7%和95.4%的准确率;针对道路车辆遮挡车牌行为的检测,全面分析了 PP-Picodet算法的网络结构,去除了 PP-Picodet算法Neck结构中C3尺度特征图的输入以及Head结构中P6尺度检测头,提出了 Picodet-License车牌遮挡检测算法,在自制的车牌遮挡检测数据集中,达到了 98.3%的检测准确率;针对电动车和摩托车骑乘人员安全头盔的检测,选择改进的NanoDet-saft作为检测模型,一次性检测骑乘人员是否佩戴安全头盔,准确率为95.82%。论文通过对驾驶员不佩戴安全带、遮挡车牌以及骑乘人员不佩戴安全头盔等交通违法行为检测方法的研究,可以有效地降低交通事故的发生率,同时也可以有效降低驾驶员和骑乘人员在事故中的死亡率。论文的研究能够为交通管理部门提供一定的理论指导和建议。
{URL}: https://link.cnki.net/doi/10.26976/d.cnki.gchau.2022.001417
{DOI}: 10.26976/d.cnki.gchau.2022.001417
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于无标签视频数据的深度预测学习方法综述
{Author}: 潘敏婷;王韫博;朱祥明;高思宇;龙明盛;杨小康
{Author Address}: 上海交通大学人工智能研究院人工智能教育部重点实验室;清华大学软件学院;
{Journal}: 电子学报
{Year}: 2022
{Volume}: 50
{Issue}: 04
{Pages}: 869-886
{Keywords}: 深度学习;自监督学习;计算机视觉;视频预测;有模型的视觉决策
{Abstract}: 基于视频数据的深度预测学习(以下简称“深度预测学习”)属于深度学习、计算机视觉和强化学习的交叉融合研究方向,是气象预报、自动驾驶、机器人视觉控制等场景下智能预测与决策系统的关键组成部分,在近年来成为机器学习的热点研究领域.深度预测学习遵从自监督学习范式,从无标签的视频数据中挖掘自身的监督信息,学习其潜在的时空模式表达.本文对基于深度学习的视频预测现有研究成果进行了详细综述.首先,归纳了深度预测学习的研究范畴和交叉应用领域.其次,总结了视频预测研究中常用的数据集和评价指标.而后,从基于观测空间的视频预测、基于状态空间的视频预测、有模型的视觉决策三个角度,分类对比了当前主流的深度预测学习模型.最后,本文分析了深度预测学习领域的热点问题,并对研究趋势进行了展望.
{ISBN/ISSN}: 0372-2112
{Notes}: 11-2087/TN
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz1zLvduY-GZFSDPmH8xvVY6bs0HVLOX5EdTiXtOEbDXCZS9TfQFqdvWWTz4g81wg7JcTu4bMgvhJYk4d2FRgRZf4KB60NC3VMXcOf_aNhJFA8T6ufAK7PmFV-_3A4CUS_4mucu63AQI6OGvT_vAoyq-f7KctD2889176eC-_vScI3VkCahWgwAlJnMH30hayY=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于颜色直方图的电路板表面缺陷检测
{Author}: 仰梓淮;黄海鸿;刘贺;刘赟;李新宇;刘志峰
{Author Address}: 合肥工业大学机械工程学院;合肥工业大学机械工业绿色设计与制造重点实验室;
{Journal}: 计算机集成制造系统
{Year}: 2024
{Volume}: 30
{Issue}: 07
{Pages}: 2296-2305
{Keywords}: 机器视觉;二次利用电路板;表面缺陷检测;颜色直方图;四叉树分裂
{Abstract}: 为了提高废旧电路板的回收再利用率，针对回收电路板常见表面缺陷，在均匀分块基础上，提出了四叉树分裂颜色直方图缺陷检测方法。该方法能快速定位电路板表面缺陷，并通过支持向量机(SVM)实现缺陷分类，进而为电路板的二次利用提供质量保障。重点分析了分块大小与判断阈值对缺陷定位结果的影响，在保证检测精度的同时，检测速度相比均匀分块方法得到明显提升。与Faster-RCNN网络方法进行对比，结果表明该方法定位效果好，分类准确率平均达81%。
{ISBN/ISSN}: 1006-5911
{Notes}: 11-5946/TP
{URL}: https://link.cnki.net/doi/10.13196/j.cims.2021.0946
{DOI}: 10.13196/j.cims.2021.0946
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于手势识别的机器人人机协作研究
{Author}: 林珂如
{Tertiary Author}: 李迅波
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人机协作;目标识别;手部跟踪;手势估计
{Abstract}: 人机协作一直是一个不断发展、突破的热门研究,近几年,我国在人机交互上也取得了很大的进展,无论是在日常生活中的人脸识别购物、触摸式交互手机进行日程操作,还是工业背景下的语音协作机器人完成卸货、人眼识别完成员工身份验证,这些都给人们的生活带来巨大的改变。由于近几年新冠疫情的反反复复,人们意识到了更卫生的非接触性交互的必要性,然而经过反复对比,既能满足非接触性要求,又能应用于嘈杂环境的工业环境中的交互方式只有灵活性高的手势交互。手是人用来表达信息和交互协作的重要部位,其灵活程度也最高,能产生大量的交互式信息和动作。本文设计了一种基于手势姿态估计结合手势识别的人机协作系统。将两者的优势结合起来,并根据实际的应用场景和当前对模型轻量化的需求,设计了一种先进行手掌检测,达到设定阈值后,再启动手部骨骼点标注的手部跟踪方法。这种方法的优点在于并不需要在图像采集手势的每一帧都启用手掌检测,从而达到对资源的优化利用,与此同时,还利用二维约束设计了手部关键点层级的手势识别实现十种手势的识别。结合这些方法,本文设计了一款双模式的手势识别人机协作系统。本论文主要内容如下:(1)构建SSD-MoblieNet手掌检测模型,采用轻量级卷积神经网络Mobile Net代替SSD网络中的VGG16,保证识别平均精准度的同时,降低模型参数量和计算量。(2)将手部目标检测和关键点检测融合在一起进行,直接从SSD-Mobile Net网络中的Roi Pooling层进行关键点的位置估计,融合六个层次的特征图,实现对低分辨率手势图关键点的良好估计。(3)设计了两种不同的人机交互模式,即以十种静态手形控制机械臂完成不同的动作及控制界面的信息调取;建立虚拟键盘,通过跟踪手部关键点来控制计算机的光标移动和虚拟键盘输入。多种交互协作方式,可以让实际的加工现场拥有更好的交互体验。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003002
{DOI}: 10.27005/d.cnki.gdzku.2022.003002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的带式输送机大块异物检测系统设计
{Author}: 王燕
{Tertiary Author}: 刘新华
{Publisher}: 中国矿业大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 带式输送机;大块异物检测;改进模板匹配算法;优化MLP分类算法
{Abstract}: 带式输送机是煤矿井下运输煤炭的关键设备,在采煤过程中岩石层掉落的大块石头,或者机器振动掉落的零部件会进入带式输送机,导致带式输送机上出现大块石头、铁器、木头杂物等大块异物,这些大块非煤异物进入带式输送机后极易造成带式输送机卡阻或输送带跑偏,导致输送带被划伤撕裂,不仅影响煤矿生产运输的安全性,还会造成严重的经济损失,且煤矿井下环境较为恶劣,采集的图像质量不理想,对大块异物的检测造成一定的干扰。针对上述问题,本文设计了基于机器视觉的带式输送机大块异物检测系统,首先对采集的运煤图像进行图像去噪和图像增强,接着对带式输送机上的大块异物进行准确识别、筛选及分类。论文的主要工作与研究内容如下:(1)进行了基于机器视觉的带式输送机大块异物检测系统的总体设计,分析了系统的功能需求,介绍了系统的软件、硬件组成,并进行了硬件选型,搭建了煤矿井下大块异物检测系统的框架,梳理了大块异物检测流程。(2)进行了煤矿井下运煤图像预处理算法的研究,包括图像去噪和图像增强。根据图像去噪客观评估指标分析对比不同去噪算法的优劣,选取滤波参数为2.3的递归滤波进行去噪。提出了一种自适应权重的多尺度Retinex算法,根据图像三个颜色通道中入射分量的大小,自适应地进行权重分配,经过改进算法处理后的运煤图像,其信息熵相比原图提高了26.6%,对比度提高了14.3%。(3)进行了大块异物识别、筛选及分类算法的研究,提出了一种基于相关性的改进模板匹配算法,将模板匹配算法结合帧差法和面积法对大块异物进行准确识别、筛选。分析对比了不同大块异物的纹理特征,选取合适的纹理特征参数作为分类依据。提出了一种基于优化灰狼算法的多层感知机(Multilayer Perceptron,MLP)分类算法,使用优化灰狼算法对多层感知机的权重和偏置进行寻优,优化MLP分类算法对大块异物的分类准确率达到98.8%。(4)进行了大块异物视觉检测系统的实验研究,根据煤矿井下的实际检测需求,对系统提出了四点设计要求,设计开发了系统的软件平台。在实验室搭建平台进行实验,在高阳煤矿开展了工业性现场试验,试验结果表明本文设计的系统能够对大块异物进行准确识别、筛选及分类,满足工业检测需求,验证了系统的可行性。本文共有图48幅,表17个,参考文献94篇。
{URL}: https://link.cnki.net/doi/10.27623/d.cnki.gzkyu.2022.000183
{DOI}: 10.27623/d.cnki.gzkyu.2022.000183
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 计算机视觉技术在食品检测中的应用——评《食品检测技术——食品安全快速检测技术》
{Author}: 谭英丽;陆薇
{Author Address}: 石家庄医学高等专科学校;
{Journal}: 粮食与油脂
{Year}: 2022
{Volume}: 35
{Issue}: 04
{Pages}: 169
{Abstract}: <正>近年来，食品安全事故频发，为保障民众有更好的生活品质，相关部门制定了多项法律法规以规范食品的质量标准管理；同时，科学家也致力于从各个方面提升国家食品安全检测技术水平。研究发现，计算机视觉技术可以高效、快速且安全无损地实现食品质量检测，且该技术应用范围十分广泛。由朱克永、揭广川、包志华联合编著，科学出版社于2016年1月出版的《食品检测技术——食品安全快速检测技术》一书，系统介绍了食品安全检测技术，详细解读了关于各类食品安全的快速检验技术，并对食品质量安全快速检测技术的发展进行了展望。
{ISBN/ISSN}: 1008-9578
{Notes}: 31-1235/TS
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvytFkcjWVWmnmM3XSienLpWJICOGQMGYfUNiM47gm9GMaW23GKkYKLllmf_ZhiZf8Lx8JLdgKz6hktUxy2PuVDVKpianp8Nhmlhcelwvbn8ml5dWNS4obHtCk-AeAmofNOCv3m76zFIxnnLP5lAmwH6kYX0frn25Hc41fpnwExCVuCr2BFf0mw5VGFISmcizBk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多模态和多模型融合的三维目标检测
{Author}: 王泽杰
{Tertiary Author}: 沈超敏
{Publisher}: 华东师范大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 三维目标检测;门控注意力;多模态融合;一致性正则化;多模型融合
{Abstract}: 随着自动驾驶技术的发展,人们对感知模块可靠性的需求愈加强烈。为保障决策与控制过程的安全,无人车对道路周围物体的轨迹进行估计,获取位置、速度、类型、大小等信息。其中,针对行人、骑行者等容易误检和漏检的目标,现存搭配单传感器的方法存在检测不确定性大、感知范围有限等不足,较难应用于城市复杂道路场景。因此,本文以多传感器和多模型融合为出发点,将激光点云精确的空间信息和二维图像稠密的像素信息优势互补,获取更全面、鲁棒的行驶环境信息,从而提升三维目标检测的性能,满足自动驾驶系统对可靠性、精准度的需求。为了实现更高精度的感知,利用集成学习的思想,将每个检测模型产生的候选框根据权重进行融合,进一步提升三维目标检测的精度,满足适应各种行驶环境的要求。本文的主要研究内容如下:1、提出了一种点云图像融合的新范式,设计了多任务联合感知的深度卷积神经网络框架。主要创新点如下:(1)将多标签物体识别网络作为三维目标检测的辅助任务,预测的物体类别信息作为三维目标检测任务的一致性正则化约束条件,有效解决了误检和漏检现象,提升自动驾驶场景下多个类别的三维目标检测精度。(2)在特征提取阶段,提出基于多层门控注意力机制的模块,自适应地融合从高维到低维不同尺度下的空间和语义信息。(3)针对两阶段检测器,将RCNN模块提取的ROI池化区域特征与图像的全局深度语义信息进行融合,整合深层的语义信息,实现更精确的回归预测。为验证方法的有效性,本文在KITTI公开数据集上进行了充分的实验比较和消融。在不依赖额外视觉图像标签的情况下,本文提出的融合算法能够显著提升三维目标检测的精度。2、融合改进的Center Point算法和Point Pillar算法,用于解决感知算法无法适应众多交通参与者存在下的复杂道路环境的问题。主要创新点如下:(1)对Center Point模型引入不同尺度的体素网格进行采样,同时在点云特征提取阶段加入子流形卷积降低模型复杂度,继而在检测网络的RPN层后添加注意力模块,实现对关键点云特征的捕捉。(2)对于Point Pillar模型,首先使用Reg Net作为骨干网络提取伪点云图像特征,然后采用Free Anchor检测头优化了物体和锚框的匹配,提升了复杂场景下多类别三维物体检测的精度。最后,通过WBF方法融合了改进的Center Point算法和Point Pillar算法,多项评价指标在nu Scenes数据上名列前茅,并在Neur IPS 2020自动驾驶挑战赛排名第一。
{URL}: https://link.cnki.net/doi/10.27149/d.cnki.ghdsu.2022.003337
{DOI}: 10.27149/d.cnki.ghdsu.2022.003337
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于多视角图像的植物三维重建与分割方法研究
{Author}: 吕惠
{Tertiary Author}: 娄路
{Publisher}: 重庆交通大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 植物表型;多视角图像;实例分割;三维重建;深度学习
{Abstract}: 由于植物姿态复杂多样和自身遮挡等问题,传统的基于单视角二维图像处理方法存在特征采集不完整、精度较低、通用性差等问题,已经不能满足植物表型学研究的需求。利用现代传感器（如深度相机、激光扫描、摄像头阵列等）数据采集,借助计算机视觉、图像分析、深度学习等最新算法,对观测植物进行多视角采集和三维模型重建,在三维空间进行植物器官分割,特征提取与分析,是当前植物表型研究的热门领域。本文提出一种基于深度学习和多视角图像的植物三维重建和分割方法,可实现植物表型参数的高精度测量。论文的主要研究工作和创新点如下:1)植物器官实例分割数据集的建立。早期用于植物表型研究的数据主要是单视角二维图像,且拍摄种类大多数是形态结构较为简单的幼苗期植物。因此,本文对自采集的拟南芥,酸浆和玉米等植物的全生长周期的多视角图像数据集进行了植物器官的手工分类标注,以COCO数据集格式建立了相应的深度学习评测植物数据集。传统的表型研究对象一般只有叶子一个类别,本数据集把植物器官分类精细化为叶子、茎和叶柄三个类别。2)多视角图像与特征跟踪的植物器官实例分割算法。为解决植物遮挡导致的分割精度低的问题,本文提出一种利用Mask-RCNN算法进行二维图像的植物茎叶分割,结合多视角图像中的叶子特征点的空间约束性,实现器官的跟踪与计数的新方法。本文在自建数据集（拟南芥、酸浆和玉米）和公共数据集（CVPPP）上进行实验,分割精度较高,可达到m AP0.5为87.5%,m IOU为73.4%的高精度。同时,增加特征匹配和跟踪算法,能有效克服植物叶片严重遮挡情况下的精度下降问题。3)植物三维点云重建与分割算法。本文提出一种基于多视角深度学习MVSNet算法的植物三维点云重建方法,并利用多视角二维图像分割精度高的优点,通过2D-3D投影转换和投票分类策略,实现植物器官的高精度点云分割。而一些传统植物三维分割方法直接应用三维图像领域中三维点云技术,通过几何特征提取、深度学习等进行植物三维点云分割,忽略了植物与静态不变的、人造的物体形态上三维点云特征的差异,存在分割精度低且速度慢的问题。本文提出的方法在三维点云重建质量、速度、器官分割精度与通用性等方面都具有很大优势。
{URL}: https://link.cnki.net/doi/10.27671/d.cnki.gcjtc.2022.000614
{DOI}: 10.27671/d.cnki.gcjtc.2022.000614
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于图像处理的木板表面缺陷检测与识别研究
{Author}: 梁建勇
{Author Address}: 安康学院电子与信息工程学院;
{Journal}: 电子设计工程
{Year}: 2022
{Volume}: 30
{Issue}: 07
{Pages}: 165-169+174
{Keywords}: 图像处理;木板缺陷;机器视觉;表面检测
{Abstract}: 基于木板表面缺陷检测操作方便、使用要求低，能满足现代板材生产企业大规模自动化生产的需求，文中采用图像处理技术对木板表面缺陷进行检测研究，对木材的节子、裂纹、虫洞等典型缺陷进行特征提取及缺陷识别。实验结果表明，文中所设计的检测系统能够对原木板材的表面缺陷情况进行快速有效的缺陷检测，识别正确率为96.6%，单图平均检测时间为0.35 s。
{ISBN/ISSN}: 1674-6236
{Notes}: 61-1477/TN
{URL}: https://link.cnki.net/doi/10.14022/j.issn1674-6236.2022.07.034
{DOI}: 10.14022/j.issn1674-6236.2022.07.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于视觉技术的非接触测量精度优化研究
{Author}: 邓伟伦;于涛;詹洪陈;丁尧
{Author Address}: 南京大学金陵学院信息科学与工程学院;中国·福州物联网开放实验室;
{Journal}: 电子测量技术
{Year}: 2022
{Volume}: 45
{Issue}: 05
{Pages}: 118-123
{Keywords}: 图像处理;非接触测量;图像增强;机器视觉;超分辨重建
{Abstract}: 针对精密加工行业零件形位公差在线检测实时性不高并且无法同时检测多个零件的问题，采用机器视觉技术，改良了相机采集图像的图像预处理流程与测量方法，提出一种基于CNN的超分辨重建的非接触测量改良算法。相较于其他超分辨率重建算法该算法模型简单，精度较高，速度快，在资源受限的情况下可以兼顾测量精度和效率。为了验证所设计算法的可靠性，设计了一套机器视觉的非接触测量系统。实验结果表明，改良测量方法后测量精度较之前使用的测量方法至少可提高47.86%,平均提高49.67%;该超分辨率算法在分辨率一定的基础上，对原始采集图像的超分辨率重建提升图像分辨率后，测量精度较不使用超分辨率重建提高了60.38%,最后利用该算法实现对多个目标在线同步测量分析，并且精度不低于同分辨率下单一零件检测精度。
{ISBN/ISSN}: 1002-7300
{Notes}: 11-2175/TN
{URL}: https://link.cnki.net/doi/10.19651/j.cnki.emt.2108489
{DOI}: 10.19651/j.cnki.emt.2108489
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的公共场景下口罩佩戴检测算法
{Author}: 朱瑞
{Tertiary Author}: 朱学勇
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 人脸检测;戴口罩人脸分类;神经架构搜索;联邦学习
{Abstract}: 随着新冠疫情的全球爆发,人们的生产和生活受到了巨大的影响。口罩是抗击新型冠状病毒的有效个人防护工具。佩戴口罩也是防止新型冠状病毒在火车站、教室、街道等公共场所传播的一种有效而简单的方法,因此在很多公共场所要求人们佩戴口罩。完全依靠人力在公共场所检测人们佩戴口罩不可避免地存在强度高、效率低、覆盖小、时效差等缺点,因此使用计算机视觉技术检测并督促人们佩戴口罩具有积极的社会意义。然而现有的检测方法主要针对行人依次通过闸机或检查点这样背景单一,人脸数量少的应用场景。本文主要针对密集人群,复杂背景,人脸存在不同的尺寸或相互遮挡等应用场景,基于深度学习相关技术设计公共场景下口罩佩戴检测算法。本文主要的创新与工作量可以总结为如下几点:(1)设计了用于人脸检测的DFL(Dilation Face Location)网络。通过实验比对了三个主干网络的检测效果,最终选择Res Net作为主干网络。通过融合自下而上和自上而下两条数据通路提高了在复杂背景下对人脸的检测能力。通过融合空洞卷积与普通卷积的方式改进了加强特征提取模块,提高了对小尺寸人脸的检测能力。DFL网络对人脸平均检测准确率达到90.6%。(2)制作了一个新的戴口罩人脸分类数据集。其中训练集包含18000张图像,分别为9000张戴口罩的人脸和9000张不戴口罩的人脸,测试集包含1751张图片,分别为656张戴口罩的人脸和1095张未戴口罩的人脸。数据集中的人脸分辨率最大1735×2342到最小20×40,跨度涵盖了人脸出现在图像中的大多数可能的尺寸,强化了网络对不同尺寸戴口罩人脸的分类能力。数据集已被公开以供其他科研人员研究。(3)创建了用于戴口罩人脸分类的网络。使用神经架构搜索的方式创建了SRNet20分类网络,采用不同的卷积核进行构建,提高了网络对戴口罩人脸的分类能力。考虑到监控视频存在的隐私问题,使用联邦训练的方式模拟了多机分布条件下的模型训练。对比预训练的Res Net网络对戴口罩人脸平均分类准确率最高为93.0%,本文创建的SRNet20网络对戴口罩人脸平均分类准确率达到98.5%。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.002873
{DOI}: 10.27005/d.cnki.gdzku.2022.002873
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的轴承圆柱滚子表面缺陷检测系统研究
{Author}: 魏思铭
{Tertiary Author}: 向敬忠
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 圆柱滚子;机器视觉;动力学分析;图像处理;表面缺陷检测
{Abstract}: 轴承是铁路列车运输中的核心关键部件,而圆柱滚子作为滚子轴承中的重要组成部分,也发挥着不可或缺的作用。在铁路运输过程当中,圆柱滚子在高速重载的条件下,其表面经常会有各种缺陷产生,导致列车行驶存在安全隐患,所以需要对轴承进行定期检修。近年来,机器视觉在轴承滚子质量检测中的应用越来越广泛,成为缺陷检测中的主流。本文在现有的滚子表面检测系统的基础上,结合理论分析、仿真验证和物理实验,设计出一套基于机器视觉轴承圆柱滚子表面缺陷检测系统,主要研究内容如下:对圆柱滚子表面缺陷进行归类和特征分析;确定圆柱滚子的输送展开方式,对圆柱滚子表面质量检测系统进行软件和硬件选型;建立圆柱滚子动力学模型,对圆柱滚子输送过程进行振动响应分析;完成圆柱滚子表面缺陷检测系统的总体方案设计。合理布置光源,完成圆柱滚子图像采集方案的制定;确定影响圆柱滚子采集图像质量的因素,确定评价圆柱滚子图像质量的评价指标;搭建实验台,对影响圆柱滚子图像采集质量的因素进行分析,通过实验获取圆柱滚子图像采集的最佳条件,完成圆柱滚子图像采集系统方案设计;对采集到的滚子图像进行预处理,便于后续缺陷识别。对圆柱滚子原始图像进行兴趣区域提取,获取滚子端面和柱面图像,并合理设计模板匹配算法,加快算法运行速度;对圆柱滚子端面和柱面图像进行处理,获取圆柱滚子表面缺陷的视觉特征,建立缺陷识别流程,设计检测系统软件界面,完成滚子表面缺陷检测。本文进行基于机器视觉的轴承圆柱滚子表面缺陷检测系统设计,实现圆柱滚子表面缺陷自动检测,解决圆柱滚子不易于行进中展开的问题,提供高效可行的缺陷检测算法,可为圆柱滚子表面缺陷检测系统的后续研究提供理论依据。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2022.000545
{DOI}: 10.27063/d.cnki.ghlgu.2022.000545
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的害虫监测方法与系统研究
{Author}: 赵楠
{Tertiary Author}: 裘正军
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 害虫检测;卷积神经网络;目标检测;迁移学习;软硬件设计;深度学习;小样本
{Abstract}: 虫害是影响世界各地农作物产量和质量的主要原因之一。在虫情监测中,对害虫进行准确、快速的识别是其中的关键环节。传统的害虫图像采集、识别、诊断中对专家知识的依赖程度较高,人力成本、时间成本较大,且诊断结果准确性不高、易出错,难以满足智慧农业的智能化、精准化需求。基于计算机视觉的图像处理技术在害虫自动检测方面得到了大量研究,然而,在目前对于害虫识别的研究中主要以单一种类的害虫检测任务为主,且这些单一种类的害虫分布简单,检测难度较低,对于存在多个种类,且存在复杂粘连情况的害虫图像,分类不够准确、计数准确度不高,检测精度较低;另一方面,研究中害虫检测流程基本是在田间人工放置害虫诱捕装置,通过人工拍照的方式对这些诱捕到的害虫的图像进行采集,之后由专家对这些图像中存在的害虫进行人工识别与计数,这种方法费时费力,自动化程度低,且识别结果不够精准,对田间虫害信息的感知缺少时效性、准确性,降低了使用计算机图像处理技术实现对田间虫害监测的可靠性与可行性。针对以上两个问题,本文从以下几个方面展开了研究:(1)研究了基于公开数据集Yellow Sticky Traps的粘虫板上害虫目标检测方法。公开数据集Yellow Sticky Traps是由荷兰4TU联盟制作并公开的有关粘虫板上害虫的数据集,包含白粉虱、烟盲蝽、臭虫3个种类害虫的284张高分辨率图像。对其中错误标注的数据使用图像标注软件Label Img进行校正。为了提高害虫的相对空间尺度、突出害虫细节特征,对Yellow Sticky Traps数据集中的图像采用缩放、裁剪、去除背景等方式进行数据增强,共得到117500张图片。在残差网络Res Net基础上,重新设计单通道卷积为多通道卷积,并优化下采样结构,引进可变形卷积核,建立新的卷积神经网络模型DPe Net。训练上,DPe Net使用先训练低分辨率图像再训练全部图片的训练策略在训练集上进行训练。在测试集上,DPe Net的AP值达到了0.941,相对于目前主流的深度学习目标检测算法,具有较大的优势。(2)研究了基于小样本数据集的迁移学习方法。人工采集不同气候条件下的45张高分辨率粘虫板害虫图像,构建小样本数据集Yellow Pest-2022。数据集包含了苍蝇、蚊子、蜜蜂、蜘蛛、其他害虫5个种类目标,并使用图像标注软件Label Img进行标注。为了突出数据集中害虫的语义特征,对数据集Yellow Pest-2022中的图像应用了调整对比度、曝光度、饱和度等数据增强方法。使用冻结征提取网络参数和不冻结参数的微调两种迁移学习方法,研究DPe Net在小样本数据集上迁移性能表现。验证了不冻结参数所得到的迁移学习模型有更好的迁移学习性能,在Yellow Pest-2022测试集上的AP值达到了0.940。与采取相同预训练与迁移学习策略的目标检测算法相比,DPe Net对害虫计数的准确系数R2达到0.982,具有明显优势。验证了迁移学习使模型在小数据集上可以实现相似但不同的害虫检测任务的可行性,并具有较高准确度。(3)开发了基于卷积神经网络的田间虫情监测远程系统。在硬件设计上,系统使用树莓派4B作为微控制单元(Microcontroller Unit,MCU),使用IMX179相机模块获取田间虫害图像,使用温湿度传感器SHT30、光照传感器BH1750获取田间的温湿度和光照强度等环境信息。在信息采集与上传上,系统通过Python程序,调用Open CV、smbus等第三方库对传感器信息进行采集;在腾讯云上搭建Apache服务器,通过PHP服务程序对My SQL数据库进行数据增减操作来存储、调用温湿度、光照强度等田间环境信息;通过POST程序、Flask服务接收粘虫板上害虫图像信息。在结果访问上,通过Apache服务器、PHP服务程序对田间温湿度变化情况、光照强度变化情况、各种类害虫数量变化情况等处理结果进行调用,并使用HTML5网页方式将处理结果可视化显示在终端上。实验在不同的终端平台上验证了该系统的跨平台性,满足不同终端设备对数据察看的使用需求。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2022.001820
{DOI}: 10.27461/d.cnki.gzjdx.2022.001820
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉的婴儿睡眠质量评估算法研究
{Author}: 姜子艳
{Tertiary Author}: 陈祝明
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 婴儿睡眠;睡眠检测;目标检测;运动检测;睡眠质量评估
{Abstract}: 睡眠是婴儿生活中至关重要的一部分,拥有良好的睡眠有利于婴儿智商的提高和身心的发育。本文针对婴儿普遍存在的入睡障碍,频发夜醒,睡眠节律失调等睡眠问题,提出一种基于计算机视觉的婴儿睡眠质量评估算法。通过构建婴儿睡眠检测模型,研究婴儿睡眠质量评估方法,突破目前非接触式低准确率的睡眠检测技术,降低硬件成本,为家长提供一种实时的高效便捷的睡眠检测方法。本文具体工作如下:(1)针对实际监控视频背景复杂的情况,本文搭建了眼睛状态识别与光流运动检测相结合的婴儿睡眠检测模型,当无法通过眼睛状态判断婴儿的睡眠状态时,通过光流运动检测辅助判断婴儿的睡眠情况;(2)为了进一步提升睡眠检测模型的检测速率,本文采用轻量级结构设计方法,在Yolov4的基础上设计新的轻量级网络,在确保模型精确度的前提下,提高了模型数据的检测处理速度,减少了模型本身带来的内存消耗;另外,为进一步提高模型的泛化能力,本文还引入了迁移学习的方式,从而改善了模型的性能;(3)针对光流运动检测容易受噪点影响的问题,本文对比了基于本征图像分解的光流估计方法和基于四帧差分的光流估计方法,经过实验分析,最终采用基于四帧差分的光流估计方法,并在计算运动量时使用投影法进行更深层次的去噪;(4)根据实际监控视频,本文提出一种睡眠质量评估方法,由于不同年龄的婴儿睡眠习惯和睡眠结构不一样,本文通过采用婴儿夜间睡眠数据,结合不同年龄段婴儿的最佳睡眠时间,得到睡眠质量评估模型,通过与专业医生的评分进行对比,验证本论文的可行性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.003669
{DOI}: 10.27005/d.cnki.gdzku.2022.003669
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于计算机视觉技术的城市生活垃圾管理系统
{Author}: 王聪
{Tertiary Author}: 陈斌
{Publisher}: 西南大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 城市垃圾管理;计算机视觉;物联网;无人车
{Abstract}: 近年来,随着社会、经济和科技的快速发展,人民生活水平不断提升,城市化进程逐渐加快。但随着城市化步伐的加速,生态环境问题日益凸显,城市日益增长的生活垃圾产量和城市生活垃圾回收处理问题逐渐成为社会关注的焦点。归功于信息技术和计算机视觉技术的快速发展,以及硬件性能的大幅提升,智能化、自动化和信息化的城市生活垃圾管理系统已经成为生态环境保护的重要研究方向。本文围绕该研究方向,结合计算机视觉技术、物联网技术,构建了一套城市生活垃圾管理系统。研究内容主要包括以下两个方面:(1)智能垃圾桶为主体的城市生活垃圾管理系统:本文基于人工神经网络的图片分类技术、物联网技术和云计算技术,构建了一套包括智能垃圾桶终端、居民手机用户端、云计算服务端和物联网数据平台的城市生活垃圾管理系统。系统将可回收城市垃圾细分为塑料、玻璃、纸或纸板、金属、织物和其他可回收废物六类。首先,居民通过手机APP拍摄并上传所要丢弃的垃圾的图片。图片数据将被上传至云计算服务端的服务器上,服务器运行图片分类识别程序,并将识别结果返回给手机用户端。然后,手机用户端即可根据识别结果控制打开对应类别的垃圾桶盖,完成垃圾的分类投放。同时,搭载了各类传感器的智能垃圾桶终端会将传感器数据上传至物联网数据平台,用于监测垃圾桶的运行状况、区域的垃圾生产总量等。这些数据可用于后续垃圾回收计划的制定,设备部署计划和设备维护计划的修改。本文共测试了7种当前先进的卷积神经网络,使用了多种图像数据的预处理方法,在验证集上,这些算法的分类准确率在91.9%到94.6%之间。其中Mobile Net V3网络具有较高的分类精度(94.26%)、较小的存储大小(49.5 MB)和最短的运行时间(261.7 ms),分类效果对于城市生活垃圾管理系统具有实际意义。(2)城市环卫无人车视觉系统的设计:在上述的城市生活垃圾管理系统体系下,针对日常局部道路清洁的需求,本文提出城市环卫无人车视觉系统。基于Robot Operating System(ROS),我们设计了一套环卫无人车视觉部分的系统框架。系统使用双目ORB-SLAM2算法实现基于视觉的环境建图和姿态估计,为无人车的运行提供周围的环境信息与位姿变化。在深度估计任务中,对比传统视觉方法和深度学习方法,选择了实时性更好、无需训练的Semi-Global Block Matching(SGBM)算法。使用YOLOX-s算法实现垃圾目标检测,结合深度估计结果和位姿数据,实现对垃圾物体空间位置的感知,完成了无人车自动清扫系统开发的前期工作。
{URL}: https://link.cnki.net/doi/10.27684/d.cnki.gxndx.2022.002816
{DOI}: 10.27684/d.cnki.gxndx.2022.002816
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于FPGA的成熟番茄机器视觉识别系统设计
{Author}: 高嘉聪
{Tertiary Author}: 张艳兵;牛砚波
{Publisher}: 中北大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: FPGA;超红超绿差分指数;帧间差分法;机器视觉
{Abstract}: 随着新农业生产模式和新技术的发展,农业采摘机器人逐渐成为农业生产发展的新趋势,通过机器视觉技术对农作物进行自动检测和识别已成为采摘机器人设计的关键技术之一,直接决定了机器人的采摘效果和农场的经济效率。采摘机器人可利用视觉传感器获取农作物的图像信息,通过图像处理算法对农作物的成熟度进行自动检测和识别。FPGA具有高速并行计算能力以及低功耗,结构紧凑的特性,可以满足实时性要求较高的场景,所以本文使用FPGA核心处理器实现机器视觉识别系统的设计。本文以成熟番茄为研究对象,设计了机器视觉识别系统。主要研究内容如下:首先,研究了成熟番茄的视觉检测和识别算法,对番茄图像进行了彩色图像分割、运动目标检测、红熟期番茄识别。在实际场景中为了将红熟期番茄与背景分离,通过实验提出将超红超绿差分指数作为彩色图像分割算法。为模拟采摘机器人的运动状态,采用帧间差分法对分割出的番茄进行运动目标检测,并通过仿真确定出合适的阈值。通过最小边框将检测到的运动目标进行框选,实现了红熟期番茄的自动识别,以便采摘机器人进行后续的操作。其次,以FPGA作为主控芯片设计了成熟番茄机器视觉识别系统。通过OV5640摄像头采集番茄图像信息并使用Verilog语言对其进行配置,输出30fps帧率,RGB565格式的图像数据。为便于工程实现,在Modelsim上对超红超绿差分指数进行仿真验证,通过对SDRAM实施乒乓操作进行图像数据的缓存,在FPGA上实现了超红超绿差分指数和帧间差分法。针对光照引起的运动目标误检测,使用开运算将非目标的噪点去除,通过最小边框对红熟期的目标番茄进行框选,将识别的结果以640*480@60的显示模式在VGA显示屏上进行显示,实现了成熟番茄的自动检测和识别。最后,经过仿真和实际测试,对超红超绿差分指数分割效果、不同阈值的帧间差分法、最小包围框与视频流叠加法的识别效果进行了验证。并且在无遮挡和有遮挡环境下对成熟番茄进行自动检测和识别,验证了系统设计的正确性。
{URL}: https://link.cnki.net/doi/10.27470/d.cnki.ghbgc.2022.001022
{DOI}: 10.27470/d.cnki.ghbgc.2022.001022
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的钢板表面缺陷检测研究
{Author}: 汪强
{Tertiary Author}: 何毅斌;万里
{Publisher}: 武汉工程大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器视觉;图像处理;缺陷检测;特征提取;钢板
{Abstract}: 钢铁行业是我国的支柱行业,产量居世界首位,但钢铁产品质量仍需要进一步提高。钢板在钢铁产业中,应用非常广泛。其在生产过程中,由于各种原因,会造成钢板表面呈现不同的缺陷,会导致一系列的质量问题。所以钢板的表面缺陷检测技术,是一项对钢铁行业甚至社会都很有意义的技术。而随着社会的进步,机器视觉与图像处理等技术的发展越来越成熟,其与钢板表面缺陷检测技术的结合已然成为该领域的一个热点。本文就基于机器视觉的钢板表面缺陷检测技术进行分析研究。首先对整个流程进行分析,然后着重就图像采集后的图像预处理算法、缺陷区域边缘检测算法、缺陷区域分割算法、特征提取和特征选择,以及缺陷识别分类算法等进行分析研究,主要研究内容如下:(1)对采集到的钢板表面缺陷图像进行预处理,通过对比试验分析研究了几种常用的图像增强算法,解决图像采集时因采集环境太差及光照不均匀带来的图像问题,并通过计算信噪比的方式,最终选择处理效果最好的同态滤波算法。然后针对图像采集及图像增强处理时可能产生的图像噪点,进行图像去噪。先对几种常见的图像去噪算法进行实验分析,然后提出一种基于中值滤波算法的改进算法,从实验结果可以看出,该改进算法的去噪效果明显优于几种常见算法。(2)对经过图像增强和去噪处理后的钢板缺陷图像,进行缺陷区域边缘检测和缺陷区域分割。对常见的边缘检测算子进行对比分析,实验结果表明Sobel算子对于钢板表面缺陷图像的边缘检测效果最好。对几种常用的阈值分割方法进行实验分析,并提出一种基于最大类间方差法的改进算法,实验结果表明该算法能够更快更好地实现目标缺陷区域与背景区域的分割。(3)提出一种基于GVF snake模型的改进算法,对钢板缺陷区域进行ROI区域提取,减小待处理区域,提高运行速度。然后进行特征提取,提取了灰度特征、几何形状特征、纹理特征和投影特征等四类特征中的25种,选用Fisher判别法来进行数据降维,选出对缺陷识别贡献最大的15种特征。(4)研究BP神经网络及SVM算法进行钢板表面缺陷的识别分类,选取数据集进行分类实验,实验结果表明SVM算法分类效果要优于BP神经网络模型。
{URL}: https://link.cnki.net/doi/10.27727/d.cnki.gwhxc.2022.000176
{DOI}: 10.27727/d.cnki.gwhxc.2022.000176
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的光电传感器焊缝自动识别方法
{Author}: 董亚男
{Author Address}: 长春教育学院;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 03
{Pages}: 180-184
{Keywords}: 机器视觉;光电传感器;目标区域;量子门模型;焊缝识别
{Abstract}: 针对光电传感器焊缝自动识别的F1较低、方法复杂度较高和存在识别时间较长的问题，提出基于机器视觉的光电传感器焊缝自动识别方法。通过机器视觉技术采集光电传感器焊缝图像，利用高斯模型检测出图像的目标区域，结合海森矩阵提取目标区域的特征点，将提取的特征点输入到量子门神经网络模型中，得到识别结果。仿真实验结果表明，所提方法的光电传感器焊缝自动识别复杂度低，且识别效率与F1值均较高。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyHjq6zvo0uxunkoeZNRG5INmtuQ3poeIwZDPDkhXpeK_wp_bFzwc6fmm0ZT721-8wCHi4-crDJu1SKORfNpI8h76_F99o0tUsRmta8t6lEoSZjN44BfKxKqTOLRuzITR2xVgYZGNHoJbIlpHIFMrdhXvlNHQKINFa0NncF6I9Udlx0odwarhtOaI_LFvt6zE8=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: OpenMV的3D打印小车系统研究
{Author}: 邓春兰;应必仕;银锦国;朱君
{Author Address}: 广西师范大学电子工程学院;
{Journal}: 自动化与仪表
{Year}: 2022
{Volume}: 37
{Issue}: 03
{Pages}: 6-10+16
{Keywords}: STM32单片机;OpenMV;PID控制;3D打印;避障
{Abstract}: 设计一种基于OpenMV的机器视觉智能小车系统，使用STM32F103RCT6为主控制器，通过模型设计与3D打印，实现快速制造小车。该系统能够从要求的指定位置出发，使用OpenMV摄像头模块系统进行数字或者图像采集，然后使用采集到的障碍物图像进行测距，从而得到障碍物的位置信息。利用数字温湿度传感器进行温湿度数据的检测，实现了温湿度显示功能并通过蓝牙模块通信协议的设计，实现手机APP对小车的监视与操控。采用“PID控制算法”实现对智能小车行进速度与方向的控制，利用单目视觉测距算法实现避障。
{ISBN/ISSN}: 1001-9944
{Notes}: 12-1148/TP
{URL}: https://link.cnki.net/doi/10.19557/j.cnki.1001-9944.2022.03.002
{DOI}: 10.19557/j.cnki.1001-9944.2022.03.002
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的轻量化网络火灾烟雾检测方法研究
{Author}: 李孝钊
{Tertiary Author}: 向南
{Publisher}: 重庆理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 火灾烟雾检测;YOLO;深度可分离卷积;注意力机制
{Abstract}: 随着国民经济的发展与机械化工厂的迅速发展,工厂和居民楼里密集用电用火的行为也越来越普遍。各种各样的易燃物和不安全用火用电行为更容易引起火灾。基于传感器的火灾烟雾检测方法大多需要与烟雾颗粒接触或者感受到火焰温度变化才能感知火情。因此研究基于深度学习的视频火灾烟雾检测与预防的技术方法势在必行。该论文以单阶段检测效率高的YOLOv4和YOLOX目标检测算法作为Baseline改进,提出FM-YOLO和CSG-YOLO火灾烟雾检测算法。本文提出的主要包括以下几个方面:针对YOLOv4目标检测网络中存在的不足,提出了FM-YOLO目标检测算法。FM-YOLO以为切入点,通过修改Backbone中CSP(Cross Stage Partial)结构的卷积模块,将倒残差结构和深度可分离卷积的组合加入CSP结构以拓展卷积运算宽度,降低模型体量,并加入SE(Squeeze-and-Excitation)注意力机制模块和Drop Path方法构成MBConv(Mobile Inverted Residual Bottleneck Block)模块。在网络的浅层使用Fused-MBConv(Fused-Mobile Inverted Residual Bottleneck Block)加快模型推理速度,最终在小幅度降低模型参数量的同时,进一步提升了模型的火灾烟雾的目标检测精度。在Pascal VOC2007数据集上,FM-YOLO对比YOLOv4模型的参数量降低了1.4×106,检测精度m AP提高了1.42个百分点。针对YOLOX-S的特征提取网络卷积运算时宽度低,准确率较大型目标检测网络低的缺点,提出了CSG-YOLO算法。CSG-YOLO算法在特征提取网络中采用了大尺寸7×7的卷积核与深度可分卷积的组合,并使用了Layer Norm、GELU(Gaussian Error Linerar Units)和SE注意力机制模块构成CSE Block。更改卷积模块后的特征提取网络参数量大,推理速度慢。为了加快模型推理速度,减小模型体量,本文在CSP结构中加入Ghost Module。在自己制作的火灾烟雾数据集上,CSG-YOLO比YOLOX-S在准确率方面提高了1.63个百分点。公开数据中只有较少的火灾场景数据集可供训练,本文使用爬虫工具获得网络火灾现场与烟雾图像,对视频抽帧后使用Labelimg软件完成Pascal VOC2017格式火灾烟雾数据集的制作。为了增强对小目标的检测能力,在模型训练期间使用了Mosaic数据增强的方法,有效改善了小目标占比不足的问题。
{URL}: https://link.cnki.net/doi/10.27753/d.cnki.gcqgx.2022.000464
{DOI}: 10.27753/d.cnki.gcqgx.2022.000464
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 深度学习中注意力机制研究及在图像分类中应用
{Author}: 周荣好
{Tertiary Author}: 夏金祥
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 注意力机制;卷积神经网络;深度学习;图像分类
{Abstract}: 图像分类是通过一定的方法从图像信息中提取出不同特征,从而把不同类别的目标区分开来。目前,深度学习成为图像分类研究领域中的主流图像处理技术。在深度学习中加入注意力机制可有效提升图像分类的准确性,但是目前注意力机制还存在一些未解决的问题:其一,注意力机制尚未针对神经网络的层级特征进行优化;其二,自注意力机制在解决卷积神经网络对特征的全局位置不敏感的问题上,参数量还有待优化,其性能还可提升。针对上述问题,本论文旨在研究深度学习中的注意力机制,并探讨其在图像分类中的应用效果。本论文工作如下:(1)提出了层级特征融合注意力机制,用于解决卷积神经网络的各层级特征重要性问题。数据集Image Net 1K、Cifar-100、Cifar-10和分心驾驶特定场景数据集State farm测试表明,与通道注意力进行对比并结合使用,使得模型的图像分类准确率提升1%左右,且在大型数据集和分类种类更多的数据集中的效果更有优势,分类准确率最高提升3.3%。(2)提出了斜对角位置自注意力机制,用于解决卷积神经网络对特征的全局位置不敏感的问题。本文将提出的方法与十字交叉注意力模型(CCNet)进行对比,数据集Image Net 1K、Cifar-100、Cifar-10和分心驾驶特定场景数据集State farm上的实验结果表明,本文提出的方法比CCNet额外添加的参数量减少近10%,准确率提升0.3%左右。(3)实现了注意力机制图像分类系统。探讨了注意力机制图像分类系统的两种实现方式:服务器端实现方式和移动终端实现方式,完成了两种实现方式下的需求分析、系统设计、详细设计、软件实现和测试。两种实现方式的设计实现与测试结果表明,基于深度学习注意力机制的图像分类模型能够较好地进行图像分类任务,验证了提出的注意力机制模型在不同设备上的实用性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.001829
{DOI}: 10.27005/d.cnki.gdzku.2022.001829
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于场景理解的视觉关系生成研究
{Author}: 郭昱宇
{Tertiary Author}: 宋井宽
{Publisher}: 电子科技大学
{Type of Work}: 博士
{Year}: 2022
{Keywords}: 视觉关系;场景图生成;结构化知识;平衡性学习;语义去偏
{Abstract}: 计算机视觉作为新一代人工智能的重要领域,它的蓬勃发展会对国计民生产生重大的积极作用。计算机视觉领域的核心要务是效仿人类视觉系统让计算机理解数字图像或视频中的视觉内容。当下计算机视觉领域中一些视觉认知任务已经取得了长足的进步,诸如图像识别和实例检测等任务。然而孤立地识别和检测实例并不能充分地理解图像中的场景内容,实例与实例之间丰富的关系对理解图像的场景内容也至关重要。因此本文关注于如何探索视觉信号中的关系信息,并以结构化的方式加以表示。具体而言,本文使用了图(Graph)结构来表示关系信息,实施的具体任务为场景图生成(Scene Graph Generation,SGG),以实现对视觉场景的完备且准确的理解。场景图由节点和边构成,其中节点代表了图像中的实例,具体包含实例的位置和类别;边连接了主体节点与客体节点,代表从主体到客体的视觉关系,具体由关系谓词表示。该图结构也可以分解为一系列从主体到客体的关系三元组,即<主体,谓词,客体>,如<人,骑,马>。由于当下实例检测模型已经能有效检测场景图中的节点,因此本文关注于如何更好地生成场景图中的边,即关系谓词。综上,本文探索了基于场景理解的视觉关系生成的研究。由于当下基于深度卷积神经网络的图像识别和检测网络已经取得了优良的效果,从这些网络中提取的深度特征可以充分地表征图像中的实例信息。因此提取关系信息的难点在于如何充分利用并补充深度卷积特征,使模型能在各种数据环境下归纳出准确且具体的关系信息。针对该研究目标,本文提炼了视觉关系生成中四个具体的关键问题,即,局部特征上下文缺失、少样本数据知识不足、长尾数据信息量匮乏及相关谓词语义混淆,提出并设计了关系正则化网络、多重结构化知识、平衡性谓词学习策略及语义去偏模块来分别处理上述问题。具体总结如下:(1)如何从局部卷积特征中提炼出有效的全局及关系上下文信息以辅助关系的预测?本文提出了关系正则化网络来捕获上下文信息以辅助场景图生成任务。由于关系的预测不是孤立的,它们极其依赖于视觉的上下文信息,即周围环境信息。而提取于卷积网络的局部特征并不具有此种信息。针对此问题,首先归纳了两种上下文,即关系型上下文和全局上下文。之后,利用图卷积神经网络以及双向长短期记忆网络从实例特征中提炼出这两种上下文信息以辅助场景图生成任务。(2)如何在少量样本的条件下仍能良好地预测关系?本文提出了多重结构化知识网络来弥补少量样本下场景图生成中知识不足的问题。人类能在少量样本的条件下学习到丰富的关系信息,然而当下场景图模型都依赖于大量样本进行学习。为了模拟人类的学习方式,本文首先提出了一个单样本场景图生成任务。之后,为了弥补单样本场景图任务中知识不足的问题,本文从视觉基因组数据集中定义了关系型知识,并从概念网络数据集中定义了常识型知识。为了从多重知识中提取知识特征,本文将这两种知识信息组织为图结构,然后利用图卷积神经网络对多重结构化知识进行编码生成知识特征以辅助单样本场景图生成。(3)如何提升在长尾数据中生成关系的信息量?本文设计了平衡性谓词学习策略来增加生成场景图的信息量。当下场景图模型受困于信息量贫瘠的一般性关系谓词,对具有丰富信息量的谓词预测能力不足。这不仅破坏了当下模型的整体性能同时也阻碍了场景图在下游任务中的应用。本文认为该问题主要是由于训练空间中谓词样本的长尾分布造成的。基于此,本文提出了基于平衡性谓词学习的场景图生成框架,其使用了随机欠采样策略以及歧义消除策略以提升现有场景图模型生成结果的信息量。(4)如何缓解相关性关系谓词的语义混淆问题?本文提出了语义去偏模块以纠正预测结果并使其更加明确具体。由于关系谓词普遍具有关联性,模型很容易混淆有语义重叠的关系谓词。基于此,本文构建了谓词的关系矩阵,并在训练和推理时使用该矩阵以缓解语义混淆问题。具体而言,本文分别使用了基线模型的混淆矩阵和由主客体重叠度构成的二部图来构建谓词的语义关系。之后,将这种谓词关系施加于模型生成的谓词分布以缓解生成场景图语义含糊的问题。最后,本文归纳并总结了上述研究内容,并展望了可能会对视觉关系任务的发展产生重要影响的潜在研究点。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000153
{DOI}: 10.27005/d.cnki.gdzku.2022.000153
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于深度学习的无人机视角小目标检测算法研究
{Author}: 高港耀
{Tertiary Author}: 颜红梅
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 小目标检测;无人机;高分辨率;YOLOv5;融合切片检测方式
{Abstract}: 无人机越来越广泛地应用于多种场景中,而目标检测技术给无人机执行任务的自动化水平带来了巨大的提升,是实现更少人力完成复杂任务的关键技术。无人机拍摄的图像具有目标尺寸小,分辨率高,目标密度高等特点,进一步带来了小目标检测的技术需求。小目标包含的信息少,并且下采样的过程中易消失,因此小目标检测依然是一个痛点和难点。生物视觉机制中存在注意力机制辅助的目标识别,受此启发我们提出了一种新型的小目标检测算法。为解决目标信息少,易与背景混淆的问题,本论文在目标检测网络中引入了注意力机制以保留小目标的信息。针对下采样目标特征消失的问题,本论文设计了微小目标检测头,在网络中融合浅层小目标特征和深层语义信息,以更好地对小型目标进行检测。基于上述技术,本论文提出了注意力微检测头YOLOv5小目标检测网络。此外,本论文还设计了一种融合切片方式的小目标检测方法。论文研究内容主要包括下面三个部分。第一部分,选取包含大量小目标的数据集Vis Drone和Tiny Person进行数据集预处理。对Vis Drone数据集进行特征分析以观察数据详细统计信息,最后简要介绍Tiny Person小目标数据集的扩充方式。结果表明在小目标数据集中,按照多种目标尺度划分标准,大多数目标都集中在小尺度上。第二部分,针对上述无人机小目标数据集,基于生物注意力机制,以及小目标的特征,本论文提出了改进方法,并在YOLOv5模型的基础上设计了注意力微检测头YOLOv5目标检测网络。此外,为了对从无人机获取到的高分辨率图像进行检测,我们提出了一种融合切片方式的小目标检测方法。基于上述方法,提出了一个完整的小目标检测算法流程。第三部分,选取合适的评价指标,通过实验验证了本文提出的各个模块以及融合切片检测方法的有效性。基于Vis Drone数据集的实验表明该方法在YOLOv5s模型上提升10.9%,达到29.9%,在YOLOv5m模型上的提升10.5%,达到32.3%。此外,我们在海上生命搜救场景下进行实验,针对部分图像中目标样本数量过少设计了数据扩充方法。基于Tiny Person数据集的实验表明,使用该数据扩充方法在YOLOv5s模型上提升17.4%,达到72.6%,有显著的提升。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2023.001002
{DOI}: 10.27005/d.cnki.gdzku.2023.001002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: LRGAN:一种运算轻量化图像修复网络
{Author}: 廖年鸿;张效娟;彭春燕;范虹
{Author Address}: 青海师范大学计算机学院;青海师范大学省部共建藏语智能信息处理及应用国家重点实验室;陕西师范大学计算机科学学院;
{Journal}: 中国科学:技术科学
{Year}: 2022
{Volume}: 52
{Issue}: 03
{Pages}: 447-457
{Keywords}: 人工神经网络;图像修复;轻量化网络;图像合成;深度学习;计算机视觉
{Abstract}: 近来的图像修复工作大多聚焦于如何提升修复质量,但并没有考虑在计算资源不足的平台如何运行.本文提出了一种结合组卷积与注意力机制的模块(LABGC)用于替换传统卷积,在此模块中利用深度可分离卷积实现了多层次图像修复工作,同时针对传统卷积处理过程中通道间信息流动性的问题提出了轮循通道注意力分配机制(C2AM),并将其应用于构建一个轻量级的图像修复网络(LRGAN).在整体网络的设计阶段使用了并行判别器结构保证图像生成的全局与局部的一致性.实验结果表明,在保证修复质量的情况下,本文提出的图像修复网络的推理时间与资源占用均远远小于同类方法.
{ISBN/ISSN}: 1674-7259
{Notes}: 11-5844/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyBwmSyXFD1v9Ge3r95swuYyiMZLNwDlnsUkN6pnUaBqiWtojJAOrs_XX88lOacNgrijZMYHrFOonJsLgBXlp-CPd5UlLgI4JKkAnXZozJgCDRuRuNSemBdaX_bBNMu2yRbwS54iizzKcZVQY3dl2uclbTs9tCS0Uo_Xm1t3xUJiMArd--g0i0K6UxMe_k_kCU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向室外环境的全景图像拼接系统设计与实现
{Author}: 陈冬子
{Tertiary Author}: 朱清新
{Publisher}: 电子科技大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 图像拼接;特征提取;接缝线;全景图像;弱纹理
{Abstract}: 随着计算机视觉的发展,图像拼接技术也有了进一步的提高,图像拼接是计算机视觉领域中一个重要的研究问题,广泛应用于医学造影,虚拟现实,水下制图,智能车载环视系统等诸多领域。全景图像拼接可拆分为多次图像拼接,将多张具有重叠区域的窄视域的图像拼成一幅宽视域的整张图像。本文通过结合基于深度局部描述的特征匹配算法和最佳接缝线算法,精准地提取待拼接图像重叠区域的特征点并准确对齐多幅图像,有效缓解了传统方法难以处理弱纹理和运动物体重影等问题,并最终给用户提供一个界面友好的全景图像拼接系统。本文主要研究内容如下:1.提出了基于Transformer的局部特征匹配算法。本文基于Transformer的长依赖全局建模能力,结合自注意力机制、交叉注意力机制,提出了一种基于Transformer的渐进式局部特征匹配模型PLFM(Progressive Local Feature Matching)。该模型将特征提取和特征匹配融合在同一个网络模型中,端到端学习图像间的特征匹配关系,模型通过轻量级的设计能够保持较快的推理速度,同时能够解决传统方法在弱纹理、无纹理场景中难以提取到足量的特征点的问题。最后本文在数据集上完成相关算法的对比实验和性能测试。2.提出了基于语义分割和接缝线的图像拼接算法。本文重点研究了室外环境中运动物体的重影消除,首先设计基于编码器-解码器的图像语义分割模型,通过分割模型得到室外场景中车辆、行人等运动物体的像素级区域。然后结合传统的接缝线方法,基于上一阶段得到的运动区域,设计避让运动物体的接缝线寻找策略消除运动物体造成的重影现象。最终,本文在数据集上完成相关算法的对比实验和性能测试。。3.全景图像拼接系统的设计与实现。本文根据相关业务需求,设计了合理的系统架构、核心功能模块和数据库实体结构,并实现了一个包含用户管理模块、全景图像拼接模块、全景视频拼接模块以及信息处理模块的系统,该系统界面友好,操作简洁,具有良好的可靠性和安全性。
{URL}: https://link.cnki.net/doi/10.27005/d.cnki.gdzku.2022.000542
{DOI}: 10.27005/d.cnki.gdzku.2022.000542
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 面向多功能贴片机的机器视觉定位关键技术研究
{Author}: 刘茂霖
{Tertiary Author}: 傅建中;肖勇
{Publisher}: 浙江大学
{Type of Work}: 硕士
{Year}: 2023
{Keywords}: 贴片机;机器视觉;PCB基准点定位;位姿定位
{Abstract}: 随着电子信息技术的高速发展,微电子制造业已经成为我国的基础性产业之一。市场需求不断扩大的同时,电子产品不断向小型化和精密化方向发展,对制造工艺和组装技术提出了越来越高的要求。全自动贴片机作为表面贴装技术(Surface Mounted Technology,SMT)中最为关键的生产设备,对电子产品生产质量和生产效率起着决定性的作用。然而,目前国产贴片机的综合性能和国外同类设备相比存在较大差距,中高端贴片机市场仍被国外产品占据主导地位,进口设备成本高昂,严重影响了对中小企业的赋能。本文面向多功能贴片机,对其机器视觉定位关键技术开展研究,主要包括印刷电路板(Printed Circuit Board,PCB)基准点定位和芯片位姿定位等关键技术,具体研究内容如下:
(1)研究贴片机视觉定位中关键的图像预处理算法,主要包括图像增强、图像边缘提取和相机标定等,设计了基于拉格朗日插值的亚像素边缘提取算法,实现了相机内部参数和畸变系数的高精度标定。
(2)研究了高速高精度PCB基准点定位技术,提出一种改进的Radon变换直线检测算法,基于该算法和迭代加权最小二乘拟合,实现了PCB十字形基准点和圆形基准点的高精度定位。
(3)针对多功能贴片机高泛化多种类芯片的定位需求,研究了高精度、高通用性的芯片位姿定位算法。首先,深入分析芯片定位和纠偏原理;然后,分析芯片图像特征,设计芯片位姿定位算法的总体方案;最后,提出了一种新的芯片位姿定位算法,先采用基于边缘特征的模板匹配算法进行初步定位,然后提出一种改进的点集配准算法,实现了芯片亚像素级的位姿定位。
(4)在合作企业的多功能贴片机上对本文研究的PCB基准点定位算法和芯片位姿定位算法进行了算法性能测试,并进行部署和应用。首先,通过仿真实验和图像实验验证了PCB基准点定位算法的定位精度和可靠性;然后,测试验证了芯片位姿定位算法的精度和通用性。小批量应用结果表明,本文提出的视觉定位算法在合作企业的多功能贴片机上运行良好,满足了贴片机对多种类PCB板和芯片的贴装定位需求。
{URL}: https://link.cnki.net/doi/10.27461/d.cnki.gzjdx.2023.000043
{DOI}: 10.27461/d.cnki.gzjdx.2023.000043
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉及深度学习的静脉药物调配机器人药瓶识别
{Author}: 滕臻;崔国华;高鹏;陈奇
{Author Address}: 河北工程大学机械与装备工程学院;上海工程技术大学智能机器人研发中心;深圳市博为医疗机器人有限公司;广东省人民医院;
{Journal}: 机床与液压
{Year}: 2022
{Volume}: 50
{Issue}: 05
{Pages}: 33-37
{Keywords}: 配药机器人;YOLOv5网络;朴素贝叶斯分类器;图像识别
{Abstract}: 静脉药物调配机器人需要对数百种不同类型的药物进行调配，不同药物药瓶类型的识别、测量是精准调配的关键。对静脉药物调配机器人在药瓶类型分类、药瓶关键尺寸测量等不同任务要求情况下，运用基于机器视觉方法和深度学习框架YOLOv5s,实现了一种高效稳定的识别测量方法。结合机器视觉方法的测量准确性，深度学习方法对背景、光源的不敏感性，实现配药过程中不同环节药瓶的准确识别、测量。并通过实验定量地检测背景、环境光源对于识别结果的影响。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyehkkEhSq3X29KFNK12R9kWHg7b_JqlbQqAXtgFXmxj3MJgiFwAC-G4Lt7i1r3XBYzruPyQBmylDJ_152FiSywMeXtzy-mquKlgpiNjIkz0LWe9sei1H1CHzVas4atqXyxXy6uQ5uNbkRKPlj6V5AcBBhmLzLSiMYlTaqWYWsLP6ghQxeGQGVeCOa6Bu0SB68=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的标准件自动分拣系统设计
{Author}: 闫炜;李雄飞
{Author Address}: 西安工程大学实验室管理处;西安工程大学电子信息学院;
{Journal}: 国外电子测量技术
{Year}: 2022
{Volume}: 41
{Issue}: 03
{Pages}: 79-84
{Keywords}: 机器视觉;图像处理;自动分拣;测量
{Abstract}: 为了提高生产车间的工作效率，满足企业节能降耗的需求，设计了一种基于机器视觉的标准件自动分拣控制系统。解决了生产车间标准件分拣的难题，代替了传统的分拣方式，提高了分拣精度和效率，符合现代工控领域的发展。该系统由图像采集系统、图像处理系统和硬件PLC控制的气动分拣设备组成。图像的采集和处理系统是本设计的核心模块，以LabVIEW为研究平台建立了基于机器视觉的图像处理系统，通过对工作区域内的工件进行图像采集，利用Vision Assistant软件进行编程实现可视化建模，完成工件的特征提取与测量，并且成功地将分拣信号通过计算机传递给执行机构。
{ISBN/ISSN}: 1002-8978
{Notes}: 11-2268/TN
{URL}: https://link.cnki.net/doi/10.19652/j.cnki.femt.2103366
{DOI}: 10.19652/j.cnki.femt.2103366
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 局部–全局关系耦合的低照度图像增强
{Author}: 王克琪;钱宇华;梁吉业;刘畅;黄琴;陈路;贾洁茹
{Author Address}: 山西大学大数据科学与产业研究院;盘古深度智能信息技术有限公司;山西大学计算智能与中文信息处理教育部重点实验室;
{Journal}: 中国科学:信息科学
{Year}: 2022
{Volume}: 52
{Issue}: 03
{Pages}: 443-460
{Keywords}: 低照度图像增强;局部–全局关系;计算机视觉;卷积神经网络;深度学习
{Abstract}: 卷积神经网络目前在人工智能多个领域均取得了不同程度的进展.卷积计算是基于参数共享的滑窗机制,这导致卷积神经网络更多地关注特征信息的局部关系,对全局关系的建模能力有限.局部关系和全局关系对特征的表达均具有重要的作用.为此,本文聚焦于如何对特征信息的局部–全局关系进行构建并有效耦合,从而挖掘更加丰富的特征信息,提高特征的判别性.本文提出了局部–全局关系耦合模块,该模块是由特征提取、基于深度卷积(depth-wise convolution, DWConv)的局部关系构建分支、基于多头自注意力机制(mutli-head self-attention, MHSA)的全局关系构建分支和基于点向卷积(point-wise convolution, PWConv)的关系耦合4部分组成.基于此模块,本文构建了编解码结构的局部–全局关系耦合神经网络,该网络可以对特征信息的局部–全局关系进行建模,增强特征信息的表征能力,进而提升模型的性能.为验证所提算法的有效性,本文在低照度图像增强任务上,使用基准数据集与其他算法进行了实验对比.实验结果表明,本文所提出的方法取得了较好的图像增强结果,优于当前先进的图像增强方法.最后,本文通过消融实验和扩展实验从多个角度进一步验证了有效耦合局部–全局关系的重要性和可扩展性.
{ISBN/ISSN}: 1674-7267
{Notes}: 11-5846/TP
{URL}: https://link.cnki.net/urlid/11.5846.TP.20220308.1139.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 非侵入式负荷识别的电流序列可视化方法
{Author}: 崔昊杨;吴轶凡;江友华;江超;韩韬;许永鹏
{Author Address}: 上海电力大学电子与信息工程学院;国网电力科学研究院有限公司;上海交通大学电子信息与电气工程学院;
{Journal}: 电力自动化设备
{Year}: 2022
{Volume}: 42
{Issue}: 07
{Pages}: 40-45
{Keywords}: 非侵入式;负荷监测;二维可视化;计算机视觉;格拉姆角场;迁移学习
{Abstract}: 以单一特征为标签的用电设备识别，因特征携带的信息量不足，在区分性质相似的负荷时易产生误判，为此，提出一种将电流序列编码为图像的二维可视化方法，通过计算机视觉技术对负荷进行分类识别。利用Fryze功率理论提取电流的非有功分量，通过格拉姆角场（GAF）将一维电流序列转换成二维图像，借助数据扩充的方式进行升维，并赋予矩阵颜色特征来提升负荷标签的辨识度；基于迁移学习的思想，利用预训练模型Inception＿v3提取并学习GAF图像特征，并以该特征为标签对负荷类型进行分类识别。在2个公开数据集上的实验验证了所提方法在高频采集场景下的准确性和有效性。
{ISBN/ISSN}: 1006-6047
{Notes}: 32-1318/TM
{URL}: https://link.cnki.net/doi/10.16081/j.epae.202203002
{DOI}: 10.16081/j.epae.202203002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于关键点特征融合的六自由度位姿估计方法
{Author}: 王太勇;孙浩文
{Author Address}: 天津大学机械工程学院;天津仁爱学院;
{Journal}: 天津大学学报(自然科学与工程技术版)
{Year}: 2022
{Volume}: 55
{Issue}: 05
{Pages}: 543-551
{Keywords}: 六自由度位姿估计;深度学习;特征融合;机器视觉
{Abstract}: 针对单张RGB-D图像进行六自由度目标位姿估计难以充分利用颜色信息与深度信息的问题，提出了一种基于多种网络(金字塔池化网络和PointNet++网络结合特征融合网络)构成的深度学习网络框架．方法用于估计在高度杂乱场景下一组已知对象的六自由度位姿．首先对RGB图像进行语义识别，将每一个已知类别的对象掩膜应用到深度图中，按照掩膜的边界框完成对彩色图与深度图进行语义分割；其次，在获取到的点云数据中采用FPS算法获取关键点，映射到彩色图像与深度图像中进行关键点特征提取，将RGB-D图像中的颜色信息与深度信息视为异构数据，考虑关键点需要充分融合局部信息与全局信息，分别采用了金子塔池化网络(pyramid scene parsing network,PSPNet)和PointNet++网络提取颜色信息与深度信息；采用一种新型的关键点特征融合方法，深度融合提取到颜色信息与几何信息的局部及全局特征，并嵌入到选定的特征点中；使用多层感知机(multilayer perceptron,MLP)输出每一个像素点的六自由度位姿和置信度，利用每一个像素点的置信度，让网络自主选择最优的估计结果；最后，利用一种端到端的迭代位姿求精网络，进一步提高六自由度位姿估计的准确度．网络在公开的数据集LineMOD和YCB-Video上进行测试，实验结果表明和现有同类型的六自由度位姿估计方法相比，本文所提出的模型预测的六自由度准确度优于现有的同类型方法，在采用相同的评价标准下，平均准确度分别达到了97.2%和95.1%，分别提升了2.9%和3.9%．网络同时满足实时性要求，完成每一帧图像的六自由度位姿预测仅需0.06 s.
{ISBN/ISSN}: 0493-2137
{Notes}: 12-1127/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvz0WIv0t3hDNzVznu7q2P3OmJx1N02TrIxCR1FmRwpxARdVw58mEnfQlJSWC-OqeY5m0QlqsfdDfE7wFfLPHn_hEdJNFXiotrRCjhPI1mYP4JtG7zlXyl_9pj2B7ikMdsDpHIkjVd3D1-gyVWbl77YkNwusy1TxCMU0Faw3jk6zAiywHGZegQXH3Ajcw8EzIDU=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的类球形水果外部品质分级方法研究
{Author}: 饶剑;吕自玉
{Author Address}: 西南科技大学制造科学与工程学院;重庆交通大学经济与管理学院;
{Journal}: 科技与创新
{Year}: 2022
{Volume}: 
{Issue}: 05
{Pages}: 63-65
{Keywords}: 机器视觉;类球形水果;特征检测;外部品质分级
{Abstract}: 针对传统方法在水果品质分级中存在的人工成本高、分级精度低等问题，开发了一种基于机器视觉的类球形水果外部品质分级方法。通过预处理获得采集目标的前景图像，采用最小外接矩阵表征果形指数，结合形态学区域填充分析果面缺陷，同时根据两特征参量大小实现对类球形水果的外部品质分级。利用设计的类球形水果外形尺寸检测系统对脐橙开展了在线检测和分级实验。结果表明，对5个抽样脐橙进行横径检测中，检测值与实际测量值的最大相对误差低于0.8%，对100个脐橙进行品质分级中，总体平均识别率高达94.4%，验证了该方法可应用于类球形水果的外部品质分级。
{ISBN/ISSN}: 2095-6835
{Notes}: 14-1369/N
{URL}: https://link.cnki.net/doi/10.15913/j.cnki.kjycx.2022.05.020
{DOI}: 10.15913/j.cnki.kjycx.2022.05.020
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的学生课堂注意力分析研究
{Author}: 陈雪
{Tertiary Author}: 罗中明
{Publisher}: 哈尔滨理工大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 机器学习;人脸检测;表情识别;课堂注意力判定
{Abstract}: 随着科技的日益进步,如何促进现代教育课堂管理数据化和智能化发展成为迫切需要解决的问题。学生课堂注意力反映了学习者对教师所授知识的掌握状态,让学习者与教课者都能根据学习状态调整学习与教课方案,同时也侧面反映出课堂的教学质量。近年来,很多信息技术用于对学生课堂注意力的分析,通过视频技术采集学生信息的方式具有实时性好、覆盖面积大等优点。通过视频来分析学生课堂注意力,这种方法存在光照、遮挡等问题使人脸检测精度降低,目前对学生课堂注意力的研究多侧重于学生表情或课堂低头率等单一特征,无法更准确的反应学生的课堂注意力状态。根据以上问题,本文针对课堂场景对学生进行人脸检测、对课堂表情、头部姿态、疲劳状态和学生坐姿倾斜程度进行了深入分析和研究,作为判定学生课堂注意力的主要判定指标,其具体研究内容如下:1.介绍了学生注意力集中度判定在国内外的研究进展与相关技术等,对技术研究形势及目前状况做出阐述,针对学生专注度检测做出详细研究方案。2.将改进MTCNN(Multi-task Cascaded Convolutional Networks)人脸检测算法结合SSH(Single Stage Headless Face Detector)人脸检测算法运用于教室环境下的多目标人脸检测,并通过实验展示算法的检测性能。3.根据课堂环境重新定义6种课堂表情,将改进Alexnet卷积神经网络用于学生课堂表情识别。根据Landmark技术获取眼部和嘴部的关键点,结合PERCLOS(Percentage of Eye Iid CIosure Over The Pupi I Over Time)原理判断学生疲劳状态。基于Head Pose Estimation算法检测学生头部姿态,通过Openpose算法获取人体关节点坐标信息,通过人体左右肩膀处关节点间连线与水平方向形成夹角描述身体倾斜度,分别进行机器识别与人工检测试验测试算法准确性。4.以人脸表情、身体倾斜度、嘴巴张开程度、眼睛闭合程度、头部方向为注意力集中度评价特征,利用模糊综合评价算法对学生注意力集中度进行评判,并对模型评判结果进行实验验证与结果分析。
{URL}: https://link.cnki.net/doi/10.27063/d.cnki.ghlgu.2022.000286
{DOI}: 10.27063/d.cnki.ghlgu.2022.000286
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于改进YOLO v3网络的齿轮毛刺检测方法
{Author}: 田峰;高龙琴;李鹭扬
{Author Address}: 扬州大学机械工程学院;
{Journal}: 机床与液压
{Year}: 2022
{Volume}: 50
{Issue}: 04
{Pages}: 56-59
{Keywords}: 机器视觉;YOLO v3网络;齿轮毛刺
{Abstract}: 由于齿轮毛刺位置的特殊性以及周围环境的相似性，传统的图像处理方法并不能取得很好的效果。因此，提出一种基于改进YOLO v3网络的目标检测算法，实现对齿轮毛刺特征的快速检测。通过提高网络输入的分辨率和调整网络结构的方法，使改进YOLO v3网络的性能得到进一步优化，提高检测效率。在制作标签前，采用张氏标定法消除镜头畸变对图片的影响。结果表明：与原YOLO v3网络相比，改进后的网络具有更优的检测效果，其网络大小减少了1/4,而检测速度提高了近2倍。
{ISBN/ISSN}: 1001-3881
{Notes}: 44-1259/TH
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvziZDiP0qye0-PmsQzT1f9rx1CThDr1Kwv6wUqq0nTwhgQxYHHcHY9Y55yysCMfy2aJgJfnaPp318ki9Ki5WFnErdahr88iW2GuZmN1PA24gy5uzy-Egj7fZ8KS-VutZfeI_75mhh57MZmaFUVyuQyVuXiqtUbPG5G6yu0G_7MTdNPCa6LG1WCz6sQroYzUK6c=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉和YOLOv4的破损鸡蛋在线检测研究
{Author}: 赵祚喜;罗阳帆;黄杏彪;袁凯;黄渊;曹阳阳
{Author Address}: 华南农业大学工程学院;广州广兴牧业设备集团有限公司;
{Journal}: 现代农业装备
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 8-16
{Keywords}: 深度学习;YOLOv4;破损鸡蛋;在线检测
{Abstract}: 破损鸡蛋导致的漏液会污染自动化生产线和完好鸡蛋，不仅影响生产效率，还会干扰裂纹鸡蛋的检测。为实现破损鸡蛋快速、准确、低成本的识别，本文利用机器视觉技术，并结合深度学习网络深层次特征提取、高精度检测分类的特性，提出一种基于YOLOv4网络的破损鸡蛋检测方法。构建破损鸡蛋图像数据集，搭建YOLOv4深度学习网络，训练含有破损蛋和完好蛋图像的分类模型；并对比YOLOv4与YOLOv3、Faster RCNN网络模型对破损蛋的识别精度；同时为验证YOLOv4的在线检测能力，模拟搭建鸡蛋实际生产环境，对比不同破壳鸡蛋比例、不同移动速度下的检测精度。研究结果如下：相同数据集下，YOLOv4识别精度高出YOLOv3、Faster RCNN网络模型平均值4.62%；在线检测时，YOLOv4模型对含不同比例的破损蛋识别正确率平均为86.22%；鸡蛋生产线移动速度在5～6 m/min下，识别正确率平均为84.91%。结果表明，本文提出的基于YOLOv4的破损鸡蛋检测方法对流水线上移动的鸡蛋有较好的检测效果，检测速率较高，为鸡蛋智能化生产、品质检测提供一种新的方法，具有一定的实用价值。
{ISBN/ISSN}: 1673-2154
{Notes}: 44-1616/S
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvyF68EOfUpq_mv9cYCcDgv_p0fjrTxuk0bS3iPfV1wKZMYX50XyDpBsM5o1jlV7wOeOameoeDtFPxlsgB86qtNT-1nriVjo4jNtf_Xt-5lK9FPNKvSoiBU64RwlQLsXS6mtl948ae_KV5XXmeCW-qJCech0fEJ_p1oLniCr78s_udfBw0amSTp6LynO-eqMnaw=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于计算机视觉的建筑施工期临时结构损伤识别方法
{Author}: 梁振宇;华嘉皓;陈浩龙;邓逸川
{Author Address}: 华南理工大学土木与交通学院;亚热带建筑科学国家重点实验室;
{Journal}: 图学学报
{Year}: 2022
{Volume}: 43
{Issue}: 04
{Pages}: 608-615
{Keywords}: 欧拉运动放大;临时结构;计算机视觉;结构损伤识别;损伤动力指纹
{Abstract}: 建筑施工临时结构是施工现场的事故主要风险源。以往的基于振动的临时结构监测方法依赖于在预先分析确定的监测关键部位放置的加速度传感器。但由于临时结构存在构件搭设不规范、施工现场不确定性等因素，通过有限元分析等手段得到的监测关键部位可能与实际情况相差较大，存在不确定性。为此提出一种基于欧拉运动放大算法的临时结构损伤识别方法，充分利用计算机视觉技术的全域覆盖及监测高效的优点。采用数码摄像机采集临时结构的数字图像序列，经过基于相位的欧拉运动放大算法处理，获取运动放大后的数字图像序列；运用Canny边缘识别算法获取边缘图像序列并消除运动放大造成的噪声，通过基于形心的运动跟踪算法获取临时结构的位移时程数据，并利用快速傅里叶变换进行频谱分析；与预先建立的损伤动力指纹库进行对比判断临时结构的损伤状态。以存在10种损伤状态的门式脚手架为测试对象，证明该方法的可行性与适用性。与加速度传感器测量进行对比，该方法平均误差为0.95%，满足临时结构损伤状态识别的精度要求。
{ISBN/ISSN}: 2095-302X
{Notes}: 10-1034/T
{URL}: https://link.cnki.net/urlid/10.1034.T.20220224.1435.002
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于深度学习的图像语义分割算法的应用研究
{Author}: 朱贺
{Author Address}: 华中科技大学;
{Journal}: 电子元器件与信息技术
{Year}: 2022
{Volume}: 6
{Issue}: 02
{Pages}: 196-198
{Keywords}: 计算机技术;数据;深度学习;图像分割
{Abstract}: 随着近年来计算机技术的高速发展，各种高科技的产品不断出现在我们的生活中，数据已经成为我们生活中不能分割的部分。图像分割技术已经在生活中有了很广泛的应用，同时随着计算机的发展，基于深度学习的数据处理方法能够处理大量的数据信息，同时其也有着比较好的图像语义分割效果。但是在实际使用过程中，由于深度学习仍存在许多不足，神经网络需要进行大量的训练准备工作才能够投入实际的使用过程中，不仅如此相关参数的设计和结构都决定着神经网络的工作效率，大量的专业人才、知识、时间和精力的投入使得效率不能得到提升。基于此，本文提出了使用边界框来实现对图像语义的分割，从而实现在弱监督条件下获得比较精准的分割精度，同时通过在实际交通中的应用进行了验证。验证结果表明，提出的改进算法能够获得比较好的图像语义分割效果。
{ISBN/ISSN}: 2096-4455
{Notes}: 10-1509/TN
{URL}: https://link.cnki.net/doi/10.19772/j.cnki.2096-4455.2022.2.075
{DOI}: 10.19772/j.cnki.2096-4455.2022.2.075
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于ROS和机器视觉的移动回收机器人设计
{Author}: 曾梓锐;梁永盛;黄永鹏;刘东湖;李欣
{Author Address}: 广东石油化工学院计算机学院;
{Journal}: 广东石油化工学院学报
{Year}: 2022
{Volume}: 32
{Issue}: 01
{Pages}: 41-46
{Keywords}: ROS;移动机器人;机器视觉
{Abstract}: 为解决室外人工清理、分类垃圾的重复劳作、费时费力等问题，设计一款基于ROS与人工智能技术的垃圾回收机器人。机器人基于ROS架构和图像分类技术设计，使用采集的垃圾图像进行学习得到分类模型。利用机器视觉获得物体图像，识别垃圾种类，使用Open CV辅助机械臂抓取物体。该设计兼容性高，二次开发方便，解决了面对复杂多样的物体机器人系统需进行大规模控制改动的问题。
{ISBN/ISSN}: 2095-2562
{Notes}: 44-1684/Z
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvzb2N4zPVNFFGeChFq7uecBiQ2ZizJ5EIvFH-zbixW1Famtu4es8rScggYqXju_E1fmLpX-wm0_nt3dRjnftbiZ84wzy6aOeu6x7bdDo-FgMwVTHNoqCUAR9OLAfzPK-Nq5lOAMud7bjGOgFQ23jegUDoKIOc3_e9kftz89KM5h53LOX5nPd5YtHpfED8Hj4Yk=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉与改进遗传算法的机械手分拣方法研究
{Author}: 周志霄;王宸;张秀峰;刘超;唐禹;张伟
{Author Address}: 湖北汽车工业学院机械工程学院;上海大学上海市智能制造与机器人重点实验室;
{Journal}: 制造技术与机床
{Year}: 2022
{Volume}: 
{Issue}: 02
{Pages}: 25-29
{Keywords}: 零件分拣;天牛须搜索;遗传算法;路径规划;机器视觉
{Abstract}: 针对机械零部件快速分拣需求,提出一种基于机器视觉与天牛须改进遗传算法(BAS-GA)的机械手分拣方法。该分拣方法首先对零件图像进行预处理,然后利用Sift特征匹配的图像识别算法提取零件图像,并使用仿射变换对目标零件定位。接着,对得到的零件位置建立数学模型,使用BAS-GA算法求解该数学模型,得到机械手的抓取路径,实现机械手的快速分拣。实验表明BAS-GA算法相对于模拟退火算法,遗传算法和一种改进蚁群算法都取得了较好的寻优效果。经过优化后的路径缩短了11%,说明该方法可有效提升机械手分拣速度。
{ISBN/ISSN}: 1005-2402
{Notes}: 11-3398/TH
{URL}: https://link.cnki.net/doi/10.19287/j.cnki.1005-2402.2022.02.004
{DOI}: 10.19287/j.cnki.1005-2402.2022.02.004
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 红外弱光下多特征融合与注意力增强铁路异物检测
{Author}: 陈永;王镇;卢晨涛;张娇娇
{Author Address}: 兰州交通大学电子与信息工程学院;甘肃省人工智能与图形图像处理工程研究中心;
{Journal}: 北京航空航天大学学报
{Year}: 2023
{Volume}: 49
{Issue}: 08
{Pages}: 1884-1895
{Keywords}: 机器视觉;红外弱光;异物检测;自适应特征融合;空洞卷积增强注意力模块;无锚框网络
{Abstract}: 针对红外弱光环境下铁路异物检测时存在目标特征提取不充分、检测精度及实时性低的问题，在CenterNet目标检测模型的基础上，提出了一种红外弱光下多特征融合与注意力增强的无锚框异物检测深度学习模型。在红外目标多尺度特征提取的基础上，引入自适应特征融合(ASFF)模块，充分利用目标高层语义与底层细粒度特征信息，提升红外目标特征提取能力。通过提出的空洞卷积增强注意力模块(Dilated-CBAM)进行关键特征提取，扩大注意力模块感受野范围，克服了原始CenterNet卷积块感受野映射区域变窄、无法检测弱小目标的问题，提升了无锚框网络的检测精度。使用Smooth L1损失函数进行训练，克服了L1损失函数在网络训练过程收敛速度慢及训练不稳定解的问题。通过铁路红外数据集及现场实验测试，结果表明：所提方法较原始CenterNet模型平均检测精度提高了8.03%，检测框置信度提升了31.23%，平均检测速率是Faster R-CNN模型的9.6倍，所提方法在红外弱光环境下能够更加快速准确地检测出铁路异物，主客观评价均优于对比方法。
{ISBN/ISSN}: 1001-5965
{Notes}: 11-2625/V
{URL}: https://link.cnki.net/doi/10.13700/j.bh.1001-5965.2021.0591
{DOI}: 10.13700/j.bh.1001-5965.2021.0591
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 视觉引导机器人协作AGV上下料系统研究
{Author}: 吕开旺;王明睿;刘振国;郭瑞;田禛
{Author Address}: 北京机械工业自动化研究所;
{Journal}: 制造业自动化
{Year}: 2022
{Volume}: 44
{Issue}: 01
{Pages}: 123-126
{Keywords}: 机器视觉;目标定位;工件抓取
{Abstract}: 本文构建了一套引导机器人抓取物料的机器视觉定位系统。该系统以机器人,AGV和相机为硬件基础,借助软件平台对目标进行检测、识别及偏移误差计算等研究,在机器人程序内进行二次运算,根据相机软件运算的数据与机器人示教工件坐标系的数据建立偏移坐标模型,给出mark点偏移量与工件抓取点偏移量的转换关系,从而引导机器人精确抓取物料。经过实验数据验证,该系统具有较高的精度,可以精准有效的控制机器人对物料进行操作,对类似的作业类型有较好的参考价值。
{ISBN/ISSN}: 1009-0134
{Notes}: 11-4389/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxABGSSJLq8W8kSR4er15ATaFdFhmMXafnewvDHNl-J4JUkX71QGhQXxXWU5CRGiEZvFbWUY13Ayty7-3t-_5g7yvGiKwo1EqpPRT6AczzLuBjBDQUy0rFGN7JBSt0wZEfAtWg6IfvO7n_CrL8QRFED6SgxXaqtO190MGPBcYlKPgT-r8ijcNdegAUpTLfaZO0=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 车牌自动识别系统的设计与实现
{Author}: 梁宏炜
{Author Address}: 兰州职业技术学院;
{Journal}: 数字技术与应用
{Year}: 2022
{Volume}: 40
{Issue}: 01
{Pages}: 180-182
{Abstract}: <正>随着人工智能技术的迅猛发展,文字识别、图像识别技术都得到了快速的发展,这也为开发车牌自动识别提供了技术支持。本系统运用先进的图像处理、模式识别和人工智能技术,能够即时精准地快速识别出车牌中包含的所有的汉字、数字和字母,并直接提供识别结果,从而使得对于机动车辆的自动化监控和管理成为了现实。本系统采用Visual C#作为开发平台,结合开源、跨平台的计算机视觉库OpenCV搭建了交叉编译环境,采用模块化的设计理念,利用模块化的编程方法对各个基本功能模块进行设计与开发,得到了一套可视化的车牌自动识别系统软件。该软件系统密切贴合生活,
{ISBN/ISSN}: 1007-9416
{Notes}: 12-1369/TN
{URL}: https://link.cnki.net/doi/10.19695/j.cnki.cn12-1369.2022.01.58
{DOI}: 10.19695/j.cnki.cn12-1369.2022.01.58
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于Halcon的直齿圆柱齿轮参数检测
{Author}: 李徽;盛汝谦;周昊民
{Author Address}: 湖南理工学院机械工程学院;
{Journal}: 湖南理工学院学报(自然科学版)
{Year}: 2022
{Volume}: 35
{Issue}: 01
{Pages}: 41-43
{Keywords}: 机器视觉;齿轮参数;图像处理;Halcon
{Abstract}: 工业齿轮在机械传动及生产设备中具有广泛应用,齿轮精度对机械设备的性能和使用寿命有着重要影响.目前,测量齿轮参数主要采用三坐标测量仪、数控齿轮测量中心等接触式测量方法.但接触式测量装置的使用及维护成本较高,不利于大规模推广.研究基于Halcon软件的齿轮尺寸测量方法,首先通过拍摄得到齿轮图像,再用Halcon软件对图像进行处理,最后根据处理之后的图像进一步测量齿轮的参数.测量结果表明,所提方法可加快齿轮检测的速度,降低检测齿轮的成本,对齿轮无任何损伤,具有一定的实用性.
{ISBN/ISSN}: 1672-5298
{Notes}: 43-1421/N
{URL}: https://link.cnki.net/doi/10.16740/j.cnki.cn43-1421/n.2022.01.008
{DOI}: 10.16740/j.cnki.cn43-1421/n.2022.01.008
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 卷积神经网络在图片分类中层级结构效用分析
{Author}: 石慧;陈培辉;张海珍
{Author Address}: 汕尾职业技术学院;
{Journal}: 电脑编程技巧与维护
{Year}: 2022
{Volume}: 
{Issue}: 01
{Pages}: 132-135
{Keywords}: 卷积神经网络;图片分类;深度学习
{Abstract}: 卷积神经网络等深度学习算法在图片分类等计算机视觉应用领域取得了很好的效果。利用卷积神经网络算法对猫狗图片进行分类,取得较好的实验效果,通过对实验过程中图片、数据的中间层级输入、输出结果的比对分析,深入剖析了卷积神经网络在图片分类中的层级结构效用,提示深度学习框架下的计算机视觉技术具有明显的优势。
{ISBN/ISSN}: 1006-4052
{Notes}: 11-3411/TP
{URL}: https://link.cnki.net/doi/10.16184/j.cnki.comprg.2022.01.037
{DOI}: 10.16184/j.cnki.comprg.2022.01.037
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的智能车设计与实验研究
{Author}: 路亚宁;陆翔;方凤才
{Author Address}: 广西大学物理科学与工程技术学院;哈尔滨工业大学航天学院;南宁师范大学物理与电子工程学院;
{Journal}: 现代电子技术
{Year}: 2022
{Volume}: 45
{Issue}: 02
{Pages}: 177-182
{Keywords}: 智能车;机器视觉;目标检测;颜色识别;控制系统;目标定位;网络传输
{Abstract}: 为适应复杂且不适宜人操作的工作环境,设计一种机器视觉处理算法与智能系统控制算法相结合的智能车。首先,电脑端通过目标颜色识别算法、图像填充去噪算法以及最大轮廓检测算法实现物体的检测与定位;接着,根据物体与车体的距离与相对方位,智能车控制系统相应接收动作指令;最后,无线路由网络控制模块将该控制算法与智能车控制系统相结合,实现智能车的移动与机械臂的抓取。实验结果表明,该算法能够在复杂环境中准确识别目标颜色物体,判断物体的位置,为智能车的勘探、分拣等带来极大的便利。
{ISBN/ISSN}: 1004-373X
{Notes}: 61-1224/TN
{URL}: https://link.cnki.net/doi/10.16652/j.issn.1004-373x.2022.02.034
{DOI}: 10.16652/j.issn.1004-373x.2022.02.034
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的低对比度物体尺寸测量研究
{Author}: 王晓杰;莫绪涛;陶新宇;李轩;杨舟;黄仙山
{Author Address}: 安徽工业大学数理科学与工程学院;
{Journal}: 光学技术
{Year}: 2022
{Volume}: 48
{Issue}: 01
{Pages}: 27-33
{Keywords}: 机器视觉;图像处理;亚像素;尺寸测量;低对比度
{Abstract}: 工业零件的产品检测是保证零件质量合格最重要的环节。传统的接触式检测方法难以满足工业现场高效、高精度等需求,基于机器视觉的图像测量系统已广泛应用于检测产品的几何参数。非透明物体形成的高对比度图像的测量已经进行了大量的工作,针对透明物体形成的低对比度图像的研究相对较少。以直角棱镜为对象,开发了一种用于测量低对比度产品尺寸的图像测量系统。对不同光照强度下采集到的图像进行平均,得到平滑的图像;采用限制对比度的直方图均衡化算法增强图像的对比度和使用Zernike矩边缘检测算法确定精确的亚像素边缘。通过多个对比实验验证了改进算法的合理性和优越性。棱镜厚度的平均误差小于0.003mm,标准偏差小于0.0015mm。提出的方案为相对透明物体的高精度测量领域提供了一种可行性方案。
{ISBN/ISSN}: 1002-1582
{Notes}: 11-1879/O4
{URL}: https://link.cnki.net/doi/10.13741/j.cnki.11-1879/o4.2022.01.017
{DOI}: 10.13741/j.cnki.11-1879/o4.2022.01.017
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的林果识别定位技术进展分析
{Author}: 郑如新;孙青云;肖国栋;马素慧
{Author Address}: 南京林业大学机械电子工程学院;天津微深科技有限公司;河北科技师范学院机电工程学院;
{Journal}: 林业机械与木工设备
{Year}: 2022
{Volume}: 50
{Issue}: 01
{Pages}: 7-11
{Keywords}: 机器视觉;林果;定位;识别;检测;采摘
{Abstract}: 随着机器视觉的不断发展,应用的范围也在不断扩大,将机器视觉与林果采摘相融合,能够实现自动化、智能化采摘,不仅能够减轻劳动力,还能够增加采摘效率、实现林果产业化的可持续发展。文中主要概述了利用机器视觉以及人工智能中的一些算法在林果识别、定位和缺陷检测等产业化过程中的应用现状,同时分析了一些相关算法的不足之处,表明机器视觉在林果的采摘中扮演了重要的角色,林果的采摘也必然是朝着自动化、智能化、高效化、低成本化方向发展,同时也为我国农林业发展做出理论指导和技术支持。
{ISBN/ISSN}: 2095-2953
{Notes}: 23-1405/S
{URL}: https://link.cnki.net/doi/10.13279/j.cnki.fmwe.2022.0016
{DOI}: 10.13279/j.cnki.fmwe.2022.0016
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于人工智能的人脸图像识别校园安防系统设计
{Author}: 董新颐
{Author Address}: 滁州市应用技术学校;
{Journal}: 软件
{Year}: 2022
{Volume}: 43
{Issue}: 01
{Pages}: 151-153
{Keywords}: 人工智能;机器视觉;人脸检测;校园安防
{Abstract}: 当前,校园安防主要借助于专门的保安人员来对非校内人员进行甄别,这种方式不仅甄别准确性较低,并且效率也较低。为了对此问题进行解决,研究出一种以机器视觉技术为基础的校园安防智能识别系统。该系统可以对出入校门的人脸影像图进行动态采集,并根据OpenCv等算法,对这些采集到的影像图进行动态分析,然后对这些影像图的人脸特征进行检测。借助于数学算法对其进行处理,从而完成相应的人脸特征信息提取,这样就能将其与存储的信息进行对比,从而对出入人员进行动态甄别。这种方式不仅有着较高的甄别准确性,同时还具有颇高的检测效率,具有较高的推广与研究价值。
{ISBN/ISSN}: 1003-6970
{Notes}: 12-1151/TP
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvw01JO6_cmfnVu5mjva38XjCuNUnI3yTmglZ8u9YDHjYb1QbpYj5gbjHAB4u7jiw-TJHIaKeBJUrp9uPh212OikcKdIIKJOe3ww0W3ATxM-bd-fMObuYI_YbFz-SwptpVoK3D05eV2ay8z05-qIEW4aXoWs13gI5WenMWJbsfDKuM-jq6RTsmJaUxcHO7ocY2Y=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的机采鲜茶叶智能分级技术
{Author}: 颜国霖;朱凤芝
{Author Address}: 黎明职业大学智能制造工程学院;
{Journal}: 集成电路应用
{Year}: 2022
{Volume}: 39
{Issue}: 01
{Pages}: 176-177
{Keywords}: 机器视觉;机器采茶;智能化分级
{Abstract}: 阐述机器视觉技术在机采茶鲜叶智能化分级中的应用,以传感器作为信息采集载体,利用不同类别的终端操控机构,保证机器视觉系统在运行过程中,进行数据采集与分析,驱动终端机构操作。
{ISBN/ISSN}: 1674-2583
{Notes}: 31-1325/TN
{URL}: https://link.cnki.net/doi/10.19339/j.issn.1674-2583.2022.01.071
{DOI}: 10.19339/j.issn.1674-2583.2022.01.071
{Database Provider}: CNKI

{Reference Type}: Journal Article
{Title}: 基于机器视觉的PCB元器件智能检测系统
{Author}: 郭瑞霞;韩钦;韩英向
{Author Address}: 天津中新华兴光电技术有限公司研发中心;
{Journal}: 科学技术创新
{Year}: 2022
{Issue}: 01
{Pages}: 105-108
{Keywords}: 机器视觉;阈值选择;缺陷检测;图像定位;HALCON
{Abstract}: 机器视觉技术的快速发展使得大量新应用成为可能，并在不断扩大的应用基础上提供尖端的解决方案。为了不断提高工业生产的效率和产品质量，降低生产过程中的经济成本和劳动成本，本设计由图像实时采集模块、图像预处理模块、阈值选取模块、图像定位模块、缺陷检测模块构成，达到了预期的缺陷检测效果，实现了高效益、低成本的目标。
{ISBN/ISSN}: 2096-4390
{Notes}: 23-1600/N
{URL}: https://kns.cnki.net/kcms2/article/abstract?v=bEegF8awJvxmn9qp8Yo1R_T64o-Erz5KqvOsS6O1MBSv-l3Gux9hDCyka5yYBwzxK4N_ak6RFzvLPLtnE8CP7lo1nLBhqZ-7ha4CwPP8e6zDxxBbbolkbnnOogEIkocluTPKNZuZxaHJeul8XNbm6rqDpICwS00TkwvBAfg0YyAPlQ6wySOeWYYrDVozgxBZAgnJv_2Z3-4=&uniplatform=NZKPT&language=CHS
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于YOLOv5的实时检测算法研究
{Author}: 李少君
{Tertiary Author}: 刘晓东
{Publisher}: 武汉邮电科学研究院
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 目标检测;YOLOv5;注意力机制;混类增强;K-means
{Abstract}: 随着深度学习越发成熟,目标检测已经成为计算机视觉领域中一项非常重要的基础性任务并受到了研究者们重点的关注。该技术已经被广泛的应用在如人脸识别、动作识别、实时监测等不同领域。在目标检测领域,较为主流的算法就是通过应用卷积神经网络来对图像进行特征提取的算法。随着算法的不断改进,如何针对复杂场景下图片特征的提取,同时保证不同尺度下的特征图的平衡性成为了提高算法模型精确度和实用性的关键。当今YOLOv5算法凭借出色的效果在该领域占据了主导地位。但是现实场景中不确定因素较多,YOLOv5针对复杂场景下的运用还需要根据不同需求进行优化改进。因此,设计一种检测性能更好,检测效果更稳定的模型成为了一项挑战。基于上述背景,本论文对YOLOv5算法进行改进,结合YOLOv5算法的几个阶段,提出在训练阶段将数据增强中加入混类增强,将注意力机制添加到YOLOv5网络结构之中,并且在自适应预测框计算阶段使用改进K-means算法并加深主干网络进行多尺度输入。具体改进包括三个方面:首先,为扩充YOLOv5算法训练数据,提出加入混类增强的数据增强方式。通过设置0.5的常数系数以达到Copy-paste同等的尺度缩放效果。其次,YOLOv5中使用K-means算法结合遗传算法实现的自适应锚框更新,该方法在锚框的选取上,利用YOLOv5作为相似性的评价标准,但是IOU无法精确反映两者重合度大小。本论文提出使用GIOU代替IOU作为标准,完善了锚框自适应更新的合理性,同时,使用K-means算法匹配新的锚点坐标,将YOLOv5算法中的3个检测尺度扩展为4个,提高模型检测精度。最后,为解决YOLOv5中不同尺度下的特征的不平衡问题提出添加注意力模块。针对选取的数据集在网络结构添加注意力模块,使检测网络能够根据权重提取重要信息,增加了网络的检测能力。对于本论文对模型的算法改进,利用安全帽佩戴检测数据集将改进后的算法和原检测算法进行对比实验,通过对比实验证明加入改进的混类增强机制对模型Map提升3.3%。同时将添加了不同注意力模块的网络与原网络进行对比实验,结果表明,添加不同注意力机制对算法性能提升不同,从而选取最优注意力模块构建检测系统。最后进行消融试验,结果表明改进后的模型比原有模型在平均精度上提高了5.2%。
{URL}: https://link.cnki.net/doi/10.27386/d.cnki.gwyky.2022.000014
{DOI}: 10.27386/d.cnki.gwyky.2022.000014
{Database Provider}: CNKI

{Reference Type}: Thesis
{Title}: 基于机器视觉的激光焊接质量在线监测算法研究
{Author}: 高垠芮
{Tertiary Author}: 钟平
{Publisher}: 东华大学
{Type of Work}: 硕士
{Year}: 2022
{Keywords}: 激光焊接;在线质量识别;机器学习;抗干扰处理
{Abstract}: 激光焊接是一种先进焊接技术,与传统焊接技术相比较,其在焊接的精度、效率、可靠性和自动化等方面都有非常大的优越性。现有激光焊接质量检测方法大多为焊后检测,实现高效的激光焊接在线监测能更好的利用激光焊接可进行高速深熔焊接的优点。基于机器视觉的激光焊接缺陷监测系统可对激光焊接的过程进行实时监控,有助于提高激光焊接过程的效率,但现今仍存在不少问题有待解决。如何在激光焊接过程中,排除干扰信息(如:金属蒸汽、等离子体飞溅等),准确快速的提取焊接质量评价的特征信息,并进行缺陷识别,是激光焊接在线监测技术急需解决的一大问题。本文在国家重点研发计划项目“大型薄壁构件高质量激光焊接技术集成与高可靠性装备研制”(编号:2018YFB1107804)的资助下主要完成了以下工作:1)搭建了激光焊接质量在线监测实验系统,系统包含激光焊接系统、带辅助光的成像采集系统和图像处理系统三个部分。激光焊接系统主要采用一支机械臂搭载激光焊接头控制焊接过程,具备高稳定性、高功率的激光焊接作业能力;成像采集系统具备4000FPS、480pix*480pix的图像采集能力,同时采用了辅助照明激光与相匹配的滤光片,能过滤掉许多干扰信息,准确地捕捉焊接时的状态;图像处理系统主要为一台高算力计算机设备,使算力不会成为制约算法性能的瓶颈。2)将图像处理领域中基于暗通道先验的除雾算法引入激光焊接过程图像的处理过程中。在焊接过程图像中,金属蒸汽与等离子体等会对相机采集的图像会造成与自然界雾气对图像类似的影响,故在调整参数后可应用于焊接图像的抗干扰过程中。首先对高速相机采集到的焊接过程图像提取其暗通道图像,并使用导向滤波算法对暗通道图像进行细化,同时估计图像中的全局大气光照强度。然后根据大气散射物理模型进行计算,并还原无干扰图像。3)在抗干扰算法处理后的焊接图像中提取与图像特征较为显著的一些缺陷特征值。使用图像处理算法中常用的各种形态学滤波、边缘提取与图像分割等算法,对干净的焊接图像进行特征提取,主要关注小孔的轮廓信息与焊缝的宽度信息。其中,使用小孔的轮廓信息计算其Hu矩值作为小孔形貌的特征。4)使用机器学习算法对特征值进行分类,分别使用支持向量机、K临近分类、朴素贝叶斯算法和单隐层BP神经网络对数据集进行分类测试。在本文描述的数据集下,使用上述算法对抗干扰步骤前后的图像数据集进行检测,各类机器学习算法的分类准确率均有提升,最高提升了5.1%的分类准确率。其中单层BP神经网络对数据集的分类效果最好,在二分类情况下可达97.18%的分类准确率,在六分类的情况下可达91.29%的分类准确率。5)使用C++编程语言与Qt、Open CV等第三方库构建了集成激光焊接质量识别算法的客户端软件,软件能实现相机控制、激光焊接质量在线识别、图像显示回放、数据库存储、质量报表出具等功能。本文使用优化后的暗通道先验抗干扰预处理算法与基于轮廓与OTSU阈值分割的特征信息提取算法,对图像采集系统所采集的焊接图形进行特征提取,最后通过BP神经网络分类算法进行激光焊接缺陷识别。本文使用304不锈钢进行实验。实验证明,本文所提出的方法能有效的去除金属蒸汽与等离子体飞溅对特征信息的干扰,并达到97.18%的二分类识别率与91.29%的六分类识别率。
{URL}: https://link.cnki.net/doi/10.27012/d.cnki.gdhuu.2022.001878
{DOI}: 10.27012/d.cnki.gdhuu.2022.001878
{Database Provider}: CNKI

 